{
  "id": "arxiv_2502.20981v1",
  "text": "Distribution Prototype Diffusion Learning for Open-set Supervised\nAnomaly Detection\nFuyun Wang, Tong Zhang, Yuanzhi Wang, Yide Qiu, Xu Guo\nSchool of Computer Science and Engineering\nNanjing University of Science and Technology\nfyw271828@njust.edu.cn, tong.zhang@njust.edu.cn, yuanzhiwang@njust.edu.cn,\n121106010824@njust.edu.cn, guo.xu@njust.edu.cn\nXin Liu\nSeetaCloud Technology\nNanjing, China\nxin.liu@seetacloud.com\nZhen Cui\nSchool of Artificial Intelligence\nBeijing Normal University\nzhen.cui@bnu.edu.cn\nAbstract\nIn Open-set Supervised Anomaly Detection (OSAD), the\nexisting methods typically generate pseudo anomalies to\ncompensate for the scarcity of observed anomaly samples,\nwhile overlooking critical priors of normal samples, lead-\ning to less effective discriminative boundaries. To address\nthis issue, we propose a Distribution Prototype Diffusion\nLearning (DPDL) method aimed at enclosing normal sam-\nples within a compact and discriminative distribution space.\nSpecifically, we construct multiple learnable Gaussian pro-\ntotypes to create a latent representation space for abun-\ndant and diverse normal samples and learn a SchrÂ¨odinger\nbridge to facilitate a diffusive transition toward these pro-\ntotypes for normal samples while steering anomaly sam-\nples away.\nMoreover, to enhance inter-sample separa-\ntion, we design a dispersion feature learning way in hyper-\nspherical space, which benefits the identification of out-of-\ndistribution anomalies. Experimental results demonstrate\nthe effectiveness and superiority of our proposed DPDL,\nachieving state-of-the-art performance on 9 public datasets.\n1. Introduction\nAnomaly detection (AD) [15, 21, 42, 44] aims to iden-\ntify outliers significantly diverging from the prevailing sam-\nples in a dataset, and has a wide range of applications like\nindustrial inspection, medical image analysis, and scien-\ntific discovery, etc.\nRecently, unsupervised anomaly de-\ntection (UAD) [6, 11, 26, 28] and few-shot anomaly de-\ntection (FSAD) [12, 21, 22] have emerged as prominent\nresearch paradigms, emphasizing the modeling of normal\nsample distributions to discern anomalies effectively. Yet,\nthese methods often neglect prior knowledge from limited\nanomaly samples, resulting in imprecise delineation of nor-\nmal sample boundaries and reduced efficacy in differenti-\nating normal from anomaly instances. On the contrary, su-\npervised anomaly detection (SAD) [2, 20, 41] leverages a\nlimited subset of anomaly samples as prior knowledge, im-\nproving detection performance. However, this reliance on\nseen anomalies poses a risk of overfitting and hampers gen-\neralization to unseen anomalies in real-world settings.\nTo mitigate the challenge of limited generalization in-\nherent in closed-set training, we focus on open-set super-\nvised anomaly detection (OSAD) [1, 27, 45, 46], which\nutilizes a small set of known anomaly classes during train-\ning to identify unseen anomalies from open-set classes. By\nleveraging prior knowledge from observed samples, OSAD\nmethods could reduce false positive errors. To improve the\ngeneralized detection of unseen anomalies, DRA [9] lever-\nages data augmentation and outlier exposure to learn a de-\ncomposed anomaly representation comprising seen anoma-\nlies, pseudo-anomalies, and potential residual anomalies.\nBGAD [41] leverages decision boundaries derived from\nnormalized flow models to capture and model anomaly in-\nformation.\nRecently, AHL [45] simulates heterogeneous\nanomaly distributions and performs collaborative differen-\ntiable learning to further enhance the modelâ€™s generality.\nWhile data augmentation and outlier exposure tech-\nniques [9, 19, 33] have demonstrated considerable success\nin anomaly detection, they fall short in generating com-\nprehensive pseudo anomalies, capturing only a fraction of\npotential unseen anomalies.\nThis limitation arises from\noverlooking the intricate nature of real-world anomaly dis-\ntributions, thereby hindering the modelâ€™s ability to gener-\nalize to novel anomaly types.\nAlthough AHL [45] has\narXiv:2502.20981v1  [cs.CV]  28 Feb 2025\n\n\nmade strides in addressing this issue by simulating hetero-\ngeneous anomaly distributions, it still relies on approximat-\ning unknown out-of-distribution anomalies using known in-\ndistribution anomalies for generalization. Yet, three critical\nissues persist: i) the simulation mechanism cannot cover all\nanomaly distribution patterns due to the varied scales and\nstructures of anomaly distributions; ii) simulated anoma-\nlies inherit in-distribution data biases, leading to subopti-\nmal performance on out-of-distribution anomalies; iii) the\ndiversity of normal samples presents dilemmas for existing\nmethods, complicating the differentiation between normal\nand anomaly boundaries. These issues prompt a fundamen-\ntal question: Instead of generating pseudo and uncertain\nanomaly samples, how can we accurately characterize com-\npact distribution boundaries amidst a range of diverse nor-\nmal samples and achieve robust generalization for unknown\nout-of-distribution anomalies?\nTo address the aforementioned issue, in this work,\nwe propose a Distribution Prototype Diffusion Learning\n(DPDL) method for open-set supervised anomaly detection.\nConsidering abundant and diverse normal samples but very\nlimited anomaly data, our method involves learning latent\ndistribution prototypes, specifically multiple Gaussian dis-\ntributions, onto which all observed normal samples can be\neffectively projected. To facilitate the mapping of normal\nsamples into the prototype space, we leverage SchrÂ¨odinger\nbridge (SB) framework, which enables a diffusive transi-\ntion by aligning the distributions of these samples with the\nprototypes.\nThe SB-based diffusion way could mitigate\nthe out-of-distribution issue for normal samples to some\nextent. Within the distribution prototype space, we push\nobserved anomaly samples away from normal samples to\nenhance discriminative capacity. Notably, both the proto-\ntypes and the diffusive bridge are learned jointly, resulting\nin a robust embedding space for normal samples. More-\nover, to enhance generalization across unseen anomaly do-\nmains, we introduce a dispersion feature learning mecha-\nnism that maps intermediate features to a hyperspherical\nspace, leveraging a mixture of von Mises-Fisher (vMF) dis-\ntributions. This approach bolsters directional feature ex-\ntraction and promotes robust inter-sample separation, facili-\ntating effective identification of out-of-distribution samples.\nExperiments demonstrate that our method greatly improves\ndetection capabilities for unseen anomalies. In the single-\nanomaly training setting, DPDL outperforms the next best-\nperforming method by over 8.3% on datasets including AI-\nTEX, ELPV, and Mastcam.\nIn summary, our contributions are three-fold: i) we pro-\npose a distribution prototype diffusion learning framework\nthat jointly learns multiple Gaussian prototypes and the as-\nsociated diffusion bridge, creating a compact and discrim-\ninative embedding space; ii) we develop dispersion feature\nlearning in hyperspherical space to enhance inter-sample\nseparation and improve generalization; iii) we achieve state-\nof-the-art performance in 9 public datasets, demonstrating\nthe efficacy of our approach.\n2. Related Work\nOpen-set Supervised Anomaly Detection. Open-set su-\npervised anomaly detection (OSAD) seeks to develop a ro-\nbust anomaly detection framework that generalizes from\na limited set of training anomalies to effectively iden-\ntify previously unseen anomalies within an open-set con-\ntext [1, 27, 34, 41, 46]. Leveraging the prior knowledge pro-\nvided by observed anomalies, contemporary OSAD meth-\nods significantly mitigate false positive errors, thereby en-\nhancing overall detection performance [9, 45]. Recently,\nDRA [9] learns disentangled representations of observed,\npseudo, and residual anomalies to boost the detection of\nboth seen and unseen anomalies. In contrast, AHL [45]\nsimulates diverse heterogeneous anomaly distributions and\nemploys collaborative differentiable learning, significantly\nimproving the modelâ€™s generalization capacity.\nSchrÂ¨odinger Bridge. SchrÂ¨odinger bridge (SB), widely\nrecognized as the entropy-regularized optimal transport\n(OT) problem, involves learning a stochastic process that\nevolves from an initial probability distribution to a terminal\ndistribution under the influence of a reference measure[5,\n7, 16, 18, 23, 24, 37]. I2-SB [25] and UNSB [14] learn\na nonlinear diffusion process between two given distribu-\ntions or represent the SB problem as a series of adversar-\nial learning problems to realize the image transformation\ntask. Recently, LightSB [10, 17] introduces a novel, fast,\nand simple SB solver, which achieves optimal matching in\npractice through the Gaussian mixture parameterization of\nthe adjusted schrÂ¨odinger potential.\n3. Preliminaries\nWe focus on how to build the connection between two dis-\ntributions p0 and p1, where the distributions are defined as\nabsolutely continuous Borel probability distributions with\nfinite second-order moments. Building upon the founda-\ntion of entropy-regularized optimal transport (EOT) [5, 7,\n16, 18, 23, 24, 32, 37], we review the related properties\nof EOT and the schrÂ¨odinger bridge (SB) problem with a\nWiener prior.\nEntropy-regularized optimal transport (EOT). Given\ntwo point sets Z0 and Z1, we seek for the optimal transport\ncost between any two points z0 âˆˆZ0 and z1 âˆˆZ1. This\ntask may be formulated as an EOT problem with a parame-\nter Ïµ > 0, i.e., minimizing the following objective:\nmin\nÏ€âˆˆÎ (p0,p1){\nZ\nRD\nZ\nRD\n1\n2âˆ¥z0 âˆ’z1âˆ¥2Ï€(z0, z1)dz0dz1\n+ÏµKL(z âˆ¥p0 Ã— p1)},\n(1)\n\n\nwhere Î (p0, p1) denotes the set of transport plans, i.e., joint\nprobability distributions on RD Ã— RD with marginals p0\nand p1, respectively, and KL denotes Kullback-Leibler di-\nvergence. The minimizer Ï€âˆ—of Eqn. (1) is guaranteed to\nexist, be unique, and absolutely continuous, and is referred\nas the EOT plan.\nSchrÂ¨odinger Bridge (SB). We define â„¦as the space\nof RD-valued functions over time t âˆˆ[0, 1], representing\ntrajectories in RD that start at t = 0 and end at t = 1.\nWe denote the set of probability distributions over â„¦, i.e.,\nstochastic processes, by P(â„¦). The differential of the stan-\ndard Wiener process is represented by dWt. For a process\nT âˆˆP(â„¦), we denote its joint distribution at t = 0, 1 by\nÏ€T âˆˆP(RD Ã—RD). Similarly, we use T|z0,z1 to denote the\ndistribution of T for t âˆˆ(0, 1), conditioned on Tâ€™s values\nz0 and z1 at t = 0 and t = 1, respectively.\nLet W Ïµ\nâˆˆP(â„¦) represents a Wiener process with\nvolatility Ïµ > 0, starting from p0 at t = 0. Its differential\nis governed by the stochastic differential equation (SDE):\ndW Ïµ\nt = âˆšÏµ dWt. The SchrÂ¨odinger bridge problem with the\nWiener prior W Ïµ between p0 and p1 is minimizing:\nmin\nT âˆˆF(p0,p1) KL(T âˆ¥W Ïµ),\n(2)\nwhere F(p0, p1) âŠ‚P(â„¦) denotes the subset of stochastic\nprocesses that begin with distribution p0 at t = 0 and reach\np1 at t = 1. This problem has a unique solution, a SDE\ndiffusion process T âˆ—defined: dZt = gâˆ—(Zt, t) dt + dW Ïµ\nt .\nThe process T âˆ—is referred to as SB, and gâˆ—: RD Ã—[0, 1] â†’\nRD is the optimal drift.\nCharacterization of solutions. The EOT plan Ï€âˆ—=\nÏ€T âˆ—takes a specific form [18]:\nÏ€âˆ—(z0, z1) = uâˆ—(z0)exp(âˆ’âˆ¥z0 âˆ’z1âˆ¥2\n2Ïµ\n)vâˆ—(z1),\n(3)\nwhere uâˆ—, vâˆ—: R â†’R+ are measurable functions known as\nSchrÂ¨odinger potentials. The optimal drift gâˆ—is derived as:\ngâˆ—(z, t) = Ïµâ–½zlog\nZ\nRD N(zâ€²|z, (1 âˆ’t)ÏµID)vâˆ—(zâ€²)dzâ€², (4)\n4. Method\n4.1. Problem Formulation\nLet Xtr = {(xi, yi)} denotes a weakly-supervised training\nset with only image-level labels, where xi denotes one RGB\nimage and yi âˆˆ{0, 1} denotes whether xi is an anomaly\nsample (anomaly: yi = 1, normal: yi = 0).\nHereby,\nXtr is consist of a normal subset X n\ntr (|X n\ntr | = N) and an\nanomaly subset X a\ntr (|X a\ntr | = M), formally, Xtr .= X n\ntr âˆªX a\ntr ,\nwhere generally N â‰«M.\nGiven a testing set Xte, we\nneed to predict whether one sample x âˆˆXte is anomaly\nor normal. In OSAD, the anomaly patterns of the testing\nset do less recurred in those encountered training set. In\nother word, the distribution of anomalies are obviously dis-\ncrepant, i.e., P(X a\nte) Ì¸= P(X a\ntr ). Hereby, we need to learn a\nrobust anomaly detection model Ïˆ from the training set Xtr,\nso that Ïˆ accurately infers anomaly scores for test samples.\nOur abstract idea is to learn latent distribution proto-\ntypes that not only encapsulate normal samples in a con-\ncise manner but also discriminate against anomaly sam-\nples. Given the abundance of observed normal samples, one\nnatural approach is to characterize the distribution P(X n\ntr ),\nwhere samples outside this distribution, x /âˆˆP(X n\ntr ), would\nbe awarded higher probabilities as anomalies. Considering\nthe inherent diversity of normal samples, we endeavor to\nlearn multiple simple distributions (e.g., Gaussians) as pro-\ntotypes PMGP, named multi-Gaussian prototypes (MGP). To\nembed input data into the prototype space, we introduce a\ngenerative bridge model Ïˆp for distribution transformation.\nThe more abstract formulation is given as follows:\nmin\nÏˆp,PMGP,fDp(Ïˆp(Fn\ntr), Ïˆp(Fa\ntr), PMGP)+Î»Ds(Fn\ntr, Fa\ntr), (5)\ns.t. , Ïˆp : P(F)\nbridge\nâˆ’â†’PMGP,\n(6)\nf : X\nfeature\nâˆ’â†’F,\n(7)\nwhere PMGP denotes the distribution prototypes to be\nlearned, Ïˆp is the flow function across probability distribu-\ntions, Dp signifies the discriminative function in the space\nof prototypes, f stands for the feature extraction process,\nand Ds acts as a regularizer to increase feature discrim-\ninability. In the above formulation, besides distribution pro-\ntotype learning (DPL), we also introduce dispersion feature\nlearning (DFL) executed within a hyperspherical embed-\nding space, i.e., Ds(Fn\ntr, Fa\ntr). The advantage of DFL is to\nprevent abrupt feature collapse in feature learning, thus pre-\nserving discriminative qualities. The overview of our frame-\nwork is abstractly depicted in Fig. 1. Detailed elaboration1\non these aspects will be provided in the subsequent sections.\n4.2. Distribution Prototype Learning\nDistribution prototype learning is operated in the feature\nspace. Hence, to extract intermediate image features, we\ncan leverage those classic networks as the backbone, such\nas ResNet-18. Formally, the feature extraction process, de-\nnoted as a function f : X â†’F, transforms an image\nx into the intermediate feature x = f(x)2âˆˆRd. Conse-\nquently, we designate the intermediate feature sets of nor-\nmal and anomaly samples as Fn\ntr = {xn\ni |i = 1, Â· Â· Â· , N} and\nFa\ntr = {xa\ni |i = 1, Â· Â· Â· , M}, respectively.\nConsidering the rarity of anomalies and the diversity of\nnormal samples, it is pertinent to capture the intricate dis-\ntributions of normal samples by mapping the distribution\n1The concrete algorithm is deferred to the supplementary material.\n2Here a flatten operation is used on convolution maps for vectorization.\n\n\nNormal Features\nAnomaly Features\nâ€¦\nâ€¦\nDispersion Feature Learning\nDistribution Prototype Learning\nâ„’DFL\nNormal Samples\nAnomaly Samples\nDistribution Prototypes\nTied\nSchrÃ¶dinger Bridge \nTied\nLearnable \nğ’«ğ’«MGP: {ğğğ‘˜ğ‘˜, ğ›”ğ›”ğ‘˜ğ‘˜}ğ‘˜ğ‘˜=1\nğ¾ğ¾\nMIL-based Anomaly Score \nComputation\nAnomaly Score\nScore Prediction\nDistribution Flow \nDistribution Flow \nDispersion Loss\nEncoder\nâ„±tr\na\nâ„±tr\nn\nğœ“ğœ“ğ‘ğ‘\nğœ“ğœ“ğ‘ğ‘\nâ„’DPL\nn\nğ‘“ğ‘“\nâ„’DPL\na\nFigure 1. Our proposed DPDL framework. It comprises three distinct modules: Distribution Prototype Learning (DPL, Sec. 4.2), Disper-\nsion Feature Learning (DFL, Sec. 4.3), and anomaly score prediction (Sec. 4.4). DPL transforms the distribution of normal samples to a\nspace of learnable multiple Gaussian prototypes through building schrÂ¨odinger bridge, meantime pushing anomaly distribution away from\nthese prototypes. DFL operates in a hyperspherical space, enlarging the distances of intermediate features of all samples in a hyperspher-\nical space to strengthen feature generalization for detecting anomalies. The score prediction module leverages a multi-instance-learning\nmethod to compute anomaly scores.\np0 = P(Fn\ntr) of intermediate features to a distinct and well-\ncharacterized distribution p1 like Gaussian. But due to vari-\nous normal samples, we opt for a multi-Gaussian prototypes\n(MGP) comprising multiple Gaussian distributions as pro-\ntotypes PMGP = {Pi .= N(Âµi, Ïƒi)|i = 1, Â· Â· Â· , C}. Given\na normal sample xn\ni , we expect to align it with the closest\nprototype with high likelihood. However, in the open-set\nsetting, it is challenge to transform unseen points x âˆ¼p0\nto the target distribution p1. Drawing inspiration from the\ncapability of diffusion generation models in aligning dis-\nparate distributions, we frame the transition from source\ndomain distribution p0 to target domain distribution p1 as a\nSchrÂ¨odinger bridge problem. As formulated in Eqn. (6), we\nneed learn an essential bridge flow Ïˆp : P(Fn\ntr)\nbridge\nâˆ’â†’PMGP.\nAfter bridge transformation, the condition probability in op-\ntimal transport plan conforms to:\nÏ€(Ïˆp(x)|x) âˆ\nC\nX\nc=1\nÎ±cN(Ïˆp(x); Âµc, Ïƒc))\n|\n{z\n}\n.=Ï•1(Ïˆp(x))\n,\n(8)\nwhere the parameters {Î±c, Âµc, Ïƒc}C\nc=1 (known as Gaussian\nmixed model (GMM), abstracted into the function Ï•1) as\nwell as the flow function Ïˆp (in bridge) need to be learned.\nFor simplicity, below we adopt diagonal matrices for Ïƒc.\nDrawing inspiration from previous works [10, 17], we\nreframe distribution prototype learning in Eqn. (8) as the\nSchrÂ¨odinger bridge. Given the specific form taken by the\nEOT plan described in Eqn. (3), we redefine these measur-\nable functions u, v : R â†’R+, termed SchrÂ¨odinger poten-\ntials, as follows:\nu(xn\ni ) .= exp(âˆ¥xn\ni âˆ¥2\n2Ïµ\n)Ï•0(xn\ni ),\n(9)\nv(Ïˆ(xn\ni )) .= exp(âˆ¥Ïˆ(xn\ni )âˆ¥2\n2Ïµ\n)Ï•1(Ïˆ(xn\ni )),\n(10)\nwhere Ï•0 is defined within the source feature domain Ftr,\nand Ï•1 is defined in Eqn. (8). Ïµ is set to 0.001 in our exper-\niments. Accordingly, Eqn. (3) can be converted to:\nÏ€(xn\ni , Ïˆ(xn\ni ))=Ï•0(xn\ni ) exp(âŸ¨xn\ni , Ïˆ(xn\ni )âŸ©\nÏµ\n)Ï•1(Ïˆ(xn\ni )), (11)\nHence, the condition probability of the transport plan in\nEqn. (8) could be exactly defined as\nÏ€(Ïˆ(xn\ni )|xn\ni ) .= Î·(xn\ni , Ïˆ(xn\ni ))Ï•1(Ïˆ(xn\ni )),\n(12)\nwhere the connection factor is denoted as Î·(xn\ni , Ïˆ(xn\ni )) =\n1\nÏ–(xn\ni) exp( âŸ¨xn\ni,Ïˆ(xn\ni)âŸ©\nÏµ\n)\nwith\nthe\nnormalization\nterm\nÏ–(xn\ni ) =\nR\nexp(âŸ¨xn\ni , Ïˆ(xn\ni )âŸ©)Ï•1(Ïˆ(xn\ni ))dÏˆ(xn\ni ). Accord-\ning to Eqns. (8) and (12), we can further derive a more\ntractable form:\nÏ€(Ïˆ(xn\ni )|xn\ni )=eÎ·(xn\ni )\nC\nX\nc=1\neÎ±c(xn\ni )N(Ïˆ(xn\ni );eÂµc(xn\ni ),Ïƒc), (13)\nwhere the normalization factor is denoted as eÎ·(xn\ni ) =\n1/ PC\nc=1 eÎ±c(xn\ni ), the coefficients of multi-Gaussian are de-\nfined as eÎ±c(xn\ni ) = Î±cexp( 1\n2(xn\ni )âŠºÏƒcxn\ni + 1\nÏµ (eÂµc)âŠº(xn\ni )), and\nthe mean vectors are calculated as eÂµc(xn\ni ) = Âµc + 1\nÏµ Ïƒcxn\ni .\n\n\nWe proceed with deriving the bridge function Ïˆp that\nrepresents a SDE process: dxt = g(xt, t)dt+âˆšÏµdWt where\nthe shift function g is solved. According to Eqn. (4), we can\nobtain the shift function of diffusion process as follows:\ng(xn\ni , t) = ÏµÏMGP(xn\ni )âˆ‡xn\ni log(N(xn\ni |0, Ïµ(1 âˆ’t))I),\n(14)\nwhere the coefficients ÏMGP defined on multiple dis-\ntribution prototypes is calculated as:\nÏMGP(xn\ni )\n=\nPC\nc=1(Î±cN(eÂµc(xn\ni )|0, Ïƒc)N(hc(xn\ni , t)|0, Î£t\nc)), with an-\nother Gaussian of hc(xn\ni , t) =\n1\nÏµ(1âˆ’t)xn\ni + Ïƒâˆ’1\nc\neÂµc(xn\ni ) and\nÎ£t\nc =\nt\nÏµ(1âˆ’t)I + Ïƒâˆ’1\nc . The derivation about Eqns. (13) and\n(14) is deferred to the supplementary material.\nDistribution prototypes initialization.\nJointly learning\nprototypes {Î±c, Âµc, Ïƒc}C\nc=1 and the bridge transformation\nÏˆp (also the shift g) is a challenging task as they are in-\nterdependent. For this, we leverage a vector quantization\nfunction to learn a codebook E of prototypes within a dis-\ncrete latent space from training data. Specifically, given an\ninput image feature xn\ni , we can assign xn\ni to the closest pro-\ntotype ek by minimizing the L2 distance between xn\ni and\neach of prototypes ec âˆˆE, as follows:\nmin\n{ec} Exn\niâˆˆFtr[âˆ¥xn\niâˆ’ecâˆ—âˆ¥2\n2], s.t. , câˆ—=arg min\nc\nâˆ¥xn\niâˆ’ecâˆ¥2, (15)\nwhere câˆ—denotes the index of the prototype closest to xn\ni .\nThe learned {ec}C\nc=1 are used to initialize the mean vectors\n{Âµc}C\nc=1, while the variances of all prototypes are set to the\nidentity matrix. We observe that this initialization strategy\naccelerates the training process.\nDistribution loss of normal and anomaly samples. As p0\nand p1 are accessible only via samples Ftr and prototypes\nPMGP, we optimize the empirical form in Eqn. (2) for nor-\nmal samples as follows:\nLn\nDPL = 1\nN\nN\nX\ni=1\nlog Ï–Î¸(xn\ni ) âˆ’1\nC\nC\nX\nc=1\nlog Ï•1(Âµc),\n(16)\nIn contrast, for anomaly samples, we aim to push anomaly\ndistribution away from p1, i.e., negative loss, formally,\nLa\nDPL = 1\nC\nC\nX\nc=1\nlog Ï•1(Âµc) âˆ’1\nM\nM\nX\ni=1\nlog Ï–Î¸(xa\ni ),\n(17)\n4.3. Dispersion Feature Learning\nA critical challenge in OSAD is detecting previously un-\nseen anomalies in open-set environments.\nDue to the\nlimited anomaly observations, existing methods often use\npseudo-anomaly generation strategies as a means of effec-\ntive data augmentation. Nonetheless, the effectiveness of\nthese methods heavily depends on the quality of the pseudo-\nanomaly feature embeddings.\nNotably, pseudo-anomaly\ndistributions often inherit biases from the in-distribution\ndata, which differ from the unknown anomaly distributions\nin out-of-distribution data. Current methods fail to address\nthe relationship between observed and unknown anomalies,\nparticularly for out-of-distribution generalization.\nTo improve out-of-distribution detection, it is essential\nto promote a larger inter-sample dispersion, as greater dis-\ntances among in-distribution samples facilitate their more\neffective separation from out-of-distribution samples.\nIn\nother words, if all inter-sample distances are close to zero,\ni.e., collapse to a single point, it becomes impossible to dif-\nferentiate between samples. Hence, promoting separability\nthrough a larger inter-sample dispersion is critical for accu-\nrately identifying samples that do not belong to known cate-\ngories. To do so, we map the features into a hyperspherical\nspace. Draws inspiration from the vMF distribution [30] in\ndirectional statistics, we compute spherical Gaussian distri-\nbutions for unit-norm features bxi = xi/âˆ¥xiâˆ¥2\n2. The proba-\nbility density function of a unit vector bxi âˆˆRD is defined\nin the hyperspherical space as follows:\npD(bxi; bxj, Îº) = FD(Îº) exp(ÎºâŸ¨bxi, bxjâŸ©),\n(18)\nwhere Îº â‰¥0 controls the concentration of the distribution\naround the mean direction bxj and FD(Îº) is the normaliza-\ntion factor. A larger Îº value increases concentration around\nthe mean, while in the extreme case Îº = 0, sample points\nare uniformly distributed on the hypersphere. Therefore, we\ndesign a dispersion loss to optimize large angular distances\nbetween the features of all samples:\nLDFL= 1\nU\nU\nX\ni=1\nlog\n1\nU âˆ’1\nU\nX\ni,j=1\n1{i Ì¸= j} exp(ÎºâŸ¨bxi, bxjâŸ©), (19)\nwhere U = N + M, and Îº is set to 10 in our experiments.\n4.4. Anomaly Score Prediction\nBased on the above designs, we leverage the multiple-\ninstance-learning (MIL)-based method proposed in [34] to\neffectively learn anomaly scores. Similar to the work [9],\nwe design three modules M = {Ma, Mn and Mr} for esti-\nmating anomaly scores. Firstly, for the feature map xi3, we\ngenerate pixel-wise feature vectors V = {vi}Hâ€²Ã—W â€²\ni=1\nto rep-\nresent the feature of small patches of the image xi, where\n(Hâ€², W â€²) denotes the size of the feature map. These pixel-\nwise representations are then mapped by an anomaly clas-\nsifier Sa to estimate pixel-level anomaly scores. To capture\nthose points with the most salient anomalies, we compute\nthe top-K most anomaly pixel points and define the loss\nfunction as:\nLMa(xi, yi) = Lbinary( 1\nK\nX\nTopK{Sa(vi; Î¸a)}, yi), (20)\n3Here xi refers to convolution maps without flattening (as used above).\n\n\nwhere Lbinary refers to a binary classification loss function,\nand TopK selects the highest K anomaly scores among all\nthe vectors. Secondly, we use Mn to learn the normal fea-\ntures:\nLMn(xi, yi) = Lbinary(Sn(\n1\nHâ€² Ã— W â€²\nHâ€²Ã—W â€²\nX\ni=1\nvi; Î¸n), yi),\n(21)\nwhere Sn : V â†’R is a fully connected binary anomaly\nclassifier. Finally, we define Mr to compute the residual\nanomaly scores between fine-grained visual semantics and\nabstract prototypes:\nLMr = Lbinary(Sr((Ïˆp(xi) âˆ’Âµcâˆ—)/Ïƒcâˆ—; Î¸r), yi),\n(22)\nwhere câˆ—denotes the index of the most probable prototypes,\ni.e., câˆ—= arg maxc N(Ïˆp(xi); Âµc, Ïƒc), and Sr utilize the\nsame method to obtain anomaly score as Sa.\nTraining. During the training phase, the SB and three\nprediction modules are jointly trained. To this end, we em-\nploy an objective function that encompasses three compo-\nnents as follows:\nL = LMa + LMn + LMr\n|\n{z\n}\nMIL-based learning\n+ Ln\nDPL + La\nDPL\n|\n{z\n}\nSB transform\n+ Î»LDFL\n| {z }\ndispersion\n. (23)\nwhere the coefficient Î» modulates the relative importance\nof dispersion loss, and the learnable parameters include\n{Î±c, Âµc, Ïƒc}, Î¸Ïˆp, and {Î¸a, Î¸n, Î¸r}.\nInference. During the test phase, we find the most sim-\nilar class prototype through SB, and subsequently compute\nthe anomaly score by adding the scores from both Sa and\nSr, while subtracting the normal score obtained from Sn for\nthe given test image.\nIn summary, we reduce all the above processes into an\nalgorithm given in the supplementary material for clarity.\n5. Experiment\n5.1. Dataset and Evaluation Metric\nDataset To validate the effectiveness of DPDL, compre-\nhensive experiments are conducted on nine real-world AD\ndatasets, including six industrial defect detection datasets\n(MVTec AD [3], Optical [40], SDD [?\n], AITEX [38],\nELPV [8], Mastcam [13]) and three medical image datasets\n(Hyper-Kvasir [4], Brain-MRI [36], HeadCT [36]). We fol-\nlow the previous OSAD baselines [9, 45] to adopt two pro-\ntocols for sampling, including general setting and hard set-\nting. The general setting assumes that anomaly examples\nare randomly sampled from the anomaly class, while the\nhard setting samples from a single class to assess general-\nization to new or unseen anomaly classes.\nEvaluation Metric We utilize the widely adopted Area Un-\nder ROC Curve (AUC) as a metric to evaluate the perfor-\nmance across all methods and settings. All reported AUCs\nare averaged results over five independent runs.\n5.2. Baselines\nWe compare DPDL against six related state-of-the-art\nOSAD baselines, including SAOE [19, 31, 39], MLEP [27],\nFLOS [35], DevNet [34], DRA [9], and AHL [45]. MLEP,\nDevNet, DRA, and AHL are specifically designed for\nOSAD. SAOE is a supervised detector enhanced with syn-\nthetic anomalies and anomaly exposure, whereas FLOS is\nan imbalanced classifier leveraging focal loss.\n5.3. Implementation Details\nThe input image size is 448Ã—448Ã—3. We set K in the top-\nK MIL to 10% of the number of all scores per score map.\nAdamW optimizer [29] is used for the parameter optimiza-\ntion using an initial learning rate 2Ã—10âˆ’4 with a weight de-\ncay of 1Ã—10âˆ’5. DPDL is trained on one NVIDIA GeForce\nRTX 4090 GPU, which are trained using 50 epochs, with 20\niterations per epoch. Following previous protocol [9, 45],\nwe evaluate performance with anomaly sample numbers of\nM = 10 and M = 1, and for robust detection of unseen\nanomalies, we use CutMix [43] to create pseudo-anomaly\nsamples as augmented data for known anomalies. The pro-\ntotype quantity C is set to 32 as default. Our code will be\navailable at our site4.\n5.4. Results under General Setting\nTab. 1 highlights DPDLâ€™s strong performance. In the chal-\nlenging scenario of single-anomaly detection, DPDL im-\nproves the performance of AHL [45] by more than 8.3%\non the AITEX, ELPV, and Mastcam datasets. Furthermore,\nit achieves significant improvements across six additional\ndatasets, which suggest the effective utilization of few-shot\nanomaly examples in DPDL, while mitigating overfitting to\nthe seen anomalies. When shifting to ten anomaly examples\nsettings, DPDL continues to maintain a significant lead with\nover 5.4% improvement on those datasets. Given the rich\nand diverse set of normal samples in these datasets, DPDL\nleverages the DPL component to encapsulate these samples\nwithin a compact, discriminative distribution space, while\neffectively pushing anomalous samples outside this space,\nthereby enabling accurate anomaly detection. In the setting\nwith ten abnormal samples, although existing methods have\nreached performance saturation on the MVTecAD, Optical,\nand SDD datasets, DPDL still has a certain lead, demon-\nstrating the strong ability of DPL and DFL in learning tight\nboundaries of normal sample distributions and generalizing\nto previously unseen anomaly domains. Furthermore, when\nevaluated on the medical datasets BrainMRI and HeadCT,\nDPDL demonstrates competitive performance despite these\ndatasets being notably small in scale and containing only a\nsingle class. This highlights the algorithmâ€™s ability to de-\nliver robust results even in data-scarce conditions.\n4https://github.com/fuyunwang/DPDL\n\n\nTable 1. AUC performance (mean Â± std) across nine real-world AD datasets is reported under the general setting. red highlights the best\nresults, and blue indicates sub-optimal outcomes. All baseline SOTA results are sourced from the original papers [9, 45].\nDataset\nDevNet\nFLOS\nSAOE\nMLEP\nDRA\nAHL\nDPDL (Ours)\nTen Training Anomaly Examples\nMVTec AD\n0.945Â±0.004\n0.939Â±0.007\n0.926Â±0.010\n0.907Â±0.005\n0.959Â±0.003\n0.970Â±0.002\n0.977Â±0.002\nOptical\n0.782Â±0.065\n0.720Â±0.055\n0.941Â±0.013\n0.740Â±0.039\n0.965Â±0.006\n0.976Â±0.004\n0.983Â±0.005\nSDD\n0.988Â±0.006\n0.967Â±0.018\n0.955Â±0.020\n0.983Â±0.013\n0.991Â±0.005\n0.991Â±0.001\n0.996Â±0.001\nAITEX\n0.887Â±0.013\n0.841Â±0.049\n0.874Â±0.024\n0.867Â±0.037\n0.893Â±0.017\n0.925Â±0.013\n0.975Â±0.007\nELPV\n0.846Â±0.022\n0.818Â±0.032\n0.793Â±0.047\n0.794Â±0.047\n0.845Â±0.013\n0.850Â±0.004\n0.937Â±0.003\nMastcam\n0.790Â±0.021\n0.703Â±0.029\n0.810Â±0.029\n0.798Â±0.026\n0.848Â±0.008\n0.855Â±0.005\n0.934Â±0.010\nHyper-Kvasir\n0.829Â±0.018\n0.773Â±0.029\n0.666Â±0.050\n0.600Â±0.069\n0.834Â±0.004\n0.880Â±0.003\n0.939Â±0.005\nBrainMRI\n0.958Â±0.012\n0.955Â±0.011\n0.900Â±0.041\n0.959Â±0.011\n0.970Â±0.003\n0.977Â±0.001\n0.969Â±0.005\nHeadCT\n0.982Â±0.009\n0.971Â±0.004\n0.935Â±0.021\n0.972Â±0.014\n0.972Â±0.002\n0.999Â±0.003\n0.981Â±0.003\nOne Training Anomaly Example\nMVTec AD\n0.780Â±0.020\n0.755Â±0.136\n0.834Â±0.007\n0.744Â±0.019\n0.883Â±0.008\n0.901Â±0.003\n0.927Â±0.002\nOptical\n0.523Â±0.003\n0.518Â±0.003\n0.815Â±0.014\n0.516Â±0.009\n0.888Â±0.012\n0.888Â±0.007\n0.915Â±0.002\nSDD\n0.881Â±0.009\n0.840Â±0.043\n0.781Â±0.009\n0.811Â±0.045\n0.859Â±0.014\n0.909Â±0.001\n0.917Â±0.003\nAITEX\n0.598Â±0.070\n0.538Â±0.073\n0.675Â±0.094\n0.564Â±0.055\n0.692Â±0.124\n0.734Â±0.008\n0.838Â±0.008\nELPV\n0.514Â±0.076\n0.457Â±0.056\n0.635Â±0.092\n0.578Â±0.062\n0.675Â±0.024\n0.828Â±0.005\n0.897Â±0.002\nMastcam\n0.595Â±0.016\n0.542Â±0.017\n0.662Â±0.018\n0.625Â±0.045\n0.692Â±0.058\n0.743Â±0.003\n0.838Â±0.011\nHyper-Kvasir\n0.653Â±0.037\n0.668Â±0.004\n0.498Â±0.100\n0.445Â±0.040\n0.690Â±0.017\n0.768Â±0.015\n0.821Â±0.007\nBrainMRI\n0.694Â±0.004\n0.693Â±0.036\n0.531Â±0.060\n0.632Â±0.017\n0.744Â±0.004\n0.866Â±0.004\n0.893Â±0.004\nHeadCT\n0.742Â±0.076\n0.698Â±0.092\n0.597Â±0.022\n0.758Â±0.038\n0.796Â±0.105\n0.825Â±0.014\n0.865Â±0.005\nTable 2. AUC results (mean Â± std) under the hard setting. The best and second-best results are highlighted in red and blue, respectively.\nCarpet and Metal nut are subsets of MVTec AD. The datasets used are consistent with those in [9, 45], where those datasets only containing\none anomaly class are excluded to adapt for the hard setting. For detailed class-level results, please refer to the supplementary materia.\nDataset\nDevNet\nFLOS\nSAOE\nMLEP\nDRA\nAHL\nDPDL (Ours)\nTen Training Anomaly Examples\nCarpet (mean)\n0.847Â±0.017\n0.761Â±0.012\n0.762Â±0.073\n0.751Â±0.023\n0.935Â±0.013\n0.949Â±0.002\n0.956Â±0.004\nMetal nut (mean)\n0.965Â±0.011\n0.922Â±0.014\n0.855Â±0.016\n0.878Â±0.058\n0.945Â±0.017\n0.972Â±0.002\n0.978Â±0.002\nAITEX (mean)\n0.683Â±0.032\n0.635Â±0.043\n0.724Â±0.032\n0.626Â±0.041\n0.733Â±0.009\n0.747Â±0.002\n0.798Â±0.005\nELPV (mean)\n0.702Â±0.023\n0.642Â±0.032\n0.683Â±0.047\n0.745Â±0.020\n0.766Â±0.029\n0.788Â±0.003\n0.818Â±0.003\nMastcam (mean)\n0.588Â±0.011\n0.616Â±0.021\n0.697Â±0.014\n0.588Â±0.016\n0.695Â±0.004\n0.721Â±0.003\n0.778Â±0.007\nHyper-Kvasir (mean)\n0.822Â±0.019\n0.786Â±0.021\n0.698Â±0.021\n0.571Â±0.014\n0.844Â±0.009\n0.854Â±0.004\n0.864Â±0.002\nOne Training Anomaly Example\nCarpet (mean)\n0.767Â±0.018\n0.678Â±0.040\n0.753Â±0.055\n0.679Â±0.029\n0.901Â±0.006\n0.932Â±0.003\n0.941Â±0.006\nMetal nut (mean)\n0.855Â±0.016\n0.855Â±0.024\n0.816Â±0.029\n0.825Â±0.023\n0.932Â±0.017\n0.939Â±0.004\n0.944Â±0.003\nAITEX (mean)\n0.646Â±0.034\n0.624Â±0.024\n0.674Â±0.034\n0.466Â±0.030\n0.684Â±0.033\n0.707Â±0.007\n0.753Â±0.005\nELPV (mean)\n0.648Â±0.057\n0.691Â±0.008\n0.614Â±0.048\n0.566Â±0.111\n0.703Â±0.022\n0.740Â±0.003\n0.762Â±0.003\nMastcam (mean)\n0.511Â±0.013\n0.524Â±0.013\n0.689Â±0.037\n0.541Â±0.007\n0.667Â±0.012\n0.673Â±0.010\n0.733Â±0.004\nHyper-Kvasir (mean)\n0.595Â±0.023\n0.571Â±0.004\n0.406Â±0.018\n0.480Â±0.044\n0.700Â±0.009\n0.706Â±0.007\n0.715Â±0.004\n5.5. Results under the Hard Setting\nTab. 2 summarizes the performance comparison under the\nhard setting. It is evident that DPDL achieves the highest\nAUC scores in both the single-anomaly and ten-anomaly\nsample settings. Specifically, compared to the closest com-\npeting method, AHL [45], DPDL achieves an improve-\nment in AUC scores ranging from 0.6% to 7.9% in the ten\nanomaly examples settings and from 0.5% to 8.9% in the\none anomaly example settings, respectively. The observed\nimprovement can be attributed to the strong generalization\nability of DPDL in detecting unseen anomaly classes, even\nwhen the model is trained on only a single anomaly class.\n5.6. Ablation Study\nThe ablation study in Fig. 2 highlights the critical roles of\nthe DPL and DFL components in improving DPDLâ€™s open-\nset anomaly detection. We denote the variants that remove\nonly DPL or DFL as â€˜DPDL w/o DPLâ€™ and â€˜DPDL w/o\nDFLâ€™, respectively. Compared to the full DPDL model, re-\nmoving neither DPL nor DFL leads to a significant AUC de-\ncline, illustrating their critical utility. Specifically, â€˜DPDL\n\n\nMVTec AD\nOptical\nSDD\nAITEX\n0.60\n0.65\n0.70\n0.75\n0.80\n0.85\n0.90\n0.95\n1.00\nAUC\nDPDL\nDPDL w/o DPL\nDPDL w/o DFL\nELPV\nMastcamHyper-KvasirBrainMRI HeadCT\n0.60\n0.65\n0.70\n0.75\n0.80\n0.85\n0.90\n0.95\n1.00\nDPDL\nDPDL w/o DPL\nDPDL w/o DFL\nCarpet\nMetal_nut\nAITEX\n0.60\n0.65\n0.70\n0.75\n0.80\n0.85\n0.90\n0.95\n1.00\nDPDL\nDPDL w/o DPL\nDPDL w/o DFL\nELPV\nMastcam\nHyper-Kvasir\n0.60\n0.65\n0.70\n0.75\n0.80\n0.85\n0.90\n0.95\n1.00\nDPDL\nDPDL w/o DPL\nDPDL w/o DFL\nTen Training Anomaly Examples Under General Settings\nTen Training Anomaly Examples Under Hard Settings\nFigure 2. Ablation study for SB and DFL under the general settings and hard settings.\n8\n16\n32\n64\nC\n0.90\n0.92\n0.94\n0.96\n0.98\n1.00\n1.02\nAUC\nMVTec AD\nOptical\nSDD\nAITEX\nELPV\nMastcam\nHyper-Kvasir\nBrainMRI\nHeadCT\n0.001\n0.01\n0.1\n1\n10\n0.90\n0.92\n0.94\n0.96\n0.98\n1.00\n1.02\nMVTec AD\nOptical\nSDD\nAITEX\nELPV\nMastcam\nHyper-Kvasir\nBrainMRI\nHeadCT\n0.1\n1\n10\n100\n1000\n0.90\n0.92\n0.94\n0.96\n0.98\n1.00\n1.02\nMVTec AD\nOptical\nSDD\nAITEX\nELPV\nMastcam\nHyper-Kvasir\nBrainMRI\nHeadCT\n0.0001\n0.001\n0.01\n0.1\n1\n10\n0.90\n0.92\n0.94\n0.96\n0.98\n1.00\n1.02\nMVTec AD\nOptical\nSDD\nAITEX\nELPV\nMastcam\nHyper-Kvasir\nBrainMRI\nHeadCT\nFigure 3. Parameter sensitivity analysis for C, Ïµ, Îº and Î».\nTable 3. An ablation study for Mn, Ma and Mr.\nMn\nMa\nMr\nAITEX\nELPV\nMastcam\nTen Training Anomaly Examples Under General Settings\n0.928 Â± 0.019 0.914 Â± 0.021\n0.899 Â± 0.036\n0.939 Â± 0.023 0.919 Â± 0.011\n0.908 Â± 0.017\n0.963 Â± 0.008 0.930 Â± 0.013\n0.924 Â± 0.019\n0.975 Â± 0.007\n0.937 Â± 0.003\n0.934 Â± 0.010\nTen Training Anomaly Examples Under Hard Settings\n0.746 Â± 0.025 0.797 Â± 0.026\n0.723 Â± 0.017\n0.758 Â± 0.035 0.802 Â± 0.024\n0.736 Â± 0.028\n0.781 Â± 0.014 0.811 Â± 0.018\n0.762 Â± 0.021\n0.798 Â± 0.005\n0.818 Â± 0.003\n0.778 Â± 0.007\nw/o DPLâ€™ exhibits the most significant performance drop\non industrial anomaly datasets, reflecting DPLâ€™s prominent\nrole in learning precise and tight distribution boundaries\nfor normal samples. By transforming normal samples into\nGaussian distribution prototype space and pushing abnor-\nmal samples away, DPL enhances the recognition ability of\nanomaly samples. Meanwhile, ablation studies on â€˜DPDL\nw/o DFLâ€™ further highlight the critical role of the DFL com-\nponent. By performing discreteness feature learning in hy-\nperspherical space, DFL enhances the generalization ability\nto out-of-distribution anomalies.\nAdditionally, the ablation experiments on Mn, Ma, and\nMr across three datasets in Tab. 3 reveal their varying con-\ntributions. DPDL shows the most significant performance\ndrop when Mr is removed, which illustrates that Mr plays\nthe most critical role in detecting anomalies. Furthermore,\nthe removal of Ma and Mn lead to a noticeable performance\ndrop in DPDL, which underscores their essential roles.\n5.7. Parameter Sensitivity Analysis\nFig. 3 illustrates the results of the four hyperparameters un-\nder the general settings across nine datasets. Overall, the\nperformance remains stable within a certain range of hyper-\nparameter variations, demonstrating the DPDLâ€™s robustness.\nPrototype quantity C.\nWe begin by investigating the\ncritical impact of the number of initialized prototypes\nC on distributed prototype learning in DPDL. We select\n{8, 16, 32, 64} as the values for the hyperparameters. As\nC increases, DPDLâ€™s performance improves steadily, but\nexcessively large values of C hinder the modelâ€™s effective-\nness. This phenomenon is particularly pronounced on AI-\nTEX, Mastcam, MVTecAD, and Hyper-Kvasir, which con-\ntain more categories. One possible explanation is that a pro-\ntotype space with too few prototypes loses discriminative\ninformation, while an excessively large number of proto-\ntypes reduces the compactness of the space.\nDPL trajectory Ïµ in Eqns. (9), (10), (11) and (14).\nIt\ncan be observed that, particularly on the AITEX, Mastcam,\nand MVTecAD datasets with a larger number of categories,\nDPDL exhibits a relatively stable performance decline as\nÏµ increases. As a crucial parameter in SB, Ïµ governs the\ntrajectory state. Since smaller values produce straighter tra-\njectories and larger values increase fluctuation, smaller Ïµ fa-\ncilitates sampling more robust abstract prototypes from the\nrelatively dispersed conditional distribution.\nDFL tightness Îº. According to Fig. 3, increasing Îº gener-\nally enhances model performance, but values above Îº = 10\nintroduce negative effects in certain scenarios. A possible\nreason is that excessive sample dispersion makes it more\n\n\nchallenging to tighten the normal distribution boundary.\nLoss parameter Î». We conduct a sensitivity analysis on\nthe loss parameters Î». It can be observe that setting Î» =\n0.01 achieves optimal performance on seven larger-scale\ndatasets, while Î» = 1 yields the best results on two datasets\nwith limited data. As Î» increases, the performance declines,\npotentially due to gradient conflicts among the dispersion\nloss, SB transform loss and the main task loss.\n6. Conclusion\nWe propose Distribution Prototype Diffusion Learning\n(DPDL) for OSAD. DPDL leverages schrÂ¨odinger bridge to\nmap the normal distribution to a prototype space, simultane-\nously repelling anomalies to facilitate precise anomaly de-\ntection. We propose a dispersion feature learning way in\nhyperspherical space, which benefits the detection of out-\nof-distribution anomalies.\nExperimental results illustrate\nDPDLâ€™s robustness in diverse anomaly detection scenarios.\nReferences\n[1] Andra\nAcsintoae,\nAndrei\nFlorescu,\nMariana-Iuliana\nGeorgescu, Tudor Mare, Paul Sumedrea, Radu Tudor\nIonescu, Fahad Shahbaz Khan, and Mubarak Shah.\nUb-\nnormal:\nNew benchmark for supervised open-set video\nanomaly detection.\nIn Proceedings of the IEEE/CVF\nconference on computer vision and pattern recognition,\npages 20143â€“20153, 2022. 1, 2\n[2] Aimira Baitieva, David Hurych, Victor Besnier, and Olivier\nBernard. Supervised anomaly detection for complex indus-\ntrial images. In Proceedings of the IEEE/CVF Conference\non Computer Vision and Pattern Recognition, pages 17754â€“\n17762, 2024. 1\n[3] Paul Bergmann, Michael Fauser, David Sattlegger, and\nCarsten Steger.\nMvtec adâ€“a comprehensive real-world\ndataset for unsupervised anomaly detection. In Proceedings\nof the IEEE/CVF conference on computer vision and pattern\nrecognition, pages 9592â€“9600, 2019. 6, 1\n[4] Hanna Borgli, Vajira Thambawita, Pia H Smedsrud, Steven\nHicks, Debesh Jha, Sigrun L Eskeland, Kristin Ranheim\nRandel, Konstantin Pogorelov, Mathias Lux, Duc Tien Dang\nNguyen, et al. Hyperkvasir, a comprehensive multi-class im-\nage and video dataset for gastrointestinal endoscopy. Scien-\ntific data, 7(1):283, 2020. 6, 1\n[5] Yongxin Chen, Tryphon T Georgiou, and Michele Pavon.\nOn the relation between optimal transport and schrÂ¨odinger\nbridges: A stochastic control viewpoint. Journal of Opti-\nmization Theory and Applications, 169:671â€“691, 2016. 2\n[6] Songmin Dai, Yifan Wu, Xiaoqiang Li, and Xiangyang\nXue.\nGenerating and reweighting dense contrastive pat-\nterns for unsupervised anomaly detection. In Proceedings of\nthe AAAI Conference on Artificial Intelligence, pages 1454â€“\n1462, 2024. 1\n[7] Valentin De Bortoli, James Thornton, Jeremy Heng, and Ar-\nnaud Doucet. Diffusion schrÂ¨odinger bridge with applications\nto score-based generative modeling. Advances in Neural In-\nformation Processing Systems, 34:17695â€“17709, 2021. 2\n[8] Sergiu Deitsch, Vincent Christlein, Stephan Berger, Claudia\nBuerhop-Lutz, Andreas Maier, Florian Gallwitz, and Chris-\ntian Riess. Automatic classification of defective photovoltaic\nmodule cells in electroluminescence images. Solar Energy,\n185:455â€“468, 2019. 6, 1\n[9] Choubo Ding, Guansong Pang, and Chunhua Shen. Catching\nboth gray and black swans: Open-set supervised anomaly\ndetection. In Proceedings of the IEEE/CVF conference on\ncomputer vision and pattern recognition, pages 7388â€“7398,\n2022. 1, 2, 5, 6, 7\n[10] Nikita Gushchin, Sergei Kholkin, Evgeny Burnaev, and\nAlexander Korotin. Light and optimal schrÂ¨odinger bridge\nmatching.\nIn Forty-first International Conference on Ma-\nchine Learning, 2024. 2, 4\n[11] Liren He, Zhengkai Jiang, Jinlong Peng, Liang Liu, Qian-\ngang Du, Xiaobin Hu, Wenbing Zhu, Mingmin Chi, Yabiao\nWang, and Chengjie Wang. Learning unified reference rep-\nresentation for unsupervised multi-class anomaly detection.\narXiv preprint arXiv:2403.11561, 2024. 1\n[12] Teng Hu, Jiangning Zhang, Ran Yi, Yuzhen Du, Xu Chen,\nLiang Liu, Yabiao Wang, and Chengjie Wang. Anomalyd-\niffusion: Few-shot anomaly image generation with diffusion\nmodel. In Proceedings of the AAAI Conference on Artificial\nIntelligence, pages 8526â€“8534, 2024. 1\n[13] Hannah R Kerner, Kiri L Wagstaff, Brian D Bue, Danika F\nWellington, Samantha Jacob, Paul Horton, James F Bell,\nChiman Kwan, and Heni Ben Amor. Comparison of novelty\ndetection methods for multispectral images in rover-based\nplanetary exploration missions. Data Mining and Knowledge\nDiscovery, 34:1642â€“1675, 2020. 6, 1\n[14] Beomsu Kim,\nGihyun Kwon,\nKwanyoung Kim,\nand\nJong Chul Ye. Unpaired image-to-image translation via neu-\nral schr\\â€ odinger bridge. arXiv preprint arXiv:2305.15086,\n2023. 2\n[15] Daehyun Kim, Sungyong Baik, and Tae Hyun Kim. San-\nflow: Semantic-aware normalizing flow for anomaly detec-\ntion. Advances in Neural Information Processing Systems,\n36:75434â€“75454, 2023. 1\n[16] Hyunsu Kim, Jongmin Yoon, and Juho Lee. Fast ensem-\nbling with diffusion schr\\â€ odinger bridge. arXiv preprint\narXiv:2404.15814, 2024. 2\n[17] Alexander Korotin, Nikita Gushchin, and Evgeny Bur-\nnaev.\nLight schr\\â€ odinger bridge.\narXiv preprint\narXiv:2310.01174, 2023. 2, 4\n[18] Christian LÂ´eonard. A survey of the schr\\â€ odinger problem\nand some of its connections with optimal transport. arXiv\npreprint arXiv:1308.0215, 2013. 2, 3\n[19] Chun-Liang Li, Kihyuk Sohn, Jinsung Yoon, and Tomas\nPfister. Cutpaste: Self-supervised learning for anomaly de-\ntection and localization. In Proceedings of the IEEE/CVF\nconference on computer vision and pattern recognition,\npages 9664â€“9674, 2021. 1, 6\n[20] Hanxi Li, Jingqi Wu, Hao Chen, Mingwen Wang, and Chun-\nhua Shen.\nEfficient anomaly detection with budget anno-\ntation using semi-supervised residual transformer.\narXiv\npreprint arXiv:2306.03492, 2023. 1\n\n\n[21] Xiaofan Li, Zhizhong Zhang, Xin Tan, Chengwei Chen,\nYanyun Qu, Yuan Xie, and Lizhuang Ma. Promptad: Learn-\ning prompts with only normal samples for few-shot anomaly\ndetection. In Proceedings of the IEEE/CVF Conference on\nComputer Vision and Pattern Recognition, pages 16838â€“\n16848, 2024. 1\n[22] Jingyi Liao, Xun Xu, Manh Cuong Nguyen, Adam Goodge,\nand Chuan Sheng Foo. Coft-ad: Contrastive fine-tuning for\nfew-shot anomaly detection. IEEE Transactions on Image\nProcessing, 2024. 1\n[23] Guan-Horng Liu, Tianrong Chen, Oswin So, and Evangelos\nTheodorou. Deep generalized schrÂ¨odinger bridge. Advances\nin Neural Information Processing Systems, 35:9374â€“9388,\n2022. 2\n[24] Guan-Horng Liu, Yaron Lipman, Maximilian Nickel, Brian\nKarrer, Evangelos A Theodorou, and Ricky TQ Chen. Gen-\neralized schr\\â€ odinger bridge matching.\narXiv preprint\narXiv:2310.02233, 2023. 2\n[25] Guan-Horng Liu, Arash Vahdat, De-An Huang, Evange-\nlos A Theodorou, Weili Nie, and Anima Anandkumar. i2-\nsb: Image-to-image schr\\â€ odinger bridge. arXiv preprint\narXiv:2302.05872, 2023. 2\n[26] Jiaqi Liu, Kai Wu, Qiang Nie, Ying Chen, Bin-Bin\nGao, Yong Liu, Jinbao Wang, Chengjie Wang, and Feng\nZheng.\nUnsupervised continual anomaly detection with\ncontrastively-learned prompt. In Proceedings of the AAAI\nConference on Artificial Intelligence, pages 3639â€“3647,\n2024. 1\n[27] Wen Liu, Weixin Luo, Zhengxin Li, Peilin Zhao, Shenghua\nGao, et al. Margin learning embedded prediction for video\nanomaly detection with a few anomalies. In IJCAI, pages\n023â€“3, 2019. 1, 2, 6\n[28] Xinyue Liu,\nJianyuan Wang,\nBiao Leng,\nand Shuo\nZhang.\nDual-modeling decouple distillation for unsuper-\nvised anomaly detection. arXiv preprint arXiv:2408.03888,\n2024. 1\n[29] I Loshchilov. Decoupled weight decay regularization. arXiv\npreprint arXiv:1711.05101, 2017. 6\n[30] Kanti V Mardia and Peter E Jupp. Directional statistics. John\nWiley & Sons, 2009. 5\n[31] Amir Markovitz, Gilad Sharir, Itamar Friedman, Lihi Zelnik-\nManor, and Shai Avidan. Graph embedded pose clustering\nfor anomaly detection.\nIn Proceedings of the IEEE/CVF\nConference on Computer Vision and Pattern Recognition,\npages 10539â€“10547, 2020. 6\n[32] Maxence Noble, Valentin De Bortoli, Arnaud Doucet, and\nAlain Durmus. Tree-based diffusion schrÂ¨odinger bridge with\napplications to wasserstein barycenters. Advances in Neural\nInformation Processing Systems, 36, 2024. 2\n[33] Guansong Pang, Chunhua Shen, and Anton Van Den Hen-\ngel. Deep anomaly detection with deviation networks. In\nProceedings of the 25th ACM SIGKDD international confer-\nence on knowledge discovery & data mining, pages 353â€“362,\n2019. 1\n[34] Guansong Pang,\nChoubo Ding,\nChunhua Shen,\nand\nAnton van den Hengel.\nExplainable deep few-shot\nanomaly detection with deviation networks. arXiv preprint\narXiv:2108.00462, 2021. 2, 5, 6\n[35] T-YLPG Ross and GKHP DollÂ´ar. Focal loss for dense ob-\nject detection.\nIn proceedings of the IEEE conference on\ncomputer vision and pattern recognition, pages 2980â€“2988,\n2017. 6\n[36] Mohammadreza\nSalehi,\nNiousha\nSadjadi,\nSoroosh\nBaselizadeh, Mohammad H Rohban, and Hamid R Ra-\nbiee.\nMultiresolution knowledge distillation for anomaly\ndetection.\nIn Proceedings of the IEEE/CVF confer-\nence on computer vision and pattern recognition, pages\n14902â€“14912, 2021. 6, 1\n[37] Yuyang Shi, Valentin De Bortoli, Andrew Campbell, and Ar-\nnaud Doucet. Diffusion schrÂ¨odinger bridge matching. Ad-\nvances in Neural Information Processing Systems, 36, 2024.\n2\n[38] Javier Silvestre-Blanes, Teresa Albero-Albero, Ignacio Mi-\nralles, RubÂ´en PÂ´erez-Llorens, and Jorge Moreno. A public\nfabric database for defect detection methods and results. Au-\ntex Research Journal, 19(4):363â€“374, 2019. 6, 1\n[39] Jihoon Tack, Sangwoo Mo, Jongheon Jeong, and Jinwoo\nShin. Csi: Novelty detection via contrastive learning on dis-\ntributionally shifted instances. Advances in neural informa-\ntion processing systems, 33:11839â€“11852, 2020. 6\n[40] Matthias Wieler and Tobias Hahn. Weakly supervised learn-\ning for industrial optical inspection. In DAGM symposium\nin, page 11, 2007. 6, 1\n[41] Xincheng Yao, Ruoqi Li, Jing Zhang, Jun Sun, and\nChongyang Zhang.\nExplicit boundary guided semi-push-\npull contrastive learning for supervised anomaly detection.\nIn Proceedings of the IEEE/CVF Conference on Computer\nVision and Pattern Recognition, pages 24490â€“24499, 2023.\n1, 2\n[42] Xincheng Yao, Ruoqi Li, Zefeng Qian, Lu Wang, and\nChongyang Zhang. Hierarchical gaussian mixture normal-\nizing flow modeling for unified anomaly detection. arXiv\npreprint arXiv:2403.13349, 2024. 1\n[43] Sangdoo Yun, Dongyoon Han, Seong Joon Oh, Sanghyuk\nChun, Junsuk Choe, and Youngjoon Yoo. Cutmix: Regu-\nlarization strategy to train strong classifiers with localizable\nfeatures. In Proceedings of the IEEE/CVF international con-\nference on computer vision, pages 6023â€“6032, 2019. 6\n[44] Qihang Zhou, Guansong Pang, Yu Tian, Shibo He, and\nJiming Chen. Anomalyclip: Object-agnostic prompt learn-\ning for zero-shot anomaly detection.\narXiv preprint\narXiv:2310.18961, 2023. 1\n[45] Jiawen Zhu, Choubo Ding, Yu Tian, and Guansong Pang.\nAnomaly heterogeneity learning for open-set supervised\nanomaly detection. In Proceedings of the IEEE/CVF Con-\nference on Computer Vision and Pattern Recognition, pages\n17616â€“17626, 2024. 1, 2, 6, 7\n[46] Yuansheng Zhu, Wentao Bao, and Qi Yu. Towards open set\nvideo anomaly detection. In European Conference on Com-\nputer Vision, pages 395â€“412. Springer, 2022. 1, 2\n\n\nDistribution Prototype Diffusion Learning for Open-set Supervised\nAnomaly Detection\nSupplementary Material\n7. Dataset Statistics\nExtensive experiments are conducted on nine real-world\nanomaly detection (AD) datasets. Tab. 4 provides key statis-\ntics for all datasets used in this study. We follow the exact\nsame settings as in previous open-set supervised anomaly\ndetection (OSAD) studies.\nSpecifically, for the MVTec\nAD dataset, we adhere to the original split, dividing the\nnormal samples into training and test sets. For the other\neight datasets, normal samples are randomly partitioned\ninto training and test sets at a 3:1 ratio.\nTable 4. The statistical information for nine real-world anomaly\ndetection (AD) datasets, with the first 15 rows detailing the subsets\nof the MVTec AD dataset.\nDataset\nOriginal Training\nOriginal Test\n|C|\nType\nNormal\nNormal Anomaly\nCarpet\n5\nTextture\n280\n28\n89\nGrid\n5\nTextture\n264\n21\n57\nLeather\n5\nTextture\n245\n32\n92\nTile\n5\nTextture\n230\n33\n83\nWood\n5\nTextture\n247\n19\n60\nBottle\n3\nObject\n209\n20\n63\nCapsule\n5\nObject\n219\n23\n109\nPill\n7\nObject\n267\n26\n141\nTransistor\n4\nObject\n213\n60\n40\nZipper\n7\nObject\n240\n32\n119\nCable\n8\nObject\n224\n58\n92\nHazelnut\n4\nObject\n391\n40\n70\nMetal nut\n4\nObject\n220\n22\n93\nScrew\n5\nObject\n320\n41\n119\nToothbrush\n1\nObject\n60\n12\n30\nMVTecAD\n73\n-\n3629\n467\n1258\nOptical\n1\nObject\n10500\n3500\n2100\nSDD\n1\nTextture\n594\n286\n54\nAITEX\n12 Textture\n1692\n564\n183\nELPV\n2\nTextture\n1131\n377\n715\nMastcam\n11\nObject\n9302\n426\n451\nHyper-Kvasir\n4\nMedical\n2021\n674\n757\nBrainMRI\n1\nMedical\n73\n25\n155\nHeadCT\n1\nMedical\n75\n25\n100\nâ€¢ MVTec AD [3] is a widely-used benchmark for defect de-\ntection, comprising 15 distinct categories, each of which\nincludes one or several subcategories. The dataset con-\ntains a total of 73 fine-grained anomaly classes at either\nthe texture or object level.\nâ€¢ Optical [40] is a synthetic dataset designed for industrial\noptical inspection and defect detection. The artificially\ngenerated data mimics real-world tasks.\nâ€¢ SDD [? ] is a defect product image detection dataset\nwith pixel-level defect annotations. The original images,\nwhich have a resolution of 500 Ã— 1250, are vertically di-\nvided into three segments. Each segment is then anno-\ntated at the pixel level.\nâ€¢ AITEX [38] is a fabric defect detection dataset that in-\ncludes 12 defect categories with pixel-level annotations.\nThe original images, which have a resolution of 4096 Ã—\n256, are cropped into multiple 256 Ã— 256 patches. Each\npatch is then re-annotated at the pixel level.\nâ€¢ ELPV [8] is a dataset for defect detection in electrolumi-\nnescence (EL) images of solar cells. It includes two types\nof defects, corresponding to different types of solar cells:\nmonocrystalline and polycrystalline.\nâ€¢ Mastcam [13] is a novelty detection dataset con-\nstructed from geological images captured by the mul-\ntispectral imaging system installed on the Mars rover.\nThe dataset includes typical images and images from\n11 novel geological classes.\nEach image comprises\nboth shorter-wavelength (color) channels and longer-\nwavelength (grayscale) channels, with this study focusing\non the shorter-wavelength channels.\nâ€¢ Hyper-Kvasir [4] is a large-scale, open-access gastroin-\ntestinal dataset collected during real endoscopy and\ncolonoscopy procedures.\nIt comprises four main cate-\ngories and 23 subcategories of endoscopic and colono-\nscopic images. This work focuses on endoscopic images,\nwhere anatomical landmark categories are considered as\nnormal samples and pathological categories are treated as\nabnormal samples.\nâ€¢ BrainMRI [36] is a brain tumor detection dataset obtained\nthrough magnetic resonance imaging (MRI).\nâ€¢ HeadCT [36] is a dataset for detecting intracranial hemor-\nrhage obtained through head computed tomography (CT)\nscans.\n8. Full Results under General Setting\nTab. 5 presents a comprehensive comparison of the pro-\nposed DPDL method with state-of-the-art (SOTA) ap-\nproaches under general settings.\nIt reports performance\nmetrics for each category within the MVTec AD dataset.\nOverall, the DPDL model consistently outperforms base-\nline methods across all application scenarios in both ten-\nshot and one-shot settings, achieving the best performance\nin terms of Area Under the Curve (AUC).\n\n\nTable 5. AUC performance (mean Â± std) across nine real-world AD datasets is reported under the general setting. red highlights the best\nresults, and blue indicates sub-optimal outcomes. All baseline SOTA results are sourced from the original papers [9, 45].\nDataset\nOne Training Anomaly Example\nTen Training Anomaly Examples\nDevNet\nFLOS\nSAOE\nMLEP\nDRA\nAHL\nDPDL (Ours)\nDevNet\nFLOS\nSAOE\nMLEP\nDRA\nAHL\nDPDL (Ours)\nCarpet\n0.746Â±0.076\n0.755Â±0.026\n0.766Â±0.098\n0.701Â±0.091\n0.859Â±0.023\n0.877Â±0.004 0.914Â±0.006\n0.867Â±0.040\n0.780Â±0.009\n0.755Â±0.136\n0.781Â±0.049\n0.940Â±0.027 0.953Â±0.001\n0.988Â±0.002\nGrid\n0.891Â±0.040\n0.871Â±0.076\n0.921Â±0.032\n0.839Â±0.028\n0.972Â±0.011\n0.975Â±0.005 0.999Â±0.001\n0.967Â±0.021\n0.966Â±0.005\n0.952Â±0.011\n0.980Â±0.009\n0.987Â±0.009 0.992Â±0.002\n0.999Â±0.001\nLeather\n0.873Â±0.026\n0.791Â±0.057\n0.996Â±0.007\n0.781Â±0.020\n0.989Â±0.005\n0.988Â±0.001 0.996Â±0.001\n0.999Â±0.001\n0.993Â±0.004 1.000Â±0.000\n0.813Â±0.158\n1.000Â±0.000 1.000Â±0.000\n1.000Â±0.000\nTile\n0.752Â±0.038\n0.787Â±0.038\n0.935Â±0.034\n0.927Â±0.036\n0.965Â±0.015\n0.968Â±0.001 0.994Â±0.002\n0.987Â±0.005\n0.952Â±0.010\n0.944Â±0.013\n0.988Â±0.009\n0.994Â±0.006 1.000Â±0.000\n0.999Â±0.001\nWood\n0.900Â±0.068\n0.927Â±0.065\n0.948Â±0.009\n0.660Â±0.142\n0.985Â±0.011\n0.987Â±0.003 0.998Â±0.002\n0.999Â±0.001 1.000Â±0.000\n0.976Â±0.031\n0.999Â±0.002 0.998Â±0.001 0.998Â±0.000\n0.998Â±0.001\nBottle\n0.976Â±0.006\n0.975Â±0.023\n0.989Â±0.019\n0.927Â±0.090\n1.000Â±0.000\n1.000Â±0.000 1.000Â±0.000\n0.993Â±0.008\n0.995Â±0.002\n0.998Â±0.003\n0.981Â±0.004 1.000Â±0.000 1.000Â±0.000\n1.000Â±0.000\nCapsule\n0.564Â±0.032\n0.666Â±0.020\n0.611Â±0.109\n0.558Â±0.075\n0.631Â±0.056\n0.665Â±0.030 0.757Â±0.017\n0.865Â±0.057\n0.902Â±0.017\n0.850Â±0.054\n0.818Â±0.063 0.935Â±0.022\n0.930Â±0.001\n0.976Â±0.004\nPill\n0.769Â±0.017\n0.745Â±0.064\n0.652Â±0.078\n0.656Â±0.061\n0.832Â±0.034\n0.840Â±0.003 0.842Â±0.002\n0.866Â±0.038 0.929Â±0.012\n0.872Â±0.049\n0.845Â±0.048\n0.904Â±0.024\n0.918Â±0.001\n0.923Â±0.001\nTransistor\n0.722Â±0.032\n0.709Â±0.041\n0.680Â±0.182\n0.695Â±0.124\n0.668Â±0.068\n0.796Â±0.003 0.748Â±0.002\n0.924Â±0.027\n0.862Â±0.037\n0.860Â±0.053 0.927Â±0.043\n0.915Â±0.025\n0.926Â±0.009\n0.928Â±0.001\nZipper\n0.922Â±0.018\n0.885Â±0.033\n0.970Â±0.033\n0.865Â±0.086\n0.984Â±0.016\n0.986Â±0.000 0.989Â±0.001\n0.990Â±0.009\n0.990Â±0.008\n0.995Â±0.004\n0.965Â±0.002 1.000Â±0.000 1.000Â±0.000\n1.000Â±0.000\nCable\n0.783Â±0.058\n0.790Â±0.039\n0.819Â±0.060\n0.688Â±0.017\n0.876Â±0.012\n0.858Â±0.011 0.935Â±0.008\n0.892Â±0.020\n0.890Â±0.063\n0.862Â±0.022\n0.857Â±0.062\n0.909Â±0.011 0.921Â±0.001\n0.929Â±0.000\nHazelnut\n0.979Â±0.010\n0.976Â±0.021\n0.961Â±0.042\n0.704Â±0.090\n0.977Â±0.030\n0.984Â±0.004 0.997Â±0.002\n1.000Â±0.000 1.000Â±0.000 1.000Â±0.000 1.000Â±0.000 1.000Â±0.000 1.000Â±0.000\n1.000Â±0.000\nMetal nut\n0.876Â±0.007\n0.930Â±0.022\n0.922Â±0.033\n0.878Â±0.038\n0.948Â±0.046\n0.952Â±0.003 0.948Â±0.007\n0.991Â±0.006\n0.984Â±0.004\n0.976Â±0.013\n0.974Â±0.009 0.997Â±0.002 0.998Â±0.000\n0.996Â±0.001\nScrew\n0.399Â±0.187\n0.337Â±0.091\n0.653Â±0.074\n0.675Â±0.294\n0.903Â±0.064\n0.927Â±0.009 0.977Â±0.004\n0.970Â±0.015\n0.940Â±0.017\n0.975Â±0.023\n0.899Â±0.039\n0.977Â±0.009 0.985Â±0.002\n0.995Â±0.001\nToothbrush\n0.753Â±0.027\n0.731Â±0.028\n0.686Â±0.110\n0.617Â±0.058\n0.650Â±0.029\n0.794Â±0.016 0.807Â±0.001\n0.860Â±0.066\n0.900Â±0.008\n0.865Â±0.062\n0.783Â±0.048\n0.826Â±0.021 0.921Â±0.007\n0.929Â±0.000\nMVTec AD\n0.780Â±0.020\n0.755Â±0.136\n0.834Â±0.007\n0.744Â±0.019\n0.883Â±0.008\n0.901Â±0.003 0.927Â±0.002\n0.945Â±0.004\n0.939Â±0.007\n0.926Â±0.010\n0.907Â±0.005\n0.959Â±0.003 0.970Â±0.002\n0.977Â±0.002\nOptical\n0.523Â±0.003\n0.518Â±0.003\n0.815Â±0.014\n0.516Â±0.009\n0.888Â±0.012\n0.888Â±0.007 0.915Â±0.002\n0.782Â±0.065\n0.720Â±0.055\n0.941Â±0.013\n0.740Â±0.039\n0.965Â±0.006 0.976Â±0.004\n0.983Â±0.005\nSDD\n0.881Â±0.009\n0.840Â±0.043\n0.781Â±0.009\n0.811Â±0.045\n0.859Â±0.014\n0.909Â±0.001 0.917Â±0.003\n0.988Â±0.006\n0.967Â±0.018\n0.955Â±0.020\n0.983Â±0.013\n0.991Â±0.005 0.991Â±0.001\n0.996Â±0.001\nAITEX\n0.598Â±0.070\n0.538Â±0.073\n0.675Â±0.094\n0.564Â±0.055\n0.692Â±0.124\n0.734Â±0.008 0.838Â±0.008\n0.887Â±0.013\n0.841Â±0.049\n0.874Â±0.024\n0.867Â±0.037\n0.893Â±0.017 0.925Â±0.013\n0.975Â±0.007\nELPV\n0.514Â±0.076\n0.457Â±0.056\n0.635Â±0.092\n0.578Â±0.062\n0.675Â±0.024\n0.828Â±0.005 0.897Â±0.002\n0.846Â±0.022\n0.818Â±0.032\n0.793Â±0.047\n0.794Â±0.047\n0.845Â±0.013 0.850Â±0.004\n0.937Â±0.003\nMastcam\n0.595Â±0.016\n0.542Â±0.017\n0.662Â±0.018\n0.625Â±0.045\n0.692Â±0.058\n0.743Â±0.003 0.838Â±0.011\n0.790Â±0.021\n0.703Â±0.029\n0.810Â±0.029\n0.798Â±0.026\n0.848Â±0.008 0.855Â±0.005\n0.934Â±0.010\nHyper-Kvasir\n0.653Â±0.037\n0.668Â±0.004\n0.498Â±0.100\n0.445Â±0.040\n0.690Â±0.017\n0.768Â±0.015 0.821Â±0.007\n0.829Â±0.018\n0.773Â±0.029\n0.666Â±0.050\n0.600Â±0.069\n0.834Â±0.004 0.880Â±0.003\n0.939Â±0.005\nBrainMRI\n0.694Â±0.004\n0.693Â±0.036\n0.531Â±0.060\n0.632Â±0.017\n0.744Â±0.004\n0.866Â±0.004 0.893Â±0.004\n0.958Â±0.012\n0.955Â±0.011\n0.900Â±0.041\n0.959Â±0.011 0.970Â±0.003 0.977Â±0.001\n0.969Â±0.005\nHeadCT\n0.742Â±0.076\n0.698Â±0.092\n0.597Â±0.022\n0.758Â±0.038\n0.796Â±0.105\n0.825Â±0.014 0.865Â±0.005\n0.982Â±0.009\n0.971Â±0.004\n0.935Â±0.021\n0.972Â±0.014\n0.972Â±0.002 0.999Â±0.003\n0.981Â±0.003\nTable 6. Detailed class-level AUC results (mean Â± std) under the hard setting. The best and second-best results are highlighted in red and\nblue, respectively. Carpet and Metal nut are subsets of MVTec AD.\nDataset\nOne Training Anomaly Example\nTen Training Anomaly Examples\nDevNet\nFLOS\nSAOE\nMLEP\nDRA\nAHL\nDPDL (Ours)\nDevNet\nFLOS\nSAOE\nMLEP\nDRA\nAHL\nDPDL (Ours)\nCarpet\nColor\n0.716Â±0.085 0.467Â±0.278 0.763Â±0.100 0.547Â±0.056 0.879Â±0.021 0.894Â±0.004 0.909Â±0.001 0.767Â±0.015 0.760Â±0.005 0.467Â±0.067 0.698Â±0.025 0.886Â±0.042 0.929Â±0.007 0.933Â±0.002\nCut\n0.666Â±0.035 0.685Â±0.007 0.664Â±0.165 0.658Â±0.056 0.902Â±0.033 0.934Â±0.003 0.941Â±0.003 0.819Â±0.037 0.688Â±0.059 0.793Â±0.175 0.653Â±0.120 0.922Â±0.038 0.943Â±0.002 0.951Â±0.004\nHole\n0.721Â±0.067 0.594Â±0.142 0.772Â±0.071 0.653Â±0.065 0.901Â±0.033 0.935Â±0.014 0.945Â±0.009 0.814Â±0.038 0.733Â±0.014 0.831Â±0.125 0.674Â±0.076 0.947Â±0.016 0.960Â±0.003 0.964Â±0.003\nMetal\n0.819Â±0.032 0.701Â±0.028 0.780Â±0.172 0.706Â±0.047 0.871Â±0.037 0.931Â±0.007 0.940Â±0.001 0.863Â±0.022 0.678Â±0.083 0.883Â±0.043 0.764Â±0.061 0.933Â±0.022 0.921Â±0.003 0.938Â±0.005\nThread\n0.912Â±0.044 0.941Â±0.005 0.787Â±0.204 0.831Â±0.117 0.950Â±0.029 0.966Â±0.005 0.970Â±0.002 0.972Â±0.009 0.946Â±0.005 0.831Â±0.297 0.967Â±0.006 0.989Â±0.004 0.991Â±0.001 0.993Â±0.000\nMean\n0.767Â±0.018 0.678Â±0.040 0.753Â±0.055 0.679Â±0.029 0.901Â±0.006 0.932Â±0.003 0.941Â±0.006 0.847Â±0.017 0.761Â±0.012 0.762Â±0.073 0.751Â±0.023 0.935Â±0.013 0.949Â±0.002 0.956Â±0.004\nMetal nut\nBent\n0.797Â±0.048 0.851Â±0.046 0.864Â±0.032 0.743Â±0.013 0.952Â±0.020 0.954Â±0.003 0.958Â±0.001 0.904Â±0.022 0.827Â±0.075 0.901Â±0.023 0.956Â±0.013 0.990Â±0.003 0.989Â±0.000 0.991Â±0.002\nColor\n0.909Â±0.023 0.821Â±0.059 0.857Â±0.037 0.835Â±0.075 0.946Â±0.023 0.933Â±0.008 0.938Â±0.003 0.978Â±0.016 0.978Â±0.008 0.879Â±0.018 0.945Â±0.039 0.967Â±0.011 0.958Â±0.001 0.969Â±0.005\nFlip\n0.764Â±0.014 0.799Â±0.058 0.751Â±0.090 0.813Â±0.031 0.921Â±0.029 0.931Â±0.002 0.940Â±0.004 0.987Â±0.004 0.942Â±0.009 0.795Â±0.062 0.805Â±0.057 0.913Â±0.021 0.937Â±0.003 0.955Â±0.003\nScratch\n0.952Â±0.052 0.947Â±0.027 0.792Â±0.075 0.907Â±0.085 0.909Â±0.023 0.934Â±0.005 0.936Â±0.002 0.991Â±0.017 0.943Â±0.002 0.845Â±0.041 0.805Â±0.153 0.911Â±0.034 0.999Â±0.000 0.992Â±0.002\nMean\n0.855Â±0.016 0.855Â±0.024 0.816Â±0.029 0.825Â±0.023 0.932Â±0.017 0.939Â±0.004 0.944Â±0.003 0.965Â±0.011 0.922Â±0.014 0.855Â±0.016 0.878Â±0.058 0.945Â±0.017 0.972Â±0.002 0.978Â±0.002\nAITEX\nBroken end\n0.712Â±0.069 0.645Â±0.030 0.778Â±0.068 0.441Â±0.111 0.708Â±0.094 0.704Â±0.005 0.761Â±0.010 0.658Â±0.111 0.585Â±0.037 0.712Â±0.068 0.732Â±0.065 0.693Â±0.099 0.735Â±0.010 0.796Â±0.001\nBroken pick\n0.552Â±0.003 0.598Â±0.023 0.644Â±0.039 0.476Â±0.070 0.731Â±0.072 0.727Â±0.003 0.760Â±0.014 0.585Â±0.028 0.548Â±0.054 0.629Â±0.012 0.555Â±0.027 0.760Â±0.037 0.683Â±0.002 0.784Â±0.011\nCut selvage\n0.689Â±0.016 0.694Â±0.036 0.681Â±0.077 0.434Â±0.149 0.739Â±0.101 0.753Â±0.007 0.765Â±0.007 0.709Â±0.039 0.745Â±0.035 0.770Â±0.014 0.682Â±0.025 0.777Â±0.036 0.781Â±0.006 0.796Â±0.005\nFuzzyball\n0.617Â±0.075 0.525Â±0.043 0.650Â±0.064 0.525Â±0.157 0.538Â±0.092 0.647Â±0.007 0.715Â±0.013 0.734Â±0.039 0.550Â±0.082 0.842Â±0.026 0.677Â±0.223 0.701Â±0.093 0.775Â±0.024 0.808Â±0.003\nNep\n0.722Â±0.023 0.734Â±0.038 0.710Â±0.044 0.517Â±0.059 0.717Â±0.052 0.703Â±0.005 0.757Â±0.005 0.810Â±0.042 0.746Â±0.060 0.771Â±0.032 0.740Â±0.052 0.750Â±0.038 0.792Â±0.007 0.811Â±0.005\nWeft crack\n0.586Â±0.134 0.546Â±0.114 0.582Â±0.108 0.400Â±0.029 0.669Â±0.045 0.706Â±0.009 0.758Â±0.006 0.599Â±0.137 0.636Â±0.051 0.618Â±0.172 0.370Â±0.037 0.717Â±0.072 0.713Â±0.003 0.790Â±0.004\nMean\n0.646Â±0.034 0.624Â±0.024 0.674Â±0.034 0.466Â±0.030 0.684Â±0.033 0.707Â±0.007 0.753Â±0.005 0.683Â±0.032 0.635Â±0.043 0.724Â±0.032 0.656Â±0.041 0.733Â±0.009 0.747Â±0.002 0.798Â±0.004\nELPV\nMono\n0.634Â±0.087 0.717Â±0.025 0.563Â±0.102 0.649Â±0.027 0.735Â±0.031 0.774Â±0.013 0.785Â±0.002 0.599Â±0.040 0.629Â±0.072 0.569Â±0.035 0.756Â±0.045 0.731Â±0.021 0.745Â±0.004 0.793Â±0.003\nPoly\n0.662Â±0.050 0.665Â±0.021 0.665Â±0.173 0.483Â±0.247 0.671Â±0.051 0.705Â±0.006 0.738Â±0.008 0.804Â±0.022 0.662Â±0.042 0.796Â±0.084 0.734Â±0.078 0.800Â±0.064 0.831Â±0.011 0.843Â±0.004\nMean\n0.648Â±0.057 0.691Â±0.008 0.614Â±0.048 0.566Â±0.111 0.703Â±0.022 0.740Â±0.003 0.762Â±0.003 0.702Â±0.023 0.646Â±0.032 0.683Â±0.047 0.745Â±0.020 0.766Â±0.029 0.788Â±0.003 0.818Â±0.003\nMastcam\nBedrock\n0.495Â±0.028 0.499Â±0.056 0.636Â±0.072 0.532Â±0.036 0.668Â±0.012 0.679Â±0.012 0.732Â±0.003 0.550Â±0.053 0.499Â±0.098 0.636Â±0.068 0.512Â±0.062 0.658Â±0.021 0.673Â±0.006 0.757Â±0.004\nBroken-rock\n0.533Â±0.020 0.569Â±0.025 0.699Â±0.058 0.544Â±0.088 0.645Â±0.053 0.661Â±0.009 0.738Â±0.004 0.547Â±0.018 0.608Â±0.085 0.712Â±0.052 0.651Â±0.063 0.649Â±0.047 0.722Â±0.004 0.783Â±0.002\nDrill-hole\n0.555Â±0.037 0.539Â±0.077 0.697Â±0.074 0.636Â±0.066 0.657Â±0.070 0.654Â±0.004 0.738Â±0.011 0.583Â±0.022 0.601Â±0.009 0.682Â±0.042 0.660Â±0.002 0.725Â±0.005 0.760Â±0.003 0.797Â±0.004\nDrt\n0.529Â±0.046 0.591Â±0.042 0.735Â±0.020 0.624Â±0.042 0.713Â±0.053 0.724Â±0.006 0.745Â±0.005 0.621Â±0.043 0.652Â±0.024 0.761Â±0.062 0.616Â±0.048 0.760Â±0.033 0.772Â±0.004 0.818Â±0.002\nDump-pile\n0.521Â±0.020 0.508Â±0.021 0.682Â±0.022 0.545Â±0.127 0.767Â±0.043 0.756Â±0.011 0.764Â±0.003 0.705Â±0.011 0.700Â±0.070 0.750Â±0.037 0.696Â±0.047 0.748Â±0.066 0.802Â±0.005 0.830Â±0.005\nFloat\n0.502Â±0.020 0.551Â±0.030 0.711Â±0.041 0.530Â±0.075 0.670Â±0.065 0.702Â±0.005 0.739Â±0.007 0.615Â±0.052 0.736Â±0.041 0.718Â±0.064 0.671Â±0.032 0.744Â±0.073 0.765Â±0.002 0.816Â±0.012\nMeteorite\n0.467Â±0.049 0.462Â±0.077 0.669Â±0.037 0.476Â±0.014 0.637Â±0.015 0.616Â±0.013 0.704Â±0.004 0.554Â±0.021 0.568Â±0.053 0.647Â±0.030 0.473Â±0.047 0.716Â±0.004 0.691Â±0.001 0.785Â±0.017\nScuff\n0.472Â±0.031 0.508Â±0.070 0.679Â±0.048 0.492Â±0.037 0.549Â±0.027 0.581Â±0.020 0.714Â±0.002 0.528Â±0.034 0.575Â±0.042 0.676Â±0.019 0.504Â±0.052 0.636Â±0.086 0.656Â±0.009 0.777Â±0.003\nVeins\n0.527Â±0.023 0.493Â±0.052 0.688Â±0.069 0.489Â±0.028 0.699Â±0.045 0.687Â±0.017 0.789Â±0.003 0.589Â±0.072 0.608Â±0.044 0.686Â±0.053 0.510Â±0.090 0.620Â±0.036 0.650Â±0.003 0.766Â±0.008\nMean\n0.511Â±0.013 0.524Â±0.013 0.689Â±0.037 0.541Â±0.007 0.667Â±0.012 0.673Â±0.010 0.733Â±0.004 0.588Â±0.011 0.616Â±0.021 0.697Â±0.014 0.588Â±0.016 0.695Â±0.004 0.721Â±0.003 0.778Â±0.007\nHyper-Kvasir\nBarretts\n0.672Â±0.014 0.703Â±0.040 0.382Â±0.117 0.438Â±0.111 0.772Â±0.019 0.792Â±0.007 0.793Â±0.000 0.834Â±0.012 0.764Â±0.066 0.698Â±0.037 0.540Â±0.014 0.824Â±0.006 0.829Â±0.002 0.832Â±0.004\nBarretts-short-seg 0.604Â±0.048 0.538Â±0.033 0.367Â±0.050 0.532Â±0.075 0.674Â±0.018 0.651Â±0.006 0.658Â±0.003 0.799Â±0.036 0.810Â±0.034 0.661Â±0.034 0.480Â±0.107 0.835Â±0.021 0.895Â±0.003 0.906Â±0.002\nEsophagitis-a\n0.569Â±0.051 0.536Â±0.040 0.518Â±0.063 0.491Â±0.084 0.778Â±0.020 0.760Â±0.006 0.758Â±0.001 0.844Â±0.014 0.815Â±0.022 0.820Â±0.034 0.646Â±0.036 0.881Â±0.035 0.878Â±0.021 0.878Â±0.003\nEsophagitis-b-d\n0.536Â±0.033 0.505Â±0.039 0.358Â±0.039 0.457Â±0.086 0.577Â±0.025 0.622Â±0.014 0.652Â±0.002 0.810Â±0.015 0.754Â±0.073 0.611Â±0.017 0.621Â±0.042 0.837Â±0.009 0.815Â±0.010 0.841Â±0.002\nMean\n0.595Â±0.023 0.571Â±0.004 0.406Â±0.018 0.480Â±0.044 0.700Â±0.009 0.706Â±0.007 0.715Â±0.004 0.822Â±0.019 0.786Â±0.021 0.698Â±0.021 0.571Â±0.014 0.844Â±0.009 0.854Â±0.004 0.864Â±0.002\n9. Detailed Class-level AUC Results under\nHard Setting\nTo evaluate the performance of the DPDL framework in\ndetecting emerging anomaly classes, we conducted exper-\niments under challenging settings and provided detailed\nresults on six multi-subset datasets, including per-class\nanomaly performance, as shown in Tab. 6.\nOverall, the\nDPDL model achieved the highest AUC scores across both\nM = 1 and M = 10 settings.\n\n\n10. The Algorithm of DPDL\nAlgorithm 1 Distribution Prototype Diffusion Learning\n1: Input: Input X = {(xi, yi)}, C, Ïµ, Îº\n2: for epoch = 1 to n do\n3:\nExtract features F\nfeature\nâ†âˆ’X\n4:\nDistribution of normal samples transform PMGP\nbridge\nâ†âˆ’\nP(F)\n5:\nDistribution Prototype Learning LDPL = Ln\nDPL +\nLa\nDPL\n6:\nDispersion Feature Learning LDFL\n7:\nSample xi âˆ¼X, ecâˆ—âˆ¼PMGP\n8:\nCalculate scores Sa â†Ma, Sn â†Mn, Sr â†Mr\n9: end for\n10: Output : Anomaly score S â†Sr + Sa âˆ’Sn\n\n\n11. Derivation of Eqns. (13) and (14)\nWe use Eqns. (8) and (12) to derive Eqn. (13) as follows:\nÏ€(Ïˆ(xn\ni )|xn\ni ) =\n1\nÏ–(xn\ni ) exp(âŸ¨xn\ni , Ïˆ(xn\ni )âŸ©\nÏµ\n)\nC\nX\nc=1\nÎ±cN(Ïˆ(xn\ni ); Âµc, Ïƒc)\n=\n1\nÏ–(xn\ni )\nC\nX\nc=1\nÎ±c(2Ï€)âˆ’D/2|Ïƒc|âˆ’1/2 exp(âŸ¨xn\ni , Ïˆ(xn\ni )âŸ©\nÏµ\n) exp(âˆ’1\n2(Ïˆ(xn\ni )))âŠ¤Ïƒâˆ’1\nc (Ïˆ(xn\ni ) âˆ’Âµc))\n=\n1\nÏ–(xn\ni )\nC\nX\nc=1\nÎ±c(2Ï€)âˆ’D/2|Ïƒc|âˆ’1/2 exp( 1\n2Ïµ(2xn\ni\nâŠ¤Ïˆ(xn\ni ) âˆ’Ïˆ(xn\ni )âŠ¤ÏµÏƒâˆ’1\nc Ïˆ(xn\ni )âŠ¤+ 2ÂµâŠ¤\nc ÏµÏƒâˆ’1\nc Ïˆ(xn\ni ) âˆ’ÂµâŠ¤\nc ÏµÏƒâˆ’1\nc Âµc))\n=\n1\nÏ–(xn\ni )\nC\nX\nc=1\nÎ±c(2Ï€)âˆ’D/2|Ïƒc|âˆ’1/2 exp( 1\n2Ïµ(âˆ’Ïˆ(xn\ni )âŠ¤ÏµÏƒâˆ’1\nc Ïˆ(xn\ni )âŠ¤+ 2 (1\nÏµ Ïƒcxn\ni + Âµc)âŠ¤\n|\n{z\n}\neÂµc(xn\ni)\nÏµÏƒâˆ’1\nc Ïˆ(xn\ni ) âˆ’ÂµâŠ¤\nc ÏµÏƒâˆ’1\nc Âµc))\n=\n1\nÏ–(xn\ni )\nC\nX\nc=1\nÎ±c(2Ï€)âˆ’D/2|Ïƒc|âˆ’1/2 exp(âˆ’1\n2Ïµ(Ïˆ(xn\ni ) âˆ’eÂµc(xn\ni )âŠ¤ÏµÏƒâˆ’1\nc (Ïˆ(xn\ni ) âˆ’eÂµc(xn\ni ))))\nexp( 1\n2Ïµ(âˆ’ÂµâŠ¤\nc ÏµÏƒâˆ’1\nc Âµc + eÂµâŠ¤\nc (xn\ni )ÏµÏƒâˆ’1\nc\neÂµâŠ¤\nc (xn\ni ))\n=\n1\nÏ–(xn\ni )\nC\nX\nc=1\nÎ±c exp(ÂµâŠ¤\nc ÏµÏƒâˆ’1\nc Âµc + (eÂµâŠ¤\nc Ïµâˆ’1Ïƒc + eÂµc)âŠ¤(xn\ni )ÏµÏƒâˆ’1\nc (eÂµâŠ¤\nc Ïµâˆ’1Ïƒc + eÂµc)(xn\ni )\n2Ïµ\n)N(Ïˆ(xn\ni ); eÂµc(xn\ni ), Ïƒc)\n=\n1\nÏ–(xn\ni )\nC\nX\nc=1\nÎ±c exp( 1\n2Ïµ2 (xn\ni )âŠ¤Ïƒcxn\ni + 1\nÏµ (eÂµc)âŠ¤(xn\ni ))\n|\n{z\n}\neÎ±c(xn\ni)\nN(Ïˆ(xn\ni ); eÂµc(xn\ni ), Ïƒc)\n= eÎ·(xn\ni )\nC\nX\nc=1\neÎ±c(xn\ni )N(Ïˆ(xn\ni ); eÂµc(xn\ni ), Ïƒc)\nwhere eÎ·(xn\ni ) =\n1\nÏ–(xn\ni) =\n1\nPC\nc=1 eÎ±c(xn\ni).\n\n\nAccording to Eqn. (4), we derive Eqn. (14) as follows:\ng(xn\ni , t) = Ïµâ–½xn\nilog\nZ\nRD N(Ïˆ(xn\ni )|xn\ni , (1 âˆ’t)ÏµI) exp(âˆ¥Ïˆ(xn\ni )âˆ¥2\n2Ïµ\n)Ï•1(Ïˆ(xn\ni ))dÏˆ(xn\ni )\n= Ïµâ–½xn\nilog\nZ\nRD N(Ïˆ(xn\ni )|xn\ni , (1 âˆ’t)ÏµI) exp(âˆ¥Ïˆ(xn\ni )âˆ¥2\n2Ïµ\n)\nC\nX\nc=1\nÎ±cN(Ïˆ(xn\ni ); eÂµc, Ïƒc)dÏˆ(xn\ni )\n= Ïµâ–½xn\nilog((2Ï€)âˆ’D\n2 |(1 âˆ’t)ÏµI|âˆ’1\n2\nC\nX\nc=1\n{Î±c|Ïƒc|âˆ’1\n2\nZ\nRD exp(âˆ’(Ïˆ(xn\ni ) âˆ’xn\ni )âŠ¤(Ïˆ(xn\ni ) âˆ’xn\ni )\n2Ïµ(1 âˆ’t)\nâˆ’(Ïˆ(xn\ni ) âˆ’eÂµc)ÏµÏƒâˆ’1\nc (Ïˆ(xn\ni ) âˆ’eÂµc)\n2Ïµ\n+ Ïˆ(xn\ni )âŠ¤Ïˆ(xn\ni )\n2Ïµ\n)})\n= Ïµâ–½xn\nilog(exp(âˆ’xn\ni\nâŠ¤xn\ni\n2Ïµ(1 âˆ’t))\nC\nX\nc=1\n{Î±c|Ïƒc|âˆ’1\n2 exp(âˆ’eÂµâŠ¤\nc ÏµÏƒâˆ’1 eÂµc\n2Ïµ\n)})\nZ\nRD exp(âˆ’1\n2[Ïˆ(xn\ni )âŠ¤(\nt\nÏµ(1 âˆ’t)I + Ïƒâˆ’1\nc )\n|\n{z\n}\nÎ£tc\nÏˆ(xn\ni )] + [\n1\nÏµ(1 âˆ’t)xn\ni + Ïƒâˆ’1\nc\neÂµc]âŠ¤\n|\n{z\n}\nhc(xn\ni,t)\nÏˆ(xn\ni )dÏˆ(xn\ni ))\n= Ïµâ–½xn\nilog((2Ï€)âˆ’D\n2 exp(âˆ’xn\ni\nâŠ¤xn\ni\n2Ïµ(1 âˆ’t))\nC\nX\nc=1\n{Î±c(2Ï€)âˆ’D\n2 |Ïƒc|âˆ’1\n2 exp(âˆ’eÂµâŠ¤\nc ÏµÏƒâˆ’1\nc\neÂµc\n2Ïµ\n)\n|\n{z\n}\nN(xn\ni|0,Ïµ(1âˆ’t))I\nC\nX\nc=1\n(Î±cN(eÂµc(xn\ni )|0, Ïƒc)N(hc(xn\ni , t)|0, Î£t\nc))\n|\n{z\n}\nÏMGP(xn\ni)\n})\n= ÏµÏMGP(xn\ni )âˆ‡xn\ni log(N(xn\ni |0, Ïµ(1 âˆ’t))I)\n\n\n",
  "metadata": {
    "source_file": "dataset/pdfs/arxiv_2502.20981v1.pdf",
    "total_pages": 15,
    "title": "Distribution Prototype Diffusion Learning for Open-set Supervised Anomaly Detection",
    "authors": [
      "Fuyun Wang",
      "Tong Zhang",
      "Yuanzhi Wang",
      "Yide Qiu",
      "Xin Liu",
      "Xu Guo",
      "Zhen Cui"
    ],
    "abstract": "In Open-set Supervised Anomaly Detection (OSAD), the existing methods\ntypically generate pseudo anomalies to compensate for the scarcity of observed\nanomaly samples, while overlooking critical priors of normal samples, leading\nto less effective discriminative boundaries. To address this issue, we propose\na Distribution Prototype Diffusion Learning (DPDL) method aimed at enclosing\nnormal samples within a compact and discriminative distribution space.\nSpecifically, we construct multiple learnable Gaussian prototypes to create a\nlatent representation space for abundant and diverse normal samples and learn a\nSchr\\\"odinger bridge to facilitate a diffusive transition toward these\nprototypes for normal samples while steering anomaly samples away. Moreover, to\nenhance inter-sample separation, we design a dispersion feature learning way in\nhyperspherical space, which benefits the identification of out-of-distribution\nanomalies. Experimental results demonstrate the effectiveness and superiority\nof our proposed DPDL, achieving state-of-the-art performance on 9 public\ndatasets.",
    "published_date": "2025-02-28",
    "source": "arxiv"
  }
}