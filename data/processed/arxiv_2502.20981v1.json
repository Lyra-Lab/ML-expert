{
  "id": "arxiv_2502.20981v1",
  "text": "Distribution Prototype Diffusion Learning for Open-set Supervised\nAnomaly Detection\nFuyun Wang, Tong Zhang, Yuanzhi Wang, Yide Qiu, Xu Guo\nSchool of Computer Science and Engineering\nNanjing University of Science and Technology\nfyw271828@njust.edu.cn, tong.zhang@njust.edu.cn, yuanzhiwang@njust.edu.cn,\n121106010824@njust.edu.cn, guo.xu@njust.edu.cn\nXin Liu\nSeetaCloud Technology\nNanjing, China\nxin.liu@seetacloud.com\nZhen Cui\nSchool of Artificial Intelligence\nBeijing Normal University\nzhen.cui@bnu.edu.cn\nAbstract\nIn Open-set Supervised Anomaly Detection (OSAD), the\nexisting methods typically generate pseudo anomalies to\ncompensate for the scarcity of observed anomaly samples,\nwhile overlooking critical priors of normal samples, lead-\ning to less effective discriminative boundaries. To address\nthis issue, we propose a Distribution Prototype Diffusion\nLearning (DPDL) method aimed at enclosing normal sam-\nples within a compact and discriminative distribution space.\nSpecifically, we construct multiple learnable Gaussian pro-\ntotypes to create a latent representation space for abun-\ndant and diverse normal samples and learn a Schr¨odinger\nbridge to facilitate a diffusive transition toward these pro-\ntotypes for normal samples while steering anomaly sam-\nples away.\nMoreover, to enhance inter-sample separa-\ntion, we design a dispersion feature learning way in hyper-\nspherical space, which benefits the identification of out-of-\ndistribution anomalies. Experimental results demonstrate\nthe effectiveness and superiority of our proposed DPDL,\nachieving state-of-the-art performance on 9 public datasets.\n1. Introduction\nAnomaly detection (AD) [15, 21, 42, 44] aims to iden-\ntify outliers significantly diverging from the prevailing sam-\nples in a dataset, and has a wide range of applications like\nindustrial inspection, medical image analysis, and scien-\ntific discovery, etc.\nRecently, unsupervised anomaly de-\ntection (UAD) [6, 11, 26, 28] and few-shot anomaly de-\ntection (FSAD) [12, 21, 22] have emerged as prominent\nresearch paradigms, emphasizing the modeling of normal\nsample distributions to discern anomalies effectively. Yet,\nthese methods often neglect prior knowledge from limited\nanomaly samples, resulting in imprecise delineation of nor-\nmal sample boundaries and reduced efficacy in differenti-\nating normal from anomaly instances. On the contrary, su-\npervised anomaly detection (SAD) [2, 20, 41] leverages a\nlimited subset of anomaly samples as prior knowledge, im-\nproving detection performance. However, this reliance on\nseen anomalies poses a risk of overfitting and hampers gen-\neralization to unseen anomalies in real-world settings.\nTo mitigate the challenge of limited generalization in-\nherent in closed-set training, we focus on open-set super-\nvised anomaly detection (OSAD) [1, 27, 45, 46], which\nutilizes a small set of known anomaly classes during train-\ning to identify unseen anomalies from open-set classes. By\nleveraging prior knowledge from observed samples, OSAD\nmethods could reduce false positive errors. To improve the\ngeneralized detection of unseen anomalies, DRA [9] lever-\nages data augmentation and outlier exposure to learn a de-\ncomposed anomaly representation comprising seen anoma-\nlies, pseudo-anomalies, and potential residual anomalies.\nBGAD [41] leverages decision boundaries derived from\nnormalized flow models to capture and model anomaly in-\nformation.\nRecently, AHL [45] simulates heterogeneous\nanomaly distributions and performs collaborative differen-\ntiable learning to further enhance the model’s generality.\nWhile data augmentation and outlier exposure tech-\nniques [9, 19, 33] have demonstrated considerable success\nin anomaly detection, they fall short in generating com-\nprehensive pseudo anomalies, capturing only a fraction of\npotential unseen anomalies.\nThis limitation arises from\noverlooking the intricate nature of real-world anomaly dis-\ntributions, thereby hindering the model’s ability to gener-\nalize to novel anomaly types.\nAlthough AHL [45] has\narXiv:2502.20981v1  [cs.CV]  28 Feb 2025\n\n\nmade strides in addressing this issue by simulating hetero-\ngeneous anomaly distributions, it still relies on approximat-\ning unknown out-of-distribution anomalies using known in-\ndistribution anomalies for generalization. Yet, three critical\nissues persist: i) the simulation mechanism cannot cover all\nanomaly distribution patterns due to the varied scales and\nstructures of anomaly distributions; ii) simulated anoma-\nlies inherit in-distribution data biases, leading to subopti-\nmal performance on out-of-distribution anomalies; iii) the\ndiversity of normal samples presents dilemmas for existing\nmethods, complicating the differentiation between normal\nand anomaly boundaries. These issues prompt a fundamen-\ntal question: Instead of generating pseudo and uncertain\nanomaly samples, how can we accurately characterize com-\npact distribution boundaries amidst a range of diverse nor-\nmal samples and achieve robust generalization for unknown\nout-of-distribution anomalies?\nTo address the aforementioned issue, in this work,\nwe propose a Distribution Prototype Diffusion Learning\n(DPDL) method for open-set supervised anomaly detection.\nConsidering abundant and diverse normal samples but very\nlimited anomaly data, our method involves learning latent\ndistribution prototypes, specifically multiple Gaussian dis-\ntributions, onto which all observed normal samples can be\neffectively projected. To facilitate the mapping of normal\nsamples into the prototype space, we leverage Schr¨odinger\nbridge (SB) framework, which enables a diffusive transi-\ntion by aligning the distributions of these samples with the\nprototypes.\nThe SB-based diffusion way could mitigate\nthe out-of-distribution issue for normal samples to some\nextent. Within the distribution prototype space, we push\nobserved anomaly samples away from normal samples to\nenhance discriminative capacity. Notably, both the proto-\ntypes and the diffusive bridge are learned jointly, resulting\nin a robust embedding space for normal samples. More-\nover, to enhance generalization across unseen anomaly do-\nmains, we introduce a dispersion feature learning mecha-\nnism that maps intermediate features to a hyperspherical\nspace, leveraging a mixture of von Mises-Fisher (vMF) dis-\ntributions. This approach bolsters directional feature ex-\ntraction and promotes robust inter-sample separation, facili-\ntating effective identification of out-of-distribution samples.\nExperiments demonstrate that our method greatly improves\ndetection capabilities for unseen anomalies. In the single-\nanomaly training setting, DPDL outperforms the next best-\nperforming method by over 8.3% on datasets including AI-\nTEX, ELPV, and Mastcam.\nIn summary, our contributions are three-fold: i) we pro-\npose a distribution prototype diffusion learning framework\nthat jointly learns multiple Gaussian prototypes and the as-\nsociated diffusion bridge, creating a compact and discrim-\ninative embedding space; ii) we develop dispersion feature\nlearning in hyperspherical space to enhance inter-sample\nseparation and improve generalization; iii) we achieve state-\nof-the-art performance in 9 public datasets, demonstrating\nthe efficacy of our approach.\n2. Related Work\nOpen-set Supervised Anomaly Detection. Open-set su-\npervised anomaly detection (OSAD) seeks to develop a ro-\nbust anomaly detection framework that generalizes from\na limited set of training anomalies to effectively iden-\ntify previously unseen anomalies within an open-set con-\ntext [1, 27, 34, 41, 46]. Leveraging the prior knowledge pro-\nvided by observed anomalies, contemporary OSAD meth-\nods significantly mitigate false positive errors, thereby en-\nhancing overall detection performance [9, 45]. Recently,\nDRA [9] learns disentangled representations of observed,\npseudo, and residual anomalies to boost the detection of\nboth seen and unseen anomalies. In contrast, AHL [45]\nsimulates diverse heterogeneous anomaly distributions and\nemploys collaborative differentiable learning, significantly\nimproving the model’s generalization capacity.\nSchr¨odinger Bridge. Schr¨odinger bridge (SB), widely\nrecognized as the entropy-regularized optimal transport\n(OT) problem, involves learning a stochastic process that\nevolves from an initial probability distribution to a terminal\ndistribution under the influence of a reference measure[5,\n7, 16, 18, 23, 24, 37]. I2-SB [25] and UNSB [14] learn\na nonlinear diffusion process between two given distribu-\ntions or represent the SB problem as a series of adversar-\nial learning problems to realize the image transformation\ntask. Recently, LightSB [10, 17] introduces a novel, fast,\nand simple SB solver, which achieves optimal matching in\npractice through the Gaussian mixture parameterization of\nthe adjusted schr¨odinger potential.\n3. Preliminaries\nWe focus on how to build the connection between two dis-\ntributions p0 and p1, where the distributions are defined as\nabsolutely continuous Borel probability distributions with\nfinite second-order moments. Building upon the founda-\ntion of entropy-regularized optimal transport (EOT) [5, 7,\n16, 18, 23, 24, 32, 37], we review the related properties\nof EOT and the schr¨odinger bridge (SB) problem with a\nWiener prior.\nEntropy-regularized optimal transport (EOT). Given\ntwo point sets Z0 and Z1, we seek for the optimal transport\ncost between any two points z0 ∈Z0 and z1 ∈Z1. This\ntask may be formulated as an EOT problem with a parame-\nter ϵ > 0, i.e., minimizing the following objective:\nmin\nπ∈Π(p0,p1){\nZ\nRD\nZ\nRD\n1\n2∥z0 −z1∥2π(z0, z1)dz0dz1\n+ϵKL(z ∥p0 × p1)},\n(1)\n\n\nwhere Π(p0, p1) denotes the set of transport plans, i.e., joint\nprobability distributions on RD × RD with marginals p0\nand p1, respectively, and KL denotes Kullback-Leibler di-\nvergence. The minimizer π∗of Eqn. (1) is guaranteed to\nexist, be unique, and absolutely continuous, and is referred\nas the EOT plan.\nSchr¨odinger Bridge (SB). We define Ωas the space\nof RD-valued functions over time t ∈[0, 1], representing\ntrajectories in RD that start at t = 0 and end at t = 1.\nWe denote the set of probability distributions over Ω, i.e.,\nstochastic processes, by P(Ω). The differential of the stan-\ndard Wiener process is represented by dWt. For a process\nT ∈P(Ω), we denote its joint distribution at t = 0, 1 by\nπT ∈P(RD ×RD). Similarly, we use T|z0,z1 to denote the\ndistribution of T for t ∈(0, 1), conditioned on T’s values\nz0 and z1 at t = 0 and t = 1, respectively.\nLet W ϵ\n∈P(Ω) represents a Wiener process with\nvolatility ϵ > 0, starting from p0 at t = 0. Its differential\nis governed by the stochastic differential equation (SDE):\ndW ϵ\nt = √ϵ dWt. The Schr¨odinger bridge problem with the\nWiener prior W ϵ between p0 and p1 is minimizing:\nmin\nT ∈F(p0,p1) KL(T ∥W ϵ),\n(2)\nwhere F(p0, p1) ⊂P(Ω) denotes the subset of stochastic\nprocesses that begin with distribution p0 at t = 0 and reach\np1 at t = 1. This problem has a unique solution, a SDE\ndiffusion process T ∗defined: dZt = g∗(Zt, t) dt + dW ϵ\nt .\nThe process T ∗is referred to as SB, and g∗: RD ×[0, 1] →\nRD is the optimal drift.\nCharacterization of solutions. The EOT plan π∗=\nπT ∗takes a specific form [18]:\nπ∗(z0, z1) = u∗(z0)exp(−∥z0 −z1∥2\n2ϵ\n)v∗(z1),\n(3)\nwhere u∗, v∗: R →R+ are measurable functions known as\nSchr¨odinger potentials. The optimal drift g∗is derived as:\ng∗(z, t) = ϵ▽zlog\nZ\nRD N(z′|z, (1 −t)ϵID)v∗(z′)dz′, (4)\n4. Method\n4.1. Problem Formulation\nLet Xtr = {(xi, yi)} denotes a weakly-supervised training\nset with only image-level labels, where xi denotes one RGB\nimage and yi ∈{0, 1} denotes whether xi is an anomaly\nsample (anomaly: yi = 1, normal: yi = 0).\nHereby,\nXtr is consist of a normal subset X n\ntr (|X n\ntr | = N) and an\nanomaly subset X a\ntr (|X a\ntr | = M), formally, Xtr .= X n\ntr ∪X a\ntr ,\nwhere generally N ≫M.\nGiven a testing set Xte, we\nneed to predict whether one sample x ∈Xte is anomaly\nor normal. In OSAD, the anomaly patterns of the testing\nset do less recurred in those encountered training set. In\nother word, the distribution of anomalies are obviously dis-\ncrepant, i.e., P(X a\nte) ̸= P(X a\ntr ). Hereby, we need to learn a\nrobust anomaly detection model ψ from the training set Xtr,\nso that ψ accurately infers anomaly scores for test samples.\nOur abstract idea is to learn latent distribution proto-\ntypes that not only encapsulate normal samples in a con-\ncise manner but also discriminate against anomaly sam-\nples. Given the abundance of observed normal samples, one\nnatural approach is to characterize the distribution P(X n\ntr ),\nwhere samples outside this distribution, x /∈P(X n\ntr ), would\nbe awarded higher probabilities as anomalies. Considering\nthe inherent diversity of normal samples, we endeavor to\nlearn multiple simple distributions (e.g., Gaussians) as pro-\ntotypes PMGP, named multi-Gaussian prototypes (MGP). To\nembed input data into the prototype space, we introduce a\ngenerative bridge model ψp for distribution transformation.\nThe more abstract formulation is given as follows:\nmin\nψp,PMGP,fDp(ψp(Fn\ntr), ψp(Fa\ntr), PMGP)+λDs(Fn\ntr, Fa\ntr), (5)\ns.t. , ψp : P(F)\nbridge\n−→PMGP,\n(6)\nf : X\nfeature\n−→F,\n(7)\nwhere PMGP denotes the distribution prototypes to be\nlearned, ψp is the flow function across probability distribu-\ntions, Dp signifies the discriminative function in the space\nof prototypes, f stands for the feature extraction process,\nand Ds acts as a regularizer to increase feature discrim-\ninability. In the above formulation, besides distribution pro-\ntotype learning (DPL), we also introduce dispersion feature\nlearning (DFL) executed within a hyperspherical embed-\nding space, i.e., Ds(Fn\ntr, Fa\ntr). The advantage of DFL is to\nprevent abrupt feature collapse in feature learning, thus pre-\nserving discriminative qualities. The overview of our frame-\nwork is abstractly depicted in Fig. 1. Detailed elaboration1\non these aspects will be provided in the subsequent sections.\n4.2. Distribution Prototype Learning\nDistribution prototype learning is operated in the feature\nspace. Hence, to extract intermediate image features, we\ncan leverage those classic networks as the backbone, such\nas ResNet-18. Formally, the feature extraction process, de-\nnoted as a function f : X →F, transforms an image\nx into the intermediate feature x = f(x)2∈Rd. Conse-\nquently, we designate the intermediate feature sets of nor-\nmal and anomaly samples as Fn\ntr = {xn\ni |i = 1, · · · , N} and\nFa\ntr = {xa\ni |i = 1, · · · , M}, respectively.\nConsidering the rarity of anomalies and the diversity of\nnormal samples, it is pertinent to capture the intricate dis-\ntributions of normal samples by mapping the distribution\n1The concrete algorithm is deferred to the supplementary material.\n2Here a flatten operation is used on convolution maps for vectorization.\n\n\nNormal Features\nAnomaly Features\n…\n…\nDispersion Feature Learning\nDistribution Prototype Learning\nℒDFL\nNormal Samples\nAnomaly Samples\nDistribution Prototypes\nTied\nSchrödinger Bridge \nTied\nLearnable \n𝒫𝒫MGP: {𝝁𝝁𝑘𝑘, 𝛔𝛔𝑘𝑘}𝑘𝑘=1\n𝐾𝐾\nMIL-based Anomaly Score \nComputation\nAnomaly Score\nScore Prediction\nDistribution Flow \nDistribution Flow \nDispersion Loss\nEncoder\nℱtr\na\nℱtr\nn\n𝜓𝜓𝑝𝑝\n𝜓𝜓𝑝𝑝\nℒDPL\nn\n𝑓𝑓\nℒDPL\na\nFigure 1. Our proposed DPDL framework. It comprises three distinct modules: Distribution Prototype Learning (DPL, Sec. 4.2), Disper-\nsion Feature Learning (DFL, Sec. 4.3), and anomaly score prediction (Sec. 4.4). DPL transforms the distribution of normal samples to a\nspace of learnable multiple Gaussian prototypes through building schr¨odinger bridge, meantime pushing anomaly distribution away from\nthese prototypes. DFL operates in a hyperspherical space, enlarging the distances of intermediate features of all samples in a hyperspher-\nical space to strengthen feature generalization for detecting anomalies. The score prediction module leverages a multi-instance-learning\nmethod to compute anomaly scores.\np0 = P(Fn\ntr) of intermediate features to a distinct and well-\ncharacterized distribution p1 like Gaussian. But due to vari-\nous normal samples, we opt for a multi-Gaussian prototypes\n(MGP) comprising multiple Gaussian distributions as pro-\ntotypes PMGP = {Pi .= N(µi, σi)|i = 1, · · · , C}. Given\na normal sample xn\ni , we expect to align it with the closest\nprototype with high likelihood. However, in the open-set\nsetting, it is challenge to transform unseen points x ∼p0\nto the target distribution p1. Drawing inspiration from the\ncapability of diffusion generation models in aligning dis-\nparate distributions, we frame the transition from source\ndomain distribution p0 to target domain distribution p1 as a\nSchr¨odinger bridge problem. As formulated in Eqn. (6), we\nneed learn an essential bridge flow ψp : P(Fn\ntr)\nbridge\n−→PMGP.\nAfter bridge transformation, the condition probability in op-\ntimal transport plan conforms to:\nπ(ψp(x)|x) ∝\nC\nX\nc=1\nαcN(ψp(x); µc, σc))\n|\n{z\n}\n.=ϕ1(ψp(x))\n,\n(8)\nwhere the parameters {αc, µc, σc}C\nc=1 (known as Gaussian\nmixed model (GMM), abstracted into the function ϕ1) as\nwell as the flow function ψp (in bridge) need to be learned.\nFor simplicity, below we adopt diagonal matrices for σc.\nDrawing inspiration from previous works [10, 17], we\nreframe distribution prototype learning in Eqn. (8) as the\nSchr¨odinger bridge. Given the specific form taken by the\nEOT plan described in Eqn. (3), we redefine these measur-\nable functions u, v : R →R+, termed Schr¨odinger poten-\ntials, as follows:\nu(xn\ni ) .= exp(∥xn\ni ∥2\n2ϵ\n)ϕ0(xn\ni ),\n(9)\nv(ψ(xn\ni )) .= exp(∥ψ(xn\ni )∥2\n2ϵ\n)ϕ1(ψ(xn\ni )),\n(10)\nwhere ϕ0 is defined within the source feature domain Ftr,\nand ϕ1 is defined in Eqn. (8). ϵ is set to 0.001 in our exper-\niments. Accordingly, Eqn. (3) can be converted to:\nπ(xn\ni , ψ(xn\ni ))=ϕ0(xn\ni ) exp(⟨xn\ni , ψ(xn\ni )⟩\nϵ\n)ϕ1(ψ(xn\ni )), (11)\nHence, the condition probability of the transport plan in\nEqn. (8) could be exactly defined as\nπ(ψ(xn\ni )|xn\ni ) .= η(xn\ni , ψ(xn\ni ))ϕ1(ψ(xn\ni )),\n(12)\nwhere the connection factor is denoted as η(xn\ni , ψ(xn\ni )) =\n1\nϖ(xn\ni) exp( ⟨xn\ni,ψ(xn\ni)⟩\nϵ\n)\nwith\nthe\nnormalization\nterm\nϖ(xn\ni ) =\nR\nexp(⟨xn\ni , ψ(xn\ni )⟩)ϕ1(ψ(xn\ni ))dψ(xn\ni ). Accord-\ning to Eqns. (8) and (12), we can further derive a more\ntractable form:\nπ(ψ(xn\ni )|xn\ni )=eη(xn\ni )\nC\nX\nc=1\neαc(xn\ni )N(ψ(xn\ni );eµc(xn\ni ),σc), (13)\nwhere the normalization factor is denoted as eη(xn\ni ) =\n1/ PC\nc=1 eαc(xn\ni ), the coefficients of multi-Gaussian are de-\nfined as eαc(xn\ni ) = αcexp( 1\n2(xn\ni )⊺σcxn\ni + 1\nϵ (eµc)⊺(xn\ni )), and\nthe mean vectors are calculated as eµc(xn\ni ) = µc + 1\nϵ σcxn\ni .\n\n\nWe proceed with deriving the bridge function ψp that\nrepresents a SDE process: dxt = g(xt, t)dt+√ϵdWt where\nthe shift function g is solved. According to Eqn. (4), we can\nobtain the shift function of diffusion process as follows:\ng(xn\ni , t) = ϵρMGP(xn\ni )∇xn\ni log(N(xn\ni |0, ϵ(1 −t))I),\n(14)\nwhere the coefficients ρMGP defined on multiple dis-\ntribution prototypes is calculated as:\nρMGP(xn\ni )\n=\nPC\nc=1(αcN(eµc(xn\ni )|0, σc)N(hc(xn\ni , t)|0, Σt\nc)), with an-\nother Gaussian of hc(xn\ni , t) =\n1\nϵ(1−t)xn\ni + σ−1\nc\neµc(xn\ni ) and\nΣt\nc =\nt\nϵ(1−t)I + σ−1\nc . The derivation about Eqns. (13) and\n(14) is deferred to the supplementary material.\nDistribution prototypes initialization.\nJointly learning\nprototypes {αc, µc, σc}C\nc=1 and the bridge transformation\nψp (also the shift g) is a challenging task as they are in-\nterdependent. For this, we leverage a vector quantization\nfunction to learn a codebook E of prototypes within a dis-\ncrete latent space from training data. Specifically, given an\ninput image feature xn\ni , we can assign xn\ni to the closest pro-\ntotype ek by minimizing the L2 distance between xn\ni and\neach of prototypes ec ∈E, as follows:\nmin\n{ec} Exn\ni∈Ftr[∥xn\ni−ec∗∥2\n2], s.t. , c∗=arg min\nc\n∥xn\ni−ec∥2, (15)\nwhere c∗denotes the index of the prototype closest to xn\ni .\nThe learned {ec}C\nc=1 are used to initialize the mean vectors\n{µc}C\nc=1, while the variances of all prototypes are set to the\nidentity matrix. We observe that this initialization strategy\naccelerates the training process.\nDistribution loss of normal and anomaly samples. As p0\nand p1 are accessible only via samples Ftr and prototypes\nPMGP, we optimize the empirical form in Eqn. (2) for nor-\nmal samples as follows:\nLn\nDPL = 1\nN\nN\nX\ni=1\nlog ϖθ(xn\ni ) −1\nC\nC\nX\nc=1\nlog ϕ1(µc),\n(16)\nIn contrast, for anomaly samples, we aim to push anomaly\ndistribution away from p1, i.e., negative loss, formally,\nLa\nDPL = 1\nC\nC\nX\nc=1\nlog ϕ1(µc) −1\nM\nM\nX\ni=1\nlog ϖθ(xa\ni ),\n(17)\n4.3. Dispersion Feature Learning\nA critical challenge in OSAD is detecting previously un-\nseen anomalies in open-set environments.\nDue to the\nlimited anomaly observations, existing methods often use\npseudo-anomaly generation strategies as a means of effec-\ntive data augmentation. Nonetheless, the effectiveness of\nthese methods heavily depends on the quality of the pseudo-\nanomaly feature embeddings.\nNotably, pseudo-anomaly\ndistributions often inherit biases from the in-distribution\ndata, which differ from the unknown anomaly distributions\nin out-of-distribution data. Current methods fail to address\nthe relationship between observed and unknown anomalies,\nparticularly for out-of-distribution generalization.\nTo improve out-of-distribution detection, it is essential\nto promote a larger inter-sample dispersion, as greater dis-\ntances among in-distribution samples facilitate their more\neffective separation from out-of-distribution samples.\nIn\nother words, if all inter-sample distances are close to zero,\ni.e., collapse to a single point, it becomes impossible to dif-\nferentiate between samples. Hence, promoting separability\nthrough a larger inter-sample dispersion is critical for accu-\nrately identifying samples that do not belong to known cate-\ngories. To do so, we map the features into a hyperspherical\nspace. Draws inspiration from the vMF distribution [30] in\ndirectional statistics, we compute spherical Gaussian distri-\nbutions for unit-norm features bxi = xi/∥xi∥2\n2. The proba-\nbility density function of a unit vector bxi ∈RD is defined\nin the hyperspherical space as follows:\npD(bxi; bxj, κ) = FD(κ) exp(κ⟨bxi, bxj⟩),\n(18)\nwhere κ ≥0 controls the concentration of the distribution\naround the mean direction bxj and FD(κ) is the normaliza-\ntion factor. A larger κ value increases concentration around\nthe mean, while in the extreme case κ = 0, sample points\nare uniformly distributed on the hypersphere. Therefore, we\ndesign a dispersion loss to optimize large angular distances\nbetween the features of all samples:\nLDFL= 1\nU\nU\nX\ni=1\nlog\n1\nU −1\nU\nX\ni,j=1\n1{i ̸= j} exp(κ⟨bxi, bxj⟩), (19)\nwhere U = N + M, and κ is set to 10 in our experiments.\n4.4. Anomaly Score Prediction\nBased on the above designs, we leverage the multiple-\ninstance-learning (MIL)-based method proposed in [34] to\neffectively learn anomaly scores. Similar to the work [9],\nwe design three modules M = {Ma, Mn and Mr} for esti-\nmating anomaly scores. Firstly, for the feature map xi3, we\ngenerate pixel-wise feature vectors V = {vi}H′×W ′\ni=1\nto rep-\nresent the feature of small patches of the image xi, where\n(H′, W ′) denotes the size of the feature map. These pixel-\nwise representations are then mapped by an anomaly clas-\nsifier Sa to estimate pixel-level anomaly scores. To capture\nthose points with the most salient anomalies, we compute\nthe top-K most anomaly pixel points and define the loss\nfunction as:\nLMa(xi, yi) = Lbinary( 1\nK\nX\nTopK{Sa(vi; θa)}, yi), (20)\n3Here xi refers to convolution maps without flattening (as used above).\n\n\nwhere Lbinary refers to a binary classification loss function,\nand TopK selects the highest K anomaly scores among all\nthe vectors. Secondly, we use Mn to learn the normal fea-\ntures:\nLMn(xi, yi) = Lbinary(Sn(\n1\nH′ × W ′\nH′×W ′\nX\ni=1\nvi; θn), yi),\n(21)\nwhere Sn : V →R is a fully connected binary anomaly\nclassifier. Finally, we define Mr to compute the residual\nanomaly scores between fine-grained visual semantics and\nabstract prototypes:\nLMr = Lbinary(Sr((ψp(xi) −µc∗)/σc∗; θr), yi),\n(22)\nwhere c∗denotes the index of the most probable prototypes,\ni.e., c∗= arg maxc N(ψp(xi); µc, σc), and Sr utilize the\nsame method to obtain anomaly score as Sa.\nTraining. During the training phase, the SB and three\nprediction modules are jointly trained. To this end, we em-\nploy an objective function that encompasses three compo-\nnents as follows:\nL = LMa + LMn + LMr\n|\n{z\n}\nMIL-based learning\n+ Ln\nDPL + La\nDPL\n|\n{z\n}\nSB transform\n+ λLDFL\n| {z }\ndispersion\n. (23)\nwhere the coefficient λ modulates the relative importance\nof dispersion loss, and the learnable parameters include\n{αc, µc, σc}, θψp, and {θa, θn, θr}.\nInference. During the test phase, we find the most sim-\nilar class prototype through SB, and subsequently compute\nthe anomaly score by adding the scores from both Sa and\nSr, while subtracting the normal score obtained from Sn for\nthe given test image.\nIn summary, we reduce all the above processes into an\nalgorithm given in the supplementary material for clarity.\n5. Experiment\n5.1. Dataset and Evaluation Metric\nDataset To validate the effectiveness of DPDL, compre-\nhensive experiments are conducted on nine real-world AD\ndatasets, including six industrial defect detection datasets\n(MVTec AD [3], Optical [40], SDD [?\n], AITEX [38],\nELPV [8], Mastcam [13]) and three medical image datasets\n(Hyper-Kvasir [4], Brain-MRI [36], HeadCT [36]). We fol-\nlow the previous OSAD baselines [9, 45] to adopt two pro-\ntocols for sampling, including general setting and hard set-\nting. The general setting assumes that anomaly examples\nare randomly sampled from the anomaly class, while the\nhard setting samples from a single class to assess general-\nization to new or unseen anomaly classes.\nEvaluation Metric We utilize the widely adopted Area Un-\nder ROC Curve (AUC) as a metric to evaluate the perfor-\nmance across all methods and settings. All reported AUCs\nare averaged results over five independent runs.\n5.2. Baselines\nWe compare DPDL against six related state-of-the-art\nOSAD baselines, including SAOE [19, 31, 39], MLEP [27],\nFLOS [35], DevNet [34], DRA [9], and AHL [45]. MLEP,\nDevNet, DRA, and AHL are specifically designed for\nOSAD. SAOE is a supervised detector enhanced with syn-\nthetic anomalies and anomaly exposure, whereas FLOS is\nan imbalanced classifier leveraging focal loss.\n5.3. Implementation Details\nThe input image size is 448×448×3. We set K in the top-\nK MIL to 10% of the number of all scores per score map.\nAdamW optimizer [29] is used for the parameter optimiza-\ntion using an initial learning rate 2×10−4 with a weight de-\ncay of 1×10−5. DPDL is trained on one NVIDIA GeForce\nRTX 4090 GPU, which are trained using 50 epochs, with 20\niterations per epoch. Following previous protocol [9, 45],\nwe evaluate performance with anomaly sample numbers of\nM = 10 and M = 1, and for robust detection of unseen\nanomalies, we use CutMix [43] to create pseudo-anomaly\nsamples as augmented data for known anomalies. The pro-\ntotype quantity C is set to 32 as default. Our code will be\navailable at our site4.\n5.4. Results under General Setting\nTab. 1 highlights DPDL’s strong performance. In the chal-\nlenging scenario of single-anomaly detection, DPDL im-\nproves the performance of AHL [45] by more than 8.3%\non the AITEX, ELPV, and Mastcam datasets. Furthermore,\nit achieves significant improvements across six additional\ndatasets, which suggest the effective utilization of few-shot\nanomaly examples in DPDL, while mitigating overfitting to\nthe seen anomalies. When shifting to ten anomaly examples\nsettings, DPDL continues to maintain a significant lead with\nover 5.4% improvement on those datasets. Given the rich\nand diverse set of normal samples in these datasets, DPDL\nleverages the DPL component to encapsulate these samples\nwithin a compact, discriminative distribution space, while\neffectively pushing anomalous samples outside this space,\nthereby enabling accurate anomaly detection. In the setting\nwith ten abnormal samples, although existing methods have\nreached performance saturation on the MVTecAD, Optical,\nand SDD datasets, DPDL still has a certain lead, demon-\nstrating the strong ability of DPL and DFL in learning tight\nboundaries of normal sample distributions and generalizing\nto previously unseen anomaly domains. Furthermore, when\nevaluated on the medical datasets BrainMRI and HeadCT,\nDPDL demonstrates competitive performance despite these\ndatasets being notably small in scale and containing only a\nsingle class. This highlights the algorithm’s ability to de-\nliver robust results even in data-scarce conditions.\n4https://github.com/fuyunwang/DPDL\n\n\nTable 1. AUC performance (mean ± std) across nine real-world AD datasets is reported under the general setting. red highlights the best\nresults, and blue indicates sub-optimal outcomes. All baseline SOTA results are sourced from the original papers [9, 45].\nDataset\nDevNet\nFLOS\nSAOE\nMLEP\nDRA\nAHL\nDPDL (Ours)\nTen Training Anomaly Examples\nMVTec AD\n0.945±0.004\n0.939±0.007\n0.926±0.010\n0.907±0.005\n0.959±0.003\n0.970±0.002\n0.977±0.002\nOptical\n0.782±0.065\n0.720±0.055\n0.941±0.013\n0.740±0.039\n0.965±0.006\n0.976±0.004\n0.983±0.005\nSDD\n0.988±0.006\n0.967±0.018\n0.955±0.020\n0.983±0.013\n0.991±0.005\n0.991±0.001\n0.996±0.001\nAITEX\n0.887±0.013\n0.841±0.049\n0.874±0.024\n0.867±0.037\n0.893±0.017\n0.925±0.013\n0.975±0.007\nELPV\n0.846±0.022\n0.818±0.032\n0.793±0.047\n0.794±0.047\n0.845±0.013\n0.850±0.004\n0.937±0.003\nMastcam\n0.790±0.021\n0.703±0.029\n0.810±0.029\n0.798±0.026\n0.848±0.008\n0.855±0.005\n0.934±0.010\nHyper-Kvasir\n0.829±0.018\n0.773±0.029\n0.666±0.050\n0.600±0.069\n0.834±0.004\n0.880±0.003\n0.939±0.005\nBrainMRI\n0.958±0.012\n0.955±0.011\n0.900±0.041\n0.959±0.011\n0.970±0.003\n0.977±0.001\n0.969±0.005\nHeadCT\n0.982±0.009\n0.971±0.004\n0.935±0.021\n0.972±0.014\n0.972±0.002\n0.999±0.003\n0.981±0.003\nOne Training Anomaly Example\nMVTec AD\n0.780±0.020\n0.755±0.136\n0.834±0.007\n0.744±0.019\n0.883±0.008\n0.901±0.003\n0.927±0.002\nOptical\n0.523±0.003\n0.518±0.003\n0.815±0.014\n0.516±0.009\n0.888±0.012\n0.888±0.007\n0.915±0.002\nSDD\n0.881±0.009\n0.840±0.043\n0.781±0.009\n0.811±0.045\n0.859±0.014\n0.909±0.001\n0.917±0.003\nAITEX\n0.598±0.070\n0.538±0.073\n0.675±0.094\n0.564±0.055\n0.692±0.124\n0.734±0.008\n0.838±0.008\nELPV\n0.514±0.076\n0.457±0.056\n0.635±0.092\n0.578±0.062\n0.675±0.024\n0.828±0.005\n0.897±0.002\nMastcam\n0.595±0.016\n0.542±0.017\n0.662±0.018\n0.625±0.045\n0.692±0.058\n0.743±0.003\n0.838±0.011\nHyper-Kvasir\n0.653±0.037\n0.668±0.004\n0.498±0.100\n0.445±0.040\n0.690±0.017\n0.768±0.015\n0.821±0.007\nBrainMRI\n0.694±0.004\n0.693±0.036\n0.531±0.060\n0.632±0.017\n0.744±0.004\n0.866±0.004\n0.893±0.004\nHeadCT\n0.742±0.076\n0.698±0.092\n0.597±0.022\n0.758±0.038\n0.796±0.105\n0.825±0.014\n0.865±0.005\nTable 2. AUC results (mean ± std) under the hard setting. The best and second-best results are highlighted in red and blue, respectively.\nCarpet and Metal nut are subsets of MVTec AD. The datasets used are consistent with those in [9, 45], where those datasets only containing\none anomaly class are excluded to adapt for the hard setting. For detailed class-level results, please refer to the supplementary materia.\nDataset\nDevNet\nFLOS\nSAOE\nMLEP\nDRA\nAHL\nDPDL (Ours)\nTen Training Anomaly Examples\nCarpet (mean)\n0.847±0.017\n0.761±0.012\n0.762±0.073\n0.751±0.023\n0.935±0.013\n0.949±0.002\n0.956±0.004\nMetal nut (mean)\n0.965±0.011\n0.922±0.014\n0.855±0.016\n0.878±0.058\n0.945±0.017\n0.972±0.002\n0.978±0.002\nAITEX (mean)\n0.683±0.032\n0.635±0.043\n0.724±0.032\n0.626±0.041\n0.733±0.009\n0.747±0.002\n0.798±0.005\nELPV (mean)\n0.702±0.023\n0.642±0.032\n0.683±0.047\n0.745±0.020\n0.766±0.029\n0.788±0.003\n0.818±0.003\nMastcam (mean)\n0.588±0.011\n0.616±0.021\n0.697±0.014\n0.588±0.016\n0.695±0.004\n0.721±0.003\n0.778±0.007\nHyper-Kvasir (mean)\n0.822±0.019\n0.786±0.021\n0.698±0.021\n0.571±0.014\n0.844±0.009\n0.854±0.004\n0.864±0.002\nOne Training Anomaly Example\nCarpet (mean)\n0.767±0.018\n0.678±0.040\n0.753±0.055\n0.679±0.029\n0.901±0.006\n0.932±0.003\n0.941±0.006\nMetal nut (mean)\n0.855±0.016\n0.855±0.024\n0.816±0.029\n0.825±0.023\n0.932±0.017\n0.939±0.004\n0.944±0.003\nAITEX (mean)\n0.646±0.034\n0.624±0.024\n0.674±0.034\n0.466±0.030\n0.684±0.033\n0.707±0.007\n0.753±0.005\nELPV (mean)\n0.648±0.057\n0.691±0.008\n0.614±0.048\n0.566±0.111\n0.703±0.022\n0.740±0.003\n0.762±0.003\nMastcam (mean)\n0.511±0.013\n0.524±0.013\n0.689±0.037\n0.541±0.007\n0.667±0.012\n0.673±0.010\n0.733±0.004\nHyper-Kvasir (mean)\n0.595±0.023\n0.571±0.004\n0.406±0.018\n0.480±0.044\n0.700±0.009\n0.706±0.007\n0.715±0.004\n5.5. Results under the Hard Setting\nTab. 2 summarizes the performance comparison under the\nhard setting. It is evident that DPDL achieves the highest\nAUC scores in both the single-anomaly and ten-anomaly\nsample settings. Specifically, compared to the closest com-\npeting method, AHL [45], DPDL achieves an improve-\nment in AUC scores ranging from 0.6% to 7.9% in the ten\nanomaly examples settings and from 0.5% to 8.9% in the\none anomaly example settings, respectively. The observed\nimprovement can be attributed to the strong generalization\nability of DPDL in detecting unseen anomaly classes, even\nwhen the model is trained on only a single anomaly class.\n5.6. Ablation Study\nThe ablation study in Fig. 2 highlights the critical roles of\nthe DPL and DFL components in improving DPDL’s open-\nset anomaly detection. We denote the variants that remove\nonly DPL or DFL as ‘DPDL w/o DPL’ and ‘DPDL w/o\nDFL’, respectively. Compared to the full DPDL model, re-\nmoving neither DPL nor DFL leads to a significant AUC de-\ncline, illustrating their critical utility. Specifically, ‘DPDL\n\n\nMVTec AD\nOptical\nSDD\nAITEX\n0.60\n0.65\n0.70\n0.75\n0.80\n0.85\n0.90\n0.95\n1.00\nAUC\nDPDL\nDPDL w/o DPL\nDPDL w/o DFL\nELPV\nMastcamHyper-KvasirBrainMRI HeadCT\n0.60\n0.65\n0.70\n0.75\n0.80\n0.85\n0.90\n0.95\n1.00\nDPDL\nDPDL w/o DPL\nDPDL w/o DFL\nCarpet\nMetal_nut\nAITEX\n0.60\n0.65\n0.70\n0.75\n0.80\n0.85\n0.90\n0.95\n1.00\nDPDL\nDPDL w/o DPL\nDPDL w/o DFL\nELPV\nMastcam\nHyper-Kvasir\n0.60\n0.65\n0.70\n0.75\n0.80\n0.85\n0.90\n0.95\n1.00\nDPDL\nDPDL w/o DPL\nDPDL w/o DFL\nTen Training Anomaly Examples Under General Settings\nTen Training Anomaly Examples Under Hard Settings\nFigure 2. Ablation study for SB and DFL under the general settings and hard settings.\n8\n16\n32\n64\nC\n0.90\n0.92\n0.94\n0.96\n0.98\n1.00\n1.02\nAUC\nMVTec AD\nOptical\nSDD\nAITEX\nELPV\nMastcam\nHyper-Kvasir\nBrainMRI\nHeadCT\n0.001\n0.01\n0.1\n1\n10\n0.90\n0.92\n0.94\n0.96\n0.98\n1.00\n1.02\nMVTec AD\nOptical\nSDD\nAITEX\nELPV\nMastcam\nHyper-Kvasir\nBrainMRI\nHeadCT\n0.1\n1\n10\n100\n1000\n0.90\n0.92\n0.94\n0.96\n0.98\n1.00\n1.02\nMVTec AD\nOptical\nSDD\nAITEX\nELPV\nMastcam\nHyper-Kvasir\nBrainMRI\nHeadCT\n0.0001\n0.001\n0.01\n0.1\n1\n10\n0.90\n0.92\n0.94\n0.96\n0.98\n1.00\n1.02\nMVTec AD\nOptical\nSDD\nAITEX\nELPV\nMastcam\nHyper-Kvasir\nBrainMRI\nHeadCT\nFigure 3. Parameter sensitivity analysis for C, ϵ, κ and λ.\nTable 3. An ablation study for Mn, Ma and Mr.\nMn\nMa\nMr\nAITEX\nELPV\nMastcam\nTen Training Anomaly Examples Under General Settings\n0.928 ± 0.019 0.914 ± 0.021\n0.899 ± 0.036\n0.939 ± 0.023 0.919 ± 0.011\n0.908 ± 0.017\n0.963 ± 0.008 0.930 ± 0.013\n0.924 ± 0.019\n0.975 ± 0.007\n0.937 ± 0.003\n0.934 ± 0.010\nTen Training Anomaly Examples Under Hard Settings\n0.746 ± 0.025 0.797 ± 0.026\n0.723 ± 0.017\n0.758 ± 0.035 0.802 ± 0.024\n0.736 ± 0.028\n0.781 ± 0.014 0.811 ± 0.018\n0.762 ± 0.021\n0.798 ± 0.005\n0.818 ± 0.003\n0.778 ± 0.007\nw/o DPL’ exhibits the most significant performance drop\non industrial anomaly datasets, reflecting DPL’s prominent\nrole in learning precise and tight distribution boundaries\nfor normal samples. By transforming normal samples into\nGaussian distribution prototype space and pushing abnor-\nmal samples away, DPL enhances the recognition ability of\nanomaly samples. Meanwhile, ablation studies on ‘DPDL\nw/o DFL’ further highlight the critical role of the DFL com-\nponent. By performing discreteness feature learning in hy-\nperspherical space, DFL enhances the generalization ability\nto out-of-distribution anomalies.\nAdditionally, the ablation experiments on Mn, Ma, and\nMr across three datasets in Tab. 3 reveal their varying con-\ntributions. DPDL shows the most significant performance\ndrop when Mr is removed, which illustrates that Mr plays\nthe most critical role in detecting anomalies. Furthermore,\nthe removal of Ma and Mn lead to a noticeable performance\ndrop in DPDL, which underscores their essential roles.\n5.7. Parameter Sensitivity Analysis\nFig. 3 illustrates the results of the four hyperparameters un-\nder the general settings across nine datasets. Overall, the\nperformance remains stable within a certain range of hyper-\nparameter variations, demonstrating the DPDL’s robustness.\nPrototype quantity C.\nWe begin by investigating the\ncritical impact of the number of initialized prototypes\nC on distributed prototype learning in DPDL. We select\n{8, 16, 32, 64} as the values for the hyperparameters. As\nC increases, DPDL’s performance improves steadily, but\nexcessively large values of C hinder the model’s effective-\nness. This phenomenon is particularly pronounced on AI-\nTEX, Mastcam, MVTecAD, and Hyper-Kvasir, which con-\ntain more categories. One possible explanation is that a pro-\ntotype space with too few prototypes loses discriminative\ninformation, while an excessively large number of proto-\ntypes reduces the compactness of the space.\nDPL trajectory ϵ in Eqns. (9), (10), (11) and (14).\nIt\ncan be observed that, particularly on the AITEX, Mastcam,\nand MVTecAD datasets with a larger number of categories,\nDPDL exhibits a relatively stable performance decline as\nϵ increases. As a crucial parameter in SB, ϵ governs the\ntrajectory state. Since smaller values produce straighter tra-\njectories and larger values increase fluctuation, smaller ϵ fa-\ncilitates sampling more robust abstract prototypes from the\nrelatively dispersed conditional distribution.\nDFL tightness κ. According to Fig. 3, increasing κ gener-\nally enhances model performance, but values above κ = 10\nintroduce negative effects in certain scenarios. A possible\nreason is that excessive sample dispersion makes it more\n\n\nchallenging to tighten the normal distribution boundary.\nLoss parameter λ. We conduct a sensitivity analysis on\nthe loss parameters λ. It can be observe that setting λ =\n0.01 achieves optimal performance on seven larger-scale\ndatasets, while λ = 1 yields the best results on two datasets\nwith limited data. As λ increases, the performance declines,\npotentially due to gradient conflicts among the dispersion\nloss, SB transform loss and the main task loss.\n6. Conclusion\nWe propose Distribution Prototype Diffusion Learning\n(DPDL) for OSAD. DPDL leverages schr¨odinger bridge to\nmap the normal distribution to a prototype space, simultane-\nously repelling anomalies to facilitate precise anomaly de-\ntection. We propose a dispersion feature learning way in\nhyperspherical space, which benefits the detection of out-\nof-distribution anomalies.\nExperimental results illustrate\nDPDL’s robustness in diverse anomaly detection scenarios.\nReferences\n[1] Andra\nAcsintoae,\nAndrei\nFlorescu,\nMariana-Iuliana\nGeorgescu, Tudor Mare, Paul Sumedrea, Radu Tudor\nIonescu, Fahad Shahbaz Khan, and Mubarak Shah.\nUb-\nnormal:\nNew benchmark for supervised open-set video\nanomaly detection.\nIn Proceedings of the IEEE/CVF\nconference on computer vision and pattern recognition,\npages 20143–20153, 2022. 1, 2\n[2] Aimira Baitieva, David Hurych, Victor Besnier, and Olivier\nBernard. Supervised anomaly detection for complex indus-\ntrial images. In Proceedings of the IEEE/CVF Conference\non Computer Vision and Pattern Recognition, pages 17754–\n17762, 2024. 1\n[3] Paul Bergmann, Michael Fauser, David Sattlegger, and\nCarsten Steger.\nMvtec ad–a comprehensive real-world\ndataset for unsupervised anomaly detection. In Proceedings\nof the IEEE/CVF conference on computer vision and pattern\nrecognition, pages 9592–9600, 2019. 6, 1\n[4] Hanna Borgli, Vajira Thambawita, Pia H Smedsrud, Steven\nHicks, Debesh Jha, Sigrun L Eskeland, Kristin Ranheim\nRandel, Konstantin Pogorelov, Mathias Lux, Duc Tien Dang\nNguyen, et al. Hyperkvasir, a comprehensive multi-class im-\nage and video dataset for gastrointestinal endoscopy. Scien-\ntific data, 7(1):283, 2020. 6, 1\n[5] Yongxin Chen, Tryphon T Georgiou, and Michele Pavon.\nOn the relation between optimal transport and schr¨odinger\nbridges: A stochastic control viewpoint. Journal of Opti-\nmization Theory and Applications, 169:671–691, 2016. 2\n[6] Songmin Dai, Yifan Wu, Xiaoqiang Li, and Xiangyang\nXue.\nGenerating and reweighting dense contrastive pat-\nterns for unsupervised anomaly detection. In Proceedings of\nthe AAAI Conference on Artificial Intelligence, pages 1454–\n1462, 2024. 1\n[7] Valentin De Bortoli, James Thornton, Jeremy Heng, and Ar-\nnaud Doucet. Diffusion schr¨odinger bridge with applications\nto score-based generative modeling. Advances in Neural In-\nformation Processing Systems, 34:17695–17709, 2021. 2\n[8] Sergiu Deitsch, Vincent Christlein, Stephan Berger, Claudia\nBuerhop-Lutz, Andreas Maier, Florian Gallwitz, and Chris-\ntian Riess. Automatic classification of defective photovoltaic\nmodule cells in electroluminescence images. Solar Energy,\n185:455–468, 2019. 6, 1\n[9] Choubo Ding, Guansong Pang, and Chunhua Shen. Catching\nboth gray and black swans: Open-set supervised anomaly\ndetection. In Proceedings of the IEEE/CVF conference on\ncomputer vision and pattern recognition, pages 7388–7398,\n2022. 1, 2, 5, 6, 7\n[10] Nikita Gushchin, Sergei Kholkin, Evgeny Burnaev, and\nAlexander Korotin. Light and optimal schr¨odinger bridge\nmatching.\nIn Forty-first International Conference on Ma-\nchine Learning, 2024. 2, 4\n[11] Liren He, Zhengkai Jiang, Jinlong Peng, Liang Liu, Qian-\ngang Du, Xiaobin Hu, Wenbing Zhu, Mingmin Chi, Yabiao\nWang, and Chengjie Wang. Learning unified reference rep-\nresentation for unsupervised multi-class anomaly detection.\narXiv preprint arXiv:2403.11561, 2024. 1\n[12] Teng Hu, Jiangning Zhang, Ran Yi, Yuzhen Du, Xu Chen,\nLiang Liu, Yabiao Wang, and Chengjie Wang. Anomalyd-\niffusion: Few-shot anomaly image generation with diffusion\nmodel. In Proceedings of the AAAI Conference on Artificial\nIntelligence, pages 8526–8534, 2024. 1\n[13] Hannah R Kerner, Kiri L Wagstaff, Brian D Bue, Danika F\nWellington, Samantha Jacob, Paul Horton, James F Bell,\nChiman Kwan, and Heni Ben Amor. Comparison of novelty\ndetection methods for multispectral images in rover-based\nplanetary exploration missions. Data Mining and Knowledge\nDiscovery, 34:1642–1675, 2020. 6, 1\n[14] Beomsu Kim,\nGihyun Kwon,\nKwanyoung Kim,\nand\nJong Chul Ye. Unpaired image-to-image translation via neu-\nral schr\\” odinger bridge. arXiv preprint arXiv:2305.15086,\n2023. 2\n[15] Daehyun Kim, Sungyong Baik, and Tae Hyun Kim. San-\nflow: Semantic-aware normalizing flow for anomaly detec-\ntion. Advances in Neural Information Processing Systems,\n36:75434–75454, 2023. 1\n[16] Hyunsu Kim, Jongmin Yoon, and Juho Lee. Fast ensem-\nbling with diffusion schr\\” odinger bridge. arXiv preprint\narXiv:2404.15814, 2024. 2\n[17] Alexander Korotin, Nikita Gushchin, and Evgeny Bur-\nnaev.\nLight schr\\” odinger bridge.\narXiv preprint\narXiv:2310.01174, 2023. 2, 4\n[18] Christian L´eonard. A survey of the schr\\” odinger problem\nand some of its connections with optimal transport. arXiv\npreprint arXiv:1308.0215, 2013. 2, 3\n[19] Chun-Liang Li, Kihyuk Sohn, Jinsung Yoon, and Tomas\nPfister. Cutpaste: Self-supervised learning for anomaly de-\ntection and localization. In Proceedings of the IEEE/CVF\nconference on computer vision and pattern recognition,\npages 9664–9674, 2021. 1, 6\n[20] Hanxi Li, Jingqi Wu, Hao Chen, Mingwen Wang, and Chun-\nhua Shen.\nEfficient anomaly detection with budget anno-\ntation using semi-supervised residual transformer.\narXiv\npreprint arXiv:2306.03492, 2023. 1\n\n\n[21] Xiaofan Li, Zhizhong Zhang, Xin Tan, Chengwei Chen,\nYanyun Qu, Yuan Xie, and Lizhuang Ma. Promptad: Learn-\ning prompts with only normal samples for few-shot anomaly\ndetection. In Proceedings of the IEEE/CVF Conference on\nComputer Vision and Pattern Recognition, pages 16838–\n16848, 2024. 1\n[22] Jingyi Liao, Xun Xu, Manh Cuong Nguyen, Adam Goodge,\nand Chuan Sheng Foo. Coft-ad: Contrastive fine-tuning for\nfew-shot anomaly detection. IEEE Transactions on Image\nProcessing, 2024. 1\n[23] Guan-Horng Liu, Tianrong Chen, Oswin So, and Evangelos\nTheodorou. Deep generalized schr¨odinger bridge. Advances\nin Neural Information Processing Systems, 35:9374–9388,\n2022. 2\n[24] Guan-Horng Liu, Yaron Lipman, Maximilian Nickel, Brian\nKarrer, Evangelos A Theodorou, and Ricky TQ Chen. Gen-\neralized schr\\” odinger bridge matching.\narXiv preprint\narXiv:2310.02233, 2023. 2\n[25] Guan-Horng Liu, Arash Vahdat, De-An Huang, Evange-\nlos A Theodorou, Weili Nie, and Anima Anandkumar. i2-\nsb: Image-to-image schr\\” odinger bridge. arXiv preprint\narXiv:2302.05872, 2023. 2\n[26] Jiaqi Liu, Kai Wu, Qiang Nie, Ying Chen, Bin-Bin\nGao, Yong Liu, Jinbao Wang, Chengjie Wang, and Feng\nZheng.\nUnsupervised continual anomaly detection with\ncontrastively-learned prompt. In Proceedings of the AAAI\nConference on Artificial Intelligence, pages 3639–3647,\n2024. 1\n[27] Wen Liu, Weixin Luo, Zhengxin Li, Peilin Zhao, Shenghua\nGao, et al. Margin learning embedded prediction for video\nanomaly detection with a few anomalies. In IJCAI, pages\n023–3, 2019. 1, 2, 6\n[28] Xinyue Liu,\nJianyuan Wang,\nBiao Leng,\nand Shuo\nZhang.\nDual-modeling decouple distillation for unsuper-\nvised anomaly detection. arXiv preprint arXiv:2408.03888,\n2024. 1\n[29] I Loshchilov. Decoupled weight decay regularization. arXiv\npreprint arXiv:1711.05101, 2017. 6\n[30] Kanti V Mardia and Peter E Jupp. Directional statistics. John\nWiley & Sons, 2009. 5\n[31] Amir Markovitz, Gilad Sharir, Itamar Friedman, Lihi Zelnik-\nManor, and Shai Avidan. Graph embedded pose clustering\nfor anomaly detection.\nIn Proceedings of the IEEE/CVF\nConference on Computer Vision and Pattern Recognition,\npages 10539–10547, 2020. 6\n[32] Maxence Noble, Valentin De Bortoli, Arnaud Doucet, and\nAlain Durmus. Tree-based diffusion schr¨odinger bridge with\napplications to wasserstein barycenters. Advances in Neural\nInformation Processing Systems, 36, 2024. 2\n[33] Guansong Pang, Chunhua Shen, and Anton Van Den Hen-\ngel. Deep anomaly detection with deviation networks. In\nProceedings of the 25th ACM SIGKDD international confer-\nence on knowledge discovery & data mining, pages 353–362,\n2019. 1\n[34] Guansong Pang,\nChoubo Ding,\nChunhua Shen,\nand\nAnton van den Hengel.\nExplainable deep few-shot\nanomaly detection with deviation networks. arXiv preprint\narXiv:2108.00462, 2021. 2, 5, 6\n[35] T-YLPG Ross and GKHP Doll´ar. Focal loss for dense ob-\nject detection.\nIn proceedings of the IEEE conference on\ncomputer vision and pattern recognition, pages 2980–2988,\n2017. 6\n[36] Mohammadreza\nSalehi,\nNiousha\nSadjadi,\nSoroosh\nBaselizadeh, Mohammad H Rohban, and Hamid R Ra-\nbiee.\nMultiresolution knowledge distillation for anomaly\ndetection.\nIn Proceedings of the IEEE/CVF confer-\nence on computer vision and pattern recognition, pages\n14902–14912, 2021. 6, 1\n[37] Yuyang Shi, Valentin De Bortoli, Andrew Campbell, and Ar-\nnaud Doucet. Diffusion schr¨odinger bridge matching. Ad-\nvances in Neural Information Processing Systems, 36, 2024.\n2\n[38] Javier Silvestre-Blanes, Teresa Albero-Albero, Ignacio Mi-\nralles, Rub´en P´erez-Llorens, and Jorge Moreno. A public\nfabric database for defect detection methods and results. Au-\ntex Research Journal, 19(4):363–374, 2019. 6, 1\n[39] Jihoon Tack, Sangwoo Mo, Jongheon Jeong, and Jinwoo\nShin. Csi: Novelty detection via contrastive learning on dis-\ntributionally shifted instances. Advances in neural informa-\ntion processing systems, 33:11839–11852, 2020. 6\n[40] Matthias Wieler and Tobias Hahn. Weakly supervised learn-\ning for industrial optical inspection. In DAGM symposium\nin, page 11, 2007. 6, 1\n[41] Xincheng Yao, Ruoqi Li, Jing Zhang, Jun Sun, and\nChongyang Zhang.\nExplicit boundary guided semi-push-\npull contrastive learning for supervised anomaly detection.\nIn Proceedings of the IEEE/CVF Conference on Computer\nVision and Pattern Recognition, pages 24490–24499, 2023.\n1, 2\n[42] Xincheng Yao, Ruoqi Li, Zefeng Qian, Lu Wang, and\nChongyang Zhang. Hierarchical gaussian mixture normal-\nizing flow modeling for unified anomaly detection. arXiv\npreprint arXiv:2403.13349, 2024. 1\n[43] Sangdoo Yun, Dongyoon Han, Seong Joon Oh, Sanghyuk\nChun, Junsuk Choe, and Youngjoon Yoo. Cutmix: Regu-\nlarization strategy to train strong classifiers with localizable\nfeatures. In Proceedings of the IEEE/CVF international con-\nference on computer vision, pages 6023–6032, 2019. 6\n[44] Qihang Zhou, Guansong Pang, Yu Tian, Shibo He, and\nJiming Chen. Anomalyclip: Object-agnostic prompt learn-\ning for zero-shot anomaly detection.\narXiv preprint\narXiv:2310.18961, 2023. 1\n[45] Jiawen Zhu, Choubo Ding, Yu Tian, and Guansong Pang.\nAnomaly heterogeneity learning for open-set supervised\nanomaly detection. In Proceedings of the IEEE/CVF Con-\nference on Computer Vision and Pattern Recognition, pages\n17616–17626, 2024. 1, 2, 6, 7\n[46] Yuansheng Zhu, Wentao Bao, and Qi Yu. Towards open set\nvideo anomaly detection. In European Conference on Com-\nputer Vision, pages 395–412. Springer, 2022. 1, 2\n\n\nDistribution Prototype Diffusion Learning for Open-set Supervised\nAnomaly Detection\nSupplementary Material\n7. Dataset Statistics\nExtensive experiments are conducted on nine real-world\nanomaly detection (AD) datasets. Tab. 4 provides key statis-\ntics for all datasets used in this study. We follow the exact\nsame settings as in previous open-set supervised anomaly\ndetection (OSAD) studies.\nSpecifically, for the MVTec\nAD dataset, we adhere to the original split, dividing the\nnormal samples into training and test sets. For the other\neight datasets, normal samples are randomly partitioned\ninto training and test sets at a 3:1 ratio.\nTable 4. The statistical information for nine real-world anomaly\ndetection (AD) datasets, with the first 15 rows detailing the subsets\nof the MVTec AD dataset.\nDataset\nOriginal Training\nOriginal Test\n|C|\nType\nNormal\nNormal Anomaly\nCarpet\n5\nTextture\n280\n28\n89\nGrid\n5\nTextture\n264\n21\n57\nLeather\n5\nTextture\n245\n32\n92\nTile\n5\nTextture\n230\n33\n83\nWood\n5\nTextture\n247\n19\n60\nBottle\n3\nObject\n209\n20\n63\nCapsule\n5\nObject\n219\n23\n109\nPill\n7\nObject\n267\n26\n141\nTransistor\n4\nObject\n213\n60\n40\nZipper\n7\nObject\n240\n32\n119\nCable\n8\nObject\n224\n58\n92\nHazelnut\n4\nObject\n391\n40\n70\nMetal nut\n4\nObject\n220\n22\n93\nScrew\n5\nObject\n320\n41\n119\nToothbrush\n1\nObject\n60\n12\n30\nMVTecAD\n73\n-\n3629\n467\n1258\nOptical\n1\nObject\n10500\n3500\n2100\nSDD\n1\nTextture\n594\n286\n54\nAITEX\n12 Textture\n1692\n564\n183\nELPV\n2\nTextture\n1131\n377\n715\nMastcam\n11\nObject\n9302\n426\n451\nHyper-Kvasir\n4\nMedical\n2021\n674\n757\nBrainMRI\n1\nMedical\n73\n25\n155\nHeadCT\n1\nMedical\n75\n25\n100\n• MVTec AD [3] is a widely-used benchmark for defect de-\ntection, comprising 15 distinct categories, each of which\nincludes one or several subcategories. The dataset con-\ntains a total of 73 fine-grained anomaly classes at either\nthe texture or object level.\n• Optical [40] is a synthetic dataset designed for industrial\noptical inspection and defect detection. The artificially\ngenerated data mimics real-world tasks.\n• SDD [? ] is a defect product image detection dataset\nwith pixel-level defect annotations. The original images,\nwhich have a resolution of 500 × 1250, are vertically di-\nvided into three segments. Each segment is then anno-\ntated at the pixel level.\n• AITEX [38] is a fabric defect detection dataset that in-\ncludes 12 defect categories with pixel-level annotations.\nThe original images, which have a resolution of 4096 ×\n256, are cropped into multiple 256 × 256 patches. Each\npatch is then re-annotated at the pixel level.\n• ELPV [8] is a dataset for defect detection in electrolumi-\nnescence (EL) images of solar cells. It includes two types\nof defects, corresponding to different types of solar cells:\nmonocrystalline and polycrystalline.\n• Mastcam [13] is a novelty detection dataset con-\nstructed from geological images captured by the mul-\ntispectral imaging system installed on the Mars rover.\nThe dataset includes typical images and images from\n11 novel geological classes.\nEach image comprises\nboth shorter-wavelength (color) channels and longer-\nwavelength (grayscale) channels, with this study focusing\non the shorter-wavelength channels.\n• Hyper-Kvasir [4] is a large-scale, open-access gastroin-\ntestinal dataset collected during real endoscopy and\ncolonoscopy procedures.\nIt comprises four main cate-\ngories and 23 subcategories of endoscopic and colono-\nscopic images. This work focuses on endoscopic images,\nwhere anatomical landmark categories are considered as\nnormal samples and pathological categories are treated as\nabnormal samples.\n• BrainMRI [36] is a brain tumor detection dataset obtained\nthrough magnetic resonance imaging (MRI).\n• HeadCT [36] is a dataset for detecting intracranial hemor-\nrhage obtained through head computed tomography (CT)\nscans.\n8. Full Results under General Setting\nTab. 5 presents a comprehensive comparison of the pro-\nposed DPDL method with state-of-the-art (SOTA) ap-\nproaches under general settings.\nIt reports performance\nmetrics for each category within the MVTec AD dataset.\nOverall, the DPDL model consistently outperforms base-\nline methods across all application scenarios in both ten-\nshot and one-shot settings, achieving the best performance\nin terms of Area Under the Curve (AUC).\n\n\nTable 5. AUC performance (mean ± std) across nine real-world AD datasets is reported under the general setting. red highlights the best\nresults, and blue indicates sub-optimal outcomes. All baseline SOTA results are sourced from the original papers [9, 45].\nDataset\nOne Training Anomaly Example\nTen Training Anomaly Examples\nDevNet\nFLOS\nSAOE\nMLEP\nDRA\nAHL\nDPDL (Ours)\nDevNet\nFLOS\nSAOE\nMLEP\nDRA\nAHL\nDPDL (Ours)\nCarpet\n0.746±0.076\n0.755±0.026\n0.766±0.098\n0.701±0.091\n0.859±0.023\n0.877±0.004 0.914±0.006\n0.867±0.040\n0.780±0.009\n0.755±0.136\n0.781±0.049\n0.940±0.027 0.953±0.001\n0.988±0.002\nGrid\n0.891±0.040\n0.871±0.076\n0.921±0.032\n0.839±0.028\n0.972±0.011\n0.975±0.005 0.999±0.001\n0.967±0.021\n0.966±0.005\n0.952±0.011\n0.980±0.009\n0.987±0.009 0.992±0.002\n0.999±0.001\nLeather\n0.873±0.026\n0.791±0.057\n0.996±0.007\n0.781±0.020\n0.989±0.005\n0.988±0.001 0.996±0.001\n0.999±0.001\n0.993±0.004 1.000±0.000\n0.813±0.158\n1.000±0.000 1.000±0.000\n1.000±0.000\nTile\n0.752±0.038\n0.787±0.038\n0.935±0.034\n0.927±0.036\n0.965±0.015\n0.968±0.001 0.994±0.002\n0.987±0.005\n0.952±0.010\n0.944±0.013\n0.988±0.009\n0.994±0.006 1.000±0.000\n0.999±0.001\nWood\n0.900±0.068\n0.927±0.065\n0.948±0.009\n0.660±0.142\n0.985±0.011\n0.987±0.003 0.998±0.002\n0.999±0.001 1.000±0.000\n0.976±0.031\n0.999±0.002 0.998±0.001 0.998±0.000\n0.998±0.001\nBottle\n0.976±0.006\n0.975±0.023\n0.989±0.019\n0.927±0.090\n1.000±0.000\n1.000±0.000 1.000±0.000\n0.993±0.008\n0.995±0.002\n0.998±0.003\n0.981±0.004 1.000±0.000 1.000±0.000\n1.000±0.000\nCapsule\n0.564±0.032\n0.666±0.020\n0.611±0.109\n0.558±0.075\n0.631±0.056\n0.665±0.030 0.757±0.017\n0.865±0.057\n0.902±0.017\n0.850±0.054\n0.818±0.063 0.935±0.022\n0.930±0.001\n0.976±0.004\nPill\n0.769±0.017\n0.745±0.064\n0.652±0.078\n0.656±0.061\n0.832±0.034\n0.840±0.003 0.842±0.002\n0.866±0.038 0.929±0.012\n0.872±0.049\n0.845±0.048\n0.904±0.024\n0.918±0.001\n0.923±0.001\nTransistor\n0.722±0.032\n0.709±0.041\n0.680±0.182\n0.695±0.124\n0.668±0.068\n0.796±0.003 0.748±0.002\n0.924±0.027\n0.862±0.037\n0.860±0.053 0.927±0.043\n0.915±0.025\n0.926±0.009\n0.928±0.001\nZipper\n0.922±0.018\n0.885±0.033\n0.970±0.033\n0.865±0.086\n0.984±0.016\n0.986±0.000 0.989±0.001\n0.990±0.009\n0.990±0.008\n0.995±0.004\n0.965±0.002 1.000±0.000 1.000±0.000\n1.000±0.000\nCable\n0.783±0.058\n0.790±0.039\n0.819±0.060\n0.688±0.017\n0.876±0.012\n0.858±0.011 0.935±0.008\n0.892±0.020\n0.890±0.063\n0.862±0.022\n0.857±0.062\n0.909±0.011 0.921±0.001\n0.929±0.000\nHazelnut\n0.979±0.010\n0.976±0.021\n0.961±0.042\n0.704±0.090\n0.977±0.030\n0.984±0.004 0.997±0.002\n1.000±0.000 1.000±0.000 1.000±0.000 1.000±0.000 1.000±0.000 1.000±0.000\n1.000±0.000\nMetal nut\n0.876±0.007\n0.930±0.022\n0.922±0.033\n0.878±0.038\n0.948±0.046\n0.952±0.003 0.948±0.007\n0.991±0.006\n0.984±0.004\n0.976±0.013\n0.974±0.009 0.997±0.002 0.998±0.000\n0.996±0.001\nScrew\n0.399±0.187\n0.337±0.091\n0.653±0.074\n0.675±0.294\n0.903±0.064\n0.927±0.009 0.977±0.004\n0.970±0.015\n0.940±0.017\n0.975±0.023\n0.899±0.039\n0.977±0.009 0.985±0.002\n0.995±0.001\nToothbrush\n0.753±0.027\n0.731±0.028\n0.686±0.110\n0.617±0.058\n0.650±0.029\n0.794±0.016 0.807±0.001\n0.860±0.066\n0.900±0.008\n0.865±0.062\n0.783±0.048\n0.826±0.021 0.921±0.007\n0.929±0.000\nMVTec AD\n0.780±0.020\n0.755±0.136\n0.834±0.007\n0.744±0.019\n0.883±0.008\n0.901±0.003 0.927±0.002\n0.945±0.004\n0.939±0.007\n0.926±0.010\n0.907±0.005\n0.959±0.003 0.970±0.002\n0.977±0.002\nOptical\n0.523±0.003\n0.518±0.003\n0.815±0.014\n0.516±0.009\n0.888±0.012\n0.888±0.007 0.915±0.002\n0.782±0.065\n0.720±0.055\n0.941±0.013\n0.740±0.039\n0.965±0.006 0.976±0.004\n0.983±0.005\nSDD\n0.881±0.009\n0.840±0.043\n0.781±0.009\n0.811±0.045\n0.859±0.014\n0.909±0.001 0.917±0.003\n0.988±0.006\n0.967±0.018\n0.955±0.020\n0.983±0.013\n0.991±0.005 0.991±0.001\n0.996±0.001\nAITEX\n0.598±0.070\n0.538±0.073\n0.675±0.094\n0.564±0.055\n0.692±0.124\n0.734±0.008 0.838±0.008\n0.887±0.013\n0.841±0.049\n0.874±0.024\n0.867±0.037\n0.893±0.017 0.925±0.013\n0.975±0.007\nELPV\n0.514±0.076\n0.457±0.056\n0.635±0.092\n0.578±0.062\n0.675±0.024\n0.828±0.005 0.897±0.002\n0.846±0.022\n0.818±0.032\n0.793±0.047\n0.794±0.047\n0.845±0.013 0.850±0.004\n0.937±0.003\nMastcam\n0.595±0.016\n0.542±0.017\n0.662±0.018\n0.625±0.045\n0.692±0.058\n0.743±0.003 0.838±0.011\n0.790±0.021\n0.703±0.029\n0.810±0.029\n0.798±0.026\n0.848±0.008 0.855±0.005\n0.934±0.010\nHyper-Kvasir\n0.653±0.037\n0.668±0.004\n0.498±0.100\n0.445±0.040\n0.690±0.017\n0.768±0.015 0.821±0.007\n0.829±0.018\n0.773±0.029\n0.666±0.050\n0.600±0.069\n0.834±0.004 0.880±0.003\n0.939±0.005\nBrainMRI\n0.694±0.004\n0.693±0.036\n0.531±0.060\n0.632±0.017\n0.744±0.004\n0.866±0.004 0.893±0.004\n0.958±0.012\n0.955±0.011\n0.900±0.041\n0.959±0.011 0.970±0.003 0.977±0.001\n0.969±0.005\nHeadCT\n0.742±0.076\n0.698±0.092\n0.597±0.022\n0.758±0.038\n0.796±0.105\n0.825±0.014 0.865±0.005\n0.982±0.009\n0.971±0.004\n0.935±0.021\n0.972±0.014\n0.972±0.002 0.999±0.003\n0.981±0.003\nTable 6. Detailed class-level AUC results (mean ± std) under the hard setting. The best and second-best results are highlighted in red and\nblue, respectively. Carpet and Metal nut are subsets of MVTec AD.\nDataset\nOne Training Anomaly Example\nTen Training Anomaly Examples\nDevNet\nFLOS\nSAOE\nMLEP\nDRA\nAHL\nDPDL (Ours)\nDevNet\nFLOS\nSAOE\nMLEP\nDRA\nAHL\nDPDL (Ours)\nCarpet\nColor\n0.716±0.085 0.467±0.278 0.763±0.100 0.547±0.056 0.879±0.021 0.894±0.004 0.909±0.001 0.767±0.015 0.760±0.005 0.467±0.067 0.698±0.025 0.886±0.042 0.929±0.007 0.933±0.002\nCut\n0.666±0.035 0.685±0.007 0.664±0.165 0.658±0.056 0.902±0.033 0.934±0.003 0.941±0.003 0.819±0.037 0.688±0.059 0.793±0.175 0.653±0.120 0.922±0.038 0.943±0.002 0.951±0.004\nHole\n0.721±0.067 0.594±0.142 0.772±0.071 0.653±0.065 0.901±0.033 0.935±0.014 0.945±0.009 0.814±0.038 0.733±0.014 0.831±0.125 0.674±0.076 0.947±0.016 0.960±0.003 0.964±0.003\nMetal\n0.819±0.032 0.701±0.028 0.780±0.172 0.706±0.047 0.871±0.037 0.931±0.007 0.940±0.001 0.863±0.022 0.678±0.083 0.883±0.043 0.764±0.061 0.933±0.022 0.921±0.003 0.938±0.005\nThread\n0.912±0.044 0.941±0.005 0.787±0.204 0.831±0.117 0.950±0.029 0.966±0.005 0.970±0.002 0.972±0.009 0.946±0.005 0.831±0.297 0.967±0.006 0.989±0.004 0.991±0.001 0.993±0.000\nMean\n0.767±0.018 0.678±0.040 0.753±0.055 0.679±0.029 0.901±0.006 0.932±0.003 0.941±0.006 0.847±0.017 0.761±0.012 0.762±0.073 0.751±0.023 0.935±0.013 0.949±0.002 0.956±0.004\nMetal nut\nBent\n0.797±0.048 0.851±0.046 0.864±0.032 0.743±0.013 0.952±0.020 0.954±0.003 0.958±0.001 0.904±0.022 0.827±0.075 0.901±0.023 0.956±0.013 0.990±0.003 0.989±0.000 0.991±0.002\nColor\n0.909±0.023 0.821±0.059 0.857±0.037 0.835±0.075 0.946±0.023 0.933±0.008 0.938±0.003 0.978±0.016 0.978±0.008 0.879±0.018 0.945±0.039 0.967±0.011 0.958±0.001 0.969±0.005\nFlip\n0.764±0.014 0.799±0.058 0.751±0.090 0.813±0.031 0.921±0.029 0.931±0.002 0.940±0.004 0.987±0.004 0.942±0.009 0.795±0.062 0.805±0.057 0.913±0.021 0.937±0.003 0.955±0.003\nScratch\n0.952±0.052 0.947±0.027 0.792±0.075 0.907±0.085 0.909±0.023 0.934±0.005 0.936±0.002 0.991±0.017 0.943±0.002 0.845±0.041 0.805±0.153 0.911±0.034 0.999±0.000 0.992±0.002\nMean\n0.855±0.016 0.855±0.024 0.816±0.029 0.825±0.023 0.932±0.017 0.939±0.004 0.944±0.003 0.965±0.011 0.922±0.014 0.855±0.016 0.878±0.058 0.945±0.017 0.972±0.002 0.978±0.002\nAITEX\nBroken end\n0.712±0.069 0.645±0.030 0.778±0.068 0.441±0.111 0.708±0.094 0.704±0.005 0.761±0.010 0.658±0.111 0.585±0.037 0.712±0.068 0.732±0.065 0.693±0.099 0.735±0.010 0.796±0.001\nBroken pick\n0.552±0.003 0.598±0.023 0.644±0.039 0.476±0.070 0.731±0.072 0.727±0.003 0.760±0.014 0.585±0.028 0.548±0.054 0.629±0.012 0.555±0.027 0.760±0.037 0.683±0.002 0.784±0.011\nCut selvage\n0.689±0.016 0.694±0.036 0.681±0.077 0.434±0.149 0.739±0.101 0.753±0.007 0.765±0.007 0.709±0.039 0.745±0.035 0.770±0.014 0.682±0.025 0.777±0.036 0.781±0.006 0.796±0.005\nFuzzyball\n0.617±0.075 0.525±0.043 0.650±0.064 0.525±0.157 0.538±0.092 0.647±0.007 0.715±0.013 0.734±0.039 0.550±0.082 0.842±0.026 0.677±0.223 0.701±0.093 0.775±0.024 0.808±0.003\nNep\n0.722±0.023 0.734±0.038 0.710±0.044 0.517±0.059 0.717±0.052 0.703±0.005 0.757±0.005 0.810±0.042 0.746±0.060 0.771±0.032 0.740±0.052 0.750±0.038 0.792±0.007 0.811±0.005\nWeft crack\n0.586±0.134 0.546±0.114 0.582±0.108 0.400±0.029 0.669±0.045 0.706±0.009 0.758±0.006 0.599±0.137 0.636±0.051 0.618±0.172 0.370±0.037 0.717±0.072 0.713±0.003 0.790±0.004\nMean\n0.646±0.034 0.624±0.024 0.674±0.034 0.466±0.030 0.684±0.033 0.707±0.007 0.753±0.005 0.683±0.032 0.635±0.043 0.724±0.032 0.656±0.041 0.733±0.009 0.747±0.002 0.798±0.004\nELPV\nMono\n0.634±0.087 0.717±0.025 0.563±0.102 0.649±0.027 0.735±0.031 0.774±0.013 0.785±0.002 0.599±0.040 0.629±0.072 0.569±0.035 0.756±0.045 0.731±0.021 0.745±0.004 0.793±0.003\nPoly\n0.662±0.050 0.665±0.021 0.665±0.173 0.483±0.247 0.671±0.051 0.705±0.006 0.738±0.008 0.804±0.022 0.662±0.042 0.796±0.084 0.734±0.078 0.800±0.064 0.831±0.011 0.843±0.004\nMean\n0.648±0.057 0.691±0.008 0.614±0.048 0.566±0.111 0.703±0.022 0.740±0.003 0.762±0.003 0.702±0.023 0.646±0.032 0.683±0.047 0.745±0.020 0.766±0.029 0.788±0.003 0.818±0.003\nMastcam\nBedrock\n0.495±0.028 0.499±0.056 0.636±0.072 0.532±0.036 0.668±0.012 0.679±0.012 0.732±0.003 0.550±0.053 0.499±0.098 0.636±0.068 0.512±0.062 0.658±0.021 0.673±0.006 0.757±0.004\nBroken-rock\n0.533±0.020 0.569±0.025 0.699±0.058 0.544±0.088 0.645±0.053 0.661±0.009 0.738±0.004 0.547±0.018 0.608±0.085 0.712±0.052 0.651±0.063 0.649±0.047 0.722±0.004 0.783±0.002\nDrill-hole\n0.555±0.037 0.539±0.077 0.697±0.074 0.636±0.066 0.657±0.070 0.654±0.004 0.738±0.011 0.583±0.022 0.601±0.009 0.682±0.042 0.660±0.002 0.725±0.005 0.760±0.003 0.797±0.004\nDrt\n0.529±0.046 0.591±0.042 0.735±0.020 0.624±0.042 0.713±0.053 0.724±0.006 0.745±0.005 0.621±0.043 0.652±0.024 0.761±0.062 0.616±0.048 0.760±0.033 0.772±0.004 0.818±0.002\nDump-pile\n0.521±0.020 0.508±0.021 0.682±0.022 0.545±0.127 0.767±0.043 0.756±0.011 0.764±0.003 0.705±0.011 0.700±0.070 0.750±0.037 0.696±0.047 0.748±0.066 0.802±0.005 0.830±0.005\nFloat\n0.502±0.020 0.551±0.030 0.711±0.041 0.530±0.075 0.670±0.065 0.702±0.005 0.739±0.007 0.615±0.052 0.736±0.041 0.718±0.064 0.671±0.032 0.744±0.073 0.765±0.002 0.816±0.012\nMeteorite\n0.467±0.049 0.462±0.077 0.669±0.037 0.476±0.014 0.637±0.015 0.616±0.013 0.704±0.004 0.554±0.021 0.568±0.053 0.647±0.030 0.473±0.047 0.716±0.004 0.691±0.001 0.785±0.017\nScuff\n0.472±0.031 0.508±0.070 0.679±0.048 0.492±0.037 0.549±0.027 0.581±0.020 0.714±0.002 0.528±0.034 0.575±0.042 0.676±0.019 0.504±0.052 0.636±0.086 0.656±0.009 0.777±0.003\nVeins\n0.527±0.023 0.493±0.052 0.688±0.069 0.489±0.028 0.699±0.045 0.687±0.017 0.789±0.003 0.589±0.072 0.608±0.044 0.686±0.053 0.510±0.090 0.620±0.036 0.650±0.003 0.766±0.008\nMean\n0.511±0.013 0.524±0.013 0.689±0.037 0.541±0.007 0.667±0.012 0.673±0.010 0.733±0.004 0.588±0.011 0.616±0.021 0.697±0.014 0.588±0.016 0.695±0.004 0.721±0.003 0.778±0.007\nHyper-Kvasir\nBarretts\n0.672±0.014 0.703±0.040 0.382±0.117 0.438±0.111 0.772±0.019 0.792±0.007 0.793±0.000 0.834±0.012 0.764±0.066 0.698±0.037 0.540±0.014 0.824±0.006 0.829±0.002 0.832±0.004\nBarretts-short-seg 0.604±0.048 0.538±0.033 0.367±0.050 0.532±0.075 0.674±0.018 0.651±0.006 0.658±0.003 0.799±0.036 0.810±0.034 0.661±0.034 0.480±0.107 0.835±0.021 0.895±0.003 0.906±0.002\nEsophagitis-a\n0.569±0.051 0.536±0.040 0.518±0.063 0.491±0.084 0.778±0.020 0.760±0.006 0.758±0.001 0.844±0.014 0.815±0.022 0.820±0.034 0.646±0.036 0.881±0.035 0.878±0.021 0.878±0.003\nEsophagitis-b-d\n0.536±0.033 0.505±0.039 0.358±0.039 0.457±0.086 0.577±0.025 0.622±0.014 0.652±0.002 0.810±0.015 0.754±0.073 0.611±0.017 0.621±0.042 0.837±0.009 0.815±0.010 0.841±0.002\nMean\n0.595±0.023 0.571±0.004 0.406±0.018 0.480±0.044 0.700±0.009 0.706±0.007 0.715±0.004 0.822±0.019 0.786±0.021 0.698±0.021 0.571±0.014 0.844±0.009 0.854±0.004 0.864±0.002\n9. Detailed Class-level AUC Results under\nHard Setting\nTo evaluate the performance of the DPDL framework in\ndetecting emerging anomaly classes, we conducted exper-\niments under challenging settings and provided detailed\nresults on six multi-subset datasets, including per-class\nanomaly performance, as shown in Tab. 6.\nOverall, the\nDPDL model achieved the highest AUC scores across both\nM = 1 and M = 10 settings.\n\n\n10. The Algorithm of DPDL\nAlgorithm 1 Distribution Prototype Diffusion Learning\n1: Input: Input X = {(xi, yi)}, C, ϵ, κ\n2: for epoch = 1 to n do\n3:\nExtract features F\nfeature\n←−X\n4:\nDistribution of normal samples transform PMGP\nbridge\n←−\nP(F)\n5:\nDistribution Prototype Learning LDPL = Ln\nDPL +\nLa\nDPL\n6:\nDispersion Feature Learning LDFL\n7:\nSample xi ∼X, ec∗∼PMGP\n8:\nCalculate scores Sa ←Ma, Sn ←Mn, Sr ←Mr\n9: end for\n10: Output : Anomaly score S ←Sr + Sa −Sn\n\n\n11. Derivation of Eqns. (13) and (14)\nWe use Eqns. (8) and (12) to derive Eqn. (13) as follows:\nπ(ψ(xn\ni )|xn\ni ) =\n1\nϖ(xn\ni ) exp(⟨xn\ni , ψ(xn\ni )⟩\nϵ\n)\nC\nX\nc=1\nαcN(ψ(xn\ni ); µc, σc)\n=\n1\nϖ(xn\ni )\nC\nX\nc=1\nαc(2π)−D/2|σc|−1/2 exp(⟨xn\ni , ψ(xn\ni )⟩\nϵ\n) exp(−1\n2(ψ(xn\ni )))⊤σ−1\nc (ψ(xn\ni ) −µc))\n=\n1\nϖ(xn\ni )\nC\nX\nc=1\nαc(2π)−D/2|σc|−1/2 exp( 1\n2ϵ(2xn\ni\n⊤ψ(xn\ni ) −ψ(xn\ni )⊤ϵσ−1\nc ψ(xn\ni )⊤+ 2µ⊤\nc ϵσ−1\nc ψ(xn\ni ) −µ⊤\nc ϵσ−1\nc µc))\n=\n1\nϖ(xn\ni )\nC\nX\nc=1\nαc(2π)−D/2|σc|−1/2 exp( 1\n2ϵ(−ψ(xn\ni )⊤ϵσ−1\nc ψ(xn\ni )⊤+ 2 (1\nϵ σcxn\ni + µc)⊤\n|\n{z\n}\neµc(xn\ni)\nϵσ−1\nc ψ(xn\ni ) −µ⊤\nc ϵσ−1\nc µc))\n=\n1\nϖ(xn\ni )\nC\nX\nc=1\nαc(2π)−D/2|σc|−1/2 exp(−1\n2ϵ(ψ(xn\ni ) −eµc(xn\ni )⊤ϵσ−1\nc (ψ(xn\ni ) −eµc(xn\ni ))))\nexp( 1\n2ϵ(−µ⊤\nc ϵσ−1\nc µc + eµ⊤\nc (xn\ni )ϵσ−1\nc\neµ⊤\nc (xn\ni ))\n=\n1\nϖ(xn\ni )\nC\nX\nc=1\nαc exp(µ⊤\nc ϵσ−1\nc µc + (eµ⊤\nc ϵ−1σc + eµc)⊤(xn\ni )ϵσ−1\nc (eµ⊤\nc ϵ−1σc + eµc)(xn\ni )\n2ϵ\n)N(ψ(xn\ni ); eµc(xn\ni ), σc)\n=\n1\nϖ(xn\ni )\nC\nX\nc=1\nαc exp( 1\n2ϵ2 (xn\ni )⊤σcxn\ni + 1\nϵ (eµc)⊤(xn\ni ))\n|\n{z\n}\neαc(xn\ni)\nN(ψ(xn\ni ); eµc(xn\ni ), σc)\n= eη(xn\ni )\nC\nX\nc=1\neαc(xn\ni )N(ψ(xn\ni ); eµc(xn\ni ), σc)\nwhere eη(xn\ni ) =\n1\nϖ(xn\ni) =\n1\nPC\nc=1 eαc(xn\ni).\n\n\nAccording to Eqn. (4), we derive Eqn. (14) as follows:\ng(xn\ni , t) = ϵ▽xn\nilog\nZ\nRD N(ψ(xn\ni )|xn\ni , (1 −t)ϵI) exp(∥ψ(xn\ni )∥2\n2ϵ\n)ϕ1(ψ(xn\ni ))dψ(xn\ni )\n= ϵ▽xn\nilog\nZ\nRD N(ψ(xn\ni )|xn\ni , (1 −t)ϵI) exp(∥ψ(xn\ni )∥2\n2ϵ\n)\nC\nX\nc=1\nαcN(ψ(xn\ni ); eµc, σc)dψ(xn\ni )\n= ϵ▽xn\nilog((2π)−D\n2 |(1 −t)ϵI|−1\n2\nC\nX\nc=1\n{αc|σc|−1\n2\nZ\nRD exp(−(ψ(xn\ni ) −xn\ni )⊤(ψ(xn\ni ) −xn\ni )\n2ϵ(1 −t)\n−(ψ(xn\ni ) −eµc)ϵσ−1\nc (ψ(xn\ni ) −eµc)\n2ϵ\n+ ψ(xn\ni )⊤ψ(xn\ni )\n2ϵ\n)})\n= ϵ▽xn\nilog(exp(−xn\ni\n⊤xn\ni\n2ϵ(1 −t))\nC\nX\nc=1\n{αc|σc|−1\n2 exp(−eµ⊤\nc ϵσ−1 eµc\n2ϵ\n)})\nZ\nRD exp(−1\n2[ψ(xn\ni )⊤(\nt\nϵ(1 −t)I + σ−1\nc )\n|\n{z\n}\nΣtc\nψ(xn\ni )] + [\n1\nϵ(1 −t)xn\ni + σ−1\nc\neµc]⊤\n|\n{z\n}\nhc(xn\ni,t)\nψ(xn\ni )dψ(xn\ni ))\n= ϵ▽xn\nilog((2π)−D\n2 exp(−xn\ni\n⊤xn\ni\n2ϵ(1 −t))\nC\nX\nc=1\n{αc(2π)−D\n2 |σc|−1\n2 exp(−eµ⊤\nc ϵσ−1\nc\neµc\n2ϵ\n)\n|\n{z\n}\nN(xn\ni|0,ϵ(1−t))I\nC\nX\nc=1\n(αcN(eµc(xn\ni )|0, σc)N(hc(xn\ni , t)|0, Σt\nc))\n|\n{z\n}\nρMGP(xn\ni)\n})\n= ϵρMGP(xn\ni )∇xn\ni log(N(xn\ni |0, ϵ(1 −t))I)\n\n\n",
  "metadata": {
    "source_file": "dataset/pdfs/arxiv_2502.20981v1.pdf",
    "total_pages": 15,
    "title": "Distribution Prototype Diffusion Learning for Open-set Supervised Anomaly Detection",
    "authors": [
      "Fuyun Wang",
      "Tong Zhang",
      "Yuanzhi Wang",
      "Yide Qiu",
      "Xin Liu",
      "Xu Guo",
      "Zhen Cui"
    ],
    "abstract": "In Open-set Supervised Anomaly Detection (OSAD), the existing methods\ntypically generate pseudo anomalies to compensate for the scarcity of observed\nanomaly samples, while overlooking critical priors of normal samples, leading\nto less effective discriminative boundaries. To address this issue, we propose\na Distribution Prototype Diffusion Learning (DPDL) method aimed at enclosing\nnormal samples within a compact and discriminative distribution space.\nSpecifically, we construct multiple learnable Gaussian prototypes to create a\nlatent representation space for abundant and diverse normal samples and learn a\nSchr\\\"odinger bridge to facilitate a diffusive transition toward these\nprototypes for normal samples while steering anomaly samples away. Moreover, to\nenhance inter-sample separation, we design a dispersion feature learning way in\nhyperspherical space, which benefits the identification of out-of-distribution\nanomalies. Experimental results demonstrate the effectiveness and superiority\nof our proposed DPDL, achieving state-of-the-art performance on 9 public\ndatasets.",
    "published_date": "2025-02-28",
    "source": "arxiv"
  }
}