{
  "id": "arxiv_2502.21198v1",
  "text": "Prepared for submission to JINST\nAI-Enhanced Self-Triggering for Extensive Air Showers:\nPerformance and FPGA Feasibility\nQader Dorosti\nCenter for Particle Physics Siegen,\nDepartment f√ºr Physik, Universit√§t Siegen,\nWalter-Flex-Str. 3, 57072 Siegen, Germany\nE-mail: dorosti@hep.physik.uni-siegen.de\nAbstract: Cosmic-ray detection with radio antennas has traditionally depended on external trig-\ngers from particle detectors, constraining sensitivity and increasing complexity. Previous attempts\nat fully standalone, radio-only triggers have often failed under intense radio frequency interference,\nmaking genuine air-shower signals difficult to isolate. We present a proof-of-principle artificial\nintelligence-based self-triggering system that overcomes these limitations.\nBy training a deep\nlearning model on both real noise data and injected cosmic-ray-like pulses, we achieve an excep-\ntionally low false-positive rate alongside high detection efficiency. Configurable operating points\ncan suppress false positives below 0.01% while retaining more than 88% of genuine signals, and\ncan even eliminate false positives entirely at a modest reduction in signal efficiency. This flexi-\nbility makes single-station cosmic-ray detection feasible without requiring external trigger inputs.\nApplying our approach to real-world noise conditions reduces the initial false-positive event rate\nby several orders of magnitude, supporting large-scale deployments. Extrapolation to dedicated\nhardware implementations, such as FPGAs, indicates that sub-¬µs inference times are achievable,\nenabling real-time autonomous triggering. These results highlight the transformative potential of\nartificial intelligence for enhancing radio detection sensitivity and inaugurate a new generation of\nfully self-triggered cosmic-ray observatories.\nKeywords: Performance of High Energy Physics Detectors, Large detector systems for particle\nand astroparticle physics, Detector modelling and simulations II, Digital signal processing, Trigger\nconcepts and systems, Pattern recognition\narXiv:2502.21198v1  [astro-ph.IM]  28 Feb 2025\n\n\nContents\n1\nIntroduction\n1\n2\nExperimental Setup\n3\n2.1\nTraining and Validation Datasets\n5\n3\nMethodology\n6\n3.1\nModel Architecture\n6\n3.1.1\nCNN-Based Denoiser\n6\n3.1.2\nFully Convolutional Classifier (FCN)\n7\n3.2\nTraining and Optimization\n7\n4\nModel Performance Analysis\n8\n4.1\nPerformance Metrics and Trigger Rates\n8\n4.1.1\nTrigger Efficiency in Controlled Conditions (Validation Dataset 1)\n9\n4.1.2\nRobustness to Weaker Pulses (Validation Dataset 2)\n9\n4.1.3\nFalse Trigger Rate Estimation in a High-Noise Environment (Validation\nDataset 3)\n10\n4.1.4\nExample of a Low-Amplitude Signal Classification\n10\n5\nEstimated Latency on FPGA Platforms\n11\n6\nConclusion\n12\n7\nDiscussion\n13\n1\nIntroduction\nUltra-high-energy cosmic rays (UHECRs) are primarily detected using large-scale ground-based\nobservatories that employ a combination of particle detectors, fluorescence telescopes, and radio\nantennas [1]. Each technique provides complementary insights into extensive air showers (EAS),\nenabling detailed studies of cosmic-ray composition, energy spectrum, and arrival direction. Among\nthese methods, radio detection has gained increasing attention due to its cost-effectiveness, full-\nsky coverage, and near-continuous operation [2].\nBy measuring the radio emission generated\nprimarily by geomagnetic deflection [3] and the charge-excess effect [4] in the EAS, radio arrays\ncan reconstruct key shower parameters, such as the atmospheric depth of the shower maximum\n(ùëãmax) and primary energy, with high precision [5, 6].\nA distinct advantage of radio detection is its sensitivity to inclined air showers, where traditional\nparticle detector arrays struggle due to the attenuation of the electromagnetic shower component\nin the atmosphere [6]. However, despite these benefits, current radio detection techniques rely on\n‚Äì 1 ‚Äì\n\n\nexternal triggers from other detector systems, such as surface or fluorescence detectors, limiting\ntheir autonomy and increasing operational complexity.\nThe development of an effective self-\ntriggering system is therefore crucial to fully exploit the potential of radio detection for cosmic-ray\nobservations [7].\nPrevious attempts to implement self-triggering in radio arrays, such as those by CODALEMA\nand AERA, relied on conventional techniques like narrowband radio frequency interference (RFI)\nsuppression and threshold-based triggering [8, 9]. However, these methods proved ineffective in\ndistinguishing cosmic-ray-induced radio pulses from transient noise sources, leading to a high\nrate of false positives. As a result, these efforts faced significant challenges and did not produce\nestablished scientific results, underscoring the need for more advanced signal-processing strategies.\nRecent developments in modelling EAS radio emissions, combined with experimental and\nsimulation studies, have provided a deeper understanding of characteristic pulse shapes and ground\nradiation patterns [2]. This progress has paved the way for more sophisticated signal-processing\ntechniques, including artificial intelligence (AI)-driven approaches for enhancing radio-based self-\ntriggering. Recent studies show that deep learning models, including convolutional neural networks\n(CNNs) and recurrent neural networks (RNNs), can effectively distinguish cosmic-ray signals\nfrom background noise, significantly reducing detection thresholds. These techniques have been\nsuccessfully applied to identify air-shower radio pulses in offline analyses [10], demonstrating\ntheir potential to enhance signal selection. Recent efforts, such as those in the GRAND experiment,\ncontinue to investigate self-triggering using AI-based methods, including CNNs. While preliminary\nresults indicate that these methods can reject at least 40% of background noise at a 90% signal\nselection efficiency [11], achieving real-time deployment remains challenging.\nSelf-triggering\nrequires ultra-low latency processing to ensure the identification of cosmic-ray signals within\nmicroseconds of their arrival, while also maintaining a false-positive trigger rate at the sub-Hz\nlevel, a constraint that traditional software-based neural networks struggle to meet.\nTo address the challenge of self-triggering in cosmic-ray radio signal detection, AI-accelerated\nsignal processing implemented on Field-Programmable Gate Arrays (FPGAs) offers a viable solu-\ntion. FPGAs provide exceptional parallel processing capabilities and low-latency inference, making\nthem ideal for real-time feature extraction and classification of radio pulses. Similar approaches\nhave been explored in high-energy physics experiments, such as the ATLAS Tile Calorimeter, where\ndeep learning algorithms implemented on FPGAs have demonstrated significant improvements in\nreal-time signal reconstruction under high pileup conditions [12, 13]. These advancements highlight\nthe potential of FPGA-based AI techniques in handling complex, high-rate signal environments,\nwhich are also crucial for enhancing the efficiency and accuracy of cosmic-ray self-triggering.\nIn this work, we investigate the feasibility of FPGA-based AI self-triggering for radio cosmic-\nray detection. We begin by training and evaluating our deep neural network on Metal Performance\nShaders (MPS) with data that includes experimentally measured background noise, then estimate\ntheir potential performance on FPGAs. While high-level synthesis (HLS) frameworks such as\nHLS4ML [14] and Xilinx Vitis AI [15] offer streamlined approaches to deploying AI models on\nFPGAs, we consider their integration a logical extension of this proof-of-concept study rather than\npart of our immediate scope.\nOur method comprises a fully convolutional autoencoder that denoises radio traces by sup-\npressing background noise while retaining cosmic-ray pulses, followed by a fully convolutional\n‚Äì 2 ‚Äì\n\n\nclassifier (FCN) that differentiates cosmic-ray signals from noise. By leveraging real data with\nmeasured background noise, we enhance the robustness of our approach in practical deployments.\nWe also address critical issues associated with FPGA-based AI, including quantization strategies,\nresource utilization, and latency reduction, and propose a framework for real-time classification\nof cosmic-ray radio pulses. This proof-of-principle demonstration paves the way for future work\nincorporating more advanced HLS techniques to further optimize deployment on FPGA hardware.\nThe implementation of AI-accelerated FPGA-based self-triggering represents a significant ad-\nvancement in radio detection technology. By reducing reliance on external detector triggers and\nincreasing detection efficiency, this approach enables greater autonomy for radio observatories,\nfacilitating the detection of rare and high-energy events, including ultra-high-energy neutrinos. Our\nresults demonstrate the feasibility of deploying AI-driven self-triggering at the detector level, mark-\ning an important step toward fully autonomous, real-time radio detection systems for astroparticle\nphysics.\n2\nExperimental Setup\nThe dataset used in this study consists of experimentally recorded noise traces collected in the\nphysics campus of the University of Siegen. The measurements were performed using a butterfly\nantenna connected to a low-noise amplifier with 30 dB gain, which was further linked to a digital\noscilloscope. These recordings capture real-world transient noise sources, including atmospheric\nand anthropogenic contributions.\nTo focus on the frequency range relevant for air shower radio detection, the recorded signals\nwere digitally bandpass-filtered between 30 and 80 MHz.\nFurthermore, data was sampled at\n250 MHz to ensure comparability with real-world cosmic-ray radio detectors, such as AERA and\nAuger RD, which operate at 180 MHz and 250 MHz, respectively. This adjustment reflects the\npractical constraints of large-scale detectors, where lower sampling rates are used due to budget and\nhardware limitations, ensuring the applicability of the method to future radio arrays.\nThe dataset used in this study was collected in an urban environment, where background noise\nlevels are higher and more variable compared to remote cosmic-ray observatories. To capture a\ndiverse range of real-world noise conditions, data was collected over approximately two hours,\nyielding 200 million samples. Data was continuously streamed, with traces read out at a rate of\none per second. Given the high variability of the urban noise environment, the dataset presents\na challenging test case for AI-driven signal detection methods. This setting introduces additional\nchallenges, including increased transient interference and strong radio frequency interference (RFI).\nTwo prominent narrowband RFI sources were identified at approximately 45 MHz and 71 MHz,\nalong with other narrowband and transient RFI. The power spectrum of the recorded traces, shown\nin Figure 1, was obtained after applying a digital bandpass filter in the range of 30 to 80 MHz. For\nthe initial analysis, these narrowband RFIs were not suppressed to assess the model‚Äôs robustness\nin the presence of strong interference. The results presented in the following section reflect model\nperformance when both training and testing were conducted on data sets containing these RFIs.\nAdditionally, we examine how performance changes when these narrowband RFIs are mitigated\nprior to training and validation, providing insights into the impact of RFI suppression on the learning\nprocess, which we will report in the discussion section 7.\n‚Äì 3 ‚Äì\n\n\n0.0\n0.2\n0.4\n0.6\n0.8\n1.0\n1.2\nFrequency (Hz)\n1e8\n100\n80\n60\n40\n20\n0\n20\nPower (dB)\nFigure 1. Power spectrum of the recorded signal after applying a bandpass filter in the range of 30‚Äì80 MHz.\nTwo prominent narrowband RFI sources are observed at approximately 45 MHz and 71 MHz.\nTo evaluate the AI model‚Äôs performance, signal-like pulses were injected into measured noise\ntraces at random positions, covering a broad range of amplitudes. The pulse power was scaled\nrelative to the noise power, which was calculated using a pre-filtered version of each trace. This\nensured that the injected pulses maintained a well-controlled signal-to-noise ratio (SNR) within\na user-defined range while accurately reflecting real-world noise conditions. However, to prevent\ndouble filtering of the noise, which could distort its characteristics, the pulses were injected into\nthe original (unfiltered) traces. This step also eliminated systematic biases by ensuring that the\nstatistical properties of the background noise remained unaffected by the injection process. To\nmaintain consistency in data processing, the digital bandpass filter was applied only after pulse\ninjection, ensuring that both noise-only and signal-injected datasets underwent identical filtering\nand conditioning. This approach was chosen over COREAS simulations [16] to establish a proof\nof principle based purely on signal strength, avoiding dependencies on the absolute energy scale,\nantenna gain pattern, and shower inclination, which introduce additional uncertainties. By injecting\nshort pulses into measured noise traces from a real-world, high-interference environment, we\nenable a focused evaluation of the AI model‚Äôs ability to detect transient signal shapes under\nconditions where traditional threshold-based triggering systems struggle or fail entirely due to\noverwhelming radio frequency interference (RFI). This approach enables a systematic assessment\nof the model sensitivity in varying SNRs while ensuring robustness under challenging conditions.\nBy directly testing and refining AI-based techniques on measured noise traces‚Äîwithout relying on\nan external event-reconstruction framework or requiring a particle detector‚Äîit provides a controlled\nand scalable test case. Although it does not fully replicate all details of cosmic-ray pulse shapes,\nmuch of which may already be washed out by bandpass filtering, it offers a robust estimate of the\nfalse positive rate of AI-based triggering methods in a realistic noise environment.\n‚Äì 4 ‚Äì\n\n\n2.1\nTraining and Validation Datasets\nTo train and evaluate the model, multiple datasets were used, each designed to fulfil a specific\nrole in ensuring robust performance. The datasets were categorized into training, cross-validation,\nand independent validation sets to assess the model‚Äôs generalization and sensitivity. All noise\ntraces are unique and are derived from experimental measurements, randomly selected from the\nfull duration of the noise measurement campaign, whereas the signal-containing traces consist of\ninjected pulses, as previously described. For the initial analysis, only a bandpass filter was applied,\nwith no additional filtering. However, we later incorporate further filtering to suppress prominent\nRFI sources in the 30‚Äì80 MHz range for comparison, the results of which are discussed in section 7.\n‚Ä¢ Training and Cross-Validation Datasets: The dataset used for training and model tuning\nwas randomly split into two equal parts:\n‚Äì Training Dataset (50%): Comprised 15,000 time series traces, each containing 128\nsamples recorded at a sampling rate of 250 MHz, consistent with standard practices in\nradio-based air shower detection. It included an equal distribution of 5,000 pure noise\ntraces (background), 5,000 traces of isolated EAS-like pulses (pure signal), and\n5,000 traces with EAS-like pulses injected into noise (signal). This setup ensured\nthat the model effectively learned to distinguish genuine signals from background noise.\n‚Äì Cross-Validation Dataset (50%): Consisted of another 15,000 traces, also evenly\ndivided into 5,000 background traces, 5,000 pure signal traces, and 5,000 signal\ntraces. This dataset was used to fine-tune the model and monitor its generalization\nperformance during training.\nThese datasets were randomly derived from a larger pool of available traces, ensuring an\nunbiased and representative sample distribution.\n‚Ä¢ Independent Validation Datasets: Three independent validation datasets were used to\nassess the robustness of the model under different conditions.\n‚Äì Validation Dataset 1: Contained 20,000 traces, equally split into 10,000 background\nand 10,000 signal traces. This dataset was applied to evaluate the performance of the\nmodel on unseen data with an SNR distribution similar to the training set.\n‚Äì Validation Dataset 2: Consisted of 20,000 traces, equally divided into 10,000 back-\nground traces and 10,000 signal traces with extremely low-amplitude pulses. This\ndataset was specifically designed to test the sensitivity of the model in low-SNR sce-\nnarios.\n‚Äì Validation Dataset 3: Comprised 1 million pure noise traces to assist in evaluating\nthe false positive triggering rate. This dataset provides a large statistical sample to\nquantify how frequently the model incorrectly classifies noise as a signal event.\nThese independent validation data sets were crucial to assessing the model‚Äôs ability to generalize\nto previously unseen data and to reliably detect signals under varying noise conditions, particularly\nat low SNR.\n‚Äì 5 ‚Äì\n\n\nFigure 2 illustrates the SNR distributions for background and signal traces across Validation\nDataset 1, which closely follows the distribution of the training dataset, and Validation Dataset 2,\nwhich consists of low-amplitude signals. This comparison provides insights into the differences in\nsignal detectability across varying SNR conditions.\n0.5\n1.0\n1.5\n2.0\n2.5\n3.0\n3.5\nlog10 (SNR)\n100\n101\n102\n103\nCounts\nSignal\nBackground\n0.5\n1.0\n1.5\n2.0\n2.5\nlog10 (SNR)\n100\n101\n102\n103\nCounts\nSignal\nBackground\nFigure 2. SNR distributions for background and signal traces in Validation Dataset 1 (left) and Validation\nDataset 2 (right). Validation Dataset 1 follows the distribution of the training dataset, while Validation\nDataset 2 contains low-amplitude signals.\n3\nMethodology\nWe implemented a deep learning-based pipeline for denoising and classifying radio time series\nin the context of self-triggering for EAS events. The pipeline consists of two primary components:\n1. A CNN-based denoiser to suppress noise in the input signals.\n2. A fully convolutional classifier (FCN) to distinguish between signal and background in a\nbinary classification task.\nThese models operate sequentially, where the denoiser first refines raw data before passing it to the\nclassifier for event discrimination.\n3.1\nModel Architecture\n3.1.1\nCNN-Based Denoiser\nThe denoiser is a fully convolutional autoencoder designed to suppress noise and enhance cosmic\nray pulses in noisy radio time series.. It follows an encoder-bottleneck-decoder structure with a\nskip connection to retain fine-grained features.\n‚Ä¢ Encoder: Two convolutional layers extract multi-scale features, followed by a single max\npooling layer that reduces resolution by a factor of two.\n‚Ä¢ Bottleneck: A deeper convolutional block refines feature representations at the reduced\nresolution.\n‚Äì 6 ‚Äì\n\n\n‚Ä¢ Decoder: An upsampling layer restores the original resolution, followed by convolutional\nlayers that refine the denoised signal. A skip connection concatenates high-resolution features\nfrom the encoder to enhance detail recovery.\nThe denoiser learns from a dataset where the inputs are noisy traces containing EAS-like\npulses (signal), and the targets are the corresponding pure EAS-like pulses (pure signal).\nThe training process minimises the Mean Squared Error (MSE) loss between the clean target\nùë•ùëñand the denoised prediction ÀÜùë•ùëñ:\nLdenoiser = 1\nùëÅ\nùëÅ\n‚àëÔ∏Å\nùëñ=1\n(ùë•ùëñ‚àíÀÜùë•ùëñ)2 .\n(3.1)\nThis architecture ensures that the model preserves cosmic ray features while effectively filtering\nout background noise.\n3.1.2\nFully Convolutional Classifier (FCN)\nThe FCN classifier classifies time series into background or signal, where signal refers to a noisy\ntrace containing an EAS pulse. It includes:\n‚Ä¢ Three convolutional blocks with batch normalization, dropout, and max pooling.\n‚Ä¢ Global average pooling (GAP) to reduce spatial dimensions while retaining features.\n‚Ä¢ A fully connected layer with a sigmoid activation function for binary classification.\nThe classifier is trained using the Binary Cross-Entropy (BCE) loss:\nLclassifier = ‚àí1\nùëÅ\nùëÅ\n‚àëÔ∏Å\nùëñ=1\n[ùë¶ùëñlog ÀÜùë¶ùëñ+ (1 ‚àíùë¶ùëñ) log(1 ‚àíÀÜùë¶ùëñ)]\n(3.2)\nwhere ùë¶ùëñis the true label and ÀÜùë¶ùëñis the predicted probability.\n3.2\nTraining and Optimization\nBoth models were trained using the Adam optimizer, with task-specific loss functions, following\na two-step training approach:\n1. Denoiser Training:\n‚Ä¢ Trained on traces with pulses injected into noise (signal) and pure signal.\n‚Ä¢ Optimised to minimize Mean Squared Error (MSE) loss, enhancing signal quality\nwhile suppressing noise.\n2. Classifier Training:\n‚Ä¢ Trained on denoised signal traces (output of the denoiser) alongside denoised back-\nground traces.\n‚Äì 7 ‚Äì\n\n\n‚Ä¢ Optimized to minimize Binary Cross-Entropy (BCE) loss, ensuring accurate discrim-\nination between signal-containing and noise-only traces.\nThe model was trained for 15 epochs with a batch size of 64 and a learning rate of 0.001, using\nthe Training Dataset. Its generalization performance was monitored with the Cross-Validation\nDataset described in Section 2.1. The model was implemented using PyTorch with support for\nMPS acceleration. Training was conducted using the Adam optimizer, and model performance\nwas evaluated on the cross-validation dataset using classification accuracy, precision, recall, and\nF1-score.\n4\nModel Performance Analysis\nThe first two plots in Figure 3 (top row) illustrate the probability distributions of sigmoid prediction\nfor validation datasets 1 and 2, which differ in their SNR distributions. In Validation Dataset 1,\nwhere the SNR distribution closely resembles that of the training set (see Section 2.1), the model\nexhibits a strong separation between background and signal traces. Most noise traces receive lower\nprobabilities, while signal-containing traces are predominantly assigned higher values. In contrast,\nValidation Dataset 2 contains traces with significantly lower SNRs, commonly below the noise\nfloor. While the model still distinguishes between the two classes, the classification performance\ndegrades: the distribution of signal-containing traces is more spread out, with a noticeable tail\nextending toward lower probabilities. This shift indicates a reduction in signal efficiency, as weaker\nsignals are increasingly misclassified due to their low SNR.\nBeyond assessing performance across different SNRs, it is also essential to evaluate the model‚Äôs\nbehaviour in environments dominated by overwhelming background noise, where false positives\nbecome a critical concern. To investigate this, we introduce Validation Dataset 3, which consists\nof one million background traces. The bottom row of Figure 3 explores the model‚Äôs response\nto this dataset by comparing background traces from Validation Dataset 3 with signal traces\nfrom Validation Dataset 1. The sigmoid probability distribution (bottom left) shows that while\nmost noise traces receive low probabilities, the large dataset size results in a fraction extending\ninto the signal region. This highlights the need to quantify the false trigger rate under realistic\nhigh-background conditions. The final plot (bottom right) presents the distributions of the model‚Äôs\nlogits, i.e. the raw scores before applying a probability function. These distributions reveal a\nclear separation between background traces from Validation Dataset 3 and signal traces from\nValidation Dataset 1. Using logits instead of sigmoid probabilities significantly improves false\npositive rejection, albeit at the cost of true positive efficiency. This trade-off is particularly relevant\nwhen designing self-triggering strategies in noisy environments.\n4.1\nPerformance Metrics and Trigger Rates\nFollowing the qualitative assessment in Figure 3, we systematically evaluate the model‚Äôs perfor-\nmance across different validation datasets. This analysis focuses on three key aspects: trigger\nefficiency, robustness to low-SNR signals, and false trigger rate in high-background condi-\ntions. The results are presented as follows.\n‚Äì 8 ‚Äì\n\n\n0.0\n0.2\n0.4\n0.6\n0.8\n1.0\nPredicted Probability\n100\n101\n102\n103\n104\nCounts\nSignal\nBackground\n0.0\n0.2\n0.4\n0.6\n0.8\n1.0\nPredicted Probability\n100\n101\n102\n103\n104\nCounts\nSignal\nBackground\n0.0\n0.2\n0.4\n0.6\n0.8\n1.0\nPredicted Probability\n100\n101\n102\n103\n104\n105\n106\nCounts\nSignal\nBackground\n10\n0\n10\n20\n30\n40\nLogits\n101\n102\n103\n104\n105\nCounts\nDistribution of Model Logits (Signal vs Noise)\nSignal\nBackground\nFigure 3. Probability distributions of sigmoid predictions for validation datasets with varying SNRs (top\nrow) and in a high-background environment (bottom row). Validation Dataset 1 has an SNR distribution\nsimilar to the training set, while Validation Dataset 2 contains lower-SNR traces. The bottom row compares\nbackground traces from Validation Dataset 3 with signal traces from Validation Dataset 1, highlighting\nfalse positives under high-background conditions. The logits distribution (bottom right) shows improved\nbackground rejection compared to sigmoid probabilities, though at the cost of efficiency.\n4.1.1\nTrigger Efficiency in Controlled Conditions (Validation Dataset 1)\n‚Ä¢ True Positives: 99.93%\n‚Ä¢ False Positives: 0.07%\nA simple probability threshold is sufficient for efficient signal selection in this case.\n4.1.2\nRobustness to Weaker Pulses (Validation Dataset 2)\n‚Ä¢ True Positives: 87.96%\n‚Ä¢ False Positives: 0.08%\nDespite the increased challenge, the model effectively distinguishes signal-containing traces,\ndemonstrating its robustness to weaker pulses. The reduction in efficiency is expected as most of\nthese signals fall outside the training range. Although further tuning could enhance performance,\n‚Äì 9 ‚Äì\n\n\nthe primary objective here is to assess the model‚Äôs ability to generalise rather than optimise for\nspecific low-SNR cases.\n4.1.3\nFalse Trigger Rate Estimation in a High-Noise Environment (Validation Dataset 3)\nTo assess the model‚Äôs performance in the presence of overwhelming background noise, we evaluated\nit on Validation Dataset 3. This dataset simulates realistic high-RFI conditions, such as those found\nin urban environments (e.g., LOFAR, LOPES) or certain AERA stations [7].\nThe primary objective of this evaluation is to quantify false trigger rates in such environments.\nThe results are as follows:\n‚Ä¢ True Positives (Initial Threshold): 99.93%\n‚Ä¢ False Positives: 768 per 1M events (0.08%), which translates to approximately 800 Hz\nfirst-level trigger (FLT) rate in a 1 MHz trigger scenario.\nApplying confidence-based selection criteria (referred here as entropy cut) significantly reduces\nthe false positive rate while maintaining high true positive efficiency.\n‚Ä¢ Entropy Cut: 99.35% True Positives, 79 False Positives per 1M events (0.008%), corre-\nsponding to approximately 80 Hz false triggers in a 1 MHz trigger scenario.\nThe 80 Hz FLT rate is already suitable for a station-level trigger and provides a strong foun-\ndation for further refinement. A subsequent second-level trigger (SLT) stage, utilizing array-level\ncoincidence searches, could further suppress false positives while preserving efficiency.\nTo explore the feasibility of detecting cosmic-ray events at a single station, we further applied\nlogits-based cuts, which resulted in:\n‚Ä¢ Logit Cut: 72.4% True Positives, 0 False Positives, completely eliminating false triggers in\nthis dataset.\nThis analysis shows that entropy-based selection effectively reduces the trigger rate to an\nacceptable level for an FLT, while still maintaining high detection efficiency. Further refinement\nat the SLT stage, through array-level coincidence searches, could optimise false positive rejection\neven further. On the other hand, applying logits-based cuts enables the possibility of detecting\ncosmic-ray events at a single station, drastically suppressing false positives, with none observed\nin our dataset. While this comes with some reduction in signal efficiency, it remains within a\nreasonable range, making single-station detection feasible in certain scenarios.\n4.1.4\nExample of a Low-Amplitude Signal Classification\nFigure 4 illustrates a representative trace containing a faint signal pulse correctly classified by\nthe model. The pulse is indistinguishable by eye due to transient noise, yet the classifier confidently\nassigns it a high probability. This result highlights the model‚Äôs ability to recover weak air shower\nsignals that would otherwise remain undetectable using traditional threshold-based methods.\n‚Äì 10 ‚Äì\n\n\n0\n20\n40\n60\n80\n100\n120\n0.02\n0.01\n0.00\n0.01\n0.02\nFigure 4. Representative trace with a faint signal pulse correctly classified by the model despite transient\nnoise, demonstrating its ability to recover weak air shower signals undetectable by threshold-based methods.\n5\nEstimated Latency on FPGA Platforms\nTo evaluate the feasibility of real-time deployment, the model‚Äôs inference latency was first measured\non an Apple Silicon GPU using Metal Performance Shaders (MPS). Each inference took approx-\nimately 33 ¬µs per trace, which implies a required buffer of around 8,250 samples when sampling\nat 250 MSPS. Since real-time streaming at this rate is continuous, reducing inference latency is\nessential to minimize buffering and avoid potential pipeline stalls.\nMoving from a GPU to an FPGA requires a different set of assumptions compared to traditional\nCPU-to-FPGA speed-up estimates. In particular, FPGAs allow for specialized parallelism and\nhardware-friendly dataflow optimizations that can significantly reduce latency if designed properly.\nTable 1 summarizes conservative latency estimates for different FPGA classes, along with the\ncorresponding buffer sizes at 250 MSPS. These values were derived by adjusting for GPU-to-FPGA\nacceleration, assuming an optimized hardware design that capitalizes on the inherent parallelism of\nFPGAs.\nHere, the row labeled High-end (INT8-Optimized) represents a design flow that leverages 8-bit\nquantization on a device similar to other high-end FPGAs, rather than indicating a distinct family of\nboards. Narrower data paths in an INT8 pipeline can further reduce latency and resource utilization,\nat the expense of additional quantization efforts.\nEven a low-end FPGA such as a Zynq device could reduce the baseline GPU latency from\n33 ¬µs down to approximately 11.17 ¬µs, significantly lowering the buffering requirement. However,\nwhether this meets ‚Äúreal-time constraints‚Äù depends on the total system requirements, including\nany overhead from I/O, external memory transfers, and other pipeline stages. In large-scale or\n‚Äì 11 ‚Äì\n\n\nTable 1. Estimated inference latency and required buffer sizes for different FPGA platforms (sampling rate:\n250 MSPS).\nFPGA Type / Design Flow\nEstimated Latency (per trace)\nRequired Buffer Size (samples)\nLow-end FPGA (Zynq)\n11.17 ùúás\n2,792 samples\nMid-range FPGA (Arria 10)\n4.78 ùúás\n1,195 samples\nHigh-end FPGA (Alveo U280)\n2.23 ùúás\n558 samples\nHigh-end (INT8-Optimized)\n1.12 ùúás\n280 samples\npower-sensitive deployments, factors such as cost, power consumption, and design complexity also\nguide the choice of FPGA platform and quantization scheme. The final selection must balance these\nconsiderations to ensure both feasibility and efficiency for the target application.\nTo fully enable real-time classification of cosmic-ray radio pulses, a dedicated FPGA-based\nframework must balance latency, resource utilization, and quantization precision while integrating\nseamlessly with experimental data streams. The results in Table 1 demonstrate that even low-end\nFPGA platforms can achieve substantial latency reductions, but practical deployment also requires\noptimizing DSP and memory utilization to handle high-rate data streams efficiently. Implementing\n8-bit quantization (INT8) can further reduce both inference latency and resource consumption,\nalthough additional effort is needed to mitigate potential accuracy loss. A real-time classification\nsystem must also account for I/O bandwidth constraints, buffering mechanisms, and event prioriti-\nzation to avoid pipeline stalls. Future work will focus on refining this framework by incorporating\nreal-time data acquisition, firmware-level optimizations, and adaptive triggering strategies, ensuring\na robust and scalable AI-driven self-triggering system for next-generation cosmic-ray experiments.\nFuture work will extend beyond optimizing the model for FPGA deployment while preserving\nclassification performance. A key focus will be on benchmarking against alternative AI architec-\ntures, refining network optimization techniques, and expanding the training dataset to enhance gen-\neralization. Incorporating extensive air shower (EAS) simulations with state-of-the-art tools such\nas CoREAS will provide a more comprehensive and physically motivated dataset. Additionally,\nintegrating experimental data from particle detector-triggered events will create an unprecedentedly\nrealistic training set. Our preliminary results indicate that training on high-amplitude datasets\nenables the detection of even the faintest radio pulses‚Äîsignals that have remained undetected by\ntraditional methods to date. By leveraging these advancements, we aim to push the boundaries of\nreal-time cosmic ray detection, making AI-driven self-triggering a transformative technology for\nnext-generation astroparticle physics experiments.\n6\nConclusion\nIn this work, we have demonstrated that artificial intelligence can dramatically enhance the\nself-triggering capability of radio detectors for extensive air showers (EAS). By training on\nlarge volumes of measured noise data and injected cosmic-ray-like pulses, our deep learning\npipeline‚Äîincorporating both an autoencoder-based denoiser and a fully convolutional classi-\nfier‚Äîachieves excellent separation of genuine signals from background. Over a wide range of\n‚Äì 12 ‚Äì\n\n\nsignal-to-noise ratios, the approach retains efficiencies in excess of 99% while simultaneously\nsuppressing false positives down to sub-percent levels. Even in an urban-like noise environment,\nwith RFI sources and transient interference, the model maintains robust performance, indicating\nstrong potential for deployment under realistic conditions. Crucially, the flexibility of our inference\nstage enables an operating point where false positives can be entirely eliminated (as observed in our\nlarge-scale noise dataset), albeit at a modest reduction in true-positive rate to roughly 72%. This\nresult opens the door to single-station cosmic-ray detection purely by radio triggers, removing the\nneed to rely on any particle detectors for trigger generation. Although multiple-station coincidences\nremain a valuable method for additional false-positive suppression, these findings show that a single\nantenna unit could be made sufficiently selective to capture genuine air-shower events in high-noise\nenvironments. A key outcome of this study is the successful demonstration of latency estimates\nthat make real-time triggering feasible. Our analysis of FPGA implementations shows that when\nusing optimized designs and dataflow pipelines, inference times can reach the microsecond regime.\nThis aligns well with the strict timing requirements of large-scale radio observatories, where trigger\ndecisions must be made rapidly to record short-lived air shower signals. The ability to process\ndata in-stream, directly on reconfigurable hardware, underscores the practical viability of these AI-\ndriven methods for next-generation detectors. Overall, these results address one of the longstanding\nchallenges in radio-based cosmic ray detection: reducing or eliminating the need for external trig-\ngers from particle or fluorescence detectors. An autonomous trigger operating purely on radio data\nlowers complexity and costs, while also unlocking sensitivity to high zenith angles and potentially\nexotic UHE particle interactions. Moving forward, further integration with simulation tools (e.g.\nCoREAS) and additional real shower data will refine the models‚Äô accuracy and increase robustness\nto a wider spectrum of signal morphologies. The high efficiency and low false trigger rates shown\nhere pave the way for a new class of AI-based, fully self-triggered radio arrays, promising both\nimproved coverage and enhanced scientific reach in ultra-high-energy cosmic ray research.\n7\nDiscussion\nThe results presented in this study highlight several key insights into the performance and robustness\nof our AI-driven self-triggering framework for radio detectors. Beyond achieving high detection\nefficiencies and minimal false-positive rates, a deeper examination of the model‚Äôs behaviour reveals\nits ability to generalise well across different noise conditions, preserve signal fidelity through\ndenoising, and maintain robustness in realistic deployment scenarios.\nA notable finding is the classifier‚Äôs ability to maintain high purity on non-denoised background\ntraces, even though it was never trained on them. Because the classifier was trained exclusively on\ndenoised signal and background data, one might have expected it to misinterpret raw background as\ncontaining signals. However, testing showed that it continued to distinguish signal from background\nwith high accuracy, suggesting it was not misled by potential artifacts introduced by the denoiser\non background samples. This indicates that the combined denoiser‚Äìclassifier pipeline does not\nmerely adapt to denoiser-induced modifications but instead learns robust, physically meaningful\npulse features, demonstrating strong generalization across different noise conditions. Furthermore,\nthese results suggest that mixing raw and denoised data in the training set may be an intriguing\navenue for future exploration, as it could further improve robustness to a wider range of conditions.\n‚Äì 13 ‚Äì\n\n\nWe also investigated the effect of narrow-band RFI suppression. For the datasets discussed in\nthis work, we did not initially remove strong RFI components. However, we produced an alternate\nnoise dataset in which these narrow-band RFI components were suppressed prior to pulse injection.\nBecause suppressing RFI lowers the noise floor by about 17 dB, we scaled down the injected\npulses by a matching factor to preserve the same relative signal-to-noise ratio (SNR) distribution\nthat our model was originally trained on.\nAs expected, the classifier‚Äôs performance remained\nvirtually unchanged, since the effective classification task difficulty was not altered. Nevertheless,\neliminating RFI could simplify the denoiser and classifier in a real-world deployment, as it reduces\nbackground complexity. A simpler network architecture may lead to faster inference times and\nlower computational costs, paving the way for real-time triggering with reduced latency.\nAnother key consideration for real-world applications is the resilience of our pipeline to vari-\nations in noise characteristics. Our tests in an urban-like interference environment suggest that the\ndenoiser‚Äìclassifier chain is learning fundamental signal-versus-noise traits rather than overfitting to\nspecific noise profiles. Further studies could systematically probe this robustness using augmented\ntraining datasets (e.g., artificially injecting varied noise profiles) or by testing on independent,\ngeographically diverse datasets.\nBeyond classification accuracy, latency remains critical for real-time self-triggering applica-\ntions. Preliminary estimates indicate that microsecond inference is feasible on FPGA platforms, but\nhardware-specific optimisations are needed to confirm these figures in practice. Refining the neural\nnetwork architectures to strike an optimal balance between complexity and speed could ensure that\nreal-time decision-making constraints are met without compromising accuracy.\nLooking ahead, our framework could be extended by incorporating CoREAS-simulated pulses\ncovering a wide range of air shower scenarios, including variations in energy, zenith angle, and\nprimary composition. Training on these simulated signals would allow the model to learn a more\ncomprehensive representation of shower-induced radio emission, likely improving its ability to\ndetect real cosmic-ray pulses in challenging regimes. This approach would also provide a clear path\nfor systematically evaluating the pipeline‚Äôs performance under diverse air shower conditions.\nFinally, although our results demonstrate the feasibility of single-antenna triggering, integrat-\ning AI-driven self-triggering with multi-station coincidence algorithms is an exciting possibility.\nCross-station coincidence can lower false-positive rates while preserving sensitivity to rare events,\nincluding highly inclined cosmic rays that might elude traditional triggers.\nIn summary, our findings underscore the transformative potential of deep learning for self-\ntriggered radio detection of extensive air showers. By preserving robust generalisation, demonstrat-\ning strong performance even with various noise conditions, and operating at latencies amenable to\nreal-time applications, AI-based triggering stands poised to play an integral role in next-generation\ncosmic-ray observatories. Future work will focus on refining model architectures, evaluating per-\nformance across different noise environments, integrating large-scale radio arrays, and exploring\nhow single-station AI triggers may combine with multi-station coincidence for enhanced detection\nconfidence.\n‚Äì 14 ‚Äì\n\n\nAcknowledgments\nThe author gratefully acknowledges the support of the Electronics Laboratory (E-Lab) of the\nPhysics Department at Universit√§t Siegen for their assistance in designing and producing the elec-\ntronics used in this research. Their contributions facilitated the development and testing of the\nhardware components, streamlining the experimental setup.\nThis research made use of open-source software, including PyTorch and various scientific\ncomputing libraries in Python, such as NumPy, SciPy, and Matplotlib. The author acknowledges\ntheir developers for providing these valuable tools, which played a crucial role in data processing,\nmodel training, and analysis.\nReferences\n[1] F.G. Schr√∂der, Radio detection of cosmic-ray air showers and high-energy neutrinos, Prog. Part.\nNucl. Phys. 93 (2017) 1.\n[2] T. Huege, Radio detection of cosmic ray air showers in the digital era, Phys. Rep. 620 (2016) 1.\n[3] F. D. Kahn and I. Lerche, Radiation from cosmic ray air showers, Proc. R. Soc. Lond. A 289 (1966)\n206.\n[4] E. Conti and G. Sartori, On the coherent emission of radio frequency radiation from high energy\nparticle showers, Int. J. Mod. Phys. D 26 (2017) 1750083.\n[5] Pierre Auger collaboration, Radio measurements of the depth of air-shower maximum at the pierre\nauger observatory, Phys. Rev. D. 109 (2024) .\n[6] Pierre Auger collaboration, Energy estimation of cosmic rays with the engineering radio array of\nthe pierre auger observatory, Phys. Rev. D. 93 (2016) .\n[7] A. Schmidt, Realization of a self-triggered detector for the radio emission of cosmic rays, Ph.D.\nthesis, Karlsruher Institut f√ºr Technologie (KIT), 2011.\n[8] CODALEMA collaboration, Latest results of the CODALEMA experiment: cosmic rays radio\ndetection in a self trigger mode, J. Phys. Conf. Ser. 409 (2013) 012074.\n[9] J. Kelley, Data acquisition, triggering, and filtering at the auger engineering radio array, Nucl.\nInstrum. Methods Phys. Res. A\" 725 (2013) 133.\n[10] IceCube collaboration, Application of machine learning to identify radio pulses of air showers at the\nsouth pole, Proc. PoS(ARENA2024) (2024) 034.\n[11] GRAND collaboration, Development of an autonomous detection-unit self-trigger for GRAND, Proc.\nPoS(ARENA2024) (2024) 060.\n[12] J.O. Arciniega, F. Carri√≥ and A. Valero, Fpga implementation of a deep learning algorithm for\nreal-time signal reconstruction in particle detectors under high pile-up conditions, JINST 14 (2019)\nArticle No. P09002.\n[13] N. Chiedde and on behalf of the ATLAS liquid argon calorimeter group, Machine learning for\nreal-time processing of atlas liquid argon calorimeter signals with fpgas, JINST 17 (2022) Article\nNo. C04010.\n[14] J. Duarte, S. Han, P. Harris, S. Jindariani, E. Kreinar, B. Kreis et al., Fast inference of deep neural\nnetworks in fpgas for particle physics, JINST 13 (2018) Article No. P07027.\n‚Äì 15 ‚Äì\n\n\n[15] AMD Xilinx, Vitis AI Development Environment, 2025.\n[16] T. Huege, M. Ludwig and C.W. James, Simulating radio emission from air showers with CoREAS,\nProc. PoS(ARENA2012) (2013) .\n‚Äì 16 ‚Äì\n\n\n",
  "metadata": {
    "source_file": "dataset/pdfs/arxiv_2502.21198v1.pdf",
    "total_pages": 17,
    "title": "AI-Enhanced Self-Triggering for Extensive Air Showers: Performance and FPGA Feasibility",
    "authors": [
      "Qader Dorosti"
    ],
    "abstract": "Cosmic-ray detection with radio antennas has traditionally depended on\nexternal triggers from particle detectors, constraining sensitivity and\nincreasing complexity. Previous attempts at fully standalone, radio-only\ntriggers have often failed under intense radio frequency interference, making\ngenuine air-shower signals difficult to isolate. We present a\nproof-of-principle artificial intelligence-based self-triggering system that\novercomes these limitations. By training a deep learning model on both real\nnoise data and injected cosmic-ray-like pulses, we achieve an exceptionally low\nfalse-positive rate alongside high detection efficiency. Configurable operating\npoints can suppress false positives below 0.01\\% while retaining more than 88\\%\nof genuine signals, and can even eliminate false positives entirely at a modest\nreduction in signal efficiency. This flexibility makes single-station\ncosmic-ray detection feasible without requiring external trigger inputs.\nApplying our approach to real-world noise conditions reduces the initial\nfalse-positive event rate by several orders of magnitude, supporting\nlarge-scale deployments. Extrapolation to dedicated hardware implementations,\nsuch as FPGAs, indicates that sub-\\SI{}{\\micro\\second} inference times are\nachievable, enabling real-time autonomous triggering. These results highlight\nthe transformative potential of artificial intelligence for enhancing radio\ndetection sensitivity and inaugurate a new generation of fully self-triggered\ncosmic-ray observatories.",
    "published_date": "2025-02-28",
    "source": "arxiv"
  }
}