{
  "id": "arxiv_2502.21282v1",
  "text": "Large Sample Inference with Dynamic Information Borrowing\nSergey Tarima\nData Science Institute, Medical College of Wisconsin\nSilvia Calderazzo\nDivision of Biostatistics, German Cancer Research Center (DKFZ)\nMary Homan\nInstitute of Health and Equity, Medical College of Wisconsin\nMarch 3, 2025\nAbstract\nLarge sample behavior of dynamic information borrowing (DIB) estimators is investigated. Asymptotic proper-\nties of several DIB approaches (adaptive risk minimization, adaptive LASSO, Bayesian procedures with empirical\npower prior, fully Bayesian procedures, and a Bayes-frequentist compromise) are explored against shrinking to zero\nalternatives. As shown theoretically and with simulations, local asymptotic distributions of DIB estimators are often\nnon-normal. A simple Gaussian setting with external information borrowing illustrates that none of the considered\nDIB methods outperforms others in terms of mean squared error (MSE): at different conflict values, the MSEs of DIBs\nare changing between the MSEs of the maximum likelihood estimators based on the current and pooled data. To\nuniquely determine an optimality criterion for DIB, a prior distribution on the conflict needs be either implicitly or\nexplicitly determined using data independent considerations. Data independent assumptions on the conflict are also\nneeded for DIB-based hypothesis testing. New families of DIB estimators parameterized by a sensitivity-to-conflict\nparameter “s” are suggested and their use is illustrated in an infant mortality example. The choice of “s” is determined\nin a data-independent manner by a cost-benefit compromise associated with the use of external data.\n1\nIntroduction\nBorrowing information from external data (e.g., historical controls) is an attractive approach for overcoming limitations\nof a given (current) dataset. Information borrowing can be achieved by jointly modelling the data generating processes\nof the external and current datasets, which typically relies on existence of shared parameters. The main concern with the\nuse of external information is that the shared parameters may not exist, which is addressed by the dynamic information\nborrowing (DIB) methods.\nPocock and Simon [1975] outlined guidelines for ‘acceptability’ of historical controls for\nuse in the current trial analysis; these guidelines broadly apply to the differences between the current and external\ntrial populations as well as how these trials were conducted. Researchers can use covariate information to reduce the\ndifferences, but typically this only partially addresses the problem. Such differences can negatively impact inference:\nbias and variance in estimation tasks and error rates in hypothesis testing problems. The issue of the negative impact\nrepeatedly appears in statistical literature; see Freidlin and Korn [2013], Jin et al. [2023], Galwey [2017]. In contrast to\nother information borrowing methods, DIB methods borrow external information depending on the observed conflict:\nexternal data are used more if no conflict is determined and suppress external data otherwise. In our manuscript we focus\non DIB-based inference in the presence of the conflict of an unknown magnitude which cannot be reduced or further\nreduced with the use of observed covariates.\nWe consider statistical inference about a population parameter θ = EX for a random variable X observable in\nthe current data, where EX denotes the expected value of X. If θ is known to be shared between the two datasets\n(θ = EX = EY ), Y is a random variable observable in the external data, then both datasets should be pooled together\nfor inferential purposes. If, however, there is a possibility that EY = β = θ + δ, where the conflict δ ̸= 0, the use of\nexternal data becomes questionable. Several groups of DIB estimators are explored in our manuscript: test-then-pool\n(Viele et al. [2014]), mean squared error minimization (Tarima and Dmitriev [2009], Dmitriev and Tarassenko [2015]),\nadaptive LASSO (ALASSO), (Zou [2006], Li et al. [2023]), Bayesian power prior methods (Ibrahim and Chen [2000],\nIbrahim et al. [2015]) with estimated tuning parameters (e.g., Gravestock et al. [2017], Calderazzo et al. [2023]), purely\nBayes approaches with a prior on the conflict, and compromise estimators bounding limiting risk of Bayes estimators\n1\narXiv:2502.21282v1  [stat.ME]  28 Feb 2025\n\n\n(Efron and Morris [1972]). Out of these methods only ALASSO enjoys the oracle property: asymptotically equivalent to\nthe pooled estimator if δ = 0 and the maximum likelihood estimator (MLE) based on the current data only if δ ̸= 0.\nThe literature on the use of external information without conflict (δ = 0) is large, see a review Qin et al. [2022]. Tarima\nand Pavlov [2006] incorporated uncertain additional information from external observations on a different but correlated\nquantity. Chen et al. [2024] incorporated external summary information without a known measure of uncertainty of\nexternal information. Our focus is only on the situation when δ = 0 is under question.\nThis manuscript investigates asymptotic distributions of DIB estimators and their impact on estimation and hypoth-\nesis testing in the local asymptotic framework, where δ = h/√n, h ̸= 0 is a local conflict and n is the sample size of the\ncurrent data. When n is large, a case where δ is a fixed value different from zero is not very interesting as many DIB\nmethods easily detect δ ̸= 0 and asymptotically fully suppress the impact of external data. This motivates our focus on\na fixed h. Local asymptotics gives additional and somewhat unexpected insights into DIB behavior, as their properties\nhave been mostly evaluated for fixed deltas. More reasons for the choice of local asymptotic framework are given in a\ndedicated Section 2.\nTo simplify explanation of asymptotic comparisons of DIB estimators, we immediately start Section 3 with the\nasymptotic case by considering normal data with unit variances. No covariates, no multiple external datasets, and no\nnon-Gaussian distributions of data are needed to highlight important similarities and differences of large sample properties\nof DIBs.\nSection 3 introduces known DIB estimators and proposes Generalized DIB (GDIB) estimators (see Section 3.7). These\nGDIB estimators incorporate a sensitivity-to-conflict parameter used to select a DIB estimator with desired properties.\nSection 4 derives the asymptotic properties of the DIB estimators, which are typically not normal. Section 5 compares\n√\nn · MSE (SRMSE) of DIB estimators to the SRMSE’s lower bound. Section 5.2 reports on hypothesis testing. Section\n6 presents an illustrative example, which uses a family of DIB estimators introduced in Section 3.7. Illustrative example\nshows how additional model parameters (e.g., sensitivity to conflict) can be chosen to secure the desired asymptotic\ncharacteristics. Section 7 summarizes the paper with a short discussion and key findings.\n2\nImportance of local asymptotics framework\nThe practical value of local alternatives is not sufficiently emphasized in a curriculum of a typical statistics graduate\nprogram, its applied use is rarely discussed, and local alternatives are often perceived as not directly applicable to practice.\nHowever, most statistical inference relying on the central limit theorem (CLT) is done within the local asymptotic\nframework.\nExamples of estimators which analysis relies on CLT include but are not limited to regression coefficients of generalized\nlinear models (e.g. logistic regression), quasi-likelihood based models, semi-parametric models (e.g. Cox regression), M-\nand U- statistics (e.g. Mann-Whitney U), some non-parametric estimators (e.g., kernel based density estimators). Under\ncertain regularity conditions (see, for example, Section 5 of Ferguson [2017]), √n\n\u0010\nˆθ −θ\n\u0011\nd→N(0, σ2), where ˆθ is an\nestimator of θ and 0 < σ2 < ∞. When a researcher relies on a CLT, the effect size becomes inversely proportional to the\nsquare root of the sample size, which immediately places the whole statistical inference in a local asymptotic setting: a\nsimple sample size formula for asymptotic testing of H0 : β = θ versus H1 : β = θ + δ > θ is n = [z0.95 + z0.8]2 σ2/δ2 ≈\n6.18σ2/δ2 at 0.05 and 0.2 type 1 and 2 error rates. Thus, h = √nδ ≈\n√\n6.18σ2 and δ = O(n−0.5).\nWhat happens if asymptotics against a fixed alternative is considered? The power of the test converges to 100% for\nany fixed bounded away from zero alternative. This type of asymptotics sometimes applies to epidemiological studies\nwith large sample sizes so that many reasonable hypothesis testing tasks ends up with very low p-values. Our manuscript\ndoes not consider asymptotics against fixed alternatives.\nLocal alternatives are used in definitions of Pitman asymptotic relative efficiency of non-parametric tests (Nikitin\n[1995]) and asymptotic power (Ferguson [2017]). Local alternatives are related to the concept of contiguety introduced\nby Le Cam [1960]. Interested readers are referred to Van der Vaart [1998] and Sidak et al. [1999]. Local alternatives are\nalso important for comparing MSEs of estimators: asymptotically non-zero contributions of variance and squared bias\nto the MSE are only possible when the magnitude of the bias is O(1/√n).\nWhen a CLT meets local alternatives, large sample properties become more complex. Le Cam [1960] showed local\nasymptotic normality but, in contrast to regular CLTs, both the mean and the variance of the limiting normal distribution\ndepend on the local alternatives. In some settings, the limiting distribution is a mixture of normal distributions (Kahn\nand Gut¸˘a [2009]), in others is a mixture of truncated distributions (Tarima and Flournoy [2024]).\n2\n\n\n3\nDynamic Information Borrowing Methods\nMany statistical methods rely on CLTs when their large sample properties are evaluated. Thus, in our pursuit of deriving\nlarge sample properties for DIB estimators, we directly focus on Gaussian settings assuming that the sample sizes of the\ncurrent and external datasets are sufficiently large. Without loss of generality, we also assume unit standard deviations\n(SD) for current and external data: at large samples the unknown SDs can be consistently estimated and the observations\ncan be standardized to the unit scale.\nLet Xn = (X1, . . . , Xn) be an independent random sample (the current data) with Xi ∼N(θ, 1), where θ is the\nparameter of interest. The MLE of θ, ˆθ = n−1 Pn\ni=1 Xi, is unbiased (Eˆθ = θ), and absorbs all relevant information about\nθ from Xn; fˆθ(x|θ)\nd= N(θ, n−1). Similarly, let Ym = (Y1, . . . , Ym) be an independent sample (an external sample) with\nYi ∼N(β, 1), β = θ + δ. The MLE of β based on Ym is ˆβ = m−1 Pm\ni=1 Yi; f ˆβ(x|β) = N(β, m−1). Both samples are used\nto calculate the MLE of δ, ˆδ = ˆβ −ˆθ.\nIf δ = 0, the pooled estimator ˆθp = (nˆθ + mˆβ)/(n + m) is more precise than ˆθ: var(ˆθ) = n−1, var(ˆβ) = m−1, and\nvar(ˆθp) = (n + m)−1. If δ ̸= 0, ˆθp becomes biased its bias is not suppressed as n →∞. DIB estimators are “floating”\nbetween ˆθ and ˆθp depending on ˆδ.\n3.1\nTest-then-pool [TTPool]\nThe TTPool estimator was suggested by Viele et al. [2014] and stems out from traditional hypothesis testing. The\napproach starts with testing H0 : δ = 0 using ˆξ = (1/n + 1/m)−1/2 ˆδ ∼N(0, 1) under H0. Specifically, if ˆξ2 ≥c, at some\ncritical value c, H0 is rejected and ˆθ is used to estimate θ. Otherwise ˆθp is used instead. Thus, TTPool estimator is\nˆθttp = I\n\u0010\nˆξ2 ≥c\n\u0011\nˆθ + I\n\u0010\nˆξ2 < c\n\u0011\nˆθp.\nUnder h = 0, ˆξ2\nd= χ2\n1, where χ2\n1 a chi-squared random variable with 1 degrees of freedom. A typical choice of c is\n0.95-level quantile of χ2\n1, c = 3.84.\n3.2\nMinimum Mean Squared Error[OMMSE and AMMSE]\nTo borrow external information, consider θλ = ˆθ + λ\n\u0010\nˆβ −ˆθ\n\u0011\n= ˆθ + λˆδ, where λ defines a mixing proportion. Fol-\nlowing Tarima and Dmitriev [2009] and Tarima et al. [2020], the smallest MSE in the class θλ is reached at λ0 =\n−cov\n\u0010\nˆθ, ˆδ\n\u0011\nE−1 \u0010\nˆδ2\u0011\nby\nˆθommse = ˆθ + λ0ˆδ = ˆθ +\nm\nn + m + nmδ2 ˆδ\nwith MSE\n\u0010\nˆθommse\u0011\n= n−1 \u00001 −m/(n + m + nmδ2)\n\u0001\n.\nUnder δ = 0, θλ becomes unbiased for all choices of λ and\nˆθommse = ˆθp with var\n\u0010\nˆθp\u0011\n= 1/(n + m). For a fixed n, var\n\u0010\nˆθp\u0011\n> 0 and only gets close to zero when m is much larger\nthan n (m >> n). The optimal MMSE (OMMSE) estimator ˆθommse cannot be applied in practice because δ is unknown.\nThe adaptive version of OMMSE (AMMSE) substitutes δ with ˆδ:\nˆθammse = ˆθ +\nm\nn + m + nmˆδ2\nˆδ.\n3.3\nAdaptive LASSO [ALASSO]\nRecently ALASSO (Zou [2006]), a modification of the LASSO regression (Tibshirani [1996]), was used for dynamic\ninformation borrowing (see Li et al. [2023] and Kanapka and Ivanova [2024]). In our settings, the ALASSO’s penalized\nlog-likelihood (PL)\nPL(θ, δ|ˆθ, ˆβ) ∝−\nn\nX\ni=1\n(Xi −θ)2 −\nm\nX\ni=1\n(Yi −θ −δ)2 −(n + m)τ |δ|\n|ˆδ|\n∝−\nn\nn + m\n\u0010\nˆθ −θ\n\u00112\n−\nm\nn + m\n\u0010\nˆβ −θ −δ\n\u00112\n−\n|δ|\n(n + m)0.5−τ√n + m|ˆδ|\n,\n3\n\n\nwhere the tuning parameter (n + m)τ−1 and the adaptive “weight” |ˆδ|−1 = |ˆβ −ˆθ|−1 make the penalized loglikelihood\ndiffer from the (un-adaptive) LASSO. Per Theorem 2 in Zou [2006], τ ∈(0, 0.5) ensures the oracle property of the\nALASSO estimator\nˆθalasso(τ) = argθ max\nθ,δ PL(θ, δ|ˆθ, ˆβ).\nThe ALASSO estimator is equivalent to the posterior mode under an (empirical) Laplace prior on δ. In particular,\nthe posterior density would be of the form\nπ(θ, δ|ˆθ, ˆβ) ∝exp\n\u001a\n−n\n2 (ˆθ −θ)2 −m\n2 (ˆβ −θ −δ)2 −|δ|\nˆb\n\u001b\n,\nwhere ˆb = |ˆδ|(n + m)−τ is a data-adaptive choice of the scale parameter of a zero-mean Laplace prior, π(δ) =\n\u0010\n2ˆb\n\u0011−1\nexp\n\u0010\n−|δ|ˆb−1\u0011\n. In Section 5, Monte-Carlo simulations use τ = 0.25, which determines the tuning parameter\n(n + m)τ.\n3.4\nBayes estimators with power prior [HDPP and EBPP]\nPopular Bayesian DIB methods include the power prior approach (Ibrahim and Chen [2000], Ibrahim et al. [2015]), the\n(robust) meta-analytic approach (Neuenschwander et al. [2010], Schmidli et al. [2014]), and the commensurate prior\napproach (Hobbs et al. [2012]). Power and commensurate priors discount external information by introducing a specific\nvalue or a distribution of the conflict parameter into the joint external and current data likelihood. For a normal outcome\nwith a normal prior, analytic connections between the parameters of each approach have been shown for fixed, and, in\ncertain cases, estimated values (see Neuenschwander and Schmidli [2020], Wiesenfarth and Calderazzo [2020], Pawel\net al. [2024]). The robust mixture prior achieves DIB differently, i.e. by direct modification of the external analysis\nposterior/current analysis prior. The power prior is π(θ|ˆβ, γ) = π0(θ)L(θ; ˆβ)γ/C(γ), where γ ∈[0, 1] determines the\nfraction of external data retained in the analysis and C(γ) =\nR\nπ0(θ)L(θ; ˆβ)γdθ is a normalising constant.\nIn our normal settings L(θ; ˆβ) =\nh√mϕ(√m(ˆβ −θ))\ni\nand L(θ; ˆθ) =\nh√nϕ(√n(ˆθ −θ))\ni\n, where ϕ denotes the standard\nnormal probability density function. The prior π0(θ) is often chosen to be a normal distribution with very large variance,\nso that its impact on posterior inferences is minimized. After some minor algebra, the posterior density for a given γ is\nπ(θ | ˆθ, ˆβ, γ) ∝\nh√mϕ(√m(ˆβ −θ))\niγ\n·\nh√nϕ(√n(ˆθ −θ))\ni\n∝√n + mγϕ\n \n√n + mγ\n \nnˆθ + mγ ˆβ\nn + mγ\n−θ\n!!\n.\nThe posterior mean = nˆθ+mγ ˆβ\nn+mγ\n= ˆθ +\nm\nm+n/γ ˆδ and is equivalent to pooling ˆθ with variance 1/n and ˆβ with inflated by a\nfactor 1/γ variance 1/(mγ). This posterior mean is equivalent to OMMSE when δ2 = (1 −γ)/(mγ).\nWhen δ = 0, the optimal γ = 1, i.e., external information is fully borrowed and the posterior mean is equivalent to\nˆθp. Smaller γ lead to fractional information borrowing.\nThere are many ways to estimate γ. A similarity measure was suggested to estimate γ in Thompson et al. [2021].\nThis new measure is equal to the posterior probability that |δ| > 0 if ˆδ is below a clinically relevant threshold and 0\notherwise. In Nikolakopoulos et al. [2018], authors considered two more versions of the power parameter, which also use\ntest-then-pool.\nHellinger distance between normalized likelihoods associated with ˆθ and ˆβ can be used to estimate γ (Ollier et al.\n[2020]):\nH2(ˆβ, ˆθ) = 1\n2\nZ  s\nL(θ|ˆθ)M1\nR\nL(θ|ˆθ)M1dθ\n−\ns\nL(θ|ˆβ)M2\nR\nL(θ|ˆβ)M2dθ\n!2\ndθ,\nwhere M1 = min\n\u00001, m\nn\n\u0001\nand M2 = min\n\u00001, n\nm\n\u0001\n.\nSo that ˆγhd,pp =\n\u0010\n1 −H(ˆβ, ˆθ)\n\u00112\n, which in our case is ˆγhd,pp =\n\u0012\n1 −\nr\n1 −exp\n\u0010\n−nˆδ2/8\n\u0011\u00132\n. Then, a posterior mean estimate for Hellinger-distance based power prior (HDPP) is\nˆθhd,pp = ˆθ +\nm\nm + n/ˆγhd,pp ˆδ.\n4\n\n\nGravestock et al. [2017] suggested empirical Bayes approach (EBPP) to estimate γ by maximization of L(γ; ˆθ, ˆβ) =\nR\nπ(θ|ˆβ, γ)L(θ; ˆθ)dθ, so that in our normal settings,\nˆγeb,pp = arg max\nγ\nL(γ; ˆθ, ˆβ) =\n1/m\nmax{ˆδ2, 1/n + 1/m} −1/n\nand\nˆθeb,pp = ˆθ +\nm\nm + n/ˆγeb,pp ˆδ.\n(1)\n3.5\nBayes estimators with a prior on the conflict [NP and LSTP]\nA full Bayesian approach assigns prior on both, θ and δ. We continue using a non-informative flat prior on θ but impose\nGaussian and location-scale t priors on δ, respectively.\nFollowing Pocock and Simon [1975], the assumed normal prior (NP) centered at zero π(δ) = √nϕ(√n(0 −δ)) leads\nto posterior\nπ(θ, δ|ˆθ, ˆβ) ∝√nϕ(√n(0 −δ))√mϕ(√m(ˆβ −θ −δ))√nϕ(√n(ˆθ −θ)).\nFrom π(θ, δ|ˆθ, ˆβ) ∝π(θ|ˆθ, ˆβ)π(δ|ˆθ, ˆβ) the posterior mode is\n\u0010\nˆδnp, ˆθnp\u0011\n=\n \nˆδ/(1/n + 1/m)\n1/(1/n + 1/m) + n,\nˆθn + ˆδ/(1/n + 1/m)\n1/(1/n + 1/m) + n\n!\n=\n \nmˆδ\n2m + n, ˆθ + ˆδ\nm\n2m + n\n!\n.\nThus, the influence of external information on ˆθnp is not reduced for large conflict.\nA t distribution prior fully discards prior information for large δ and Gaussian data (Dawid [1973], O’Hagan [1979]).\nAssuming δ ∼lst(v, 0, 1/√n), i.e., a location-scale t prior centered at zero, with scale 1/√n and v degrees of freedom,\nthe posterior becomes\nπ(θ, δ|ˆθ, ˆβ) ∝\nh\nv +\n\u0000√nδ\n\u00012i−(v+1)/2 √mϕ(√m(ˆβ −θ −δ))√nϕ(√n(ˆθ −θ)).\nThis posterior requires numeric approximation to find posterior mode or mean. In our simulations, we use a location-scale\nt prior with v = 3, calculate the posterior mode and denote the estimator as LSTP.\n3.6\nLimited translation rules [LRT] estimators\nLTR estimators were suggested in Efron and Morris [1972] as a compromise between a Bayes estimator and a frequentist\nminimax risk estimator. LTR estimators, akin to TTPool, rely on hypothesis testing. Adopting formulas (3.1)-(3.9)\nfrom Efron and Morris [1972], we use ˆh = √nˆδ ∼N(√nδ, 1 + n/m), and h = √nδ ∼N(0, 1). Then, the posterior mean\nfor the local conflict is h∗= ˆh\nm\n2m+n and the posterior mean for θ is equal to ˆθnp. Thus, at M =\np\n1/n + 1/m and\nC = M(2m + n)/(m + n), the LTR estimator of (δ, θ) is\nˆδltr = I\n\u0010\nˆδ > C\n\u0011 \u0010\nˆδ −M\n\u0011\n+ I\n\u0010\nˆδ < −C\n\u0011 \u0010\nˆδ + M\n\u0011\n+ I\n\u0010\n|ˆδ| ≤C\n\u0011\nˆδnp\nˆθltr = I\n\u0010\nˆδ > C\n\u0011 \u0012\nˆθ −M\nm\nm + n\n\u0013\n+ I\n\u0010\nˆδ < −C\n\u0011 \u0012\nˆθ + M\nm\nm + n\n\u0013\n+ I\n\u0010\n|ˆδ| ≤C\n\u0011\nˆθnp.\n3.7\nGeneralized DIB estimators [GDIB]\nAmong the considered estimators, TTPool, AMMSE, HDPP, EBPP, LSTP, and ALASSO suppress external information\nif δ is a fixed value different from zero and benefit from external information when δ = 0.\nALASSO is the only estimator with the asymptotic oracle property. At the same time, as shown later in Theorem 5.1,\nALASSO’s asymptotic power, by analogy with the pooled estimator, is equal to type 1 error against any local alternative:\nfor any local alternative ALASSO estimator is asymptotically equivalent to the pooled estimator.\nFor given n and m, shapes of distributions of TTPool, AMMSE, HDPP and EBPP are fully determined by the\ndistribution of √nˆδ, whereas the distribution of ˆθ only changes their locations; changes in θ shift the whole distribution.\n5\n\n\nUsing a sensitivity parameter, s, previously suggested in Tarima et al. [2013] to suppress or exuberate the effect of √nˆδ,\nthe DIBs from the set {TTPool, AMMSE, HDPP and EBPP} are generalized to:\nˆθGDIB (g, s) =\nh\n1 −g\n\u0010\nnˆδ2s\n\u0011i\nˆθ + g\n\u0010\nnˆδ2s\n\u0011\nˆβ = ˆθ + g\n\u0010\nnˆδ2s\n\u0011\nˆδ,\nwhere the function g\n\u0010\nnˆδ2s\n\u0011\nis an estimator of the mixing parameter λ and defined on the unit interval. When the\nsensitivity-to-conflict is tied to n via s = n−2τat τ ∈(0, 0.5) it becomes asymptotically equivalent to the pooled estimator\n(see Theorem 4.4).\nThe function g\n\u0010\nnˆδ2s\n\u0011\nis an estimator of λ ∈[0, 1] when s ∈[0, +∞).\nIn ˆθGDIB(g, s), with\ns = n−2τ a tuning parameter τ is introduced and s depends on n. Both parameterizations, via s (n- independent)\nand via τ (n-dependent) describe departure from a base estimator, but asymptotic properties differ. For example, if\ng\n\u0010\nsnˆδ2\u0011\n= m/\n\u0010\nn + m + m · nˆδ2\u0011\ns, the GDIB family is built around AMMSE (Tarima et al. [2013])\nˆθammse(s) = ˆθ +\nm\nn + m + m · nˆδ2s\nˆδ.\nThe ˆθammse(s) used in our illustrative example for choosing s to secure desired asymptotic properties.\n4\nLarge Sample Properties\nAsymptotics is considered at n →∞with δ = h/√n. We assume n(n + m)−1 →p, 0 ≤p ≤1, [1 + n/m →1/(1 −p) and\nn/m →p/(1 −p)], ζ1 := √n\n\u0010\nˆθ −θ\n\u0011 d= N(0, 1), and ζ2 := √m\n\u0010\nˆβ −β\n\u0011 d= N(0, 1); ζ1 and ζ2 are mutually independent;\nξ := √1 −p(h −ζ1) + √pζ2.\nTheorem 4.1. √n\n\u0010\nˆβ −θ\n\u0011\nd→N (h, p/(1 −p)).\nTheorem 4.2. √n\n\u0010\nˆθp −θ\n\u0011\n→N ((1 −p)h, p).\nTheorem 4.3.\n√n\n\u0010\nˆθttp −θ\n\u0011\nd→Pr(ξ2 > c)ζ1 + Pr(ξ2 ≤c)\n\u0010\npζ1 +\np\np(1 −p)ζ2 + (1 −p)h\n\u0011\nThus, the distribution of TTPool is an informative mixture of two dependent Gaussian random variables: ζ1 and ζp\n(see Appendix B). This mixture results in a unimodal distribution at δ = 0, then as δ increases bi-modality becomes\nclearly seen. As δ becomes even larger the contribution from the external dataset is suppressed and the density converges\nto the density of ˆδ. When δ = 0 and c = 3.84, √n\n\u0010\nˆθttp −0\n\u0011\n→0.05 · N(0, 1) + 0.95 · N\n\u00000, p−1\u0001\n. If δ is a fixed ̸= 0 value,\nPr\n\u0010\nˆξ2 > c\n\u0011\n→1 and √n\n\u0010\nˆθttp −θ\n\u0011\nd→N (0, 1).\nTheorem 4.4. If τ ∈(0, 0.5), √n\n\u0010\nˆθalasso\nn\n(τ) −θ\n\u0011\nand √n\n\u0010\nˆθGDIB\nn\n\u0000g, n−2τ\u0001\n−θ\n\u0011\nconverge to N ((1 −p)h, p) in distri-\nbution.\nTheorem 4.5. √n\n\u0010\nˆθGDIB\nn\n(g, s) −θ\n\u0011\nd→ζ1 + g\n\u0010\nsξ2\n1−p\n\u0011\nξ.\nCorollary 4.1. √n\n\u0010\nˆθeb −θ\n\u0011\nd→ζ1+\n1−p\n1−p+p/γeb ξ, √n\n\u0010\nˆθhd −θ\n\u0011\nd→ζ1+\n1−p\n1−p+p/γhd ξ, where γeb := p\n\u0000max{ξ2, 1} −1 + p\n\u0001−1\nand γhd :=\n\u0010\n1 −\np\n1 −exp (−ξ2/(8 −8p))\n\u00112\n.\nAMMSE asymptotics is found in Van Lancker et al. [2023] and follows from Theorem 4.5:\nCorollary 4.2 (AMMSE). √n\n\u0010\nˆθammse −θ\n\u0011\nd→ζ1 +\n√1−p\n1+ξ2 ξ\nNo asymptotics was derived for NP, LSTP and LRT: NP and LRT do not suppress external data if δ ̸= 0 (Section 5).\nDerivation of LSTP distribution is analytically challenging. Numeric approximation was used to find LSTP’s posterior\nmode. Section 5 shows that conflicting external data is eventually suppressed by LSTP. Heavy tailed priors are especially\nimportant for practical applications of fully Bayes DIB.\n6\n\n\n0\n1\n2\n3\n-5\n0\n5\nδ n\nStandardised RMSE\nmethod\nALASSO\nAMMSE\nLTR\nTTPool\nOMMSE\nMLE\nPooled\nFrequentist approaches\n0\n1\n2\n3\n-5\n0\n5\nδ n\nEBPP\nHDPP\nLSTP\nNP\nOMMSE\nMLE\nPooled\nBayesian approaches\nFigure 1: Standardized root mean squared error for Bayesian and frequentist borrowing approaches for varying conflict\nδ√n. Results are derived from grid-based numerical integration.\n5\nSimulations\nSection 5.1 uses θ = 0; Section uses 5.2 θ ∈{0.03, 0.06, 0.09}. The current sample is summarized by ˆθ ∼N(0, 1/n),\nn = 1, 000. The external data is given by ˆβ ∼N(θ + δ, 1/m), m = 100, 000. Appendix B shows DIB densities at\n√nδ ∈{0, 0.32, 1.58, 5.06}.\n5.1\nMean Squared Error\nFigure 1 reports SRMSE (Standardized Square Root of MSEs), which we define as\n√\nn · MSE. Since MSE of the MLE\nis 1/n, its SRMSE is equal to one. Then, SRMSE can be viewed as a square root of the relative efficiency defined as\nthe ratio of MSE of a DIB estimator and MSE of the MLE. Patterns of SRMSEs in Figure 1 are similar to what was\nreported by others (e.g., Dmitriev and Tarassenko [2015], Nikolakopoulos et al. [2018], Calderazzo et al. [2023]), but we\nexplore them jointly with respect to the lower bound determined by OMMSE. SRMSE approximates the limiting risk of\nθ estimation for a quadratic loss.\nTo determine an optimal DIB estimator a single optimality criterion is needed. One option would be to assign a cost\nfor each value of δ. From the Bayes perspective this cost is naturally determined by a prior, π(δ). Then, the integrated\nover π(δ) MSE is\nIMSE(ˆθDIB|θ, π) =\nZ +∞\n−∞\nMSE(ˆθDIB|θ, δ)π(δ)dδ\n=\nZ +∞\n−∞\nZ +∞\n−∞\n(z −θ)2fˆθDIB(z|θ, δ)π(δ)dzdδ,\nwhere fˆθDIB(z|θ, δ) refers to the sampling distribution of a DIB estimator.\nTTPool, NP, AMMSE, HDPP, EBPP, and Generalized DIB are location invariant with respect to θ: any change in θ\nis associated with a shift of a whole distribution of a DIB estimator. The location invariance property of DIB estimators\nensures that the integrated MSE is also invariant to changes in θ: IMSE(ˆθDIB|θ, π) = IMSE(ˆθDIB|π).\nNote that\nIMSE(ˆθDIB, π) = EˆθDIB\n\u0010\nEπ(z −θ)2|ˆθDIB = z\n\u0011\n≥Eˆθ∗\n\u0010\nEπ(z −θ)2|ˆθ∗= z\n\u0011\n,\nwhere ˆθ∗is the Bayes optimal decision (see Section 8.8 DeGroot [2005]). In Section 8.9 DeGroot [2005], the optimal\ndecision is obtained by minimizing an expected posterior loss for a given Xn and YnIn the case of quadratic loss, the\nexpected posterior is minimized by the posterior mean. Thus, the IMSE is minimized when the DIB is the posterior\nmean under the prior π(δ) (see e.g. Parmigiani and Inoue [2009]).\n7\n\n\nEstimator\nπ1(δ)\nπ2(δ)\nπ3(δ)\nπ4(δ)\nπ5(δ)\nMLE\n1.00\n1.00\n1.00\n1.00\n1.00\nPooled\n0.80\n1.38\n15.66\n0.58\n1.10\nNP\n0.68\n0.91\n7.91\n0.61\n0.81\nAMMSE\n0.83\n0.92\n1.01\n0.78\n0.86\nTTPool\n0.94\n1.12\n1.03\n0.80\n0.98\nALASSO\n0.78\n1.23\n1.35\n0.57\n0.94\nEBPP\n0.82\n0.95\n1.02\n0.74\n0.86\nHDPP\n0.75\n1.14\n1.12\n0.55\n0.87\nLTR\n0.71\n0.87\n1.36\n0.64\n0.77\nLSTP\n0.80\n0.89\n1.02\n0.76\n0.83\nOMMSE\n0.53\n0.67\n0.97\n0.42\n0.58\nTable 1: Bayes risk at different choices of π(δ): π1(δ) = N(0, 1/n), π2(δ) = N(0, 3/n + 3/m), π3(δ) = Unif(−1, 1),\nπ4(δ) = Laplace(0, (n + m)−0.35), π5(δ) = LST(3, 0, 1/√n); LST stands for a location scale T distribution. Results are\nderived from grid-based numerical integration.\nTable 1 reports a few versions of IMSE calculated for the DIB estimators. For computational simplicity, our simulations\nuse the posterior mode as LSTP estimator, which does not guarantee optimality in terms of IMSE minimization because\nit may not coincide with the posterior mean.\n5.2\nHypothesis testing\nAs shown in Section 3 and illustrated in Web Appendix B, majority of the DIB estimators which can be used for\nhypothesis testing have different from normal distributions in the local neighbourhood of δ = 0. Consequently, choices of\ntheir critical values depend on δ. Figures 2(a-b) [row one], 2(c-d) [row two], and 2(e-f) [row three] show power properties\nwhen θ ∈{0.03, 0.06, 0.09}, respectively. For each scenario T1ER is secured at 2.5% type, but the null hypotheses is\ndefined differently for each column of Figure 2.\nColumn one represents the most conservative situation when ∀δ, T1ER is controlled exactly. The problem with such\nsetting is that statistical power is the highest if the testing is based on ˆθ (the black horizontal line). These simulations\nconfirm the findings of Kopp-Schneider et al. [2020] and Kopp-Schneider et al. [2023], where the authors showed that no\npower gain is possible when external information is incorporated in a statistical procedure if a uniformly most powerful\ntest exists. Column one also indicate that there exist just a single value of δ where AMMSE, ALASSO, LTR, EBPP,\nLSTP, and HDPP estimators show comparable to the MLE power. By the Karlin-Rubin lemma the likelihood ratio test\n(equivalent to the MLE in our settings) is uniformly (∀HA : θ = θA) most powerful if data came from the exponential\nfamily.\nWith increasing sample size ALASSO’s the power to detect local departures from H0 : θ = 0 is equal to zero, because\nALASSO procedure forces all local ALASSO estimates to zero.\nTheorem 5.1. Asymptotic power to detect H0 : θ = hθ/√n is equal to zero if testing is based on ˆθp\nn, ˆθalasso\nn\n(τ) or\nˆθDIB\nn\n\u0000g, n−2τ\u0001\nat τ ∈(0, 0.5).\nT1ER control ∀δ is an extreme setting: information borrowing becomes useless.\nAnother extreme is to determine the critical value for testing H0 : θ = 0 assuming δ = 0, see the last column of\nFigure 2. Statistical powers when θ ∈{0.03, 0.06, 0.09} are shown in Figures 2(b,d,f), respectively. In this setting, the\nDIB estimators are the most useful for testing θ = 0 and the pooled estimator tops them all in terms of statistical power.\nFinally, researchers can consider a compromise when the critical value is chosen to be the highest critical value within\na range of plausible departures of the conflict from zero. Figure 3 reports T1ER and power when the critical value is\nselected to control T1ER for testing H0 : θ = 0 for δ < δ0 = 0.0636. The threshold δ0 is chosen by an investigator\nindependently of the data and heavily depends on a subject area.\nFigure 3(a) shows that T1ER is exactly controlled when δ = δ0 across all methods, and can be only smaller when\nδ < δ0. The pooled estimator and NP based testing do not suppress incorrect external information can have T1ER as\nhigh as 100%. T1ER of the test based on the LTR estimator converges to a constant value as a conflict increases.\nSmall positive departures from θ = 0 (Figure 3(b)) show similar power properties for all DIBs when θ = δ0/2 and\nδ = δ0/2. The range δ0/2 < δ ≤δ0 at θ = δ0/2 shows higher power properties when a DIB is used for testing, but\nδ0/2 < δ ≤δ0 at θ = δ0/2 reduces power as compared to the MLE.\nOverall other power curves (Figure 3(c,d)) show similar patterns to Figure 3(b). When δ < δ0, T1ER for testing θ\nis controlled at a predetermined level, and as simulations show there is a sub-range of values of δ (δ ∈R = (δ0 −θ, δ0))\n8\n\n\nwhere the power of detecting θ > 0 is higher than the power of test based on the MLE. This is analogous to the “sweet\nspot” region of Viele et al. [2014], which is determined by MSE reduction as compared to the MSE of the MLE.\nDue to the complexity of distributions of the DIB estimators and non-monotonicity of their power curves, the region\nR where T1ER is controlled and the power of superiority testing is higher than the power of the MLE may need to be\ndetermined numerically.\nThus, if a researcher is willing to benefit from using a DIB estimator for hypothesis testing, some additional specifi-\ncations on the conflict should be in place.\nControl of the additional specifications on the conflict, e.g. δ ≤δ0, in real-life settings may be problematic, and\nresearchers may be tempted to probabilistically describe how likely these additional specifications hold true. For example,\na researcher can opt for reporting an estimate of p2 = Pr\n\u0010√nδ0 −√nˆθ < √nˆδ < √nδ0\n\u0011\nto describe how likely the conflict\nis in the “sweet spot” (T1ER is controlled and power is higher than the power of the MLE) and/or p3 = Pr\n\u0010√nˆδ < √nδ0\n\u0011\nto describe how likely δ belongs to the range where T1ER is controlled. However, p2 ≤p3 ≤Pr\n\u0010√nˆθ < √nδ0\n\u0011\nunder\nθ = 0, where the last inequality is a result of var(√nˆδ) ≥var(√nˆθ). Then, under √nδ0 = 1.96, Pr\n\u0010√nˆθ < 1.96|θ = 0\n\u0011\n=\n0.975 leads to Pr\n\u0010√nˆδ < 1.96|θ = 0\n\u0011\n≤0.975. So, T1ER of the test {√nˆθ > 1.96} for testing θ = 0 is always smaller\nthan T1ER of the test {√nˆδ > 1.96} for testing δ = 0. This controversy can be formulated as follows: the probability\nthat T1ER is not controlled, 1 −p3 = Pr{√nˆδ > 1.96}, is always higher than T1ER of the MLE-based test for all\ncommon sense δ0 (√nδ0 above a critical value, e.g. 1.96, are of no interest for testing H0 : θ = 0). Thus, we emphasize\nthe importance of choosing δ0 using expert opinion and common sense. Sample estimates of p2 and p3 can be explored\nas functions of δ0 in a sensitivity analysis as is completed in Section 6, but their practical relevance is questionable.\nRemark: Theorem 5.1 uses a sample size dependent definition of the sensitivity-to-conflict parameter (s = n−2τ),\nwhich makes the sensitivity parameter converge to zero as sample size increases, which ensures convergence of ˆθDIB\nn\n\u0000g, n−2τ\u0001\nto the pooled estimator. Theorem 5.1 does not apply to GDIB estimators with a sample size independent s > 0.\nNote that in this section θ0 = 0 is assumed; in Section 6, θ0 ̸= 0 and θ needs to be substituted with θ −θ0 to make\nthe formulas of this section applicable.\n6\nIllustrative Example\nThe Pregnancy Risk Assessment Monitoring System (PRAMS) began in 1987 as a response to a continuing high rate\nof maternal and infant mortality in the United States. PRAMS is conducted by the Centers for Disease Control and\nPrevention’s Division of Reproductive Health in collaboration with state health departments PRAMS continues today\nas a state-based surveillance system (e.g., WIPRAMS for WI) of maternal behaviors, attitudes, and experiences before,\nduring, and shortly after pregnancy (Shulman et al. [2018]).\nUsing WIPRAMS, we estimated the mortality rate (=37/94=39.36%) for extremely preterm infants (gestational age\n<28 weeks). We also know a 2017 USA-level finding the mortality is = 38.4% (m = 20, 000). Sample SDs for WI and\nUS rates are SDwi ≈0.4886 and SDus ≈0.4864, which lead to the standardized quantities: ˆθst = ˆθ/SDwi = 0.7895 and\nˆβst = ˆβ/SDus = 0.8057. To borrow information we considered the family ˆθammse(s).\nAfter exploring dependence of SRMSEs of ˆθammse(s) (s = n−2τ) on δ for different values of τ (Figure 4a), it was\ndetermined that τ = 0.1(s = 94−0.2 ≈0.4) gives a reasonable compromise between maximum expected loss (highest\nMSE inflation is 25% in comparison to the MSE of the MLE) and maximum expected benefits (about 50% reduction of\nMSE if δ = 0). This choice of s is not based on the observed data but uses Theorem 4.5 for asymptotic distribution of\nˆθammse(s). Then, using the observed data at s = 0.4, ˆθammse(0.4) = 0.396 with a 95% bootstrap confidence interval (107\nresamples) 0.334 −0.454. Figure 4b shows confidence intervals for other choice of τ.\nFor illustrative purposes, we also consider a hypothesis testing problem. Can we make a claim that more than two\nthirds of extremely preterm infants are alive at their first birthday? This claim (our research hypothesis) needs further\nspecifications imposed on δ:\nOption 1 (∀δ): As shown in Section 5.2, testing H0 : θ = 1/3(∀δ) versus HA : θ < 1/3(∀δ) cannot benefit from\ninformation borrowing. Then, the MLE based testing relies on Z1 = √n\n\u0010\nˆθ −1/3\n\u0011\n∼N(0, 1) under H0. The p-value,\nPr (Z1 > z1|θ = 1/3) = 0.1157, where the observed value of Z1, z1 =\n√\n94 (0.8057 −1/3) = 1.1963. Then, H0 is not\nrejected.\nOption 2 (δ = 0): We test H0 : θ = 1/3 under δ = 0: uncertainty about θ becomes small and H0 is rejected with ˆθp.\nUsing asymptotics of Z2 = √n\n\u0010\nˆθp −1/3\n\u0011\nunder H0 with δ = 0, Pr (Z2 > z2|θ = 1/3, δ = 0) < 0.0001, where Z2 = z2.\n9\n\n\nOption 3 (δ ≤δ0): H0 : θ = 1/3(δ < δ0).\nPreviously, we chose τ = 0.1, and to fully specify the hypothesis\ntesting task, we choose δ0 = 0.05 and using Monte-Carlo simulations of Z3 = √n\n\u0010\nˆθammse(0.4) −θ\n\u0011\nunder θ = 1/3 and\nδ0 = 0.05. The p-value Pr(ˆθammse(0.4) > z3|δ = 0.05, θ = 1/3) = 0.0423, where z3 = 1.0421; H0 is rejected, at δ ≤δ0.\nThe choice of δ0 = 0.05 was driven by common sense considerations and an expert opinion that it was highly unlikely\nthat in the population of extremely preterm births, infant mortality rate in WI differs from the US by more than 5%. If\nwe consider δ0 = 0.01, p-value decreases to 0.0355, whereas δ0 = 0.087 determines the tipping point when p-value= 0.05\nand statistical significance disappears for δ > 0.087. Sample estimates of p3 = Pr(ˆδ < δ0), ˆp3 = 0.60 if δ0 = 0.01,\nˆp3 = 0.74 if δ0 = 0.05, and ˆp3 = 0.14 if δ0 = 0.087, are not overly useful because, as it was mentioned earlier, uncertainly\nassociated with estimation of δ is always higher than uncertainty associated with estimation of θ. Sample estimates of\nthe probability of being in the sweet spot p2 are even smaller than the estimates of p3: ˆp2 = 0.60 if δ0 = 0.01, ˆp2 = 0.55\nif δ0 = 0.05, and ˆp2 = 0 if δ0 = 0.087. Again, estimates of p2 are of limited use.\n7\nSummary\nThis manuscript explored large sample properties of several DIB estimators: TTPool (test-then-pool), AMMSE (adaptive\nminimim mean squared error), ALASSO (adaptive lasso), HDPP (Hellinger distance based power prior), EBPP (empirical\nbayes power prior), NP (normal prior), LSTP (local-scale t prior), and LTR (limited translation rule). Their properties\nwere evaluated in the local asymptotic framework where both the treatment effect θ and the conflict between the\nexternal and current datasets δ were evaluated in their local neighbourhoods: θ = hθ/√n and δ = h/√n. Asymptotic\ndistributions of TTPool, AMMSE, ALASSO, HDPP, and EBPP estimators are found to be non-Gaussian. As h changes,\nDIB estimators are “floating” between two extremes: the pooled estimator, which fully borrows external information,\nand the MLE derived on the current data only. ALASSO, HDPP and EBPP can be viewed as empirical Bayes estimators,\nwhere prior parameters are estimated from the data. NP and LSTP are full Bayes estimators. AMMSE is fully frequentist\nestimator which an estimated version of the OMMSE - the estimator with the lowest possible MSE. TTPool is an estimator\nbased on hypothesis testing and LRT is a compromise estimators between the full Bayes estimator pooling data from\nboth data sources and the MLE.\nThere are no DIB estimators with uniformly smallest MSE ∀δ. However, if the MSE is integrated over some prior\ndistribution π(δ) assigning prior weights to δ, the optimization problem is fully determined and Bayes estimators obtained\nunder π(δ) are optimal as they minimize the integrated MSE. There are some desired properties for π(δ): (1) π(δ) should\nsuppress external data if δ ̸= 0, (2) a DIB should benefit from external information if δ = 0 or small, (3) limiting risk\nagainst local alternatives (the SRMSE in our setting) should be bounded. For example, pure Bayes NP estimator does\nnot suppress external data so that its SRMSE diverges to infinity when the conflict increases. Property 1 also does not\nhold for the LRT estimator because its limiting MSE is always higher than the MSE of the MLE at large δ. The LSTP\n(location scale t distribution; location = 0, scale = 1/n, and degrees of freedom = 3) preserves these three desirable\nproperties: its heavy tails (3+ degrees of freedom ensure existence of the first two moments) suppress external data at\nhigh δ and the use of scale = 1/n incorporates external information at small δ at any sample sizes. The main challenge\nassociated with LSTP is computational intensity of calculating posterior means or modes. Variance of posterior mean\nwith heavy tailed priors may be higher than variance of the MLE (Pericchi and Smith [1992]), which can be confusing\nto practitioners.\nEmpirical Bayesian estimators (EBPP, HDPP and ALASSO) approximate optimal Bayes solutions.\nUsing large\nsample properties one can evaluate dependence of SRMSE on h. ALASSO does not preserve Property 3: ∀h ̸= 0 its\nSRMSE diverges as n →∞. Table 2 summarizes the properties of DIB methods.\nALASSO is the only DIB estimator with the oracle property. ALASSO is asymptotically equivalent to the pooled\nestimator for finite h and is asymptotically equivalent to the current data MLE when δ is a fixed sample size-independent\nvalue different from zero. When SRMSE is evaluated at a local conflict δ = h/√n, h ̸= 0, the estimator is asymptotically\nequivalent to the pooled estimator and its SRMSE is unbounded. Consequently, asymptotically, in contrast to many other\nDIB approaches (EBPP, HDPP, AMMSE, TTP, LST, GDIB(g, s), and LSTP) ALASSO does not distinguish between\nδ = 0 and δ = h/√n and opts for full information borrowing.\nAsymptotics of EBPP, HDPP, AMMSE and TTP is determined by hθ and h. Sufficient statistic is two dimensional,\n√nˆθ and √nˆδ, but DIB estimators are one-dimensional quantities. Then, optimal inference about θ is only possible when\nδ is known. This is why OMMSE sets MSE’s lower bound, but cannot be applied in practice. It is still instructive to\ncompare MSEs of DIB estimators against the lower bound.\nWhen √nˆδ is replaced with n−τ√nˆδ, τ ∈(0, 0.5) (the sensitivity-to-conflict s = n−2τ depends on n), the GDIB\nbecome asymptotically equivalent to ALASSO and enjoy the oracle property.\nBy analogy with ALASSO at a fixed\nh ̸= 0 conflicting external information is not asymptotically suppressed. To avoid the asymptotic impact of functional\ndependence of the sensitivity-to-conflict parameter (s) on sample size\n\u0000s = n−2τ\u0001\n, a sample size independent version of\n10\n\n\ns ≥0 is considered and √snˆδ is used instead of √nˆδ in EBPP, HDPP, AMMSE and TTP. This modification changes local\nasymptotic properties without imposing the oracle property. Our illustrative example chose s to determine an acceptable\nMSE profile independently of n, ˆθ, and ˆδ.\nEstimator\nPr. 1\nPr. 2\nPr. 3\nOracle Pr.\nMLE\nX\nPooled\nX\nNP\nX\nAMMSE\nX\nX\nX\nTTPool\nX\nX\nX\nALASSO\nX\nX\nX\nEBPP\nX\nX\nX\nHDPP\nX\nX\nX\nLTR\npartially\nX\nX\nLSTP\nX\nX\nX\nGDIB\n\u0000g, n−2τ\u0001\nX\nX\nX\nGDIB(g, s)\nX\nX\nX\nOMMSE\nX\nX\nX\nX\nTable 2: Property 1 (suppresses external data if conflict is present and large); Property 2 (benefits from external\ninformation is the conflict is absent or small); Property 3 (bounds limiting risk against local alternatives); Oracle\nProperty (suppresses external data if conflict is present and large and fully uses external information is the conflict is\nabsent\nHypothesis testing is problematic with DIB if one wishes to control T1ER ∀δ, but under certain data-independent\nassumptions on δ DIB benefits can be substantial. In our illustrative example, superiority testing on θ under the assump-\ntion that δ < δ0 increased statistical power while T1ER was still controlled. Within the local asymptotic framework,\nstochastic uncertainty that δ belongs to a desired region never goes away as n →∞and data independent justification\nof the assumptions on δ are necessary.\nWe considered external data as a sample which is not observed or known at the time when the trial is designed. In\nreal-life settings by the nature historical data external to the study, the external data may be available at the time the\nstudy is being designed and may potentially affect design decisions. However, importantly, availability of historical data\ndoes not inform the study design on the magnitude of δ because the current data are not yet collected. Thus, the critical\nassumptions on the magnitude of δ can still be made in a data-independent manner.\nDynamic information borrowing comes with nontrivial complications. Data generating mechanisms depend on both,\nthe parameter of interest and the conflict between the current and external data. This dependence continues to be present\nin large samples of the local asymptotic framework. Consequently, to determine an unambiguous optimality criterion,\nstatistical inference needs additional specifications on the conflict. For estimation tasks, specification a prior distribution\non the conflict, implicitly or explicitly, determines an optimality criterion. In our work, we considered integrated mean\nsquared error, but a prior distribution on the conflict determines an unambiguous optimality criterion for other loss\nfunctions as well. For hypothesis testing tasks, additional assumptions on the conflict should also be based on data\nindependent considerations. Previously proposed methods for dynamic information borrowing work well for some ranges\nof the conflict and poorly at others. Thus, data independent choice of a dynamic information borrowing method has to\nbe closely aligned with non-sampling prior knowledge on the magnitude of the conflict.\nOur findings are generally in line with the skepticism expressed in Galwey [2017] on dynamic information borrowing\nmethods. However, under certain implicit or explicit assumptions on the magnitude of the conflict, as our illustrative\nexample showed, dynamic information borrowing can substantially improve statistical inference.\nThere is no “free lunch” for statisticians when they try to dynamically incorporate external information to improve\nstatistical inference (estimation or hypothesis testing tasks). Asymptotic distributions of statistics often become complex\nand differ from normal. Implicit or explicit data-independent assumptions on the magnitude of the conflict between\nthe current and external data have to made. Our work suggests generalizations of already known dynamic information\nborrowing estimators and shows how such data-independent assumptions can be imposed to secure a desired compromise\nbetween costs and benefits of external information use.\n11\n\n\nAcknowledgment\nThis project was partially supported by the Health Resources and Services Administration (HRSA) of the U.S. Depart-\nment of Health and Human Services (HHS) under R40MC41748 the Maternal and Child Health Secondary Data Analysis\nResearch Program. This information or content and conclusions are those of the author(s) and should not be construed\nas the official position or policy of, nor should any endorsements be inferred by HRSA, HHS or the U.S. Government.\nAppendix A: Large Sample Properties\nProof of Theorem 1: Since β = θ + δ and θ = β −δ = β −h/√n, √n\n\u0010\nˆβ −θ\n\u0011\n= p n\nm\n√m\n\u0010\nˆβ −β + h/√n\n\u0011\nconverges\nin distribution to\nq\np\n1−pζ2 + h = N\n\u0010\nh,\np\n1−p\n\u0011\n.\nProof of Theorem 2: √n\n\u0010\nˆθp −θ\n\u0011\n=\nn\nn+mζ1 +\nm\nn+m\n√n\n\u0010\nˆβ −β + h/√n\n\u0011\n=\nn\nn+mζ1 +\nm\nn+m\n\u0010p n\nm\n√m\n\u0010\nˆβ −β\n\u0011\n+ h\n\u0011\ncon-\nverges in distribution to pζ1 +(1−p)\n\u0010q\np\n1−pζ2 + h\n\u0011\n= pζ1 +\np\np(1 −p)ζ2 +(1−p)h =: ζp. Note that the asymptotic dis-\ntribution of √n\n\u0010\nˆθp −θ\n\u0011\nat δ = h/√n is a linear combination ζ1 ∼N(0, 1) and ζ2 ∼N(0, 1). Then, ζp ∼N ((1 −p)h, p).\nProof of Theorem 3: Since ˆξ =\nˆβ−ˆθ\n√\n1/n+1/m = θ+h/√n+ζ2/√m−θ−ζ1/√n\n√\n1/n+1/m\n=\n√m(h−ζ1)+√nζ2\n√n+m\n→ξ and, using theorems 4.1\nand 4.2, we find\n√n\n\u0010\nˆθttp\nn\n−θ\n\u0011\nd→Pr(ξ2 > c)ζ1 + Pr(ξ2 ≤c)\n\u0010\npζ1 +\np\np(1 −p)ζ2 + (1 −p)h\n\u0011\n.\nProof of Theorem 4.4: At δ = h/√n, √nˆδ\nd→\np\n1/(1 −p)ξ =\np\np/(1 −p)ζ2 + h −ζ1, which is a non-degenerate\nrandom variable. Then, if τ ∈(0, 0.5), n−τ|ˆδ|\np→0, which makes the penalty term in the ALASSO criterion diverge to\ninfinity. Consequently, ALASSO estimator of δ converges to zero and ˆθalasso converges to the pooled estimator ˆθp. One\ncan easily see that if τ ∈(0, 0.5), ˆθDIB \u0000g, n−2τ\u0001\nalso converges to ˆθp.\nProof of Theorem 4.5: √n\n\u0000θGDIB(g, s) −θ\n\u0001 d= √n\n\u0010\nˆθ −θ\n\u0011\n+g(snˆδ2)√nˆδ\nd→ζ1+g\n\u0010\nsξ2\n1−p\n\u0011\nξ, where √nˆδ\nd=\np\nn (n−1 + m−1)ˆξ\nd→\nq\n1\n1−pξ.\nProof of Corollary 4.1: Since √nˆδ\nd→ξ/√1 −p,\nˆγeb =\nn/m\nmax{nˆδ2, 1 + n/m} −1\nd→\np/(1 −p)\nmax{ξ2/(1 −p), 1/(1 −p)} −1 = γeb\nand ˆγhd =\n\u0012\n1 −\nr\n1 −exp\n\u0010\n−nˆδ2/8\n\u0011\u00132\nd→\n\u0010\n1 −\np\n1 −exp (−ξ2/(8 −8p))\n\u00112\n= γhd. Then,\n√n\n\u0010\nˆθhd −θ\n\u0011 d= √n\n\u0010\nˆθ −θ\n\u0011\n+\n1\n1 + n/(mˆγhd)\n√nˆδ\nd→ζ1 +\n1 −p\n1 −p + p/γhd ξ,\nand, similarly, √n\n\u0010\nˆθeb −θ\n\u0011\nd→ζ1 +\n1−p\n1−p+p/γeb ξ, where √nˆδ\nd=\np\nn (n−1 + m−1)ˆξ\nd→\nq\n1\n1−pξ.\nProof of Corollary 4.2: √n\n\u0010\nˆθammse −θ\n\u0011 d= √n\n\u0010\nˆθ −θ\n\u0011\n+\n1\nn/m+1+nˆδ2\n√nˆδ\nd→ζ1+\n√1−p\n1+ξ2 ξ, where √nˆδ\nd=\np\nn (n−1 + m−1)ˆξ\nd→\nq\n1\n1−pξ.\nProof of Theorem 5.1: Proof directly follows from Theorem 4.4. The asymptotic distribution of √n\n\u0010\nˆθalasso\nn\n(τ) −θ\n\u0011\nand √n\n\u0010\nˆθDIB\nn\n(τ) −θ\n\u0011\nis the same of the distribution of the pooled estimator: N((1 −p)h, p) if δ = h/√n including\nδ = 0. Then, the critical value to secure α for testing hθ = 0 versus hθ > 0 is (1 −p)h + √pz1−α. If a researcher wants to\ncontrol T1ER ∀h, a maximum critical value should be chosen. As h increases the critical value, which is a linear function\nof h also increases and the maximum critical value = +∞. Then, it is not possible to control T1ER at a predetermined\nlevel and asymptotic power to detect hθ is zero.\nAppendix B\nFigure 5 shows DIB densities √nδ ∈{0, 0.32, 1.58, 5.06}, n = 1, 000 and m = 100, 000.\n12\n\n\n0.00\n0.25\n0.50\n0.75\n1.00\n-10\n-5\n0\n5\n10\nPower\nθ = 0.03\n(a)\n0.00\n0.25\n0.50\n0.75\n1.00\n-10\n-5\n0\n5\n10\nθ = 0.03\n(b)\n0.00\n0.25\n0.50\n0.75\n1.00\n-10\n-5\n0\n5\n10\nPower\nθ = 0.06\n(c)\n0.00\n0.25\n0.50\n0.75\n1.00\n-10\n-5\n0\n5\n10\nθ = 0.06\n(d)\n0.00\n0.25\n0.50\n0.75\n1.00\n-10\n-5\n0\n5\n10\nδ n\nPower\nθ = 0.09\n(e)\n0.00\n0.25\n0.50\n0.75\n1.00\n-10\n-5\n0\n5\n10\nδ n\nθ = 0.09\n(f)\nmethod\nALASSO\nEBPP\nLTR\nHDPP\nLSTP\nAMMSE\nNP\nPooled\nMLE\nTTPool\n        ∀δ0                                    \nδ0 = 0\nFigure 2:\nPower as a function of δ at different θ and different definitions of H0; T1ER = 0.025. Results are derived\nfrom grid-based numerical integration.\n13\n\n\n0.00\n0.25\n0.50\n0.75\n1.00\n-10\n-5\n0\n5\n10\nTIE rate\nθ = 0\n(a)\n0.00\n0.25\n0.50\n0.75\n1.00\n-10\n-5\n0\n5\n10\nPower\nθ = 0.03\n(b)\n0.00\n0.25\n0.50\n0.75\n1.00\n-10\n-5\n0\n5\n10\nδ n\nPower\nθ = 0.06\n(c)\n0.00\n0.25\n0.50\n0.75\n1.00\n-10\n-5\n0\n5\n10\nδ n\nPower\nθ = 0.09 \n(d)\nmethod\nALASSO\nEBPP\nLTR\nHDPP\nLSTP\nAMMSE\nNP\nPooled\nMLE\nTTPool\nFigure 3:\nType I error rate and power as a function of δ at different θ, with critical value obtained assuming δ < 0.06\nunder H0. The vertical line is at δ√n = 0.06\n√\n1000. Results are based on 5 × 104 Monte Carlo samples.\n14\n\n\n(a)\n−0.3\n−0.2\n−0.1\n0.0\n0.1\n0.2\n0.3\n0.0\n0.5\n1.0\n1.5\n2.0\n2.5\n3.0\ndeltas\nStandardized RMSE\n(b)\n−0.4\n−0.2\n0.0\n0.2\n0.4\n0.30\n0.35\n0.40\n0.45\n0.50\ntau\nestimator\nFigure 4: (a) SRMSE of ˆθammse\nn\n\u0000n−2τ\u0001\nfor τ ∈[−5, 5]; solid blue is for τ = 0(s = 1); solid dashed blue is for τ =\n0.1(s ≈0.4). (b) Infant Mortality and 95% confidence intervals; ˆθ (black dotted, n = 94); ˆβ (red dotted, m = 20, 000);\nˆθammse\nn\n\u0000n−2τ\u0001\n(blue)\nTTPool\nALASSO\nLTR\nNP\nEBPP\nHDPP\nLSTP\nMLE\nPooled\nAMMSE\nOMMSE\n-5.0\n-2.5\n0.0\n2.5\n5.0\n-5.0\n-2.5\n0.0\n2.5\n5.0\n-5.0\n-2.5\n0.0\n2.5\n5.0\n-5.0\n-2.5\n0.0\n2.5\n5.0\n0\n2\n4\n6\n8\n0\n2\n4\n6\n8\n0\n2\n4\n6\n8\nδ n\nLog-density\nδ n\n0\n0.32\n1.58\n5.06\nFigure 5:\nDistributions (log-densities) of estimators of θ = 0 under four conflict values: δ ∈{0, 0.32, 1.58, 5.06}; n=103,\nm=105, and 5 × 104 Monte Carlo samples.\n15\n\n\nBibliography\nStuart J Pocock and Richard Simon.\nSequential treatment assignment with balancing for prognostic factors in the\ncontrolled clinical trial. Biometrics, pages 103–115, 1975.\nBoris Freidlin and Edward L Korn. Borrowing information across subgroups in phase ii trials: is it useful?\nClinical\nCancer Research, 19(6):1326–1334, 2013.\nHuaqing Jin, Mi-Ok Kim, Aaron Scheffler, and Fei Jiang. Bayesian adaptive design for covariate-adaptive historical\ncontrol information borrowing. Statistics in Medicine, 42(29):5338–5352, 2023.\nNW Galwey. Supplementation of a clinical trial by historical control data: is the prospect of dynamic borrowing an\nillusion? Statistics in Medicine, 36(6):899–916, 2017.\nKert Viele, Scott Berry, Beat Neuenschwander, Billy Amzal, Fang Chen, Nathan Enas, Brian Hobbs, Joseph G Ibrahim,\nNelson Kinnersley, Stacy Lindborg, et al. Use of historical control data for assessing treatment effects in clinical trials.\nPharmaceutical statistics, 13(1):41–54, 2014.\nSS Tarima and YG Dmitriev. Statistical estimation with possibly incorrect model assumptions. Bul. Tomsk St. University:\ncont., comput., inf., 8:78–99, 2009.\nYury Dmitriev and Peter Tarassenko. On adaptive estimation using a prior guess. In Proceedings The International Work-\nshop, Applied Methods of Statistical Analysis. Nonparametric Approach, pages 14–15. Novosibirsk, Russia. Novosibirsk,\n2015.\nHui Zou. The adaptive lasso and its oracle properties. Journal of the American statistical association, 101(476):1418–1429,\n2006.\nRuilin Li, Ray Lin, Jiangeng Huang, Lu Tian, and Jiawen Zhu. A frequentist approach to dynamic borrowing. Biometrical\nJournal, page 2100406, 2023.\nJoseph G. Ibrahim and Ming-Hui Chen. Power Prior Distributions for Regression Models. Statistical Science, 15(1):\n46–60, 2000. ISSN 08834237. URL http://www.jstor.org/stable/2676676.\nJoseph Ibrahim, Ming Hui Chen, Yeongjin Gwon, and Fang Chen. The Power Prior: Theory and Applications. Statistics\nin Medicine, 34(28):3724–3749, 09 2015. doi: 10.1002/sim.6728.\nIsaac Gravestock, Leonhard Held, and COMBACTE-Net consortium. Adaptive power priors with empirical bayes for\nclinical trials. Pharmaceutical statistics, 16(5):349–360, 2017.\nSilvia Calderazzo, Sergey Tarima, Carissa Reid, Nancy Flournoy, Tim Friede, Nancy Geller, James L Rosenberger, Nigel\nStallard, Moreno Ursino, Marc Vandemeulebroecke, et al.\nCoping with information loss and the use of auxiliary\nsources of data: A report from the niss ingram olkin forum series on unplanned clinical trial disruptions. Statistics in\nBiopharmaceutical Research, pages 1–17, 2023.\nBradley Efron and Carl Morris. Limiting the risk of bayes and empirical bayes estimators—part ii: The empirical bayes\ncase. Journal of the American Statistical Association, 67(337):130–139, 1972.\nJing Qin, Yukun Liu, and Pengfei Li. A selective review of statistical methods using calibration information from similar\nstudies. Statistical Theory and Related Fields, pages 1–16, 2022.\nS Tarima and D Pavlov. Using auxiliary information in statistical function estimation. ESAIM: Probab. Stat., 10:11–23,\n2006.\n16\n\n\nChixiang Chen, Peisong Han, Shuo Chen, Michelle Shardell, and Jing Qin. Integrating external summary information in\nthe presence of prior probability shift: an application to assessing essential hypertension. Biometrics, 80(3):ujae090,\n2024.\nThomas S Ferguson. A course in large sample theory. Routledge, 2017.\nYakov Yurievich Nikitin. Asymptotic efficiency of nonparametric tests. Cambridge University Press, 1995.\nLe Cam. Locally asymptotically normal families of distributions. certain approximations to families of distributions and\ntheir use in the theory of estimation and testing hypotheses. Univ. California Publ. Statist., 3:37, 1960.\nA.W. Van der Vaart. Asymptotic Statistics. Cambridge University Press, 1998.\nZbynek Sidak, Pranab K Sen, and Jaroslav Hajek. Theory of rank tests. Elsevier, 1999.\nLucien M. Le Cam. Locally asymptotically normal families of distributions. Univ. California Publ. Statist., 3:37–98,\n1960.\nJonas Kahn and M˘ad˘alin Gut¸˘a. Local asymptotic normality for finite dimensional quantum systems. Communications\nin Mathematical Physics, 289(2):597–652, 2009.\nSergey Tarima and Nancy Flournoy. The cost of sequential adaptation and the lower bound for mean squared error.\nStatistical Papers, pages 1–25, 2024.\nSergey Tarima, Bonifride Tuyishimire, Rodney Sparapani, Lisa Rein, and John Meurer. Estimation combining unbiased\nand possibly biased estimators. Journal of Statistical Theory and Practice, 14(2):1–20, 2020.\nRobert Tibshirani. Regression shrinkage and selection via the lasso. Journal of the Royal Statistical Society Series B:\nStatistical Methodology, 58(1):267–288, 1996.\nLauren Kanapka and Anastasia Ivanova. A frequentist design for basket trials using adaptive lasso. Statistics in Medicine,\n43(1):156–172, 2024.\nBeat Neuenschwander, Gorana Capkun-Niggli, Michael Branson, and David J Spiegelhalter. Summarizing historical\ninformation on controls in clinical trials.\nClinical Trials, 7(1):5–18, 2010.\ndoi: 10.1177/1740774509356002.\nURL\nhttps://doi.org/10.1177/1740774509356002. PMID: 20156954.\nHeinz Schmidli, Sandro Gsteiger, Satrajit Roychoudhury, Anthony O’Hagan, David Spiegelhalter, and Beat Neuen-\nschwander. Robust meta-analytic-predictive priors in clinical trials with historical control information. Biometrics, 70\n(4):1023–1032, 2014. ISSN 0006341X, 15410420. URL http://www.jstor.org/stable/24538386.\nBrian P. Hobbs, Daniel J. Sargent, and Bradley P. Carlin. Commensurate priors for incorporating historical information\nin clinical trials using general and generalized linear models. Bayesian Analysis, 7(3):639 – 674, 2012. doi: 10.1214/\n12-BA722. URL https://doi.org/10.1214/12-BA722.\nBeat Neuenschwander and Heinz Schmidli. Use of historical data. In Bayesian Methods in Pharmaceutical Research,\npages 111–137. Chapman and Hall/CRC, 2020.\nManuel Wiesenfarth and Silvia Calderazzo. Quantification of prior impact in terms of effective current sample size.\nBiometrics, 76(1):326–336, 2020. doi: https://doi.org/10.1111/biom.13124. URL https://onlinelibrary.wiley.\ncom/doi/abs/10.1111/biom.13124.\nSamuel Pawel, Frederik Aust, Leonhard Held, and Eric-Jan Wagenmakers. Power priors for replication studies. TEST,\n33(1):127–154, 2024.\nLaura Thompson, Jianxiong Chu, Jianjin Xu, Xuefeng Li, Rajesh Nair, and Ram Tiwari. Dynamic borrowing from a\nsingle prior data source using the conditional power prior. Journal of Biopharmaceutical Statistics, 31(4):403–424,\n2021.\nStavros Nikolakopoulos, Ingeborg van der Tweel, and Kit CB Roes. Dynamic borrowing through empirical power priors\nthat control type i error. Biometrics, 74(3):874–880, 2018.\nAdrien Ollier, Satoshi Morita, Moreno Ursino, and Sarah Zohar. An adaptive power prior for sequential clinical trials–\napplication to bridging studies. Statistical methods in medical research, 29(8):2282–2294, 2020.\n17\n\n\nA. P. Dawid. Posterior expectations for large observations. Biometrika, 60(3):664–667, 12 1973. ISSN 0006-3444. doi:\n10.1093/biomet/60.3.664. URL https://doi.org/10.1093/biomet/60.3.664.\nAnthony O’Hagan. On outlier rejection phenomena in bayes inference. Journal of the Royal Statistical Society. Series B\n(Methodological), 41(3):358–367, 1979. ISSN 00359246. URL http://www.jstor.org/stable/2985064.\nSS Tarima, A Vexler, and S Singh.\nRobust mean estimation under a possibly incorrect log-normality assumption.\nCommun. Stat.–Simul. C., 42(2):316–326, 2013.\nKelly Van Lancker, Sergey Tarima, Jonathan Bartlett, Madeline Bauer, Bharani Bharani-Dharan, Frank Bretz, Nancy\nFlournoy, Hege Michiels, Camila Olarte Parra, James L Rosenberger, et al. Rejoinder: Estimands and their estimators\nfor clinical trials impacted by the covid-19 pandemic: A report from the niss ingram olkin forum series on unplanned\nclinical trial disruptions. Statistics in Biopharmaceutical Research, 15(1):119–124, 2023.\nMorris H DeGroot. Optimal statistical decisions. John Wiley & Sons, 2005.\nGiovanni Parmigiani and Lurdes Inoue. Decision theory: principles and approaches, volume 812. John Wiley & Sons,\n2009.\nAnnette Kopp-Schneider, Silvia Calderazzo, and Manuel Wiesenfarth. Power gains by using external information in\nclinical trials are typically not possible when requiring strict type i error control. Biometrical Journal, 62(2):361–374,\n2020.\nAnnette Kopp-Schneider, Manuel Wiesenfarth, Leonhard Held, and Silvia Calderazzo. Simulating and reporting frequen-\ntist operating characteristics of clinical trials that borrow external information: Towards a fair comparison in case of\none-arm and hybrid control two-arm trials. Pharmaceutical Statistics, 2023. doi: https://doi.org/10.1002/pst.2334.\nURL https://onlinelibrary.wiley.com/doi/abs/10.1002/pst.2334.\nHolly B. Shulman, Denise V. D’Angelo, Leslie Harrison, Ruben A. Smith, and Lee Warner. The Pregnancy Risk Assess-\nment Monitoring System (PRAMS): Overview of Design and Methodology. American Journal of Public Health, 108(10):\n1305–1313, August 2018. ISSN 0090-0036. doi: 10.2105/AJPH.2018.304563. URL https://ajph.aphapublications.\norg/doi/abs/10.2105/AJPH.2018.304563.\nL. R. Pericchi and A. F. M. Smith. Exact and approximate posterior moments for a normal location parameter. Journal\nof the Royal Statistical Society. Series B (Methodological), 54(3):793–804, 1992. ISSN 00359246. URL http://www.\njstor.org/stable/2345859.\n18\n\n\n",
  "metadata": {
    "source_file": "dataset/pdfs/arxiv_2502.21282v1.pdf",
    "total_pages": 18,
    "title": "Large Sample Inference with Dynamic Information Borrowing",
    "authors": [
      "Sergey Tarima",
      "Silvia Calderazzo",
      "Mary Homan"
    ],
    "abstract": "Large sample behavior of dynamic information borrowing (DIB) estimators is\ninvestigated. Asymptotic properties of several DIB approaches (adaptive risk\nminimization, adaptive LASSO, Bayesian procedures with empirical power prior,\nfully Bayesian procedures, and a Bayes-frequentist compromise) are explored\nagainst shrinking to zero alternatives. As shown theoretically and with\nsimulations, local asymptotic distributions of DIB estimators are often\nnon-normal. A simple Gaussian setting with external information borrowing\nillustrates that none of the considered DIB methods outperforms others in terms\nof mean squared error (MSE): at different conflict values, the MSEs of DIBs are\nchanging between the MSEs of the maximum likelihood estimators based on the\ncurrent and pooled data. To uniquely determine an optimality criterion for DIB,\na prior distribution on the conflict needs be either implicitly or explicitly\ndetermined using data independent considerations. Data independent assumptions\non the conflict are also needed for DIB-based hypothesis testing. New families\nof DIB estimators parameterized by a sensitivity-to-conflict parameter S are\nsuggested and their use is illustrated in an infant mortality example. The\nchoice of S is determined in a data-independent manner by a cost-benefit\ncompromise associated with the use of external data.",
    "published_date": "2025-02-28",
    "source": "arxiv"
  }
}