{
  "id": "arxiv_2502.20938v1",
  "text": "A Deep User Interface for Exploring LLaMa\nDivya Perumal & Swaroop Panda\nNorthumbria University\nAbstract. The growing popularity and widespread adoption of large\nlanguage models (LLMs) necessitates the development of tools that en-\nhance the effectiveness of user interactions with these models. Under-\nstanding the structures and functions of these models poses a significant\nchallenge for users. Visual analytics-driven tools enables users to explore\nand compare, facilitating better decision-making. This paper presents a\nvisual analytics-driven tool equipped with interactive controls for key\nhyperparameters, including top-p, frequency and presence penalty, en-\nabling users to explore, examine and compare the outputs of LLMs. In\na user study, we assessed the tool’s effectiveness, which received favor-\nable feedback for its visual design, with particular commendation for the\ninterface layout and ease of navigation. Additionally, the feedback pro-\nvided valuable insights for enhancing the effectiveness of Human-LLM\ninteraction tools.\nKeywords: Large Language Models · User Interface · Hyperparameters\n· Explainable AI · Visual Analytics\n1\nIntroduction\nThe emergence of Large Language Models (LLMs), such as OpenAI’s GPT,\nGoogle’s BERT, and Meta’s Llama, has fundamentally transformed the field\nof natural language processing. These models have introduced significant ad-\nvancements in areas such as text generation [24], summarization [44], and other\nrelated applications. In everyday tasks, these LLMs have also found widespread\napplication, significantly enhancing user experiences across various domains. For\ninstance, they are embedded in conversational voice assistants allowing users to\ninteract with technology through natural, conversational language [38,29].\nDespite the impressive capabilities of LLMs, their complex nature often\npresents challenges in terms of interpretability and usability [41]. As these mod-\nels continue to grow in size and complexity, the need for effective tools to facil-\nitate the communication and visualization of their inputs and outputs becomes\nincreasingly urgent. For example, LLMs are being increasingly utilized in the\nmedical field for diagnosing diseases [6], recommending treatments [40], and gen-\nerating medical reports [36], as well as in data science, where they contribute to\ndata analysis[28], trend prediction[18], and decision support [39]. However, the\nopaque, black-box nature of LLMs [5,26] presents a considerable barrier to vali-\ndating the accuracy and reliability of their results. There remains a substantial\narXiv:2502.20938v1  [cs.HC]  28 Feb 2025\n\n\n2\nD Perumal & S Panda\ngap in understanding [27] how these models function and how they can be mod-\nified to produce different outcomes. The impact of these applications is largely\ncontingent on the precision and appropriateness of the models, underscoring the\ncritical need for transparency [23] and accountability [10] in AI systems, partic-\nularly as they become increasingly integrated into daily life.\nExplainable AI and visual analytics [1,12] methods have been adapted to\nmitigate this black box nature of LLMs. These approaches facilitate a deeper\nunderstanding of model behavior by providing insights [42] into decision-making\nprocesses and enabling users to visualize the relationships between input parame-\nters and output predictions, thereby enhancing interpretability [2] and trustwor-\nthiness [31]. By employing techniques such as interactive visualizations[14,4] or\nexplorations[17], these methods empower users to gain a clearer understanding of\nhow LLMs generate responses. This increased transparency is essential for foster-\ning user confidence[21] and ensuring responsible AI [3] deployment, particularly\nin sensitive applications such as healthcare, finance, and legal decision-making.\nIn this paper,we present a visual analytics-driven tool to facilitate an under-\nstanding of working of LLMs by examining their underlying hyperparameters.\nThe contributions of the paper are,\n1. We design and develop a deep user interface to facilitate the hyperparameter\ndriven exploration of a Large Language Model\n2. We evaluate this user interface through user feedback and incorporate their\nsuggestions to enhance its design.\n3. We provide preliminarily actionable insights for researchers to design and\ndevelop user interfaces for LLMs.\n2\nBackground\n2.1\nVisual Analytics based User Interfaces\nVisual Analytics (VA) combines visualization, human interaction, and data anal-\nysis to support analytical reasoning through interactive visual interfaces [9]. Vi-\nsual analytics tools such as model performance dashboards help in identifying\nissues like overfitting, bias, or data leakage by visually representing mode per-\nformance metrics enhance the AI interpretability [43]. VA has also been used to\nunderstand the inner workings of neural networks by visualizing activations and\nweights help the interpretation of the model decisions [13]. VA supports these\ncognitive processes by providing interactive tools that clear the way for deeper\ninsights and better decision-making [11].\n2.2\nInterpretability and Exploration for LLMs\nInterpretability in machine learning refers to the capacity to comprehend, trust,\nand manage a model’s outputs and decision-making processes. The inherent\nblack-box nature of LLMs, attributed to their deep neural network architectures\ncomprising millions or even billions of parameters, presents significant challenges\n\n\nA Deep User Interface for Exploring LLaMa\n3\nin this regard. Various interpretability methodologies have been developed, in-\ncluding post-hoc approaches, which generate explanations after a model has\nproduced a prediction. Many of these methods do not directly interpret the\nmodel itself but rather attempt to elucidate its decision-making process. Several\ntechniques, such as SHapley Additive exPlanations (SHAP) [20] and Local Inter-\npretable Model-agnostic Explanations (LIME) [35], assign importance scores to\ninput features. In the context of LLMs, these methods are commonly employed\nto analyze the significance of specific words, phrases, or tokens. The resulting\nvisualizations aid in understanding how different linguistic elements influence\npredictions, thereby offering insights into complex model behavior. These tech-\nniques may not always capture the true reasoning of the model, potentially lead-\ning to misleading interpretations. Moreover, the application of these methods to\nLLMs, which involve extensive parameter sets and input tokens, is computation-\nally expensive and complex. Many LLMs, such as BERT, utilize self-attention\nmechanisms to assign varying levels of importance to different words within a\nsentence [16]. Researchers have explored the interpretation of attention weights\nas proxies for understanding model decisions [8,22]. However, the extent to which\nthese weights provide meaningful insights into a model’s reasoning remains an\narea of ongoing investigation.\n2.3\nUser Interfaces for LLMs\nOne of the key challenges in utilizing LLMs is the selection of optimal hyper-\nparameters, which significantly influence model performance [25]. Visual ana-\nlytics facilitates hyper-parameter tuning by providing interactive visualizations\nthat help both experts and non-experts discern parameter relationships, enhanc-\ning model optimization. For example, Google Vizier employs parallel coordinates\nplots to analyze hyper-parameters, elucidating the relationships between inputs\nand outputs [15]. Sacha et al. [34] proposed an interactive machine learning\nframework that incorporates human feedback via visualization, improving pa-\nrameter refinement. Similarly, Kahng et al. [19] introduced a tool for comparing\nand evaluating LLM outputs during fine-tuning, addressing visualization chal-\nlenges but still limited in scope and standardization. Chen et al. [7] explored\nvisual analytics in ChatGPT through StudentGPT, a tool that analyzes student\ninteractions to derive cognitive insights. Despite the availability of such tools,\nthere remains a gap in integrating visual analytics for hyper-parameter analysis\nwhere human intuition is crucial [32].\nAlthough visual analytics has been explored in various machine learning\ncontexts, its application to hyper-parameter tuning in LLMs remains relatively\nunder-explored, with limited dedicated tools. Hyperparameter tuning is crucial\nfor optimizing model performance, yet it often remains an empirical process\nwith limited interpretability. Visual analytics could aid in exploring the hyper-\nparameter space and understanding parameter interactions, though its impact\non tuning efficiency requires further validation.\n\n\n4\nD Perumal & S Panda\n3\nDesign & Development of the User Interface\nThe visual analytics tool was designed and developed to enable users to adjust\nmodel hyperparameters visually, making it easier to see how changes affect the\nLLM’s outputs. This involved creating intuitive visualizations for each hyperpa-\nrameter to facilitate user interaction. For this tool, we choose the open source\nlarge language model Llama [37].\n3.1\nHyperparameters\nWe selected two hyperparameters, top p and frequency and presence penalty\nbased on their availability via the LLaMA API.\nTop-P: The top-p hyperparameter [33], also known as nucleus sampling, is\na technique used in NLP to control text generation. It plays the role of selecting\nthe next word in a sequence impacting the creativity of the generated text.\nIn LLMs, content generation is the prediction of the next word in a sequence\nbased on the words that generated previously. The model generates a list of all\npossible tokens and ranks them by their predicted probability. Top-p sampling\nis a method used to choose the next word based on these probabilities. The\nmodel accumulates the probabilities until the sum reaches a threshold value, p,\nwhich is set by the top-p parameter. At this point, the model forms a candidate\npool of tokens, and the next token is randomly selected from this pool. This\nrandomness introduces variation in the generated text, making it more creative.\nThe top-p vocabulary V (p) is the smallest subset of the total vocabulary V\nwhere the cumulative probability mass meets or exceeds the threshold value p\n(Eq. 1). The selection of the next word depends on ensuring that the cumulative\nprobability is at least p, which adds randomness and diversity to the generated\ntext.\nX\nx∈V (p)\nP(x | x1:i−1) ≥p.\n(1)\nFrequency and Presence penalty: Frequency and presence penalty [30]\nare two hyperparameters used in language models to control the repetition and\ndiversity of the generated text. Both are designed to influence how often certain\nwords or phrases appear in the generated text. Frequency penalty reduces the\nrepetition of the same token within the generated text. The presence penalty\nencourages the model to introduce a new token into the generated text. The\npresence penalty works by reducing the probability of selecting a token that has\nalready appeared in the text, regardless of how many times it has been used. To\nadjust token probabilities for diversity and repetition control, we define the new\nmodified probability P ′(t) for token t as:\nP ′(t) =\nP(t)\n(1 + α · f(t))(1 + β · 1{f(t)>0})\n(2)\nwhere P(t) is the original probability, f(t) is the frequency of t in prior text,\nα is the frequency penalty, and β is the presence penalty and 1{f(t)>0} is an\n\n\nA Deep User Interface for Exploring LLaMa\n5\nindicator function that equals 1 if token t has appeared at least once in the text\nand 0 otherwise. The frequency penalty reduces P(t) proportional to f(t), while\nthe presence penalty reduces P(t) if t has already appeared, enhancing diversity\nin the generated text.\n3.2\nDevelopment & Visual Design\nThe tool was developed using Python for backend logic and integration with the\nLlama API from Meta LLAMA-7B, Flask for building the web interface, d3js for\ninteractive data visualizations in web browsers and MongoDB for storing user\ninteractions and survey responses.\nTo visualize the top-p hyperparameter we use a knob (clock-like) interface\nthat allows users to adjust the parameter values (which controls the nucleus\nsampling in the language model). This visual representation aims to provide\nan intuitive way for users to adjust and understand the impact of the top-p\nhyperparameter on text generation, allowing for more or less randomness in the\noutput based on the setting.\nTo visualize the frequency and presence penalty we use a co-ordinate plane\ngraph with x and y axis which represent presence and frequency penalty re-\nspectively. This scatter plot-type of visualization aids users in comprehending\nthe relationship between these two hyperparameters as reflected in the model’s\noutput.\nIn Fig. 1 (A) is the prompt section where the user enters their prompts to\ninteract with the LLM. (B) represents the hyperparameters section, which is\ndesigned to be visually engaging. (C) is the graphical representation to adjust\nthe presence and frequency penalty. (D) denotes the previous point used, which\nenables the user to compare outputs given the hyperparameter value.\nFig. 2 (E) denotes the output of the LLaMA. The content given in the image\nis for sample. (F) is the rating scale for the users to score the generated output;\nfor the user study.\nFig. 3 (G) represents the graph with points of frequency and presence pre-\nviously used for the given prompt (from Fig. 1 D). The shade of the points\nrepresents the score given to the output by the user. Fig. 3 (H) indicates the\ntable with all the prompts, parameter values used and rating for each output.\n4\nEvaluation of the User Interface\n4.1\nUser Study\nWith approval from the relevant institutional ethics committee, participants\nwere selected from among students enrolled in postgraduate programs, ensuring\na decent understanding of LLM usage. Participants had academic backgrounds\nin computer and data science. A total of 10 participants took part in the exper-\niment. Participants were of the age group mean:24.3 yrs, stddev:0.82.\nParticipants received a list of ten predefined prompts and were instructed to\nselect three. They subsequently inputted these chosen prompts into the visual\n\n\n6\nD Perumal & S Panda\nFig. 1. Visualization of Hyperparameters in the UI\nFig. 2. Visual Representation of LLM Outputs with the Scale for User Rating\nanalytics tool. Utilizing the tool’s visualized interfaces, participants adjusted\nhyperparameters— top-p, frequency penalty, and presence penalty—to exam-\nine their impacts on the model’s outputs. After setting these hyperparameters,\nparticipants submitted the prompts to the LLaMA to generate corresponding\ntext outputs. Each output was subsequently evaluated on a standardized rating\nscale.These tasks and exploration were designed to assess how effectively par-\nticipants could use the tool to change hyperparameters and compare, explore,\n\n\nA Deep User Interface for Exploring LLaMa\n7\nFig. 3. Visual Representation of Score Graph and Table\nevaluate the generated outputs. Followed by the experiment participants were\nasked to complete survey with combination of likert scale and qualitative ques-\ntions to gain feedback on the tool’s functionalities, interface and overall user\nexperience.\n4.2\nResults & Analysis\nBased on the user study results, participants provided overall positive feedback,\nparticularly regarding the tool’s interface and its visual appeal (Table 1). Users\nfound the interface visually engaging, with the layout receiving especially high\nratings, indicating that the design is well-organized and easy to navigate. The\ninterface of the tool is found to be visually appealing to the users, with a mean\nrating of 4.22 and a relatively low standard deviation of 0.83, indicating the most\nrespondents appreciated the design. The layout of the interface was rated even\nhigher, with a mean of 4.56 and a standard deviation of 0.53, reflecting that the\ninterface was well organized and easy to navigate.\nQualitative feedback yielded valuable insights; users expressed a desire for\nmore clarification regarding the functionality of the hyperparameters. Partic-\nipants highlighted features that enhanced their experience with the system.\nThey appreciated the ability to see varying outputs for prompts. One participant\nstated that \"It was a good experience to see varying outputs for the prompts. The\noutputs differed on the parameters which provided different kinds of outputs which\ncould then be rated as creative, average, or satisfying.\". The feature of adjusting\nhyperparameters using visualizations stood out as particularly convenient, with\na participant noting, \"the feature of adjusting parameters using visualizations\nwas the most convenient one, along with the option of accessing history, which\n\n\n8\nD Perumal & S Panda\nhelped to compare the previous parameters.\" Access to history was also valued\nfor its role in facilitating comparisons between different parameter settings. The\nuser interface was praised for its simplicity, making the selection of parameters\nstraightforward. One participant suggested \"selecting the parameters was easy as\nit was simple as the user interface was simple. For the prompts provided, it was\nhelpful to play around with the parameters to check various outputs.\". Another\nparticipant stated, \"most helpful parameter my opinion would be changing the\nanswers as user changes the parameter.\"\nFollowing the user study, we refined the tool based on user feedback to en-\nhance clarity and usability. One key improvement was the addition of written\ndescriptions for each hyperparameter, providing users with a clearer understand-\ning of their influence on the model’s behavior. This change aims to make the tool\nmore accessible, especially for those with limited prior knowledge, enabling more\ninformed adjustments and interactions.\nQuestion\nMean StdDev\nHow visually appealing do you find the interface of the visual\nanalytics tool?\n4.22\n0.83\nHow well-organized is the layout of the tool’s interface?\n4.55\n0.52\nHow readable and appropriate is the typography used in the\ntool?\n4.66\n0.5\nHow easy was it for you to navigate and use the visual analytics\ntool?\n4.33\n0.86\nHow effective are the tool’s features in helping you achieve your\ngoals?\n4.33\n0.70\nHow effective is the answer changing according to the given pa-\nrameters?\n4.22\n0.66\nHow clear and understandable are the visualizations provided\nby the tool?\n4.33\n0.5\nHow would you rate the interactivity of the visualizations?\n4.3\n0.67\nTable 1. Results of the User Study on a 5-point Likert Scale\n5\nDiscussion\nWhile the findings of the user study offer valuable perspectives, it is important\nto interpret them with caution due to the limited sample size. While the tool’s\nnavigation was generally rated as easy with a mean score of 4.33, the standard\ndeviation of 0.86 suggests that a minority of users encountered difficulties. The\ntool’s functional effectiveness, particularly in how well the features helped users\nachieve their goals, the responses were favorable. This indicates that the tool\nwas generally effective though there were some variations in user experience,\n\n\nA Deep User Interface for Exploring LLaMa\n9\nsuggesting that certain features might benefit from further enhancement to en-\nsure consistent effectiveness.\n5.1\nActionable Insights\nPreliminary insights suggest some considerations for the design of user interfaces\nfor LLMs. These following actionable insights provide guidance on optimizing\ninteraction paradigms, improving usability, and enhancing the overall user ex-\nperience.\n1. Providing users with access to adjustable hyperparameters within the inter-\nface appears to facilitate exploration, particularly when these hyperparam-\neters have a substantial impact on the generated outputs. This feature may\nenhance user engagement and comprehension of model behavior.\n2. While enabling hyperparameter-based exploration, it is beneficial to incorpo-\nrate a history of generated responses. Such a feature allows users to compare\noutputs systematically, fostering a clearer understanding of how hyperpa-\nrameter adjustments influence the model’s responses over time.\n5.2\nFuture Work\nFuture research includes exploring more hyperparameters of LLMs and devel-\noping visualizations that enhance user understanding, thereby facilitating more\ntargeted LLM outputs. Furthermore, a more comprehensive user study involv-\ning diverse participants could reveal patterns in hyperparameter adjustments\nand user ratings, thereby providing deeper insights into user behavior and pref-\nerences.\n6\nConclusion\nThe aim of our study was to explore how visual analytics could be integrated into\nthe process of tuning hyperparameters in LLMs to improve user experience and\nmake these models more interpretable. From our initial findings, we discovered\nthat a more intuitive user interface—one that lets users adjust model settings,\nview and compare results—can transform complex models like LLama from a\n\"black box\" into something more transparent and user-friendly. The positive\nfeedback we received on the design of this tool shows great potential for its wider\nuse, making these advanced models more accessible and easier to understand.\n\n\n10\nD Perumal & S Panda\nReferences\n1. Alicioglu, G., Sun, B.: A survey of visual analytics for explainable artificial intel-\nligence methods. Computers & Graphics 102, 502–520 (2022)\n2. Andrienko, N., Andrienko, G., Adilova, L., Wrobel, S.: Visual analytics for human-\ncentered machine learning. IEEE Computer Graphics and Applications 42(1), 123–\n133 (2022)\n3. Arrieta, A.B., Díaz-Rodríguez, N., Del Ser, J., Bennetot, A., Tabik, S., Barbado,\nA., García, S., Gil-López, S., Molina, D., Benjamins, R., et al.: Explainable artifi-\ncial intelligence (xai): Concepts, taxonomies, opportunities and challenges toward\nresponsible ai. Information fusion 58, 82–115 (2020)\n4. Batch, A., Elmqvist, N.: The interactive visualization gap in initial exploratory\ndata analysis. IEEE transactions on visualization and computer graphics 24(1),\n278–287 (2017)\n5. Bhattacharjee, A., Moraffah, R., Garland, J., Liu, H.: Llms as counterfactual ex-\nplanation modules: Can chatgpt explain black-box text classifiers? arXiv preprint\narXiv:2309.13340 (2023)\n6. Chen, X., Mao, X., Guo, Q., Wang, L., Zhang, S., Chen, T.: Rarebench: Can\nllms serve as rare diseases specialists? In: Proceedings of the 30th ACM SIGKDD\nConference on Knowledge Discovery and Data Mining. pp. 4850–4861 (2024)\n7. Chen, Z., Wang, J., Xia, M., Shigyo, K., Liu, D., Zhang, R., Qu, H.: Stugptviz: A\nvisual analytics approach to understand student-chatgpt interactions. IEEE Trans-\nactions on Visualization and Computer Graphics (2024)\n8. Coscia, A., Holmes, L., Morris, W., Choi, J.S., Crossley, S., Endert, A.: iscore:\nVisual analytics for interpreting how language models automatically score sum-\nmaries. In: Proceedings of the 29th International Conference on Intelligent User\nInterfaces. pp. 787–802 (2024)\n9. Cui, W.: Visual analytics: A comprehensive overview. IEEE access 7, 81555–81573\n(2019)\n10. Doshi-Velez, F., Kortz, M., Budish, R., Bavitz, C., Gershman, S., O’Brien, D.,\nScott, K., Schieber, S., Waldo, J., Weinberger, D., et al.: Accountability of ai under\nthe law: The role of explanation. arXiv preprint arXiv:1711.01134 (2017)\n11. Endert, A., Ribarsky, W., Turkay, C., Wong, B.W., Nabney, I., Blanco, I.D., Rossi,\nF.: The state of the art in integrating machine learning into visual analytics. In:\nComputer Graphics Forum. vol. 36, pp. 458–486. Wiley Online Library (2017)\n12. Epp, C.D., Bull, S.: Uncertainty representation in visualizations of learning ana-\nlytics for learners: Current approaches and opportunities. IEEE Transactions on\nLearning Technologies 8(3), 242–260 (2015)\n13. Garcia, R., Telea, A.C., da Silva, B.C., Tørresen, J., Comba, J.L.D.: A task-and-\ntechnique centered survey on visual analytics for deep learning model engineering.\nComputers & Graphics 77, 30–49 (2018)\n14. Godfrey, P., Gryz, J., Lasek, P.: Interactive visualization of large data sets. IEEE\ntransactions on knowledge and data engineering 28(8), 2142–2157 (2016)\n15. Golovin, D., Solnik, B., Moitra, S., Kochanski, G., Karro, J., Sculley, D.: Google\nvizier: A service for black-box optimization. In: Proceedings of the 23rd ACM\nSIGKDD international conference on knowledge discovery and data mining. pp.\n1487–1495 (2017)\n16. Insuasti, J., Roa, F., Zapata-Jaramillo, C.M.: Computers’ interpretations of knowl-\nedge representation using pre-conceptual schemas: An approach based on the bert\nand llama 2-chat models. Big Data and Cognitive Computing 7(4), 182 (2023)\n\n\nA Deep User Interface for Exploring LLaMa\n11\n17. Jankun-Kelly, T., Ma, K.L., Gertz, M.: A model and framework for visualization\nexploration. IEEE Transactions on Visualization and Computer Graphics 13(2),\n357–369 (2007)\n18. Jin, M., Tang, H., Zhang, C., Yu, Q., Liu, C., Zhu, S., Zhang, Y., Du, M.: Time se-\nries forecasting with llms: Understanding and enhancing model capabilities. arXiv\npreprint arXiv:2402.10835 (2024)\n19. Kahng, M., Tenney, I., Pushkarna, M., Liu, M.X., Wexler, J., Reif, E., Kallarackal,\nK., Chang, M., Terry, M., Dixon, L.: Llm comparator: Visual analytics for side-\nby-side evaluation of large language models. In: Extended Abstracts of the CHI\nConference on Human Factors in Computing Systems. pp. 1–7 (2024)\n20. Khediri, A., Slimi, H., Yahiaoui, A., Derdour, M., Bendjenna, H., Ghenai, C.E.:\nEnhancing machine learning model interpretability in intrusion detection systems\nthrough shap explanations and llm-generated descriptions. In: 2024 6th Interna-\ntional Conference on Pattern Analysis and Intelligent Systems (PAIS). pp. 1–6.\nIEEE (2024)\n21. Kizilcec, R.F.: How much information? effects of transparency on trust in an algo-\nrithmic interface. In: Proceedings of the 2016 CHI conference on human factors in\ncomputing systems. pp. 2390–2395 (2016)\n22. La Rosa, B., Blasilli, G., Bourqui, R., Auber, D., Santucci, G., Capobianco, R.,\nBertini, E., Giot, R., Angelini, M.: State of the art of visual analytics for explainable\ndeep learning. In: Computer Graphics Forum. vol. 42, pp. 319–355. Wiley Online\nLibrary (2023)\n23. Larsson, S., Heintz, F.: Transparency in artificial intelligence. Internet policy review\n9(2) (2020)\n24. Li, J., Tang, T., Zhao, W.X., Nie, J.Y., Wen, J.R.: Pre-trained language models\nfor text generation: A survey. ACM Computing Surveys 56(9), 1–39 (2024)\n25. Li, T., Convertino, G., Wang, W., Most, H., Zajonc, T., Tsai, Y.H.: Hypertuner:\nVisual analytics for hyperparameter tuning by professionals. In: 2018 IEEE Work-\nshop on Machine Learning from User Interaction for Visualization and Analytics\n(MLUI). pp. 1–11. IEEE (2018)\n26. Liu, H., Yin, Q., Wang, W.Y.: Towards explainable nlp: A generative explanation\nframework for text classification. arXiv preprint arXiv:1811.00196 (2018)\n27. Liu, Y., He, H., Han, T., Zhang, X., Liu, M., Tian, J., Zhang, Y., Wang, J., Gao,\nX., Zhong, T., et al.: Understanding llms: A comprehensive overview from training\nto inference. arXiv preprint arXiv:2401.02038 (2024)\n28. Ma, P., Ding, R., Wang, S., Han, S., Zhang, D.: Insightpilot: An llm-empowered\nautomated data exploration system. In: Proceedings of the 2023 Conference on\nEmpirical Methods in Natural Language Processing: System Demonstrations. pp.\n346–352 (2023)\n29. Mahmood, A., Wang, J., Yao, B., Wang, D., Huang, C.M.: Llm-powered conversa-\ntional voice assistants: Interaction patterns, opportunities, challenges, and design\nguidelines. arXiv preprint arXiv:2309.13879 (2023)\n30. Martínez, G., Hernández, J.A., Conde, J., Reviriego, P., Merino-Gómez, E.: Beware\nof words: Evaluating the lexical diversity of conversational llms using chatgpt as\ncase study. ACM Transactions on Intelligent Systems and Technology (2024)\n31. Ooge, J., Verbert, K.: Explaining artificial intelligence with tailored interactive\nvisualisations. In: Companion Proceedings of the 27th International Conference on\nIntelligent User Interfaces. pp. 120–123 (2022)\n32. Park, H., Nam, Y., Kim, J.H., Choo, J.: Hypertendril: Visual analytics for user-\ndriven hyperparameter optimization of deep neural networks. IEEE Transactions\non Visualization and Computer Graphics 27(2), 1407–1416 (2020)\n\n\n12\nD Perumal & S Panda\n33. Requeima, J., Bronskill, J., Choi, D., Turner, R.E., Duvenaud, D.: Llm processes:\nNumerical predictive distributions conditioned on natural language. arXiv preprint\narXiv:2405.12856 (2024)\n34. Sacha, D., Sedlmair, M., Zhang, L., Lee, J.A., Peltonen, J., Weiskopf, D., North,\nS.C., Keim, D.A.: What you see is what you can change: Human-centered machine\nlearning by interactive visualization. Neurocomputing 268, 164–175 (2017)\n35. Spinner, T., Schlegel, U., Schäfer, H., El-Assady, M.: explainer: A visual analytics\nframework for interactive and explainable machine learning. IEEE transactions on\nvisualization and computer graphics 26(1), 1064–1074 (2019)\n36. Tan, Y., Zhang, Z., Li, M., Pan, F., Duan, H., Huang, Z., Deng, H., Yu, Z., Yang,\nC., Shen, G., et al.: Medchatzh: A tuning llm for traditional chinese medicine\nconsultations. Computers in Biology and Medicine 172, 108290 (2024)\n37. Touvron, H., Lavril, T., Izacard, G., Martinet, X., Lachaux, M.A., Lacroix, T.,\nRozière, B., Goyal, N., Hambro, E., Azhar, F., et al.: Llama: Open and efficient\nfoundation language models. arXiv preprint arXiv:2302.13971 (2023)\n38. Wang, B., Li, G., Li, Y.: Enabling conversational interaction with mobile ui using\nlarge language models. In: Proceedings of the 2023 CHI Conference on Human\nFactors in Computing Systems. pp. 1–17 (2023)\n39. Wang, D., Weisz, J.D., Muller, M., Ram, P., Geyer, W., Dugan, C., Tausczik,\nY., Samulowitz, H., Gray, A.: Human-ai collaboration in data science: Exploring\ndata scientists’ perceptions of automated ai. Proceedings of the ACM on human-\ncomputer interaction 3(CSCW), 1–24 (2019)\n40. Wilhelm, T.I., Roos, J., Kaczmarczyk, R.: Large language models for therapy rec-\nommendations across 3 clinical specialties: comparative study. Journal of medical\nInternet research 25, e49324 (2023)\n41. Xu, Z., Wall, E.: Exploring the capability of llms in performing low-level visual\nanalytic tasks on svg data visualizations. arXiv preprint arXiv:2404.19097 (2024)\n42. Yi, J.S., Kang, Y.a., Stasko, J.T., Jacko, J.A.: Understanding and characterizing\ninsights: how do people gain insights using information visualization? In: Proceed-\nings of the 2008 Workshop on BEyond time and errors: novel evaLuation methods\nfor Information Visualization. pp. 1–6 (2008)\n43. Yuan, J., Chen, C., Yang, W., Liu, M., Xia, J., Liu, S.: A survey of visual analytics\ntechniques for machine learning. Computational Visual Media 7, 3–36 (2021)\n44. Zhang, T., Ladhak, F., Durmus, E., Liang, P., McKeown, K., Hashimoto, T.B.:\nBenchmarking large language models for news summarization. Transactions of the\nAssociation for Computational Linguistics 12, 39–57 (2024)\n\n\n",
  "metadata": {
    "source_file": "dataset/pdfs/arxiv_2502.20938v1.pdf",
    "total_pages": 12,
    "title": "A Deep User Interface for Exploring LLaMa",
    "authors": [
      "Divya Perumal",
      "Swaroop Panda"
    ],
    "abstract": "The growing popularity and widespread adoption of large language models\n(LLMs) necessitates the development of tools that enhance the effectiveness of\nuser interactions with these models. Understanding the structures and functions\nof these models poses a significant challenge for users. Visual\nanalytics-driven tools enables users to explore and compare, facilitating\nbetter decision-making. This paper presents a visual analytics-driven tool\nequipped with interactive controls for key hyperparameters, including top-p,\nfrequency and presence penalty, enabling users to explore, examine and compare\nthe outputs of LLMs. In a user study, we assessed the tool's effectiveness,\nwhich received favorable feedback for its visual design, with particular\ncommendation for the interface layout and ease of navigation. Additionally, the\nfeedback provided valuable insights for enhancing the effectiveness of\nHuman-LLM interaction tools.",
    "published_date": "2025-02-28",
    "source": "arxiv"
  }
}