{
  "id": "arxiv_2502.21037v1",
  "text": "The amplifier effect of artificial agents in social contagion\nEric Hitz, Mingmin Feng, Radu Tanase, Ren´e Algesheimer, Manuel S. Mariani1, a)\nDepartment of Business Administration, University of Zurich, Switzerland\nRecent advances in artificial intelligence have led to the proliferation of artificial agents in social contexts,\nranging from education to online social media and financial markets, among many others. The increasing\nrate at which artificial and human agents interact makes it urgent to understand the consequences of human-\nmachine interactions for the propagation of new ideas, products, and behaviors in society. Across two distinct\nempirical contexts, we find here that artificial agents lead to significantly faster and wider social contagion.\nTo this end, we replicate a choice experiment previously conducted with human subjects by using artificial\nagents powered by large language models (LLMs). We use the experiment’s results to measure the adoption\nthresholds of artificial agents and their impact on the spread of social contagion. We find that artificial agents\ntend to exhibit lower adoption thresholds than humans, which leads to wider network-based social contagions.\nOur findings suggest that the increased presence of artificial agents in real-world networks may accelerate\nbehavioral shifts, potentially in unforeseen ways.\nThe increasing role of artificial agents in human activities is not guaranteed to promote more inclusive, healthy, and\nsustainable societies [1]. As a result, even before the recent popularization of large language models (LLMs), scholars\nfrom multiple disciplines have called for the development of an interdisciplinary science of machine behavior where\nthe behavior of AI agents is studied with similar tools to those traditionally used to understand human behaviors [2].\nThe proliferation of large language models such as ChatGPT and the increased impact of algorithms on large-scale\nsocial dynamics makes it urgent to advance in this direction [1, 3]. However, despite some early efforts [4, 5], the\nimpacts of autonomous agents driven by LLMs (hereafter, artificial agents) on social contagion processes have not\nyet been widely examined. Here we ask: What role could artificial agents play in the spreading of social contagions?\nTo answer, we consider simple artificial agents obtained by prompting popular LLMs (OpenAI’s gpt-3.5-turbo and\nGoogle’s gemini-1.5-flash) with the demographic information and political orientation of the human subjects in a\nprevious study [6]. We perform the first measurement of the artificial agents’ thresholds to adoption, namely, the\nlevel of social reinforcement they need before supporting a new policy or adopting a new technology [7]. Our findings\nindicate that across both contexts, compared to human subjects, artificial agents exhibit a lower threshold to adoption,\nwhich invariably results in wider diffusion. The higher the proportion of artificial agents in a human-LLM network,\nthe wider the diffusion.\nCOMPARING HUMAN AND ARTIFICIAL AGENTS’ THRESHOLDS\nThe literature on social contagion defines the adoption threshold as the minimum level of exposure to a new product\nor behavior required for an individual to adopt it [8]. Artificial agents may exhibit higher thresholds than human\nsubjects if, when deciding whether to adopt a new product or behavior, they are less susceptible to social influence [9]\n– e.g., by outweighing the product’s attributes compared to social cues. Conversely, artificial agents may exhibit lower\nadoption thresholds if: (1) they integrate social cues into their decision-making more heavily than humans (e.g., as\na result of being trained with research articles on social theories); or (2) they perceive the factors that contribute to\nhigh thresholds – such as financial costs, potential reputational damage, or uncertainty [8] – to a lesser extent than\nhumans.\nHere, we aim to advance this debate by providing empirical evidence on the artificial agents’ thresholds. To this\nend, we adopt two different LLMs – OpenAI’s gpt-3.5-turbo model (hereafter, GPT) and Google’s gemini-flash-1.5\nmodel (hereafter, Gemini) – to simulate the responses of survey participants to the same two choice-based conjoint\nexperiments performed in ref. [6] with human subjects. In conjoint experiments, participants face a set of choice\ntasks where they need to choose one among several hypothetical products or behaviors (each characterized by a\nset of attributes) or the status-quo option to not adopt any [10]. The two experiments cover two choice contexts\nwhere the complex contagion theory is expected to apply [8]: (1) political views support [11] (where decision-makers\nchoose which energy policy to support, if any; hereafter referred to as PS experiment) and (2) new social technology\nadoption [7] (where decision-makers select which instant messaging app to switch to, if any; hereafter referred to\nas the AA experiment; see Supplementary Note I A for all details).\nIn our implementation of the surveys with\na)Electronic mail: manuel.mariani@business.uzh.ch\narXiv:2502.21037v1  [cs.SI]  28 Feb 2025\n\n\n2\nPS Experiment\nAA Experiment\nA\nB\nC\nD\nE\nF\nFig. 1. Social contagion driven by artificial agents. (A, D) Attribute importance in the PS and AA experiments for\nhuman and artificial subjects. The social signal plays a much more important role in both GPT-based and Gemini-based\nartificial subjects’ choices, whereas the ranking by the importance of the other attributes remains largely unchanged. (B, E)\nAverage threshold of subjects in the PS experiment and the AA experiment for both human and artificial subjects. The error\nbars represent the 95% confidence intervals (CI) for the averaged thresholds across all energy policies/messaging apps. Artificial\nsubjects tend to exhibit significantly lower thresholds. (C, F) Adoption rate as a function of the proportion of artificial agents\nin the network, with a seeding rate of 1% for each diffusion, for both the policy support experiment and the app adoption\nexperiment. The error bars represent the 95% CI for the average adoption rate across all energy policies/messaging apps. The\nhigher the proportion of artificial agents in a human-LLM network, the wider the diffusion.\nartificial agents, we prompted the LLMs by including the demographic information and political orientation of the\nhuman subjects from ref. [6], which is expected to reduce differences between the human participants and the LLM\nagents [12] (see Supplementary Note I B for all the implementation details). We analyze the resulting choice data\nin the same way as done by ref. [6] for human subjects, which allows us to estimate the threshold of each artificial\nagent for each alternative product (see Methods). This procedure places us in the position to directly compare the\nthreshold distribution across human subjects and artificial agents.\nIn contrast with prior hypotheses [9], we find that the artificial agents exhibit stronger susceptibility to social\ninfluence than human subjects. Compared to human subjects’ choices, the social signal is indeed more important in\ndetermining artificial agents’ choices in both the policy support and the app adoption experiments. Specifically, for\neach respondent n and attribute a, we measure the difference between the maximum and minimum marginal utility\nacross all the attribute’s levels; We normalize the obtained attribute importance values so that they sum to one for\neach individual [10]. We find that in the AA experiment, the social signal is the most important attribute for both\nhuman and artificial agents, with an average attribute importance of 41.4% (SEM = 0.8%) for the human subjects\nand even higher attribute importance for the artificial agents, 54.0% (SE = 0.4%) for GPT and 70.0% (SEM = 0.2%)\nfor Gemini, respectively (see Fig. 1D). More surprisingly, in the PS experiment, the social signal is the most important\nattribute for the artificial agents (51.4% (SEM = 0.4%) for GPT and 32.4% (SEM = 0.2%) for Gemini), although it\nwas only ranked 6th out of 7th for the human subjects (average importance 12.8% (SEM = 0.5%), see Fig. 1A). With\nminor discrepancies, the rankings of other attributes’ importance are largely consistent across artificial and human\nsubjects (see Fig. 1A, D).\nThese findings indicate that the social signal has the highest importance for the artificial agents’ choices even in a\ncontext where it was not important for the human subjects’ choices (i.e., in the PS experiment). According to the\nrandom utility theory, the threshold of a decision-maker for a given alternative is expected to be inversely proportional\nto the decision-maker’s susceptibility to social influence [6, 7]. Therefore, we expect the high importance of social\nsignals for the artificial agents’ choices in the PS experiment to directly translate into a lower threshold, which is\nconfirmed by our results (Fig. 1B, E). Specifically, in the PS experiment, the average threshold over all policies for\n\n\n3\nFig. 2. An illustrative human-LLM social network with 20 nodes and different proportions of artificial agents.\nA proportion 1 −q of the nodes is populated by human agents and a proportion q by artificial agents. For each value of q, the\npositions of artificial and human agents are randomly assigned. The three panels depict one instance for q = 0.1 (A), q = 0.5\n(B), and q = 0.9 (C).\nthe human participants was 41.2% (SEM = 0.5%), while it is only 11.3% (SEM = 0.2%)/12.2% (SEM = 0.2%) for the\nartificial agents generated with GPT/Gemini. Similarly, in the AA experiment, the average threshold for the human\nparticipants was 59.6% (SEM = 0.4%), which is significantly higher than 1.3% (SEM = 0.1%)/18.0% (SEM = 0.1%)\nobserved for the artificial agents generated with GPT/Gemini.\nCONTAGION AMPLIFIERS\nThe relevance of the threshold distributions for diffusion outcomes [6] motivates us to examine theoretically whether\ncomplex contagions would spread wider in social networks composed of artificial agents compared to networks com-\nposed of human subjects.\nTo answer this question, we perform calibrated simulations of complex contagion on\nempirical networks, where a proportion 1 −q of the nodes is occupied by human agents, a proportion q by artificial\nagents (see Fig. 2); the human and artificial agents make adoption decisions determined by their thresholds estimated\nin the conjoint experiments with human subjects and artificial agents, respectively (see Methods). For each study and\nfor each type of artificial agent, we measure the adoption rate for 36 products/behaviors in 18 empirical networks for\n6 values of q under two seeding policies (top degree and random), which leads to a total of 31,104 distinct diffusion\nsimulations (see Supplementary Note II).\nAcross both contexts, the net effect of q (proportion of artificial agents) is to monotonically widen the reach of\nthe complex contagion. This holds true both in the PS experiment (Fig. 1C) and the AA experiment (Fig. 1F),\nboth when the contagion originates from central nodes and when it originates from randomly-selected nodes. These\nfindings indicate that artificial subjects act as “contagion amplifiers”: For example, in a social network comprising\n20% GPT agents with 1% randomly seeded nodes, on average, energy policies would receive 1.14 times more support\nthan in a human-only network; Similarly, under the same conditions, 2.22 times more nodes would decide to switch\nto a new messaging app compared to a human-only network.\nDISCUSSION\nThese findings open two main directions for future research. One thought-provoking conjecture – supported by the\nsimulated diffusion patterns reported here – is that once artificial agents are injected into a social system, contagion\nwill spread wider. At the same time, because of the limited scope of this Report, it remains open to test the amplifier\neffect in real-world platforms where artificial and human decision-makers interact longitudinally [13], and to delimit\nin what conditions we can expect it to occur.\nIn those contexts where the amplifier effect will be confirmed, we can expect faster behavioral changes at the\ncollective level, with potentially unpredictable consequences. Particularly in high-uncertainty environments, where\nsocial signals play a stronger role in guiding behavior [8], artificial agents may accelerate diffusion in ways that are\ndifficult to anticipate. This raises a crucial question for policymakers: how can we steward the resulting collective\nbehavioral patterns toward healthy and sustainable outcomes? Addressing this challenge will likely require integration\nof experimental and simulation techniques [1, 6], ensuring that artificial agents contribute to beneficial rather than\ndestabilizing social dynamics.\nA second important conjecture is that using current LLMs to predict the reach of a social contagion process may\nsystematically overestimate the actual size of contagion. While pioneering studies have highlighted the LLMs’ ability\nto mirror human behaviors – including cognitive biases [14] and troubling stereotypes [15] – our findings suggest a\nneed for greater scrutiny in contexts where social influence plays a major role. Specifically, future research should\n\n\n4\ninvestigate the conditions under which LLMs can accurately predict collective human behavior and how their design\nand prompting can be optimized for more realistic simulations. Advancing this understanding will be crucial for\nensuring that AI-driven models of social behavior produce reliable insights rather than misleading projections.\nFinally, an important assumption in the analyzed experiments is that all agents – human and artificial alike – are\nonly influenced by the aggregate social signal they receive about the alternatives, encoded in the fraction of friends\nwho have already adopted it. In real-world scenarios, the agents might be influenced differently from agents of the\nsame or different type. Future studies should examine whether knowing that some agents are artificial alter decision-\nmaking and diffusion processes. Investigating this question will help refine our understanding of hybrid human-AI\nsocial systems and their emergent properties.\nMATERIALS AND METHODS\nThe threshold estimation follows the methodology described in ref. [6]. Individual n’s utility from adopting product\nor behavior i (Uni) consists of two components: the utility of the product attributes on n (U (A)\nni ) and the social influence\nutility (U (S)\nni ), such that: Uni = U (A)\nni +U (S)\nni . The adoption threshold is then defined as the minimal level of the social\nsignal required for Uni to exceed the status-quo utility (U (0)\nn ). Under the assumption that U (0)\nn\n−U (A)\nni\n> 0 and the\nutility from the social signal is linear in the number of adopters (U (S)\nni\n= γnsni, where sni denotes the percentage of\nadopters of i within n’s social neighborhood, and γn represents n’s marginal utility of the social signal), the adoption\nthreshold can be expressed as in ref. [6, 7]: τni = (U (0)\nn\n−U (A)\nni )/γn. Following discrete choice theory [6, 7], the utility\nis assumed to be additive over product/behavior attributes: U (A)\nni\n= PK\nk=1 βnk xki, where xki encodes if alternative i\nhas attribute k and βnk is the (partworth) utility of n for attribute k. All parameters (βnk, γn, U (0)\nn ) can be estimated\nwith the Hierarchical Bayes (HB) algorithm from observed choices, as in a choice-based conjoint analysis.\nREFERENCES\n1Joseph B Bak-Coleman, Mark Alfano, Wolfram Barfuss, Carl T Bergstrom, Miguel A Centeno, Iain D Couzin, Jonathan F Donges,\nMirta Galesic, Andrew S Gersick, Jennifer Jacquet, et al. Stewardship of global collective behavior. Proceedings of the National Academy\nof Sciences, 118(27), 2021.\n2Iyad Rahwan, Manuel Cebrian, Nick Obradovich, Josh Bongard, Jean-Fran¸cois Bonnefon, Cynthia Breazeal, Jacob W Crandall,\nNicholas A Christakis, Iain D Couzin, Matthew O Jackson, et al. Machine behaviour. Nature, 568(7753):477–486, 2019.\n3Levin Brinkmann, Fabian Baumann, Jean-Fran¸cois Bonnefon, Maxime Derex, Thomas F M¨uller, Anne-Marie Nussberger, Agnieszka\nCzaplicka, Alberto Acerbi, Thomas L Griffiths, Joseph Henrich, et al. Machine culture. Nature Human Behaviour, 7(11):1855–1868,\n2023.\n4Giordano De Marzo, Luciano Pietronero, and David Garcia. Emergence of scale-free networks in social interactions among large language\nmodels. arXiv preprint arXiv:2312.06619, 2023.\n5Yikang Lu, Alberto Aleta, Chunpeng Du, Lei Shi, and Yamir Moreno. Llms and generative agent-based models for complex systems\nresearch. Physics of Life Reviews, 2024.\n6Radu Tanase, Ren´e Algesheimer, and Manuel S Mariani. Integrating behavioral experimental findings into dynamical models to inform\nsocial change interventions. arXiv preprint arXiv:2405.13224, 2024.\n7Jacob Goldenberg, Barak Libai, and Eitan Muller. The chilling effects of network externalities. International Journal of Research in\nMarketing, 27(1):4–15, 2010.\n8Douglas Guilbeault, Joshua Becker, and Damon Centola. Complex contagions: A decade in review. Complex Spreading Phenomena in\nSocial Systems, pages 3–25, 2018.\n9Milena Tsvetkova, Taha Yasseri, Niccolo Pescetelli, and Tobias Werner. A new sociology of humans and machines. Nature Human\nBehaviour, 8(10):1864–1876, 2024.\n10Vithala R Rao. Applied conjoint analysis. Springer Science & Business Media, 2014.\n11Silvia Pianta, Adrian Rinscheid, and Elke U Weber. Carbon capture and storage in the united states: perceptions, preferences, and\nlessons for policy. Energy Policy, 151:112149, 2021.\n12Lisa P Argyle, Ethan C Busby, Nancy Fulda, Joshua R Gubler, Christopher Rytting, and David Wingate. Out of one, many: Using\nlanguage models to simulate human samples. Political Analysis, 31(3):337–351, 2023.\n13Moshe Glickman and Tali Sharot. How human–ai feedback loops alter human perceptual, emotional and social judgements. Nature\nHuman Behaviour, pages 1–15, 2024.\n14Thilo Hagendorff, Sarah Fabi, and Michal Kosinski. Human-like intuitive behavior and reasoning biases emerged in large language\nmodels but disappeared in chatgpt. Nature Computational Science, 3(10):833–838, 2023.\n15Myra Cheng, Esin Durmus, and Dan Jurafsky. Marked personas: Using natural language prompts to measure stereotypes in language\nmodels. arXiv preprint arXiv:2305.18189, 2023.\n16Sawtooth Software. CBC Questionnaires and Design Strategy, Accessed on May 16th, 2024.\n17Greg M Allenby and Peter E Rossi. Hierarchical bayes models. The handbook of marketing research: Uses, misuses, and future advances,\npages 418–440, 2006.\n18Ryan Sermas. ChoiceModelR: Choice Modeling in R, 2022. R package version 1.3.0.\n\n\n5\n19Kathleen Mullan Harris, Carolyn Tucker Halpern, Eric A. Whitsel, Jon M. Hussey, Ley A. Killeya-Jones, Joyce Tabor, and Sarah C. Dean.\nCohort Profile: The National Longitudinal Study of Adolescent to Adult Health (Add Health). International Journal of Epidemiology,\n48(5):1415–1415k, October 2019.\n20Douglas Guilbeault and Damon Centola. Topological measures for identifying and predicting the spread of complex contagions. Nature\nCommunications, 12(1):1–9, 2021.\n21Albert-L´aszl´o Barab´asi and M´arton P´osfai. Network Science. Cambridge University Press, Cambridge, 1st edition edition, 2016.\n22Mark Newman. Networks. Oxford University Press, 2018.\n\n\n6\nSupplementary Material for: “The amplifier effect of artificial agents in social contagion”\nEric Hitz, Mingmin Feng, Radu Tanase, Ren´e Algesheimer, Manuel S. Mariani\nCONTENTS\nComparing human and artificial agents’ thresholds\n1\nContagion amplifiers\n3\nDiscussion\n3\nMaterials and Methods\n4\nReferences\n4\nI. Choice-based conjoint experiments with artificial subjects\n6\nA. Overview of the original experiments\n6\n1. The policy support study (PS)\n6\n2. The app adoption study (AA)\n7\nB. Implementation with ChatGPT/Gemini\n7\n1. Prompt example PS Study\n7\n2. Prompt example AA Study\n8\nII. Diffusion simulation\n10\nA. Data for the diffusion\n10\n1. Social network data\n10\n2. Agent sampling\n10\n3. Product sampling\n10\nB. Seeding policies\n10\nC. Diffusion process\n10\nI.\nCHOICE-BASED CONJOINT EXPERIMENTS WITH ARTIFICIAL SUBJECTS\nA.\nOverview of the original experiments\nThe conjoint studies described in the main article have been conducted by [6] with human participants recruited\nfrom Prolific (296 participants in the PS study; 300 participants in the AA study). We removed from the original\ndata all participants who had missing demographic data that was needed to prompt artificial agents. This resulted\nin 277/284 participants in the PS/AA study, whose data was used in this article.\n1.\nThe policy support study (PS)\nStudy design and data\nIn the original study 296 US participants were recruited from Prolific. The resulting sample\nwas representative for the US population in terms of gender and ethnicity. Participants were told to imagine that a new\nenvironmental policy to capture and store carbon could be implemented in their state. Participants were presented\nwith 15 choice sets, each consisting of three policies and a none option. The policies differed in terms of policy type\n(ban/subsidy/tax), cost ($4/$9/$14/$19), the beginning of policy implementation (2025/2035/2045/2055), required\ndistance to residential areas (2 miles/5 miles/10 miles/50 miles), the organization endorsing the policy (Carbon\nCapture Coalition/Greenpeace/Democratic Party/Republican Party) and the (hypothetical) percentage of friends\nendorsing the policy (1%/23%/45%/76%/98%). Except for the last attribute (percentage of friends endorsing the\npolicy), the policies described closely follow [11]. Participants had to select from each choice set which policy they\nwould endorse or select the none option. Each participant received a different set of choice tasks, generated by the\nSawtooth software using the balanced overlap method [16].\n\n\n7\nEstimation\nWe estimated the individual partworth coefficients using the Hierarchical Bayes [17] algorithm imple-\nmented in the function choicemodelr from the R package ChoiceModelR [18]. We used 30’000 MCMC iterations, the\nfirst 10’000 for burn in and the remaining 20’000 for parameter estimation. The attribute Percentage of friends who\nendorse the policy was coded as numeric and all remaining attributes were categorical. More implementation details\nand an evaluation of the model quality can be found in the Supplementary Material of [6].\n2.\nThe app adoption study (AA)\nStudy design and data\nIn the original study 300 US participants have been recruited from a convenience sample\non Prolific. Participants were told to imagine a new instant messaging app available on the market. Participants\nwere presented which 14 choice sets, each consisting of three instant messaging apps and a none option. The apps\ndiffered in terms of accessibility (mobile/web), authentication (simple/two-factor/multi-factor), customization level\n(low/medium/high), support for video calls (multi-person/one-to-one), and the (hypothetical) percentage of friends\nwho are already using the app (1%/23%/45%/76%/98%). Participants had to select from each choice set which app\nthey would use or to select the none option. Each participant received a different set of choice tasks, generated by\nthe Sawtooth software using the balanced overlap method.\nEstimation\nSimilarly to the PS Study, we estimated the individual partworth coefficients using the Hierarchical\nBayes algorithm with 30’000 MCMC iterations, the first 10’000 for burn in and the remaining 20’000 for parameter\nestimation. The attribute Percentage of friends who already use the app was coded as numeric and all remaining\nattributes were categorical. More implementation details and an evaluation of the model quality can be found in the\nSupplementary Material of [6].\nB.\nImplementation with ChatGPT/Gemini\nWe replicated both studies with artificial agents as follows. We constructed a number of artificial agents equal\nto the number of participants in the study. The agent was initialized with a prompt consisting of three sections:\ndemographic information (age, gender, highest education level, education subject, and income; PS experiment also\nincludes political orientation and social media connections) corresponding to one human participant in the survey;\n(2) description of the study as presented to the human participant; and (3) the attributes describing the options in\nthe choice set, as presented to the human participant. Subsequently, the artificial agent was presented with the choice\nsets (same number as in the original experiments) and asked to select which option in the choice set it would choose\nor to select the none option. Examples of prompts can be found in Section I B 1 (PS Study) and Section I B 2 (AA\nStudy)\nWe used the same prompt with two LLMs: GPT-3.5-turbo (thereafter, GPT-3.5) from OpenAI and Gemini Flash-\n1.5 from Google with the default temperature setting of one. Additionally, for GPT-3.5 we varied the temperature\nlevels – high (two) and low (zero) —, while for Gemini Flash-1.5 we used the default setting of one. The temperature\nparameter controls the randomness in the answers provided by the AI agent. Higher temperature values result in more\ndiverse answers compared to lower temperature values. At temperature zero the answers are completely deterministic.\nThe main article contains the results for the default temperature settings. We note the results are consistent for all\ntemperature values.\n1.\nPrompt example PS Study\nWe present below an example of a prompt used in the PS Study. We made minor layout adjustments to enhance\nreadability.\nYou are a 35-44 years old male, your highest level of school you have completed or the highest degree you have\nreceived is Master’s degree, your major subject of study was Science, your total yearly household income before taxes\nis approximately 75,000 to 99,000 you describe your political orientation as liberal and anti-traditional.\nCarbon capture and storage (CCS) is a set of technologies aimed at capturing, transporting, and storing carbon\ndioxide (CO2) emitted from industrial facilities and power plants that use fossil fuels like coal and natural gas. CO2\nemissions are one of the major contributors to climate change. The goal of CCS is to prevent CO2 from reaching the\natmosphere by injecting it in suitable underground geological formations - depleted oil and gas fields and deep saline\nformations - for permanent storage.\n\n\n8\nSome scientific studies promote CCS as a prospective solution to climate change, as it could significantly contribute\nto the reduction of CO2 emissions, while other studies emphasize that CCS is a very costly technology and there is\na need to investigate its potential risks in order to ensure that its deployment would not have an adverse impact on\npeople and the environment. Political discussions currently focus on how to regulate and implement the use of CCS.\nYou may or may not agree with scaling up CCS, but if a scale-up were to be implemented in your state, you may still\nhave different preferences as to specific scenarios. In the following, we will sketch out some scenarios for a scale-up\nof CCS. Please take a look at these scenarios and evaluate them.\nThe below-mentioned policy scenarios each consist of 6 aspects:\n1. Policy type: Which policies should be implemented to promote CCS? a) A ban on the construction of new fossil\nfuel power plants without CCS in your state: According to this policy, no new coal- or gas-fired power stations\ncan be built in your state without including CCS. b) Government subsidies for CCS in your state: Your state\ngovernment could subsidize CCS projects. This would make deployment of the technology more economically\nattractive. c) Increase in taxes on fossil fuel power generation without CCS in your state: Such a policy would\nmake fossil fuel power generation with no CCS more expensive.\n2. Policy cost: All policies to scale up CCS would produce some costs for American consumers. However, the exact\namount depends on many factors, such as the concrete policy calibration, economic conditions, etc. Estimates\nfor a scale-up policy currently range between costs of US$ 4 and 19 per household (per month).\n3. Beginning of policy implementation: When should the policy be implemented? Various scenarios include\nimplementation in 2025, 2035, 2045 or 2055.\n4. Distance from residential areas: CCS facilities are currently planned in many American states.\nSome\npeople fear that they could negatively affect buildings and the safety of communities. Different rules regarding\nthe required distance of CCS facilities from residential areas are currently being discussed: 2 miles / 5 miles /\n10 miles / 50 miles.\n5. Policy endorsement: Various stakeholders (e.g., Greenpeace or the U.S.-based Carbon Capture Coalition\n(ccc)) and political parties (Democrats(dp), Republicans(rp)) have their own opinions on policy proposals to\nscale up CCS.\n6. Percentage of your friends who endorse the policy scenario: Think about your friends and imagine\nyou could know if they endorse a policy scenario. This attribute represents the percentage of your friends, out\nof your total number of friends, who endorse it.\nYou will repeatedly see three different policy scenarios and I will ask you which one you would prefer. If you think\nyou wouldn’t prefer any, feel free to choose the None option.\n• Option 1 is a subsidies policy, costs $9 per household per month, will be implemented in 2035, the required\ndistance to residential areas is 5 miles, is endorsed by dp, and 45% of your friends endorse it.\n• Option 2 is a ban policy, costs $14 per household per month, will be implemented in 2045, the required distance\nto residential areas is 10 miles, is endorsed by greenpeace, and 23% of your friends endorse it.\n• Option 3 is a tax policy, costs $4 per household per month, will be implemented in 2025, the required distance\nto residential areas is 2 miles, is endorsed by ccc, and 76% of your friends endorse it.\n• Option 4 is to choose no policy.\nWhich option do you choose? You have to pick one option. Don’t explain your choice, just name the option you\nchoose.\n2.\nPrompt example AA Study\nWe present below an example of a prompt used in the AA Study. We made minor layout adjustments to enhance\nreadability.\nYou are a 35-44 years old male, your highest level of school you have completed or the highest degree you have\nreceived is Graduate or professional degree and your total household income during the past 12 months was More than\n100,000 pounds.\n\n\n9\nImagine there are several new multiple instant messaging apps on the market. All apps are free and are similar\nto each other in all but the aspects described below. Furthermore, we ask you to imagine several of your friends are\nalready using such an app. We will show you this information as one of the app attributes.\nThe apps differ in terms of the following attributes:\n1. Accessibility: Instant messaging apps differ in the way you can access them. They can be:\n• Mobile only: A mobile only app is specifically developed for smartphones and tablets. It takes full ad-\nvantage of mobile device features such as push notifications, camera integration, and location services. It\noffers a seamless, on-the-go communication experience, but it’s not accessible on desktop or web browsers.\n• Web accessible: Web-accessible instant messaging apps expand their reach beyond mobile devices. They\nallow users to access their chats and conversations via web browsers on desktop computers or laptops. This\nversatility enables seamless transition between devices, convenient typing with a physical keyboard, and the\nability to share files and links more easily on a larger screen.\n2. Authentication: Authentication is important to safeguard your personal information and ensure that your\nconversations remain private. The apps can use one of the three levels of authentication described below, sorted\nby the least to the most secure:\n• Simple authentication: Login with username and password.\n• Two-factor authentication:\nTwo-factor authentication (2FA) requires an additional authentication\nmethod beyond your username and password. This involves receiving a one-time verification code via SMS\nor email, which you must enter alongside your password to access your account.\n• Multi-factor authentication: In addition to your username, password, and the SMS or email verification\ncode, you must also verify your identity using a fingerprint scanner or a hardware token (a device connected\nto your mobile or computer.)\n3. Customisation level: The customization level determines how much you can personalize your messaging\nexperience. It can take one of the following values:\n• Low: You can adjust the basic settings, like security and notification preferences.\n• Medium: In addition to the basic settings, you have the flexibility to shape your chat organization, such\nas creating chat lists and pinning important conversations to the top.\n• High: Additionally, you have the option to customize themes and appearance, including elements like color\nschemes, backgrounds, fonts used and many others.\n4. Video calls: To make the most of your video communication experience, apps focus either on One-on-one or\nmulti-person video calls.\n• One-on-One: The app provides a straightforward and personal video calling experience designed and\noptimised for one-on-one interactions. The app does not support video calls between more than two people\nat once.\n• Multi-person: The app offers a versatile video calling feature, allowing you to connect with multiple\nparticipants simultaneously.\nI will repeatedly show you three apps which differ in terms of the attributes previously described and ask you to\nselect which one (out of the three) you would use instead of the app you are currently using. If you don’t like any of\nthe options, please feel free to select the None option.\n• Option 1 is mobile only, has multi-factor authentication, a high customisation level, and allows one-on-one calls\nand 98% of your friends are already using the app.\n• Option 2 is web accessible, has two-factor authentication, a medium customisation level, and allows multi-person\ncalls and 76% of your friends are already using the app.\n• Option 3 is mobile only, has simple authentication, a low customisation level, and allows multi-person calls and\n45% of your friends are already using the app.\n• Option 4 is to use no app.\nWhich option do you choose? You have to pick one option. Don’t explain your choice, just name the option you\nchoose.\n\n\n10\nII.\nDIFFUSION SIMULATION\nA.\nData for the diffusion\n1.\nSocial network data\nThe National Longitudinal Study of Adolescent Health (Add Health) study was conducted via an in-school survey\nover a nationally representative sample of more than 20,000 adolescents in grades 7-12 when in 1994-95 in the United\nStates [19]. We use the cleaned Add Health network data from https://github.com/drguilbe/complexpaths [20],\nwhich contains 85 networks. To save computational time, we restricted our analysis to the sample of 18 networks\nused in [6]. The sample was constructed by dividing the 85 networks into six groups based on the number of nodes\nand the global transitivity index of the graph [21]. Each network was classified for each metric into low (metric <\n33% quantile), medium (metric lies between the 33% and the 67% quantiles), or high (metric > 67% quantile). From\nthe resulting nine possible combinations, two networks were selected at random to be part of the sample.\n2.\nAgent sampling\nWe create two types of agents from the above-described experiments: human and artificial, each with its own\nspecific thresholds estimated from the experiments. For a given network, we assign to a proportion 1 −q of the nodes\nthe human agents and to a proportion q the artificial agents. The agents are randomly sampled with replacements\nfrom each type.\n3.\nProduct sampling\nFor simplicity, we use the term product to refer to both products (e.g., instant messaging app in the AA study) and\nbehaviors (e.g., policy support in the PS study). In both the PS and the AA studies we conducted the simulations\nusing 36 products. The total number of products that can be generated from a conjoint design is equal to all distinct\ncombinations of attribute levels (not considering the social signal). Thus, the total number of possible products is\n768 (3 × 4 × 4 × 4 × 4) in the PS study and 36 (2 × 2 × 3 × 3) in the AA study. To save computational time, in the PS\nstudy, we restricted our analysis to the sample of 36 products used in [6]. The sample was constructed by computing\nthe average adoption threshold over the (human) subjects for each product, setting 6 equally-sized intervals for the\nrange of average threshold, and sampling 6 products from each interval.\nB.\nSeeding policies\nGiven a certain network and a determined percentage of seeds, we calculate the number of seeds and decide who\nto seed in each diffusion based on two seeding policies: (1) random policy (seeds are chosen at random from all nodes\nin the network); and (2) degree policy (the seeds are the nodes with the highest degree centrality – the number of\nconnections to other nodes in the network[e.g., 22])\nC.\nDiffusion process\nFor each configuration, identified by the agent type, the network structure, the product spreading through the\nnetwork, the ratio q of artificial agents in the network, and the selected seeding policy, we simulate a threshold model\nwhere agents make adoption decisions based on their thresholds estimated from the two experiments. At each time\nstep of the simulation, an agent decides to adopt the product if the proportion of neighbors who had adopted the\nproduct in the previous stage is greater or equal to the agent’s adoption threshold. We assume the agents learn about\nthe product from their neighbors and thus an agent can only adopt once it has been exposed to an adopting neighbor\n(i.e., an agent with threshold zero adopts only once at least one neighbor has adopted). The diffusion process runs\nuntil there are no new adoptions in the network. We calculate the adoption rate as the total number of adopters in\nthe last step of the simulation divided by the total number of nodes in the network.\n\n\n",
  "metadata": {
    "source_file": "dataset/pdfs/arxiv_2502.21037v1.pdf",
    "total_pages": 10,
    "title": "The amplifier effect of artificial agents in social contagion",
    "authors": [
      "Eric Hitz",
      "Mingmin Feng",
      "Radu Tanase",
      "René Algesheimer",
      "Manuel S. Mariani"
    ],
    "abstract": "Recent advances in artificial intelligence have led to the proliferation of\nartificial agents in social contexts, ranging from education to online social\nmedia and financial markets, among many others. The increasing rate at which\nartificial and human agents interact makes it urgent to understand the\nconsequences of human-machine interactions for the propagation of new ideas,\nproducts, and behaviors in society. Across two distinct empirical contexts, we\nfind here that artificial agents lead to significantly faster and wider social\ncontagion. To this end, we replicate a choice experiment previously conducted\nwith human subjects by using artificial agents powered by large language models\n(LLMs). We use the experiment's results to measure the adoption thresholds of\nartificial agents and their impact on the spread of social contagion. We find\nthat artificial agents tend to exhibit lower adoption thresholds than humans,\nwhich leads to wider network-based social contagions. Our findings suggest that\nthe increased presence of artificial agents in real-world networks may\naccelerate behavioral shifts, potentially in unforeseen ways.",
    "published_date": "2025-02-28",
    "source": "arxiv"
  }
}