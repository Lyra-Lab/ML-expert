{
  "id": "arxiv_2502.20882v1",
  "text": "Managing Federated Learning on Decentralized Infrastructures as a\nReputation-based Collaborative Workflow\nYuandou Wanga, Zhiming Zhaoa,b\naMultiscale Networked System, University of Amsterdam, Science Park 900, Amsterdam, 1098 XH, The Netherlands\nbLifeWatch ERIC Virtual Lab and Innovation Center (VLIC), Science Park 904, Amsterdam, 1098 XH, The Netherlands\nA R T I C L E I N F O\nKeywords:\nFederated Learning\nCollaborative Workflows\nIncentives\nReputation\nOptimal Contract\nBlockchain\nA B S T R A C T\nFederated Learning (FL) has recently emerged as a collaborative learning paradigm that can train a\nglobal model among distributed participants without raw data exchange to satisfy varying require-\nments. However, there remain several challenges in managing FL in a decentralized environment,\nwhere potential candidates exhibit varying motivation levels and reliability in the FL process\nmanagement: 1) reconfiguring and automating diverse FL workflows are challenging, 2) difficulty\nin incentivizing potential candidates with high-quality data and high-performance computing to join\nthe FL, and 3) difficulty in ensuring reliable system operations, which may be vulnerable to various\nmalicious attacks from FL participants. To address these challenges, we focus on the workflow-based\nmethods to automate diverse FL pipelines and propose a novel approach to facilitate reliable FL system\noperations with robust mechanism design and blockchain technology by considering a contribution\nmodel, fair committee selection, dynamic reputation updates, reward and penalty methods, and\ncontract theory. Moreover, we study the optimality of contracts to guide the design and implementation\nof smart contracts that can be deployed in blockchain networks. We perform theoretical analysis and\nconduct extensive simulation experiments to validate the proposed approach. The results show that\nour incentive mechanisms are feasible and can achieve fairness in reward allocation in unreliable\nenvironment settings.\n1. Introduction\nFederated learning (FL) is a promising distributed ma-\nchine learning (ML) paradigm that enables collaborative\nlearning over decentralized data to mitigate many systematic\nprivacy risks and costs resulting from traditional, centralized\nlearning. In recent years, FL has been studied in many\nresearch and application domains, particularly in the fields\nof digital medicine and health [1], open banking [2], and\nthe Internet of Things [3], in which data cannot be shared\nor exchanged due to privacy and security concerns.\nFL often involves a number of participants, which fea-\nture highly heterogeneous training infrastructures and non-\nindependently and identically distributed (non-IID) data [4].\nIn a traditional setting of FL, several participants, each\nkeeping its data and training process on-premise, aim to\ncollaboratively train a joint model under a central aggregator\nthat initializes, collects, aggregates, and redistributes the\nmodels to and from the training participants, as shown in\nFigure 1 (a). Over time, the federated model aggregation has\nemerged in varying modes [5] and performed as different\ntopology types in the distributed computing ecosystem [6],\nwhile the data and its training infrastructure are still decen-\ntralized. It is known that such diversity can be attributed\nto different FL design choices and customizations to satisfy\ndifferent user requirements. For instance, some researchers\nintroduced hierarchical FL, as shown in Figure 1 (b), to\ntackle the bottleneck of communication overhead in the core\ny.wang8@uva.nl (Y. Wang); z.zhao@uva.nl (Z. Zhao)\nhttps://www.linkedin.com/in/yuandou-w-aa717b135/ (Y. Wang);\nhttps://staff.fnwi.uva.nl/z.zhao/ (Z. Zhao)\nORCID(s): 0000-0003-4694-9572 (Y. Wang)\nnetwork [7, 8]. Some proposed decentralized FL, as depicted\nin Figure 1 (c), with a Peer-to-Peer (P2P) communication\narchitecture to cope with the drawbacks of a single point of\nfailure and scaling issues for the increasing network size [9,\n10]. Moreover, various aggregation strategies associated\nwith FL topologies for updating the FL model parameters\nhave been studied, including but not limited to sequen-\ntial updates [11], (a)synchronous parallel updates [12], and\npeer-to-peer approaches [13], as illustrated in Figure 1 (d),\n(e), and (f), respectively. The final well-trained model can\nbe obtained through the iteratively collaborative training\nrounds. However, due to the heterogeneity of decentralized\ninfrastructure or platforms, it poses execution challenges.\nFL development involves three typical activities: 1) dis-\ncover potential participants with high-quality data or re-\nsource providers and stimulate them to join the FL, 2) cus-\ntomize the FL application workflows for specific purposes,\nand 3) define a reliable training process with local updates\nevaluation.\nIn real-world scenarios, collaborative FL typically fol-\nlows two main approaches. The first involves pre-established\ncollaborations, where participants are obligated to join FL\ndue to prior agreements within research projects. These\nparticipants are considered trustworthy and contribute to\nthe entire FL training process with complete information.\nThe second approach relies on incentive-driven participa-\ntion, where FL proposers solicit collaboration through in-\ncentives [14, 15] from a decentralized community. In this\ncase, participation is voluntary, and the trustworthiness of\npotential candidates is initially unknown.\nDue to diverse availability of local resources and in-\nterests, FL participants may have different motivation in\nYuandou Wang et al.: Preprint submitted to Elsevier\nPage 1 of 16\narXiv:2502.20882v1  [cs.DC]  28 Feb 2025\n\n\nManaging Federated Learning on Decentralized Infrastructures as a Reputation-based Collaborative Workflow\nData\nTraining Node\nAggregator\nModel Aggregation\nInitial Model\nFinal Model\nWeight Exchange\n(a) Centralized FL\n(d) Sequential\n(e) Parallel\n(f) Peer to Peer\nLegend\nTopologies in FL\nModel updates' patterns in FL\nFederated Node\n(c) Decentralized FL\n(b) Hierarchical FL\nFigure 1: An overview of diverse FL design choices. FL topologies. (a) Centralized FL: a central aggregation server manages the\ntraining process by coordinating iterative training rounds. (b) Hierarchical FL: typically, the FL network has a tree structure with\nat least three tiers. (c) Decentralized FL: each training node is connected to one or more peers and aggregation happens on the\nselected node. FL model updatesâ€™ paths. (d) Sequential. (e) Parallel. (f) Peer to Peer.\njoining an FL application, and deliver diverse quality in con-\ntributions. This heterogeneity introduces several challenges,\nincluding unequal participation [16], free-riding [17], and\ndifficulties in accurately assessing and rewarding individual\ncontributions [18]. Encouraging active engagement from\ndiverse stakeholders, such as data owners, infrastructure\nproviders, and model developers, remains a critical chal-\nlenge. This requires incentivizing participation in customized\nFL workflows, facilitating local model update sharing, and\nensuring fair contributions to global model development\nwithin a decentralized community.\nFurthermore, these complexities create efficiency chal-\nlenges, as substantial time and effort are needed to set up\nFL workflows, identify suitable participants, and maintain\nlearning quality. In addition, FL operations are vulnerable\nto both intentional and unintentional threats, including data\npoisoning, malicious servers, inference attacks, system dis-\nruptions, and service unavailability [19]. Addressing these\nrisks is particularly difficult when some participants are\nunreliable during the training process.\nIn this work, we address the efficiency challenges in FL\ndevelopment and management within decentralized com-\nmunity settings. We begin by automating FL operations\nby modeling them as workflows and leveraging workflow\nengines to orchestrate their execution on remote infrastruc-\ntures at scale. Our approach emphasizes workflow-based FL\nmanagement, focusing on FL workflow composition, data\nowner incentivization, and reliable training processes via\ncombining with decentralized technologies.\nThe reminder of this article is structured as follows:\nSection 2 reviews the state-of-the-art reliable FL practices,\ncompares with existing work, and analyzes their research\ngap. Section 3 describes how we can describe FL as a\ncomputational workflow and scale it out to decentralized\ninfrastructure via the CWL open standards. Section 4 intro-\nduces a decentralized collaboration framework for FL and\nillustrates the mechanism design approach and studies the\ncontract optimality to answer research questions. Section 5\ndetails the experiments and the analysis of results; finally,\nSection 6 concludes this work.\n2. Related Work\nThis section reviews the state-of-the-art reliable fed-\nerated learning operation practices and explores existing\nframeworks for managing FL in decentralized infrastruc-\ntures.\nIn recent years, several FL frameworks have made no-\ntable advancements in managing the FL research and de-\nvelopment lifecycle. Yang et al. [20] introduced FLScalize,\nwhich extends the machine learning operations (MLOps)\nconcept to generate a baseline model, integrating FL clients,\nthe FL server, and model performance to oversee the entire\nFL lifecycle. Colonnelli et al. [21] employed the open stan-\ndard workflow language, CWL [22], to abstract and auto-\nmate FL applications in a hybrid Cloud-HPC environment.\nDespite these advances, their approach remains constrained\nby the traditional client-server architecture of centralized FL,\nalthough the open standard workflow language holds signif-\nicant promise for describing diverse FL workflows [23].\nYuandou Wang et al.: Preprint submitted to Elsevier\nPage 2 of 16\n\n\nManaging Federated Learning on Decentralized Infrastructures as a Reputation-based Collaborative Workflow\nDaga et al. [24] introduced the Flame framework, of-\nfering flexibility in the topology configuration of FL ap-\nplications tailored to the specific deployment context using\nnew high-level abstraction topology graphs (TAGs) that\nincorporate five types of FL topologies. While both Colon-\nnelli et al. [21] and Daga et al. [24] align closely with our\nstudy by utilizing high-level abstractions to enable flexibility\nin topology-aware FL, a key assumption in many existing\nworks is that potential participants will join the FL process\nunconditionally and are sufficiently trustworthy to contribute\nthroughout the entire FL training process. Our study diverges\nfrom previous works in several critical ways. We explore\nclassic workflow patterns [25] and FL architectural pat-\nterns [26], making fundamental workflow concepts â€” such\nas automation, scalability, abstraction, portability, flexibility,\nand reusability â€” applicable to the context of federated\nlearning operations (FLOps) via the open standard CWL.\nPreliminary results of this approach have been presented in\nCWL-FLOps [23].\nFurthermore, Cheng and Long [27] introduced a novel\nmethodology called FLOps for managing the FL lifecycle\ncontinuously and efficiently. FLOps integrates a range of\nprocesses, technologies, and tools to enhance the efficiency\nand quality of developing and deploying cross-silo FL sys-\ntems. They highlight that workflow-related approaches, such\nas metadata engineering, dual deployment, and checkpoints,\ncan help establish and automate FLOps practices, enabling\nsmoother and more efficient operations from an engineering\nperspective. However, the automation of FLOps remains an\nopen challenge, particularly when addressing security and\nprivacy concerns, which differ from those encountered in\ntraditional DevOps [28] and MLOps [29] practices. More-\nover, they do not address the issue of incentivizing partic-\nipants to make high-quality contributions if the assumption\nof their willingness and trustworthiness does not hold â€” this\nis a crucial factor for maintaining a reliable and secure FL\nprocess.\nOur work connects to the broader discussion of pro-\nmoting collaborative fairness among federated participants\nwithin decentralized communities, where incentives and\nfairness have been extensively explored [30, 18, 31]. Wang\net al. [32] examined incentive mechanism design in the con-\ntext of resource allocation for FL clients in Blockchain-based\nFederated Learning (BCFL). They modeled the problem\nas a two-stage Stackelberg game under both complete and\nincomplete information. Using the Shapley value approach,\nthey quantified clientsâ€™ contributions to the training process.\nBy transforming the game model into two optimization\nproblems and solving them sequentially, they derived the\noptimal strategies for both players. Gao et al. [33] introduced\nFGFL, an attack-resistant incentive mechanism for FL that\ndetects and repels abnormal updates, thereby protecting the\nsystem in unreliable scenarios. The task publisher rewards\nefficient workers and punishes or eliminates malicious ones\nbased on reputation and contribution indicators.\nWhile both incentive mechanisms are deemed feasible\nthrough experimental evaluation, neither explores the op-\ntimal contract design required for creating smart contracts\nfor FL operations. The question of whether the incentives\nembedded in smart contracts are either over-rewarding or\ninsufficient to effectively motivate participants remains un-\nclear. Kang et al. [34] proposed a joint optimization approach\ncombining a reputation-based worker selection scheme with\ncontract theory to determine the optimal computation re-\nsources (e.g., contributed CPU cycles) and corresponding\nrewards for all participants. However, this approach does\nnot fully capture the entire contribution to the FL training\nprocess. Furthermore, although existing works touch on fair\nrewards, there is a clear need for precise fairness metrics that\nalign with specific incentives, particularly in the context of\nreliable FL systems.\n3. Federated Learning as a Workflow\nThis section explores the advantages of managing feder-\nated learning as a workflow within decentralized infrastruc-\nture, addressing the following research question: \"How can\nwe abstract FL workflows in an open standard manner and\norganize their execution on remote infrastructure?\"\n3.1. Federated Learning\nWe consider an FL application scenario consisting of\nğ‘= {1, 2, â‹¯, ğ‘›} clients, each client ğ‘–holds a local dataset\nğ·ğ‘–= {(ğ‘¥, ğ‘¦)} âˆ¼îˆ°ğ‘–consisting of ğ‘ ğ‘–data samples, where ğ‘¥\nand ğ‘¦denote the data sample and its corresponding labels,\nrespectively [35]. The total sample size ğ‘†sample from ğ‘\nclients is given by ğ‘†sample = âˆ‘ğ‘›\nğ‘–=1 ğ‘ ğ‘–, âˆ€ğ‘–âˆˆğ‘. Additionally,\nthe union of all client datasets denote by ğ·= âˆªğ‘›\nğ‘–=1ğ·ğ‘–âˆ¼îˆ°.\nFL aims to minimize a global loss function îˆ¸(â‹…) from the\nğ‘clientsâ€™ local loss function îˆ¸ğ‘–âˆˆğ‘(â‹…) through the model\naggregation strategy techniques. The overall FL problem can\nbe formulated as\nmin\nğ°âˆˆâ„îˆ¸(ğ°)\nwhere\nğ‘\nâˆ‘\nğ‘–=1\nğ‘ ğ‘–\nğ‘†sample\nîˆ¸ğ‘–(ğ°)\n(1)\nHere, îˆ¸ğ‘–(ğ°) = âˆ‘ğ‘ ğ‘–\nğ‘˜=1 ğ“ğ‘–(ğ°; (ğ‘¥ğ‘˜, ğ‘¦ğ‘˜) âˆˆğ·ğ‘–) is the expected\nlocal loss of the ğ‘–ğ‘¡â„client on its local dataset ğ·ğ‘–, and\nğ“ğ‘–(ğ°; (ğ‘¥ğ‘˜, ğ‘¦ğ‘˜)) is the local loss function of the shared model\nweights ğ°on sample data (ğ‘¥ğ‘˜, ğ‘¦ğ‘˜) âˆˆğ·ğ‘–.\nTraditionally, clients train their local models ğ°(ğ‘¡)\nğ‘–\ninde-\npendently at round ğ‘¡by optimizing the loss function îˆ¸ğ‘–(â‹…) on\ntheir local datasets. Clients validate the trained model using\na validation dataset and upload their updated models to an\naggregator for federated model aggregation. The aggrega-\ntor then performs the aggregation strategy and updates the\nshared global model of all the local model updates. Take the\nmodel averaging method, i.e., FedAvg [36], as an example.\nIt is a technique developed to reduce the variance of a global\nmodel update by periodically averaging models trained over\nmultiple communication rounds in FL. The model averaging\nYuandou Wang et al.: Preprint submitted to Elsevier\nPage 3 of 16\n\n\nManaging Federated Learning on Decentralized Infrastructures as a Reputation-based Collaborative Workflow\naggregation is often formulated as,\nğ°(ğ‘¡+1) =\nğ‘›\nâˆ‘\nğ‘–=1\nğ‘ ğ‘–\nğ‘†sample\nğ°(ğ‘¡)\nğ‘–\n(2)\nwhere ğ°(ğ‘¡+1) denotes the updated global model weight for\nthe new round ğ‘¡+ 1. Then, it will be sent back to all active\nclients to initialize the next round of local training, itera-\ntively. This process repeats until the global loss converges.\nIt is known that high-quality data, efficient computation,\nand reliable communication at each round may contribute to\nthe local model training with high model performance (e.g.,\nhigh accuracy) and can lead to faster convergence of the local\nloss function îˆ¸ğ‘–(ğ°). The faster speed of the convergence\nof the local training and high-quality model updates will\nmake the convergence of the global loss function quicker,\nand thus, the training time and cost will decrease for a\ntargeted model performance [34]. Therefore, participants\nwith high-quality data, high-performance computation, and\ncommunication efficiency can significantly improve the FL\nquality and efficiency.\n3.2. Federated Learning as a Workflow\nWe define an FL workflow ğ¹\n= (ğ°, ğ‘, ğ´, ğ‘¡ğ‘‡) as a\ncombination of four random sets of variables: the global\nmodel ğ°, the participant set ğ‘, the aggregation strategy ğ´,\nand the topology type ğ‘¡ğ‘‡. These variables consist of the\nfundamental building blocks of FL workflows, and users\ncan reconfigure such blocks and customize ğ¹with their\npreferences under an agreement of all participants.\nWe build on existing solutions to develop a flexible,\nadaptable approach tailored to end usersâ€™ specific needs.\nAs a first step, we explored the component containerizer\nin NaaVRE [37] to create and store FL building blocks â€”\nsuch as models and aggregation strategies â€” as research\nassets. For instance, a model developer can build ML models\nin a local NaaVRE environment using small-scale datasets,\nperforming testing and validation. The model provider can\nthen package the ML model or code files with the FL\nframework into a container and store them on Docker Hub. It\nfacilitates the global distribution of reusable, containerized\napplications [38]. This approach enhances reproducibility,\nportability, and scalability, streamlining the integration of\nthese building blocks into reconfigurable FL workflows [39]\nand accelerating FL development.\nIn [38], we primarily used docker-nvidia for local client\ntraining with CUDA GPU resources, automating FL pipelines\nwhile allowing clients to retain control over their data and\ncomputation. For large-scale automated deployment, Docker\nSwarm serves as an alternative solution. The case study\non histological image analysis demonstrated the feasibility\nof the proposed approach, where we utilized the Flower\nframework [40] within the Jupyter environment for FL code\ndevelopment. However, most existing frameworks, such as\nTensorFlow Federated (TFF)1, NVFlare2, IBM FL [41],\n1https://www.tensorflow.org/federated\n2https://github.com/NVIDIA/NVFlare\nOpenFL [42], PySyft [43], and Flower, follow a centralized\nFL paradigm with a client-server architecture, in which the\naggregator cannot be replaced or changed during the training\nprocess. They typically rely on direct bidirectional commu-\nnication (e.g., gRPC [44]) between the aggregator and client\ntraining nodes, which limits their flexibility in supporting\ndiverse FL deployment scenarios. For example, locations\nof decentralized data infrastructure can be heterogeneous,\nexposing different hardware resources and protocols for\nauthentication, communication, resource allocation, and job\nexecution. Plus, they can be independent of each other,\nmeaning that direct communication among them may not\nbe allowed [21].\nTo overcome this limitation, we model the FL pipeline\nas a computational workflow and utilize a workflow engine\nto orchestrate its execution across remote infrastructures.\nSpecifically, we employ CWL open standards to define FL\npipelines, and make them more manageable to automate and\nparallelize the joint model training from the local computer\nto the remote cloud environments. We first employ the\nclassic workflow patterns to describe diverse computational\nFL workflows. Table 1 introduces a taxonomy of 43 control\npatterns and 40 data patterns identified in the Workflow\nPatterns Initiative (WPI)3, mapping them to a diverse range\nof FL topology types.\nA review of the 43 WPI patterns related to the control-\nflow perspective reveals that 11 patterns are supported by\nCWL v1.2 or earlier. Of the 40 data patterns, only 17 are\nsupported by CWL constructs, and just 2 of the 43 resource\npatterns are covered. Additionally, CWL standards offer\nlimited support for exception handling and do not address the\nevent log imperfection patterns defined in the WPI patterns.\nFor workflow presentation patterns, 19 are supported by\nCWL v1.2 or earlier, with one pattern still unsupported.\nCertain environments, such as blockchain networks, mobile\ndevices, and wireless systems, cannot directly interface with\nCWL-supported workflow patterns.\nFL requires loop patterns for describing the iterative\ntraining. While CWL v1.2 lacks loop constructs and re-\ncursion support, there are alternative methods to enable\nloops in describing iterative FL workflows. These include\n1) combining sub-workflows with loop extensions in the\ncurrent stable version (v1.2) and 2) the upcoming v1.3.0-\ndev1 version of CWL, which is expected to introduce loop\nconstructs in a future stable release. Figure 2 shows the\nsnippet of the main steps of a decentralized FL work-\nflow example written in CWL version v1.2. It orches-\ntrates multiple steps, including service discovery, client\nreading, initialization, and decentralized training rounds.\nThis CWL snippet set up a loop within a sub-workflow\nnamed decentralized_training_round. It manages decen-\ntralized training rounds in FL, iterating until the specified\nnumber of rounds is completed. Unlike a fixed aggregator\nin the centralized FL workflow, the aggregator is randomly\nchosen from the distributed clients to perform federated\n3http://www.workflowpatterns.com/\nYuandou Wang et al.: Preprint submitted to Elsevier\nPage 4 of 16\n\n\nManaging Federated Learning on Decentralized Infrastructures as a Reputation-based Collaborative Workflow\nTable 1\nThe mappings of different FL topology types on WPIâ€™s workflow patterns.\nFL Topology Types\nStar\nTree\nDecentralized\nMinor\nSynchronous\nAsynchronous\nHierarchical\nDynamic\nDe-Mesh\nDe-Wireless\nBlockchain\nRing\nClique\nGrid\nFog\nSemi-Ring\nPatterns\nControl (43)\nBasic control (5/5)\n1\n1\n1\n1\n1\n1\n1\n1\n1\n1\n1\n1\nAdvanced Branching and Synchronization (1/14)\n1\n1\n1\n1\n1\n1\n1\n1\n1\n1\n1\n1\nIteration (3/3) â€“>loops extension\n1\n1\n1\n1\n1\n1\n1\n1\n1\n1\n1\n1\nMultiple Instance (1/7)\n1\n1\n1\n1\n0\n1\n1\n0\n1\n1\n1\n1\nState-based (0/5)\n0\n1\n0\n1\n1\n1\n1\n1\n1\n1\n1\n1\nTrigger (0/2)\n1\n1\n1\n1\n1\n1\n1\n1\n1\n1\n1\n1\nCancelation and Force Completion (0/5)\n0\n1\n1\n1\n1\n1\n0\n0\n0\n1\n1\n1\nTermination (1/2)\n0\n0\n1\n1\n1\n1\n0\n0\n1\n1\n1\n1\nData (40)\nData Visibility (4/8)\n1\n1\n1\n1\n0\n1\n1\n1\n1\n1\n1\n1\nInternal Data Interaction (5/6)\n1\n1\n1\n1\n0\n1\n1\n1\n1\n1\n1\n1\nExternal Data Interaction (0/12)\n1\n1\n1\n1\n0\n1\n1\n1\n1\n1\n1\n1\nData Transfer (3/7)\n1\n1\n1\n1\n0\n1\n1\n1\n1\n1\n1\n1\nData-based Routing (2/7)\n1\n1\n1\n1\n1\n1\n1\n1\n1\n1\n1\n1\nFigure 2: Snippet of the CWL workflow.\nmodel aggregation in the decentralized training round de-\nsign. The loop feature implements a dynamic mechanism\nto handle multiple training rounds, ensuring scalability and\nflexibility in FL operations. Additionally, it can be fully\nautomated using GitHub Action workflows. More details can\nbe found in the source code, which is available in the GitHub\nrepository4.\n4https://github.com/CWL-FLOps/DecentralizedFL-CWL/\n3.3. Demonstration of FL Workflow\nWe demonstrate how the workflow-based approach en-\nables scalable automation of FL operations across cloud\ninfrastructures. Additionally, we integrate the implemented\nCWL-supported FL workflows with the Jupyter environment\nto facilitate collaborative learning and seamless workflow\nmanagement. Some related preliminary results have been\npublished in [45, 23].\nVisualized CWL-supported FL workflow. Figure 3 dis-\nplays the screenshot of the visualized CWL workflow graph\nnamed decentralizedFL.cwl via the CWL viewer tool5. It\nhas been verified with cwltool version 3.1.20230201224320\nand consists of five inputs (highlighted in a blue rectangle),\nthree steps (highlighted in a yellow rectangle), and a nested\nworkflow (highlighted in an orange rectangle). The connec-\ntions between the workflow inputs and steps illustrate the\ndependencies within the process. This workflow can serve\nas a research object bundle, enriched with comprehensive\nmetadata and licensing information to ensure its reusability.\nFor example, it is publicly available as an open-source\nworkflow and can be reused under the terms of the Apache\nLicense 2.0.\nFL workflow execution on hybrid Clouds. To demon-\nstrate the FL workflow execution over decentralized data\ninfrastructures, we utilized a well-known dataset named\nMNIST6 and five cloud instances from different providers.\nThese included one t4g.small instance (2 ARM-based vC-\nPUs, 2 GiB memory) and t3.small instance (2 x86-based vC-\nPUs, 2 GiB memory) from Amazon Web Services (AWS),\none t2a-standard-1 instance (1 ARM-based vCPU, 4 GiB\nmemory) and e2-medium instance (2 x86-based vCPUs, 4\nGiB memory) from Google Cloud Platform (GCP), and\none lab.uvalight.net instance (2 x86-based vCPUs, 2 GiB\n5https://view.commonwl.org/\n6https://git-disl.github.io/GTDLBench/datasets/mnist_datasets/\nYuandou Wang et al.: Preprint submitted to Elsevier\nPage 5 of 16\n\n\nManaging Federated Learning on Decentralized Infrastructures as a Reputation-based Collaborative Workflow\nFigure 3: The screenshot of the visualized FL workflow in the\nCWL viewer with detailed license, specification, and metadata.\nmemory) from the OpenLab infrastructure provided by the\nuniversity. Each dataset stored on the cloud instances was\nsplit from the MNIST dataset, with a size of approximately\n60 MB. The FL source code is based on PyTorch, reproduced\nfrom [46], where the author used the FedAvg method for the\nfederated model aggregation. We re-configured the FL work-\nflow with ten local training epochs and 12 communication\nrounds. Each setup was executed ten times to collect results\nfor statistical analysis.\nThe average training time is approximately (9.786 Â±\n0.238) minutes, and the average test accuracy achieved by\nthe FL workflow execution is (98.127 Â± 0.085)%. These\nempirical results demonstrate that CWL-supported FL work-\nflows are scalable, reusable, and portable, making them\nsuitable for execution in off-chain decentralized infrastruc-\ntures such as hybrid cloud environments. Since the CWL\ncommunity provides standardized alternatives for defining\nportable and reusable workflows that remain engine- and\nvendor-neutral, any CWL-compliant workflow execution en-\ngine should be able to execute this standardized workflow\ndescription and produce consistent results, regardless of the\nunderlying infrastructure [47]. Furthermore, by incorporat-\ning the principles of FAIR computational workflows within\nCWL, we can advance toward realizing FAIR FL workflow\nmanagement in future work.\n3.4. Lessons and Challenges\nThe empirical results demonstrate that CWL effectively\ndescribes FL workflows and automates their execution using\ncloud technologies. However, this approach assumes a pre-\nestablished collaboration, where distributed data sources are\npredefined within the workflow.\nCWL does not inherently address trust and reliable col-\nlaboration among multiple participants in FL workflows.\nThe decentralized nature of data providers challenges the tra-\nditional centralized workflow management paradigm, where\nproviders are predefined for composing application-specific\nFL workflows. To overcome this, an effective collaboration\nframework is needed to enable the dynamic selection of\ndata or resource providers and ensure the quality of their\ncontributions.\nIn the next section, we will explore how to incentivize\ncollaborations and ensure training quality by addressing the\nfollowing research questions:\nâ€¢ How can we incentivize participants with high-quality\ncontribution to join the FL training process?\nâ€¢ How can we assure training quality from decentralized\nparticipants in an unreliable environment?\n4. Decentralized Collaboration Framework\nTo tackle the challenges identified in 3.4, this section in-\ntroduces a decentralized collaboration framework that aims\nto manage the dynamic collaboration among participants\nwithin a decentralized community. The basic design ideas\ninclude:\nâ€¢ Using blockchain environment to manage the decen-\ntralized relation among FL participants and to record\ntheir interaction history.\nâ€¢ Managing the collaboration agreement by employing\nthe smart contract of the blockchain, where an FL\ndeveloper can explicitly describe the conditions for\ndesired participants in a smart contract.\nâ€¢ Verifying the contribution through blockchain ledgers\nand manage the update of the FL aggregations via\ndynamic consensus among participants through smart\ncontracts.\n4.1. System Overview\nFigure 4 depicts the basic idea for FL applications, build-\ning on our previous work on the D-VRE framework [48].\nThis framework equips Jupyter users with essential com-\nponents for enabling robust FL collaboration, integrating a\npersonal Jupyter working environment, a blockchain net-\nwork, and off-chain legacy resources, such as data storage,\ncomputation, and networking, within a decentralized ecosys-\ntem. It enables a group of Jupyter users with different roles\nto engage in scientific community activities and create FL\nbuilding blocks as research assets. This is achieved through\nthe Create FL Building Blocks function (Component Con-\ntainerizer within NaaVRE).\nYuandou Wang et al.: Preprint submitted to Elsevier\nPage 6 of 16\n\n\nManaging Federated Learning on Decentralized Infrastructures as a Reputation-based Collaborative Workflow\n \nfrontend \n \n \n \n \n \n \nSystem status \nÂ updates\nBlockchain Network\n \nData ownerÂ stakes their native  \ntokens in staking pool\n \n \n \n \nBlock data\n... ...\nBlockchain network\nNode 1\nNode 2\nNode i\nNode j\nNode N\nMake an agreement for the FL workï¬‚ow\n \nLocal updates evaluation\nPost an ad to call for collaboration (CfC)\n \n \n \n \n \n \n \n \n \n \nIndividual user with digital wallet\n \nData owner\n \nData ownerÂ \nCompute\nPrivate Cloud\n \n \n \n \nData\n \n \n \nData\nPrivate Cloud\n \n \n \n \n \n \n \n \n \n \nfrontend \n \n \n \n \n \n \n \n \n \n \n \n \n \n \nfrontend \n \n \n \n \n \n \n \n \n \n \n \n \n \n \nÂ Create ML Model \nÂ  [ Component Containerizer ]\nÂ Customize FL Workï¬‚ows \nÂ  Â [ Workï¬‚ow Composer ]\nSign Multidimensional Contracts \nÂ  [ Make Agreements ]\nFL computational workï¬‚ow examples\nDeliver models to data owners (stakeholders), trigger the deployment and execution of FL workï¬‚ow(s) off-chain\nCWL engine \nScale FL workï¬‚ows\n...\nHierarchical FL\nDecentralized FL\nCentralized FL\n......\n \n \nData\n \nfrontend \n \n \n \n \n \n \n \n \n \n \n \n \n \n \nInfra ownerÂ \nCompute\nfrontend\nLocal Virtual Research Environment\nTraining Node\nAggregator\nFederated Node\nSmart contract\nBlockchain\n \n \n \n \nTokens\nÂ Access to blockchain\nÂ  [ Auth via Digital Wallet ]\nFigure 4: This is an overview of the system for FL applications. A local virtual research environment enables a user to develop\nML models on-premise and unlocks the potential of establishing robust collaboration in a decentralized environment via â¶â·\nand â¸. It consists of two main interfaces: 1) via blockchain interfaces, users can access to the blockchain network to call for\ncollaboration, make an agreement, and evaluate local updates on-chain; 2) via workflow runtime interfaces, users can create ML\nmodels, customize FL workflows, operate collaborative workflows on decentralized infrastructure.\nThrough the function Access to blockchain (Auth via\nDigital Wallet within D-VRE), the system allows users to\nconfigure their digital wallets like MetaMask, to unlock the\ndecentralized Web and applications to call for collaboration\nand secure asset sharing in a decentralized environment [48].\nDue to the diverse data access restrictions, data can not\nbe moved out of the institutions [38]. The system allows\nmodel providers (also called FL task publishers) to Call\nfor Collaborations (CfCs) to enable secure data sharing,\ncomputing resource sharing, and collaborative learning from\nthe decentralized community, via the Sign multidimensional\ncontracts function (Make Agreements within D-VRE). Data\nor resource owners can respond to the CfCs via the interfaces\nembedded in their personal frontends.\nEach CfC will include specific requirements, e.g., the\ndata and resource specifications, required stakes, targeted\nmodel performance, minimum number of participants, and\nwhat the publisher can offer (such as reward), rules of\npenalty, and reputation updates resulting from different con-\ntribution behaviours. These requirements can be explicitly\ndescribed in a smart contract. The stake is related to crypto\nstaking in the blockchain system, which is the practice of\nlocking participantsâ€™ digital tokens to a blockchain network\nto earn rewards. For instance, a participantâ€™s stake can be re-\nturned later with an additional reward if there is no indication\nof malicious behaviours [49]. The stake plays a crucial role\nin reliable FL, as 1) it can increase the cost of attacks and\n2) promote risk-sharing during FL system operations. The\ncandidate has to join the contract to make agreements.\nVia the function of Customize FL workflow (Workflow\nComposer and CWL-based FL workflow composition),\nusers who signed contracts acting as FL participants can\ncustomize a computational FL workflow through verified\nresources from the off-chain decentralized (data) infras-\ntructures. We assume that data are stored in the infras-\ntructures which provide computation capacity and network\nfor communication. Some participants may only contribute\nto infrastructure, e.g., computing, storage, and network\nresources. Each participant can be identified and verified\nfor their resources through trusted external committees,\nsuch as Oracle and DAO [50]. Hence, the composition of\ncomputational FL workflows can combine the on-chain and\noff-chain services to scale different FL scenarios.\nAfter the FL workflow with on-chain engagement has\nbeen confirmed, the system generates a number of smart con-\ntract instances to enforce the contract items and ensures that\nprecise, mutually agreed-upon terms govern collaborations\nin the decentralized network. The system enables users to\nstart the CWL engine for automating FL workflow deploy-\nment and execution over legacy data infrastructures while\nenabling secure and transparent execution in the blockchain\nenvironment. Since the block data has stored ledgers about\nFL actions for all participants in the blockchain network,\nit can correlate the captured data with user behaviours to\nmaintain a transparent record of any changes made to an\nFL operation. Finally, users can evaluate local updates of\ntheir FL workflows related to domain-specific subjects and\nanalyze the consequences of participantsâ€™ actions regarding\nrelevant task contributions, reputation updates, and rewards.\n4.2. How to Incentivize Collaboration?\nIn real-life scenarios, the FL task publisher does not\nknow which users in the system would join the FL training\ndue to the lack of prior information. The local data quality\nYuandou Wang et al.: Preprint submitted to Elsevier\nPage 7 of 16\n\n\nManaging Federated Learning on Decentralized Infrastructures as a Reputation-based Collaborative Workflow\nand the computing power of available resources from poten-\ntial candidates are unknown to the publisher owing to data\nprivacy and security concerns. Therefore, it is essential for\nthe task publisher to design an efficient incentive mechanism\nto stimulate active engagement from high-quality candidates\nwhile reducing the over-reward risks caused by the issues\nof asymmetric information [34, 51]. This study employs\nthe contract theory with a multidimensional scheme as an\nefficient approach to address the incentive collaboration\nproblem.\nAssume a set of â„•potential candidates responds to the\nCfC task in the system. Let ğ‘= 1, 2, â‹¯, ğ‘›, where ğ‘âŠ†â„•,\nrepresent the set of identity-verified candidates who have\nsigned contracts with stakes ğ‘†= ğ‘†1, ğ‘†2, â‹¯, ğ‘†ğ‘›and initial\nreputations ğ‘Ÿ0 = ğ‘Ÿ0\n1, ğ‘Ÿ0\n2, â‹¯, ğ‘Ÿ0\nğ‘›. These candidates act as FL\nparticipants, continuously contributing to the FL network.\nEach participantâ€™s reputation is dynamically updated based\non their behaviour.\nLet ğœƒdenote a standard type space to differentiate the\nparticipant nodes. Suppose participants are classified into ğ‘\ntypes, which can be sorted in a descending order regarding\ncontribution types: ğœƒ1 > ğœƒ2 > â‹¯> ğœƒğ‘›, ğ‘–âˆˆ{1, 2, â‹¯, ğ‘›}.\nLet Ì‚ğœƒğ‘–be the claimed type by participant ğ‘–with the true\nğœƒğ‘–. We assume that candidates who join the FL must claim\ntheir types Ì‚ğœƒand select the corresponding contract item ğœ™Ì‚ğœƒ.\nAlthough the task publisher does not know about the true\ntype of a given participant due to the information asym-\nmetry, it has information about the reported type Ì‚ğœƒğ‘–by the\nparticipant with the true type ğœƒğ‘–(e.g., data and infrastructure\nspecifications), from which the publisher can inform the\nprobability that a participant belongs to a particular type ğœƒğ‘–\nwith reported (meta)data and computing power categories,\ndenoted as âˆ‘ğ‘\nğ‘–=1 ğ‘ğ‘–(Ì‚ğœƒğ‘–) = 1.\nFor participants with different contributions, the task\npublisher signs different contract items with them. We define\nthe contract îˆ¯= (ğ‘‡max, Î¦) is comprised of a maximum\nwaiting time ğ‘‡max and contract terms Î¦ = {ğœ™ğ‘–}ğ‘–âˆˆğ‘. ğ‘‡max\ndenotes the maximum allowable time for receiving partic-\nipantsâ€™ contributions. Each contract item ğœ™ğ‘–â‰œ(ğ¶ğ‘–, ğ‘†ğ‘–, ğ‘…ğ‘–)\nspecifies the relationship among each type-ğ‘–participantâ€™s\nstake ğ‘†ğ‘–, contribution ğ¶ğ‘–(often associated with a completion\ntime ğœğ‘–â‰¤ğ‘‡max), and its corresponding reward ğ‘…ğ‘–. Any par-\nticipant who completes their contributions to the FL network\nwithin the required time during each communication round\nwill receive a reward ğ‘…ğ‘–. Conversely, participants whose\ncompletion time ğœğ‘–exceeds ğ‘‡max will receive a zero reward,\nresulting in a zero contract instance.\nContribution model. We define a contribution model for\neach FL workflow. Let ğ¶(ğ‘¡)\nğ‘–\ndenote an estimated contribution\nbased on the ğ‘–ğ‘¡â„participantâ€™s local model training ğ‘“local and\nits behaviours ğ‘”behaviour at round ğ‘¡, which can be formally\ndefined as:\nğ¶(ğ‘¡)\nğ‘–\n=ğ‘“local(ğ·ğ‘–, ğ°(ğ‘¡)\nğ‘–) â‹…ğ‘”behaviour(â„(ğ‘¡)\nğ‘–),\nâˆ€ğ‘–âˆˆğ‘\n(3)\nwhere ğ¶(ğ‘¡)\nğ‘–\nâ‰¥0 and â„(ğ‘¡)\nğ‘–\nis the historical behaviour records\nregarding reputation and stake which can be used to differ-\nentiate honest participant nodes and malicious ones.\nLet ğ‘‡max denote the upper limit on the duration in FL\nsynchronous settings, within which participants must sub-\nmit their contributions, such as local model updates ğ°(ğ‘¡)ğ‘–,\nbefore the aggregation is triggered within the federation.\nSpecifically, participants with ğœğ‘–â‰¤ğ‘‡max can complete the\nsubmission of model updates to allow the aggregation of\nfederated models to proceed on time per communication\nround. We define the contribution value function ğ‘‰(â‹…) for\nany participant ğ‘–âˆˆğ‘as follows:\nğ‘‰(ğ¶(ğ‘¡)\nğ‘–, ğœğ‘–) = ğ‘‹ğ‘\nğœğ‘–\nâ‹…ğ‘(ğ‘¡)\nğ‘–,\nğ‘(ğ‘¡)\nğ‘–\n= ğœ(\nğ¶(ğ‘¡)\nğ‘–\nâˆ’ğ¶min\nğ¶max âˆ’ğ¶min\n)\n(4)\nwhere ğœğ‘–is the time cost for participant ğ‘–to make contribu-\ntion ğ¶(ğ‘¡)\nğ‘–, and ğ‘‹ğ‘\nğœğ‘–represents the unit price of the contribution\nfor participant ğ‘–, where ğ‘‹ğ‘is a constant factor representing\nthe value associated with the contribution. We define ğ‘(ğ‘¡)\nğ‘–\nas a dynamic quality parameter via the sigma function ğœ(â‹…),\nwhere ğ¶max represents the saturation threshold for contri-\nbution, and ğ¶min is the minimum required contribution. A\nhigher value of ğ‘‰(â‹…) indicates better quality in the local\ntraining contribution, leading to fewer training iterations\nneeded to reach a targeted model performance score (e.g.,\naccuracy, precision, recall, or F1 score).\nUtility function of participants. For a signed contract ğœ™ğ‘–,\nwe define the utility function of the type-ğ‘–participant at\nround ğ‘¡as follows,\nğ‘ˆğ‘(ğœ™ğ‘–|ğœƒğ‘–) = ğ‘…ğ‘–ğ•€compl âˆ’ğœ†ğ‘ ğ‘†ğ‘–(1 âˆ’ğ•€compl) âˆ’ğ‘(ğ¶(ğ‘¡)\nğ‘–) (5)\nğ•€compl = exp(âˆ’\nğ¾\nâˆ‘\nğ‘˜=1\nğœ”ğ‘˜â‹…VSLğ‘˜).\n(6)\nThe compliance condition, ğ•€compl âˆˆ[0, 1], is derived from\nthe violation levels. For example, minor violations (e.g.,\noccasional timeouts) will result in a partial retention of\nproceeds, while severe violations (e.g., malicious behaviour)\nwill reduce the proceeds to zero. The normalized violation\nlevel for the ğ¾violation types is denoted by VSLğ‘˜âˆˆ[0, 1],\nwith ğœ”ğ‘˜representing the weight of the ğ‘˜ğ‘¡â„violation type. A\nvalue of ğ•€compl = 1 indicates no violations, while ğ•€compl = 0\nsignifies severe violations.\nThe parameter ğœ†ğ‘ defines the penalty factor applied to\nthe ğ‘–ğ‘¡â„participantâ€™s stake, ğ‘†ğ‘–. If a node operates without\nviolations, a proportion of the stake, ğœ†ğ‘ ğ‘†ğ‘–, is allocated to\nthe systemâ€™s risk reserve. However, if violations occur, the\nparticipant risks forfeiting the entire stake, ğœ†ğ‘ ğ‘†ğ‘–. Addition-\nally, ğ‘(â‹…) represents the effort cost for contributing ğ¶(ğ‘¡)\nğ‘–\nwith\ntime ğœğ‘–by the type-ğ‘–participant. This cost can be further\nextended to more complex expressions by factoring in the\nresource utilization required for model training, validation,\nand aggregation.\nProfit function of the task publisher. Task publisherâ€™s\nprofit derived from a type-ğ‘–participant is influenced by\nYuandou Wang et al.: Preprint submitted to Elsevier\nPage 8 of 16\n\n\nManaging Federated Learning on Decentralized Infrastructures as a Reputation-based Collaborative Workflow\nmultiple factors. Although a high-quality contribution can\nincrease the task publisherâ€™s profit, it also incurs a higher re-\nward cost for the publisher. In addition, any violations (e.g.,\ntimeouts, malicious actions, or mismatched behaviours) by\nparticipants will result in a deduction from their stake (or\ntokens) as penalties, which are then allocated as profits to the\npublisher. Therefore, we define the profit function obtained\nfrom participant ğ‘–as follows:\nğœ‹(ğœ™ğ‘–) =(ğ‘‰(ğ¶(ğ‘¡)\nğ‘–) âˆ’ğ‘…ğ‘–)ğ•€compl + ğœ†ğ‘ ğ‘†ğ‘–(1 âˆ’ğ•€compl),\n(7)\nwhere ğ‘‰(ğ¶(ğ‘¡)\nğ‘–) âˆ’ğ‘…ğ‘–â‰¥0, the profit is positive; otherwise,\nthe publisher risks incurring a negative profit, even if no\nviolations occur from any participant ğ‘–.\nTo make the contract feasible, it must satisfy the follow-\ning constraints simultaneously.\nDefinition 1 (Individual Rationality (IR)). Let ğ‘ˆğ‘(ğœ™ğ‘–|ğœƒğ‘–) be\nthe utility for the type-ğ‘–participant under the contract ğœ™ğ‘–.\nEach type-ğ‘–participant achieves the non-negative utility if it\nchooses the contract item ğœ™ğ‘–that is designed for its own type\nğœƒğ‘–, which is given by\nğ‘ˆğ‘(ğœ™ğ‘–|ğœƒğ‘–) â‰¥0.\n(8)\nDefinition 2 (Incentive Compatibility (IC)). Each partici-\npant ğ‘–achieves the maximum utility by truthfully reporting\nits type ğœƒğ‘–if it chooses the contract item ğœ™ğ‘–that is designed\nfor its own type ğœƒğ‘–rather than other types ğœƒâˆ’ğ‘–in contract\nitems ğœ™ğœƒâˆ’ğ‘–. The mechanism is incentive compatible if\nğ‘ˆğ‘(ğœ™ğ‘–|Ì‚ğœƒğ‘–= ğœƒğ‘–, ğœ™ğœƒâˆ’ğ‘–) â‰¥ğ‘ˆğ‘(ğœ™ğ‘–|Ì‚ğœƒğ‘–â‰ ğœƒğ‘–, ğœ™ğœƒâˆ’ğ‘–),\n(9)\nğ‘ˆğ‘(ğœ™ğ‘–|Ì‚ğœƒğ‘–= ğœƒğ‘–, ğœ™ğœƒâˆ’ğ‘–) â‰¥ğ‘ˆğ‘(ğœ™ğ‘—|Ì‚ğœƒğ‘—= ğœƒğ‘—, ğœ™ğœƒâˆ’ğ‘–),\n(10)\nwhere ğœƒâˆ’ğ‘–âˆªğœƒğ‘–= ğœƒ, ğœƒâˆ’ğ‘–â‰ ğœƒğ‘–, and ğœƒğ‘–â‰¥ğœƒğ‘—for all participants\nğ‘–, ğ‘—âˆˆğ‘.\nAs a rational individual, the task publisher aims to max-\nimize its profit in the system [52]. Therefore, the total\nincentive problem is given by\nmax Î (Î¦) =\nğ‘\nâˆ‘\nğ‘–=1\nğ‘ğ‘–(Ì‚ğœƒğ‘–) â‹…ğœ‹(ğœ™ğ‘–),\nâˆ€ğœ™ğ‘–âˆˆÎ¦\n(11)\ns.t., IR(ğ¸ğ‘. 8) and IC(ğ¸ğ‘ğ‘ . 9, 10) constraints.\n(12)\nTo mitigate the risks of over-rewarding or insufficient re-\nwards, it is crucial to examine the optimality of the contract\nproblem.\n4.3. How to Assure Training Quality along with\nContract Optimality?\nThis section first employs a mechanism design approach\nthat integrates a reputation system and dynamic incentive\nindicators within contracts to ensure training quality in an\nunreliable environment. Then, leveraging a quantified re-\nward measurement, we analyze the optimality of the con-\ntract problem. Figure 5 illustrates the key steps involved in\nassuring training quality, including reputation-based com-\nmittee selection, malicious detection and penalty, reputation\nupdates, and reward calculation.\nReputation-based committee selection. We introduce a\ncommittee of high-reputable and highly effective nodes\namong participants to do extra work like being responsible\nfor partial model validation and aggregation. Let îˆ¹(ğ‘¡) be the\nfinal selected committee in each round ğ‘¡, where îˆ¹(0) = âˆ…\nand îˆ·is the committee size. We use a stratified sampling\nmethod [53] based on reputation ğ‘Ÿ(ğ‘¡) = {ğ‘Ÿ(ğ‘¡)\n1 , ğ‘Ÿ(ğ‘¡)\n2 , â‹¯, ğ‘Ÿ(ğ‘¡)\nğ‘›}\nand a cooling-down mechanism, to balance the advantages\nof highly reputable nodes.\nFirst, we sort the nodes with reputation descending\nand divide them into several strata layers. Let ğ‘sorted =\nsort(ğ‘, ğ‘Ÿğ‘–â†“) be the sorted set and ğ¿be the number of\nstrata to divide the nodes into. For each stratum layer ğ¿ğ‘˜=\nğ‘sorted[ (ğ‘˜âˆ’1)ğ‘\nğ¿\n, ğ‘˜ğ‘\nğ¿), 1 â‰¤ğ‘˜â‰¤ğ¿, the initial quota per stratum\nğ‘„ğ‘˜is calculated by\nğ‘„ğ‘˜= âŒŠîˆ·\nğ¿âŒ‹+\n{\n1,\nif ğ‘˜â‰¤îˆ·\nmod ğ¿,\n0,\notherwise.\n(13)\nFor each layer, the set of eligible nodes is îˆ±ğ‘˜= {ğ‘–âˆˆ\nğ¿ğ‘˜|ğ‘ğ‘‘(ğ‘¡)\nğ‘–\n= 0}, where ğ‘ğ‘‘(ğ‘¡)\nğ‘–\n= 0 indicates the node ğ‘–is\nnot cooling down. Hence, we can determine the number of\nselected nodes ğ‘šğ‘˜= max(1, min(ğ‘„ğ‘˜, |îˆ±ğ‘˜|)) per layer, using\nthe selection probability sampling performed as follows:\nP(ğ‘–) =\n(ğ‘Ÿğ‘–)ğ›¾\nâˆ‘\nğ‘—âˆˆîˆ±ğ‘˜(ğ‘Ÿğ‘—)ğ›¾,\nğ‘—âˆˆîˆ±ğ‘˜\n(14)\nwhere ğ›¾âˆˆ(0, 1] is a decay exponent of reputation co-\nefficient. Then, îˆ¹ğ‘˜is obtained by randomly selecting ğ‘šğ‘˜\nnodes in îˆ±ğ‘˜based on selection probabilities P(ğ‘–) without\nreplacement. Hence, it follows a hypergeometric distribu-\ntion in probability theory and statistics [54], which can be\nformally stated as îˆ¹ğ‘˜âˆ¼Hypergeometric(ğ‘šğ‘˜, îˆ±ğ‘˜, P(ğ‘–)).\nIn the case of âˆ‘ğ¿\nğ‘˜=1 |îˆ¹ğ‘˜| < îˆ·, we calculate a re-\nmaining quota îˆ·remain = îˆ·âˆ’âˆ‘ğ¿\nğ‘˜=1 |îˆ¹ğ‘˜| and gather all\neligible nodes not yet selected as a global candidate pool,\nîˆ±global = (âˆªğ¿\nğ‘˜=1îˆ±ğ‘˜)âˆ–(âˆªğ¿\nğ‘˜=1îˆ¹ğ‘˜). Again, using the selection\nprobability sampling on the global eligible pool to calculate\nthe remaining committee îˆ¹remain, which is given by,\nPâ€²(ğ‘–) =\n(ğ‘Ÿğ‘–)ğ›¾\nâˆ‘\nğ‘—âˆˆîˆ±global (ğ‘Ÿğ‘—)ğ›¾,\nğ‘—âˆˆîˆ±global\n(15)\nHence, îˆ¹remain âˆ¼Hypergeometric(îˆ·remain, îˆ±global, Pâ€²(ğ‘–)),\nand the total committee is obtained by îˆ¹= (âˆªğ¿\nğ‘˜=1îˆ¹ğ‘˜) âˆª\nîˆ¹remain.\nAfter the final selection, the system updates each nodeâ€™s\nstatuses, including the selected history and the cooldown\ntime ğ‘ğ‘‘ğ‘–, which is formulated by\nğ‘ğ‘‘(ğ‘¡+1)\nğ‘–\n=\n{\n3,\nif ğ‘–âˆˆîˆ¹,\nmax(0, ğ‘ğ‘‘(ğ‘¡)\nğ‘–\nâˆ’1),\notherwise.\n(16)\nYuandou Wang et al.: Preprint submitted to Elsevier\nPage 9 of 16\n\n\nManaging Federated Learning on Decentralized Infrastructures as a Reputation-based Collaborative Workflow\nÂ Â  \nÂ  Â The proposedÂ FL workï¬‚ow run per round\n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \ncontracts\nstart a new FL round\nSelect committee\nmembers\nPerform federated model\naggregation\nTraverse all nodes\nYes\nNo\nMalicious?\nApply penalty to\nmalicious nodes\nUpdate\nreputation\nCalculate reward\nRecord metrics\nEnd the round\nCollect all contributions\nMake contributions\nFigure 5: Flowchart of FL system operations per round.\nwhere we specify that if ğ‘–is selected as a committee, the\nsystem will update the cooldown as three at the current round\nand decrease the cooling time of the unselected nodes by one\ncooldown per round.\nReputation update model. We employ a dynamic reputa-\ntion update model to encourage long-term high-quality and\nstable contributions for all participants through a bonus for\nthe quality and stability of contributions while discouraging\nmalicious behaviours by penalties on reputation. To achieve\nthat, we consider a dynamic decay factor ğ›¿âˆˆ[0, 1] to\nincentivize long-term participation by obtaining a reputation\ncompensation from the last round, which is given by\nğ›¿= ğ›¿ğ‘+ ğœ†ğ‘â‹…(1 âˆ’\n1\n1 + participationğ‘–âˆ•100),\n(17)\nwhere ğ›¿ğ‘is a base decay factor. ğœ†ğ‘denotes a decay com-\npensation parameter and participationğ‘–is the ğ‘–ğ‘¡â„partic-\nipantâ€™s historical participation times. As such, the more\nparticipationğ‘–, the higher the reputation compensation ğ›¿â‹…\nğ‘Ÿ(ğ‘¡âˆ’1)\nğ‘–\nfor round ğ‘¡.\nBesides, a good quality of contribution is good for an\nincreased reputation. Let ğ‘‹ğ‘denote a unit bonus from the\ncontribution quality to reputation updates, the amount of in-\ncreased reputation resulting from good contribution is given\nby ğ‘‹ğ‘â‹…ğ‘(ğ‘¡)\nğ‘–, where ğ‘(ğ‘¡)\nğ‘–\nis quantified by Eq. 4. Additionally,\nwe define ğœ†stab = 1 âˆ’std([ğ¶ğ‘¡âˆ’ğœ\nğ‘–\n, â‹¯, ğ¶ğ‘¡\nğ‘–])âˆ•ğœas a stability\nparameter during the last ğœrounds to avoid malicious nodes\nwith random attacks to obtain rewards. Hence, the new\nreputation at round ğ‘¡can be defined by\nğ‘Ÿ(ğ‘¡)\nğ‘–\n= ğ›¿ğ‘Ÿ(ğ‘¡âˆ’1)\nğ‘–\n+ ğ‘(ğ‘¡)\nğ‘–ğ‘‹ğ‘+ ğœ†stabğ‘‹ğ‘ ,\n(18)\nwhere ğ‘‹ğ‘ denote unit bonus from the stability to reputation\nupdates and ğ‘Ÿ(ğ‘¡)\nğ‘–\nâˆˆ[0, ğ‘Ÿmax]. We employ a dynamic maxi-\nmum capability ğ‘Ÿmax per round to limit the upper bound of\nreputation updates.\nMalicious detection and penalty. To safeguard the FL pro-\ncess, we consider malicious detection and penalty through\na set of conditions. It consists of: 1) persistent low contri-\nbutions (condition 1), 2) abnormal fluctuations (condition\n2), and 3) sudden behavioural changes (condition 3), which\nserve as indicators for detecting malicious nodes. For ease\nof analysis, we assume that any participantsâ€™ behaviours\nmeet the condition set (condition 1 AND condition 2) OR\ncondition 3, the system will detect them as a set of malicious\nnodes ğ‘malicious and perform a penalty to them. The penalty\nfunction is defined by,\npenalty = min(ğœ†ğ‘Ÿğ‘Ÿğ‘—+ ğœ†ğ‘ ğ‘†ğ‘—,\nğ‘Ÿğ‘—\n2 ),\n(19)\nwhere ğœ†ğ‘Ÿ, ğœ†ğ‘ denote the factors of applying penalty to repu-\ntation updates and stake, respectively. The upper bound\nğ‘Ÿğ‘—\n2\nis intended to avoid excessive penalties on the reputation.\nHence, the updated reputation for node ğ‘—at round ğ‘¡is given\nby ğ‘Ÿ(ğ‘¡)\nğ‘—= ğ‘Ÿ(ğ‘¡âˆ’1)\nğ‘—\nâˆ’penalty, âˆ€ğ‘—âˆˆğ‘malicious.\nReward calculation. Let ğµdenote the base reward of the\nreward pool. The reward calculation considers a participantâ€™s\nstake, historical contribution performance, and committee\nbonus. The stake and contribution proportions relative to\nthe overall records influence the rewards participants receive\nfrom the reward pool.\nWe introduce two dynamic weights, ğ›¼and ğ›½, based on\nreputation to balance the influence of stake and historical\ncontributions in reward calculation, where ğ›½= 1 âˆ’ğ›¼. The\nweight ğ›¼is defined as ğ›¼= ğœ(\nğ‘Ÿâˆ’ğ‘Ÿ0\nğ‘–\nğ‘“scale ) â‹…ğœ†stake, where ğœ†stake\nis the global stake weight, and reputation ğ‘Ÿdetermines the\nadjustment.\nTo prevent monopolization, we introduce an effective\nstake limit for large nodes, ensuring no single node domi-\nnates. The effective stake is given by ğ‘†eff\nğ‘–\n= min(ğ‘†ğ‘–, 3 â‹…ğ‘†),\nwhere nodes holding more than three times the average stake\nğ‘†are capped.\nThe historical contribution of participant ğ‘–over the last ğœ\nrounds is computed as ğ¶hist\nğ‘–\n= âˆ‘ğœ\nğ‘¡=0 ğ¶(ğ‘¡âˆ’ğœ)\nğ‘–\nâ‹…ğœğ‘¡, where ğœğ‘¡(ğœâˆˆ\n(0, 1)) is an exponential decay factor that prioritizes more\nrecent contributions. The total historical contribution across\nall participants is given by ğ¶total = âˆ‘\nğ‘–âˆˆğ‘\nâˆ‘ğœ\nğ‘¡=0 ğ¶(ğœâˆ’ğ‘¡)\nğ‘–\nâ‹…ğœğ‘¡.\nYuandou Wang et al.: Preprint submitted to Elsevier\nPage 10 of 16\n\n\nManaging Federated Learning on Decentralized Infrastructures as a Reputation-based Collaborative Workflow\nAny participant selected as a committee member will\nreceive a bonus for their contributions to model validation\nand aggregation, which is formulated by,\nğ‘…cmm =\n{\nğµcmm â‹…ğ½c(ğ‘Ÿ),\nif ğ‘–âˆˆîˆ¹(ğ‘¡),\n0,\notherwise.\n(20)\nHere, ğ½c(ğ‘Ÿ) =\n(âˆ‘îˆ·\nğ‘–=1 ğ‘Ÿğ‘–)2\nîˆ·â‹…âˆ‘îˆ·\nğ‘–=1 ğ‘Ÿğ‘–2+ğœ–â‹…ğœ( ğ‘Ÿ\n10), ğµcmm represents a base\nbonus, and ğ½ğ‘(ğ‘Ÿ) is an improved Jainâ€™s fairness index [55]\ncalculated from the reputation scores of the committee. A\nsmall constant ğœ–is introduced to prevent division by zero\nerrors. The sigmoid function ğœ( ğ‘Ÿ\n10) ensures that the average\nreputation score is mapped to the range (0, 1). When the\nmean reputation ğ‘Ÿis low, the overall score decreases accord-\ningly. If the fairness index ğ½ğ‘(ğ‘Ÿ) is low, the committee reward\nğ‘…cmm is also reduced, which promotes fair and balanced\nincentives.\nFurthermore, we employ ğ½(ğ‘Ÿ) based on reputation, as\na fairness indicator to ensure equitable reward distribution\namong all participants ğ‘–âˆˆğ‘when earning rewards from\ntheir stake and historical contributions. Consequently, the to-\ntal reward allocated to each participant at round ğ‘¡is formally\ndefined as\nğ‘…(ğ‘¡)\nğ‘–\n= (ğ›¼â‹…ğµ\nğ‘†eff\nğ‘–\nâˆ‘ğ‘†ğ‘—\n+ ğ›½â‹…ğµ\nğ¶hist\nğ‘–\nğ¶total\n) â‹…ğ½(ğ‘Ÿ) + ğ‘…cmm (21)\nNote that if a participant has no contribution history (i.e.,\nğ¶hist\nğ‘–\n= âˆ…or ğ¶(ğ‘¡)\nğ‘–\n= 0), the current reward is set to zero,\nğ‘…(ğ‘¡)\nğ‘–\n= 0. Therefore, it enables adjustable weights and zero-\ncontribution handling to calculate the participantâ€™s reward.\nThe entire procedure can be implemented as a reputation-\nbased consensus in a smart contract for reliable FL pro-\ncesses, whose pseudocode is presented in Algorithm 1.\nContract optimality. With the above formulated optimiza-\ntion problem and detailed reward model, we can now study\nthe optimality of the contract problem.\nLet ğœ™âˆ—\nğ‘–\nâ‰œ(ğ¶âˆ—\nğ‘–, ğ‘†âˆ—\nğ‘–, ğ‘…âˆ—\nğ‘–) âˆˆÎ¦âˆ—, âˆ€ğ‘–âˆˆğ‘in the new\nordering be the optimal contract that the task publisher\ncan derive from maximizing its total profit Î (â‹…) and each\nparticipant performs optimal behaviours to maximize its\nutility. These contract items are found through solving the\noptimization problem as presented in Eq. 11 under the IC\nand IR constraints. To derive the optimal contract for this\nproblem, there may be several solutions.\nFor ease of analysis, we simplify the derivation process.\nBy assuming that: 1) all participants comply with the rules\nviz ğ•€compl = 1 (no violations), 2) consider a single participant\nscenario that can ignore the IC constraint, and 3) the cost of\ncontribution ğ‘(ğ¶) = 1\n2ğ›¾ğ‘ğ¶2 where ğ›¾ğ‘> 0 is a cost parameter\nand ğ¶âˆˆ[0, ğ¶max], the relaxation version of the optimal\nproblem can be formulated as\nmax\nğ¶,ğ‘†,ğ‘…Î  = ğ‘‰(ğ¶) âˆ’ğ‘…,\ns.t. ğ‘…âˆ’1\n2ğ›¾ğ‘ğ¶2 â‰¥0.\n(22)\nIf we ignore the IR constraint and directly maximize profit\nÎ , we need to define the relationship between the reward ğ‘…\nAlgorithm 1: Reputation-based reliable FL con-\ntract.\nOutput: Well-trained model ğ°, updated reputation\nğ‘Ÿ, reward ğ‘….\nInput: FL workflow ğ¹, consisting of: an initial\nmodel ğ°, a set of ğ‘participants indexed by\nğ‘–, an aggregation strategy ğ´, and system\nconfiguration.\n1 Initialize the FL workflow ğ¹;\n/* Define the data structures:\n*/\n2 struct Node { id, stake, reputation, totalReward,\nviolations, participation, cooldown, ...,\nidentityVerified }\n3 struct SystemConfig { baseReward, committeeSize,\nstakeWeight, ..., maliciousPercent }\n4 contract FLSystem {\n// Define the main contract\n5\nInitialize the nodes;\n6\nInitialize the SystemConfig;\n7 â‹¯\n/* Core logic of the main contract:\n*/\n8\nfunction runRound() {\n9\nfor each round ğ‘¡do\n10\nCollect ğ¶(ğ‘¡) = {ğ¶(ğ‘¡)\nğ‘–\nâˆ£âˆ€ğ‘–âˆˆğ‘} within ğ‘‡max;\n11\nîˆ¹(ğ‘¡) â†selectCommittee(ğ‘Ÿ(ğ‘¡), îˆ·, ğ¿);\n12\ncommittee performs aggregation;\n13\n/* Malicious detection and penalty:\n*/\n14\nif âˆ€ğ‘–âˆˆğ‘malicious = âˆ…then\n15\nUpdate reputation: ğ‘Ÿ(ğ‘¡)\nğ‘–\nâ†Eq. 18;\n16\nelse\n17\nApply penalty: ğ‘ğ‘’ğ‘›ğ‘ğ‘™ğ‘¡ğ‘¦ğ‘–â†Eq. 19;\n18\nğ‘Ÿ(ğ‘¡)\nğ‘–\nâ†ğ‘Ÿ(ğ‘¡âˆ’1)\nğ‘–\nâˆ’ğ‘ğ‘’ğ‘›ğ‘ğ‘™ğ‘¡ğ‘¦ğ‘–, âˆ€ğ‘–âˆˆğ‘malicious;\nviolation + +;\n19\nCalculate rewards: ğ‘…(ğ‘¡)\nğ‘–\nâ†Eq. 21, âˆ€ğ‘–âˆˆğ‘;\n20\nğ‘¡+ +;\n/* Stop when an end condition triggers\n*/\n21\nreturn final model weights ğ°, ğ‘Ÿ, ğ‘….\n22\n}\n23 Each FL client executes:\n24\nfor each client ğ‘–âˆˆğ‘at round ğ‘¡in parallel do\n25\nUpdate model and calculate contributions:\nğ°(ğ‘¡)\nğ‘–, ğ¶(ğ‘¡)\nğ‘–\nâ†Eqs. 1, 3;\n26 Committee executes:\n27\nAggregate model weights: ğ°(ğ‘¡+1) â†Eq. 2;\n(Eq. 21) and contribution value ğ‘‰(ğ¶) (Eq. 4). We further\nassume 1) there are no monopoly stakes ğ‘†â‰¤3ğ‘†, then\nğ‘†eff = ğ‘†, 2) ğ‘Ÿğ‘–= ğ‘Ÿ, then ğ›¼= ğœ†stake, and 3) both ğ¶hist and\nğ¶total are constants. At this point, maximizing Î  is equivalent\nto differentiating the objective function with respect to the\nfirst term ğ¶and solving the first-order condition, which can\nbe rearranged as\nğœ•Î \nğœ•ğ¶= ğ‘‰â€²(ğ¶)âˆ’(1 âˆ’ğœ†stake)ğµğ½(ğ‘Ÿ)\nğ¶total\nâ‹…ğœ•ğ¶hist\nğœ•ğ¶\n= 0,\n(23)\nYuandou Wang et al.: Preprint submitted to Elsevier\nPage 11 of 16\n\n\nManaging Federated Learning on Decentralized Infrastructures as a Reputation-based Collaborative Workflow\nwhere we assume ğ¶hist = ğ¶â‹…âˆ‘ğœ\nğ‘¡=0 ğœğ‘¡, which leads to\nğ‘‰â€²(ğ¶) = (1 âˆ’ğœ†stake)ğµğ½(ğ‘Ÿ)\nğ¶total\nâ‹…1 âˆ’ğœğœ+1\n1 âˆ’ğœ\n.\n(24)\nCorrespondingly, we define ğ‘˜=\n1\nğ¶max to extend the ğ‘‰(ğ¶)\nas the full version and calculate its derivative ğ‘‰â€²(ğ¶), which\nis calculated by,\nğ‘‰â€²(ğ¶) =\nğœ•( ğ‘‹ğ‘\nğœâ‹…\n1\n1+ğ‘’âˆ’ğ‘˜ğ¶)\nğœ•ğ¶\n= ğ‘‹ğ‘â‹…ğ‘˜ğ‘’âˆ’ğ‘˜ğ¶\nğœ(1 + ğ‘’âˆ’ğ‘˜ğ¶)2 ,\n(25)\nThus, the optimal contribution ğ¶âˆ—made by participant can\nbe derived from ğ‘‰â€²(ğ¶âˆ—) (Eq. 24) = ğ‘‰â€²(ğ¶âˆ—) (Eq. 25), which\nis given by\nğ¶âˆ—= 1\nğ‘˜ln(\nğ‘‹ğ‘â‹…ğ‘˜ğœ(1 âˆ’ğœ)\n(1 âˆ’ğœ†stake)ğµğ½(ğ‘Ÿ)(1 âˆ’ğœğœ+1)ğ¶total\nâˆ’1).\n(26)\nSince 1\nğ‘˜= ğ¶max, then we have ğ¶âˆ—= ğ¶max â‹…ğ‘¦where\nğ‘¦= ln(ğ‘¥âˆ’1) is a logarithmically increasing function\nfor ğ‘¥=\nğ‘‹ğ‘â‹…ğ‘˜ğœ(1âˆ’ğœ)\n(1âˆ’ğœ†stake)ğµğ½(ğ‘Ÿ)(1âˆ’ğœğœ+1)ğ¶total that asymptotically con-\nverges, theoretically, the optimal contribution would ap-\nproach to positive infinity. However, the maximum prac-\ntical constraints ğ¶âˆˆ[ğ¶min = 0, ğ¶max], as a result, the\nactual optimal solution is ğ¶âˆ—\n= ğ¶max. In other words,\nğ¶âˆ—\nğ‘–âˆğ‘“local(ğ·ğ‘–, ğ°) â‹…ğ‘”behaviour(â„ğ‘–), adhering to optimal local\ntraining while demonstrating good behaviour, becomes the\ndominant strategy to maximize its utility for any participant.\nMeanwhile, ln(\nğ‘‹ğ‘â‹…ğ‘˜ğœ(1âˆ’ğœ)\n(1âˆ’ğœ†stake)ğµğ½(ğ‘Ÿ)(1âˆ’ğœğœ+1)ğ¶total âˆ’1) = 1 can serve\nas a guideline for tuning the parameters (e.g., ğœ†stake, ğ‘‹ğ‘and\nğµif given fixed others) to achieve the optimal solution. By\nbinding IR constraint, the optimal reward is ğ‘…âˆ—= ğ‘(ğ¶âˆ—). As\nall participants stake the same amount ğ‘†, which leads to\nğ‘†âˆ—=\nğœ†stakeğµğ½(ğ‘Ÿ)\nğ‘›â‹…(ğ‘…âˆ—âˆ’ğ‘…cmm âˆ’(1âˆ’ğœ†stake)ğµğ½(ğ‘Ÿ)ğ¶hist\nğ¶total\n)\n,\n(27)\nğ‘…âˆ—=ğ‘(ğ¶âˆ—).\n(28)\nIf we consider the IR constraint, the optimization prob-\nlem can be reorganized as a Lagrangian function with a\nLagrange multiplier and then repeat the derivation process\nfor the three terms ğ¶, ğ‘†, ğ‘…, respectively. With the help of\nmath tools (e.g., SciPy methods in Python) to solve for the\nproblem, we can obtain the optimal ğ¶âˆ—, ğ‘†âˆ—, ğ‘…âˆ—by adjusting\nthe parameters as needed by numerical analysis. Suppose\nthe distribution of the participantsâ€™ violations (concerning\nByzantine failures) is not predictable and the stakes are\nunbalanced. In those cases, we can consider using advanced\napproaches, such as Bayesian priors [56] or reinforcement\nlearning optimization [57], to meet the requirements.\n5. Experiments and Evaluation\nThis section illustrates simulation setup, demonstrates\nthe feasibility of the proposed incentive mechanisms, and\nevaluates the outcomes for validation and guidance of (opti-\nmal) smart contract design.\n5.1. Simulation Setup\nIn the simulation, we conducted extensive simulation\nexperiments on a local computer equipped with an Apple\nM1 chip with eight (four performance and four efficiency)\ncores, 16GB memory, and a 500 GB Macintosh HD disk.\nFor the evaluation of solutions, we utilize a normal\ndistribution îˆºwith random fluctuation îˆ²for the ease of\ntraining process to present the normal behaviour pattern\nfor participants acting normally, ğ¶normal = max(0, îˆº(ğœ‡=\n7, ğœ2 = 1)â‹…îˆ²), where ğœ‡and ğœdenote the mean and standard\ndeviation of the set of contributions collected from the\nnormal (or honest) FL participants. For malicious behaviour\npatterns, we simulate malicious patterns with three different\nattacks: 1) false high contribution attack, where malicious\nnodes disguise themselves as high-value nodes through ab-\nnormally high contributions to avoid detection based on low\ncontributions; 2) zero contribution attack where malicious\nnodes directly destroy the federated model aggregation and\nreduce model performance, and 3) random attack which is\ngiven by a random choice of 60% false high contribution\nattack and 40% zero contribution attack.\nWe introduce a parameter ğœ‚switch that allows switching\nbetween different patterns to simulate various malicious be-\nhaviours during the training process. The parameter defines\nthe longest time window threshold at which the system tran-\nsitions from base to progressive malicious phases â€” rang-\ning from high-contribution and zero-contribution attacks to\nrandomly hybrid attacks. This enables the implementation of\nmalicious pattern-switch logic for progressive attack testing,\nperiodic behavioural perturbations, and defense mechanism\nverification. By periodically switching attack strategies (e.g.,\nevery 30 rounds), we simulate the adaptability of malicious\nparticipants. Additional details are available in the source\ncode.\nAdditionally, we set different malicious percentages as\nan adjustable parameter to distinguish between malicious\nand honest nodes among the total participants. An attack\ndetection function is implemented to identify such malicious\nbehaviours, which allows us to test and evaluate the effects\nof penalties, reputation updates, and rewards on the system.\nA summary of the other parameters used in the simulation is\npresented in Table 2.\nTo measure the fairness in reward allocation based on\nactual contributions, we consider two metrics for evaluation.\nJainâ€™s fairness index [55] is a quantitative measure of fairness\nand discrimination for resource allocation in shared systems.\nWe have used it to maintain the fairness of committee\nselection on reputation presented in Eq. 20, whereas it can\nalso be employed to measure the fairness of reward allo-\ncation ğ½(ğ‘…) by replacing the input as ğ‘…. Additionally, we\nconsider an opposite metric â€” the Gini coefficient [58], as\na measurement of reward inequality, which is formulated by\nğ½(ğ‘…) =\n(âˆ‘ğ‘›\nğ‘–=1 ğ‘…ğ‘–)2\nğ‘›âˆ‘ğ‘›\nğ‘–=1 ğ‘…ğ‘–\n2 + ğœ–\nâ‹…ğœ( ğ‘…\n10),\n(29)\nYuandou Wang et al.: Preprint submitted to Elsevier\nPage 12 of 16\n\n\nManaging Federated Learning on Decentralized Infrastructures as a Reputation-based Collaborative Workflow\nTable 2\nParameter setting in the simulation.\nParameter\nDescription\nSetting\nğ‘†ğ‘–\ninitial stake\n100\nğ‘Ÿ0\nğ‘–\ninitial reputation score\n100\nğ¶min\nminimal contribution score\n0\nğ¶max\nmaximum contribution score\n10\nğ›¾\nreputation decay coefficient\n0.5\nğ‘Ÿğ‘¡â‰¤5\nmax, ğ‘Ÿğ‘¡>5\nmax\nmaximum capabilities of reputation updates\n300, 500\nğœ–\na small constant\n10âˆ’8\nğ‘ğ‘‘(â‹…)\ncooldown period\n3\nğ¿\nnumber of strata\n3\nğµcmm\nbase bonus to committee member\n40\nğ›¿ğ‘\nbase decay factor\n0.88\nğœ†ğ‘\ndecay compensation parameter\n0.07\nğœ\nrecent historical rounds\n5\nğœstab\ndefault stability for new participants\n0.8\nğ‘‹ğ‘\nbase bonus of contribution\n50\nğ‘‹ğ‘ \nbase bonus of stability\n30\nğœ†ğ‘Ÿ\npenalty factor to reputation\n0.3\nğœ†ğ‘ \npenalty factor to stake\n0.1\nğœ\nhistorical decay factor\n0.9\nğµ\nbase reward value in the pool\n1200\nğ‘›\nthe number of participants\n100\nğœ†stake\nstake weight\n0.4\nîˆ·\ncommittee size\n5\nğ‘š\nmalicious percent\n15%\nğœ‚switch\nthe first time window of observing a switch of malicious patterns\n5\nğ‘…ğ‘œğ‘¢ğ‘›ğ‘‘\nthe total number of the FL rounds\n90\nğº(ğ‘…) = (ğ‘›+ 1 âˆ’2\nâˆ‘ğ‘›\nğ‘–=1\nâˆ‘ğ‘–\nğ‘—=1 ğ‘…ğ‘—\nâˆ‘ğ‘›\nğ‘—=1 ğ‘…ğ‘—\n)âˆ•ğ‘›\n(30)\nwhere the input set ğ‘…is performed in ascending order. The\nsource code is available online at the GitHub repository7.\n5.2. Simulation Results\nThis section presents an overview of the simulation\nresults under the parameter setting presented in Table 2. Fig-\nure 6 showcases the dynamics of malicious node detection,\nreputation updates, and reward distribution per round.\nMalicious detection. Sub Figure 6a illustrates the malicious\ndetection performance per round. The detection method\nfollows the condition set (condition 1 AND condition 2) OR\ncondition 3, based on a malicious percentage of 15%. The\nmalicious pattern switch parameter ğœ‚switch plays a crucial\nrole in shaping the behaviour records of malicious partici-\npants, thereby influencing detection performance.\nNotably, false high-contribution malicious nodes were\nnot detected during the first five rounds, as the current\ndetection conditions do not account for high-contribution\nattacks, allowing such behaviours to appear normal. When\nthe round ğ‘¡âˆˆ[5, 30), the malicious pattern shifts to zero\ncontributions. By the eighth round, the system successfully\nidentified 12 out of 15 malicious nodes. When the round\nğ‘¡âˆˆ[30, 60), the malicious pattern transitions to random\nattacks, with a 60% probability of high-contribution at-\ntacks and a 40% probability of zero-contribution attacks.\nIn the final 30 rounds, malicious behaviours revert to zero-\ncontribution attacks. The detection method proves to be\nmore effective against zero-contribution attacks but remains\nineffective against false high-contribution attacks due to\ncurrent detection limitations.\nReputation updates. Sub Figure 6b illustrates the repu-\ntation update dynamics per round, distinguishing between\n7https://github.com/yuandou168/reliableFLOps\nhigh-contribution attack\nzero-contribution attack\nrandom contribution attack\n60% (high), 40% (zero)\nzero-contribution attack\n(a) Total malicious nodes detected per round.\n(b) Reputation update dynamics.\n(c) Reward distribution.\nFigure 6: Overview of malicious detection, reputation updates,\nand reward distribution per round.\nhonest and malicious nodes among 85 honest participants\nand 15 malicious ones. Initially, all nodes start with a repu-\ntation score of 100, which increases as new contributions are\ncollected during the first few rounds. This growth continues\nuntil it reaches a plateau around a reputation score of 300.\nNotably, there is no difference in reputation growth between\nhonest and malicious nodes until the eighth round.\nAt the eighth round, some malicious nodes experience\na sharp drop in reputation due to detected malicious be-\nhaviours, as shown in Figure 6a. Since most malicious nodes\nYuandou Wang et al.: Preprint submitted to Elsevier\nPage 13 of 16\n\n\nManaging Federated Learning on Decentralized Infrastructures as a Reputation-based Collaborative Workflow\nwere identified during this period, it caused their reputation\nscores to decline significantly, eventually approaching zero.\nDuring the random attack phase, the system fails to detect all\nmalicious activities, allowing some malicious nodes to tem-\nporarily regain their reputation through high-contribution at-\ntacks. This results in fluctuations in their reputation updates,\nas not all malicious nodes receive penalties in this phase.\nHowever, once all 15 malicious nodes are successfully de-\ntected, the fluctuations cease, and their reputation scores\nrapidly decline, dropping by an average of 148.3 points.\nMeanwhile, the reputation of the 85 honest nodes steadily\nincreased as expected in the first five rounds by 300. Then\nthey gradually reach the upper limit of 500. The average\nreputation increase for honest nodes is approximately 354.6,\nsignificantly higher than that of the malicious nodes.\nReward distribution dynamics. Sub Figure 6c illustrates\nthe reward distribution dynamics among 85 honest and 15\nmalicious nodes out of 100 participants. Because malicious\nnodes mimic high-contribution participants, they accumu-\nlate higher rewards than honest nodes. Hence, they exhibit\na higher average reward value and a faster growth rate\nin the early rounds. However, as the system detects zero-\ncontribution attacks, their rewards drop sharply to zero.\nAlthough some malicious nodes temporarily regain their\nreputation by engaging in high-contribution attacks in the\nperiod of random attacks, as more malicious nodes are\nprogressively detected, their corresponding rewards decline.\nAlthough all malicious nodes ultimately reach a very\nlow reward level over the 90 rounds, their total rewards are\nnot zero. Overall, the final reward values range between 4.1\nand 40.5 at round 90, satisfying the IR constraint. However,\nparticipants acting maliciously or continuing such behaviour\nunder this reward incentive mechanism cannot achieve op-\ntimal utility. Specifically, the average reward for malicious\nnodes dropped by 10.7, while the average reward for honest\nnodes increased by 23.0. The total reward accumulated by\nthe 85 honest nodes is 8.38 times greater than that of the 15\nmalicious nodes in the simulation system.\nConsequently, this incentive mechanism encourages par-\nticipants to adopt a more rational strategy â€” avoiding ma-\nlicious behaviour to maximize their rewards. Therefore, it\npreserves the trend of rewarding aligned with the incentives\nwhile reducing the risk of over-penalty and over-reward.\nFairness. Figure 7 compares the fairness of reward dis-\ntribution across 100 participant nodes under five different\nmalicious percentage settings. Similar to the reward dynam-\nics observed in Figure 6c, the fairness initially improves,\nas indicated by an increase in Jainâ€™s fairness index and a\ndecrease in the Gini coefficient (see Eq. 29), that suggests a\ntrend toward a more equitable reward distribution. However,\ndue to the influence of malicious nodes, the reward allocation\nis not always fair.\nFor instance, given a malicious percentage 15%, we\nobserved that malicious detection significantly influences\nreward allocationâ€™s fairness. When most or all malicious\nnodes are successfully identified, i.e., during rounds between\n8 and 30, as well as 60 to 90, the fairness index decreases\nFigure 7: Comparisons of total fairness metric dynamics across\nthe last 90 rounds.\nwhile the Gini coefficient increases. Conversely, fairness\nremains relatively stable when the system detects only a few\nmalicious nodes. It reflects an imbalanced reward allocation\ninfluenced by the performance of malicious detection.\nAs the percentage of malicious nodes in the system\nincreases, e.g., from 10% to 30%, the reward distribution\nbecomes more inequitable between honest and malicious\nnodes. However, such inequity remains at a healthy threshold\n(<0.3). Such a change is positive because it still preserves\nfairness among honest participants while preventing mali-\ncious participants from obtaining unfair rewards.\nThe optimal parameter space. In the simulation, we em-\nploy the controlled variable method and an optimization\nsolver â€˜SLSQPâ€™, which is suitable for constrained optimiza-\ntion, to analyze the applicable approximations of the optimal\ncontract items (ğ¶âˆ—\nğ‘–, ğ‘†âˆ—\nğ‘–, ğ‘…âˆ—\nğ‘–) âˆˆÎ¦âˆ—. The numerical analysis\nvalidates the optimal contribution ğ¶âˆ—â†’ğ¶max for all par-\nticipants. It also verifies that the IR-constrained satisfaction\nrate is 100% while minimum utility is more than zero. With\nthis numerical analysis, users can adjust their contract terms\nfor different requirements with optimal parameter settings.\nMore technical details have been presented in the source\ncode.\nThese simulation results suggest that the proposed incen-\ntive mechanisms are feasible in an FL system with honest\nand malicious participants. By coding these mechanisms\ninto smart contracts and bounding blockchain, the system\ncan effectively constrain and guide participant behaviour,\nensuring that honest participants can receive fair compensa-\ntion while discouraging malicious activities. The numerical\nanalysis can help customize (approximately) optimal con-\ntract items written in smart contracts to adopt diverse FL\nscenarios.\n6. Summary\nThis study demonstrated how FL can be structured as a\nworkflow using open workflow standards and executed on\nremote infrastructure to address automation challenges. To\nbridge the gap between traditional workflow-based automa-\ntion and decentralized collaboration, we propose a novel\nYuandou Wang et al.: Preprint submitted to Elsevier\nPage 14 of 16\n\n\nManaging Federated Learning on Decentralized Infrastructures as a Reputation-based Collaborative Workflow\nstrategy that builds upon our prior work to enhance re-\nliability in FL management over decentralized infrastruc-\ntures. We leverage contract theory with a multidimensional\nscheme to tackle the incentivizing collaboration problem\nby constructing a contribution model, implementing fair\ncommittee selection, dynamically updating reputations, cal-\nculating rewards, and defining corresponding profit and util-\nity functions. Additionally, we explore the optimality of\ncontracts to guide the design and implementation of smart\ncontracts that can be deployed on blockchain networks to\nassure training quality. We conduct extensive simulation\nexperiments to validate the proposed approach. The results\ndemonstrate that our incentive mechanisms are effective,\nensuring fair reward allocation despite malicious attacks.\nFuture improvements include encoding the optimal contract\nitems into smart contracts for real-world system performance\nevaluation and prototyping an integrated on-chain and off-\nchain system demonstration.\nAcknowledgments\nWe thank Mr. Anandan Krishnasamy for running FL\nworkflow experiments over the hybrid cloud environment\nand validating the FL training results. This research was\nmade possible through partial funding from several Eu-\nropean Union projects: CLARIFY (860627), ENVRI-Hub\nNext (101131141), EVERSE (101129744), BlueCloud-2026\n(101094227), OSCARS (101129751), LifeWatch ERIC,\nBioDT (101057437, through LifeWatch ERIC), and Dutch\nNWO LTER-LIFE project.\nReferences\n[1] Rodolfo Stoffel Antunes, Cristiano AndrÃ© da Costa, Arne KÃ¼derle,\nImrana Abdullahi Yari, and BjÃ¶rn Eskofier.\nFederated learning\nfor healthcare: Systematic review and architecture proposal. ACM\nTransactions on Intelligent Systems and Technology (TIST), 13(4):1â€“\n23, 2022.\n[2] Guodong Long, Yue Tan, Jing Jiang, and Chengqi Zhang. Federated\nlearning for open banking.\nIn Federated learning: privacy and\nincentive, pages 240â€“254. Springer, 2020.\n[3] Dinh C Nguyen, Ming Ding, Pubudu N Pathirana, Aruna Seneviratne,\nJun Li, and H Vincent Poor. Federated learning for internet of things:\nA comprehensive survey. IEEE Communications Surveys & Tutorials,\n23(3):1622â€“1658, 2021.\n[4] Biwei Yan, Hongliang Zhang, Minghui Xu, Dongxiao Yu, and Xi-\nuzhen Cheng. Fedrfq: Prototype-based federated learning with re-\nduced redundancy, minimal failure, and enhanced quality.\nIEEE\nTransactions on Computers, 2024.\n[5] Pian Qi, Diletta Chiaro, Antonella Guzzo, Michele Ianni, Giancarlo\nFortino, and Francesco Piccialli. Model aggregation techniques in\nfederated learning: A comprehensive survey.\nFuture Generation\nComputer Systems, 2023.\n[6] Jiajun Wu, Fan Dong, Henry Leung, Zhuangdi Zhu, Jiayu Zhou, and\nSteve Drew. Topology-aware federated learning in edge computing: A\ncomprehensive survey. ACM Computing Surveys, 56(10):1â€“41, 2024.\n[7] Bo Xu, Wenchao Xia, Wanli Wen, Pei Liu, Haitao Zhao, and Hongbo\nZhu. Adaptive hierarchical federated learning over wireless networks.\nIEEE Transactions on Vehicular Technology, 71(2):2070â€“2083, 2021.\n[8] Lumin Liu, Jun Zhang, Shenghui Song, and Khaled B Letaief. Hier-\narchical federated learning with quantization: Convergence analysis\nand system design. IEEE Transactions on Wireless Communications,\n22(1):2â€“18, 2022.\n[9] Stefano Savazzi, Monica Nicoli, and Vittorio Rampa.\nFederated\nlearning with cooperating devices: A consensus approach for massive\niot networks. IEEE Internet of Things Journal, 7(5):4641â€“4654, 2020.\n[10] Yuan Liu, Zhengpeng Ai, Shuai Sun, Shuangfeng Zhang, Zelei Liu,\nand Han Yu. Fedcoin: A peer-to-peer payment system for federated\nlearning. In Federated learning: privacy and incentive, pages 125â€“\n138. Springer, 2020.\n[11] Nicola Rieke, Jonny Hancox, Wenqi Li, Fausto Milletari, Holger R\nRoth, Shadi Albarqouni, Spyridon Bakas, Mathieu N Galtier, Ben-\nnett A Landman, Klaus Maier-Hein, et al. The future of digital health\nwith federated learning. NPJ digital medicine, 3(1):1â€“7, 2020.\n[12] Jianchun Liu, Hongli Xu, Lun Wang, Yang Xu, Chen Qian, Jinyang\nHuang, and He Huang. Adaptive asynchronous federated learning in\nresource-constrained edge computing. IEEE Transactions on Mobile\nComputing, 22(2):674â€“690, 2021.\n[13] Minghui Xu, Zongrui Zou, Ye Cheng, Qin Hu, Dongxiao Yu, and\nXiuzhen Cheng.\nSpdl: A blockchain-enabled secure and privacy-\npreserving decentralized learning system.\nIEEE Transactions on\nComputers, 72(2):548â€“558, 2022.\n[14] Yufeng Zhan, Jie Zhang, Zicong Hong, Leijie Wu, Peng Li, and Song\nGuo. A survey of incentive mechanism design for federated learning.\nIEEE Transactions on Emerging Topics in Computing, 10(2):1035â€“\n1044, 2021.\n[15] Xuezhen Tu, Kun Zhu, Nguyen Cong Luong, Dusit Niyato, Yang\nZhang, and Juan Li. Incentive mechanisms for federated learning:\nFrom economic and game theoretic perspective. IEEE transactions\non cognitive communications and networking, 8(3):1566â€“1593, 2022.\n[16] Han Xu, Priyadarsi Nanda, and Jie Liang.\nReciprocal federated\nlearning framework: Balancing incentives for model and data owners.\nFuture Generation Computer Systems, 161:146â€“161, 2024.\n[17] Yann Fraboni, Richard Vidal, and Marco Lorenzi. Free-rider attacks\non model aggregation in federated learning. In International Con-\nference on Artificial Intelligence and Statistics, pages 1846â€“1854.\nPMLR, 2021.\n[18] Leon Witt, Mathis Heyer, Kentaroh Toyoda, Wojciech Samek, and\nDan Li. Decentral and incentivized federated learning frameworks: A\nsystematic literature review. IEEE Internet of Things Journal, 10(4):\n3642â€“3663, 2022.\n[19] Viraaji Mothukuri, Reza M Parizi, Seyedamin Pouriyeh, Yan Huang,\nAli Dehghantanha, and Gautam Srivastava. A survey on security and\nprivacy of federated learning. Future Generation Computer Systems,\n115:619â€“640, 2021.\n[20] Semo Yang, Jihwan Moon, Jinsoo Kim, Kwangkee Lee, and Kangy-\noon Lee. Flscalize: Federated learning lifecycle management plat-\nform. IEEE Access, 11:47212â€“47222, 2023.\n[21] Iacopo Colonnelli, Bruno Casella, Gianluca Mittone, Yasir Arfat,\nBarbara Cantalupo, Roberto Esposito, Alberto Riccardo Martinelli,\nDoriana MediÄ‡, and Marco Aldinucci. Federated learning meets hpc\nand cloud. In ML4Astro International Conference, pages 193â€“199.\nSpringer, 2022.\n[22] Peter Amstutz, Michael R. Crusoe, NebojÅ¡a TijaniÄ‡, Brad Chapman,\nJohn Chilton, Michael Heuer, et al.\nCommon workflow language,\nv1.0, 2016.\n[23] Chronis Kontomaris, Yuandou Wang, and Zhiming Zhao. Cwl-flops:\nA novel method for federated learning operations at scale. In 2023\nIEEE 19th International Conference on e-Science (e-Science), pages\n1â€“2. IEEE, 2023.\n[24] Harshit Daga, Jaemin Shin, Dhruv Garg, Ada Gavrilovska, Myungjin\nLee, and Ramana Rao Kompella.\nFlame: Simplifying topology\nextension in federated learning.\nIn Proceedings of the 2023 ACM\nSymposium on Cloud Computing, pages 341â€“357, 2023.\n[25] Wil MP van Der Aalst, Arthur HM Ter Hofstede, Bartek Kie-\npuszewski, and Alistair P Barros. Workflow patterns. Distributed\nand parallel databases, 14:5â€“51, 2003.\n[26] Sin Kit Lo, Qinghua Lu, Liming Zhu, Hye-Young Paik, Xiwei Xu, and\nChen Wang. Architectural patterns for the design of federated learning\nsystems. Journal of Systems and Software, 191:111357, 2022.\nYuandou Wang et al.: Preprint submitted to Elsevier\nPage 15 of 16\n\n\nManaging Federated Learning on Decentralized Infrastructures as a Reputation-based Collaborative Workflow\n[27] Qi Cheng and Guodong Long. Federated learning operations (flops):\nChallenges, lifecycle and approaches.\nIn 2022 International Con-\nference on Technologies and Applications of Artificial Intelligence\n(TAAI), pages 12â€“17. IEEE, 2022.\n[28] Christof Ebert, Gorka Gallardo, Josune Hernantes, and Nicolas Ser-\nrano. Devops. IEEE software, 33(3):94â€“100, 2016.\n[29] Dominik Kreuzberger, Niklas KÃ¼hl, and Sebastian Hirschl. Machine\nlearning operations (mlops): Overview, definition, and architecture.\nIEEE access, 11:31866â€“31879, 2023.\n[30] Rongfei Zeng, Chao Zeng, Xingwei Wang, Bo Li, and Xiaowen\nChu. A comprehensive survey of incentive mechanism for federated\nlearning. arXiv preprint arXiv:2106.15406, 2021.\n[31] Nika Haghtalab, Mingda Qiao, and Kunhe Yang. Platforms for effi-\ncient and incentive-aware collaboration. In Proceedings of the 2025\nAnnual ACM-SIAM Symposium on Discrete Algorithms (SODA),\npages 2607â€“2628. SIAM, 2025.\n[32] Zhilin Wang, Qin Hu, Ruinian Li, Minghui Xu, and Zehui Xiong. In-\ncentive mechanism design for joint resource allocation in blockchain-\nbased federated learning. IEEE Transactions on Parallel and Dis-\ntributed Systems, 34(5):1536â€“1547, 2023.\n[33] Liang Gao, Li Li, Yingwen Chen, ChengZhong Xu, and Ming Xu.\nFgfl: A blockchain-based fair incentive governor for federated learn-\ning. Journal of Parallel and Distributed Computing, 163:283â€“299,\n2022.\n[34] Jiawen Kang, Zehui Xiong, Dusit Niyato, Shengli Xie, and Junshan\nZhang. Incentive mechanism for reliable federated learning: A joint\noptimization approach to combining reputation and contract theory.\nIEEE Internet of Things Journal, 6(6):10700â€“10714, 2019.\n[35] Tailin Zhou, Zehong Lin, Jun Zhang, and Danny HK Tsang.\nUn-\nderstanding and improving model averaging in federated learning on\nheterogeneous data. IEEE Transactions on Mobile Computing, 2024.\n[36] Brendan McMahan, Eider Moore, Daniel Ramage, Seth Hampson,\nand Blaise Aguera y Arcas.\nCommunication-efficient learning of\ndeep networks from decentralized data. In Artificial intelligence and\nstatistics, pages 1273â€“1282. PMLR, 2017.\n[37] Zhiming Zhao, Spiros Koulouzis, Riccardo Bianchi, Siamak Farshidi,\nZeshun Shi, Ruyue Xin, Yuandou Wang, Na Li, Yifang Shi, Joris\nTimmermans, et al. Notebook-as-a-vre (naavre): From private note-\nbooks to a collaborative cloud virtual research environment. Software:\nPractice and Experience, 52(9):1947â€“1966, 2022.\n[38] LaÃ«titia Launet, Yuandou Wang, AdriÃ¡n Colomer, Jorge Igual, Cris-\ntian PulgarÃ­n-Ospina, Spiros Koulouzis, Riccardo Bianchi, AndrÃ©s\nMosquera-Zamudio, Carlos Monteagudo, Valery Naranjo, et al. Fed-\nerating medical deep learning models from private jupyter notebooks\nto distributed institutions. Applied Sciences, 13(2):919, 2023.\n[39] Yuandou Wang, Spiros Koulouzis, Riccardo Bianchi, Na Li, Yifang\nShi, Joris Timmermans, W Daniel Kissling, and Zhiming Zhao. Scal-\ning notebooks as re-configurable cloud workflows. Data Intelligence,\n4(2):409â€“425, 2022.\n[40] Daniel J Beutel, Taner Topal, Akhil Mathur, Xinchi Qiu, Titouan\nParcollet, Pedro PB de GusmÃ£o, and Nicholas D Lane.\nFlower:\nA friendly federated learning research framework.\narXiv preprint\narXiv:2007.14390, 2020.\n[41] Heiko Ludwig, Nathalie Baracaldo, Gegi Thomas, Yi Zhou, Ali An-\nwar, Shashank Rajamoni, Yuya Ong, Jayaram Radhakrishnan, Ashish\nVerma, Mathieu Sinn, et al. Ibm federated learning: an enterprise\nframework white paper v0. 1. arXiv preprint arXiv:2007.10987, 2020.\n[42] G Anthony Reina, Alexey Gruzdev, Patrick Foley, Olga Perepelkina,\nMansi Sharma, Igor Davidyuk, Ilya Trushkin, Maksim Radionov,\nAleksandr Mokrov, Dmitry Agapov, et al. Openfl: An open-source\nframework for federated learning. arXiv preprint arXiv:2105.06413,\n2021.\n[43] Alexander Ziller, Andrew Trask, Antonio Lopardo, Benjamin\nSzymkow, Bobby Wagner, Emma Bluemke, Jean-Mickael Nouna-\nhon, Jonathan Passerat-Palmbach, Kritika Prakash, Nick Rose, et al.\nPysyft: A library for easy federated learning.\nFederated Learning\nSystems: Towards Next-Generation AI, pages 111â€“139, 2021.\n[44] Kasun Indrasiri and Danesh Kuruppu.\ngRPC: up and running:\nbuilding cloud native applications with Go and Java for Docker and\nKubernetes. Oâ€™Reilly Media, 2020.\n[45] Anandan Krishnasamy, Yuandou Wang, and Zhiming Zhao. A col-\nlaborative framework for facilitating federated learning among jupyter\nusers. In 2024 IEEE 20th International Conference on e-Science (e-\nScience), pages 1â€“2. IEEE, 2024.\n[46] Shaoxiong Ji. A pytorch implementation of federated learning, March\n2018. URL https://doi.org/10.5281/zenodo.4321561.\n[47] Carole Goble, Sarah Cohen-Boulakia, Stian Soiland-Reyes, Daniel\nGarijo, Yolanda Gil, Michael R Crusoe, Kristian Peters, and Daniel\nSchober. Fair computational workflows. Data Intelligence, 2(1-2):\n108â€“121, 2020.\n[48] Yuandou Wang, Sheejan Tripathi, Siamak Farshidi, and Zhiming\nZhao. D-vre: From a jupyter-enabled private research environment\nto decentralized collaborative research ecosystem. Blockchain: Re-\nsearch and Applications, page 100244, 2024.\n[49] Huong Nguyen, Hong-Tri Nguyen, Lauri LovÃ©n, and Susanna Pirt-\ntikangas. Stake-driven rewards and log-based free rider detection in\nfederated learning. In 2024 21st Annual International Conference on\nPrivacy, Security and Trust (PST), pages 1â€“10. IEEE, 2024.\n[50] Shuai Wang, Wenwen Ding, Juanjuan Li, Yong Yuan, Liwei Ouyang,\nand Fei-Yue Wang. Decentralized autonomous organizations: Con-\ncept, model, and applications. IEEE Transactions on Computational\nSocial Systems, 6(5):870â€“878, 2019.\n[51] Ningning Ding, Zhixuan Fang, and Jianwei Huang. Optimal contract\ndesign for efficient federated learning with multi-dimensional private\ninformation. IEEE Journal on Selected Areas in Communications, 39\n(1):186â€“200, 2020.\n[52] Zehui Xiong, Wei Yang Bryan Lim, Jiawen Kang, Dusit Niyato, Ping\nWang, and Chunyan Miao. Incentive mechanism design for mobile\ndata rewards using multi-dimensional contract. In 2020 IEEE Wire-\nless Communications and Networking Conference (WCNC), pages 1â€“\n6. IEEE, 2020.\n[53] Jerzy Neyman.\nOn the two different aspects of the representative\nmethod: the method of stratified sampling and the method of pur-\nposive selection. In Breakthroughs in statistics: Methodology and\ndistribution, pages 123â€“150. Springer, 1992.\n[54] Anders Hald. The compound hypergeometric distribution and a sys-\ntem of single sampling inspection plans based on prior distributions\nand costs. Technometrics, 2(3):275â€“340, 1960.\n[55] Rajendra K Jain, Dah-Ming W Chiu, William R Hawe, et al.\nA\nquantitative measure of fairness and discrimination.\nEastern Re-\nsearch Laboratory, Digital Equipment Corporation, Hudson, MA, 21:\n1, 1984.\n[56] Peter I Frazier. A tutorial on bayesian optimization. arXiv preprint\narXiv:1807.02811, 2018.\n[57] Leslie Pack Kaelbling, Michael L Littman, and Andrew W Moore.\nReinforcement learning: A survey. Journal of artificial intelligence\nresearch, 4:237â€“285, 1996.\n[58] Robert Dorfman. A formula for the gini coefficient. The review of\neconomics and statistics, pages 146â€“149, 1979.\nYuandou Wang et al.: Preprint submitted to Elsevier\nPage 16 of 16\n\n\n",
  "metadata": {
    "source_file": "dataset/pdfs/arxiv_2502.20882v1.pdf",
    "total_pages": 16,
    "title": "Managing Federated Learning on Decentralized Infrastructures as a Reputation-based Collaborative Workflow",
    "authors": [
      "Yuandou Wang",
      "Zhiming Zhao"
    ],
    "abstract": "Federated Learning (FL) has recently emerged as a collaborative learning\nparadigm that can train a global model among distributed participants without\nraw data exchange to satisfy varying requirements. However, there remain\nseveral challenges in managing FL in a decentralized environment, where\npotential candidates exhibit varying motivation levels and reliability in the\nFL process management: 1) reconfiguring and automating diverse FL workflows are\nchallenging, 2) difficulty in incentivizing potential candidates with\nhigh-quality data and high-performance computing to join the FL, and 3)\ndifficulty in ensuring reliable system operations, which may be vulnerable to\nvarious malicious attacks from FL participants. To address these challenges, we\nfocus on the workflow-based methods to automate diverse FL pipelines and\npropose a novel approach to facilitate reliable FL system operations with\nrobust mechanism design and blockchain technology by considering a contribution\nmodel, fair committee selection, dynamic reputation updates, reward and penalty\nmethods, and contract theory. Moreover, we study the optimality of contracts to\nguide the design and implementation of smart contracts that can be deployed in\nblockchain networks. We perform theoretical analysis and conduct extensive\nsimulation experiments to validate the proposed approach. The results show that\nour incentive mechanisms are feasible and can achieve fairness in reward\nallocation in unreliable environment settings.",
    "published_date": "2025-02-28",
    "source": "arxiv"
  }
}