{
  "id": "arxiv_2502.20882v1",
  "text": "Managing Federated Learning on Decentralized Infrastructures as a\nReputation-based Collaborative Workflow\nYuandou Wanga, Zhiming Zhaoa,b\naMultiscale Networked System, University of Amsterdam, Science Park 900, Amsterdam, 1098 XH, The Netherlands\nbLifeWatch ERIC Virtual Lab and Innovation Center (VLIC), Science Park 904, Amsterdam, 1098 XH, The Netherlands\nA R T I C L E I N F O\nKeywords:\nFederated Learning\nCollaborative Workflows\nIncentives\nReputation\nOptimal Contract\nBlockchain\nA B S T R A C T\nFederated Learning (FL) has recently emerged as a collaborative learning paradigm that can train a\nglobal model among distributed participants without raw data exchange to satisfy varying require-\nments. However, there remain several challenges in managing FL in a decentralized environment,\nwhere potential candidates exhibit varying motivation levels and reliability in the FL process\nmanagement: 1) reconfiguring and automating diverse FL workflows are challenging, 2) difficulty\nin incentivizing potential candidates with high-quality data and high-performance computing to join\nthe FL, and 3) difficulty in ensuring reliable system operations, which may be vulnerable to various\nmalicious attacks from FL participants. To address these challenges, we focus on the workflow-based\nmethods to automate diverse FL pipelines and propose a novel approach to facilitate reliable FL system\noperations with robust mechanism design and blockchain technology by considering a contribution\nmodel, fair committee selection, dynamic reputation updates, reward and penalty methods, and\ncontract theory. Moreover, we study the optimality of contracts to guide the design and implementation\nof smart contracts that can be deployed in blockchain networks. We perform theoretical analysis and\nconduct extensive simulation experiments to validate the proposed approach. The results show that\nour incentive mechanisms are feasible and can achieve fairness in reward allocation in unreliable\nenvironment settings.\n1. Introduction\nFederated learning (FL) is a promising distributed ma-\nchine learning (ML) paradigm that enables collaborative\nlearning over decentralized data to mitigate many systematic\nprivacy risks and costs resulting from traditional, centralized\nlearning. In recent years, FL has been studied in many\nresearch and application domains, particularly in the fields\nof digital medicine and health [1], open banking [2], and\nthe Internet of Things [3], in which data cannot be shared\nor exchanged due to privacy and security concerns.\nFL often involves a number of participants, which fea-\nture highly heterogeneous training infrastructures and non-\nindependently and identically distributed (non-IID) data [4].\nIn a traditional setting of FL, several participants, each\nkeeping its data and training process on-premise, aim to\ncollaboratively train a joint model under a central aggregator\nthat initializes, collects, aggregates, and redistributes the\nmodels to and from the training participants, as shown in\nFigure 1 (a). Over time, the federated model aggregation has\nemerged in varying modes [5] and performed as different\ntopology types in the distributed computing ecosystem [6],\nwhile the data and its training infrastructure are still decen-\ntralized. It is known that such diversity can be attributed\nto different FL design choices and customizations to satisfy\ndifferent user requirements. For instance, some researchers\nintroduced hierarchical FL, as shown in Figure 1 (b), to\ntackle the bottleneck of communication overhead in the core\ny.wang8@uva.nl (Y. Wang); z.zhao@uva.nl (Z. Zhao)\nhttps://www.linkedin.com/in/yuandou-w-aa717b135/ (Y. Wang);\nhttps://staff.fnwi.uva.nl/z.zhao/ (Z. Zhao)\nORCID(s): 0000-0003-4694-9572 (Y. Wang)\nnetwork [7, 8]. Some proposed decentralized FL, as depicted\nin Figure 1 (c), with a Peer-to-Peer (P2P) communication\narchitecture to cope with the drawbacks of a single point of\nfailure and scaling issues for the increasing network size [9,\n10]. Moreover, various aggregation strategies associated\nwith FL topologies for updating the FL model parameters\nhave been studied, including but not limited to sequen-\ntial updates [11], (a)synchronous parallel updates [12], and\npeer-to-peer approaches [13], as illustrated in Figure 1 (d),\n(e), and (f), respectively. The final well-trained model can\nbe obtained through the iteratively collaborative training\nrounds. However, due to the heterogeneity of decentralized\ninfrastructure or platforms, it poses execution challenges.\nFL development involves three typical activities: 1) dis-\ncover potential participants with high-quality data or re-\nsource providers and stimulate them to join the FL, 2) cus-\ntomize the FL application workflows for specific purposes,\nand 3) define a reliable training process with local updates\nevaluation.\nIn real-world scenarios, collaborative FL typically fol-\nlows two main approaches. The first involves pre-established\ncollaborations, where participants are obligated to join FL\ndue to prior agreements within research projects. These\nparticipants are considered trustworthy and contribute to\nthe entire FL training process with complete information.\nThe second approach relies on incentive-driven participa-\ntion, where FL proposers solicit collaboration through in-\ncentives [14, 15] from a decentralized community. In this\ncase, participation is voluntary, and the trustworthiness of\npotential candidates is initially unknown.\nDue to diverse availability of local resources and in-\nterests, FL participants may have different motivation in\nYuandou Wang et al.: Preprint submitted to Elsevier\nPage 1 of 16\narXiv:2502.20882v1  [cs.DC]  28 Feb 2025\n\n\nManaging Federated Learning on Decentralized Infrastructures as a Reputation-based Collaborative Workflow\nData\nTraining Node\nAggregator\nModel Aggregation\nInitial Model\nFinal Model\nWeight Exchange\n(a) Centralized FL\n(d) Sequential\n(e) Parallel\n(f) Peer to Peer\nLegend\nTopologies in FL\nModel updates' patterns in FL\nFederated Node\n(c) Decentralized FL\n(b) Hierarchical FL\nFigure 1: An overview of diverse FL design choices. FL topologies. (a) Centralized FL: a central aggregation server manages the\ntraining process by coordinating iterative training rounds. (b) Hierarchical FL: typically, the FL network has a tree structure with\nat least three tiers. (c) Decentralized FL: each training node is connected to one or more peers and aggregation happens on the\nselected node. FL model updates’ paths. (d) Sequential. (e) Parallel. (f) Peer to Peer.\njoining an FL application, and deliver diverse quality in con-\ntributions. This heterogeneity introduces several challenges,\nincluding unequal participation [16], free-riding [17], and\ndifficulties in accurately assessing and rewarding individual\ncontributions [18]. Encouraging active engagement from\ndiverse stakeholders, such as data owners, infrastructure\nproviders, and model developers, remains a critical chal-\nlenge. This requires incentivizing participation in customized\nFL workflows, facilitating local model update sharing, and\nensuring fair contributions to global model development\nwithin a decentralized community.\nFurthermore, these complexities create efficiency chal-\nlenges, as substantial time and effort are needed to set up\nFL workflows, identify suitable participants, and maintain\nlearning quality. In addition, FL operations are vulnerable\nto both intentional and unintentional threats, including data\npoisoning, malicious servers, inference attacks, system dis-\nruptions, and service unavailability [19]. Addressing these\nrisks is particularly difficult when some participants are\nunreliable during the training process.\nIn this work, we address the efficiency challenges in FL\ndevelopment and management within decentralized com-\nmunity settings. We begin by automating FL operations\nby modeling them as workflows and leveraging workflow\nengines to orchestrate their execution on remote infrastruc-\ntures at scale. Our approach emphasizes workflow-based FL\nmanagement, focusing on FL workflow composition, data\nowner incentivization, and reliable training processes via\ncombining with decentralized technologies.\nThe reminder of this article is structured as follows:\nSection 2 reviews the state-of-the-art reliable FL practices,\ncompares with existing work, and analyzes their research\ngap. Section 3 describes how we can describe FL as a\ncomputational workflow and scale it out to decentralized\ninfrastructure via the CWL open standards. Section 4 intro-\nduces a decentralized collaboration framework for FL and\nillustrates the mechanism design approach and studies the\ncontract optimality to answer research questions. Section 5\ndetails the experiments and the analysis of results; finally,\nSection 6 concludes this work.\n2. Related Work\nThis section reviews the state-of-the-art reliable fed-\nerated learning operation practices and explores existing\nframeworks for managing FL in decentralized infrastruc-\ntures.\nIn recent years, several FL frameworks have made no-\ntable advancements in managing the FL research and de-\nvelopment lifecycle. Yang et al. [20] introduced FLScalize,\nwhich extends the machine learning operations (MLOps)\nconcept to generate a baseline model, integrating FL clients,\nthe FL server, and model performance to oversee the entire\nFL lifecycle. Colonnelli et al. [21] employed the open stan-\ndard workflow language, CWL [22], to abstract and auto-\nmate FL applications in a hybrid Cloud-HPC environment.\nDespite these advances, their approach remains constrained\nby the traditional client-server architecture of centralized FL,\nalthough the open standard workflow language holds signif-\nicant promise for describing diverse FL workflows [23].\nYuandou Wang et al.: Preprint submitted to Elsevier\nPage 2 of 16\n\n\nManaging Federated Learning on Decentralized Infrastructures as a Reputation-based Collaborative Workflow\nDaga et al. [24] introduced the Flame framework, of-\nfering flexibility in the topology configuration of FL ap-\nplications tailored to the specific deployment context using\nnew high-level abstraction topology graphs (TAGs) that\nincorporate five types of FL topologies. While both Colon-\nnelli et al. [21] and Daga et al. [24] align closely with our\nstudy by utilizing high-level abstractions to enable flexibility\nin topology-aware FL, a key assumption in many existing\nworks is that potential participants will join the FL process\nunconditionally and are sufficiently trustworthy to contribute\nthroughout the entire FL training process. Our study diverges\nfrom previous works in several critical ways. We explore\nclassic workflow patterns [25] and FL architectural pat-\nterns [26], making fundamental workflow concepts — such\nas automation, scalability, abstraction, portability, flexibility,\nand reusability — applicable to the context of federated\nlearning operations (FLOps) via the open standard CWL.\nPreliminary results of this approach have been presented in\nCWL-FLOps [23].\nFurthermore, Cheng and Long [27] introduced a novel\nmethodology called FLOps for managing the FL lifecycle\ncontinuously and efficiently. FLOps integrates a range of\nprocesses, technologies, and tools to enhance the efficiency\nand quality of developing and deploying cross-silo FL sys-\ntems. They highlight that workflow-related approaches, such\nas metadata engineering, dual deployment, and checkpoints,\ncan help establish and automate FLOps practices, enabling\nsmoother and more efficient operations from an engineering\nperspective. However, the automation of FLOps remains an\nopen challenge, particularly when addressing security and\nprivacy concerns, which differ from those encountered in\ntraditional DevOps [28] and MLOps [29] practices. More-\nover, they do not address the issue of incentivizing partic-\nipants to make high-quality contributions if the assumption\nof their willingness and trustworthiness does not hold — this\nis a crucial factor for maintaining a reliable and secure FL\nprocess.\nOur work connects to the broader discussion of pro-\nmoting collaborative fairness among federated participants\nwithin decentralized communities, where incentives and\nfairness have been extensively explored [30, 18, 31]. Wang\net al. [32] examined incentive mechanism design in the con-\ntext of resource allocation for FL clients in Blockchain-based\nFederated Learning (BCFL). They modeled the problem\nas a two-stage Stackelberg game under both complete and\nincomplete information. Using the Shapley value approach,\nthey quantified clients’ contributions to the training process.\nBy transforming the game model into two optimization\nproblems and solving them sequentially, they derived the\noptimal strategies for both players. Gao et al. [33] introduced\nFGFL, an attack-resistant incentive mechanism for FL that\ndetects and repels abnormal updates, thereby protecting the\nsystem in unreliable scenarios. The task publisher rewards\nefficient workers and punishes or eliminates malicious ones\nbased on reputation and contribution indicators.\nWhile both incentive mechanisms are deemed feasible\nthrough experimental evaluation, neither explores the op-\ntimal contract design required for creating smart contracts\nfor FL operations. The question of whether the incentives\nembedded in smart contracts are either over-rewarding or\ninsufficient to effectively motivate participants remains un-\nclear. Kang et al. [34] proposed a joint optimization approach\ncombining a reputation-based worker selection scheme with\ncontract theory to determine the optimal computation re-\nsources (e.g., contributed CPU cycles) and corresponding\nrewards for all participants. However, this approach does\nnot fully capture the entire contribution to the FL training\nprocess. Furthermore, although existing works touch on fair\nrewards, there is a clear need for precise fairness metrics that\nalign with specific incentives, particularly in the context of\nreliable FL systems.\n3. Federated Learning as a Workflow\nThis section explores the advantages of managing feder-\nated learning as a workflow within decentralized infrastruc-\nture, addressing the following research question: \"How can\nwe abstract FL workflows in an open standard manner and\norganize their execution on remote infrastructure?\"\n3.1. Federated Learning\nWe consider an FL application scenario consisting of\n𝑁= {1, 2, ⋯, 𝑛} clients, each client 𝑖holds a local dataset\n𝐷𝑖= {(𝑥, 𝑦)} ∼𝑖consisting of 𝑠𝑖data samples, where 𝑥\nand 𝑦denote the data sample and its corresponding labels,\nrespectively [35]. The total sample size 𝑆sample from 𝑁\nclients is given by 𝑆sample = ∑𝑛\n𝑖=1 𝑠𝑖, ∀𝑖∈𝑁. Additionally,\nthe union of all client datasets denote by 𝐷= ∪𝑛\n𝑖=1𝐷𝑖∼.\nFL aims to minimize a global loss function (⋅) from the\n𝑁clients’ local loss function 𝑖∈𝑁(⋅) through the model\naggregation strategy techniques. The overall FL problem can\nbe formulated as\nmin\n𝐰∈ℝ(𝐰)\nwhere\n𝑁\n∑\n𝑖=1\n𝑠𝑖\n𝑆sample\n𝑖(𝐰)\n(1)\nHere, 𝑖(𝐰) = ∑𝑠𝑖\n𝑘=1 𝓁𝑖(𝐰; (𝑥𝑘, 𝑦𝑘) ∈𝐷𝑖) is the expected\nlocal loss of the 𝑖𝑡ℎclient on its local dataset 𝐷𝑖, and\n𝓁𝑖(𝐰; (𝑥𝑘, 𝑦𝑘)) is the local loss function of the shared model\nweights 𝐰on sample data (𝑥𝑘, 𝑦𝑘) ∈𝐷𝑖.\nTraditionally, clients train their local models 𝐰(𝑡)\n𝑖\ninde-\npendently at round 𝑡by optimizing the loss function 𝑖(⋅) on\ntheir local datasets. Clients validate the trained model using\na validation dataset and upload their updated models to an\naggregator for federated model aggregation. The aggrega-\ntor then performs the aggregation strategy and updates the\nshared global model of all the local model updates. Take the\nmodel averaging method, i.e., FedAvg [36], as an example.\nIt is a technique developed to reduce the variance of a global\nmodel update by periodically averaging models trained over\nmultiple communication rounds in FL. The model averaging\nYuandou Wang et al.: Preprint submitted to Elsevier\nPage 3 of 16\n\n\nManaging Federated Learning on Decentralized Infrastructures as a Reputation-based Collaborative Workflow\naggregation is often formulated as,\n𝐰(𝑡+1) =\n𝑛\n∑\n𝑖=1\n𝑠𝑖\n𝑆sample\n𝐰(𝑡)\n𝑖\n(2)\nwhere 𝐰(𝑡+1) denotes the updated global model weight for\nthe new round 𝑡+ 1. Then, it will be sent back to all active\nclients to initialize the next round of local training, itera-\ntively. This process repeats until the global loss converges.\nIt is known that high-quality data, efficient computation,\nand reliable communication at each round may contribute to\nthe local model training with high model performance (e.g.,\nhigh accuracy) and can lead to faster convergence of the local\nloss function 𝑖(𝐰). The faster speed of the convergence\nof the local training and high-quality model updates will\nmake the convergence of the global loss function quicker,\nand thus, the training time and cost will decrease for a\ntargeted model performance [34]. Therefore, participants\nwith high-quality data, high-performance computation, and\ncommunication efficiency can significantly improve the FL\nquality and efficiency.\n3.2. Federated Learning as a Workflow\nWe define an FL workflow 𝐹\n= (𝐰, 𝑁, 𝐴, 𝑡𝑇) as a\ncombination of four random sets of variables: the global\nmodel 𝐰, the participant set 𝑁, the aggregation strategy 𝐴,\nand the topology type 𝑡𝑇. These variables consist of the\nfundamental building blocks of FL workflows, and users\ncan reconfigure such blocks and customize 𝐹with their\npreferences under an agreement of all participants.\nWe build on existing solutions to develop a flexible,\nadaptable approach tailored to end users’ specific needs.\nAs a first step, we explored the component containerizer\nin NaaVRE [37] to create and store FL building blocks —\nsuch as models and aggregation strategies — as research\nassets. For instance, a model developer can build ML models\nin a local NaaVRE environment using small-scale datasets,\nperforming testing and validation. The model provider can\nthen package the ML model or code files with the FL\nframework into a container and store them on Docker Hub. It\nfacilitates the global distribution of reusable, containerized\napplications [38]. This approach enhances reproducibility,\nportability, and scalability, streamlining the integration of\nthese building blocks into reconfigurable FL workflows [39]\nand accelerating FL development.\nIn [38], we primarily used docker-nvidia for local client\ntraining with CUDA GPU resources, automating FL pipelines\nwhile allowing clients to retain control over their data and\ncomputation. For large-scale automated deployment, Docker\nSwarm serves as an alternative solution. The case study\non histological image analysis demonstrated the feasibility\nof the proposed approach, where we utilized the Flower\nframework [40] within the Jupyter environment for FL code\ndevelopment. However, most existing frameworks, such as\nTensorFlow Federated (TFF)1, NVFlare2, IBM FL [41],\n1https://www.tensorflow.org/federated\n2https://github.com/NVIDIA/NVFlare\nOpenFL [42], PySyft [43], and Flower, follow a centralized\nFL paradigm with a client-server architecture, in which the\naggregator cannot be replaced or changed during the training\nprocess. They typically rely on direct bidirectional commu-\nnication (e.g., gRPC [44]) between the aggregator and client\ntraining nodes, which limits their flexibility in supporting\ndiverse FL deployment scenarios. For example, locations\nof decentralized data infrastructure can be heterogeneous,\nexposing different hardware resources and protocols for\nauthentication, communication, resource allocation, and job\nexecution. Plus, they can be independent of each other,\nmeaning that direct communication among them may not\nbe allowed [21].\nTo overcome this limitation, we model the FL pipeline\nas a computational workflow and utilize a workflow engine\nto orchestrate its execution across remote infrastructures.\nSpecifically, we employ CWL open standards to define FL\npipelines, and make them more manageable to automate and\nparallelize the joint model training from the local computer\nto the remote cloud environments. We first employ the\nclassic workflow patterns to describe diverse computational\nFL workflows. Table 1 introduces a taxonomy of 43 control\npatterns and 40 data patterns identified in the Workflow\nPatterns Initiative (WPI)3, mapping them to a diverse range\nof FL topology types.\nA review of the 43 WPI patterns related to the control-\nflow perspective reveals that 11 patterns are supported by\nCWL v1.2 or earlier. Of the 40 data patterns, only 17 are\nsupported by CWL constructs, and just 2 of the 43 resource\npatterns are covered. Additionally, CWL standards offer\nlimited support for exception handling and do not address the\nevent log imperfection patterns defined in the WPI patterns.\nFor workflow presentation patterns, 19 are supported by\nCWL v1.2 or earlier, with one pattern still unsupported.\nCertain environments, such as blockchain networks, mobile\ndevices, and wireless systems, cannot directly interface with\nCWL-supported workflow patterns.\nFL requires loop patterns for describing the iterative\ntraining. While CWL v1.2 lacks loop constructs and re-\ncursion support, there are alternative methods to enable\nloops in describing iterative FL workflows. These include\n1) combining sub-workflows with loop extensions in the\ncurrent stable version (v1.2) and 2) the upcoming v1.3.0-\ndev1 version of CWL, which is expected to introduce loop\nconstructs in a future stable release. Figure 2 shows the\nsnippet of the main steps of a decentralized FL work-\nflow example written in CWL version v1.2. It orches-\ntrates multiple steps, including service discovery, client\nreading, initialization, and decentralized training rounds.\nThis CWL snippet set up a loop within a sub-workflow\nnamed decentralized_training_round. It manages decen-\ntralized training rounds in FL, iterating until the specified\nnumber of rounds is completed. Unlike a fixed aggregator\nin the centralized FL workflow, the aggregator is randomly\nchosen from the distributed clients to perform federated\n3http://www.workflowpatterns.com/\nYuandou Wang et al.: Preprint submitted to Elsevier\nPage 4 of 16\n\n\nManaging Federated Learning on Decentralized Infrastructures as a Reputation-based Collaborative Workflow\nTable 1\nThe mappings of different FL topology types on WPI’s workflow patterns.\nFL Topology Types\nStar\nTree\nDecentralized\nMinor\nSynchronous\nAsynchronous\nHierarchical\nDynamic\nDe-Mesh\nDe-Wireless\nBlockchain\nRing\nClique\nGrid\nFog\nSemi-Ring\nPatterns\nControl (43)\nBasic control (5/5)\n1\n1\n1\n1\n1\n1\n1\n1\n1\n1\n1\n1\nAdvanced Branching and Synchronization (1/14)\n1\n1\n1\n1\n1\n1\n1\n1\n1\n1\n1\n1\nIteration (3/3) –>loops extension\n1\n1\n1\n1\n1\n1\n1\n1\n1\n1\n1\n1\nMultiple Instance (1/7)\n1\n1\n1\n1\n0\n1\n1\n0\n1\n1\n1\n1\nState-based (0/5)\n0\n1\n0\n1\n1\n1\n1\n1\n1\n1\n1\n1\nTrigger (0/2)\n1\n1\n1\n1\n1\n1\n1\n1\n1\n1\n1\n1\nCancelation and Force Completion (0/5)\n0\n1\n1\n1\n1\n1\n0\n0\n0\n1\n1\n1\nTermination (1/2)\n0\n0\n1\n1\n1\n1\n0\n0\n1\n1\n1\n1\nData (40)\nData Visibility (4/8)\n1\n1\n1\n1\n0\n1\n1\n1\n1\n1\n1\n1\nInternal Data Interaction (5/6)\n1\n1\n1\n1\n0\n1\n1\n1\n1\n1\n1\n1\nExternal Data Interaction (0/12)\n1\n1\n1\n1\n0\n1\n1\n1\n1\n1\n1\n1\nData Transfer (3/7)\n1\n1\n1\n1\n0\n1\n1\n1\n1\n1\n1\n1\nData-based Routing (2/7)\n1\n1\n1\n1\n1\n1\n1\n1\n1\n1\n1\n1\nFigure 2: Snippet of the CWL workflow.\nmodel aggregation in the decentralized training round de-\nsign. The loop feature implements a dynamic mechanism\nto handle multiple training rounds, ensuring scalability and\nflexibility in FL operations. Additionally, it can be fully\nautomated using GitHub Action workflows. More details can\nbe found in the source code, which is available in the GitHub\nrepository4.\n4https://github.com/CWL-FLOps/DecentralizedFL-CWL/\n3.3. Demonstration of FL Workflow\nWe demonstrate how the workflow-based approach en-\nables scalable automation of FL operations across cloud\ninfrastructures. Additionally, we integrate the implemented\nCWL-supported FL workflows with the Jupyter environment\nto facilitate collaborative learning and seamless workflow\nmanagement. Some related preliminary results have been\npublished in [45, 23].\nVisualized CWL-supported FL workflow. Figure 3 dis-\nplays the screenshot of the visualized CWL workflow graph\nnamed decentralizedFL.cwl via the CWL viewer tool5. It\nhas been verified with cwltool version 3.1.20230201224320\nand consists of five inputs (highlighted in a blue rectangle),\nthree steps (highlighted in a yellow rectangle), and a nested\nworkflow (highlighted in an orange rectangle). The connec-\ntions between the workflow inputs and steps illustrate the\ndependencies within the process. This workflow can serve\nas a research object bundle, enriched with comprehensive\nmetadata and licensing information to ensure its reusability.\nFor example, it is publicly available as an open-source\nworkflow and can be reused under the terms of the Apache\nLicense 2.0.\nFL workflow execution on hybrid Clouds. To demon-\nstrate the FL workflow execution over decentralized data\ninfrastructures, we utilized a well-known dataset named\nMNIST6 and five cloud instances from different providers.\nThese included one t4g.small instance (2 ARM-based vC-\nPUs, 2 GiB memory) and t3.small instance (2 x86-based vC-\nPUs, 2 GiB memory) from Amazon Web Services (AWS),\none t2a-standard-1 instance (1 ARM-based vCPU, 4 GiB\nmemory) and e2-medium instance (2 x86-based vCPUs, 4\nGiB memory) from Google Cloud Platform (GCP), and\none lab.uvalight.net instance (2 x86-based vCPUs, 2 GiB\n5https://view.commonwl.org/\n6https://git-disl.github.io/GTDLBench/datasets/mnist_datasets/\nYuandou Wang et al.: Preprint submitted to Elsevier\nPage 5 of 16\n\n\nManaging Federated Learning on Decentralized Infrastructures as a Reputation-based Collaborative Workflow\nFigure 3: The screenshot of the visualized FL workflow in the\nCWL viewer with detailed license, specification, and metadata.\nmemory) from the OpenLab infrastructure provided by the\nuniversity. Each dataset stored on the cloud instances was\nsplit from the MNIST dataset, with a size of approximately\n60 MB. The FL source code is based on PyTorch, reproduced\nfrom [46], where the author used the FedAvg method for the\nfederated model aggregation. We re-configured the FL work-\nflow with ten local training epochs and 12 communication\nrounds. Each setup was executed ten times to collect results\nfor statistical analysis.\nThe average training time is approximately (9.786 ±\n0.238) minutes, and the average test accuracy achieved by\nthe FL workflow execution is (98.127 ± 0.085)%. These\nempirical results demonstrate that CWL-supported FL work-\nflows are scalable, reusable, and portable, making them\nsuitable for execution in off-chain decentralized infrastruc-\ntures such as hybrid cloud environments. Since the CWL\ncommunity provides standardized alternatives for defining\nportable and reusable workflows that remain engine- and\nvendor-neutral, any CWL-compliant workflow execution en-\ngine should be able to execute this standardized workflow\ndescription and produce consistent results, regardless of the\nunderlying infrastructure [47]. Furthermore, by incorporat-\ning the principles of FAIR computational workflows within\nCWL, we can advance toward realizing FAIR FL workflow\nmanagement in future work.\n3.4. Lessons and Challenges\nThe empirical results demonstrate that CWL effectively\ndescribes FL workflows and automates their execution using\ncloud technologies. However, this approach assumes a pre-\nestablished collaboration, where distributed data sources are\npredefined within the workflow.\nCWL does not inherently address trust and reliable col-\nlaboration among multiple participants in FL workflows.\nThe decentralized nature of data providers challenges the tra-\nditional centralized workflow management paradigm, where\nproviders are predefined for composing application-specific\nFL workflows. To overcome this, an effective collaboration\nframework is needed to enable the dynamic selection of\ndata or resource providers and ensure the quality of their\ncontributions.\nIn the next section, we will explore how to incentivize\ncollaborations and ensure training quality by addressing the\nfollowing research questions:\n• How can we incentivize participants with high-quality\ncontribution to join the FL training process?\n• How can we assure training quality from decentralized\nparticipants in an unreliable environment?\n4. Decentralized Collaboration Framework\nTo tackle the challenges identified in 3.4, this section in-\ntroduces a decentralized collaboration framework that aims\nto manage the dynamic collaboration among participants\nwithin a decentralized community. The basic design ideas\ninclude:\n• Using blockchain environment to manage the decen-\ntralized relation among FL participants and to record\ntheir interaction history.\n• Managing the collaboration agreement by employing\nthe smart contract of the blockchain, where an FL\ndeveloper can explicitly describe the conditions for\ndesired participants in a smart contract.\n• Verifying the contribution through blockchain ledgers\nand manage the update of the FL aggregations via\ndynamic consensus among participants through smart\ncontracts.\n4.1. System Overview\nFigure 4 depicts the basic idea for FL applications, build-\ning on our previous work on the D-VRE framework [48].\nThis framework equips Jupyter users with essential com-\nponents for enabling robust FL collaboration, integrating a\npersonal Jupyter working environment, a blockchain net-\nwork, and off-chain legacy resources, such as data storage,\ncomputation, and networking, within a decentralized ecosys-\ntem. It enables a group of Jupyter users with different roles\nto engage in scientific community activities and create FL\nbuilding blocks as research assets. This is achieved through\nthe Create FL Building Blocks function (Component Con-\ntainerizer within NaaVRE).\nYuandou Wang et al.: Preprint submitted to Elsevier\nPage 6 of 16\n\n\nManaging Federated Learning on Decentralized Infrastructures as a Reputation-based Collaborative Workflow\n \nfrontend \n \n \n \n \n \n \nSystem status \n updates\nBlockchain Network\n \nData owner stakes their native  \ntokens in staking pool\n \n \n \n \nBlock data\n... ...\nBlockchain network\nNode 1\nNode 2\nNode i\nNode j\nNode N\nMake an agreement for the FL workﬂow\n \nLocal updates evaluation\nPost an ad to call for collaboration (CfC)\n \n \n \n \n \n \n \n \n \n \nIndividual user with digital wallet\n \nData owner\n \nData owner \nCompute\nPrivate Cloud\n \n \n \n \nData\n \n \n \nData\nPrivate Cloud\n \n \n \n \n \n \n \n \n \n \nfrontend \n \n \n \n \n \n \n \n \n \n \n \n \n \n \nfrontend \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n Create ML Model \n  [ Component Containerizer ]\n Customize FL Workﬂows \n   [ Workﬂow Composer ]\nSign Multidimensional Contracts \n  [ Make Agreements ]\nFL computational workﬂow examples\nDeliver models to data owners (stakeholders), trigger the deployment and execution of FL workﬂow(s) off-chain\nCWL engine \nScale FL workﬂows\n...\nHierarchical FL\nDecentralized FL\nCentralized FL\n......\n \n \nData\n \nfrontend \n \n \n \n \n \n \n \n \n \n \n \n \n \n \nInfra owner \nCompute\nfrontend\nLocal Virtual Research Environment\nTraining Node\nAggregator\nFederated Node\nSmart contract\nBlockchain\n \n \n \n \nTokens\n Access to blockchain\n  [ Auth via Digital Wallet ]\nFigure 4: This is an overview of the system for FL applications. A local virtual research environment enables a user to develop\nML models on-premise and unlocks the potential of establishing robust collaboration in a decentralized environment via ❶❷\nand ❸. It consists of two main interfaces: 1) via blockchain interfaces, users can access to the blockchain network to call for\ncollaboration, make an agreement, and evaluate local updates on-chain; 2) via workflow runtime interfaces, users can create ML\nmodels, customize FL workflows, operate collaborative workflows on decentralized infrastructure.\nThrough the function Access to blockchain (Auth via\nDigital Wallet within D-VRE), the system allows users to\nconfigure their digital wallets like MetaMask, to unlock the\ndecentralized Web and applications to call for collaboration\nand secure asset sharing in a decentralized environment [48].\nDue to the diverse data access restrictions, data can not\nbe moved out of the institutions [38]. The system allows\nmodel providers (also called FL task publishers) to Call\nfor Collaborations (CfCs) to enable secure data sharing,\ncomputing resource sharing, and collaborative learning from\nthe decentralized community, via the Sign multidimensional\ncontracts function (Make Agreements within D-VRE). Data\nor resource owners can respond to the CfCs via the interfaces\nembedded in their personal frontends.\nEach CfC will include specific requirements, e.g., the\ndata and resource specifications, required stakes, targeted\nmodel performance, minimum number of participants, and\nwhat the publisher can offer (such as reward), rules of\npenalty, and reputation updates resulting from different con-\ntribution behaviours. These requirements can be explicitly\ndescribed in a smart contract. The stake is related to crypto\nstaking in the blockchain system, which is the practice of\nlocking participants’ digital tokens to a blockchain network\nto earn rewards. For instance, a participant’s stake can be re-\nturned later with an additional reward if there is no indication\nof malicious behaviours [49]. The stake plays a crucial role\nin reliable FL, as 1) it can increase the cost of attacks and\n2) promote risk-sharing during FL system operations. The\ncandidate has to join the contract to make agreements.\nVia the function of Customize FL workflow (Workflow\nComposer and CWL-based FL workflow composition),\nusers who signed contracts acting as FL participants can\ncustomize a computational FL workflow through verified\nresources from the off-chain decentralized (data) infras-\ntructures. We assume that data are stored in the infras-\ntructures which provide computation capacity and network\nfor communication. Some participants may only contribute\nto infrastructure, e.g., computing, storage, and network\nresources. Each participant can be identified and verified\nfor their resources through trusted external committees,\nsuch as Oracle and DAO [50]. Hence, the composition of\ncomputational FL workflows can combine the on-chain and\noff-chain services to scale different FL scenarios.\nAfter the FL workflow with on-chain engagement has\nbeen confirmed, the system generates a number of smart con-\ntract instances to enforce the contract items and ensures that\nprecise, mutually agreed-upon terms govern collaborations\nin the decentralized network. The system enables users to\nstart the CWL engine for automating FL workflow deploy-\nment and execution over legacy data infrastructures while\nenabling secure and transparent execution in the blockchain\nenvironment. Since the block data has stored ledgers about\nFL actions for all participants in the blockchain network,\nit can correlate the captured data with user behaviours to\nmaintain a transparent record of any changes made to an\nFL operation. Finally, users can evaluate local updates of\ntheir FL workflows related to domain-specific subjects and\nanalyze the consequences of participants’ actions regarding\nrelevant task contributions, reputation updates, and rewards.\n4.2. How to Incentivize Collaboration?\nIn real-life scenarios, the FL task publisher does not\nknow which users in the system would join the FL training\ndue to the lack of prior information. The local data quality\nYuandou Wang et al.: Preprint submitted to Elsevier\nPage 7 of 16\n\n\nManaging Federated Learning on Decentralized Infrastructures as a Reputation-based Collaborative Workflow\nand the computing power of available resources from poten-\ntial candidates are unknown to the publisher owing to data\nprivacy and security concerns. Therefore, it is essential for\nthe task publisher to design an efficient incentive mechanism\nto stimulate active engagement from high-quality candidates\nwhile reducing the over-reward risks caused by the issues\nof asymmetric information [34, 51]. This study employs\nthe contract theory with a multidimensional scheme as an\nefficient approach to address the incentive collaboration\nproblem.\nAssume a set of ℕpotential candidates responds to the\nCfC task in the system. Let 𝑁= 1, 2, ⋯, 𝑛, where 𝑁⊆ℕ,\nrepresent the set of identity-verified candidates who have\nsigned contracts with stakes 𝑆= 𝑆1, 𝑆2, ⋯, 𝑆𝑛and initial\nreputations 𝑟0 = 𝑟0\n1, 𝑟0\n2, ⋯, 𝑟0\n𝑛. These candidates act as FL\nparticipants, continuously contributing to the FL network.\nEach participant’s reputation is dynamically updated based\non their behaviour.\nLet 𝜃denote a standard type space to differentiate the\nparticipant nodes. Suppose participants are classified into 𝑁\ntypes, which can be sorted in a descending order regarding\ncontribution types: 𝜃1 > 𝜃2 > ⋯> 𝜃𝑛, 𝑖∈{1, 2, ⋯, 𝑛}.\nLet ̂𝜃𝑖be the claimed type by participant 𝑖with the true\n𝜃𝑖. We assume that candidates who join the FL must claim\ntheir types ̂𝜃and select the corresponding contract item 𝜙̂𝜃.\nAlthough the task publisher does not know about the true\ntype of a given participant due to the information asym-\nmetry, it has information about the reported type ̂𝜃𝑖by the\nparticipant with the true type 𝜃𝑖(e.g., data and infrastructure\nspecifications), from which the publisher can inform the\nprobability that a participant belongs to a particular type 𝜃𝑖\nwith reported (meta)data and computing power categories,\ndenoted as ∑𝑁\n𝑖=1 𝑝𝑖(̂𝜃𝑖) = 1.\nFor participants with different contributions, the task\npublisher signs different contract items with them. We define\nthe contract = (𝑇max, Φ) is comprised of a maximum\nwaiting time 𝑇max and contract terms Φ = {𝜙𝑖}𝑖∈𝑁. 𝑇max\ndenotes the maximum allowable time for receiving partic-\nipants’ contributions. Each contract item 𝜙𝑖≜(𝐶𝑖, 𝑆𝑖, 𝑅𝑖)\nspecifies the relationship among each type-𝑖participant’s\nstake 𝑆𝑖, contribution 𝐶𝑖(often associated with a completion\ntime 𝜏𝑖≤𝑇max), and its corresponding reward 𝑅𝑖. Any par-\nticipant who completes their contributions to the FL network\nwithin the required time during each communication round\nwill receive a reward 𝑅𝑖. Conversely, participants whose\ncompletion time 𝜏𝑖exceeds 𝑇max will receive a zero reward,\nresulting in a zero contract instance.\nContribution model. We define a contribution model for\neach FL workflow. Let 𝐶(𝑡)\n𝑖\ndenote an estimated contribution\nbased on the 𝑖𝑡ℎparticipant’s local model training 𝑓local and\nits behaviours 𝑔behaviour at round 𝑡, which can be formally\ndefined as:\n𝐶(𝑡)\n𝑖\n=𝑓local(𝐷𝑖, 𝐰(𝑡)\n𝑖) ⋅𝑔behaviour(ℎ(𝑡)\n𝑖),\n∀𝑖∈𝑁\n(3)\nwhere 𝐶(𝑡)\n𝑖\n≥0 and ℎ(𝑡)\n𝑖\nis the historical behaviour records\nregarding reputation and stake which can be used to differ-\nentiate honest participant nodes and malicious ones.\nLet 𝑇max denote the upper limit on the duration in FL\nsynchronous settings, within which participants must sub-\nmit their contributions, such as local model updates 𝐰(𝑡)𝑖,\nbefore the aggregation is triggered within the federation.\nSpecifically, participants with 𝜏𝑖≤𝑇max can complete the\nsubmission of model updates to allow the aggregation of\nfederated models to proceed on time per communication\nround. We define the contribution value function 𝑉(⋅) for\nany participant 𝑖∈𝑁as follows:\n𝑉(𝐶(𝑡)\n𝑖, 𝜏𝑖) = 𝑋𝑐\n𝜏𝑖\n⋅𝑞(𝑡)\n𝑖,\n𝑞(𝑡)\n𝑖\n= 𝜎(\n𝐶(𝑡)\n𝑖\n−𝐶min\n𝐶max −𝐶min\n)\n(4)\nwhere 𝜏𝑖is the time cost for participant 𝑖to make contribu-\ntion 𝐶(𝑡)\n𝑖, and 𝑋𝑐\n𝜏𝑖represents the unit price of the contribution\nfor participant 𝑖, where 𝑋𝑐is a constant factor representing\nthe value associated with the contribution. We define 𝑞(𝑡)\n𝑖\nas a dynamic quality parameter via the sigma function 𝜎(⋅),\nwhere 𝐶max represents the saturation threshold for contri-\nbution, and 𝐶min is the minimum required contribution. A\nhigher value of 𝑉(⋅) indicates better quality in the local\ntraining contribution, leading to fewer training iterations\nneeded to reach a targeted model performance score (e.g.,\naccuracy, precision, recall, or F1 score).\nUtility function of participants. For a signed contract 𝜙𝑖,\nwe define the utility function of the type-𝑖participant at\nround 𝑡as follows,\n𝑈𝑐(𝜙𝑖|𝜃𝑖) = 𝑅𝑖𝕀compl −𝜆𝑠𝑆𝑖(1 −𝕀compl) −𝑐(𝐶(𝑡)\n𝑖) (5)\n𝕀compl = exp(−\n𝐾\n∑\n𝑘=1\n𝜔𝑘⋅VSL𝑘).\n(6)\nThe compliance condition, 𝕀compl ∈[0, 1], is derived from\nthe violation levels. For example, minor violations (e.g.,\noccasional timeouts) will result in a partial retention of\nproceeds, while severe violations (e.g., malicious behaviour)\nwill reduce the proceeds to zero. The normalized violation\nlevel for the 𝐾violation types is denoted by VSL𝑘∈[0, 1],\nwith 𝜔𝑘representing the weight of the 𝑘𝑡ℎviolation type. A\nvalue of 𝕀compl = 1 indicates no violations, while 𝕀compl = 0\nsignifies severe violations.\nThe parameter 𝜆𝑠defines the penalty factor applied to\nthe 𝑖𝑡ℎparticipant’s stake, 𝑆𝑖. If a node operates without\nviolations, a proportion of the stake, 𝜆𝑠𝑆𝑖, is allocated to\nthe system’s risk reserve. However, if violations occur, the\nparticipant risks forfeiting the entire stake, 𝜆𝑠𝑆𝑖. Addition-\nally, 𝑐(⋅) represents the effort cost for contributing 𝐶(𝑡)\n𝑖\nwith\ntime 𝜏𝑖by the type-𝑖participant. This cost can be further\nextended to more complex expressions by factoring in the\nresource utilization required for model training, validation,\nand aggregation.\nProfit function of the task publisher. Task publisher’s\nprofit derived from a type-𝑖participant is influenced by\nYuandou Wang et al.: Preprint submitted to Elsevier\nPage 8 of 16\n\n\nManaging Federated Learning on Decentralized Infrastructures as a Reputation-based Collaborative Workflow\nmultiple factors. Although a high-quality contribution can\nincrease the task publisher’s profit, it also incurs a higher re-\nward cost for the publisher. In addition, any violations (e.g.,\ntimeouts, malicious actions, or mismatched behaviours) by\nparticipants will result in a deduction from their stake (or\ntokens) as penalties, which are then allocated as profits to the\npublisher. Therefore, we define the profit function obtained\nfrom participant 𝑖as follows:\n𝜋(𝜙𝑖) =(𝑉(𝐶(𝑡)\n𝑖) −𝑅𝑖)𝕀compl + 𝜆𝑠𝑆𝑖(1 −𝕀compl),\n(7)\nwhere 𝑉(𝐶(𝑡)\n𝑖) −𝑅𝑖≥0, the profit is positive; otherwise,\nthe publisher risks incurring a negative profit, even if no\nviolations occur from any participant 𝑖.\nTo make the contract feasible, it must satisfy the follow-\ning constraints simultaneously.\nDefinition 1 (Individual Rationality (IR)). Let 𝑈𝑐(𝜙𝑖|𝜃𝑖) be\nthe utility for the type-𝑖participant under the contract 𝜙𝑖.\nEach type-𝑖participant achieves the non-negative utility if it\nchooses the contract item 𝜙𝑖that is designed for its own type\n𝜃𝑖, which is given by\n𝑈𝑐(𝜙𝑖|𝜃𝑖) ≥0.\n(8)\nDefinition 2 (Incentive Compatibility (IC)). Each partici-\npant 𝑖achieves the maximum utility by truthfully reporting\nits type 𝜃𝑖if it chooses the contract item 𝜙𝑖that is designed\nfor its own type 𝜃𝑖rather than other types 𝜃−𝑖in contract\nitems 𝜙𝜃−𝑖. The mechanism is incentive compatible if\n𝑈𝑐(𝜙𝑖|̂𝜃𝑖= 𝜃𝑖, 𝜙𝜃−𝑖) ≥𝑈𝑐(𝜙𝑖|̂𝜃𝑖≠𝜃𝑖, 𝜙𝜃−𝑖),\n(9)\n𝑈𝑐(𝜙𝑖|̂𝜃𝑖= 𝜃𝑖, 𝜙𝜃−𝑖) ≥𝑈𝑐(𝜙𝑗|̂𝜃𝑗= 𝜃𝑗, 𝜙𝜃−𝑖),\n(10)\nwhere 𝜃−𝑖∪𝜃𝑖= 𝜃, 𝜃−𝑖≠𝜃𝑖, and 𝜃𝑖≥𝜃𝑗for all participants\n𝑖, 𝑗∈𝑁.\nAs a rational individual, the task publisher aims to max-\nimize its profit in the system [52]. Therefore, the total\nincentive problem is given by\nmax Π(Φ) =\n𝑁\n∑\n𝑖=1\n𝑝𝑖(̂𝜃𝑖) ⋅𝜋(𝜙𝑖),\n∀𝜙𝑖∈Φ\n(11)\ns.t., IR(𝐸𝑞. 8) and IC(𝐸𝑞𝑠. 9, 10) constraints.\n(12)\nTo mitigate the risks of over-rewarding or insufficient re-\nwards, it is crucial to examine the optimality of the contract\nproblem.\n4.3. How to Assure Training Quality along with\nContract Optimality?\nThis section first employs a mechanism design approach\nthat integrates a reputation system and dynamic incentive\nindicators within contracts to ensure training quality in an\nunreliable environment. Then, leveraging a quantified re-\nward measurement, we analyze the optimality of the con-\ntract problem. Figure 5 illustrates the key steps involved in\nassuring training quality, including reputation-based com-\nmittee selection, malicious detection and penalty, reputation\nupdates, and reward calculation.\nReputation-based committee selection. We introduce a\ncommittee of high-reputable and highly effective nodes\namong participants to do extra work like being responsible\nfor partial model validation and aggregation. Let (𝑡) be the\nfinal selected committee in each round 𝑡, where (0) = ∅\nand is the committee size. We use a stratified sampling\nmethod [53] based on reputation 𝑟(𝑡) = {𝑟(𝑡)\n1 , 𝑟(𝑡)\n2 , ⋯, 𝑟(𝑡)\n𝑛}\nand a cooling-down mechanism, to balance the advantages\nof highly reputable nodes.\nFirst, we sort the nodes with reputation descending\nand divide them into several strata layers. Let 𝑁sorted =\nsort(𝑁, 𝑟𝑖↓) be the sorted set and 𝐿be the number of\nstrata to divide the nodes into. For each stratum layer 𝐿𝑘=\n𝑁sorted[ (𝑘−1)𝑁\n𝐿\n, 𝑘𝑁\n𝐿), 1 ≤𝑘≤𝐿, the initial quota per stratum\n𝑄𝑘is calculated by\n𝑄𝑘= ⌊\n𝐿⌋+\n{\n1,\nif 𝑘≤\nmod 𝐿,\n0,\notherwise.\n(13)\nFor each layer, the set of eligible nodes is 𝑘= {𝑖∈\n𝐿𝑘|𝑐𝑑(𝑡)\n𝑖\n= 0}, where 𝑐𝑑(𝑡)\n𝑖\n= 0 indicates the node 𝑖is\nnot cooling down. Hence, we can determine the number of\nselected nodes 𝑚𝑘= max(1, min(𝑄𝑘, |𝑘|)) per layer, using\nthe selection probability sampling performed as follows:\nP(𝑖) =\n(𝑟𝑖)𝛾\n∑\n𝑗∈𝑘(𝑟𝑗)𝛾,\n𝑗∈𝑘\n(14)\nwhere 𝛾∈(0, 1] is a decay exponent of reputation co-\nefficient. Then, 𝑘is obtained by randomly selecting 𝑚𝑘\nnodes in 𝑘based on selection probabilities P(𝑖) without\nreplacement. Hence, it follows a hypergeometric distribu-\ntion in probability theory and statistics [54], which can be\nformally stated as 𝑘∼Hypergeometric(𝑚𝑘, 𝑘, P(𝑖)).\nIn the case of ∑𝐿\n𝑘=1 |𝑘| < , we calculate a re-\nmaining quota remain = −∑𝐿\n𝑘=1 |𝑘| and gather all\neligible nodes not yet selected as a global candidate pool,\nglobal = (∪𝐿\n𝑘=1𝑘)∖(∪𝐿\n𝑘=1𝑘). Again, using the selection\nprobability sampling on the global eligible pool to calculate\nthe remaining committee remain, which is given by,\nP′(𝑖) =\n(𝑟𝑖)𝛾\n∑\n𝑗∈global (𝑟𝑗)𝛾,\n𝑗∈global\n(15)\nHence, remain ∼Hypergeometric(remain, global, P′(𝑖)),\nand the total committee is obtained by = (∪𝐿\n𝑘=1𝑘) ∪\nremain.\nAfter the final selection, the system updates each node’s\nstatuses, including the selected history and the cooldown\ntime 𝑐𝑑𝑖, which is formulated by\n𝑐𝑑(𝑡+1)\n𝑖\n=\n{\n3,\nif 𝑖∈,\nmax(0, 𝑐𝑑(𝑡)\n𝑖\n−1),\notherwise.\n(16)\nYuandou Wang et al.: Preprint submitted to Elsevier\nPage 9 of 16\n\n\nManaging Federated Learning on Decentralized Infrastructures as a Reputation-based Collaborative Workflow\n   \n   The proposed FL workﬂow run per round\n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \ncontracts\nstart a new FL round\nSelect committee\nmembers\nPerform federated model\naggregation\nTraverse all nodes\nYes\nNo\nMalicious?\nApply penalty to\nmalicious nodes\nUpdate\nreputation\nCalculate reward\nRecord metrics\nEnd the round\nCollect all contributions\nMake contributions\nFigure 5: Flowchart of FL system operations per round.\nwhere we specify that if 𝑖is selected as a committee, the\nsystem will update the cooldown as three at the current round\nand decrease the cooling time of the unselected nodes by one\ncooldown per round.\nReputation update model. We employ a dynamic reputa-\ntion update model to encourage long-term high-quality and\nstable contributions for all participants through a bonus for\nthe quality and stability of contributions while discouraging\nmalicious behaviours by penalties on reputation. To achieve\nthat, we consider a dynamic decay factor 𝛿∈[0, 1] to\nincentivize long-term participation by obtaining a reputation\ncompensation from the last round, which is given by\n𝛿= 𝛿𝑏+ 𝜆𝑝⋅(1 −\n1\n1 + participation𝑖∕100),\n(17)\nwhere 𝛿𝑏is a base decay factor. 𝜆𝑝denotes a decay com-\npensation parameter and participation𝑖is the 𝑖𝑡ℎpartic-\nipant’s historical participation times. As such, the more\nparticipation𝑖, the higher the reputation compensation 𝛿⋅\n𝑟(𝑡−1)\n𝑖\nfor round 𝑡.\nBesides, a good quality of contribution is good for an\nincreased reputation. Let 𝑋𝑐denote a unit bonus from the\ncontribution quality to reputation updates, the amount of in-\ncreased reputation resulting from good contribution is given\nby 𝑋𝑐⋅𝑞(𝑡)\n𝑖, where 𝑞(𝑡)\n𝑖\nis quantified by Eq. 4. Additionally,\nwe define 𝜆stab = 1 −std([𝐶𝑡−𝜏\n𝑖\n, ⋯, 𝐶𝑡\n𝑖])∕𝜏as a stability\nparameter during the last 𝜏rounds to avoid malicious nodes\nwith random attacks to obtain rewards. Hence, the new\nreputation at round 𝑡can be defined by\n𝑟(𝑡)\n𝑖\n= 𝛿𝑟(𝑡−1)\n𝑖\n+ 𝑞(𝑡)\n𝑖𝑋𝑐+ 𝜆stab𝑋𝑠,\n(18)\nwhere 𝑋𝑠denote unit bonus from the stability to reputation\nupdates and 𝑟(𝑡)\n𝑖\n∈[0, 𝑟max]. We employ a dynamic maxi-\nmum capability 𝑟max per round to limit the upper bound of\nreputation updates.\nMalicious detection and penalty. To safeguard the FL pro-\ncess, we consider malicious detection and penalty through\na set of conditions. It consists of: 1) persistent low contri-\nbutions (condition 1), 2) abnormal fluctuations (condition\n2), and 3) sudden behavioural changes (condition 3), which\nserve as indicators for detecting malicious nodes. For ease\nof analysis, we assume that any participants’ behaviours\nmeet the condition set (condition 1 AND condition 2) OR\ncondition 3, the system will detect them as a set of malicious\nnodes 𝑁malicious and perform a penalty to them. The penalty\nfunction is defined by,\npenalty = min(𝜆𝑟𝑟𝑗+ 𝜆𝑠𝑆𝑗,\n𝑟𝑗\n2 ),\n(19)\nwhere 𝜆𝑟, 𝜆𝑠denote the factors of applying penalty to repu-\ntation updates and stake, respectively. The upper bound\n𝑟𝑗\n2\nis intended to avoid excessive penalties on the reputation.\nHence, the updated reputation for node 𝑗at round 𝑡is given\nby 𝑟(𝑡)\n𝑗= 𝑟(𝑡−1)\n𝑗\n−penalty, ∀𝑗∈𝑁malicious.\nReward calculation. Let 𝐵denote the base reward of the\nreward pool. The reward calculation considers a participant’s\nstake, historical contribution performance, and committee\nbonus. The stake and contribution proportions relative to\nthe overall records influence the rewards participants receive\nfrom the reward pool.\nWe introduce two dynamic weights, 𝛼and 𝛽, based on\nreputation to balance the influence of stake and historical\ncontributions in reward calculation, where 𝛽= 1 −𝛼. The\nweight 𝛼is defined as 𝛼= 𝜎(\n𝑟−𝑟0\n𝑖\n𝑓scale ) ⋅𝜆stake, where 𝜆stake\nis the global stake weight, and reputation 𝑟determines the\nadjustment.\nTo prevent monopolization, we introduce an effective\nstake limit for large nodes, ensuring no single node domi-\nnates. The effective stake is given by 𝑆eff\n𝑖\n= min(𝑆𝑖, 3 ⋅𝑆),\nwhere nodes holding more than three times the average stake\n𝑆are capped.\nThe historical contribution of participant 𝑖over the last 𝜏\nrounds is computed as 𝐶hist\n𝑖\n= ∑𝜏\n𝑡=0 𝐶(𝑡−𝜏)\n𝑖\n⋅𝜁𝑡, where 𝜁𝑡(𝜁∈\n(0, 1)) is an exponential decay factor that prioritizes more\nrecent contributions. The total historical contribution across\nall participants is given by 𝐶total = ∑\n𝑖∈𝑁\n∑𝜏\n𝑡=0 𝐶(𝜏−𝑡)\n𝑖\n⋅𝜁𝑡.\nYuandou Wang et al.: Preprint submitted to Elsevier\nPage 10 of 16\n\n\nManaging Federated Learning on Decentralized Infrastructures as a Reputation-based Collaborative Workflow\nAny participant selected as a committee member will\nreceive a bonus for their contributions to model validation\nand aggregation, which is formulated by,\n𝑅cmm =\n{\n𝐵cmm ⋅𝐽c(𝑟),\nif 𝑖∈(𝑡),\n0,\notherwise.\n(20)\nHere, 𝐽c(𝑟) =\n(∑\n𝑖=1 𝑟𝑖)2\n⋅∑\n𝑖=1 𝑟𝑖2+𝜖⋅𝜎( 𝑟\n10), 𝐵cmm represents a base\nbonus, and 𝐽𝑐(𝑟) is an improved Jain’s fairness index [55]\ncalculated from the reputation scores of the committee. A\nsmall constant 𝜖is introduced to prevent division by zero\nerrors. The sigmoid function 𝜎( 𝑟\n10) ensures that the average\nreputation score is mapped to the range (0, 1). When the\nmean reputation 𝑟is low, the overall score decreases accord-\ningly. If the fairness index 𝐽𝑐(𝑟) is low, the committee reward\n𝑅cmm is also reduced, which promotes fair and balanced\nincentives.\nFurthermore, we employ 𝐽(𝑟) based on reputation, as\na fairness indicator to ensure equitable reward distribution\namong all participants 𝑖∈𝑁when earning rewards from\ntheir stake and historical contributions. Consequently, the to-\ntal reward allocated to each participant at round 𝑡is formally\ndefined as\n𝑅(𝑡)\n𝑖\n= (𝛼⋅𝐵\n𝑆eff\n𝑖\n∑𝑆𝑗\n+ 𝛽⋅𝐵\n𝐶hist\n𝑖\n𝐶total\n) ⋅𝐽(𝑟) + 𝑅cmm (21)\nNote that if a participant has no contribution history (i.e.,\n𝐶hist\n𝑖\n= ∅or 𝐶(𝑡)\n𝑖\n= 0), the current reward is set to zero,\n𝑅(𝑡)\n𝑖\n= 0. Therefore, it enables adjustable weights and zero-\ncontribution handling to calculate the participant’s reward.\nThe entire procedure can be implemented as a reputation-\nbased consensus in a smart contract for reliable FL pro-\ncesses, whose pseudocode is presented in Algorithm 1.\nContract optimality. With the above formulated optimiza-\ntion problem and detailed reward model, we can now study\nthe optimality of the contract problem.\nLet 𝜙∗\n𝑖\n≜(𝐶∗\n𝑖, 𝑆∗\n𝑖, 𝑅∗\n𝑖) ∈Φ∗, ∀𝑖∈𝑁in the new\nordering be the optimal contract that the task publisher\ncan derive from maximizing its total profit Π(⋅) and each\nparticipant performs optimal behaviours to maximize its\nutility. These contract items are found through solving the\noptimization problem as presented in Eq. 11 under the IC\nand IR constraints. To derive the optimal contract for this\nproblem, there may be several solutions.\nFor ease of analysis, we simplify the derivation process.\nBy assuming that: 1) all participants comply with the rules\nviz 𝕀compl = 1 (no violations), 2) consider a single participant\nscenario that can ignore the IC constraint, and 3) the cost of\ncontribution 𝑐(𝐶) = 1\n2𝛾𝑐𝐶2 where 𝛾𝑐> 0 is a cost parameter\nand 𝐶∈[0, 𝐶max], the relaxation version of the optimal\nproblem can be formulated as\nmax\n𝐶,𝑆,𝑅Π = 𝑉(𝐶) −𝑅,\ns.t. 𝑅−1\n2𝛾𝑐𝐶2 ≥0.\n(22)\nIf we ignore the IR constraint and directly maximize profit\nΠ, we need to define the relationship between the reward 𝑅\nAlgorithm 1: Reputation-based reliable FL con-\ntract.\nOutput: Well-trained model 𝐰, updated reputation\n𝑟, reward 𝑅.\nInput: FL workflow 𝐹, consisting of: an initial\nmodel 𝐰, a set of 𝑁participants indexed by\n𝑖, an aggregation strategy 𝐴, and system\nconfiguration.\n1 Initialize the FL workflow 𝐹;\n/* Define the data structures:\n*/\n2 struct Node { id, stake, reputation, totalReward,\nviolations, participation, cooldown, ...,\nidentityVerified }\n3 struct SystemConfig { baseReward, committeeSize,\nstakeWeight, ..., maliciousPercent }\n4 contract FLSystem {\n// Define the main contract\n5\nInitialize the nodes;\n6\nInitialize the SystemConfig;\n7 ⋯\n/* Core logic of the main contract:\n*/\n8\nfunction runRound() {\n9\nfor each round 𝑡do\n10\nCollect 𝐶(𝑡) = {𝐶(𝑡)\n𝑖\n∣∀𝑖∈𝑁} within 𝑇max;\n11\n(𝑡) ←selectCommittee(𝑟(𝑡), , 𝐿);\n12\ncommittee performs aggregation;\n13\n/* Malicious detection and penalty:\n*/\n14\nif ∀𝑖∈𝑁malicious = ∅then\n15\nUpdate reputation: 𝑟(𝑡)\n𝑖\n←Eq. 18;\n16\nelse\n17\nApply penalty: 𝑝𝑒𝑛𝑎𝑙𝑡𝑦𝑖←Eq. 19;\n18\n𝑟(𝑡)\n𝑖\n←𝑟(𝑡−1)\n𝑖\n−𝑝𝑒𝑛𝑎𝑙𝑡𝑦𝑖, ∀𝑖∈𝑁malicious;\nviolation + +;\n19\nCalculate rewards: 𝑅(𝑡)\n𝑖\n←Eq. 21, ∀𝑖∈𝑁;\n20\n𝑡+ +;\n/* Stop when an end condition triggers\n*/\n21\nreturn final model weights 𝐰, 𝑟, 𝑅.\n22\n}\n23 Each FL client executes:\n24\nfor each client 𝑖∈𝑁at round 𝑡in parallel do\n25\nUpdate model and calculate contributions:\n𝐰(𝑡)\n𝑖, 𝐶(𝑡)\n𝑖\n←Eqs. 1, 3;\n26 Committee executes:\n27\nAggregate model weights: 𝐰(𝑡+1) ←Eq. 2;\n(Eq. 21) and contribution value 𝑉(𝐶) (Eq. 4). We further\nassume 1) there are no monopoly stakes 𝑆≤3𝑆, then\n𝑆eff = 𝑆, 2) 𝑟𝑖= 𝑟, then 𝛼= 𝜆stake, and 3) both 𝐶hist and\n𝐶total are constants. At this point, maximizing Π is equivalent\nto differentiating the objective function with respect to the\nfirst term 𝐶and solving the first-order condition, which can\nbe rearranged as\n𝜕Π\n𝜕𝐶= 𝑉′(𝐶)−(1 −𝜆stake)𝐵𝐽(𝑟)\n𝐶total\n⋅𝜕𝐶hist\n𝜕𝐶\n= 0,\n(23)\nYuandou Wang et al.: Preprint submitted to Elsevier\nPage 11 of 16\n\n\nManaging Federated Learning on Decentralized Infrastructures as a Reputation-based Collaborative Workflow\nwhere we assume 𝐶hist = 𝐶⋅∑𝜏\n𝑡=0 𝜁𝑡, which leads to\n𝑉′(𝐶) = (1 −𝜆stake)𝐵𝐽(𝑟)\n𝐶total\n⋅1 −𝜁𝜏+1\n1 −𝜁\n.\n(24)\nCorrespondingly, we define 𝑘=\n1\n𝐶max to extend the 𝑉(𝐶)\nas the full version and calculate its derivative 𝑉′(𝐶), which\nis calculated by,\n𝑉′(𝐶) =\n𝜕( 𝑋𝑐\n𝜏⋅\n1\n1+𝑒−𝑘𝐶)\n𝜕𝐶\n= 𝑋𝑐⋅𝑘𝑒−𝑘𝐶\n𝜏(1 + 𝑒−𝑘𝐶)2 ,\n(25)\nThus, the optimal contribution 𝐶∗made by participant can\nbe derived from 𝑉′(𝐶∗) (Eq. 24) = 𝑉′(𝐶∗) (Eq. 25), which\nis given by\n𝐶∗= 1\n𝑘ln(\n𝑋𝑐⋅𝑘𝜏(1 −𝜁)\n(1 −𝜆stake)𝐵𝐽(𝑟)(1 −𝜁𝜏+1)𝐶total\n−1).\n(26)\nSince 1\n𝑘= 𝐶max, then we have 𝐶∗= 𝐶max ⋅𝑦where\n𝑦= ln(𝑥−1) is a logarithmically increasing function\nfor 𝑥=\n𝑋𝑐⋅𝑘𝜏(1−𝜁)\n(1−𝜆stake)𝐵𝐽(𝑟)(1−𝜁𝜏+1)𝐶total that asymptotically con-\nverges, theoretically, the optimal contribution would ap-\nproach to positive infinity. However, the maximum prac-\ntical constraints 𝐶∈[𝐶min = 0, 𝐶max], as a result, the\nactual optimal solution is 𝐶∗\n= 𝐶max. In other words,\n𝐶∗\n𝑖∝𝑓local(𝐷𝑖, 𝐰) ⋅𝑔behaviour(ℎ𝑖), adhering to optimal local\ntraining while demonstrating good behaviour, becomes the\ndominant strategy to maximize its utility for any participant.\nMeanwhile, ln(\n𝑋𝑐⋅𝑘𝜏(1−𝜁)\n(1−𝜆stake)𝐵𝐽(𝑟)(1−𝜁𝜏+1)𝐶total −1) = 1 can serve\nas a guideline for tuning the parameters (e.g., 𝜆stake, 𝑋𝑐and\n𝐵if given fixed others) to achieve the optimal solution. By\nbinding IR constraint, the optimal reward is 𝑅∗= 𝑐(𝐶∗). As\nall participants stake the same amount 𝑆, which leads to\n𝑆∗=\n𝜆stake𝐵𝐽(𝑟)\n𝑛⋅(𝑅∗−𝑅cmm −(1−𝜆stake)𝐵𝐽(𝑟)𝐶hist\n𝐶total\n)\n,\n(27)\n𝑅∗=𝑐(𝐶∗).\n(28)\nIf we consider the IR constraint, the optimization prob-\nlem can be reorganized as a Lagrangian function with a\nLagrange multiplier and then repeat the derivation process\nfor the three terms 𝐶, 𝑆, 𝑅, respectively. With the help of\nmath tools (e.g., SciPy methods in Python) to solve for the\nproblem, we can obtain the optimal 𝐶∗, 𝑆∗, 𝑅∗by adjusting\nthe parameters as needed by numerical analysis. Suppose\nthe distribution of the participants’ violations (concerning\nByzantine failures) is not predictable and the stakes are\nunbalanced. In those cases, we can consider using advanced\napproaches, such as Bayesian priors [56] or reinforcement\nlearning optimization [57], to meet the requirements.\n5. Experiments and Evaluation\nThis section illustrates simulation setup, demonstrates\nthe feasibility of the proposed incentive mechanisms, and\nevaluates the outcomes for validation and guidance of (opti-\nmal) smart contract design.\n5.1. Simulation Setup\nIn the simulation, we conducted extensive simulation\nexperiments on a local computer equipped with an Apple\nM1 chip with eight (four performance and four efficiency)\ncores, 16GB memory, and a 500 GB Macintosh HD disk.\nFor the evaluation of solutions, we utilize a normal\ndistribution with random fluctuation for the ease of\ntraining process to present the normal behaviour pattern\nfor participants acting normally, 𝐶normal = max(0, (𝜇=\n7, 𝜎2 = 1)⋅), where 𝜇and 𝜎denote the mean and standard\ndeviation of the set of contributions collected from the\nnormal (or honest) FL participants. For malicious behaviour\npatterns, we simulate malicious patterns with three different\nattacks: 1) false high contribution attack, where malicious\nnodes disguise themselves as high-value nodes through ab-\nnormally high contributions to avoid detection based on low\ncontributions; 2) zero contribution attack where malicious\nnodes directly destroy the federated model aggregation and\nreduce model performance, and 3) random attack which is\ngiven by a random choice of 60% false high contribution\nattack and 40% zero contribution attack.\nWe introduce a parameter 𝜂switch that allows switching\nbetween different patterns to simulate various malicious be-\nhaviours during the training process. The parameter defines\nthe longest time window threshold at which the system tran-\nsitions from base to progressive malicious phases — rang-\ning from high-contribution and zero-contribution attacks to\nrandomly hybrid attacks. This enables the implementation of\nmalicious pattern-switch logic for progressive attack testing,\nperiodic behavioural perturbations, and defense mechanism\nverification. By periodically switching attack strategies (e.g.,\nevery 30 rounds), we simulate the adaptability of malicious\nparticipants. Additional details are available in the source\ncode.\nAdditionally, we set different malicious percentages as\nan adjustable parameter to distinguish between malicious\nand honest nodes among the total participants. An attack\ndetection function is implemented to identify such malicious\nbehaviours, which allows us to test and evaluate the effects\nof penalties, reputation updates, and rewards on the system.\nA summary of the other parameters used in the simulation is\npresented in Table 2.\nTo measure the fairness in reward allocation based on\nactual contributions, we consider two metrics for evaluation.\nJain’s fairness index [55] is a quantitative measure of fairness\nand discrimination for resource allocation in shared systems.\nWe have used it to maintain the fairness of committee\nselection on reputation presented in Eq. 20, whereas it can\nalso be employed to measure the fairness of reward allo-\ncation 𝐽(𝑅) by replacing the input as 𝑅. Additionally, we\nconsider an opposite metric — the Gini coefficient [58], as\na measurement of reward inequality, which is formulated by\n𝐽(𝑅) =\n(∑𝑛\n𝑖=1 𝑅𝑖)2\n𝑛∑𝑛\n𝑖=1 𝑅𝑖\n2 + 𝜖\n⋅𝜎( 𝑅\n10),\n(29)\nYuandou Wang et al.: Preprint submitted to Elsevier\nPage 12 of 16\n\n\nManaging Federated Learning on Decentralized Infrastructures as a Reputation-based Collaborative Workflow\nTable 2\nParameter setting in the simulation.\nParameter\nDescription\nSetting\n𝑆𝑖\ninitial stake\n100\n𝑟0\n𝑖\ninitial reputation score\n100\n𝐶min\nminimal contribution score\n0\n𝐶max\nmaximum contribution score\n10\n𝛾\nreputation decay coefficient\n0.5\n𝑟𝑡≤5\nmax, 𝑟𝑡>5\nmax\nmaximum capabilities of reputation updates\n300, 500\n𝜖\na small constant\n10−8\n𝑐𝑑(⋅)\ncooldown period\n3\n𝐿\nnumber of strata\n3\n𝐵cmm\nbase bonus to committee member\n40\n𝛿𝑏\nbase decay factor\n0.88\n𝜆𝑝\ndecay compensation parameter\n0.07\n𝜏\nrecent historical rounds\n5\n𝜏stab\ndefault stability for new participants\n0.8\n𝑋𝑐\nbase bonus of contribution\n50\n𝑋𝑠\nbase bonus of stability\n30\n𝜆𝑟\npenalty factor to reputation\n0.3\n𝜆𝑠\npenalty factor to stake\n0.1\n𝜁\nhistorical decay factor\n0.9\n𝐵\nbase reward value in the pool\n1200\n𝑛\nthe number of participants\n100\n𝜆stake\nstake weight\n0.4\n\ncommittee size\n5\n𝑚\nmalicious percent\n15%\n𝜂switch\nthe first time window of observing a switch of malicious patterns\n5\n𝑅𝑜𝑢𝑛𝑑\nthe total number of the FL rounds\n90\n𝐺(𝑅) = (𝑛+ 1 −2\n∑𝑛\n𝑖=1\n∑𝑖\n𝑗=1 𝑅𝑗\n∑𝑛\n𝑗=1 𝑅𝑗\n)∕𝑛\n(30)\nwhere the input set 𝑅is performed in ascending order. The\nsource code is available online at the GitHub repository7.\n5.2. Simulation Results\nThis section presents an overview of the simulation\nresults under the parameter setting presented in Table 2. Fig-\nure 6 showcases the dynamics of malicious node detection,\nreputation updates, and reward distribution per round.\nMalicious detection. Sub Figure 6a illustrates the malicious\ndetection performance per round. The detection method\nfollows the condition set (condition 1 AND condition 2) OR\ncondition 3, based on a malicious percentage of 15%. The\nmalicious pattern switch parameter 𝜂switch plays a crucial\nrole in shaping the behaviour records of malicious partici-\npants, thereby influencing detection performance.\nNotably, false high-contribution malicious nodes were\nnot detected during the first five rounds, as the current\ndetection conditions do not account for high-contribution\nattacks, allowing such behaviours to appear normal. When\nthe round 𝑡∈[5, 30), the malicious pattern shifts to zero\ncontributions. By the eighth round, the system successfully\nidentified 12 out of 15 malicious nodes. When the round\n𝑡∈[30, 60), the malicious pattern transitions to random\nattacks, with a 60% probability of high-contribution at-\ntacks and a 40% probability of zero-contribution attacks.\nIn the final 30 rounds, malicious behaviours revert to zero-\ncontribution attacks. The detection method proves to be\nmore effective against zero-contribution attacks but remains\nineffective against false high-contribution attacks due to\ncurrent detection limitations.\nReputation updates. Sub Figure 6b illustrates the repu-\ntation update dynamics per round, distinguishing between\n7https://github.com/yuandou168/reliableFLOps\nhigh-contribution attack\nzero-contribution attack\nrandom contribution attack\n60% (high), 40% (zero)\nzero-contribution attack\n(a) Total malicious nodes detected per round.\n(b) Reputation update dynamics.\n(c) Reward distribution.\nFigure 6: Overview of malicious detection, reputation updates,\nand reward distribution per round.\nhonest and malicious nodes among 85 honest participants\nand 15 malicious ones. Initially, all nodes start with a repu-\ntation score of 100, which increases as new contributions are\ncollected during the first few rounds. This growth continues\nuntil it reaches a plateau around a reputation score of 300.\nNotably, there is no difference in reputation growth between\nhonest and malicious nodes until the eighth round.\nAt the eighth round, some malicious nodes experience\na sharp drop in reputation due to detected malicious be-\nhaviours, as shown in Figure 6a. Since most malicious nodes\nYuandou Wang et al.: Preprint submitted to Elsevier\nPage 13 of 16\n\n\nManaging Federated Learning on Decentralized Infrastructures as a Reputation-based Collaborative Workflow\nwere identified during this period, it caused their reputation\nscores to decline significantly, eventually approaching zero.\nDuring the random attack phase, the system fails to detect all\nmalicious activities, allowing some malicious nodes to tem-\nporarily regain their reputation through high-contribution at-\ntacks. This results in fluctuations in their reputation updates,\nas not all malicious nodes receive penalties in this phase.\nHowever, once all 15 malicious nodes are successfully de-\ntected, the fluctuations cease, and their reputation scores\nrapidly decline, dropping by an average of 148.3 points.\nMeanwhile, the reputation of the 85 honest nodes steadily\nincreased as expected in the first five rounds by 300. Then\nthey gradually reach the upper limit of 500. The average\nreputation increase for honest nodes is approximately 354.6,\nsignificantly higher than that of the malicious nodes.\nReward distribution dynamics. Sub Figure 6c illustrates\nthe reward distribution dynamics among 85 honest and 15\nmalicious nodes out of 100 participants. Because malicious\nnodes mimic high-contribution participants, they accumu-\nlate higher rewards than honest nodes. Hence, they exhibit\na higher average reward value and a faster growth rate\nin the early rounds. However, as the system detects zero-\ncontribution attacks, their rewards drop sharply to zero.\nAlthough some malicious nodes temporarily regain their\nreputation by engaging in high-contribution attacks in the\nperiod of random attacks, as more malicious nodes are\nprogressively detected, their corresponding rewards decline.\nAlthough all malicious nodes ultimately reach a very\nlow reward level over the 90 rounds, their total rewards are\nnot zero. Overall, the final reward values range between 4.1\nand 40.5 at round 90, satisfying the IR constraint. However,\nparticipants acting maliciously or continuing such behaviour\nunder this reward incentive mechanism cannot achieve op-\ntimal utility. Specifically, the average reward for malicious\nnodes dropped by 10.7, while the average reward for honest\nnodes increased by 23.0. The total reward accumulated by\nthe 85 honest nodes is 8.38 times greater than that of the 15\nmalicious nodes in the simulation system.\nConsequently, this incentive mechanism encourages par-\nticipants to adopt a more rational strategy — avoiding ma-\nlicious behaviour to maximize their rewards. Therefore, it\npreserves the trend of rewarding aligned with the incentives\nwhile reducing the risk of over-penalty and over-reward.\nFairness. Figure 7 compares the fairness of reward dis-\ntribution across 100 participant nodes under five different\nmalicious percentage settings. Similar to the reward dynam-\nics observed in Figure 6c, the fairness initially improves,\nas indicated by an increase in Jain’s fairness index and a\ndecrease in the Gini coefficient (see Eq. 29), that suggests a\ntrend toward a more equitable reward distribution. However,\ndue to the influence of malicious nodes, the reward allocation\nis not always fair.\nFor instance, given a malicious percentage 15%, we\nobserved that malicious detection significantly influences\nreward allocation’s fairness. When most or all malicious\nnodes are successfully identified, i.e., during rounds between\n8 and 30, as well as 60 to 90, the fairness index decreases\nFigure 7: Comparisons of total fairness metric dynamics across\nthe last 90 rounds.\nwhile the Gini coefficient increases. Conversely, fairness\nremains relatively stable when the system detects only a few\nmalicious nodes. It reflects an imbalanced reward allocation\ninfluenced by the performance of malicious detection.\nAs the percentage of malicious nodes in the system\nincreases, e.g., from 10% to 30%, the reward distribution\nbecomes more inequitable between honest and malicious\nnodes. However, such inequity remains at a healthy threshold\n(<0.3). Such a change is positive because it still preserves\nfairness among honest participants while preventing mali-\ncious participants from obtaining unfair rewards.\nThe optimal parameter space. In the simulation, we em-\nploy the controlled variable method and an optimization\nsolver ‘SLSQP’, which is suitable for constrained optimiza-\ntion, to analyze the applicable approximations of the optimal\ncontract items (𝐶∗\n𝑖, 𝑆∗\n𝑖, 𝑅∗\n𝑖) ∈Φ∗. The numerical analysis\nvalidates the optimal contribution 𝐶∗→𝐶max for all par-\nticipants. It also verifies that the IR-constrained satisfaction\nrate is 100% while minimum utility is more than zero. With\nthis numerical analysis, users can adjust their contract terms\nfor different requirements with optimal parameter settings.\nMore technical details have been presented in the source\ncode.\nThese simulation results suggest that the proposed incen-\ntive mechanisms are feasible in an FL system with honest\nand malicious participants. By coding these mechanisms\ninto smart contracts and bounding blockchain, the system\ncan effectively constrain and guide participant behaviour,\nensuring that honest participants can receive fair compensa-\ntion while discouraging malicious activities. The numerical\nanalysis can help customize (approximately) optimal con-\ntract items written in smart contracts to adopt diverse FL\nscenarios.\n6. Summary\nThis study demonstrated how FL can be structured as a\nworkflow using open workflow standards and executed on\nremote infrastructure to address automation challenges. To\nbridge the gap between traditional workflow-based automa-\ntion and decentralized collaboration, we propose a novel\nYuandou Wang et al.: Preprint submitted to Elsevier\nPage 14 of 16\n\n\nManaging Federated Learning on Decentralized Infrastructures as a Reputation-based Collaborative Workflow\nstrategy that builds upon our prior work to enhance re-\nliability in FL management over decentralized infrastruc-\ntures. We leverage contract theory with a multidimensional\nscheme to tackle the incentivizing collaboration problem\nby constructing a contribution model, implementing fair\ncommittee selection, dynamically updating reputations, cal-\nculating rewards, and defining corresponding profit and util-\nity functions. Additionally, we explore the optimality of\ncontracts to guide the design and implementation of smart\ncontracts that can be deployed on blockchain networks to\nassure training quality. We conduct extensive simulation\nexperiments to validate the proposed approach. The results\ndemonstrate that our incentive mechanisms are effective,\nensuring fair reward allocation despite malicious attacks.\nFuture improvements include encoding the optimal contract\nitems into smart contracts for real-world system performance\nevaluation and prototyping an integrated on-chain and off-\nchain system demonstration.\nAcknowledgments\nWe thank Mr. Anandan Krishnasamy for running FL\nworkflow experiments over the hybrid cloud environment\nand validating the FL training results. This research was\nmade possible through partial funding from several Eu-\nropean Union projects: CLARIFY (860627), ENVRI-Hub\nNext (101131141), EVERSE (101129744), BlueCloud-2026\n(101094227), OSCARS (101129751), LifeWatch ERIC,\nBioDT (101057437, through LifeWatch ERIC), and Dutch\nNWO LTER-LIFE project.\nReferences\n[1] Rodolfo Stoffel Antunes, Cristiano André da Costa, Arne Küderle,\nImrana Abdullahi Yari, and Björn Eskofier.\nFederated learning\nfor healthcare: Systematic review and architecture proposal. ACM\nTransactions on Intelligent Systems and Technology (TIST), 13(4):1–\n23, 2022.\n[2] Guodong Long, Yue Tan, Jing Jiang, and Chengqi Zhang. Federated\nlearning for open banking.\nIn Federated learning: privacy and\nincentive, pages 240–254. Springer, 2020.\n[3] Dinh C Nguyen, Ming Ding, Pubudu N Pathirana, Aruna Seneviratne,\nJun Li, and H Vincent Poor. Federated learning for internet of things:\nA comprehensive survey. IEEE Communications Surveys & Tutorials,\n23(3):1622–1658, 2021.\n[4] Biwei Yan, Hongliang Zhang, Minghui Xu, Dongxiao Yu, and Xi-\nuzhen Cheng. Fedrfq: Prototype-based federated learning with re-\nduced redundancy, minimal failure, and enhanced quality.\nIEEE\nTransactions on Computers, 2024.\n[5] Pian Qi, Diletta Chiaro, Antonella Guzzo, Michele Ianni, Giancarlo\nFortino, and Francesco Piccialli. Model aggregation techniques in\nfederated learning: A comprehensive survey.\nFuture Generation\nComputer Systems, 2023.\n[6] Jiajun Wu, Fan Dong, Henry Leung, Zhuangdi Zhu, Jiayu Zhou, and\nSteve Drew. Topology-aware federated learning in edge computing: A\ncomprehensive survey. ACM Computing Surveys, 56(10):1–41, 2024.\n[7] Bo Xu, Wenchao Xia, Wanli Wen, Pei Liu, Haitao Zhao, and Hongbo\nZhu. Adaptive hierarchical federated learning over wireless networks.\nIEEE Transactions on Vehicular Technology, 71(2):2070–2083, 2021.\n[8] Lumin Liu, Jun Zhang, Shenghui Song, and Khaled B Letaief. Hier-\narchical federated learning with quantization: Convergence analysis\nand system design. IEEE Transactions on Wireless Communications,\n22(1):2–18, 2022.\n[9] Stefano Savazzi, Monica Nicoli, and Vittorio Rampa.\nFederated\nlearning with cooperating devices: A consensus approach for massive\niot networks. IEEE Internet of Things Journal, 7(5):4641–4654, 2020.\n[10] Yuan Liu, Zhengpeng Ai, Shuai Sun, Shuangfeng Zhang, Zelei Liu,\nand Han Yu. Fedcoin: A peer-to-peer payment system for federated\nlearning. In Federated learning: privacy and incentive, pages 125–\n138. Springer, 2020.\n[11] Nicola Rieke, Jonny Hancox, Wenqi Li, Fausto Milletari, Holger R\nRoth, Shadi Albarqouni, Spyridon Bakas, Mathieu N Galtier, Ben-\nnett A Landman, Klaus Maier-Hein, et al. The future of digital health\nwith federated learning. NPJ digital medicine, 3(1):1–7, 2020.\n[12] Jianchun Liu, Hongli Xu, Lun Wang, Yang Xu, Chen Qian, Jinyang\nHuang, and He Huang. Adaptive asynchronous federated learning in\nresource-constrained edge computing. IEEE Transactions on Mobile\nComputing, 22(2):674–690, 2021.\n[13] Minghui Xu, Zongrui Zou, Ye Cheng, Qin Hu, Dongxiao Yu, and\nXiuzhen Cheng.\nSpdl: A blockchain-enabled secure and privacy-\npreserving decentralized learning system.\nIEEE Transactions on\nComputers, 72(2):548–558, 2022.\n[14] Yufeng Zhan, Jie Zhang, Zicong Hong, Leijie Wu, Peng Li, and Song\nGuo. A survey of incentive mechanism design for federated learning.\nIEEE Transactions on Emerging Topics in Computing, 10(2):1035–\n1044, 2021.\n[15] Xuezhen Tu, Kun Zhu, Nguyen Cong Luong, Dusit Niyato, Yang\nZhang, and Juan Li. Incentive mechanisms for federated learning:\nFrom economic and game theoretic perspective. IEEE transactions\non cognitive communications and networking, 8(3):1566–1593, 2022.\n[16] Han Xu, Priyadarsi Nanda, and Jie Liang.\nReciprocal federated\nlearning framework: Balancing incentives for model and data owners.\nFuture Generation Computer Systems, 161:146–161, 2024.\n[17] Yann Fraboni, Richard Vidal, and Marco Lorenzi. Free-rider attacks\non model aggregation in federated learning. In International Con-\nference on Artificial Intelligence and Statistics, pages 1846–1854.\nPMLR, 2021.\n[18] Leon Witt, Mathis Heyer, Kentaroh Toyoda, Wojciech Samek, and\nDan Li. Decentral and incentivized federated learning frameworks: A\nsystematic literature review. IEEE Internet of Things Journal, 10(4):\n3642–3663, 2022.\n[19] Viraaji Mothukuri, Reza M Parizi, Seyedamin Pouriyeh, Yan Huang,\nAli Dehghantanha, and Gautam Srivastava. A survey on security and\nprivacy of federated learning. Future Generation Computer Systems,\n115:619–640, 2021.\n[20] Semo Yang, Jihwan Moon, Jinsoo Kim, Kwangkee Lee, and Kangy-\noon Lee. Flscalize: Federated learning lifecycle management plat-\nform. IEEE Access, 11:47212–47222, 2023.\n[21] Iacopo Colonnelli, Bruno Casella, Gianluca Mittone, Yasir Arfat,\nBarbara Cantalupo, Roberto Esposito, Alberto Riccardo Martinelli,\nDoriana Medić, and Marco Aldinucci. Federated learning meets hpc\nand cloud. In ML4Astro International Conference, pages 193–199.\nSpringer, 2022.\n[22] Peter Amstutz, Michael R. Crusoe, Nebojša Tijanić, Brad Chapman,\nJohn Chilton, Michael Heuer, et al.\nCommon workflow language,\nv1.0, 2016.\n[23] Chronis Kontomaris, Yuandou Wang, and Zhiming Zhao. Cwl-flops:\nA novel method for federated learning operations at scale. In 2023\nIEEE 19th International Conference on e-Science (e-Science), pages\n1–2. IEEE, 2023.\n[24] Harshit Daga, Jaemin Shin, Dhruv Garg, Ada Gavrilovska, Myungjin\nLee, and Ramana Rao Kompella.\nFlame: Simplifying topology\nextension in federated learning.\nIn Proceedings of the 2023 ACM\nSymposium on Cloud Computing, pages 341–357, 2023.\n[25] Wil MP van Der Aalst, Arthur HM Ter Hofstede, Bartek Kie-\npuszewski, and Alistair P Barros. Workflow patterns. Distributed\nand parallel databases, 14:5–51, 2003.\n[26] Sin Kit Lo, Qinghua Lu, Liming Zhu, Hye-Young Paik, Xiwei Xu, and\nChen Wang. Architectural patterns for the design of federated learning\nsystems. Journal of Systems and Software, 191:111357, 2022.\nYuandou Wang et al.: Preprint submitted to Elsevier\nPage 15 of 16\n\n\nManaging Federated Learning on Decentralized Infrastructures as a Reputation-based Collaborative Workflow\n[27] Qi Cheng and Guodong Long. Federated learning operations (flops):\nChallenges, lifecycle and approaches.\nIn 2022 International Con-\nference on Technologies and Applications of Artificial Intelligence\n(TAAI), pages 12–17. IEEE, 2022.\n[28] Christof Ebert, Gorka Gallardo, Josune Hernantes, and Nicolas Ser-\nrano. Devops. IEEE software, 33(3):94–100, 2016.\n[29] Dominik Kreuzberger, Niklas Kühl, and Sebastian Hirschl. Machine\nlearning operations (mlops): Overview, definition, and architecture.\nIEEE access, 11:31866–31879, 2023.\n[30] Rongfei Zeng, Chao Zeng, Xingwei Wang, Bo Li, and Xiaowen\nChu. A comprehensive survey of incentive mechanism for federated\nlearning. arXiv preprint arXiv:2106.15406, 2021.\n[31] Nika Haghtalab, Mingda Qiao, and Kunhe Yang. Platforms for effi-\ncient and incentive-aware collaboration. In Proceedings of the 2025\nAnnual ACM-SIAM Symposium on Discrete Algorithms (SODA),\npages 2607–2628. SIAM, 2025.\n[32] Zhilin Wang, Qin Hu, Ruinian Li, Minghui Xu, and Zehui Xiong. In-\ncentive mechanism design for joint resource allocation in blockchain-\nbased federated learning. IEEE Transactions on Parallel and Dis-\ntributed Systems, 34(5):1536–1547, 2023.\n[33] Liang Gao, Li Li, Yingwen Chen, ChengZhong Xu, and Ming Xu.\nFgfl: A blockchain-based fair incentive governor for federated learn-\ning. Journal of Parallel and Distributed Computing, 163:283–299,\n2022.\n[34] Jiawen Kang, Zehui Xiong, Dusit Niyato, Shengli Xie, and Junshan\nZhang. Incentive mechanism for reliable federated learning: A joint\noptimization approach to combining reputation and contract theory.\nIEEE Internet of Things Journal, 6(6):10700–10714, 2019.\n[35] Tailin Zhou, Zehong Lin, Jun Zhang, and Danny HK Tsang.\nUn-\nderstanding and improving model averaging in federated learning on\nheterogeneous data. IEEE Transactions on Mobile Computing, 2024.\n[36] Brendan McMahan, Eider Moore, Daniel Ramage, Seth Hampson,\nand Blaise Aguera y Arcas.\nCommunication-efficient learning of\ndeep networks from decentralized data. In Artificial intelligence and\nstatistics, pages 1273–1282. PMLR, 2017.\n[37] Zhiming Zhao, Spiros Koulouzis, Riccardo Bianchi, Siamak Farshidi,\nZeshun Shi, Ruyue Xin, Yuandou Wang, Na Li, Yifang Shi, Joris\nTimmermans, et al. Notebook-as-a-vre (naavre): From private note-\nbooks to a collaborative cloud virtual research environment. Software:\nPractice and Experience, 52(9):1947–1966, 2022.\n[38] Laëtitia Launet, Yuandou Wang, Adrián Colomer, Jorge Igual, Cris-\ntian Pulgarín-Ospina, Spiros Koulouzis, Riccardo Bianchi, Andrés\nMosquera-Zamudio, Carlos Monteagudo, Valery Naranjo, et al. Fed-\nerating medical deep learning models from private jupyter notebooks\nto distributed institutions. Applied Sciences, 13(2):919, 2023.\n[39] Yuandou Wang, Spiros Koulouzis, Riccardo Bianchi, Na Li, Yifang\nShi, Joris Timmermans, W Daniel Kissling, and Zhiming Zhao. Scal-\ning notebooks as re-configurable cloud workflows. Data Intelligence,\n4(2):409–425, 2022.\n[40] Daniel J Beutel, Taner Topal, Akhil Mathur, Xinchi Qiu, Titouan\nParcollet, Pedro PB de Gusmão, and Nicholas D Lane.\nFlower:\nA friendly federated learning research framework.\narXiv preprint\narXiv:2007.14390, 2020.\n[41] Heiko Ludwig, Nathalie Baracaldo, Gegi Thomas, Yi Zhou, Ali An-\nwar, Shashank Rajamoni, Yuya Ong, Jayaram Radhakrishnan, Ashish\nVerma, Mathieu Sinn, et al. Ibm federated learning: an enterprise\nframework white paper v0. 1. arXiv preprint arXiv:2007.10987, 2020.\n[42] G Anthony Reina, Alexey Gruzdev, Patrick Foley, Olga Perepelkina,\nMansi Sharma, Igor Davidyuk, Ilya Trushkin, Maksim Radionov,\nAleksandr Mokrov, Dmitry Agapov, et al. Openfl: An open-source\nframework for federated learning. arXiv preprint arXiv:2105.06413,\n2021.\n[43] Alexander Ziller, Andrew Trask, Antonio Lopardo, Benjamin\nSzymkow, Bobby Wagner, Emma Bluemke, Jean-Mickael Nouna-\nhon, Jonathan Passerat-Palmbach, Kritika Prakash, Nick Rose, et al.\nPysyft: A library for easy federated learning.\nFederated Learning\nSystems: Towards Next-Generation AI, pages 111–139, 2021.\n[44] Kasun Indrasiri and Danesh Kuruppu.\ngRPC: up and running:\nbuilding cloud native applications with Go and Java for Docker and\nKubernetes. O’Reilly Media, 2020.\n[45] Anandan Krishnasamy, Yuandou Wang, and Zhiming Zhao. A col-\nlaborative framework for facilitating federated learning among jupyter\nusers. In 2024 IEEE 20th International Conference on e-Science (e-\nScience), pages 1–2. IEEE, 2024.\n[46] Shaoxiong Ji. A pytorch implementation of federated learning, March\n2018. URL https://doi.org/10.5281/zenodo.4321561.\n[47] Carole Goble, Sarah Cohen-Boulakia, Stian Soiland-Reyes, Daniel\nGarijo, Yolanda Gil, Michael R Crusoe, Kristian Peters, and Daniel\nSchober. Fair computational workflows. Data Intelligence, 2(1-2):\n108–121, 2020.\n[48] Yuandou Wang, Sheejan Tripathi, Siamak Farshidi, and Zhiming\nZhao. D-vre: From a jupyter-enabled private research environment\nto decentralized collaborative research ecosystem. Blockchain: Re-\nsearch and Applications, page 100244, 2024.\n[49] Huong Nguyen, Hong-Tri Nguyen, Lauri Lovén, and Susanna Pirt-\ntikangas. Stake-driven rewards and log-based free rider detection in\nfederated learning. In 2024 21st Annual International Conference on\nPrivacy, Security and Trust (PST), pages 1–10. IEEE, 2024.\n[50] Shuai Wang, Wenwen Ding, Juanjuan Li, Yong Yuan, Liwei Ouyang,\nand Fei-Yue Wang. Decentralized autonomous organizations: Con-\ncept, model, and applications. IEEE Transactions on Computational\nSocial Systems, 6(5):870–878, 2019.\n[51] Ningning Ding, Zhixuan Fang, and Jianwei Huang. Optimal contract\ndesign for efficient federated learning with multi-dimensional private\ninformation. IEEE Journal on Selected Areas in Communications, 39\n(1):186–200, 2020.\n[52] Zehui Xiong, Wei Yang Bryan Lim, Jiawen Kang, Dusit Niyato, Ping\nWang, and Chunyan Miao. Incentive mechanism design for mobile\ndata rewards using multi-dimensional contract. In 2020 IEEE Wire-\nless Communications and Networking Conference (WCNC), pages 1–\n6. IEEE, 2020.\n[53] Jerzy Neyman.\nOn the two different aspects of the representative\nmethod: the method of stratified sampling and the method of pur-\nposive selection. In Breakthroughs in statistics: Methodology and\ndistribution, pages 123–150. Springer, 1992.\n[54] Anders Hald. The compound hypergeometric distribution and a sys-\ntem of single sampling inspection plans based on prior distributions\nand costs. Technometrics, 2(3):275–340, 1960.\n[55] Rajendra K Jain, Dah-Ming W Chiu, William R Hawe, et al.\nA\nquantitative measure of fairness and discrimination.\nEastern Re-\nsearch Laboratory, Digital Equipment Corporation, Hudson, MA, 21:\n1, 1984.\n[56] Peter I Frazier. A tutorial on bayesian optimization. arXiv preprint\narXiv:1807.02811, 2018.\n[57] Leslie Pack Kaelbling, Michael L Littman, and Andrew W Moore.\nReinforcement learning: A survey. Journal of artificial intelligence\nresearch, 4:237–285, 1996.\n[58] Robert Dorfman. A formula for the gini coefficient. The review of\neconomics and statistics, pages 146–149, 1979.\nYuandou Wang et al.: Preprint submitted to Elsevier\nPage 16 of 16\n\n\n",
  "metadata": {
    "source_file": "dataset/pdfs/arxiv_2502.20882v1.pdf",
    "total_pages": 16,
    "title": "Managing Federated Learning on Decentralized Infrastructures as a Reputation-based Collaborative Workflow",
    "authors": [
      "Yuandou Wang",
      "Zhiming Zhao"
    ],
    "abstract": "Federated Learning (FL) has recently emerged as a collaborative learning\nparadigm that can train a global model among distributed participants without\nraw data exchange to satisfy varying requirements. However, there remain\nseveral challenges in managing FL in a decentralized environment, where\npotential candidates exhibit varying motivation levels and reliability in the\nFL process management: 1) reconfiguring and automating diverse FL workflows are\nchallenging, 2) difficulty in incentivizing potential candidates with\nhigh-quality data and high-performance computing to join the FL, and 3)\ndifficulty in ensuring reliable system operations, which may be vulnerable to\nvarious malicious attacks from FL participants. To address these challenges, we\nfocus on the workflow-based methods to automate diverse FL pipelines and\npropose a novel approach to facilitate reliable FL system operations with\nrobust mechanism design and blockchain technology by considering a contribution\nmodel, fair committee selection, dynamic reputation updates, reward and penalty\nmethods, and contract theory. Moreover, we study the optimality of contracts to\nguide the design and implementation of smart contracts that can be deployed in\nblockchain networks. We perform theoretical analysis and conduct extensive\nsimulation experiments to validate the proposed approach. The results show that\nour incentive mechanisms are feasible and can achieve fairness in reward\nallocation in unreliable environment settings.",
    "published_date": "2025-02-28",
    "source": "arxiv"
  }
}