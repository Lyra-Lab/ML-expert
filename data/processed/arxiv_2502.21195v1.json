{
  "id": "arxiv_2502.21195v1",
  "text": "Joint Modeling in Recommendations: A Survey\nXiangyu Zhao1, Yichao Wang2, Bo Chen2, Jingtong Gao1, Yuhao Wang1\nXiaopeng Li1, Pengyue Jia1, Qidong Liu1,3, Huifeng Guo2, Ruiming Tang2\n1City University of Hong Kong, 2Huawei Noah’s Ark Lab, 3Xi’an Jiaotong University\nxianzhao@cityu.edu.hk,{jt.g,yhwang25-c,xiaopli2-c,jia.pengyue}@my.cityu.edu.hk\nliuqidong@stu.xjtu.edu.cn,{wangyichao5,chenbo116,huifeng.guo,tangruiming}@huawei.com\nABSTRACT\nIn today’s digital landscape, Deep Recommender Systems (DRS)\nplay a crucial role in navigating and customizing online content\nfor individual preferences. However, conventional methods, which\nmainly depend on single recommendation task, scenario, data modal-\nity and user behavior, are increasingly seen as insufficient due to\ntheir inability to accurately reflect users’ complex and changing\npreferences. This gap underscores the need for joint modeling ap-\nproaches, which are central to overcoming these limitations by in-\ntegrating diverse tasks, scenarios, modalities, and behaviors in the\nrecommendation process, thus promising significant enhancements\nin recommendation precision, efficiency, and customization. In this\npaper, we comprehensively survey the joint modeling methods in\nrecommendations. We begin by defining the scope of joint modeling\nthrough four distinct dimensions: multi-task, multi-scenario, multi-\nmodal, and multi-behavior modeling. Subsequently, we examine\nthese methods in depth, identifying and summarizing their under-\nlying paradigms based on the latest advancements and potential\nresearch trajectories. Ultimately, we highlight several promising av-\nenues for future exploration in joint modeling for recommendations\nand provide a concise conclusion to our findings.\nACM Reference Format:\nXiangyu Zhao1, Yichao Wang2, Bo Chen2, Jingtong Gao1, Yuhao Wang1\nand Xiaopeng Li1, Pengyue Jia1, Qidong Liu1,3, Huifeng Guo2, Ruiming\nTang2. 2025. Joint Modeling in Recommendations: A Survey. In Proceedings\nof ACM Conference (Conference’17). ACM, New York, NY, USA, 12 pages.\nhttps://doi.org/10.1145/nnnnnnn.nnnnnnn\n1\nINTRODUCTION\nIn the modern digital ecosystem, the exponential growth of online\ncontent has precipitated a significant challenge for users: Infor-\nmation overload [2]. This predicament has catalyzed the develop-\nment and widespread adoption of Deep Recommender Systems\n(DRSs) [6, 161], which have become foundational to various online\nplatforms, providing tailored content suggestions to streamline user\nexperiences. The traditional DRS models follow the simple input-\noutput deep learning framework, starting from the processing of\ninput data, going through the embedding table of dimensionality re-\nduction, participating in feature interaction, and finally generating\nPermission to make digital or hard copies of all or part of this work for personal or\nclassroom use is granted without fee provided that copies are not made or distributed\nfor profit or commercial advantage and that copies bear this notice and the full citation\non the first page. Copyrights for components of this work owned by others than the\nauthor(s) must be honored. Abstracting with credit is permitted. To copy otherwise, or\nrepublish, to post on servers or to redistribute to lists, requires prior specific permission\nand/or a fee. Request permissions from permissions@acm.org.\nConference’17, July 2017, Washington, DC, USA\n© 2025 Copyright held by the owner/author(s). Publication rights licensed to ACM.\nACM ISBN 978-1-4503-XXXX-X/18/06\nhttps://doi.org/10.1145/nnnnnnn.nnnnnnn\nthe recommendation results. This sequence has proven to be effec-\ntive in mitigating the challenges posed by the vast seas of digital\ninformation, thereby personalizing the digital landscape for users\naccording to their preferences and historical interactions [23, 140].\nDespite the notable successes of traditional DRSs, they are not\ndevoid of shortcomings. Primarily, these systems are character-\nized by a single-task orientation [97] that narrows the horizon of\ninformation extraction. Furthermore, the approach focusing on\nsingle-scenario [113, 173] overlooks the synergy between differ-\nent scenarios and also leads to excessive resource consumption\nas it maintains a specific model for each scenario. Another sig-\nnificant limitation is their reliance on ID-based (single modality)\nfeatures, which restricts the scope of information that can be ex-\ntracted from data samples [119]. Last but not least, the lack of a\ncomprehensive strategy for understanding complex relationships\nthrough user behaviors hinders the system’s ability to provide nu-\nanced and context-sensitive recommendations [149].\nIn response to these limitations, the concept of joint modeling has\nbeen introduced and is gaining momentum as a powerful enhance-\nment of the traditional DRS frameworks. This innovative approach,\nwhich encompasses multi-task [97, 103], multi-scenario [94, 148],\nmulti-modal [15, 121], and multi-behavior [45, 131] strategies, aims\nto transcend the conventional boundaries of recommender systems.\nJoint modeling endeavors to leverage a broader spectrum of data\nmodalities and user behaviors, implement more sophisticated mod-\neling techniques, and streamline the deployment process across\ndiverse scenarios and tasks. This approach is designed to facili-\ntate the delivery of more accurate, personalized, and contextually\nappropriate recommendations, thereby improving user experience.\nSpecifically, joint modeling in the recommender systems mainly\nincludes the following dimensions.\n• Multi-task Modeling: The multi-task recommendation para-\ndigm within joint modeling seeks to amalgamate and exploit\nsynergies between different recommendation tasks, thereby en-\nhancing overall efficiency and output quality. Generally, the ad-\nvantage of multi-task lies in good generalization or robustness.\n• Multi-scenario Modeling: The multi-scenario recommenda-\ntion framework aims to harness the rich diversity of data across\nvarious user interactions, unifying disparate scenario-specific\nmodels to improve system adaptability and robustness. Generally,\nmulti-scenario resolved the sparsity and improved the efficiency.\n• Multi-modal Modeling: Multi-modal recommender systems\nstrive to incorporate an array of data types–including textual,\nvisual, and auditory information–to construct a more compre-\nhensive and nuanced understanding of user preferences.\n• Multi-behavior Modeling: These recommendation strategies\noffer a more granular analysis of user behaviors. This enables the\narXiv:2502.21195v1  [cs.IR]  28 Feb 2025\n\n\nConference’17, July 2017, Washington, DC, USA\nXiangyu Zhao, et al.\nMulti-Scenario\nMulti-Task\n…\nTask/scenario adaption\nRepresentation  extraction\nMulti-Behavior\n…\nMulti-Modal\n𝑤𝐿(𝑬𝑀𝑒𝑟𝑔𝑒, 𝜽𝑠ℎ, 𝜽𝑡, 𝜽𝑠)\n𝑬𝑀𝑒𝑟𝑔𝑒= 𝑈(𝑬, 𝑬𝐵, 𝑬𝑀)\n𝑤𝐿(𝑬𝑀er𝑔𝑒, 𝜽𝑠ℎ, 𝜽𝑡, 𝜽𝑠)\nMulti-scenario\n𝑤𝐿(𝑬𝑀𝑒𝑟𝑔𝑒, 𝜽𝑠ℎ, 𝜽𝑡, 𝜽𝑠)\nMulti-task\nJoint Modeling\n𝑬𝑀= 𝑀(𝑬𝑡𝑥𝑡, 𝑬𝑣, … , 𝑬𝑝)\nMulti-modal\n𝑬𝐵= 𝐺(𝑯1, 𝑯2, … , 𝑯𝑁)\nMulti-behavior\nFigure 1: Joint modeling in recommendations.\ncapturing of intricate user interaction patterns, thereby paving\nthe way for a new generation of recommender systems capable\nof delivering unparalleled personalization and relevance.\nThe overall goal of this study is to thoroughly explore and explain\nthe growing field of joint modeling in recommender systems. This\nwork aims to understand the complex details, review the latest\nmethods, and highlight the ongoing issues and new opportunities\nfor further research. Initially, the paper outlines the basic problem\nformulation of traditional recommender systems and joint modeling\napproaches. Then, it goes on to examine each dimension of joint\nmodeling in detail, clarifying its importance, taxonomy, and current\nresearch priorities. Later, the study looks at possible directions for\nthe future of joint modeling. Finally, this paper summarizes the\nrole of joint modeling in improving recommender systems and\nstresses the need for further innovation in this area, presenting it as\ncrucial for the advancement of these systems. By doing so, this study\nseeks to chart a course for the evolution of recommender systems,\nguiding the incorporation of joint modeling techniques to foster\nthe development of more sophisticated and effective platforms.\n2\nPROBLEM FORMULATION\nConsidering a recommender system modeled by a function 𝑓(·), de-\npending on a single recommendation task and scenario, single data\nmodality, or single user behavior, aiming to optimize the model\nparameters 𝜽through a specified loss function 𝐿(𝜽). Diverging\nfrom this, the joint modeling approach facilitates refined analyses\nacross multiple dimensions, including multi-task, multi-scenario,\nmulti-modal, and multi-behavior modeling, as depicted in Figure 1.\nSpecifically, in the joint modeling frameworks, multi-behavior\nand multi-modal modeling could be applied to encode user be-\nhavior sequences and multi-modal data into dense representations:\n𝑬𝐵=𝐺(𝑯1, 𝑯2, . . . , 𝑯𝑁) ,\n𝑬𝑀=𝑀\u0000𝑬𝑡𝑥𝑡𝑬𝑣, . . . , 𝑬𝑝\u0001\n(1)\nwhere 𝐸𝐵is the behavior representation learned from the user\nbehavior sequence (𝑯1, 𝑯2, . . . , 𝑯𝑁) with 𝑁behaviors and 𝑬𝑀is\nthe modality representation learned from different modality input\n\u0000𝑬𝑡𝑥𝑡, 𝑬𝑣, . . . , 𝑬𝑝\u0001 with 𝑡𝑥𝑡for text modality, 𝑣for visual modality\nand 𝑝for other possible modality. By aggregating the original ID-\nbased representation 𝑬and the generated 𝑬𝐵and 𝑬𝑀, 𝑬𝑀𝑒𝑟𝑔𝑒can\naggregate more useful structured information for model learning,\nand it is thus treated as the final representation of input informa-\ntion for further modeling. Additionally, the multi-task modeling\nparadigm could be applied to learn 𝐾task relations via\n𝐿𝑜𝑠𝑠=\n𝐾\n∑︁\n𝑘=1\n𝑤𝑘𝐿𝑘\u0010\n𝑬𝑀𝑒𝑟𝑔𝑒, 𝜽𝑠ℎ, 𝜽𝑘\u0011\n(2)\nand multi-scenario can learn scenario relations between 𝑆scenar-\nios via\n𝐿𝑜𝑠𝑠=\n𝑆\n∑︁\n𝑠=1\n𝑤𝑠𝐿𝑠\u0010\n𝑬𝑀𝑒𝑟𝑔𝑒, 𝜽𝒔𝒉, 𝜽𝑠\u0011\n(3)\nBy dividing parameters for shared structure modeling (𝜽𝑠ℎ),\nmulti-task modeling (𝜽𝑘), and multi-scenario modeling (𝜽𝑠), the\nDRS is capable of handling multiple tasks and scenarios simulta-\nneously and further enhancing its performance. The overall loss\nfunction could be a weighted combination:\n𝐿𝑜𝑠𝑠=\n𝐼∑︁\n𝑖=1\n𝑤𝑖𝐿𝑖\u0010\n𝑬𝑀𝑒𝑟𝑔𝑒, 𝜽𝑠ℎ, 𝜽𝑘, 𝜽𝑠\u0011\n(4)\nwhere 𝑤𝑖is the weight for the 𝑖-th loss funtion and 𝐼= 𝐾+ 𝑆.\n3\nMULTI-TASK RECOMMENDATION\nIn practice, industrial recommender systems should be endowed\nwith the capability to conduct various recommendation tasks si-\nmultaneously so as to cater to multiple and diverse demands of\nusers and make profits. Consequently, Multi-task Recommendation\n(MTR) arises because it offers two main benefits. On the one hand,\nit can achieve mutual enhancement among the tasks by exploit-\ning data and knowledge across multiple tasks. On the other hand,\nA higher efficiency of computation and storage can be obtained.\nSpecifically, for example, the score prediction task aims to predict\nthe likelihood of a user performing an action, such as click-through\n\n\nJoint Modeling in Recommendations: A Survey\nConference’17, July 2017, Washington, DC, USA\nFigure 2: Overview of three task relations: parallel, cascaded,\nand auxiliary with main in multi-task recommendation.\nrate (CTR) prediction, and the generation task focuses on providing\nexplanations for recommendations.\nThe objective is to learn the MTL model with task-specific param-\neters {𝜽1, ..., 𝜽𝐾} and shared parameter 𝜽𝑠ℎ, which outputs the 𝐾\ntask-wise predictions by extracting the hidden pattern of user-item\nfeature interactions. The loss function for multi-task training is\ncommonly defined as a weighted sum of losses and can be written\nas the following optimization problem:\narg min\n{𝜽1,...,𝜽𝐾}\nL(𝑬𝑀𝑒𝑟𝑔𝑒, 𝜽𝑠ℎ, 𝜽1, · · · , 𝜽𝐾)\n= arg min\n{𝜽1,...,𝜽𝐾}\n𝐾\n∑︁\n𝑘=1\n𝑤𝑘𝐿𝑘(𝑬𝑀𝑒𝑟𝑔𝑒, 𝜽𝑠ℎ, 𝜽𝑘)\n(5)\nwhere 𝐿𝑘(𝜽𝑠ℎ, 𝜽𝑘) is the loss function for the 𝑘-th task with param-\neter 𝜽𝑠ℎ, 𝜽𝑘, and 𝑤𝑘is the loss weight for the 𝑘-th task.\n3.1\nTask Relation\nSpecifically, considering the relationship among tasks, multi-task\nrecommendations can be categorized into three groups: parallel,\ncascaded, and auxiliary with main tasks as shown in Figure 2.\n3.1.1\nParallel. A parallel task relation indicates that various tasks\nare independently calculated without the sequential dependency of\ntheir results. The objective function of parallel task relation in multi-\ntask recommendation is usually defined as the weighted sum of\nlosses with constant loss weights. Existing methods under parallel\ntask relation can be grouped by their target and challenge.\nAs for the target, RnR [35] merges the ranking and rating predic-\ntion tasks along with a two-phase decision process for personalized\nrecommendation in video recommendation. Additionally, MTER\n[105] and CAML [21] focus on recommendation and explanation\ntasks. Besides, DINOP [137] is proposed specifically for e-commerce\nonline promotions by considering multiple sales prediction tasks.\nMeanwhile, several works try to tackle the challenge of feature\nselection and sharing among parallel tasks, since a static sharing\nstrategy may fail to capture the complex task relevance. Existing\nstudies mainly adopt attention mechanisms. DUPN [85] integrates\nmulti-task learning, attention along with RNNs to extract general\nfeatures that will be shared among the associated tasks. MRAN [166]\nproposes to use an attention mechanism for feature interaction and\ntask-feature alignment. RevMan [59] uses an attentive adaptive\nfeature sharing mechanism for different tasks. MSSM [27] applies a\nfeature-field sparse mask within the input layer and the connection\ncontrol between a set of more fine cells in sub-networks of multiple\nlayers. Recently, CFS-MTL [22] proposes to select the stable causal\nfeatures via pseudo-intervention from a causal view.\n3.1.2\nCascaded. A cascaded task relationship refers to the sequen-\ntial dependency between tasks. In other words, the computation of\nthe current task depends on the previous ones, e.g., CTCVR derived\nby multiplying CTR and CVR. It can be considered as a general\nMTL problem with the assumption on the prediction scores for\neach specific task 𝑘:\nˆ𝑦𝑘\n𝑛(𝜽𝑠ℎ, 𝜽𝑘) −ˆ𝑦𝑘−1\n𝑛\n(𝜽𝑠ℎ, 𝜽𝑘) = 𝑃(𝜖𝑘= 0,𝜖𝑘−1 = 1)\n(6)\nwhere𝜖𝑘is the indicator variable for task𝑘. This assumption implies\nthe difference between ˆ𝑦𝑘𝑛(𝜽𝑠ℎ, 𝜽𝑘) and ˆ𝑦𝑘−1\n𝑛\nis the probability of\nthe task 𝑘not happening while the task 𝑘−1 is observed. Besides,\nthe formulation above is equivalent to the sequential dependence\nMTL (SDMTL) which was raised in [98].\nThe methods under the cascaded task relation setting [46, 78, 98,\n102, 115, 122, 123, 126, 127, 162, 174] basically aim at CVR predic-\ntion task on e-commerce, except AITM [127] and APEM [98] are\nproposed for advertising and financial service, respectively. Mean-\nwhile, they mainly target at tackling sample selection bias (SSB)\nand data sparsity (DS) issues caused by sparse training data of con-\nversion. Besides, their assumed sequential patterns are based on\n“impression →click →conversion” and its extension following\nthe setting and framework of ESMM [78], which adopts shared\nembedding and models over the entire space.\n3.1.3\nAuxiliary with Main Task. Auxiliary with main task refers\nto the circumstance that a task is specified as the main task while\nothers, i.e., associated auxiliary tasks help to improve its perfor-\nmance. The probability estimation for the main task is calculated\nbased on the probability of auxiliary tasks, which is estimated on\nthe entire space with richer information.\nOn the one hand, some works simply adopt the original rec-\nommendation tasks as auxiliaries [39, 115, 162, 168]. Specifically,\nMulti-IPW and Multi-DR [162] introduce an auxiliary CTR task\nwith the main CVR and imputation task. ESDF [115] treats CTR\nand CTCVR as auxiliaries of time delay tasks. DMTL [168] models\nCTR as an auxiliary of duration task.\nOn the other hand, some works design various auxiliary tasks\nunder specific settings [53, 62, 144, 147]. Specifically, MTRec [53]\ntakes link prediction for network dynamic modeling as an auxiliary\nof the recommendation task. PICO [62] considers task relevance\nbetween CTR and CVR as an auxiliary. MTAE [147] predicts the\nwinning probability as an auxiliary. Cross-Distill [144] proposes a\nranking-based task as an auxiliary containing cross-task relation.\nSpecially, CSRec [4] and PICO [62] adopt contrastive learning as\nthe auxiliary task to extract task relevance better.\nNevertheless, the frameworks above are manually-auxiliary, since\nthe design of auxiliary tasks usually requires specific domain knowl-\nedge. Recently, Wang et al. [116] propose under-parameterized\nself-auxiliaries to achieve better generalization.\n3.2\nOptimization\nFrom the optimization aspect, the joint optimization of different\ntasks needs to tackle two issues in MTL: (i) the conflict across the\nperformance of multiple tasks, e.g., accuracy, and (ii) the trade-off\nbetween objectives in each task. The former is related to negative\ntransfer, while the latter corresponds to a multi-objective trade-off.\n\n\nConference’17, July 2017, Washington, DC, USA\nXiangyu Zhao, et al.\n3.2.1\nNegative Transfer. Negative transfer is a situation in which\ntransferring unrelated information among tasks could result in\nperformance degradation and a seesaw phenomenon. When the\nperformance of some tasks is improved but at the cost of others’\nresults, the seesaw phenomenon is observed. Since most of the\nexisting methods seek better recommendation accuracy, they focus\non this problem. Specifically, there are mainly two reasons causing\nnegative transfer in MTR from the shared parameters 𝜽. The first\nis gradient dominating and the second is parameter conflict.\nGradient dominating denotes the magnitude imbalance of gradi-\nent ∥∇𝜽𝐿𝑘(𝜽)∥of different tasks, and some works try to tackle this\nproblem [20, 154]. In the recommendation community, AdaTask\n[145] proposes quantifying task dominance of shared parameters\nand calculating task-specific accumulative gradients for adaptive\nlearning rate methods. MetaBalance [39] proposes to flexibly bal-\nance the gradient magnitude proximity between auxiliary and tar-\nget tasks by a relax factor.\nBesides, parameter conflict indicates that the shared parameter 𝜽\nhas opposite directions of gradient ∇𝜽𝐿𝑘(𝜽) in different tasks. PLE\n[97] discusses the seesaw phenomenon and proposes Customized\nGate Control (CGC) that separates shared and task-specific experts\nto explicitly alleviate parameter conflicts. CSRec [4] applies an al-\nternating training procedure and contrastive learning on parameter\nmasks to reduce the conflict probability.\n3.2.2\nMulti-objective Trade-off. The trade-off among objectives\nunder the MTR setting is a new topic. Specifically, the correspond-\ning objectives in each task are usually optimized by a single model\nregardless of the potential conflict. Some study the trade-off be-\ntween group fairness and accuracy across multiple tasks [114] and\nafterward, the trade-off between minimizing task conflicts and im-\nproving multi-task generalization in a higher level [116].\n3.3\nTraining Mechanism\nTraining mechanism refers to the specific training process and\nlearning strategy of different tasks in the MTR model. Existing\nworks on MTR can be grouped into joint training, reinforcement\nlearning, and auxiliary task learning.\n3.3.1\nJoint Training. Most MTL models adopt joint training among\ntasks in a parallel manner, and the majority of the above-mentioned\nMTR models belong to this category. Specially, some works simply\njointly learn different tasks, such as session-based RS [82, 91, 93],\nroute RS [26], knowledge graph enhanced RS [103], explainability\n[75, 105], and graph-based RS [104]. Besides, some works adopt an\nalternating training procedure, e.g., contrastive pruning [4].\n3.3.2\nReinforcement Learning. Reinforcement Learning (RL)\nalgorithms have recently been applied in DRS, which models the\nsequential user behaviors as Markov Decision Process (MDP) and\nutilizes RL to generate recommendations at each decision step [80].\nBy setting user-item features as state and continuous score pairs for\nmultiple tasks as actions, the RL-based MTL method is capable of\nhandling the sequential user-item interaction and optimizing long-\nterm user engagement. Zhang et al. [160] formulate MTF as MDP\nand use batch RL to optimize long-term user satisfaction. Han et al.\n[36] use an actor-critic model to learn the optimal fusion weight of\nCTR and the bid rather than adopting greedy ranking strategies to\nmaximize the long-term revenue. Liu et al. [74] use dynamic critic\nnetworks to adaptively adjust the fusion weight considering the\nsession-wise property.\n3.3.3\nAuxiliary Task Learning. As discussed in Section 3.1.3,\nadding auxiliary tasks aims at helping to enhance the performance\nof primary tasks. Specifically, the auxiliary tasks are usually trained\nalong with the primary tasks in a joint training manner. By contrast,\nESDF [115] employs Expectation-Maximization (EM) algorithm for\noptimization. Besides, self-auxiliaries are trained with task-specific\nsub-networks while they are discarded in the inference stage.\n4\nMULTI-SCENARIO RECOMMENDATION\nIndustrial recommender systems are often required to cater to di-\nverse business needs, such as providing personalized recommenda-\ntions on the homepage and expanding user interests on the detail\npage. Data from different scenarios share commonalities and diversi-\nties. For the commonality, there is an intersection of users and items\nacross different scenarios, resulting in similar data distribution. For\nthe diversities, users behave distinctly when facing different scenar-\nios, which causes diverse data distribution. Traditional approaches\ntypically follow two main strategies. 1) Training separate models\nfor each individual scenario. This method significantly increases\nthe costs of model training and maintenance and also overlooks\nthe commonalities across different scenarios. 2) Simply using all\nthe data from various scenarios to train a unified model. However,\nthis approach fails to consider the differences between scenarios,\nresulting in subpar performance.\nIn light of this context, the concept of Multi-Scenario Recom-\nmendation (MSR) has been introduced. It aims to enhance the rec-\nommendation performance for multiple scenarios simultaneously\nby utilizing a unified model that can effectively capture the com-\nmonalities and diversities across different scenarios. As shown in\nFigure 3, there are mainly three categories of modeling methods\nin multi-scenario recommendations: hard-sharing modeling, soft-\nsharing modeling, and dynamic weight paradigm. We will detail\nthese three categories in the following subsections.\nThe objective of MSR can be formalized as follows:\narg min\n𝑆\n∑︁\n𝑠=1\n𝒘𝑠𝐿𝑠(𝑬𝑀𝑒𝑟𝑔𝑒, 𝜽𝑠ℎ, 𝜽𝑠)\n(7)\nwhere 𝜽𝑠denotes the parameters for each scenario and 𝜽𝑠ℎis the\nshared parameters across different scenarios. 𝐿𝑠is the loss function\nfor 𝑠-th scenario,𝒘𝑠is the weights of different loss for 𝑠-th scenario,\nand 𝑬𝑀𝑒𝑟𝑔𝑒denotes the merge of all input and generated feature\nrepresentations. In multi-scenario recommendations, 𝒘𝑠usually is\n1, and 𝐿𝑠usually keeps the same across scenarios.\n4.1\nHard-sharing Modeling\nHard-sharing is a modeling paradigm that was initially proposed\nin the context of MSR. It primarily focuses on controlling the inde-\npendence and sharing of network structures or parameters across\ndifferent scenarios to capture the differences and commonalities\nbetween them. STAR [94] is the first paper to propose the hard-\nsharing method in MSR. It presents a star topology structure, where\nall data can be transmitted through a shared network. In contrast,\n\n\nJoint Modeling in Recommendations: A Survey\nConference’17, July 2017, Washington, DC, USA\nShared\nNetwork\nSpecific\nNetwork for\nSenario 1\nFusion\n...\nBackbone\nModel\n...\nDynamic\nWeight\nGenerator\nWeight\nBias\nShared Bottom\nShared Bottom\nShared Bottom\nExpert\nExpert\nExpert\n...\nGate\nInputs\nOutputs\nScenario Sensitive Features\nHard-Sharing\nSoft-Sharing\nDynamic Weight\nFigure 3: Overview of three categories of multi-scenario modeling methods in recommender systems.\nspecific networks for each scenario only allow data belonging to\nthat particular scenario to pass through. ADI [44] proposes a do-\nmain interest adaptation layer to weigh features adaptively and\nthe domain-specific and shared networks to capture the common-\nalities and diversities across scenarios. AdaptDHM [54] follows\nthe paradigm and introduces a distribution adaptation module to\ndetermine the cluster of instances. Then, the relationships between\nclusters are captured by the multi-distribution network. MMN [88]\nuses independent weight matrices to model the differences between\nnetwork designs in different scenarios. Additionally, a unified base\nparameter is used to model the common characteristics between\ndifferent scenarios. In addition, EDAA [86] and Adasparse [148]\nmodel the commonalities and diversities between scenarios from\nthe perspectives of embedding and pruner, where the embeddings\nand pruners are isolated across different scenarios.\nHard-sharing in MSR models decouples the commonalities and\ndiversities between scenarios. By controlling the independence\nand sharing of network structures or parameters across different\nscenarios, it effectively models the diversities and commonalities\nbetween these scenarios. This groundbreaking approach has signif-\nicantly advanced the field of multi-scenario modeling, allowing for\na more nuanced understanding of the dynamics between different\ncontexts. Its innovative contribution has paved the way for further\ndevelopments in this area.\n4.2\nSoft-sharing Modeling\nUnlike hard-sharing, which directly shares model structures or\nparameters among scenarios, soft-sharing models employ an im-\nplicit method, where inter-scenario information is shared through\nauxiliary models such as cells, layers, or methodologies, including\nembeddings and loss functions et al. Consequently, we categorize\nthe current methods into two categories: soft-module methods\nand soft-strategies methods. (1). Soft-module methods, involv-\ning leveraging expert networks that construct scenario-specific\nand scenario-shared experts alongside dynamic routing to inte-\ngrate information seamlessly. For example, AESM2 [175] intro-\nduces an innovative expert selection algorithm to automatically\nidentify scenario-specific and scenario-shared experts for the input.\nMARIA [101] employs a Mixture of Experts (MoE) structure with a\nscenario-shared tower for final predictions, while HiNet [170] im-\nplements Sub-Experts Integration (SEI) modules to model scenario-\nrelated information, drawing inspiration from MoE. Additionally,\nSAMD [41] utilizes a meta-network to establish inter-scenario re-\nlations, and MAGRec [3] introduces a domain contextualization\nmodel that leverages a dense Transformer layer to extract domain\nrepresentations. (2). Soft-strategies methods, focus on deploy-\ning various soft strategies to address challenges across scenarios.\nFrom the perspective of embedding, EDDA [87] introduces Em-\nbedding Disentangling (ED), which segregates inter- and intra-\nscenario information into distinct embeddings for each item or\nuser. MAMDR [76] proposes Domain Negotiation (DN) to mitigate\ndomain conflict problems using different gradients, and Domain\nRegularization (DR) to optimize domain-specific parameters.\n4.3\nDynamic Weight Paradigm\nDynamic weight generation, a method that dynamically generates\nweight matrices or parameters for models, has recently gained\nsignificant attention for its ability to adapt models to various do-\nmains efficiently. For instance, PEPNet [11], developed by Kuaishou,\nleverages EPNet to map input domain features through a Gate\nNeural Unit (GateNU) to produce domain-specific weights. Sim-\nilarly, M2M [159] focuses on generating weight parameters tai-\nlored to meta units embedded with scenario-specific knowledge.\nHAMUR [58] introduces domain-specific weights for adapters plugged\ninto the backbone network, enabling efficient adaptation in various\ndomains. Meanwhile, MI-DPG [24] generates scenario-conditioned\nweight matrices via a shallow neural network, which are then de-\ncomposed into multiple low-rank matrices to enhance robustness.\n4.4\nMulti-scenario Multi-task modeling\nMulti-scenario Multi-task modeling, which integrates perspectives\nfrom both Multi-task and Multi-scenario frameworks, aims to achieve\noptimal performance across various tasks in different scenarios. For\ninstance, M2M [159] incorporates meta-cells that encode scenario\ninformation and introduces a meta-attention module to model inter-\nscenario correlations across two distinct tasks. Similarly, HiNet [170]\naddresses Multi-scenario Multi-task modeling through hierarchical\nmodels that extract correlations both inter-domain and inter-task\nvia a Scenario-aware Attentive Network (SAN) and Customized\nGate Control (CGC) models. PEPNet [11], developed by Kuaishou,\n\n\nConference’17, July 2017, Washington, DC, USA\nXiangyu Zhao, et al.\nTable 1: Category for Multi-modal Recommendation\nInteraction\nCategory\nRelated Works\nBridge\nUser-item Graph\n[99], [84], [107], [121], [151]\nItem-item Graph\n[158], [157], [83], [72], [10], [79], [158]\nKnowledge Graph\n[112], [103], [8], [106], [19], [96], [67]\nFusion\nCoarse-grained Attention\n[73], [89], [70], [18]\nFine-grained Attention\n[17], [47], [136], [60], [99], [84], [72], [19], [38], [65], [47],\n[63], [50], [67], [16], [40],[61], [172], [124], [55]\nCombined Attention\n[68], [64], [37]\nOther Fusion Methods\n[110], [14], [77], [77], [164], [138]\nFiltration\nFiltration\n[96], [171], [153], [69], [150]\ncomprises two components: the Embedding Personalized Network (EP-\nNet), which personalizes embeddings to integrate features across\ndomains, and the Parameter Personalized Network (PPNet), de-\nsigned to dynamically balance targets across multiple tasks. Addi-\ntionally, models like 3MN [165] propose a scenario and task adaptive\nnetwork for joint modeling, while AESM2 introduces a unified hi-\nerarchical structure for automatic expert selection, facilitating joint\nmodeling in the Multi-scenario Multi-task context.\n5\nMULTI-MODAL RECOMMENDATION\nIn recommendation systems, joint modeling plays a crucial role,\nwith representation extraction forming the bedrock of the overall\nframework. With the proliferation of multimedia services, item\nmodalities have become increasingly diverse, encompassing images\nand texts among others. Consequently, the exploration of various\nmodalities for representation extraction has garnered considerable\nattention due to its potential to address sparsity issues. This en-\ndeavor falls under the purview of multi-modal recommendation\nsystems (MRS). Given the diverse nature of multi-modal data, where\neach modality resides in distinct semantic spaces, existing MRS lit-\nerature predominantly focuses on the challenge of unifying modal\nrepresentations into a cohesive space, a concept termed \"feature\ninteraction\", which can be formulated as:\n𝑬𝑀= 𝑀\u0000𝑬𝑡𝑥𝑡, 𝑬𝑣, ..., 𝑬𝑝\u0001 = 𝑀\u0000E𝑡𝑥𝑡(𝑥𝑡𝑥𝑡), E𝑣(𝑥𝑣), ..., E𝑝(𝑥𝑝)\u0001\n(8)\nwhere E𝑀is the unified representation and 𝑥∗denote raw modality\ninputs. E∗(·) represents the corresponding modality encoder, such\nas ViT [28]. Thus, the core lies in the unifying function 𝑀(·). As\ndepicted in Figure 4, these interactions are categorized into three\nmain types: Bridge, Fusion, and Filtration. These techniques\nfacilitate feature interaction from multiple viewpoints, enabling\ntheir simultaneous application within a single MRS model. For\nclarity, existing works are classified by interaction types in Table 1.\n5.1\nBridge\nBridge focuses on capturing the inter-relationships between users\nand items while taking into account multi-modal information. This\napproach adopts the message-passing mechanism of GNNs to en-\nhance user representation by facilitating information exchange\nbetween users and items, thereby capturing user preferences across\ndifferent modalities. As illustrated in Figure 4, several works infer\nuser 1 preferences by aggregating interacted items for each modal-\nity. Furthermore, the modality representation of movie 1 can be\ninferred from the latent item-item graph. In this subsection, we will\ndelineate the methods for constructing bridges in MRS.\nUser 2\nUser 1\nMovie2\nMovie 1\nMovie 3\nMovie 4\nvisual vector\ntext vector\n id vector\nFusion\nFilteration\nBridge\n fused vector\nFigure 4: Three types of feature interaction for MRS.\n5.1.1\nUser-item Graph. By facilitating the exchange of infor-\nmation between users and items, it is feasible to capture users’\npreferences across various modalities. For example, MMGCN [121]\nderives a bipartite user-item graph based on the different modalities.\nExpanding upon MMGCN, GRCN [153] further improves the rec-\nommendation by dynamically adjusting the graph’s structure while\ndetecting the noisy interactions during the training. Despite their ef-\nficacy, these methods overlook variations in user preferences across\ndifferent modalities. To tackle this issue, DualGNN [107] utilizes bi-\npartite and co-occurrence graphs to extract the preferences from the\nuser’s correlations. Additionally, MMGCL [151] introduces a novel\nmulti-modal graph contrastive learning to address this challenge.\nMGAT [99] proposes a novel attention mechanism, facilitating the\nadaptive extraction of user preferences across various modalities.\n5.1.2\nItem-item Graph. Effectively leveraging item-item struc-\ntures can also contribute to improving the learning of item repre-\nsentations, thereby enhancing model performance. For instance,\napproaches like LATTICE [157] and MICRO [158] establish item-\nitem graphs for each modality by leveraging the user-item bipar-\ntite graph and amalgamating them to extract latent item graphs.\nNonetheless, these methodologies overlook the nuances in prefer-\nences among specific user segments. As a remedy, HCGCN [83]\nproposes a clustering graph convolutional network, which initially\ngroups user-item and item-item graphs. Furthermore, drawing in-\nspiration from the achievements of pre-training models, PMGT [72]\npresents a pre-trained graph transformer, furnishing side informa-\ntion in a multi-modal type and a unified perspective on project\nrelationships. In the context of bundle recommendation, models\nlike BGCN [10] and Cross-CBR [79] amalgamate user-bundle, item-\nbundle, and user-item relationships into a heterogeneous graph.\n5.1.3\nKnowledge Graph. Many researchers have endeavored to\nintegrate KGs with MRS by incorporating each modality of items\ninto the KG as entities. As a pioneering work, MKGAT [96] de-\nsigns a multi-modal graph-based attention technique to extract\ninformation from multi-modal KGs, focusing on entity information\nextraction and relationship reasoning. Besides, MMKGV [67] uti-\nlizes a graph attention network for disseminating and aggregating\ninformation on a multi-modal KG.\n5.2\nFusion\nIn contrast to bridge, fusion primarily revolves around exploring\nthe intra-relationships among various modalities of items. Its main\n\n\nJoint Modeling in Recommendations: A Survey\nConference’17, July 2017, Washington, DC, USA\naim lies in merging preferences across different modalities. Among\nfusion techniques, the attention mechanism emerges as particularly\nprevalent, offering flexibility in integrating multi-modal informa-\ntion with varying emphasis and weights. In this subsection, as de-\npicted in Figure 4, we begin by categorizing attention mechanisms\nbased on their granularity of fusion before introducing alternative\nfusion approaches within MRS.\n5.2.1\nCoarse-grained Attention. Certain models utilize atten-\ntion mechanisms to integrate information from multiple modalities\nat a coarse-grained level. For example, in UVCAN [70], multi-modal\ninformation is segregated into user-side and item-side components.\nInformation from the user side is then used to compute fusion\nweights for the item side through self-attention. MCPTR [73] builds\nupon UVCAN by proposing parallel merging of item and user in-\nformation. CMBF [18] introduces a cross-attention mechanism to\ncollectively capture semantic information from texts and images,\nfollowed by concatenation. Moreover, certain models exhibit varia-\ntions in modal proportions, such as MML [89] and MCPTR [73].\n5.2.2\nFine-grained Attention. Multi-modal data encompasses\nboth broad and nuanced features, such as audio tone variations\nand clothing patterns. Therefore, fine-grained fusion methods selec-\ntively integrate detailed feature information across various modali-\nties. This fine-grained fusion is particularly crucial in fashion rec-\nommendation contexts. For instance, POG [16] and NOR [61] em-\nploy multi-layer attention to extract deep features from fashion\nimages’ ensemble compositions, enabling continuous integration of\nintricate details. EFRM [40] enhances interpretability by incorporat-\ning a Semantic Extraction Network (SEN) to extract local features,\nwhich are then combined with fine-grained attention preferences.\nVECF [17] utilizes image segmentation techniques to merge im-\nage features from each patch with other modalities. Models like\nMINER [55], DMIN [136], and SUM [60] create interest represen-\ntations across various user aspects with the help of multi-modal\ninformation. Additionally, certain models [19, 47, 99] devise unique\ninternal structures to enhance fine-grained fusion.\n5.2.3\nCombined Attention. Expanding on fine-grained fusion,\nspecific models introduce combined fusion structures with the goal\nof preserving both fine-grained feature integration and global in-\nformation aggregation. NOVA [64], for example, proposes a non-\ninvasive attention mechanism featuring two branches. It isolates\nembedding in a separate branch to retain interactive information\nduring the fusion process. NRPA [68] employs personalized word-\nlevel attention to identify crucial words in comments for each\nuser/item, subsequently passing the comment information through\nalternating layers of fine and coarse-grained fusion. Similarly, VL-\nSNR [37], models users’ short and long-term interests, achieving\nboth fusions by combining multi-head attention and GRU networks.\n5.2.4\nOther Fusion Methods. In addition to employing atten-\ntion weights to fuse multi-modal information, some works utilize\nsimpler techniques such as concatenation operations [164] and\ngating mechanisms [64]. However, these methods are rarely used\nindependently and are often combined with graph and attention\nmechanisms, as previously discussed. Moreover, certain models\nfuse multi-modal features through both linear and nonlinear layers.\nLv et al. [77] incorporates a linear layer to merge textual and visual\nTable 2: Category for Multi-behavior Recommendation\nCategory\nRelated Works\nGraph-based\n[45], [163], [108], [109], [134], [146], [12], [129], [133], [117], [126]\n[32], [141], [81], [128], [118], [156], [25], [139], [143], [57], [92], [142]\nTransformer-based\n[34], [130], [33], [56], [155], [125]\nOthers\n[30], [13], [167], [14], [111], [66], [29], [57], [7],[131], [132], [149]\nfeatures. In MMT-Net [49], three context invariants of restaurant\ndata are labeled artificially and then fused through an MLP network.\n5.3\nFiltration\nMulti-modal data differs from user interaction data as it often in-\ncludes irrelevant information unrelated to user preferences. For\nexample, interaction such as the one between movie 3 and user 1\nshown in Figure 4 may introduce noise and should thus be filtered\nout. Removing such noisy data in multi-modal recommendation\ntasks typically results in improved recommendation performance.\nSome works adopt image processing methods for denoising. For\ninstance, VECF [17] and UVCAN [63] employ image segmentation\nto eliminate noise from images, thereby enhancing the capture\nof users’ personalized interests. Similarly, MM-Rec [124] employs\ntarget detection to identify significant image regions. Addition-\nally, various structures based on GNNs are employed for denois-\ning. FREEDOM [171] proposes a degree-sensitive edge pruning\nmethod to clean the user-item graph. GRCN [153] detects whether\nusers interact with noisy items accidentally, while PMGCRN [43]\nand MEGCF [69] address mismatched interactions. Moreover, MA-\nGAE [150] is devised to handle uncertainty issues for MRS.\n6\nMULTI-BEHAVIOR RECOMMENDATION\nExisting recommendation models usually focus solely on one single\nbehavior of users as input data, such as clicking or purchasing items.\nHowever, in real-world recommendation scenarios, users tend to\nengage in various types of behavioral interactions with products.\nFor example, in video recommendation, users exhibit different be-\nhaviors towards a single video, such as clicks, likes, and retweets.\nIt is believed that additional behavioral information (also known\nas auxiliary behaviors) apart from the target behavior contains\nrich semantic information which can better assist in modeling user\ninterests. Consequently, multi-behavior recommendation (MBR) is\napplied in various commercial domains for more personalized and\nrelevant recommendations based on multiple aspects of user behav-\niors. To be specific, the key of MBR is to learn the representation\nof user and item under different behavior semantics\n𝑬𝐵= 𝐺(𝑯1, 𝑯2, . . . , 𝑯𝑁) .\n(9)\nBesides, there are several challenges MBR aims to address. The first\nis data sparsity [12, 32, 56, 117, 126, 139] since there are usually\nsparse supervision signal under the target behavior. The second is\ncomplex inter-behavior and intra-behavior relations [14, 128]. The\nthird is noise [14, 156] under auxiliary behaviors. In the following,\nas shown in Table 2 the existing works are categorized into three\ngroups: graph-based, transformer-based, and others.\n6.1\nGraph-based Methods\nMost existing works on multi-behavior recommendation adopt\ngraph neural network in their framework design. The reason is that\n\n\nConference’17, July 2017, Washington, DC, USA\nXiangyu Zhao, et al.\nthe performance of graph-based methods is generally better than\nthat of non-graph models. A possible explanation is that the infor-\nmation propagation and aggregation based on the graph structure\ncan better mine the complex semantic relationships of heteroge-\nneous behaviors of users.\nGenerally, current models transform users’ heterogeneous his-\ntorical interactions into multi-behavior interaction graphs, where\neach user 𝑢and item 𝑖is a node, and there is a behavior-specific\nedge between them if 𝑢interacts with 𝑖under some behavior. For\nexample, MBGCN [45] conducts behavior-aware user-item propa-\ngation and item-relevance aware item-item propagation in the user-\nitem graph. Meanwhile, another significant technique leveraged\nby many graph-based methods is contrastive learning, which is a\nkind of self-supervised learning paradigm and is able to learn more\ndistinguishable representations. Specifically, different behaviors\ncan be treated as different contrastive views [117, 118, 126]. Never-\ntheless, it may also suffer from low efficiency because it requires\nintroducing random factors like graph augmentation operation.\n6.2\nTransformer-based Methods\nTo begin with, according to [149], BERT4Rec [95] can be enhanced\nto tackle MBR by injecting behavior representations into input for\nself-attention. Afterward, following the transformer architecture\nfor sequential recommendation, for example, DMT [33] employs\nmultiple deep interest Transformers to model different behavioral\nsequences, representing users’ real-time interests with multiple\nlow-dimensional vectors and making multi-task predictions. Com-\npared to traditional Transformer structures, MB-STR [155] designs\nmultiple behavior Transformer layers to capture the heterogeneous\ndependencies among multiple behaviors and the unique semantics\nof behaviors simultaneously. However, they usually achieve inferior\nperformance than graph-based methods.\n6.3\nOther Methods\nIn the early stage of MBR, some works simply regard different be-\nhaviors as different tasks to be predicted and adopt a multi-task\nlearning framework [13, 30]. This idea is closely related to the cas-\ncaded task relation introduced in Section 3.1.2 which supposes the\nsequential relationship among behaviors as a prior. For example,\nEHCF [13] leverages a transfer-based prediction and proposes an\nefficient optimization method without the need of sampling. How-\never, it is difficult for these methods to comprehensively depict\nand understand the complex cross-type behavior dependencies in\nreal-world recommendation scenarios.\nThanks to the strong capability of representing and captur-\ning complex relations between nodes, some methods adopt graph\ntransformer to model multi-behavior dependencies [131, 132, 149].\nFor example, KHGT [131] proposes a hierarchical graph trans-\nformer network with the graph-structured transformer module\nand attentive fusion network to capture high-order relations in the\nknowledge-aware multi-behavior graph. However, they also face\nsimilar challenges of graph- and transformer-based methods.\n7\nFUTURE DIRECTIONS\nMulti-task Recommendation. As discussed in Section 3.2.1, pre-\nvious works try to tackle negative transfer from either gradient or\nseparating shared and specific parameters. However, how to ex-\ntract the complex inter-task correlation needs further research, e.g.,\nfrom the causal relation [22]. Meanwhile, what, where, and when\nto transfer to alleviate negative transfer is still under-explored.\nMulti-scenario Recommendation. With scenarios numbering in\nthe thousands, there is a pressing need for scenario-unified mod-\nels optimized for real-time performance. This necessitates further\nexploration into quantification [48] and compression [152]. Further-\nmore, with scenario interrelations becoming complex, combining\nLLMs with MSR models to extract scenario information and bridge\nsemantic gaps poses an urgent challenge.\nMulti-modal Recommendation. Despite the availability of meth-\nods proposed for different interaction types within a model [50],\nthe absence of an up-to-date universal solution that integrates these\ntechniques remains a notable gap. Besides, the current dataset for\nMRS is rather constrained, lacking comprehensive coverage of var-\nious modalities, especially for joint modeling.\nMulti-behavior Recommendation Existing works, especially\nGraph-based methods necessitate a full incremental update pattern,\nwhere aggregation operations are performed on all nodes at each\nlayer of GNN, resulting in a significant computational cost. How\nto tackle their scalability and deployment in large-scale industrial\nrecommender systems requires further exploration.\nOther Joint Modeling Perspective. First, instead of representing\nuser interests with a single vector, multi-interest recommendation\nadopts multiple representations to accurately capture the user’s\ndynamic and diverse preferences [9, 51, 52, 90, 100]. Second, based\non multi-objective optimization, multi-objective recommendation\n[42, 169] focuses on the trade-off and balance among objectives, e.g.,\ndiversity [71] and fairness [135] from the optimization perspective.\nNovel Joint Modeling Technology. Traditional DRSs are de-\nsigned to meet specific requirements. However, the use of Large\nLanguage Models (LLMs) introduces a new opportunity for improve-\nment due to their strong understanding of language and context.\nCurrently, LLMs are mainly used to either add context [1, 120]\nor make recommendations simply based on fine-tuning [5, 31].\nNevertheless, the real potential lies in fully integrating LLMs with\nmultiple joint modeling dimensions to improve all aspects of rec-\nommender systems. Therefore, exploring how to effectively merge\nLLMs with joint modeling methods offers a promising direction for\nfuture research, aiming for more versatile and effective systems.\n8\nCONCLUSION\nThis survey highlights the potential of joint modeling in DRSs, ad-\ndressing the limitations of traditional approaches by integrating\nmulti-task, multi-scenario, multi-modal and multi-behavior strate-\ngies. This comprehensive approach promises enhanced personal-\nization, efficiency, and user satisfaction. The exploration of joint\nmodeling’s various dimensions and its challenges and opportuni-\nties underscores the complexity of developing more sophisticated\nrecommendation platforms. Looking forward, the advancement of\njoint modeling techniques is crucial for the evolution of recom-\nmender systems with research directions focusing on algorithm\nrefinement and scalability. This survey aims to catalyze future in-\nnovation, guiding the development of next-generation DRSs that\nare more adaptive, intelligent, and user-centric.\n\n\nJoint Modeling in Recommendations: A Survey\nConference’17, July 2017, Washington, DC, USA\nREFERENCES\n[1] Arkadeep Acharya, Brijraj Singh, and Naoyuki Onoe. 2023. Llm based generation\nof item-description for recommendation system. In Proc. of RecSys.\n[2] Muhammad Aljukhadar, Sylvain Senecal, and Charles-Etienne Daoust. 2010.\nInformation overload and usage of recommendations. In Proc. of RecSys Work-\nshop on User-Centric Evaluation of Recommender Systems and Their Interfaces\n(UCERSTI), Barcelona, Spain.\n[3] Alejandro Ariza-Casabona, Bartlomiej Twardowski, and Tri Kurniawan Wijaya.\n2023. Exploiting Graph Structured Cross-Domain Representation for Multi-\ndomain Recommendation. In Proc. of ECIR.\n[4] Ting Bai, Yudong Xiao, Bin Wu, Guojun Yang, Hongyong Yu, and Jian-Yun Nie.\n2022. A Contrastive Sharing Model for Multi-Task Recommendation. In Proc. of\nWWW.\n[5] Keqin Bao, Jizhi Zhang, Yang Zhang, Wenjie Wang, Fuli Feng, and Xiangnan\nHe. 2023. Tallrec: An effective and efficient tuning framework to align large\nlanguage model with recommendation. In Proc. of RecSys.\n[6] Zeynep Batmaz, Ali Yurekli, Alper Bilge, and Cihan Kaleli. 2019. A review on\ndeep learning for recommender systems: challenges and remedies. Artificial\nIntelligence Review (2019).\n[7] Hongyun Cai, Jie Meng, Shilin Yuan, and Jichao Ren. 2024. A Robust Sequential\nRecommendation Model Based on Multiple Feedback Behavior Denoising and\nTrusted Neighbors. Neural Processing Letters (2024).\n[8] Xianshuai Cao, Yuliang Shi, Jihu Wang, Han Yu, Xinjun Wang, and Zhongmin\nYan. 2022. Cross-modal Knowledge Graph Contrastive Learning for Machine\nLearning Method Recommendation. In Proc. of ACM MM.\n[9] Yukuo Cen, Jianwei Zhang, Xu Zou, Chang Zhou, Hongxia Yang, and Jie Tang.\n2020. Controllable multi-interest framework for recommendation. In Proc. of\nKDD.\n[10] Jianxin Chang, Chen Gao, Xiangnan He, Depeng Jin, and Yong Li. 2020. Bundle\nrecommendation with graph convolutional networks. In Proc. of SIGIR.\n[11] Jianxin Chang, Chenbin Zhang, Yiqun Hui, Dewei Leng, Yanan Niu, Yang Song,\nand Kun Gai. 2023. Pepnet: Parameter and embedding personalized network\nfor infusing with personalized prior information. In Proc. of KDD.\n[12] Chong Chen, Weizhi Ma, Min Zhang, Zhaowei Wang, Xiuqiang He, Chenyang\nWang, Yiqun Liu, and Shaoping Ma. 2021.\nGraph Heterogeneous Multi-\nRelational Recommendation. In Proc. of AAAI.\n[13] Chong Chen, Min Zhang, Yongfeng Zhang, Weizhi Ma, Yiqun Liu, and Shaoping\nMa. 2020. Efficient heterogeneous collaborative filtering without negative\nsampling for recommendation. In Proc. of AAAI.\n[14] Hong Chen, Yudong Chen, Xin Wang, Ruobing Xie, Rui Wang, Feng Xia, and\nWenwu Zhu. 2021. Curriculum disentangled recommendation with noisy multi-\nfeedback. In Proc. of NeurIPS.\n[15] Jingyuan Chen, Hanwang Zhang, Xiangnan He, Liqiang Nie, Wei Liu, and Tat-\nSeng Chua. 2017. Attentive collaborative filtering: Multimedia recommendation\nwith item-and component-level attention. In Proc. of SIGIR.\n[16] Wen Chen, Pipei Huang, Jiaming Xu, Xin Guo, Cheng Guo, Fei Sun, Chao Li,\nAndreas Pfadler, Huan Zhao, and Binqiang Zhao. 2019. POG: personalized outfit\ngeneration for fashion recommendation at Alibaba iFashion. In Proc. of KDD.\n[17] Xu Chen, Hanxiong Chen, Hongteng Xu, Yongfeng Zhang, Yixin Cao, Zheng\nQin, and Hongyuan Zha. 2019. Personalized fashion recommendation with\nvisual explanations based on multimodal attention network: Towards visually\nexplainable recommendation. In Proc. of SIGIR.\n[18] Xi Chen, Yangsiyi Lu, Yuehai Wang, and Jianyi Yang. 2021. CMBF: Cross-Modal-\nBased Fusion Recommendation Algorithm. Sensors (2021).\n[19] Xiang Chen, Ningyu Zhang, Lei Li, Shumin Deng, Chuanqi Tan, Changliang\nXu, Fei Huang, Luo Si, and Huajun Chen. 2022. Hybrid Transformer with Multi-\nlevel Fusion for Multimodal Knowledge Graph Completion. arXiv preprint\narXiv:2205.02357 (2022).\n[20] Zhao Chen, Vijay Badrinarayanan, Chen-Yu Lee, and Andrew Rabinovich. 2018.\nGradnorm: Gradient normalization for adaptive loss balancing in deep multitask\nnetworks. In Proc. of ICML.\n[21] Zhongxia Chen, Xiting Wang, Xing Xie, Tong Wu, Guoqing Bu, Yining Wang,\nand Enhong Chen. 2019. Co-attentive multi-task learning for explainable rec-\nommendation.. In Proc. of IJCAI.\n[22] Zhongde Chen, Ruize Wu, Cong Jiang, Honghui Li, Xin Dong, Can Long, Yong\nHe, Lei Cheng, and Linjian Mo. 2022. CFS-MTL: A Causal Feature Selection\nMechanism for Multi-task Learning via Pseudo-intervention. In Proc. of CIKM.\n[23] Heng-Tze Cheng, Levent Koc, Jeremiah Harmsen, Tal Shaked, Tushar Chandra,\nHrishi Aradhye, Glen Anderson, Greg Corrado, Wei Chai, Mustafa Ispir, et al.\n2016. Wide & deep learning for recommender systems. In Proc. of the 1st\nworkshop on DLRS.\n[24] Wenzhuo Cheng, Ke Ding, Xin Dong, Yong He, Liang Zhang, and Linjian Mo.\n2023. MI-DPG: Decomposable Parameter Generation Network Based on Mutual\nInformation for Multi-Scenario Recommendation. In Proc. of CIKM.\n[25] Zhiyong Cheng, Sai Han, Fan Liu, Lei Zhu, Zan Gao, and Yuxin Peng. 2023.\nMulti-Behavior Recommendation with Cascading Graph Convolution Networks.\narXiv preprint arXiv:2303.15720 (2023).\n[26] Debasis Das. 2022. MARRS: A Framework for multi-objective risk-aware route\nrecommendation using Multitask-Transformer. In Proc. of RecSys.\n[27] Ke Ding, Xin Dong, Yong He, Lei Cheng, Chilin Fu, Zhaoxin Huan, Hai Li, Tan\nYan, Liang Zhang, Xiaolu Zhang, et al. 2021. MSSM: a multiple-level sparse\nsharing model for efficient multi-task learning. In Proc. of SIGIR.\n[28] Alexey Dosovitskiy, Lucas Beyer, Alexander Kolesnikov, Dirk Weissenborn,\nXiaohua Zhai, Thomas Unterthiner, Mostafa Dehghani, Matthias Minderer,\nGeorg Heigold, Sylvain Gelly, et al. 2020. An image is worth 16x16 words:\nTransformers for image recognition at scale. arXiv preprint arXiv:2010.11929\n(2020).\n[29] Mingxin Gan, Gangxin Xu, and Yingxue Ma. 2023. A multi-behavior recommen-\ndation method exploring the preference differences among various behaviors.\nExpert Systems with Applications (2023).\n[30] Chen Gao, Xiangnan He, Dahua Gan, Xiangning Chen, Fuli Feng, Yong Li, Tat-\nSeng Chua, and Depeng Jin. 2019. Neural multi-task recommendation from\nmulti-behavior data. In Proc. of ICDE.\n[31] Shijie Geng, Shuchang Liu, Zuohui Fu, Yingqiang Ge, and Yongfeng Zhang. 2022.\nRecommendation as language processing (rlp): A unified pretrain, personalized\nprompt & predict paradigm (p5). In Proc. of RecSys.\n[32] Shuyun Gu, Xiao Wang, Chuan Shi, and Ding Xiao. 2022. Self-supervised Graph\nNeural Networks for Multi-behavior Recommendation.. In Proc. of IJCAI.\n[33] Yulong Gu, Zhuoye Ding, Shuaiqiang Wang, Lixin Zou, Yiding Liu, and Dawei\nYin. 2020. Deep multifaceted transformers for multi-objective ranking in large-\nscale e-commerce recommender systems. In Proc. of CIKM.\n[34] Long Guo, Lifeng Hua, Rongfei Jia, Binqiang Zhao, Xiaobo Wang, and Bin\nCui. 2019. Buying or browsing?: Predicting real-time purchasing intent using\nattention-based deep network with multiple behavior. In Proc. of KDD.\n[35] Guy Hadash, Oren Sar Shalom, and Rita Osadchy. 2018. Rank and rate: multi-task\nlearning for recommender systems. In Proc. of RecSys.\n[36] Jianhua Han, Yong Yu, Feng Liu, Ruiming Tang, and Yuzhou Zhang. 2019. Op-\ntimizing ranking algorithm in recommender system via deep reinforcement\nlearning. In Proc. of AIAM.\n[37] Songhao Han, Wei Huang, and Xiaotian Luan. 2022. VLSNR: Vision-Linguistics\nCoordination Time Sequence-aware News Recommendation. arXiv preprint\narXiv:2210.02946 (2022).\n[38] Tengyue Han, Pengfei Wang, Shaozhang Niu, and Chenliang Li. 2022. Modality\nMatches Modality: Pretraining Modality-Disentangled Item Representations for\nRecommendation. In Proc. of WWW.\n[39] Yun He, Xue Feng, Cheng Cheng, Geng Ji, Yunsong Guo, and James Caverlee.\n2022. MetaBalance: Improving Multi-Task Recommendations via Adapting\nGradient Magnitudes of Auxiliary Tasks. In Proc. of WWW.\n[40] Min Hou, Le Wu, Enhong Chen, Zhi Li, Vincent W Zheng, and Qi Liu. 2019.\nExplainable fashion recommendation: A semantic attribute region guided ap-\nproach. arXiv preprint arXiv:1905.12862 (2019).\n[41] Zhaoxin Huan, Ang Li, Xiaolu Zhang, Xu Min, Jieyu Yang, Yong He, and Jun\nZhou. 2023. SAMD: An Industrial Framework for Heterogeneous Multi-Scenario\nRecommendation. In Proc. of KDD.\n[42] Dietmar Jannach. 2022. Multi-Objective Recommender Systems: Survey and\nChallenges. arXiv:2210.10309 (2022).\n[43] Xiangen Jia, Yihong Dong, Feng Zhu, Yu Xin, and Jiangbo Qian. 2022. Preference-\ncorrected multimodal graph convolutional recommendation network. Applied\nIntelligence (2022).\n[44] Yuchen Jiang, Qi Li, Han Zhu, Jinbei Yu, Jin Li, Ziru Xu, Huihui Dong, and Bo\nZheng. 2022. Adaptive domain interest network for multi-domain recommen-\ndation. In Proc. of CIKM.\n[45] Bowen Jin, Chen Gao, Xiangnan He, Depeng Jin, and Yong Li. 2020. Multi-\nbehavior recommendation with graph convolutional networks. In Proc. of SIGIR.\n[46] Jiarui Jin, Xianyu Chen, Weinan Zhang, Yuanbo Chen, Zaifan Jiang, Zekun Zhu,\nZhewen Su, and Yong Yu. 2022. Multi-Scale User Behavior Network for Entire\nSpace Multi-Task Learning. In Proc. of CIKM.\n[47] Taeri Kim, Yeon-Chang Lee, Kijung Shin, and Sang-Wook Kim. 2022. MARIO:\nModality-Aware Attention and Modality-Preserving Decoders for Multimedia\nRecommendation. In Proc. of CIKM.\n[48] Yunyong Ko, Jae-Seo Yu, Hong-Kyun Bae, Yongjun Park, Dongwon Lee, and\nSang-Wook Kim. 2021. MASCOT: A Quantization Framework for Efficient\nMatrix Factorization in Recommender Systems. In Proc. of ICDM.\n[49] Adit Krishnan, Mahashweta Das, Mangesh Bendre, Hao Yang, and Hari Sun-\ndaram. 2020. Transfer learning via contextual invariants for one-to-many\ncross-domain recommendation. In Proc. of SIGIR.\n[50] Chenyi Lei, Shixian Luo, Yong Liu, Wanggui He, Jiamang Wang, Guoxin Wang,\nHaihong Tang, Chunyan Miao, and Houqiang Li. 2021. Understanding chinese\nvideo and language via contrastive multimodal pre-training. In Proc. of ACM\nMM.\n[51] Beibei Li, Beihong Jin, Jiageng Song, Yisong Yu, Yiyuan Zheng, and Wei Zhou.\n2022. Improving micro-video recommendation via contrastive multiple interests.\nIn Proc. of SIGIR.\n[52] Chao Li, Zhiyuan Liu, Mengmeng Wu, Yuchi Xu, Huan Zhao, Pipei Huang,\nGuoliang Kang, Qiwei Chen, Wei Li, and Dik Lun Lee. 2019. Multi-interest\n\n\nConference’17, July 2017, Washington, DC, USA\nXiangyu Zhao, et al.\nnetwork with dynamic routing for recommendation at Tmall. In Proc. of CIKM.\n[53] Hui Li, Yanlin Wang, Ziyu Lyu, and Jieming Shi. 2020. Multi-task learning for\nrecommendation over heterogeneous information network. IEEE Transactions\non Knowledge and Data Engineering (2020).\n[54] Jinyun Li, Huiwen Zheng, Yuanlin Liu, Minfang Lu, Lixia Wu, and Haoyuan Hu.\n2022. AdaptDHM: Adaptive Distribution Hierarchical Model for Multi-Domain\nCTR Prediction. arXiv preprint arXiv:2211.12105 (2022).\n[55] Jian Li, Jieming Zhu, Qiwei Bi, Guohao Cai, Lifeng Shang, Zhenhua Dong, Xin\nJiang, and Qun Liu. 2022. MINER: Multi-interest matching network for news\nrecommendation. In Proc. of ACL Findings.\n[56] Nuo Li, Bin Guo, Yan Liu, Lina Yao, Jiaqi Liu, and Zhiwen Yu. 2022. AskMe:\njoint individual-level and community-level behavior interaction for question\nrecommendation. In Proc. of WWW.\n[57] Qingfeng Li, Huifang Ma, Ruoyi Zhang, Wangyu Jin, and Zhixin Li. 2023. Dual-\nscale Contrastive Learning for multi-behavior recommendation. Applied Soft\nComputing (2023).\n[58] Xiaopeng Li, Fan Yan, Xiangyu Zhao, Yichao Wang, Bo Chen, Huifeng Guo, and\nRuiming Tang. 2023. Hamur: Hyper adapter for multi-domain recommendation.\nIn Proc. of CIKM.\n[59] Yu Li, Yi Zhang, Lu Gan, Gengwei Hong, Zimu Zhou, and Qiang Li. 2021.\nRevMan: Revenue-aware multi-task online insurance recommendation. In Proc.\nof AAAI.\n[60] Jianxun Lian, Iyad Batal, Zheng Liu, Akshay Soni, Eun Yong Kang, Yajun Wang,\nand Xing Xie. 2021. Multi-Interest-Aware User Modeling for Large-Scale Se-\nquential Recommendations. arXiv preprint arXiv:2102.09211 (2021).\n[61] Yujie Lin, Pengjie Ren, Zhumin Chen, Zhaochun Ren, Jun Ma, and Maarten\nDe Rijke. 2019. Explainable outfit recommendation with joint outfit matching\nand comment generation. IEEE Transactions on Knowledge and Data Engineering\n(2019).\n[62] Zihan Lin, Xuanhua Yang, Shaoguo Liu, Xiaoyu Peng, Wayne Xin Zhao, Liang\nWang, and Bo Zheng. 2022. Personalized Inter-Task Contrastive Learning for\nCTR&CVR Joint Estimation. arXiv preprint arXiv:2208.13442 (2022).\n[63] Bo Liu. 2022. Implicit semantic-based personalized micro-videos recommenda-\ntion. arXiv preprint arXiv:2205.03297 (2022).\n[64] Chang Liu, Xiaoguang Li, Guohao Cai, Zhenhua Dong, Hong Zhu, and Lifeng\nShang. 2021. Noninvasive self-attention for side information fusion in sequential\nrecommendation. In Proc. of AAAI.\n[65] Fan Liu, Zhiyong Cheng, Huilin Chen, Anan Liu, Liqiang Nie, and Mohan\nKankanhalli. 2022. Disentangled Multimodal Representation Learning for Rec-\nommendation. arXiv preprint arXiv:2203.05406 (2022).\n[66] Haobing Liu, Jianyu Ding, Yanmin Zhu, Feilong Tang, Jiadi Yu, Ruobing Jiang,\nand Zhongwen Guo. 2023. Modeling multi-aspect preferences and intents for\nmulti-behavioral sequential recommendation. Knowledge-Based Systems (2023).\n[67] Huizhi Liu, Chen Li, and Lihua Tian. 2022. Multi-modal Graph Attention\nNetwork for Video Recommendation. In Proc. of CCET.\n[68] Hongtao Liu, Fangzhao Wu, Wenjun Wang, Xianchen Wang, Pengfei Jiao,\nChuhan Wu, and Xing Xie. 2019. NRPA: neural recommendation with per-\nsonalized attention. In Proc. of SIGIR.\n[69] Kang Liu, Feng Xue, Dan Guo, Le Wu, Shujie Li, and Richang Hong. 2022.\nMEGCF: Multimodal entity graph collaborative filtering for personalized rec-\nommendation. ACM Transactions on Information Systems (2022).\n[70] Shang Liu, Zhenzhong Chen, Hongyi Liu, and Xinghai Hu. 2019. User-video\nco-attention network for personalized micro-video recommendation. In Proc. of\nWWW.\n[71] Yong Liu, Zhiqi Shen, Yinan Zhang, and Lizhen Cui. 2021. Diversity-promoting\ndeep reinforcement learning for interactive recommendation. In Proc. of ICCSE.\n[72] Yong Liu, Susen Yang, Chenyi Lei, Guoxin Wang, Haihong Tang, Juyong Zhang,\nAixin Sun, and Chunyan Miao. 2021. Pre-training graph transformer with\nmultimodal side information for recommendation. In Proc. of ACM MM.\n[73] Zhuang Liu, Yunpu Ma, Matthias Schubert, Yuanxin Ouyang, and Zhang Xiong.\n2022. Multi-Modal Contrastive Pre-training for Recommendation. In Proc. of\nICMR.\n[74] Ziru Liu, Jiejie Tian, Qingpeng Cai, Xiangyu Zhao, Jingtong Gao, Shuchang Liu,\nDayou Chen, Tonghao He, Dong Zheng, Peng Jiang, et al. 2023. Multi-Task\nRecommendations with Reinforcement Learning. arXiv preprint arXiv:2302.03328\n(2023).\n[75] Yichao Lu, Ruihai Dong, and Barry Smyth. 2018. Why I like it: multi-task\nlearning for recommendation and explanation. In Proc. of RecSys.\n[76] Linhao Luo, Yumeng Li, Buyu Gao, Shuai Tang, Sinan Wang, Jiancheng Li,\nTanchao Zhu, Jiancai Liu, Zhao Li, and Shirui Pan. 2023. MAMDR: A model\nagnostic learning framework for multi-domain recommendation. In Proc. of\nICDE.\n[77] Junmei Lv, Bin Song, Jie Guo, Xiaojiang Du, and Mohsen Guizani. 2019. Interest-\nrelated item similarity model based on multimodal data for top-N recommenda-\ntion. IEEE Access (2019).\n[78] Xiao Ma, Liqin Zhao, Guan Huang, Zhi Wang, Zelin Hu, Xiaoqiang Zhu, and Kun\nGai. 2018. Entire space multi-task model: An effective approach for estimating\npost-click conversion rate. In Proc. of SIGIR.\n[79] Yunshan Ma, Yingzhi He, An Zhang, Xiang Wang, and Tat-Seng Chua. 2022.\nCrossCBR: Cross-view Contrastive Learning for Bundle Recommendation. arXiv\npreprint arXiv:2206.00242 (2022).\n[80] Tariq Mahmood and Francesco Ricci. 2007. Learning and adaptivity in interactive\nrecommender systems. In Proc. of ICEC.\n[81] Chang Meng, Ziqi Zhao, Wei Guo, Yingxue Zhang, Haolun Wu, Chen Gao,\nDong Li, Xiu Li, and Ruiming Tang. 2023. Coarse-to-fine knowledge-enhanced\nmulti-interest learning framework for multi-behavior recommendation. ACM\nTransactions on Information Systems (2023).\n[82] Wenjing Meng, Deqing Yang, and Yanghua Xiao. 2020. Incorporating user\nmicro-behaviors and item knowledge into multi-task learning for session-based\nrecommendation. In Proc. of SIGIR.\n[83] Zongshen Mu, Yueting Zhuang, Jie Tan, Jun Xiao, and Siliang Tang. 2022. Learn-\ning Hybrid Behavior Patterns for Multimedia Recommendation. In Proc. of ACM\nMM.\n[84] Juan Ni, Zhenhua Huang, Yang Hu, and Chen Lin. 2022. A two-stage embedding\nmodel for recommendation with multimodal auxiliary information. Information\nSciences (2022).\n[85] Yabo Ni, Dan Ou, Shichen Liu, Xiang Li, Wenwu Ou, Anxiang Zeng, and Luo\nSi. 2018. Perceive your users in depth: Learning universal user representations\nfrom multiple e-commerce tasks. In Proc. of KDD.\n[86] Wentao Ning, Xiao Yan, Weiwen Liu, Reynold Cheng, Rui Zhang, and Bo Tang.\n2023. Multi-domain Recommendation with Embedding Disentangling and\nDomain Alignment. In Proc. of CIKM.\n[87] Wentao Ning, Xiao Yan, Weiwen Liu, Reynold Cheng, Rui Zhang, and Bo Tang.\n2023. Multi-domain Recommendation with Embedding Disentangling and\nDomain Alignment. In Proc. of CIKM.\n[88] Wentao Ouyang, Xiuwu Zhang, Chaofeng Guo, Shukui Ren, Yupei Sui, Kun\nZhang, Jinmei Luo, Yunfeng Chen, Dongbo Xu, Xiangzheng Liu, and Yanlong\nDu. 2023. Masked Multi-Domain Network: Multi-Type and Multi-Scenario\nConversion Rate Prediction with a Single Model. In Proc. of CIKM.\n[89] Xingyu Pan, Yushuo Chen, Changxin Tian, Zihan Lin, Jinpeng Wang, He Hu, and\nWayne Xin Zhao. 2022. Multimodal Meta-Learning for Cold-Start Sequential\nRecommendation. In Proc. of CIKM.\n[90] Qi Pi, Weijie Bian, Guorui Zhou, Xiaoqiang Zhu, and Kun Gai. 2019. Practice\non long sequential user behavior modeling for click-through rate prediction. In\nProc. of KDD.\n[91] Nan Qiu, BoYu Gao, Feiran Huang, Huawei Tu, and Weiqi Luo. 2021. Incorporat-\ning global context into multi-task learning for session-based recommendation.\nIn Proc. of KSEM.\n[92] Ran Rang, Linlin Xing, Longbo Zhang, Hongzhen Cai, and Zhaojie Sun. 2023.\nHeterogeneous multi-behavior recommendation based on graph convolutional\nnetworks. IEEE Access (2023).\n[93] Walid Shalaby, Sejoon Oh, Amir Afsharinejad, Srijan Kumar, and Xiquan Cui.\n2022. M2TRec: Metadata-aware Multi-task Transformer for Large-scale and\nCold-start free Session-based Recommendations. In Proc. of RecSys.\n[94] Xiang-Rong Sheng, Liqin Zhao, Guorui Zhou, Xinyao Ding, Binding Dai, Qiang\nLuo, Siran Yang, Jingshan Lv, Chi Zhang, Hongbo Deng, et al. 2021. One model to\nserve all: Star topology adaptive recommender for multi-domain ctr prediction.\nIn Proc. of CIKM.\n[95] Fei Sun, Jun Liu, Jian Wu, Changhua Pei, Xiao Lin, Wenwu Ou, and Peng\nJiang. 2019. BERT4Rec: Sequential recommendation with bidirectional encoder\nrepresentations from transformer. In Proc. of CIKM.\n[96] Rui Sun, Xuezhi Cao, Yan Zhao, Junchen Wan, Kun Zhou, Fuzheng Zhang,\nZhongyuan Wang, and Kai Zheng. 2020. Multi-modal knowledge graphs for\nrecommender systems. In Proc. of CIKM.\n[97] Hongyan Tang, Junning Liu, Ming Zhao, and Xudong Gong. 2020. Progressive\nlayered extraction (ple): A novel multi-task learning (mtl) model for personalized\nrecommendations. In Proc. of RecSys.\n[98] Xuewen Tao, Mingming Ha, Xiaobo Guo, Qiongxu Ma, Hongwei Cheng, and\nWenfang Lin. 2023. Task Aware Feature Extraction Framework for Sequential\nDependence Multi-Task Learning. arXiv preprint arXiv:2301.02494 (2023).\n[99] Zhulin Tao, Yinwei Wei, Xiang Wang, Xiangnan He, Xianglin Huang, and\nTat-Seng Chua. 2020. MGAT: multimodal graph attention network for recom-\nmendation. Information Processing & Management (2020).\n[100] Yu Tian, Jianxin Chang, Yanan Niu, Yang Song, and Chenliang Li. 2022. When\nmulti-level meets multi-interest: A multi-grained neural model for sequential\nrecommendation. In Proc. of SIGIR.\n[101] Yu Tian, Bofang Li, Si Chen, Xubin Li, Hongbo Deng, Jian Xu, Bo Zheng, Qian\nWang, and Chenliang Li. 2023. Multi-Scenario Ranking with Adaptive Feature\nLearning. In Proc. of SIGIR.\n[102] Hao Wang, Tai-Wei Chang, Tianqiao Liu, Jianmin Huang, Zhichao Chen, Chao\nYu, Ruopeng Li, and Wei Chu. 2022. ESCM2: Entire Space Counterfactual\nMulti-Task Model for Post-Click Conversion Rate Estimation. In Proc. of SIGIR.\n[103] Hongwei Wang, Fuzheng Zhang, Miao Zhao, Wenjie Li, Xing Xie, and Minyi\nGuo. 2019. Multi-task feature learning for knowledge graph enhanced recom-\nmendation. In Proc. of WWW.\n\n\nJoint Modeling in Recommendations: A Survey\nConference’17, July 2017, Washington, DC, USA\n[104] Menghan Wang, Yujie Lin, Guli Lin, Keping Yang, and Xiao-ming Wu. 2020.\nM2GRL: A multi-task multi-view graph representation learning framework for\nweb-scale recommender systems. In Proc. of KDD.\n[105] Nan Wang, Hongning Wang, Yiling Jia, and Yue Yin. 2018. Explainable recom-\nmendation via multi-task learning in opinionated text data. In Proc. of SIGIR.\n[106] Peng Wang, Jiangheng Wu, and Xiaohang Chen. 2022. Multimodal Entity\nLinking with Gated Hierarchical Fusion and Contrastive Training. In Proc. of\nSIGIR.\n[107] Qifan Wang, Yinwei Wei, Jianhua Yin, Jianlong Wu, Xuemeng Song, and Liqiang\nNie. 2021. Dualgnn: Dual graph neural network for multimedia recommendation.\nIEEE Transactions on Multimedia (2021).\n[108] Wen Wang, Wei Zhang, Shukai Liu, Qi Liu, Bo Zhang, Leyu Lin, and Hongyuan\nZha. 2020. Beyond clicks: Modeling multi-relational item graph for session-based\ntarget behavior prediction. In Proc. of WWW.\n[109] Wen Wang, Wei Zhang, Shukai Liu, Qi Liu, Bo Zhang, Leyu Lin, and Hongyuan\nZha. 2021. Incorporating Link Prediction into Multi-Relational Item Graph\nModeling for Session-based Recommendation. IEEE Transactions on Knowledge\nand Data Engineering (2021).\n[110] Xin Wang, Hong Chen, and Wenwu Zhu. 2021. Multimodal disentangled repre-\nsentation for recommendation. In Proc. of ICME.\n[111] Xi Wang, Wenjie Wang, Fuli Feng, Wenge Rong, and Chuantao Yin. 2022. Causal\nIntervention for Fairness in Multi-behavior Recommendation. arXiv preprint\narXiv:2209.04589 (2022).\n[112] Yuequn Wang, Liyan Dong, Hao Zhang, Xintao Ma, Yongli Li, and Minghui Sun.\n2020. An enhanced multi-modal recommendation based on alternate training\nwith knowledge graph representation. IEEE Access (2020).\n[113] Yichao Wang, Huifeng Guo, Bo Chen, Weiwen Liu, Zhirong Liu, Qi Zhang,\nZhicheng He, Hongkun Zheng, Weiwei Yao, Muyu Zhang, et al. 2022. Causalint:\nCausal inspired intervention for multi-scenario recommendation. In Proc. of\nKDD.\n[114] Yuyan Wang, Xuezhi Wang, Alex Beutel, Flavien Prost, Jilin Chen, and Ed H Chi.\n2021. Understanding and improving fairness-accuracy trade-offs in multi-task\nlearning. In Proc. of KDD.\n[115] Yanshi Wang, Jie Zhang, Qing Da, and Anxiang Zeng. 2020. Delayed feed-\nback modeling for the entire space conversion rate prediction. arXiv preprint\narXiv:2011.11826 (2020).\n[116] Yuyan Wang, Zhe Zhao, Bo Dai, Christopher Fifty, Dong Lin, Lichan Hong, Li\nWei, and Ed H Chi. 2022. Can Small Heads Help? Understanding and Improving\nMulti-Task Generalization. In Proc. of WWW.\n[117] Wei Wei, Chao Huang, Lianghao Xia, Yong Xu, Jiashu Zhao, and Dawei Yin. 2022.\nContrastive Meta Learning with Behavior Multiplicity for Recommendation. In\nProc. of WSDM.\n[118] Wei Wei, Chao Huang, Lianghao Xia, Yanwei Yu, and Chuxu Zhang. 2022.\nMulti-Behavior Dynamic Contrastive Learning for Recommendation. (2022).\n[119] Wei Wei, Chao Huang, Lianghao Xia, and Chuxu Zhang. 2023. Multi-modal\nself-supervised learning for recommendation. In Proc. of WWW.\n[120] Wei Wei, Xubin Ren, Jiabin Tang, Qinyong Wang, Lixin Su, Suqi Cheng, Junfeng\nWang, Dawei Yin, and Chao Huang. 2024. Llmrec: Large language models with\ngraph augmentation for recommendation. In Proc. of WSDM.\n[121] Yinwei Wei, Xiang Wang, Liqiang Nie, Xiangnan He, Richang Hong, and Tat-\nSeng Chua. 2019. MMGCN: Multi-modal graph convolution network for per-\nsonalized recommendation of micro-video. In Proc. of ACM MM.\n[122] Hong Wen, Jing Zhang, Fuyu Lv, Wentian Bao, Tianyi Wang, and Zulong Chen.\n2021. Hierarchically modeling micro and macro behaviors via multi-task learn-\ning for conversion rate prediction. In Proc. of SIGIR.\n[123] Hong Wen, Jing Zhang, Yuan Wang, Fuyu Lv, Wentian Bao, Quan Lin, and\nKeping Yang. 2020. Entire space multi-task modeling via post-click behavior\ndecomposition for conversion rate prediction. In Proc. of SIGIR.\n[124] Chuhan Wu, Fangzhao Wu, Tao Qi, and Yongfeng Huang. 2021. Mm-rec: multi-\nmodal news recommendation. arXiv preprint arXiv:2104.07407 (2021).\n[125] Chuhan Wu, Fangzhao Wu, Tao Qi, and Yongfeng Huang. 2022. Feedrec: News\nfeed recommendation with various user feedbacks. Proc. of WWW.\n[126] Xuyang Wu, Alessandro Magnani, Suthee Chaidaroon, Ajit Puthenputhussery,\nCiya Liao, and Yi Fang. 2022. A Multi-task Learning Framework for Product\nRanking with BERT. In Proc. of WWW.\n[127] Dongbo Xi, Zhen Chen, Peng Yan, Yinger Zhang, Yongchun Zhu, Fuzhen Zhuang,\nand Yu Chen. 2021. Modeling the sequential dependence among audience multi-\nstep conversions with multi-task learning in targeted display advertising. In\nProc. of KDD.\n[128] Lianghao Xia, Chao Huang, Yong Xu, Peng Dai, and Liefeng Bo. 2022. Multi-\nBehavior Graph Neural Networks for Recommender System. IEEE Transactions\non Neural Networks and Learning Systems (2022).\n[129] Lianghao Xia, Chao Huang, Yong Xu, Peng Dai, Mengyin Lu, and Liefeng\nBo. 2021. Multi-Behavior Enhanced Recommendation with Cross-Interaction\nCollaborative Relation Modeling. In Proc. of ICDE.\n[130] Lianghao Xia, Chao Huang, Yong Xu, Peng Dai, Bo Zhang, and Liefeng Bo.\n2020. Multiplex behavioral relation learning for recommendation via memory\naugmented transformer network. In Proc. of SIGIR.\n[131] Lianghao Xia, Chao Huang, Yong Xu, Peng Dai, Xiyue Zhang, Hongsheng\nYang, Jian Pei, and Liefeng Bo. 2021. Knowledge-enhanced hierarchical graph\ntransformer network for multi-behavior recommendation. In Proc. of AAAI.\n[132] Lianghao Xia, Chao Huang, Yong Xu, and Jian Pei. 2022. Multi-Behavior Sequen-\ntial Recommendation with Temporal Graph Transformer. IEEE Transactions on\nKnowledge and Data Engineering (2022).\n[133] Lianghao Xia, Yong Xu, Chao Huang, Peng Dai, and Liefeng Bo. 2021. Graph\nmeta network for multi-behavior recommendation. In Proc. of SIGIR.\n[134] Fengtong Xiao, Lin Li, Weinan Xu, Jingyu Zhao, Xiaofeng Yang, Jun Lang, and\nHao Wang. 2021. DMBGN: Deep Multi-Behavior Graph Networks for Voucher\nRedemption Rate Prediction. In Proc. of KDD.\n[135] Lin Xiao, Zhang Min, Zhang Yongfeng, Gu Zhaoquan, Liu Yiqun, and Ma Shaop-\ning. 2017. Fairness-aware group recommendation with pareto-efficiency. In\nProc. of RecSys.\n[136] Zhibo Xiao, Luwei Yang, Wen Jiang, Yi Wei, Yi Hu, and Hao Wang. 2020. Deep\nmulti-interest network for click-through rate prediction. In Proc. of CIKM.\n[137] Shen Xin, Martin Ester, Jiajun Bu, Chengwei Yao, Zhao Li, Xun Zhou, Yizhou Ye,\nand Can Wang. 2019. Multi-task based sales predictions for online promotions.\nIn Proc. of CIKM.\n[138] Cai Xu, Ziyu Guan, Wei Zhao, Quanzhou Wu, Meng Yan, Long Chen, and\nQiguang Miao. 2020. Recommendation by users’ multimodal preferences for\nsmart city applications. IEEE Transactions on Industrial Informatics (2020).\n[139] Jingcao Xu, Chaokun Wang, Cheng Wu, Yang Song, Kai Zheng, Xiaowei Wang,\nChangping Wang, Guorui Zhou, and Kun Gai. 2023.\nMulti-behavior Self-\nsupervised Learning for Recommendation. arXiv preprint arXiv:2305.18238\n(2023).\n[140] Hong-Jian Xue, Xinyu Dai, Jianbing Zhang, Shujian Huang, and Jiajun Chen.\n2017. Deep matrix factorization models for recommender systems.. In Proc. of\nIJCAI.\n[141] Mingshi Yan, Zhiyong Cheng, Chen Gao, Jing Sun, Fan Liu, Fuming Sun, and\nHaojie Li. 2022. Cascading Residual Graph Convolutional Network for Multi-\nBehavior Recommendation. arXiv preprint arXiv:2205.13128 (2022).\n[142] Mingshi Yan, Zhiyong Cheng, Chen Gao, Jing Sun, Fan Liu, Fuming Sun, and\nHaojie Li. 2023. Cascading residual graph convolutional network for multi-\nbehavior recommendation. ACM Transactions on Information Systems (2023).\n[143] Mingshi Yan, Zhiyong Cheng, Jing Sun, Fuming Sun, and Yuxin Peng. 2023.\nMB-HGCN: A Hierarchical Graph Convolutional Network for Multi-behavior\nRecommendation. arXiv preprint arXiv:2306.10679 (2023).\n[144] Chenxiao Yang, Junwei Pan, Xiaofeng Gao, Tingyu Jiang, Dapeng Liu, and Guihai\nChen. 2022. Cross-task knowledge distillation in multi-task recommendation.\nIn Proc. of AAAI.\n[145] Enneng Yang, Junwei Pan, Ximei Wang, Haibin Yu, Li Shen, Xihua Chen, Lei\nXiao, Jie Jiang, and Guibing Guo. 2022. AdaTask: A Task-aware Adaptive\nLearning Rate Approach to Multi-task Learning. arXiv:2211.15055 (2022).\n[146] Haoran Yang, Hongxu Chen, Lin Li, S Yu Philip, and Guandong Xu. 2021. Hyper\nmeta-path contrastive learning for multi-behavior recommendation. In Proc. of\nICDM.\n[147] Haizhi Yang, Tengyun Wang, Xiaoli Tang, Qianyu Li, Yueyue Shi, Siyu Jiang,\nHan Yu, and Hengjie Song. 2021. Multi-task Learning for Bias-Free Joint CTR\nPrediction and Market Price Modeling in Online Advertising. In Proc. of CIKM.\n[148] Xuanhua Yang, Xiaoyu Peng, Penghui Wei, Shaoguo Liu, Liang Wang, and\nBo Zheng. 2022. AdaSparse: Learning Adaptively Sparse Structures for Multi-\nDomain Click-Through Rate Prediction. In Proc. of CIKM.\n[149] Yuhao Yang, Chao Huang, Lianghao Xia, Yuxuan Liang, Yanwei Yu, and Chen-\nliang Li. 2022. Multi-behavior hypergraph-enhanced transformer for sequential\nrecommendation. In Proc. of KDD.\n[150] Jing Yi and Zhenzhong Chen. 2021. Multi-Modal Variational Graph Auto-\nEncoder for Recommendation Systems. IEEE Transactions on Multimedia (2021).\n[151] Zixuan Yi, Xi Wang, Iadh Ounis, and Craig Macdonald. 2022. Multi-modal graph\ncontrastive learning for micro-video recommendation. In Proc. of SIGIR.\n[152] Chunxing Yin, Bilge Acun, Carole-Jean Wu, and Xing Liu. 2021. Tt-rec: Tensor\ntrain compression for deep learning recommendation models. Proc. of MLSys\n(2021).\n[153] Wei Yinwei, Wang Xiang, Nie Liqiang, He Xiangnan, and Chua Tat-Seng. 2021.\nGRCN: Graph-Refined Convolutional Network for Multimedia Recommendation\nwith Implicit Feedback. arXiv preprint arXiv:2111.02036 (2021).\n[154] Tianhe Yu, Saurabh Kumar, Abhishek Gupta, Sergey Levine, Karol Hausman,\nand Chelsea Finn. 2020. Gradient surgery for multi-task learning. Proc. of\nNeurIPS (2020).\n[155] Enming Yuan, Wei Guo, Zhicheng He, Huifeng Guo, Chengkai Liu, and Ruiming\nTang. 2022. Multi-behavior sequential transformer recommender. In Proc. of\nSIGIR.\n[156] Chi Zhang, Rui Chen, Xiangyu Zhao, Qilong Han, and Li Li. 2023. Denois-\ning and Prompt-Tuning for Multi-Behavior Recommendation. arXiv preprint\narXiv:2302.05862 (2023).\n[157] Jinghao Zhang, Yanqiao Zhu, Qiang Liu, Shu Wu, Shuhui Wang, and Liang\nWang. 2021. Mining latent structures for multimedia recommendation. In Proc.\nof ACM MM.\n\n\nConference’17, July 2017, Washington, DC, USA\nXiangyu Zhao, et al.\n[158] Jinghao Zhang, Yanqiao Zhu, Qiang Liu, Mengqi Zhang, Shu Wu, and Liang\nWang. 2022. Latent Structure Mining with Contrastive Modality Fusion for Mul-\ntimedia Recommendation. IEEE Transactions on Knowledge and Data Engineering\n(2022).\n[159] Qianqian Zhang, Xinru Liao, Quan Liu, Jian Xu, and Bo Zheng. 2022. Leaving no\none behind: A multi-scenario multi-task meta learning approach for advertiser\nmodeling. In Proc. of WSDM.\n[160] Qihua Zhang, Junning Liu, Yuzhuo Dai, Yiyan Qi, Yifan Yuan, Kunlun Zheng,\nFan Huang, and Xianfeng Tan. 2022. Multi-Task Fusion via Reinforcement\nLearning for Long-Term User Satisfaction in Recommender Systems. In Proc. of\nKDD.\n[161] Shuai Zhang, Lina Yao, Aixin Sun, and Yi Tay. 2019. Deep learning based\nrecommender system: A survey and new perspectives. ACM computing surveys\n(CSUR) (2019).\n[162] Wenhao Zhang, Wentian Bao, Xiao-Yang Liu, Keping Yang, Quan Lin, Hong Wen,\nand Ramin Ramezani. 2020. Large-scale causal approaches to debiasing post-\nclick conversion rate estimation with multi-task learning. In Proc. of WWW.\n[163] Weifeng Zhang, Jingwen Mao, Yi Cao, and Congfu Xu. 2020. Multiplex graph\nneural networks for multi-behavior recommendation. In Proc. of CIKM.\n[164] Xiaoyan Zhang, Haihua Luo, Bowei Chen, and Guibing Guo. 2020. Multi-view\nvisual Bayesian personalized ranking for restaurant recommendation. Applied\nIntelligence (2020).\n[165] Yifei Zhang, Hua Hua, Hui Guo, Shuangyang Wang, Chongyu Zhong, and Shijie\nZhang. 2023. 3MN: Three Meta Networks for Multi-Scenario and Multi-Task\nLearning in Online Advertising Recommender Systems. In Proc. of CIKM.\n[166] Jiejie Zhao, Bowen Du, Leilei Sun, Fuzhen Zhuang, Weifeng Lv, and Hui Xiong.\n2019. Multiple relational attention network for multi-task learning. In Proc. of\nKDD.\n[167] Xiaoting Zhao, Raphael Louca, Diane Hu, and Liangjie Hong. 2020. The differ-\nence between a click and a cart-add: learning interaction-specific embeddings.\nIn Proc. of WWW.\n[168] Zhong Zhao, Yanmei Fu, Hanming Liang, Li Ma, Guangyao Zhao, and Hongwei\nJiang. 2021. Distillation based Multi-task Learning: A Candidate Generation\nModel for Improving Reading Duration. arXiv preprint arXiv:2102.07142 (2021).\n[169] Yong Zheng and David Xuejun Wang. 2022. A survey of recommender systems\nwith multi-objective optimization. Neurocomputing (2022).\n[170] Jie Zhou, Xianshuai Cao, Wenhao Li, Lin Bo, Kun Zhang, Chuan Luo, and Qian\nYu. 2023. Hinet: Novel multi-scenario & multi-task learning with hierarchical\ninformation extraction. In Proc. of ICDE.\n[171] Xin Zhou. 2022. A Tale of Two Graphs: Freezing and Denoising Graph Structures\nfor Multimodal Recommendation. arXiv preprint arXiv:2211.06924 (2022).\n[172] Chenxu Zhu, Peng Du, Weinan Zhang, Yong Yu, and Yang Cao. 2022. Combo-\nFashion: Fashion Clothes Matching CTR Prediction with Item History. In Proc.\nof KDD.\n[173] Feng Zhu, Yan Wang, Chaochao Chen, Jun Zhou, Longfei Li, and Guanfeng Liu.\n2021. Cross-domain recommendation: challenges, progress, and prospects. In\nProc. of IJCAI.\n[174] Feng Zhu, Mingjie Zhong, Xinxing Yang, Longfei Li, Lu Yu, Tiehua Zhang, Jun\nZhou, Chaochao Chen, Fei Wu, Guanfeng Liu, et al. 2023. DCMT: A Direct Entire-\nSpace Causal Multi-Task Framework for Post-Click Conversion Estimation.\narXiv preprint arXiv:2302.06141 (2023).\n[175] Xinyu Zou, Zhi Hu, Yiming Zhao, Xuchu Ding, Zhongyi Liu, Chenliang Li, and\nAixin Sun. 2022. Automatic expert selection for multi-scenario and multi-task\nsearch. In Proc. of SIGIR.\n\n\n",
  "metadata": {
    "source_file": "dataset/pdfs/arxiv_2502.21195v1.pdf",
    "total_pages": 12,
    "title": "Joint Modeling in Recommendations: A Survey",
    "authors": [
      "Xiangyu Zhao",
      "Yichao Wang",
      "Bo Chen",
      "Jingtong Gao",
      "Yuhao Wang",
      "Xiaopeng Li",
      "Pengyue Jia",
      "Qidong Liu",
      "Huifeng Guo",
      "Ruiming Tang"
    ],
    "abstract": "In today's digital landscape, Deep Recommender Systems (DRS) play a crucial\nrole in navigating and customizing online content for individual preferences.\nHowever, conventional methods, which mainly depend on single recommendation\ntask, scenario, data modality and user behavior, are increasingly seen as\ninsufficient due to their inability to accurately reflect users' complex and\nchanging preferences. This gap underscores the need for joint modeling\napproaches, which are central to overcoming these limitations by integrating\ndiverse tasks, scenarios, modalities, and behaviors in the recommendation\nprocess, thus promising significant enhancements in recommendation precision,\nefficiency, and customization. In this paper, we comprehensively survey the\njoint modeling methods in recommendations. We begin by defining the scope of\njoint modeling through four distinct dimensions: multi-task, multi-scenario,\nmulti-modal, and multi-behavior modeling. Subsequently, we examine these\nmethods in depth, identifying and summarizing their underlying paradigms based\non the latest advancements and potential research trajectories. Ultimately, we\nhighlight several promising avenues for future exploration in joint modeling\nfor recommendations and provide a concise conclusion to our findings.",
    "published_date": "2025-02-28",
    "source": "arxiv"
  }
}