{
  "id": "arxiv_2502.21292v1",
  "text": "Bilevel Optimized Implicit Neural Representation\nfor Scan-Specific Accelerated MRI\nReconstruction\nHongze Yu, Jeffrey A. Fessler, and Yun Jiang\nAbstract— Deep Learning (DL) methods can reconstruct\nhighly accelerated magnetic resonance imaging (MRI)\nscans, but they rely on application-specific large training\ndatasets and often generalize poorly to out-of-distribution\ndata. Self-supervised deep learning algorithms perform\nscan-specific reconstructions, but still require complicated\nhyperparameter tuning based on the acquisition and often\noffer limited acceleration. This work develops a bilevel-\noptimized implicit neural representation (INR) approach for\nscan-specific MRI reconstruction. The method automati-\ncally optimizes the hyperparameters for a given acquisition\nprotocol, enabling a tailored reconstruction without train-\ning data. The proposed algorithm uses Gaussian process\nregression to optimize INR hyperparameters, accommodat-\ning various acquisitions. The INR includes a trainable posi-\ntional encoder for high-dimensional feature embedding and\na small multilayer perceptron for decoding. The bilevel op-\ntimization is computationally efficient, requiring only a few\nminutes per typical 2D Cartesian scan. On scanner hard-\nware, the subsequent scan-specific reconstruction—using\noffline-optimized hyperparameters—is completed within\nseconds and achieves improved image quality compared to\nprevious model-based and self-supervised learning meth-\nods.\nIndex Terms— Implicit neural representation, Bayesian\noptimization, self-supervised deep learning, undersampled\nMRI reconstruction, hyperparameter optimization.\nI. INTRODUCTION\nM\nAGNETIC resonance imaging (MRI) is a diagnostic\nimaging technique that provides excellent soft-tissue\ncontrast without ionizing radiation. However, its prolonged\nacquisition times can pose a challenge in clinical practice.\nTo address this drawback, a common strategy is to develop\nreconstruction algorithms that can recover artifact-free images\nfrom sub-Nyquist sampled data. Parallel imaging techniques\n[1], [2] exploit redundancy among multiple receiver coils.\nClassical methods, however, are constrained by the number\nThis\nwork\nwas\nsupported\nby\nNIH\ngrants\nR37CA263583,\nR01CA284172, and Siemens Healthineers.\nThis work involved human subjects or animals in its research. The\nstudy was HIPAA-compliant and was approved by the Institutional\nReview Board. Informed written consent was obtained from each par-\nticipant.\nHongze Yu and Jeffrey A. Fessler are with the Department of Electri-\ncal Engineering and Computer Science, University of Michigan, Ann Ar-\nbor, MI 48109 USA (e-mail: hongze@umich.edu; fessler@umich.edu).\nYun Jiang is with the Department of Radiology and the Department\nof Biomedical Engineering, University of Michigan, Ann Arbor, MI 48109\nUSA (e-mail: yunjiang@umich.edu).\ngeometry of the coils, leading to potential residual artifacts\nand noise amplification at high acceleration rates. Compressed\nsensing [3], [4] and related model-based methods [5]–[7]\nfurther mitigate aliasing artifacts by enforcing sparsity or low-\nrank constraints and can be combined with parallel imaging to\nachieve higher acceleration rates in dynamic and quantitative\nMRI [8]–[11]. However, their computational overhead limits\ntheir broader clinical adoption [12].\nSupervised deep learning-based methods can offer efficient\nreconstruction once they are trained. Typically, neural net-\nworks are trained using a large fully sampled dataset [13].\nCommon approaches include training the neural network to\nlearn a direct mapping from undersampled images to fully\nsampled images [14], [15], or employing the network as\na regularizer in model-based iterative reconstruction [16],\n[17]. However, these require curated fully sampled training\ndatasets [18] that are often unavailable for many MRI acqui-\nsitions, such as dynamic or diffusion imaging. Moreover, these\npre-trained models often struggle to generalize effectively\nwhen applied to out-of-distribution data [19].\nVarious semi- and self-supervised deep learning-based\nmethods have been proposed to overcome the need for fully\nsampled data in supervised methods, focusing on scan-specific\nreconstruction. For instance, Noise2Recon [20] enforces con-\nsistency between model reconstructions of undersampled scan\ndata and their noise-augmented counterparts, while self-\nsupervised learning via data undersampling (SSDU) [21] di-\nvides undersampled data into subsets to ensure data consis-\ntency and calculate training losses. Other approaches [22],\n[23] rely on implicit regularization through specific network\narchitectures.\nRecent advances in novel-view synthesis and volume ren-\ndering [24] offer a new approach to reconstructing undersam-\npled MRI data. INRs model target signals, such as MR images,\nas continuous coordinate-based functions, inherently enforcing\ncontinuity. In novel-view synthesis, INR learns from multiple\nprojection views to reconstruct a continuous target scene.\nSimilarly, in MRI, INR can leverage the redundancy of coil\nsensitivity to reconstruct alias-free images from undersampled\nMRI data. Previous works have achieved scan-specific INR-\nbased reconstruction by employing fully sampled images as\npriors [25] or adding explicit, hand-crafted regularizers such\nas total variation and low rank [26]–[28]. However, INR-based\nmethods, like other self-supervised reconstruction techniques,\nare sensitive to the choice of hyperparameters. These methods\narXiv:2502.21292v1  [eess.IV]  28 Feb 2025\n\n\n2\ntypically require dedicated hyperparameter tuning (e.g., grid\nor random searches) tailored to specific datasets, considering\nfactors such as anatomy, contrast, sampling pattern. Poorly\ntuned hyperparameters can directly degrade reconstructed im-\nage quality.\nIn this work, we propose a bilevel-optimized INR for\nhyperparameter-optimized, scan-specific MRI reconstruction.\nWe introduce a self-regularized INR network that achieves\nhigh-quality reconstructions without requiring external priors\nby systematically designing the key components, such as posi-\ntional encoder, decoder multilayer perceptron (MLP) and loss\nfunction weighting. To enable automatic hyperparameter tun-\ning, we formulate the reconstruction as a bilevel optimization\nproblem [29], where the lower level is a self-supervised INR\nnetwork and the upper level handles hyperparameter optimiza-\ntion, solved using Bayesian optimization [30]. We divide the\nundersampled single-scan k-space data into mutually exclusive\ntraining and validation sets to enable self-supervision. For each\ncandidate hyperparameter vector, the INR is trained on the\ntraining set, and the validation loss is computed using unseen\ndata. We adopted Bayesian optimization for its derivative-\nfree characteristic and computational efficiency, making it suit-\nable for this global optimization task. The proposed bilevel-\noptimized INR can adapt hyperparameters to various acquisi-\ntion protocols, such as anatomy, sampling pattern, contrast. We\nalso demonstrate that these hyperparameters are transferable\nbetween subjects or similar anatomies scanned using the same\nacquisition protocol. Our proposed method improves image\nquality compared with images reconstructed using state-of-the-\nart self-supervised deep-learning and model-based methods.\nWith offline-optimized hyperparameters, our approach can\nachieve scan-specific MRI reconstruction, in under 6 seconds\nfor a 2D Cartesian scan with matrix size 384 × 384 on a\nsingle NVIDIA A40 GPU. Non-Cartesian reconstruction is\napproximately 5× slower due to non-uniform fast Fourier\ntransform (NUFFT) computation.\nWe also validate hyperparameter transferability across same\nanatomies using interventional MRI (iMRI) with residual\nlearning. Our INR method, hyperparameter-optimized on the\nsame anatomy and trained on the fully sampled first frame\nof an MR-guided biopsy scan, reconstructs subsequent under-\nsampled frames with minimal fine-tuning (under 1 second per\nframe with a matrix size of 128×128). This residual learning\nstrategy potentially enables real-time iMRI reconstruction with\nhighly accelerated acquisition (6×).\nThe main contributions of this study are: (1) we propose a\nscan-specific bilevel-optimized INR for reconstructing under-\nsampled MR data, enabling automatic hyperparameter tuning\nfor each scan; (2) we systematically investigate design choices\nfor key INR components, such as the positional encoder,\nMLP decoder, and loss function, and demonstrate that with\nproper tuning, the INR-based reconstruction can achieve high\nreconstruction quality without explicit regularization; (3) we\ndemonstrate that optimized hyperparameters are transferrable\nacross subjects or similar anatomies scanned with the same\nacquisition using bilevel-optimized INR, while also validating\nthe necessity of tailored hyperparameter tuning for different\nacquisitions; (4) with hyperparameters optimized offline, our\nmethod achieves tailored reconstructions at computation times\nunder 6 seconds, indicating the potential toward clinical trans-\nlation of self-supervised deep learning reconstructions; (5) we\nvalidate the proposed algorithm across a wide range of MR\napplications, including various anatomies, image contrasts,\nfield strengths, and sampling patterns.\nThe remaining materials are organized as follows. Section\nII and III detail the theoretical background and the proposed\nmethod. Section IV describes experiment settings. Section V\nand VI present experiment results and discussions.\nII. BACKGROUND\nA. MR Image Reconstruction\nIn an MRI system with multiple receiver coils, the signal\nfrom the lth coil can be modeled as\nsl(t) =\nZ\ncl(⃗r)f(⃗r)e−i2π⃗k(t)·⃗r d⃗r,\n(1)\nwhere cl(⃗r) is the coil sensitivity, f(⃗r) denotes the finite\nsupport continuous function that represents magnetization, and\n⃗k(t) is the sampling location in k-space at time t. During the\nacquisition, sl(t) is sampled at discrete time points, resulting\nin the measurements yl ∈CM. Let x ∈CN represent the\ndiscretized form of f(#»r ), where #»r ∈RN×d represents the\nCartesian grid of spatial sampling locations. By stacking the\nmeasurements from all L coils, we represent the multi-coil\nforward model [31] as:\ny ≜\n\n\ny1\n...\nyL\n\n= P (IL ⊗F ) C\n|\n{z\n}\nA\nx + ϵ,\nC ≜\n\n\nC1\n...\nCL\n\n.\n(2)\nHere, y ∈CLM is the stacked measurement vector, F ∈\nCM×N represents the discrete Fourier operator, Cl ∈CN×N\nrepresents the sensitivity of the lth coil, and ϵ ∈CLM\ndenotes measurement noise. An optional sampling matrix P ∈\nCLM×LM can be included to account for undersampling k-\nspace.\nWhen the image is fully sampled (LM ≥N), the model can\nbe fully determined with proper coil arrangement. However, to\naccelerate MRI acquisitions, fewer k-space samples (M < N)\nare acquired, typically leading to an underdetermined forward\noperator A. Consequently, the naive least-squares solution is\nnon-unique and introduces undersampling artifacts in images,\nnecessitating a regularizer R(x) in the image reconstruction\nproblem that can be formulated as:\nx∗≜arg min\nx\n∥y −Ax∥2\n2 + λR(x).\n(3)\nCommon choices for R(·) include sparsity- or low-rank-based\nconstraints [3], [32].\nB. Implicit Neural Representation\nAn INR can model the target image f(#»r ) as a continuous\nfunction with respect to a fixed coordinate grid. Instead of\nusing a neural network as an explicit regularizer [16], INR\nleverages a small MLP to learn the parametric representation\nfθ(⃗r) of the image with respect to the network weights\n\n\n3\nθ. By reformulating the optimization problem in (3) as an\noptimization over θ, and denoting f(·) : RN×d →RN×2 as\nthe function that maps coordinates ⃗r ∈RN×d to the stacked\nreal and imaginary parts of the image, the self-supervised INR\nfor MRI reconstruction can be formulated as:\nx ˆθ = f ˆθ(#»r ),\nˆθ = arg min\nθ\n∥y −Afθ(#»r )∥2\n2,\n(4)\nfθ(#»r ) = MθMLP\n\u0000γθEnc(#»r )\n\u0001\n,\n(5)\nwhere ˆθ denotes the optimized network parameters under a\nselected set of hyperparameters, MθMLP represents the MLP,\nand γθEnc is the positional encoding function. The “training”\nprocess at reconstruction time updates the network weights θ\niteratively to minimize the data-fidelity term in (4), while the\nsmall MLP implicitly enforces continuity constraints in the\nreconstructed image.\nIII. METHODOLOGY\nA. Overall Framework\nFig. 1 shows the proposed bilevel optimized INR framework\nfor MR reconstruction, which has two levels: (1) lower-level\nINR-based image reconstruction, and (2) upper-level hyper-\nparameter optimization using the Bayesian Optimization [30]\nwith data split from undersampled k-space [21].\nWe formulate this bilevel optimization problem as:\nβ∗≜arg min\nβ\nLV\n\u0000ˆθ(β)\n\u0001\nsubject to ˆθ(β) ≜arg min\nθ\nLT (β, θ),\n(6)\nwhere\nLV\n\u0000ˆθ(β)\n\u0001\n≜\n\r\rW\n\u0000yval −Af ˆθ(β)(#»r )\n\u0001\r\r2\n2,\nLT (β, θ) ≜\n\r\rW\n\u0000ytrain −Afθ(β)(#»r )\n\u0001\r\r2\n2.\n(7)\nHere, LT (β, θ) denotes the lower-level training loss and\nLV\n\u0000ˆθ(β)\n\u0001\nis the upper-level validation loss. W ∈CLM×LM\nrepresents a k-space weighting operator, emphasizing the\nhigher frequency components. β is a hyperparameter vector,\nincluding ℓ2 regularization strengths λEnc and λMLP, the\nlearning rate τ, and the loss-weight controller δ.\nFollowing [21], we randomly split the undersampled k-\nspace data into a training set T and a validation set V (e.g., an\n80%/20% split). In each upper-level iteration, the algorithm\nselects a hyperparameter vector β and trains an INR by\niteratively passing the vectorized image coordinates into a\nmulti-resolution hash encoder γθ(·) : Rd →RLF , encoding\neach spatial location into a higher-dimensional feature space.\nAn MLP MθMLP(·) : RN×LF →RN×2 decodes these\nfeatures into the real and imaginary parts of the target image\nxθ. The reconstructed image is then passed through the MR\nforward model to produce yθ. The parameters of the encoder\nand decoder are updated by calculating a weighted ℓ2 loss\nbetween yθ and the acquired undersampled k-space ytrain.\nOnce training converges, the validation loss compares the\npredicted k-space with the unseen measurements yval. After\na predefined number of upper-level Bayesian optimization\niterations, the method selects the hyperparameters β∗and the\nassociated reconstruction ˆxβ∗,θ∗having the lowest validation\nloss.\nB. INR for MRI reconstruction\nOur INR approach for MRI reconstruction involves three\nkey components: a positional encoder, a decoder MLP, and\nthe loss function. We outline each component below.\n1) Positional Encoder: Positional encoding lifts fixed spatial\ncoordinates from Rd to a higher-dimensional feature space\nRF , allowing a relatively small MLP decoder to learn high-\nfrequency variations of the target function. In this work, we\nadopt a multiresolution hash grid encoding [33] that arranges\nadditional trainable parameters and stores them in an auxiliary\ndata structure, such as multi-level grids.\nAs illustrated in Fig. 2, the target image fθ(⃗r) is represented\non L grid levels (e.g., L = 16), where each level is divided\ninto (a bl)×(a bl) blocks, a is the size of the coarsest grid, and\nb ∈(1, 2] is the scaling factor between levels. At each level,\nthe feature for a given coordinate is bilinearly interpolated\nfrom the features at the vertices of its enclosing block.\nThe vertex feature ⃗vi is fetched from a trainable parameter\ntable via spatial hash indexing, defined by\nh(⃗v) =\n\u0000 d\nM\ni=1\nvi πi\n\u0001\nmod T,\n(8)\nwhere ⃗v is the vertex coordinate, πi is a large prime number,\nand T is the trainable parameter table size. Stacking all L\nlevels yields a pointwise encoder γθ(⃗r) : Rd →RLF .\nThis design captures both high-resolution detail and conti-\nnuity of function manifold through multiresolution grids and\ninterpolation. It also speeds up training because only the\nparameters around the queried coordinates are updated, unlike\nan MLP where all parameters are backpropagated. The size\nof the trainable hash table is fixed for each level, resulting in\nhash collision in fine resolution levels and inducing a stronger\ngradient that can guide the network training.\n2) Multilayer Perceptron Decoder: The MLP functions as\na decoder that maps the positionally encoded features to\nthe target image intensities. Its learnable function class is\ndetermined by its activation function, width and depth. In this\nwork, we use an 8-layer MLP with 64 neurons per layer and\nReLU activation.\n3) Loss Function: Due to a large magnitude difference\nbetween the lower frequency components at the center and\nthe higher frequency components at the periphery of k-space,\nwe propose a modified self-weighting loss that weights each\nnetwork predicted k-space sample by its magnitude rather than\nseparate real and imaginary channels [28] similar to RGB\nchannels [34]. The loss function is defined as:\nW = Diag\n\u0000|Afθ(#»r )| + δ 1\n\u0001−1,\n(9)\nwhere here the absolute value is applied element-wise. This\nself-weighted loss emphasizes higher frequency components\nand attenuates lower ones, thus avoiding an overly smooth\nreconstruction. It can also be interpreted as a learnable density\ncompensation function that evolves over iterations. Although\nno explicit regularizer is applied, the loss function includes ℓ2\nregularization terms for the encoder and MLP weights. Their\nstrengths are controlled by λEnc and λMLP, respectively.\n\n\n4\nFig. 1.\nProposed bilevel-optimized INR framework. The undersampled data y is split into training and validation sets. In each upper-level Bayesian\noptimization iteration, a hyperparameter vector β is selected and used to train the INR on ytrain. The trained INR is then validated on yval using a\nweighted ℓ2 loss. The final INR reconstruction and hyperparameter set are chosen based on the smallest validation loss.\nFig. 2. Multiresolution Hash Encoding Function γθ.(⃗r) (e.g., L = 2)\nC. Bayesian Optimization\nThe upper-level hyperparameter optimization in (6) is com-\nputationally expensive because each evaluation requires train-\ning a new INR. Using gradient-based methods would be chal-\nlenging due to computational complexity, potential optimiza-\ntion difficulties, and the presence of discrete hyperparameters.\nTo address these issues, we adopt a zeroth-order method called\nBayesian optimization [30] that solves this hyperparameter\noptimization by building a Gaussian Process (GP) regression\nmodel over the objective function f(β). After each evaluation\nof β (i.e., training an INR and measuring the validation loss),\nthe GP posterior p(f(β) | D) is updated, where D denotes the\naccumulated data from all previous evaluations. This surrogate\nmodel yields both a predicted mean µ(β) and uncertainty\nσ(β). To select the next β, we use the upper confidence bound\n(UCB) acquisition function\nαUCB(β) = µ(β) + κ σ(β),\n(10)\nwhere κ balances the trade-off between exploration (high-σ\nregions) versus exploitation (low predicted loss). By iteratively\nupdating the GP and evaluating αUCB, this method efficiently\nconverges toward near-optimal hyperparameters with far fewer\ntotal network trainings compared to grid or random searches.\nD. Implementation Details\nThe proposed bilevel optimized INR tunes four hyperpa-\nrameters in the upper-level problem: the learning rate τ, the\nloss weighting controller δ, and the weight decay terms λEnc\nand λMLP for the encoder and MLP, respectively. We used\n60 upper-level iterations, each consisting of 4000 lower-level\niterations, to ensure convergence of the INR reconstruction.\nAll image coordinates were normalized to (0, 1) in each\ndimension.\nThe Hash encoder included 16 levels with 218 parameters\nper level for 2D image reconstruction. The decoder MLP had\nsix hidden layers, each with 64 ReLU neurons, while the input\nand output layers used no activation.\nCoil maps were estimated using E-SPIRiT [35] from a sepa-\nrate gradient-echo (GRE) scan or from fully sampled center k-\nspace lines. Virtual coil compression [36] and noise prewhiten-\ning [37] were applied before reconstruction. Nonuniform fast\nFourier Transforms [38] for non-Cartesian acquisitions were\nimplemented via the torchkbnufft toolbox [39].\nThe study was implemented in PyTorch 1.12.1 (Python\n3.9) on a high-performance computing cluster using an\nNVIDIA A40 GPU and a 2.9 GHz Intel Xeon Gold 6226R\nCPU with 16 GB of memory. The source code is available\nat\nhttps://github.com/MIITT-MRI-Jianglab/\nBilevel_optim_INR.\nIV. EXPERIMENTS\nA. Experiments\n1) Comparison with prior art: We compared the image\nquality of bilevel optimized INR with several other model-\nbased and self-supervised reconstruction methods, such as\n\n\n5\nCG-SENSE [40], ℓ1-wavelet [3], P-LORAKS [6], and IM-\nJENSE [26]. The comparisons were performed using data\nacquired across various anatomies, sampling patterns, and\nfield strengths. Specifically, we used balanced SSFP (bSSFP)\nand T2-weighted turbo spin echo (TSE) datasets to compare\nCartesian and Poisson undersampling patterns. Additionally,\nwe evaluated the reconstruction results of a healthy cardiac\nvolunteer using a T2-weighted bSSFP sequence on a 0.55T\nscanner. To further demonstrate capabilities of our technique\nfor non-Cartesian sampling, we simulated a spiral acquisition\nfrom a fully sampled T2-weighted TSE prostate dataset at\n3T. The spiral is designed using minimum-time gradient\ndesign [41] with zero-moment compensation, and requires 48\ninterleaves to fully sample the k-space.\n2) Ablation Study of INR Design: We performed experiments\nto determine the most effective formulation of INR for MRI\nreconstruction and validate the choices in Section III-B. We\nexamined the impact of different decoders, such as varying\nnumbers of MLP layers and using a linear layer, as well as\ndifferent positional encoders, including no encoder, frequency\nencoding [24], dense grid encoding [42], and hash encoding\n[33]. For the loss function comparison, we tested several\nweighting strategies, such as identity weighting, density com-\npensation function weighting [43], acquired data weighting,\nand self-weighting as described in (9). We also conducted\nexperiments on activation function, comparing ReLU and\nSinusoidal activation [44].\n3) Hyperparameter Optimization: We examined three hy-\npotheses on hyperparameter optimization in bilevel-optimized\nINR for image reconstruction. (H1: Comparable Quality to\nan Oracle) Our bilevel approach is hypothesized to yield\nreconstructions comparable to an oracle that selects near-\noptimal hyperparameters using fully sampled data for valida-\ntion loss; we evaluated H1 by comparing our reconstructions\nagainst this oracle standard using identical datasets and ac-\nquisition parameters. (H2: Protocol-Specific Optimization) We\ntested whether hyperparameter tuning is necessary for different\nimaging protocols by applying hyperparameters optimized for\nbSSFP to T2-weighted TSE data from the same subject, as-\nsessing performance consistency. (H3: Transferability Across\nSubjects/Anatomies) We hypothesized that hyperparameters\noptimized for one subject or anatomy can be effectively trans-\nferred to another under the same protocol; to test H3, we first\nconducted bSSFP acquisitions on two volunteers, comparing\nreconstructions using each subject’s optimized hyperparame-\nters and those from the other, and then acquired multislice\nprostate T2w imaging to perform a similar comparison across\ndifferent slices.\n4) Real-time interventional MRI: We validated the proposed\nalgorithm’s capability for real-time residual learning and hy-\nperparameter transferability for the same anatomy using the\nMR-guided biopsy liver phantom dataset. We used the fully\nsampled first time frame to optimize the hyperparameters and\npre-train the INR. We then retrospectively 6× undersampled\nsubsequent time frames with 4% autocalibration region signal\n(ACS) lines and fine-tuned the INR for 500 iterations for each\nframe.\nTable I summarizes the acquisition parameters of the above\nTABLE I\nACQUISITION PROTOCOLS AND PARAMETERS\nImaging Type\nCoil No.\nSequence\nMatrix Size\nResolution (mm2 / mm3)\nBrain (3T)\n16\nbSSFP / T2w TSE\n256 × 256\n1 × 1\nCardiac (0.55T)\n15\nT2w bSSFP\n294 × 272\n1.4 × 1.4\nProstate (3T)\n12\nT2w TSE\n384 × 384 × 32\n1 × 1 × 3\niMRI (0.55T)\n24\nbSSFP\n26 × 128 × 128\n2.3 × 2.3\nexperiments. The temporal resolution for the iMRI is 2 seconds\nper frame.\nB. Performance Measurement\nPerformance in this study was quantified using three met-\nrics: Normalized Root-mean-squared Error (NRMSE), Struc-\ntural Similarity Index (SSIM), and Peak Signal-to-noise Ratio\n(PSNR). Reconstructions were compared against the ground\ntruth from fully sampled data in both retrospective and sim-\nulated studies. For all metrics calculations, the coil map\nestimated by E-SPIRiT was used as the region-of-interest\n(ROI) mask and code implementation is based on the scikit-\nimage package1.\nV. RESULTS\nA. Comparisons with other Self-supervised\nReconstruction methods\nFig. 3 compares our proposed approach with other model-\nbased iterative and self-supervised deep-learning methods.\nFor 8× Cartesian undersampled bSSFP brain experiments\n(Fig. 3(a)), CG-SENSE introduces notable noise across the\nbrain, and ℓ1-Wavelet, P-LORAKS, and IMJENSE exhibit\nresidual artifacts from the sampling pattern. In contrast, the\nproposed method shows only minor residual artifacts and\nachieves a PSNR more than 5 dB higher than the other\napproaches.\nFig. 3(b) presents results from 20× Poisson undersampled\nexperiments with a central 10 × 10 pixel auto-calibration\nregion. Both CG-SENSE and P-LORAKS show visible non-\nstructured noise in the whole brain. In contrast, ℓ1-wavelet,\nIMJENSE, and the proposed bilevel INR display visually\nartifact-free reconstructions, with our method outperforming\nothers supported by all metrics. INR-based methods (i.e., IM-\nJENSE and ours) benefit from the relatively uniform sampling\npattern, which results in non-structural artifacts. These artifacts\nare easier to remove by INR, because of its strength in learning\ncontinuous and smooth function manifolds.\nFig. 3(c) compares methods on a non-gated cardiac dataset\nat 0.55T, acquired via a T2-weighted bSSFP sequence. The\nproposed bilevel INR reduces noise and suppresses most mo-\ntion artifacts by its implicit regularization on continuity. Other\nmethods either fail to remove noise (CG-SENSE, IMJENSE)\nor retain motion artifacts (P-LORAKS, IMJENSE). The ℓ1-\nWavelet result appears overly smooth.\nFinally, for simulated 8× spiral undersampling (Fig. 3(d)),\nall model-based methods show spiral undersampling artifacts.\nOur method achieves better metrics and yields nearly artifact-\nfree reconstructions. IMJENSE is omitted here because it only\nsupports Cartesian sampling patterns.\n1https://scikit-image.org/\n\n\n6\nFig. 3. Method comparisons. (a) Brain volunteer at 3T using bSSFP of 1×1 mm2 resolution. (b) Brain volunteer at 3T using T2w TSE of 1×1 mm2\n(c) Cardiac volunteer at 0.55T using T2w bSSFP of 1.4×1.4 mm2 resolution. (d) Prostate volunteer at 3T using T2w TSE of 1×1 mm2 resolution.\nDetailed acquisition protocols are shown in Table I.\nB. Methods ablation study\nFig. 4 presents ablation experiments on key components\nof the bilevel-optimized INR. Fig. 4(a) compares decoders\nof varying depths against a linear layer under identical hy-\nperparameters. Except for the single-layer MLP, all decoders\nconverge to similar performance based on quantitative metrics.\nEven a linear layer can decode the positionally encoded\nfeatures effectively, indicating the encoder’s dominant role in\nthe reconstruction pipeline.\nFig. 4(b) evaluates different positional encoders on a 6×\nCartesian undersampled T2-weighted TSE dataset. Without\nencoding or with frequency encoding, the model struggles to\ncapture fine details in the brain, while dense grid and hash\ngrid encodings yield comparable metrics. However, dense grid\nrequires 20× memory and 15× of training time\nFig. 4(c) focuses on loss-function weighting, tested on\na spiral undersampled prostate dataset. The proposed self-\nweighting scheme in (9) has the best reconstruction quality,\ncapturing correct contrast and detailed structure. No loss\nweighting causes visible blurriness across the pelvic region.\nUsing Pipe’s density compensation function [43] ranks second,\nwith 0.06 NRMSE, 0.97 SSIM, and 39.47 dB PSNR compared\nto 0.04, 0.98, and 41.79 dB from our approach. Substituting\nthe acquired data for the predicted k-space in each iteration\nleads to a bad local minimum during training, which shows\nincorrect contrast and degraded metrics.\nTABLE II\nCOMPARISON OF HYPERPARAMETER VALUES FOUND BY EMPIRICAL\nTUNING VS. BAYESIAN OPTIMIZATION. (FIG. 5 (A),(B))\nλENC\nλMLP\nlr\nδ\nEmpirical Tuning\n1.0 × 10−5\n1.0 × 10−10\n1.0 × 10−3\n1 × 10−4\nBayesOpt (R=6)\n2.6 × 10−4\n1.0 × 10−7\n9.3 × 10−3\n2 × 10−4\nBayesOpt (R=8)\n3.6 × 10−3\n7.2 × 10−6\n4.4 × 10−4\n2 × 10−4\nC. Hyperparameter optimization and transferability\nexperiments\nFig. 5 illustrates the hyperparameter optimization results.\nFig. 5(a) and (b) show that Bayesian optimization yields\nnearly optimal results compared to the oracle optimization\nacross NRMSE, SSIM, and PSNR for both R = 6 and\nR = 8 on volunteer 1. By contrast, empirical tuning leads to\nresidual artifacts near the brain center. The empirically tuned\nhyperparameters were chosen based on previously successful\nreconstructions for other sequences and resolutions. Table II\nlists the hyperparameter values in each case. Except for the\nloss-weighting controller δ, all other hyperparameters differ\nbetween R = 6 and R = 8, indicating that each sampling\npattern benefits from a tailored optimization.\nFig. 5(c) displays the reconstruction of the same bSSFP\nsequence with identical acquisition parameters and similar\nslice position for volunteer 2. Bayesian optimization achieves\nperformance comparable to oracle optimization across all\nmetrics. The hyperparameters optimized for volunteer 1 adapt\n\n\n7\nFig. 4. Ablation study. (a) Decoder comparison with fixed Hash Encoder\n(i.e., Linear layer vs 1/2/3/6/8 layer MLP). (b) Encoder comparison\nwith fixed Decoder MLP. (c) Loss function weighting comparison. (d)\nActivation function comparison.\nwell to volunteer 2, with similar NRMSE and SSIM, and\nonly slightly worse PSNR, showing that hyperparameters\noptimized for bilevel INR can be transferred between similar\nacquisitions.\nFig. 5(d) uses a T2-weighted TSE scan from volunteer 1\nat the same slice position to demonstrate the sequence depen-\ndence of INR-based reconstruction. The performance using\nhyperparameters optimized for the bSSFP scan of volunteer 1\nis 5.41 dB worse in PSNR and 0.05 higher in NRMSE\ncompared to tailored Bayesian Optimization. The resulting\nimages appear more blurry because bSSFP sequences gen-\nerally have lower SNR than TSE, and optimizing for bSSFP\ntends toward stronger denoising (e.g., λEnc = 2.6e −4 in\n(a)). In contrast, T2-weighted TSE scans keep anatomical\nstructures more clearly and thus need less regularization (e.g.,\nλEnc = 1.2e −5 in (d)) .\nFig. 6 further demonstrates the transferability of hyperpa-\nrameters across anatomically similar regions. Reconstructions\nfor two 6× undersampled pelvic slices are compared using\nboth tailored hyperparameters (optimized specifically for each\nslice) and hyperparameters transferred from the other slice.\nThe transferred hyperparameters yield good reconstructions,\nwith only small decreases in PSNR (0.41 dB and 0.58 dB,\nrespectively) compared to the tailored results.\nD. Examples of tuned hyperparameters\nFig. 7 demonstrates the impact of optimized hyperparam-\neters in the upper level of (6). The encoder’s ℓ2 regulariza-\ntion strength λEnc adjusts the degree of regularization on\nthe positionally encoded feature representation; sub-optimal\nchoices lead to over- or under-regularization. Similarly, the\nloss-weighting controller δ balances the trade-off between\nimage smoothness and fine details. According to (9), a larger\nδ diminishes higher-frequency components relative to the\nlower-frequency terms, resulting in blurrier reconstructions.\nConversely, smaller δ emphasizes high-frequency components,\nproducing clearer but potentially more aliased images.\nE. Real-time iMRI\nFig. 8 compares real-time interventional MRI reconstruc-\ntions of a liver phantom. The first frame was fully sampled\nto train the INR, while subsequent frames were retrospec-\ntively undersampled by 6×. Our INR-based residual learning\nreconstruction outperforms GRAPPA and CG-SENSE by over\n5 dB in PSNR, with fewer visible artifacts and noise. The\nneedle and target biopsy region remain clearly distinguishable.\nBecause the INR is pre-trained on the first frame, reconstruct-\ning each subsequent frame takes only 1 s (< 500 iterations),\nwhich is faster than the 2 s temporal resolution required for\nthis real-time acquisition. We also compared this residual\nlearning scheme with frame-specific tailored reconstruction, in\nwhich the complete bilevel optimization is performed for each\nframe. The residual learning reconstruction achieves similar\nquantitative metrics. A movie showing the full time-series\nreconstruction, including comparisons at different acceleration\nfactors (R = 4/6), is provided in the supplementary material.\nVI. DISCUSSION\nThis paper proposes a bilevel-optimized INR framework\nfor hyperparameter-optimized, scan-specific MRI reconstruc-\ntion for accelerated MRI acquisitions. Existing self-supervised\ndeep learning methods rely on task- and subject-dependent\nhyperparameter tuning [23], [25], [26], which can be imprac-\ntical in clinical settings. In contrast, we formulate the MRI\nreconstruction as a bilevel optimization problem, where the\nupper level optimizes hyperparameters and the lower level\nperforms INR-based reconstruction given sampled hyperpa-\nrameters. This approach automatically determines protocol-\nspecific hyperparameters, providing improved and tailored\nreconstruction quality.\nWe validated the proposed method on in vivo scans of\nhealthy volunteers across various anatomies, contrasts, sam-\npling patterns, and field strengths. Our bilevel-optimized INR\nachieved higher quantitative metrics (NRMSE, SSIM, and\nPSNR) than both model-based and self-supervised INR meth-\nods. Furthermore, we showed that the optimized hyperparam-\neters can be transferred to other subjects or similar anatomies\nscanned under the same protocol.\nA. Analysis of self-supervised bilevel optimization\nThe primary challenge of supervised deep learning methods\nis the need for large, application-specific training datasets\nand\ntheir\nlimited\ngeneralization\nto\nunseen\nacquisitions.\nSelf-supervised deep learning alleviates this issue by per-\nforming scan-specific reconstruction. However, existing self-\nsupervised methods require dedicated hyperparameter opti-\nmization for each dataset. Current approaches either tune\n\n\n8\nFig. 5.\nDemonstration of hyperparameter optimization using Bayesian Optimization. (a) and (b) show comparisons of bSSFP acquisitions at\nacceleration factors R = 6 and R = 8 for volunteer 1. (c) shows comparison of bSSFP acquisition for volunteer 2 at R = 6, illustrating that\nhyperparameters are transferable to a different subject for the same imaging sequence. (d) shows a comparison of a T2w TSE acquisition from\nvolunteer 1 in (a) at R = 6, illustrating that different sequences require tailored hyperparameter optimization. Acquisition parameters are provided\nin Table I.\nFig. 6.\nDemonstration of hyperparameter transferability. Reconstruc-\ntions of two slices from a multislice prostate acquisition are shown\n(6× Cartesian undersampled). Each slice is reconstructed with both\nits own optimized hyperparameters and those from the other slice,\nindicating that the optimized hyperparameters are transferable across\nsimilar anatomy under the same acquisition.\nempirically [23], [25] or use population-based hyperparameter\noptimization [26].\nThis study addresses these limitations by combining au-\ntomatic hyperparameter optimization and scan-specific self-\nsupervised reconstruction. Instead of using population-based\nhyperparameter optimization, we split the undersampled data\ninto further undersampled training and validation sets, inspired\nby SSDU [21], to achieve self-supervision. We then employ\nBayesian Optimization for the upper-level search because of\nits efficiency when evaluating multiple hyperparameters in an\nexpensive lower-level INR-based image reconstruction (i.e.,\ntraining an INR). Bayesian Optimization also handles discrete\ninputs and only requires a fixed number of iterations (e.g., 20\nfor initialization and 40 for Gaussian regression).\nWe\nfocus\non\nfour\nhyperparameters\nthat\nare\nhighly\napplication-dependent: the weight decay for encoder and de-\ncoder parameters, the learning rate, and the loss-weighting\ncontroller. Both weight decay parameters balance the trade-\noff between noise robustness and structural detail, where λEnc\nregularizes positionally encoded latent features and λMLP\ndirectly regularizes the learned function manifolds. λEnc dom-\ninates due to the hash encoder’s higher trainable weight count\ncompared to the compact MLP. As shown in Fig. 7, the loss-\nweighting controller further optimizes the balance between\nblurriness and resolution in the reconstruction. We incorporate\nthe learning rate into hyperparameter optimization because it\njointly influences reconstruction results with the other three\nparameters, and its optimal value is also interdependent on\nthe others.\nWe also considered additional hyperparameters such as the\nMLP’s width and depth, but observed that their influence\nremains relatively stable across different datasets. Fig. 4\nshows that even a linear-layer decoder can produce high-\nquality reconstructions, demonstrating the positional encoder’s\ndominant contribution for the reconstruction. For the Hash\nencoder, we tested a table size of ≥216 and a finest resolution\ndetermined by scaling factor b ≥1.5, both of which yielded\ncomparable performance across various scans. Overall, over-\nparameterization with optimized self-regularization provided\nby weight decay is another reason why the hash-encoded INR-\nbased approach can reconstruct highly accelerated MRI scans.\n\n\n9\nFig. 7. Illustrating choosing hyperparameter for Bayesian Optimization;\n(a),(c) ℓ2 regularization strength for Hash Encoder parameters. (b),(d)\nSelf-weighting loss stability value δ that controls the emphasis on higher\nfrequency k-space components.\nFig. 8.\nComparisons of real-time iMRI reconstructions. The INR is\npre-trained on the fully sampled first frame. Each subsequent frame\nis 6× undersampled with 6 ACS lines and reconstructed using only\n500 residual-learning iterations. Reconstructions of two selected frames\nobtained using our method with the fully sampled prior and frame-\nspecific tailored reconstructions without prior are compared with those\nfrom GRAPPA and CG-SENSE. Acquisition parameters are provided in\nTable I.\nB. Analysis of components of Bilevel Optimized INR\nThis study also provides experiments to analyze the effect\nand selection of key components in an INR for scan-specific\nMRI reconstruction. The main components of an INR are the\npositional encoder, the decoder MLP, and the loss function.\nFig. 4(b) compares no encoding, frequency encoding [24],\ndense grid encoding [42], and hash grid encoding [33]. Unlike\nview synthesis, which leverages multiple view images for\ntraining, no encoding and frequency encoding are both slow\nto train and even unable to capture fine MR image details. By\ncontrast, dense grid and hash grid encodings can reconstruct\nimages effectively due to over-parameterization. However, the\ndense grid demands more memory and training time since\nit stores weights for every grid corner. Fig. 4(a) compares\nMLPs of various depths against a linear layer. All decoders\nachieve similar performance upon convergence, consistent\nwith prior findings [33] that the encoder primarily solves\nthe inverse problem. However, our activation function differs\nfrom SIREN [44], which applies sinusoidal activation for\nview synthesis. In this study, ReLU activation yielded more\nstable training and was less prone to overfitting, whereas\nSIREN tended to introduce residual artifacts. We attribute\nthis to: (1) this task is heavily over-parametrized as only\na 2D MR image is reconstructed instead of full 3D view\nlike in SIREN, and (2) the implicit regularization from the\n“dying ReLU” phenomenon [45], which helps limit overfitting.\nThis also explains why previous Hash-encoded INR MRI\nreconstruction methods [26], [27] often required additional\nexplicit priors, as sinusoidal activation was used. We interpret\nthe loss weighting as a learned density compensation function\n(DCF). In non-Cartesian reconstructions, DCF emphasizes\nthe higher-frequency components (much smaller in magnitude\ncompared to low-frequency components) to avoid image blur-\nring. A similar rationale applies to INR-based reconstruction:\na standard ℓ2 loss in k-space could lead the MLP to learn\na conditional mean of the target k space distribution in the\nregression task [46]. Our experiments show that a learned self-\nweighting scheme provides the best performance, displayed in\nFig. 4(c).\nC. Limitations and Future Work\nThe proposed bilevel-optimized INR still requires coil sen-\nsitivity maps estimated from a low-resolution GRE pre-scan\nor the center of k-space. Although the method is faster than\nmost self-supervised reconstruction approaches, it remains\nslower than SENSE, GRAPPA, and similar to other model-\nbased compressed sensing algorithms if they are also imple-\nmented in PyTorch with GPU support and INR is trained\nfrom scratch. The time difference is only a few seconds for\n2D reconstructions but can become significant for higher-\ndimensional datasets. One potential solution is to use a model-\nbased reconstruction as a warm start for the INR.\nAnother challenge arises from the high dimensionality of 3D\nor dynamic imaging, which can require excessive memory use\nduring training. Unlike prior INR applications (e.g., gigapixel\nimage fitting [33]), where the loss is computed in the image\ndomain and coordinates can be divided into smaller batches,\nMRI has a forward model involving a FFT that is most efficient\nwhen the entire image is used at each iteration. Consequently,\nthe batch size should be 1, and all coordinates should be fed\ninto the MLP at once. A region-of-interest (ROI) mask can\nreduce the coordinate space, but may still be inadequate for\nlarge 3D volumes.\nFinally, although bilevel optimization with weight decay\nenhances noise robustness, the powerful function-fitting ca-\npacity of INR can still yield noisy reconstructions when\nthe undersampled k-space data have low SNR or a high\nacceleration factor. Improving the noise robustness of INR-\nbased MRI reconstruction without additional regularizers or\ndenoisers remains an open research question, especially critical\nfor applications like diffusion MRI where SNR inherently\nlimits the reconstruction quality.\n\n\n10\nACKNOWLEDGMENT\nThis study was supported by NIH grants R37CA263583,\nR01CA284172, and Siemens Healthineers.\nREFERENCES\n[1] K. P. Pruessmann, M. Weiger, M. B. Scheidegger, and P. Boesiger,\n“SENSE: Sensitivity encoding for fast MRI,” Magn. Reson. Med.,\nvol. 42, no. 5, pp. 952–962, Nov. 1999.\n[2] M. A. Griswold et al., “Generalized autocalibrating partially parallel\nacquisitions (GRAPPA),” Magn. Reson. Med., vol. 47, no. 6, pp. 1202–\n1210, Jun. 2002.\n[3] M. Lustig, D. L. Donoho, J. M. Santos, and J. M. Pauly, “Compressed\nsensing MRI,” IEEE Signal Process. Mag., vol. 25, no. 2, pp. 72–82,\n2008.\n[4] K. T. Block, M. Uecker, and J. Frahm, “Undersampled radial MRI\nwith multiple coils. Iterative image reconstruction using a total variation\nconstraint,” Magn. Reson. Med., vol. 57, no. 6, pp. 1086–1098, Jun.\n2007.\n[5] J. P. Haldar, “Low-rank modeling of local k-space neighborhoods\n(LORAKS) for constrained MRI,” IEEE Trans. Med. Imag., vol. 33,\nno. 3, pp. 668–681, Mar. 2014.\n[6] J. P. Haldar and J. Zhuo, “P-LORAKS: Low-rank modeling of local k-\nspace neighborhoods with parallel imaging data,” Magn. Reson. Med.,\nvol. 75, no. 4, pp. 1499–1514, Apr. 2016.\n[7] K. H. Jin, D. Lee, and J. C. Ye, “A general framework for compressed\nsensing and parallel MRI using annihilating filter based low-rank Hankel\nmatrix,” IEEE Trans. Comput. Imag., vol. 2, no. 4, pp. 480–495, 2016.\n[8] H. Jung, K. Sung, K. S. Nayak, E. Y. Kim, and J. C. Ye, “k-t FOCUSS:\na general compressed sensing framework for high resolution dynamic\nMRI,” Magn. Reson. Med., vol. 61, no. 1, pp. 103–116, Jan. 2009.\n[9] L. Feng et al., “Golden-angle radial sparse parallel MRI: combination of\ncompressed sensing, parallel imaging, and golden-angle radial sampling\nfor fast and flexible dynamic volumetric MRI,” Magn. Reson. Med.,\nvol. 72, no. 3, pp. 707–717, Sep. 2014.\n[10] L. Feng, L. Axel, H. Chandarana, K. T. Block, D. K. Sodickson, and\nR. Otazo, “XD-GRASP: Golden-angle radial MRI with reconstruction of\nextra motion-state dimensions using compressed sensing,” Magn. Reson.\nMed., vol. 75, no. 2, pp. 775–788, Feb. 2016.\n[11] G. L. da Cruz, A. Bustin, O. Jaubert, T. Schneider, R. M. Botnar,\nand C. Prieto, “Sparsity and locally low rank regularization for MR\nfingerprinting,” Magn. Reson. Med., vol. 81, no. 6, pp. 3530–3543, Jun.\n2019.\n[12] J. C. Ye, “Compressed sensing MRI: A review from signal processing\nperspective,” BMC Biomedical Engineering, vol. 1, p. 8, Mar. 2019.\n[13] J. Zbontar et al., “fastMRI: An open dataset and benchmarks for\naccelerated MRI,” 2018, arXiv preprint arXiv:1811.08839. [Online].\nAvailable: https://arxiv.org/abs/1811.08839\n[14] K. Kwon, D. Kim, and H. Park, “A parallel MR imaging method using\nmultilayer perceptron,” Medical Physics, vol. 44, no. 12, pp. 6209–6224,\n2017.\n[15] C. M. Hyun, H. P. Kim, S. M. Lee, S. Lee, and J. K. Seo, “Deep learning\nfor undersampled MRI reconstruction,” Physics in Medicine & Biology,\nvol. 63, no. 13, p. 135007, Jun. 2018.\n[16] H. K. Aggarwal, M. P. Mani, and M. Jacob, “MoDL: Model-based deep\nlearning architecture for inverse problems,” IEEE Trans. Med. Imag.,\nvol. 38, no. 2, pp. 394–405, 2019.\n[17] J. Zhang and B. Ghanem, “ISTA-Net: Interpretable optimization-inspired\ndeep network for image compressive sensing,” in Proc. CVPR, 2018, pp.\n1828–1837.\n[18] F. Knoll et al., “Deep-learning methods for parallel magnetic resonance\nimaging reconstruction: A survey of the current approaches, trends, and\nissues,” IEEE Signal Proc. Mag., vol. 37, no. 1, pp. 128–140, 2020.\n[19] G. M˚artensson et al., “The reliability of a deep learning model in\nclinical out-of-distribution MRI data: A multicohort study,” Medical\nImage Analysis, vol. 66, p. 101714, 2020.\n[20] A. D. Desai et al., “Noise2Recon: Enabling SNR-robust MRI reconstruc-\ntion with semi-supervised and self-supervised learning,” Magn. Reson.\nMed., vol. 90, no. 5, pp. 2052–2070, 2023.\n[21] B. Yaman, S. Hosseini, S. Moeller, J. Ellermann, K. U˘gurbil, and\nM. Akc¸akaya, “Self-supervised learning of physics-guided reconstruc-\ntion neural networks without fully sampled reference data,” Magn.\nReson. Med., vol. 84, no. 6, pp. 3172–3191, 2020.\n[22] D. Ulyanov, A. Vedaldi, and V. Lempitsky, “Deep image prior,”\n2017, arXiv preprint arXiv:1711.10925. [Online]. Available: https:\n//arxiv.org/abs/1711.10925\n[23] A. P. Leynes, N. Deveshwar, S. S. Nagarajan, and P. E. Z. Larson,\n“Scan-specific self-supervised Bayesian deep non-linear inversion for\nundersampled MRI reconstruction,” IEEE Trans. Med. Imag., vol. 43,\nno. 6, pp. 2358–2369, 2024.\n[24] B. Mildenhall, P. P. Srinivasan, M. Tancik, J. T. Barron, R. Ramamoorthi,\nand R. Ng, “NeRF: Representing scenes as neural radiance fields for\nview synthesis,” in Proc. ECCV, 2020.\n[25] L. Shen, J. Pauly, and L. Xing, “NeRP: Implicit neural representation\nlearning with prior embedding for sparsely sampled image reconstruc-\ntion,” IEEE Trans. Neural Netw. and Learn. Syst., vol. 35, no. 1, pp.\n770–782, 2024.\n[26] R. Feng et al., “IMJENSE: Scan-specific implicit representation for joint\ncoil sensitivity and image estimation in parallel MRI,” IEEE Trans. on\nMed. Imag., vol. 43, no. 4, pp. 1539–1553, 2024.\n[27] B. Liu, H. She, and Y. P. Du, “Scan-specific unsupervised highly accel-\nerated non-cartesian CEST imaging using implicit neural representation\nand explicit sparse prior,” IEEE Trans. Biomed. Eng., vol. 71, no. 10,\npp. 3032–3045, 2024.\n[28] J. Feng et al., “Spatiotemporal implicit neural representation for unsu-\npervised dynamic MRI reconstruction,” IEEE Trans. Med. Imag., pp.\n1–1, 2025.\n[29] C. Crockett and J. A. Fessler, “Bilevel methods for image reconstruc-\ntion,” Foundations and Trends® in Signal Processing, vol. 15, no. 2–3,\np. 121–289, 2022.\n[30] P. I. Frazier, “A tutorial on Bayesian optimization,” 2018, arXiv preprint\narXiv:1807.02811. [Online]. Available: https://arxiv.org/abs/1807.02811\n[31] J. A. Fessler, “Optimization methods for magnetic resonance image\nreconstruction: Key models and optimization algorithms,” IEEE Signal\nProc. Mag., vol. 37, no. 1, pp. 33–40, 2020.\n[32] B. Zhao, J. P. Haldar, C. Brinegar, and Z.-P. Liang, “Low rank matrix\nrecovery for real-time cardiac MRI,” in Proc. IEEE Int. Symp. on\nBiomed. Imag. (ISBI): From Nano to Macro, 2010, pp. 996–999.\n[33] T. M¨uller, A. Evans, C. Schied, and A. Keller, “Instant neural graphics\nprimitives with a multiresolution hash encoding,” ACM Trans. Graph.,\nvol. 41, no. 4, pp. 102:1–102:15, Jul. 2022.\n[34] B. Mildenhall, P. Hedman, R. Martin-Brualla, P. P. Srinivasan, and J. T.\nBarron, “NeRF in the dark: High dynamic range view synthesis from\nnoisy raw images,” in Proc. CVPR, 2022.\n[35] M. Uecker et al., “ESPIRiT–an eigenvalue approach to autocalibrating\nparallel MRI: Where SENSE meets GRAPPA,” Magn. Reson. Med.,\nvol. 71, no. 3, pp. 990–1001, Mar. 2014.\n[36] F. Huang, S. Vijayakumar, Y. Li, S. Hertel, and G. R. Duensing, “A\nsoftware channel compression technique for faster reconstruction with\nmany channels,” Magn. Reson. Imag., vol. 26, no. 1, pp. 133–141, 2008.\n[37] M. S. Hansen and P. Kellman, “Image reconstruction: An overview for\nclinicians,” J. Magn. Reson. Imaging, vol. 41, no. 3, pp. 573–585, Mar.\n2015.\n[38] J. A. Fessler and B. P. Sutton, “Nonuniform fast Fourier transforms using\nmin-max interpolation,” IEEE Trans. Signal Process., vol. 51, no. 2, pp.\n560–574, 2003.\n[39] M. J. Muckley, R. Stern, T. Murrell, and F. Knoll, “TorchKbNufft: A\nhigh-level, hardware-agnostic non-uniform fast Fourier transform,” in\nISMRM Workshop on Data Sampling & Image Reconstruction, 2020.\n[40] O. Maier et al., “CG-SENSE revisited: Results from the first ISMRM\nreproducibility challenge,” Magn. Reson. Med., vol. 85, no. 4, pp. 1821–\n1839, Apr. 2021.\n[41] B. A. Hargreaves, D. G. Nishimura, and S. M. Conolly, “Time-optimal\nmultidimensional gradient waveform design for rapid imaging,” Magn.\nReson. Med., vol. 51, no. 1, pp. 81–92, 2004.\n[42] J. N. P. Martel, D. B. Lindell, C. Z. Lin, E. R. Chan, M. Monteiro, and\nG. Wetzstein, “Acorn: adaptive coordinate networks for neural scene\nrepresentation,” ACM Trans. Graph., vol. 40, no. 4, Jul. 2021.\n[43] J. G. Pipe and P. Menon, “Sampling density compensation in MRI:\nRationale and an iterative numerical solution,” Magn. Reson. Med.,\nvol. 41, no. 1, pp. 179–186, Jan. 1999.\n[44] V. Sitzmann, J. N. Martel, A. W. Bergman, D. B. Lindell, and\nG. Wetzstein, “Implicit neural representations with periodic activation\nfunctions,” in Proc. NIPS, 2020.\n[45] L. Lu, Y. Shin, Y. Su, and G. E. Karniadakis, “Dying ReLU and\ninitialization: Theory and numerical examples,” Communications in\nComputational Physics, vol. 28, no. 5, p. 1671–1706, Jan. 2020.\n[Online]. Available: http://dx.doi.org/10.4208/cicp.OA-2020-0165\n[46] C. M. Bishop, Pattern Recognition and Machine Learning.\nSpringer,\n2006.\n\n\n",
  "metadata": {
    "source_file": "dataset/pdfs/arxiv_2502.21292v1.pdf",
    "total_pages": 10,
    "title": "Bilevel Optimized Implicit Neural Representation for Scan-Specific Accelerated MRI Reconstruction",
    "authors": [
      "Hongze Yu",
      "Jeffrey A. Fessler",
      "Yun Jiang"
    ],
    "abstract": "Deep Learning (DL) methods can reconstruct highly accelerated magnetic\nresonance imaging (MRI) scans, but they rely on application-specific large\ntraining datasets and often generalize poorly to out-of-distribution data.\nSelf-supervised deep learning algorithms perform scan-specific reconstructions,\nbut still require complicated hyperparameter tuning based on the acquisition\nand often offer limited acceleration. This work develops a bilevel-optimized\nimplicit neural representation (INR) approach for scan-specific MRI\nreconstruction. The method automatically optimizes the hyperparameters for a\ngiven acquisition protocol, enabling a tailored reconstruction without training\ndata. The proposed algorithm uses Gaussian process regression to optimize INR\nhyperparameters, accommodating various acquisitions. The INR includes a\ntrainable positional encoder for high-dimensional feature embedding and a small\nmultilayer perceptron for decoding. The bilevel optimization is computationally\nefficient, requiring only a few minutes per typical 2D Cartesian scan. On\nscanner hardware, the subsequent scan-specific reconstruction-using\noffline-optimized hyperparameters-is completed within seconds and achieves\nimproved image quality compared to previous model-based and self-supervised\nlearning methods.",
    "published_date": "2025-02-28",
    "source": "arxiv"
  }
}