{
  "id": "arxiv_2502.20347v1",
  "text": "Modeling Driver Behavior in Speed Advisory Systems: Koopman-based\nApproach with Online Update\nMehmet Fatih Ozkan1, Jeff Chrstos1, Marcello Canova1,2 and Stephanie Stockar2\nAbstract— Accurate driver behavior modeling is essential for\nimproving the interaction and cooperation of the human driver\nwith the driver assistance system. This paper presents a novel\napproach for modeling the response of human drivers to visual\ncues provided by a speed advisory system using a Koopman-\nbased method with online updates. The proposed method\nutilizes the Koopman operator to transform the nonlinear\ndynamics of driver-speed advisory system interactions into a\nlinear framework, allowing for efficient real-time prediction.\nAn online update mechanism based on Recursive Least Squares\n(RLS) is integrated into the Koopman-based model to ensure\ncontinuous adaptation to changes in driver behavior over time.\nThe model is validated using data collected from a human-\nin-the-loop driving simulator, capturing diverse driver-specific\ntrajectories. The results demonstrate that the offline learned\nKoopman-based model can closely predict driver behavior and\nits accuracy is further enhanced through an online update\nmechanism with the RLS method.\nI. INTRODUCTION\nIn recent years, advanced driver assistance systems\n(ADAS) such as lane-keeping assist, adaptive cruise control,\nand automatic emergency braking have been integrated into\nvehicles to enhance both safety and driver comfort. More\nrecently, there has been a shift towards extending the use\nof ADAS to improve vehicle energy efficiency. For instance,\nby incorporating advanced sensing and communication tech-\nnologies, ADAS can provide real-time speed recommenda-\ntions to drivers that result in vehicle energy savings [1]–[3].\nOn the other hand, these recommendations might be disre-\ngarded by the driver due to personal preferences, challenges\nin interpreting audio/visual cues or external factors such as\nweather and surrounding vehicles, thereby reducing the po-\ntential benefits of optimized speed advisories. Furthermore,\neven when attempting to follow the reference, there is no\nguarantee that the outcomes will closely match the intended\nguidance. Therefore, it is necessary to develop models that\npredict human driver responses to ADAS recommendations,\nimproving the system’s effectiveness and efficiency by align-\ning suggestions with actual driver behavior.\nDriver behavior modeling has been widely researched in\nthe literature [4], though understanding driver response to\nactions or suggestions provided by ADAS is still an emerging\nfield. Existing approaches for driver behavior modeling can\nbe classified into physics-based, theory-based, and data-\ndriven models [5]. Physics-based models use mathematical\n1Center\nfor\nAutomotive\nResearch,\nThe\nOhio\nState\nUniversity,\nColumbus,\nOH,\nUSA.\n2Department\nof\nMechanical\nand\nAerospace\nEngineering,\nThe\nOhio\nState\nUniversity,\nColumbus,\nOH,\nUSA.\nEmails:\nozkan.25@osu.edu, chrstos.1@osu.edu,\ncanova.1@osu.edu, stockar.1@osu.edu\nformulations to represent the physical dynamics of driving,\nsuch as acceleration and deceleration. Theory-based models\naim to capture the underlying cognitive mechanisms and\nhuman factors influencing driving behavior, such as attention,\nrisk perception, and decision-making under uncertainty [6].\nDespite the intuitive nature of the physics-based and theory-\nbased approaches, their reliance on fixed model parameters\nand limited real-time adaptability reduces their effectiveness\nin capturing the unpredictable behaviors of drivers under\nreal-world conditions, where online learning is essential [7].\nOn the other hand, data-driven models offer a more straight-\nforward path to online learning because they are designed to\nlearn from data and adapt quickly and dynamically to new\nobservations [8].\nTraditional data-driven approaches have relied heavily on\nmachine learning (ML) [9] and deep learning (DL) [10]\ntechniques to predict driving patterns over time. These meth-\nods typically involve defining a feature matrix to represent\ndriver behavior, often requiring extensive offline training\nwith large datasets and significant computational resources.\nFurthermore, these strategies can struggle with capturing the\nnonlinear dynamics of driving behavior [11]. The Koopman\noperator theory [12] presents a compelling alternative to\nidentify complex systems by transforming nonlinear system\ndynamics into a higher-dimensional linear space with com-\nputationally efficient training. Koopman operator theory has\nbeen demonstrated to be a promising approach to nonlinear\nsystem identification in vehicular applications including eco-\ndriving problems for EVs, autonomous racing, and vehicle\nplatooning [13]. Although the Koopman method is effective\nfor identifying complex nonlinear systems, it lacks the prac-\nticality of real-time updates based on new observations. This\ncan be achieved with online parameter estimation methods\nlike the recursive least squares (RLS) algorithm [14], as\nexplored in [15] and [16]. While these studies demonstrate\nthe use of RLS in updating Koopman-based models, they\ndo not address the specific challenge of modeling dynamic,\nhuman-in-the-loop responses to speed advisory systems in\nreal time.\nThis study proposes a data-driven approach for modeling\nthe human response to a speed advisory system, which\naddresses the limitations of traditional methods and results\nin a more adaptable and robust model. First, a Koopman-\nbased driver behavior model is developed to forecast an\nindividual driver’s response to speed advisory cues in a\nsimulator environment. Second, the model is enhanced with\nthe ability to adapt and improve over time by integrating real-\ntime data using the RLS estimator. Unlike previous works,\narXiv:2502.20347v1  [eess.SY]  27 Feb 2025\n\n\nthe proposed approach focuses on real-time driver adaptation,\nmaking it particularly suited for dynamic driving environ-\nments where short-term behavior variations are critical to\nsystem performance.\nII. DRIVER BEHAVIOR LEARNING\nA. Koopman Operator for Controlled Dynamic Systems\nConsider a nonlinear dynamic system described by the\nstate-space equation:\nxk+1 = f(xk,uk),\n(1)\nwhere xk ∈Rn is the state of the system at time step k,\nuk ∈Rm is the control input, and f describes the nonlinear\ndynamics of the system. The Koopman operator, K , governs\nthe evolution of the system’s observables, ψ(x), rather than\nthe original states, x:\nψ(xk+1) = K ψ(xk),\n(2)\nwhere ψ(xk) is a set of observable basis functions that map\nthe state xk into a higher-dimensional space [12]. Although\nthe Koopman operator is infinite-dimensional in theory, in\npractice, it is often approximated by projecting it onto\na finite-dimensional subspace RN, capturing the essential\ndynamics in a tractable way. The Koopman-based controlled\nlinear predictor then takes the form [12]:\nψ(xk+1) = Aψ(xk)+Buk,\nˆxk = Cψ(xk)\n(3)\nwhere A ∈RN×N, B ∈RN×m and ˆx is the prediction of x.\nC ∈Rn×N projects the lifted state back to the original space\n(RN →Rn).\nB. Koopman Operator for Driver Behavior Identification\nIn this work, the Koopman operator is applied to identify\nthe nonlinear relationship between driver actions (steering,\naccelerator, and brake inputs), vehicle longitudinal dynamics,\nand the speed advisory system in the driver-in-the-loop sim-\nulator. The speed advisory system provides real-time target\nspeeds based on GPS and mapping data, displayed visually\nto the driver via a head-up display, while the vehicle’s\nupdated position and surroundings continuously inform both\nthe driver and the system, as illustrated in Fig. 1. The system\nstates are the vehicle speed, vk and the vehicle traction force,\nFtr,k. These states are chosen to effectively model the human\nresponse to the reference speed vre f , provided by the speed\nadvisory:\nxk =\n\u0002\nvk, Ftrk\n\u0003\n, uk = vre f\n(4)\nA finite-dimensional approximation of the Koopman op-\nerator can be obtained through extended dynamic mode\ndecomposition (EDMD), which uses linear regression on\nmeasured data to identify the matrices A and B in Eq. 3 [17].\nGiven a set of measurements {xk,xk+1,uk}T\nk=1 containing\ndriver-specific trajectories, the state variables are mapped\ninto a set of basis functions, ψ(xk), forming data matrices\nX and X+ as follows:\nX =\n\u0002\nψ(x1),ψ(x2),··· ,ψ(xT)\n\u0003\n,\n(5)\nX+ =\n\u0002\nψ(x2),ψ(x3),··· ,ψ(xT+1)\n\u0003\n,\n(6)\nwhere X represents the observables at the current time\nstep, X+ represents the observables at the next time step.\nPolynomial functions are selected as the problem-specific\nbasis because they effectively capture the nonlinearities in\nhuman driver behavior. This is supported by heuristic models,\nsuch as the Gipps model [18] and the enhanced driver model\n[19], which demonstrate that polynomial functions work well\nfor modeling complex, nonlinear human responses in driving\nenvironments.In this work, the basis functions are selected\nup to third-order polynomials of the states:\nψ(x) = [vk,Ftrk,vkFtrk,v2\nk,Ftr2\nk,...,v3\nk,Ftr3\nk]\n(7)\nThe input data is collected in the matrix U:\nU =\n\u0002\nu1,u2,··· ,uT\n\u0003\n.\n(8)\nThe A and B matrices are determined by solving the\nfollowing linear regression problem:\nmin\nA,B ∥X+ −AX−BU∥F,\n(9)\nwhere ∥·∥F is the Frobenius norm. The solution is given by:\n\u0002\nA\nB\n\u0003\n= X+\n\u0014\nX\nU\n\u0015†\n,\n(10)\nwhere † denotes the Moore-Penrose pseudoinverse. Since\nthe first two functions in the lifted functions (7) are vehicle\nvelocity and traction force states, the inverse projection to\nthe original state matrix is trivial and given by:\nˆxk = Cψ(xk) =\n\u0014\n1\n0\n0\n...\n0\n0\n1\n0\n...\n0\n\u0015\nψ(xk)\n(11)\nVehicle Operation in \nSimulation Environment\nSpeed Advisory \nSystem\nHuman-Machine \nInteraction\nRoute Conditions\nFig. 1.\nSpeed advisory system in the driver-in-the-loop simulator.\nC. Online Updating of the Koopman Operator\nThe response of a human driver to the visual cues from\na speed advisory system is inherently dynamic and can\nchange over time due to factors such as fatigue, distraction,\nor adaptation to road conditions. A static model trained\noffline may fail to capture these variations, leading to reduced\naccuracy. To address this limitation, an online updating\nmechanism for the Koopman-based model that incorporates\nnew real-time measurements is proposed. One approach to\nupdating the model is to add new measurements to the\ntraining dataset D and retrain the offline Koopman-based\nmodel using the same procedure [15]. While this method\n\n\nmay work in an offline setting, it becomes impractical in an\nonline context. Continuously adding new data to D leads\nto large memory usage, and as the dataset grows, solving\nthe least squares problem for finding the Koopman matrices\nK = [AB] becomes increasingly computationally expensive\nand difficult to manage. To overcome these limitations, the\nrecursive least square method is used in this work [14].\nInstead of storing all historical data, the RLS algorithm\nupdates the matrices A and B incrementally based on new\nobservations. This makes it ideal for online applications\nwhere real-time performance and memory constraints are\ncritical.\nThe core idea of the RLS algorithm is to iteratively update\nthe solution to the least squares problem by modifying the\nKoopman matrices with each set of new measurements. The\nsteps for updating the Koopman matrices using the RLS\nalgorithm are outlined in Algorithm 1. The RLS algorithm\nstarts by initializing the Koopman matrices A0 and B0,\nalong with the covariance matrix P0 = λ −1I, where λ is\nthe forgetting factor that balances the influence of new and\npast data. At each time step m, the new lifted measurement\nψ(xm+1) is compared to the predicted value from the current\nKoopman matrices Am and Bm, producing a prediction error\nem. The gain matrix Km, which determines how much the\nKoopman matrices should be adjusted, is then updated based\non the current lifted measurement ψ(xm) and input um, as\nwell as the previous covariance matrix Pm−1. The Koopman\nmatrices Am and Bm are updated using the prediction error\nand the gain matrix, refining the approximation to account\nfor the new measurements. Finally, after incorporating the\nlatest data, the covariance matrix Pm is updated to reflect\nthe reduced uncertainty in the matrices. By iteratively apply-\ning these updates, the RLS algorithm provides an efficient\nmechanism for continuously refining the Koopman matrices\nwithout storing all past data, making it well-suited for real-\ntime applications.\nIII. CASE STUDY\nA. Driver Simulator Setup and Data Collection\nThe data for this study were gathered from an exper-\nimental campaign using the Vehicle Dynamics Driver-in-\nthe-Loop (VDDiL) simulator at The Ohio State University\n(OSU) Center for Automotive Research (CAR). The VDDiL\nsimulator combines commercial software with custom-built\ncomponents to create a versatile platform for driver-in-the-\nloop experiments. CarSim simulates the vehicle dynamics\nwith high accuracy, while a D-BOX actuation system pro-\nvides motion in three degrees of freedom (roll, pitch, and\nheave). The simulator features a SENSO-Wheel SensoDrive\nthat delivers realistic steering feedback. The pedal system\nincludes acceleration and braking controls, with the brake\npedal incorporating anti-lock braking system (ABS) feed-\nback, generating pulses when activated. The setup includes\na real vehicle cockpit, a three-screen display and an audio\nsystem to enhance immersion. SCANeR Studio by AV Sim-\nulation adds environment and traffic simulation capabilities,\nincreasing the system’s versatility and level of realism for a\nAlgorithm 1 Online Koopman Model Update with RLS\n1: Input: Initial Koopman matrices A0 and B0, forgetting\nfactor λ, new state and input measurements xm and um,\ninitial covariance matrix P0 = λ −1I\n2: for each time step m = T +1,T +2,...,H\n3:\nCompute prediction error:\nem = ψ(xm+1)−\n\u0002\nAm\nBm\n\u0003\u0014\nψ(xm)\num\n\u0015\n(12)\n4:\nUpdate gain matrix:\nKm = Pm−1\n\u0014\nψ(xm)\num\n\u0015 \nλ +\n\u0014\nψ(xm)\num\n\u0015⊤\nPm−1\n\u0014\nψ(xm)\num\n\u0015!−1\n(13)\n5:\nUpdate Koopman matrices:\n\u0002\nAm\nBm\n\u0003\n=\n\u0002\nAm−1\nBm−1\n\u0003\n+Kme⊤\nm\n(14)\n6:\nUpdate covariance matrix:\nPm = 1\nλ\n \nPm−1 −Km\n\u0014\nψ(xm)\num\n\u0015⊤\nPm−1\n!\n(15)\n7: end for\nrange of vehicle development and testing needs. The VDDiL\nverification against on-road data is presented in [20].\nA vehicle speed advisory system was integrated into the\nVDDiL simulator. The system displays the target speed for\neach point of the route on a central screen. The heads-up\ndisplay includes an inner circle showing the current speed\nand necessary actions (slow down, maintain speed, or speed\nup), and an outer circle indicating the difference between the\ntarget and current speeds, as illustrated in Fig. 1.\nDriver-specific data were collected on a 7.4 km simulated\nurban route, designed to replicate real-world commuting\nconditions in Columbus, OH. A human subject study was\nconducted on 18 subjects with diverse driving experience,\nand driving style. After a brief training session to familiarize\nparticipants with the simulation, each participant was in-\nstructed to drive the route while following the speed advisory\ncues as closely as possible.\nB. Advisory Speed Generation\nThe speed advisory profile provided to human drivers\nwas generated offline using a dynamic programming (DP)-\nbased eco-driving strategy. This strategy is formulated as\na nonlinear spatiotemporal trajectory optimization problem,\naiming to balance travel time and fuel consumption by\njointly optimizing the vehicle and powertrain dynamics of\na 2017 Chrysler Pacifica plug-in hybrid EV (PHEV) along\na specified route [21].\nIn this formulation, the state vector xs at distance step s\nincludes vehicle velocity vveh,s and battery state of charge\n(SoC) ξs. The control input vector us consists of the internal\ncombustion engine (ICE) on/off decision flag, ICEON/OFF,s,\nwhich determines the vehicle’s operation mode (HEV or EV)\nand the vehicle acceleration as. Given that route information,\n\n\nincluding speed limits, stop signs, and traffic light positions\nis available in advance from an advanced navigation system,\nthe full-route eco-driving problem over N distance steps is\nformulated as:\nJ∗\ns = min\n{µs}N\ns=1\n(\ncN+1(xN+1)+\nN\n∑\ns=1\ncs(xs,µs(xs,us))\n)\n(16)\ncs(xs,µs(xs,us)) =\n\u0012\nγ ˙meqf,s\n˙mnorm\n+(1−γ)\n\u0013\n∆ts\n(17)\nsubject to the constraints:\nvmin\nveh ≤vveh,s ≤vmax\nveh , ξ min ≤ξs ≤ξ max\n(18)\nICEON/OFF,s ∈{0,1}, amin ≤as ≤amax\n(19)\nvveh,1 = vmin\nveh,1, ξ1 = SoC0, ξN+1 > 26%\n(20)\nwhere us : X ×U represents the admissible control policy at\ndistance step s, cs : X ×U →R is the stage cost, defined as the\nweighted sum of equivalent fuel consumption and travel time,\nand cN+1 is the terminal cost. The parameter γ is the trade-\noff factor between fuel efficiency and travel time, ranging\nfrom 0 to 1. Additionally, ˙meqf,s denotes the equivalent fuel\nconsumption rate, while ˙mnorm is a normalization factor. ∆ts\nrefers to the travel time over a given distance step. The\nvariables vmin\nveh and vmax\nveh represent the minimum and maximum\nspeed limits, respectively, and amin and amax are the bounds\nfor longitudinal acceleration. In this study, the trade-off factor\nγ was set to 0.5, and the initial state of charge of the battery\nξ1 was 40%. Readers are referred to [21] for further details\nof the eco-driving strategy. Fig. 2 illustrates the solution to\nthe eco-driving optimization problem described for an initial\nSoC of 40%. This solution was used as the reference velocity\nfor the speed advisory system in the human subject study.The\nenergy-optimal solution results in smooth speed trajectories,\nminimizing unnecessary braking and acceleration events.\nThis behavior is notably consistent when approaching stop\nsigns and turns. The optimal solution also recommends\nmaintaining a steady cruising speed and optimizing energy\nefficiency while adhering to speed limits. Additionally, the\neco-driving solution maximizes the use of EV mode, avoids\nactivating the ICE, and utilizes regenerative braking early\nwhen slowing down, further enhancing energy efficiency.\nIV. RESULTS AND DISCUSSION\nA. Offline Koopman-based Driver Behavior Model Develop-\nment\nThe Koopman-based driver model is developed using 18\ndriver-specific trajectories, totaling approximately 3.4 hours\nof data collected at a 40 Hz sample rate from the VDDiL\nsimulator. The training, validation, and testing data sizes\nfor the Koopman-based model are set to 80%, 10% and\n10% of the driver-specific trajectories, respectively. Fig. 3\nshows the model’s performance during the training and\nvalidation phases. The results indicate that the Koopman-\nbased model can closely match the experimental data for\nvehicle speed and traction force states. This close alignment\nbetween predicted and actual data suggests that the model\n0\n1000\n2000\n3000\n4000\n5000\n6000\n7000\nDistance [m]\n0\n20\n40\n60\nSpeed [mph]\nEco-Driving Solution\nSpeed Advisory\nSpeed Limit\nStop Sign\nLeft/Right Turn\n0\n1000\n2000\n3000\n4000\n5000\n6000\n7000\nDistance [m]\n-100\n0\n100\nPower [kW]\nPower Demands [kW]\nBattery\nICE\n0\n1000\n2000\n3000\n4000\n5000\n6000\n7000\nDistance [m]\n30\n35\n40\nSoC [%]\nBattery State of Charge [%]\nFig. 2.\nSpeed profiles, power demands, and battery state of charge profiles\nprovided by the optimal solution in the speed advisory system.\neffectively captures the driver-vehicle interaction dynamics\nduring training and validation.\nFig. 3.\nTraining and validation results of the Koopman-based driver model.\nFor the testing phase, two distinct driver-specific trajecto-\nries from the data (Driver 17 and Driver 18) are examined.\nThe model is exercised by initializing the vehicle speed\nand traction force at the beginning of the route and using\nthe reference speed as the model input. Fig. 4 and Fig.\n5 present the testing results of Drivers 17 and 18. The\ntrained Koopman-based model demonstrates a strong ability\nto capture the drivers’ speed and traction force trajectories,\nreflecting its effectiveness in replicating observed driving\nbehaviors. This is noteworthy given that the model states\nwere initialized only at the start of the testing process.\nHowever, there are notable instances, particularly with Driver\n18, where the model’s predictions do not align as closely\nwith the actual data. One such instance occurs between the\n515 and 630 seconds in Fig. 5, where the driver exhibits\nuncertain behavior which is possibly due to inattention to\n\n\nthe speed advisory input.\n0\n100\n200\n300\n400\n500\n600\n700\nTime [s]\n0\n10\n20\n30\n40\n50\nVehicle Speed [mph]\nDriver 17\nDriver Data\nPrediction\nReference Speed\n0\n100\n200\n300\n400\n500\n600\n700\nTime [s]\n-10\n-5\n0\n5\n10\nTraction Force [kN]\nDriver Data\nPrediction\nFig. 4.\nTesting results of the Koopman-based driver model for Driver 17\n(without online update).\n100\n200\n300\n400\n500\n600\n700\nTime [s]\n0\n10\n20\n30\n40\n50\nVehicle Speed [mph]\nDriver 18\nDriver Data\nPrediction\nReference Speed\n100\n200\n300\n400\n500\n600\n700\nTime [s]\n-10\n-5\n0\n5\n10\nTraction Force [kN]\nDriver Data\nPrediction\nFig. 5.\nTesting results of the Koopman-based driver model for Driver 18\n(without online update).\nB. Online Driver Behavior Learning Analysis\nThe proposed RLS-based online update mechanism for the\nKoopman-based model is evaluated to address discrepancies\nin the driver’s behavior when following the advisory cues.\nThe RLS method is evaluated for Driver 18, between 515\nand 630 seconds, focusing on the segment of the route with\nthe largest modeling error. The online learning process is\nperformed with the forgetting factor λ = 0.9 and the Koop-\nman operator is updated every 1 s of the driver observations\nduring that period. The online Koopman-based model is\ncompared against the offline learned Koopman-based model\nunder different prediction time horizon lengths. In this anal-\nysis, the initial conditions for the velocity and traction force\nstates are set using the measured values at the end of each\nprediction horizon. The result of this comparison is shown\nin Fig. 6. The online Koopman-based model significantly\n500\n550\n600\n650\nTime [s]\n0\n20\n40\n60\nVehicle Speed [mph]\nPrediction Horizon: 50 s\nDriver Data\nOnline Update\nOffline Model\nRef. Speed\n500\n550\n600\n650\nTime [s]\n-10\n-5\n0\n5\n10\nTraction Force [kN]\nPrediction Horizon: 50 s\n500\n550\n600\n650\nTime [s]\n0\n20\n40\n60\nVehicle Speed [mph]\nPrediction Horizon: 20 s\n500\n550\n600\n650\nTime [s]\n-10\n-5\n0\n5\n10\nTraction Force [kN]\nPrediction Horizon: 20 s\n500\n550\n600\n650\nTime [s]\n0\n20\n40\n60\nVehicle Speed [mph]\nPrediction Horizon: 10 s\nDriver Data\nOnline Update\nOffline Model\nRef. Speed\n500\n550\n600\n650\nTime [s]\n-10\n-5\n0\n5\n10\nTraction Force [kN]\nPrediction Horizon: 10 s\n500\n550\n600\n650\nTime [s]\n0\n20\n40\n60\nVehicle Speed [mph]\nPrediction Horizon: 5 s\n500\n550\n600\n650\nTime [s]\n-10\n-5\n0\n5\n10\nTraction Force [kN]\nPrediction Horizon: 5 s\nFig. 6.\nComparison between the offline learned and online updated\nKoopman-based model between 515 and 630 seconds of Driver 18 under\ndifferent prediction time horizons.\noutperforms the offline version in predicting human driver\nbehavior. This improvement is due to its ability to real-time\nchanges, which cannot be achieved by merely reinitializing\nthe offline model. By integrating the RLS approach, the\nonline model continuously updates to capture short-term\nvariations in behavior, leading to substantially improved\nprediction accuracy compared to the offline model..\nTo compare the prediction accuracy performance of the\nonline and offline Koopman approaches, the Root Mean\nSquare Error (RMSE) values between predicted and actual\ntrajectories are calculated and summarized in Tables I and\nII. The online Koopman-based model reduces the speed\nprediction error by 17% to 49% and traction force prediction\nerror by 7% to 42% compared to the offline model. The\nmost significant improvements are consistently observed over\nthe shortest prediction horizons for both metrics. This is\nprimarily due to the online model’s ability to respond to\nchanges in driver behavior in real time, enabling it to capture\nimmediate shifts and short-term dynamics that the offline\nmodel may miss. This adaptability enhances prediction ac-\ncuracy, especially over shorter horizons, where rapid changes\nin Driver 18’s behavior are more frequent.\nThe total computation time for the online learning process\nof the Koopman-based model is compared to that of the\nretrained offline model with new measurements. As shown\nin Table III, online learning with RLS significantly re-\nduces computation time compared to retraining the Koopman\n\n\nmodel. This reduction is due to the continuous addition\nof data in the offline model, which increases the dataset\nsize and makes solving the least squares problem for the\nKoopman matrices computationally intensive. In contrast,\nthe RLS algorithm iteratively updates the Koopman matrices\nwith new measurements without storing the entire dataset,\nmaking it far more practical for online learning.\nTABLE I\nVELOCITY RMSE [MPH] RESULTS OF THE KOOPMAN-BASED MODEL\nWITH AND WITHOUT ONLINE UPDATE.\nPrediction Horizon [s]\n50s\n20s\n10s\n5s\nOffline Model\n12.57\n11.58\n10.78\n7.22\nOnline Model\n10.45\n7.98\n5.93\n3.69\nTABLE II\nTRACTION FORCE RMSE [KN] RESULTS OF THE KOOPMAN-BASED\nMODEL WITH AND WITHOUT ONLINE UPDATE.\nPrediction Horizon [s]\n50s\n20s\n10s\n5s\nOffline Model\n1.58\n2.10\n2.61\n3.16\nOnline Model\n1.46\n1.54\n1.67\n1.83\nTABLE III\nCOMPUTATION TIME [S] COMPARISON OF OFFLINE KOOPMAN-BASED\nMODEL WITH RETRAINING AND ONLINE UPDATE WITH RLS.\nPrediction Horizon [s]\n50s\n20s\n10s\n5s\nOffline Model with Retraining\n4.48\n4.71\n4.37\n4.33\nOnline Model\n0.04\n0.04\n0.03\n0.04\nV. CONCLUSIONS AND FUTURE WORK\nIn this paper, a novel method for modeling driver be-\nhavior in response to speed advisory systems with real-\ntime adaptability is established. A Koopman-based driver\nbehavior model is developed using data from a comprehen-\nsive human subject study with a driver-in-the-loop simulator.\nResults show that the developed model can effectively cap-\nture the dynamics of the driver-speed advisory interaction\nacross different drivers. The inclusion of an online updating\nmechanism enabled by the RLS algorithm further improves\nprediction accuracy, especially in cases where the driver’s\nbehavior deviates from the recommended speed trajectory.\nFuture work will explore personalized speed-advisory strate-\ngies integrated with the proposed driver behavior model to\nimprove human-speed advisory interactions.\nACKNOWLEDGMENT\nThe authors are grateful to the OSU Center for Automotive\nResearch for providing funding in support of this work and\nthe authors also would like to acknowledge Stellantis for the\ninspiring discussions and helpful feedback that contributed\nto the research presented in this paper.\nREFERENCES\n[1] M. Telloni, J. Farrell, L. Mendez, M. F. Ozkan, J. Chrstos, M. Canova,\nand S. Stockar, “Evaluating the impact of velocity advisory systems on\nfuel economy of passenger vehicles: A driver simulator study,” tech.\nrep., SAE Technical Paper, 2024.\n[2] J. Hong, X. Luo, H. Wu, X. Na, H. Chu, B. Gao, and H. Chen,\n“Energy-saving driving assistance system integrated with predictive\ncruise control for electric vehicles,” IEEE Transactions on Intelligent\nVehicles, 2024.\n[3] D. Rojdestvenskiy, M. Cvetkovi´c, and P. Bouchner, “Real-time driver\nadvisory system for improving energy economy based on advance\ndriver assistant systems interface,” in 2018 Smart City Symposium\nPrague (SCSP), pp. 1–6, IEEE, 2018.\n[4] M. Nasr Azadani and A. Boukerche, “Driving behavior analysis\nguidelines for intelligent transportation systems,” IEEE Transactions\non Intelligent Transportation Systems, vol. 23, no. 7, pp. 6027–6045,\n2022.\n[5] M. F. Ozkan, Interactive Autonomy in Mixed Traffic: Modeling,\nControl and Optimization. PhD thesis, Texas Tech University, 2023.\n[6] N. M. Negash and J. Yang, “Driver behavior modeling toward au-\ntonomous vehicles: Comprehensive review,” IEEE Access, vol. 11,\npp. 22788–22821, 2023.\n[7] K. Kreutz and J. Eggert, “Fast online parameter estimation of the\nintelligent driver model for trajectory prediction,” in 2022 IEEE\nIntelligent Vehicles Symposium (IV), pp. 758–765, 2022.\n[8] V. Grotto, Online learning for data-driven trajectory predictions.\nMaster thesis, KTH Royal Institute of Technology, 2024.\n[9] Z. E. Abou Elassad, H. Mousannif, H. Al Moatassime, and A. Kark-\nouch, “The application of machine learning techniques for driving\nbehavior analysis: A conceptual framework and a systematic literature\nreview,” Engineering Applications of Artificial Intelligence, vol. 87,\np. 103312, 2020.\n[10] M. H. Alkinani, W. Z. Khan, and Q. Arshad, “Detecting human driver\ninattentive and aggressive driving behavior using deep learning: Recent\nadvances, requirements and open challenges,” IEEE Access, vol. 8,\npp. 105008–105030, 2020.\n[11] Z. Elamrani Abou Elassad, H. Mousannif, H. Al Moatassime, and\nA. Karkouch, “The application of machine learning techniques for\ndriving behavior analysis: A conceptual framework and a systematic\nliterature review,” Engineering Applications of Artificial Intelligence,\nvol. 87, p. 103312, 2020.\n[12] M. Korda and I. Mezi´c, “Linear predictors for nonlinear dynamical\nsystems: Koopman operator meets model predictive control,” Auto-\nmatica, vol. 93, pp. 149–160, 2018.\n[13] W. A. Manzoor, S. Rawashdeh, and A. Mohammadi, “Vehicular\napplications of koopman operator theory—a survey,” IEEE Access,\nvol. 11, pp. 25917–25931, 2023.\n[14] R. Isermann and M. M¨unchhof, Identification of dynamic systems: an\nintroduction with applications, vol. 85. Springer, 2011.\n[15] H. M. Calder´on, E. Schulz, T. Oehlschl¨agel, and H. Werner, “Koopman\noperator-based model predictive control with recursive online update,”\nin 2021 European Control Conference (ECC), pp. 1543–1549, 2021.\n[16] O. Sayed and S. Lucia, “Recursive least squares-based identification\nfor multi-step koopman operators,” in 2024 European Control Con-\nference (ECC), pp. 941–946, 2024.\n[17] M. O. Williams, I. G. Kevrekidis, and C. W. Rowley, “A data–driven\napproximation of the koopman operator: Extending dynamic mode\ndecomposition,” Journal of Nonlinear Science, vol. 25, pp. 1307–1346,\n2015.\n[18] P. Gipps, “A behavioural car-following model for computer simula-\ntion,” Transportation Research Part B: Methodological, vol. 15, no. 2,\npp. 105–111, 1981.\n[19] S. Gupta, S. R. Deshpande, P. Tulpule, M. Canova, and G. Rizzoni,\n“An enhanced driver model for evaluating fuel economy on real-world\nroutes,” IFAC-PapersOnLine, vol. 52, no. 5, pp. 574–579, 2019. 9th\nIFAC Symposium on Advances in Automotive Control AAC 2019.\n[20] R. Sekar, O. Jacome, J. Chrstos, and S. Stockar, “Assessment of driving\nsimulators for use in longitudinal vehicle dynamics evaluation,” tech.\nrep., SAE Technical Paper, 2022.\n[21] M. F. Ozkan, S. Gupta, S. D’Alessandro, M. Spano, D. Kibalama,\nJ. Paugh, M. Canova, S. Stockar, R. A. Reese, and B. Wasacz,\n“Optimizing urban traffic efficiency via virtual eco-driving featured by\na single automated vehicle,” tech. rep., SAE Technical Paper, 2024.\n\n\n",
  "metadata": {
    "source_file": "dataset/pdfs/arxiv_2502.20347v1.pdf",
    "total_pages": 6,
    "title": "Modeling Driver Behavior in Speed Advisory Systems: Koopman-based Approach with Online Update",
    "authors": [
      "Mehmet Fatih Ozkan",
      "Jeff Chrstos",
      "Marcello Canova",
      "Stephanie Stockar"
    ],
    "abstract": "Accurate driver behavior modeling is essential for improving the interaction\nand cooperation of the human driver with the driver assistance system. This\npaper presents a novel approach for modeling the response of human drivers to\nvisual cues provided by a speed advisory system using a Koopman-based method\nwith online updates. The proposed method utilizes the Koopman operator to\ntransform the nonlinear dynamics of driver-speed advisory system interactions\ninto a linear framework, allowing for efficient real-time prediction. An online\nupdate mechanism based on Recursive Least Squares (RLS) is integrated into the\nKoopman-based model to ensure continuous adaptation to changes in driver\nbehavior over time. The model is validated using data collected from a\nhuman-in-the-loop driving simulator, capturing diverse driver-specific\ntrajectories. The results demonstrate that the offline learned Koopman-based\nmodel can closely predict driver behavior and its accuracy is further enhanced\nthrough an online update mechanism with the RLS method.",
    "published_date": "2025-02-27",
    "source": "arxiv"
  }
}