{
  "id": "arxiv_2502.21320v1",
  "text": "TomoSelfDEQ: Self-Supervised Deep Equilibrium Learning\nfor Sparse-Angle CT Reconstruction\nTatiana A. Bubba∗\nMatteo Santacesaria†\nAndrea Sebastiani‡\nAbstract\nDeep learning has emerged as a powerful tool for solving inverse problems in imaging, in-\ncluding computed tomography (CT). However, most approaches require paired training data\nwith ground truth images, which can be difficult to obtain, e.g., in medical applications. We\npresent TomoSelfDEQ, a self-supervised Deep Equilibrium (DEQ) framework for sparse-angle\nCT reconstruction that trains directly on undersampled measurements. We establish theoretical\nguarantees showing that, under suitable assumptions, our self-supervised updates match those\nof fully-supervised training with a loss including the (possibly non-unitary) forward operator\nlike the CT forward map. Numerical experiments on sparse-angle CT data confirm this finding,\nalso demonstrating that TomoSelfDEQ outperforms existing self-supervised methods, achieving\nstate-of-the-art results with as few as 16 projection angles.\nKeywords. Inverse problems, Deep learning, Deep equilibrium models, Tomographic imaging\n1\nIntroduction\nIn recent years, learning-based strategies for imaging inverse problems have become a popular alter-\nnative to more classical strategies, such as regularization theory or Bayesian approaches [2]. Initial\ndeep learning methods, generally agnostic to the physical model describing an inverse problem, in-\ncluded convolutional neural networks trained either to directly map acquired measurements to the\ndesired images or to post-process an initial “standard” reconstruction to remove noise and other arti-\nfacts [14, 16]. More recent approaches strive to retain the information coming from the physics of the\nimaging methodology by incorporating it in the learned scheme. This is the case of deep unrolling or\nunfolding where a fixed number of iterations of an iterative scheme is regarded as layers of a deep ar-\nchitecture and trained end-to-end [1, 10]. A particularly promising direction is the Deep Equilibrium\n(DEQ) paradigm [9], which allows unrolling an effectively infinite number of iterations by regarding\nminimizers of certain functionals as fixed points of suitable operators. Compared to unrolling, DEQ\ntrains a deep implicit model, thus significantly reducing the associated memory cost.\nWhile these approaches have shown impressive results, as supervised methods they typically re-\nquire paired training data with ground truth images, which can be very limiting in, e.g., medical\nimaging applications. Self-supervised learning addresses this limitation while retaining the power of\nlearning-based strategies. Well known methods include Plug-and-Play (PnP) [22], equivariant imag-\ning [4] and Noise2Noise [15]. Very recently, building on the latter approach, a self-supervised deep\nequilibrium model, called SelfDEQ, has been introduced in [8] as a framework for training model-\nbased implicit neural networks using Jacobian-Free Backpropagation (JFB). In [8] it is also proved\nthat, for unitary operators (e.g., magnetic resonance imaging (MRI)), SelfDEQ updates match those\nof fully-supervised DEQ.\nAmong imaging inverse problems, computed tomography (CT) presents a particularly challenging\ncase where learning without ground truth would be especially valuable. In sparse-angle CT, high-\nquality reconstruction from scarce angular measurements is crucial for reducing radiation dose in\n∗Department of Mathematics and Computer Science, University of Ferrara, Italy (tatiana.bubba@unife.it)\n†MaLGa Center, Department of Mathematics, University of Genoa, Genoa, Italy (matteo.santacesaria@unige.it)\n‡Department of Physics, Computer Science and Mathematics, University of Modena and Reggio Emilia, Italy\n(andrea.sebastiani@unimore.it)\n1\narXiv:2502.21320v1  [eess.IV]  28 Feb 2025\n\n\nmedical imaging and enabling rapid inspection in industrial applications. However, achieving such\nreconstructions without ground truth data remains challenging, and a framework like SelfDEQ is not\ndirectly applicable due to the non-unitary nature of the CT forward operator.\nIn this work, we introduce TomoSelfDEQ, a novel self-supervised deep equilibrium framework\nfor sparse-angle CT reconstruction, which allows the following key contributions: (1) we extend the\ntheoretical analysis of SelfDEQ to non-unitary forward operators, providing a more general relation\nbetween self- and fully-supervised losses (and corresponding JFB); (2) through extensive experiments,\nwe demonstrate the effectiveness of TomoSelfDEQ on sparse-angle CT reconstruction, achieving state-\nof-the-art results even with severely undersampled data; (3) we provide theoretical guarantees estab-\nlishing the equivalence between our self-supervised approach and fully-supervised training, ensuring\noptimal performance without the need for ground truth data.\nThis work fits into the line of research of training without the need for ground truth that is receiving\ngrowing interest in the imaging inverse problems community. In the context of tomographic imaging,\nseveral approaches have been proposed. Noise2Inverse [12], extends the ideas of Noise2Self [3] to image\nreconstruction in the case of fully sampled tomographic measurements. However, it does not explicitly\naddress the challenges of sparse-angle reconstruction. More recently, Sparse2Inverse [11] was proposed\nto specifically handle undersampled projections by combining a neural network operating in the\nreconstruction domain with a loss computed in the projection domain. In particular, Sparse2Inverse\naims to address limitations of previous methods by computing the loss in the projection domain\nwhile letting the neural network operate on images. Other approaches building on similar ideas are\nProj2Proj [20], which focuses on low-dose data by applying self-supervision principles directly in\nthe projection domain, and Self-Supervised Denoiser Framework (SDF) [21], which leverages pre-\ntraining on densely sampled data to enhance the image reconstruction quality from undersampled\ndata. TomoSelfDEQ differs from all of these approaches because it leverages the Deep Equilibrium\nframework, and provides theoretical guarantees for the general case of non-unitary operators, i.e., it\nis not limited to the CT forward operator making it well-suited to other imaging modalities that are\nmodeled by non-unitary transformations.\nThe paper is organized as follows.\nIn Section 2, we introduce the mathematical formulation\nof undersampled linear inverse problems and provide a summary of relevant existing approaches.\nSection 3 presents DEQ and introduces our method, TomoSelfDEQ. In Section 4, we provide our\ntheoretical results, establishing the equivalence between self-supervised and fully-supervised training\nfor non-unitary operators. Section 5 demonstrates the effectiveness of our approach through numerical\nexperiments on sparse-angle CT reconstruction, comparing it with conventional techniques and the\nrecently proposed Sparse2Inverse. Finally, Section 6 summarizes our findings and discusses future\nresearch directions.\n2\nBackground and mathematical formulation\nWe consider linear inverse problems of the form:\ny = MAx + e,\n(1)\nwhere y ∈Rm are the measurements, e ∈Rm is additive white Gaussian noise (AWGN), A ∈Rp×n is\na (non-unitary) measurement matrix, x ∈Rn is the unknown target and M ∈{0, 1}m×p is a matrix\nobtained from the identity matrix by keeping only those rows corresponding to the measured data.\nIn CT, A represents the Radon transform [17], i.e., each row of A corresponds to a line integral\n(at a specific angle) modeling the X-ray attenuation through the object of interest. As such, A is\na non-unitary operator. When the acquisition angles are sparse, M acts as a mask selecting (from\nthe full measurements) only those projections corresponding to the actual acquisition angles. Due to\nthe ill-posedness of the Radon transform, the sparser the acquisition protocol the more challenging\nthe reconstruction problem becomes. Therefore, traditional methods based on directly inverting the\nforward map, such as the filtered back-projection (FBP), generally perform poorly. An alternative is\nprovided by regularized approaches, which seek x by iteratively solving optimization problems of the\nform:\nˆx = arg min\nx∈Rn\n+\n{g(x) + h(x)} ,\n(2)\n2\n\n\nwhere g is the data-fidelity term that quantifies the discrepancy between the measurements and the\nsolution and h is a regularizer that imposes prior knowledge on the unknown image. In addition, in\ntomographic imaging it is natural to restrict the X-ray attenuation coefficients to be non-negative,\nthat is, Rn\n+ denotes the non-negative orthant of Rn. A common choice for the data fidelity is the\nleast square term:\ng(x) = 1\n2∥y −MAx∥2\n2,\n(3)\nand for the regularizer h(x), Total Variation (TV) or other sparsity-promoting penalties are often\nemployed to preserve edge-like features [2, Section 2].\nWhile these classical approaches generally allow for accurate reconstructions from fewer tomo-\ngraphic measurements than usually required by FBP, they rely on hand-crafted regularizers (which\ncan impact the mathematical tractability of the functional in (2)), and can be sensitive to parameter\nchoices.\nIn recent years, the theoretical understanding that comes from regularized approaches has been\ncombined with the practical advantages of learning-based methods showing that, in many instances,\nthe hybrid approaches are able to significantly surpass both pure model- and more data-based methods\nretaining a sufficient degree of theoretical understanding and guarantees. Among many, we consider\nhere Deep Equilibrium (DEQ), a paradigm initially introduced for supervised learning and very re-\ncently adapted in [8] to work as in the self-supervised framework using Jacobian-Free Backpropagation\n(JFB).\n3\nDeep Equilibrium Models\nDeep Equilibrium (DEQ) enables training recursive networks with effectively infinite layers without\nstoring intermediate variables [9]. The key idea is to find a fixed point ¯x of a suitable operator Tθ\nrather than explicitly unrolling a finite number of iterations, that is:\n¯x = Tθ(¯x, y),\n(4)\nwhere y is the measurement vector and Tθ is defined as:\nTθ(x) = αfθ(s) + (1 −α)s\nwith\ns = x −γ∇g(x),\n(5)\nbeing α, γ > 0 hyperparameters, fθ a (convolutional) neural network with learnable parameters θ,\nand g(x) the data fidelity term from (3). DEQ is generally trained end-to-end in a supervised fashion,\nconsidering the empirical risk as minimization loss. In this setting, the neural network fθ enforces a\npriori properties on the resulting fixed point ¯x, functioning as a denoiser similar to PnP [22].\nIn [8], the authors propose to combine DEQ with the self-supervised framework of Noise2Noise,\nwhich uses different noisy realizations of the same ground truth image to train a network without\nthe need for the actual ground truth. The resulting method, named SelfDEQ, considers pairs of\nmeasurements {yi, y′\ni}N\ni=1 of the same underlying image xi:\nyi = MiAxi + ei\nand\ny′\ni = M ′\niAxi + e′\ni\n(6)\nwhere N ≥1 denotes the number of training pairs and, in [8], A is the operator associated with\nMRI (i.e., the Fourier transform). Then, training the method consists of two steps in each training\niteration.\nForward Pass.\nStarting from an initial guess x0, the fixed point ¯x is computed by running a\nfixed-point iteration of the form:\nxk = Tθ(xk−1, y)\n(7)\nuntil convergence or a maximum number of iterations is reached. Generally, an acceleration algorithm\n(e.g., Anderson acceleration) is used.\n3\n\n\nBackward Pass.\nGiven a loss function L, parameter updates are computed via Jacobian-Free\nBackpropagation (JFB), which has been theoretically shown to provide valid descent directions for\ntraining implicit networks [7], and avoids explicitly computing and storing the inverse Jacobian,\nleading to efficient training with constant memory complexity:\nJFBL(θ) = Real\n\u0012\n(∇θTθ(¯x))T\n\u0014∂L\n∂¯x\n\u0015T \u0013\n.\n(8)\nTo enable self-supervised training, the authors of [8] consider the following weighted loss:\nLself(θ) = E\n\u00141\n2∥M ′A¯x(θ, y) −y′∥2\nW\n\u0015\n(9)\nwhere ∥· ∥W denotes the weighted norm given by ∥z∥2\nW = zT Wz for z ∈Rm.\nIn [8], W =\nM ′W(M ′W)T ∈Rm×m is a subsampling of the diagonal weighting matrix W, whose entries are\ndefined by:\nwk =\n(\n1\n√\nE[M ′T M ′]k,k\nif\np\nE[M ′T M ′]k,k ̸= 0\n0\notherwise\n.\n(10)\nNote that, by minimizing Lself, we implicitly learn the regularization through fθ. The main theoretical\nresult in [8] establishes that the JFB updates from the weighted self-supervised loss in (8) match those\nobtained using conventional supervised learning on DEQ, i.e., considering the supervised loss:\nL′\nsup = E\n\u0002\n∥¯x −x∥2\n2\n\u0003\n.\n(11)\nHowever, this result was only derived under the limiting assumption of A being a unitary operator.\n3.1\nTomoSelfDEQ\nThe framework of SelfDEQ can be easily extended to work with more general non-unitary forward\noperators A, as it is the case of tomographic imaging. To this end, we introduce TomoSelfDEQ, which\nis particularly well-suited for sparse-angle CT reconstruction, where both the physics of the imaging\nprocess and the self-supervised nature of the training need to be carefully considered. Starting from\nthe original SelfDEQ framework, we modify (5) to include the projection onto the positive orthant\nΠ+, that is:\nTθ(x) = Π+(αfθ(s) + (1 −α)s)\nwith\ns = x −γ∇g(x).\n(12)\nThe measurement pairs in (6) are obtained by splitting each measurement acquisition into two com-\nplementary subsets of angles. Each training iteration consists of a forward and a backward pass, as\nfor SelfDEQ. The definition of the self-supervised loss Lself(θ) and the diagonal weighting matrix W,\nwhich is crucial for handling the possibly non-uniform sampling density across angles, are as in (9)\nand (10), respectively.\nOur main theoretical result is presented in the next section. In particular, Theorem 2 establishes\nthat the JFB updates from the weighted self-supervised loss (9) match those obtained using the\nfollowing supervised loss:\nLsup = E\n\u00141\n2∥A(¯x −x)∥2\n2\n\u0015\n.\n(13)\nNote that this loss differs from that of [8] (and more in general from standard supervised losses\nin deep learning), as it includes the forward operator A in its formulation. This choice is crucial\nfor establishing the equivalence with the self-supervised loss and reflects the physics of the imaging\nprocess. The more common supervised loss (11) would not lead to the same theoretical guarantees\ndue to the non-unitary nature of the Radon transform.\n4\n\n\n4\nTheoretical Results\nWe now establish the relationship between self-supervised and supervised training of TomoSelfDEQ\nfor non-unitary operators. Our analysis relies on two key assumptions.\nAssumption 1. The training samples correspond to the setting in (6) with x ∼πx, M ∼πM,\nM ′ ∼πM, e ∼N(0, σ2I), and e′ ∼N(0, σ2I) drawn i.i.d. from their respective distributions.\nAssumption 2. A and EM[M T M], where the expectation is taken over πM, have full rank.\nAssumption 1 is a mild statistical requirement stating that sampling matrices, images, and noise\nare sampled independently.\nAssumption 2 ensures that the sampling matrices provide complete\ncoverage of the measurement domain, though each individual matrix can still represent undersampled\nmeasurements.\nOur first result establishes a key property of the weighted measurements.\nProposition 1. When Assumption 2 is satisfied,\nE\n\u0002\n(M ′A)T WM ′A\n\u0003\n= AT A\nwhere the expectation is with respect to πM and W = M ′W(M ′W)T is defined through (10).\nProof. Since Assumption 2 implies that E[M ′]k,k ̸= 0,\nwk =\n1\np\nE[M ′T M ′]k,k\n.\n(14)\nGiven M ′T M ′ ∈{0, 1}p×p and W ∈Rp×p are both diagonal matrices, we have:\nE[M ′T WM ′] = E[M ′T M ′WW\nT M ′T M ′] = WW\nT E[M ′T M ′M ′T M ′] = I.\n(15)\nTherefore,\nE[(M ′A)T WM ′A] = AT E[M ′T WM ′]A = AT A,\n(16)\nwhere the last equation follows from (15).\nNext, our main result shows that TomoSelfDEQ updates match those of supervised training. This\nimplies that TomoSelfDEQ can achieve the same performance as supervised training even for non-\nunitary operators like the Radon transform, provided the sampling pattern satisfies our assumptions.\nTheorem 2. Under Assumptions 1 and 2, the JFB update of the weighted self-supervised loss equals\nits supervised counterpart:\nJFBLself(θ) = JFBLsup(θ)\n(17)\nwhere Lsup = E\n\u0002 1\n2∥A(¯x −x)∥2\n2\n\u0003\nand Lself is defined in (9).\nProof. The supervised update JFBLsup(θ) is given by:\nJFBLsup(θ) = E\n\u0002\n(∇θTθ(¯x))T (AT A)(¯x −x)\n\u0003\n.\nFor the self-supervised update, let H′ :=\n√\nWM ′A. Then:\nJFBLself(θ) = E\nh\n(∇θTθ(¯x))T H′T (H′¯x −\n√\nWy′)\ni\n= E\nh\n(∇θTθ(¯x))T E\nh\nH′T (H′¯x −\n√\nW(M ′Ax + e′))\n\f\f\fx, M, e\nii\nThe conditional expectation can be decomposed as:\nE\nh\nH′T (H′¯x −\n√\nW(M ′Ax + e′))\n\f\f\fx, M, e\ni\n= E[H′T H′](¯x −x) + E[H′T √\nW]E[e′]\n= AT A(¯x −x)\nwhere we used Proposition 1 and E[e′] = 0. Therefore,\nJFBLself(θ) = E\n\u0002\n(∇θTθ(¯x))T (AT A)(¯x −x)\n\u0003\n= JFBLsup(θ)\nwhich establishes the desired result.\n5\n\n\n4.1\nProperties of Random Sampling Patterns\nFor practical implementation in sparse-angle CT, we adopt uniform random sampling from [0, π) to\nsatisfy Assumption 2. The following proposition shows that this sampling strategy leads to a simple\nform for E[M T M], which determines the weighting matrix W in our self-supervised loss.\nProposition 3. When the sampling patterns M are drawn uniformly at random from a fixed subset\nof size s, the expectation E[M T M] is a scalar multiple of the identity matrix. Specifically,\nE[M T M] = s\nnΣ\nI,\n(18)\nwhere nΣ is the total number of possible measurements and s is the number of selected measurements.\nProof. For a masking matrix M with entries in {0, 1}, M T M is diagonal. Under uniform random\nsampling with size s, the probability of any index being selected is s/nΣ, giving E[(M T M)k,k] = s/nΣ\nfor diagonal entries. Off-diagonal entries are always zero by construction. Therefore equation (18)\nfollows.\n5\nNumerical experiments\nIn this section, we describe the implementation1 of TomoSelfDEQ and we show some numerical results,\ncomparing them with conventional techniques, i.e., FBP and TV regularization with non-negativity\nconstraints (cf. Section 2) and the recently proposed self-supervised methods Sparse2Inverse [11],\ntailored to sparse CT problems. For a fair comparison with our method, we applied Sparse2Inverse on\nsimulated measurements with AWGN, which differs from its original implementation. We conducted\nall the experiments on a workstation equipped with an Intel i9-12900K processor and a NVIDIA RTX\nA5000 GPU.\nThe operator A is a discretization of the Radon transform, implemented with Tomosipo [13]\n(which relies on LION to specify the CT geometry2). We consider a discretization of the full angular\nrange made of nΣ = 384 equispaced angles. The matrix M is obtained sampling a fixed number s\nof angles from the total 384 angles and keeping only the rows corresponding to the selected angles.\nThe forward pass is executed until the relative norm of the differences between iterations is less than\n10−3. In case the stopping criterion is not met, the maximum number of iterations is set to 100.\nSimilarly to [8], we use a U-Net [18] for fθ, considering the spectral normalization in all layers to\nimprove the stability of the model [19]. We adaptively set the parameter γ in (5) depending on the\nnumber of selected angles s, to ensure the operator Tθ is non-expansive. Specifically, γ =\n1\nbγs , where bγs\nis the spectral norm of the operator MsA, with Ms being the sampling matrix obtained by selecting\ns equispaced angles. For the optimizer, we use a Schedule-Free version of Adam [5]. The learning\nrate is set to 2 ∗10−4, the mini-batch size is 8 and we run 2000 training epochs.\nThe training dataset is generated on-the-fly, considering 32 2D slices from the CBCT Walnut\ndataset [6]. In detail, for each training batch the undersampled measurements are obtained randomly\nsampling s angles from [0, π) with a uniform distribution. This data augmentation strategy ensures\nuniform coverage of the angular range during training as required by Assumption 2, enabling more\nrobust learning. It is important to point out that this strategy is feasible since we have the full\nrange data and it is not practical in a real medical settings. It has to be intended only for validation\npurposes. In contrast to the random sampling used during training, the validation set is fixed and\nuses equispaced angles, with the sampling mask Ms selecting s equispaced angles.\nThe numerical results are summarized in Table 1. These are evaluated in terms of peak signal-\nto-noise ratio (PSNR) and structural similarity index (SSIM) considering three different sampling\nsettings, with different sparsity levels s = 16, 32, 64 angles, and noise set to 1% AWGN. It is\nevident that our method, TomoSelfDEQ, outperforms the competing approaches in terms of both\nPSNR and SSIM. In Fig. 1, we report the results obtained with the different methods considering 64\n1https://github.com/sedaboni/TomoSelfDEQ/\n2https://github.com/CambridgeCIA/LION\n6\n\n\nTable 1: Average PSNR and SSIM on the validation set with different sparsity levels s. The best\nresults are highlighted in bold.\ns = 16\ns = 32\ns = 64\nPSNR\nSSIM\nPSNR\nSSIM\nPSNR\nSSIM\nFBP\n14.27\n0.100\n18.42\n0.143\n22.87\n0.205\nTV\n23.83\n0.722\n26.14\n0.828\n27.39\n0.863\nSparse2Inverse\n19.21\n0.314\n21.14\n0.675\n26.80\n0.760\nTomoSelfDEQ\n26.25\n0.884\n28.26\n0.911\n29.41\n0.927\n(top row), 32 (middle row) and 16 (bottom row) angles. We can see that with TomoSelfDEQ was\nable to reconstruct sharp and neat boundaries, even though some finer details are lost due to over-\nsmoothing in certain regions. In addition, TomoSelfDEQ accurately reconstructs constant patches,\nwithout adding any significant artifacts and it proves to be stable with respect to the reduction\nof angles. On the other hand, FBP reconstructions are noisy and show an increasing number of\nstreaking artifacts as the number of angles decreases. In the TV regularized reconstructions, the\nstaircasing behavior is evident, and the sharpness of the boundaries deteriorates as the number of\nangles decreases. Sparse2Inverse produces reconstructions with clear artifacts, particularly when only\n16 angles are considered.\nSimilar consideration can be drawn for the reconstructions in Fig. 2, where we show reconstruc-\ntions of different walnut slices in the most challenging setting, i.e., with 16 angles. From the close-ups\nit is clear that Sparse2Inverse introduces numerous noisy artifacts, compromising the reconstructions,\nwhile TomoSelfDEQ better preserves objects shapes, significantly reducing noise presence. A note is,\nhowever, in order on the comparison with Sparse2Inverse. While both methods share key ideas such\nas operating in both image and projection domains, computing losses in the projection domain, and\navoiding explicit nullspace assumptions, TomoSelfDEQ differs fundamentally in several important\naspects. First, while Sparse2Inverse uses a standard U-Net architecture, our method leverages DEQ\nto implicitly represent an infinite-depth network. Second, TomoSelfDEQ provides theoretical guar-\nantees about matching supervised performance, while Sparse2Inverse relies primarily on empirical\nvalidation. These theoretical and architectural advantages translate into practical improvements, as\ndemonstrated in our numerical results where TomoSelfDEQ consistently outperforms Sparse2Inverse\nacross different undersampling rates (cf. Table 1).\nAblation study. We trained the same infinite-depth network through DEQ, considering different\nlosses to numerically validate the theoretical result in Theorem 2. In particular, we compare the self-\nsupervised loss Lself (cf. (9)), the usual supervised loss L′\nsup (cf. (11)), and the supervised loss Lsup\n(cf. (13)). We report the behavior in terms of PSNR and SSIM during training with these different\nlosses in Fig. 3. It can be seen that the unsupervised framework achieves comparable results with that\nof the supervised loss Lsup, thus confirming the result of Theorem 2. It is evident that the results with\nthe standard supervised loss L′\nsup outperform the others, since in this loss the information concerning\nthe undersampled data is not taken into account.\n6\nConclusions\nWe introduced TomoSelfDEQ, a self-supervised DEQ framework for sparse-angle CT reconstruction.\nOur main theoretical contribution extends SelfDEQ training guarantees to non-unitary operators\nlike the Radon transform, showing that under suitable assumptions, the self-supervised updates\nmatch those of fully-supervised training. Through extensive experiments on sparse-angle CT data,\nwe demonstrated that TomoSelfDEQ achieves state-of-the-art reconstruction quality while requiring\nonly undersampled measurements for training. The method consistently outperforms existing self-\nsupervised approaches across different undersampling rates, achieving high-quality reconstructions\neven with as few as 16 projection angles. Future work could explore extensions to other non-unitary\ninverse problems and investigate the theoretical implications of different sampling strategies. Addi-\ntionally, while our current validation strategy using equispaced angles demonstrates strong perfor-\n7\n\n\nGT\nFBP\nTV\nSparse2Inverse\nTomoSelfDEQ\nFigure 1: Qualitative results on different sparsity levels s. Top row: s = 64 angles. Middle row:\ns = 32 angles. Bottom row: s = 16 angles.\nGT\nFBP\nTV\nSparse2Inverse\nTomoSelfDEQ\nFigure 2: Qualitative results on different walnut slices considering s = 16 angles.\nmance, further investigation, using different validation protocols and testing on out-of-distribution\ndatasets, would provide valuable insights into the method’s generalization capabilities.\nAcknowledgments\nThe authors acknowledge (partial) support by the: Royal Society through the International Ex-\nchange scheme (grant n.\nIES\\R3\\223061 to TAB and MS); European Union - NextGeneration\n8\n\n\n(a) s = 16 angles\n(b) s = 32 angles\n(c) s = 64 angles\nFigure 3: Quality metrics computed on the validation set and plotted with respect to the training\nepochs for different selection of loss. Top row: PSNR. Bottom row: SSIM.\nEU (FAIR “Future Partnership Artificial Intelligence Research”, CUP J33C22002830006 to TAB,\nCUP J53C22003010006 to MS; PRIN P2022J9SNP “Advanced optimization METhods for automated\ncentral veIn Sign detection in multiple sclerosis from magneTic resonAnce imaging\" (AMETISTA)\nCUP E53D23017980001 to AS, PRIN 2022B32J5C “Inverse problems in PDE: theoretical and nu-\nmerical analysis\", CUP D53D23005770006 to MS); Air Force Office of Scientific Research (award\nnumber FA8655-23-1-7083 to MS); INdAM-GNCS (CUP E53C24001950001 to TAB and AS, CUP\nE53C23001670001 to AS); MUR Excellence Department Project (awarded to Dipartimento di Matem-\natica, Università di Genova, CUP D33C23001110001 to MS).\nReferences\n[1] Jonas Adler and Ozan Öktem. Solving ill-posed inverse problems using iterative deep neural\nnetworks. Inverse Problems, 33(12):124007, 2017.\n[2] Simon Arridge, Peter Maass, Ozan Öktem, and Carola-Bibiane Schönlieb. Solving inverse prob-\nlems using data-driven models. Acta Numerica, 28:1–174, 2019.\n[3] Joshua Batson and Loic Royer. Noise2self: Blind denoising by self-supervision. In International\nConference on Machine Learning, pages 524–533. PMLR, 2019.\n[4] Dongdong Chen, Julián Tachella, and Mike E Davies. Equivariant imaging: Learning beyond the\nrange space. In Proceedings of the IEEE/CVF International Conference on Computer Vision,\npages 4379–4388, 2021.\n[5] Aaron Defazio, Xingyu Alice Yang, Harsh Mehta, Konstantin Mishchenko, Ahmed Khaled, and\nAshok Cutkosky. The Road Less Scheduled. arXiv:2405.15682, 2024.\n[6] Henri Der Sarkissian, Felix Lucka, Maureen van Eijnatten, Giulia Colacicco, Sophia Bethany\nCoban, and Kees Joost Batenburg. A cone-beam X-ray computed tomography data collection\ndesigned for machine learning. Scientific data, 6(1):215, 2019.\n9\n\n\n[7] Samy Wu Fung, Howard Heaton, Qiuwei Li, Daniel McKenzie, Stanley Osher, and Wotao Yin.\nJFB: Jacobian-free backpropagation for implicit networks. In Proceedings of the AAAI Confer-\nence on Artificial Intelligence, volume 36, pages 6648–6656, 2022.\n[8] Weijie Gan, Chunwei Ying, Parna Eshraghi Boroojeni, Tongyao Wang, Cihat Eldeniz, Yuyang\nHu, Jiaming Liu, Yasheng Chen, Hongyu An, and Ulugbek S Kamilov. Self-supervised deep\nequilibrium models with theoretical guarantees and applications to MRI reconstruction. IEEE\nTransactions on Computational Imaging, 2023.\n[9] Davis Gilton, Gregory Ongie, and Rebecca Willett. Deep equilibrium architectures for inverse\nproblems in imaging. IEEE Transactions on Computational Imaging, 7:1123–1133, 2021.\n[10] Karol Gregor and Yann LeCun. Learning fast approximations of sparse coding. In Proceedings of\nthe 27th international conference on international conference on machine learning, pages 399–\n406, 2010.\n[11] Nadja Gruber, Johannes Schwab, Elke Gizewski, and Markus Haltmeier. Sparse2inverse: Self-\nsupervised inversion of sparse-view CT data. arXiv:2402.16921, 2024.\n[12] Allard A Hendriksen, Daniël Maria Pelt, and K Joost Batenburg. Noise2inverse: Self-supervised\ndeep convolutional denoising for tomography. IEEE Transactions on Computational Imaging,\n6:1320–1335, 2020.\n[13] Allard A Hendriksen, Dirk Schut, Willem Jan Palenstijn, Nicola Viganó, Jisoo Kim, Daniël M\nPelt, Tristan Van Leeuwen, and K Joost Batenburg. Tomosipo: fast, flexible, and convenient 3D\ntomography for complex scanning geometries in python. Optics Express, 29(24):40494–40513,\n2021.\n[14] Kyong Hwan Jin, Michael T McCann, Emmanuel Froustey, and Michael Unser. Deep convo-\nlutional neural network for inverse problems in imaging. IEEE Transactions on Computational\nImaging, 26(9):4509–4522, 2017.\n[15] Jaakko Lehtinen, Jacob Munkberg, Jon Hasselgren, Samuli Laine, Tero Karras, Miika Aittala,\nand Timo Aila. Noise2noise: Learning image restoration without clean data. arXiv:1803.04189,\n2018.\n[16] Alice Lucas, Michael Iliadis, Rafael Molina, and Aggelos K Katsaggelos.\nUsing deep neural\nnetworks for inverse problems in imaging: beyond analytical methods. IEEE Signal Processing\nMagazine, 35(1):20–36, 2018.\n[17] Frank Natterer. The mathematics of computerized tomography. SIAM, 2001.\n[18] Olaf Ronneberger, Philipp Fischer, and Thomas Brox.\nU-net:\nConvolutional networks for\nbiomedical image segmentation. In Medical image computing and computer-assisted intervention–\nMICCAI 2015: 18th international conference, Munich, Germany, October 5-9, 2015, proceedings,\npart III 18, pages 234–241. Springer, 2015.\n[19] Ernest Ryu, Jialin Liu, Sicheng Wang, Xiaohan Chen, Zhangyang Wang, and Wotao Yin. Plug-\nand-play methods provably converge with properly trained denoisers. In International Conference\non Machine Learning, pages 5546–5557. PMLR, 2019.\n[20] Mehmet Ozan Unal, Metin Ertas, and Isa Yildirim. Proj2proj: self-supervised low-dose CT\nreconstruction. PeerJ Computer Science, 10:e1849, 2024.\n[21] Emilien Valat, Andreas Hauptmann, and Ozan Öktem.\nSelf-supervised denoiser framework.\narXiv:2411.19593, 2024.\n[22] Singanallur V Venkatakrishnan, Charles A Bouman, and Brendt Wohlberg. Plug-and-play priors\nfor model based reconstruction.\nIn 2013 IEEE global conference on signal and information\nprocessing, pages 945–948. IEEE, 2013.\n10\n\n\n",
  "metadata": {
    "source_file": "dataset/pdfs/arxiv_2502.21320v1.pdf",
    "total_pages": 10,
    "title": "TomoSelfDEQ: Self-Supervised Deep Equilibrium Learning for Sparse-Angle CT Reconstruction",
    "authors": [
      "Tatiana A. Bubba",
      "Matteo Santacesaria",
      "Andrea Sebastiani"
    ],
    "abstract": "Deep learning has emerged as a powerful tool for solving inverse problems in\nimaging, including computed tomography (CT). However, most approaches require\npaired training data with ground truth images, which can be difficult to\nobtain, e.g., in medical applications. We present TomoSelfDEQ, a\nself-supervised Deep Equilibrium (DEQ) framework for sparse-angle CT\nreconstruction that trains directly on undersampled measurements. We establish\ntheoretical guarantees showing that, under suitable assumptions, our\nself-supervised updates match those of fully-supervised training with a loss\nincluding the (possibly non-unitary) forward operator like the CT forward map.\nNumerical experiments on sparse-angle CT data confirm this finding, also\ndemonstrating that TomoSelfDEQ outperforms existing self-supervised methods,\nachieving state-of-the-art results with as few as 16 projection angles.",
    "published_date": "2025-02-28",
    "source": "arxiv"
  }
}