{
  "id": "arxiv_2502.21104v1",
  "text": "Extending the OmpSs-2 Programming Model for Hybrid\nQuantum-Classical Programming\nPhilip Döbler1, David Álvarez2, Lucas J. Menger1, Thomas Lippert1,3, Vicenç Beltran2,\nand Manpreet Singh Jattana1\n1Modular Supercomputing and Quantum Computing, Goethe University Frankfurt,\nKettenhofweg 139, 60325 Frankfurt am Main, Germany\n2Computer Sciences - System Tools and Advanced Runtimes, Barcelona\nSupercomputing Center, Plaça Eusebi Güell 1-3, 08034 Barcelona, Spain\n3Jülich Supercomputing Centre, Institute for Advanced Simulation, Forschungszentrum\nJülich, Wilhelm-Johnen-Straße, 52428 Jülich, Germany\n{doebler, menger, t.lippert, jattana}@em.uni-frankfurt.de,\n{david.alvarez, vbeltran}@bsc.es\nFebruary 28, 2025\nAbstract\nThe OmpSs-2 programming model is used in HPC programs to parallelize code and offload\ncode to accelerators. In this work, we extend the offloading capability to quantum computers.\nWe explain the necessary changes to the Clang compiler and the Nanos6 runtime, which are\nboth part of OmpSs-2.\nIn addition, we develop a simulator that simulates a quantum\ncomputer in the network and receives the jobs offloaded by the runtime.\nFour detailed\nexamples show how our programming model can be used to write hybrid quantum-classical\nsoftware. The examples are random number generation, a parameter scan using the mean-\nfield ansatz, a variational algorithm using this ansatz, and handwritten digit recognition\nusing a hybrid convolutional neural network.\n1\nIntroduction\nOver the past 40 years, quantum computers have evolved from a theoretical idea [1, 2] to\nexperiments in physics labs [3, 4] to programmable machines that are becoming increasingly\naccessible to computer scientists [5, 6]. At the same time, we are seeing a slowdown in Moore’s\nLaw, which has driven the rapid evolution of the High Performance Computing (HPC) sector\nfor decades. To further increase the performance of HPC systems, more and more specialized\naccelerators are being used that are very good at solving specific types of problems. A well-\nknown example is the GPU, which is well suited for machine learning workloads, among others.\nFor quantum computers, it has been shown theoretically that they can solve certain types of\n1\narXiv:2502.21104v1  [cs.ET]  28 Feb 2025\n\n\ntasks better than classical computers [7, 8]. However, they are poorly suited for other tasks that\nclassical computers are very good at, such as the simple addition of two numbers [9, 10]. Because\nof this specification, quantum computers fit very well into the accelerator model. Instead of being\nstandalone machines, they will be used as part of a larger HPC system to handle parts of larger\nworkloads that are well suited for them.\nHPC users should therefore be able to extend their programs for quantum computers without\nhaving to also become experts in quantum mechanics. This is possible if we extend tools from\nthe HPC world to quantum computers, so that users can continue to work in their familiar envi-\nronment. One such tool is the OmpSs-2 programming model [11], which supports heterogeneous\nenvironments with accelerators such as GPUs and FPGAs. OmpSs-2 allows existing code to\nbe parallelized and offloaded to accelerators through a set of compiler directives similar to the\nwidely used OpenMP [12]. Several of the features developed in OmpSs-2 were later adopted in\nthe OpenMP standard. The ease of use of pragma annotations, together with the already exist-\ning support for accelerators, is ideal for enabling HPC users to extend their code for quantum\ncomputing, but support for quantum accelerators is not yet available in OmpSs-2.\nIn this paper, we present an extension to OmpSs-2 that allows parts of the code to be offloaded\nto quantum computers in the form of specially declared tasks. The classical code can be written\nas usual in C, C++ or FORTRAN, which are widely used in HPC. Using pragma statements,\nwe can declare kernels to be offloaded that are implemented in separate files in a domain specific\nquantum language. Other features of OmpSs-2, such as the task-based programming model or\nsupport for other accelerators, can be used in parallel with our quantum extension.\nThe remainder of the paper is organized as follows: Section 2 gives an overview of other\nframeworks for quantum-classical hybrid programs. Section 3 introduces the OmpSs-2 program-\nming model, and in Section 4 we discuss the quantum computing extension. Section 5 contains\nfour application examples that illustrate the use of our extension. The main results are concluded\nin Section 6.\n2\nRelated Work\nThere are many programming languages specifically for quantum computing, as well as many\nextensions of classical programming languages to support quantum computing [13, 14]. The first\nlanguage was introduced in 1996 [15] as a pseudocode to describe quantum algorithms. Review\narticles on this topic have already been published in the years 2004 [16] and 2006 [17].\n2.1\nXACC and QCOR\nThe field for hybrid quantum-classical programming models however is relatively new. The first\nquantum-classical hybrid programming model, called eXtreme-scale ACCelerator (XACC) [18],\nwas presented in 2018 and described in more detail in a later publication [19]. Another paper\napplies the programming model to quantum chemistry [20]. XACC defines a model in which\nthere is a host (the CPU), an accelerator (the QPU), and a buffer. The buffer is generated by the\nhost and used by the accelerator to store results. Users describe the quantum code in kernels,\n2\n\n\nwhich are annotated with __qpu__. The description is done at the circuit level, either in XACC\nassembly language (XASM) or another common language. XACC also provides a compiler to\ncompile the quantum kernels.\nThe XACC framework is related to the QCOR specification [21]. It defines how languages\ncan be extended for single-source quantum-classical programming. The memory model defines\nmemory spaces on the host and device. Host device memory can be allocated explicitly. The\ncompiler allocates device memory if, for example, host memory is reserved for quantum results\nand handles memory transfers between host and device memory. There is a C++ implementation\nof the QCOR specification [22]. It introduces a compiler called qcor (note the small letters in\ncontrast to the capital letters of the specification name), which provides a plugin for the clang\ncompiler [23] and uses the XACC framework to compile quantum resources.\nThe compiler\nhandles quantum-specific issues and can be invoked with similar options as classical compilers.\nThere is also a multi threading extension to qcor [24], as well as a Python implementation [25].\n2.2\nCUDA Quantum\nNVIDIA CUDA Quantum [26] takes a similar approach to QCOR. The extension to CUDA [27]\nalso provides a single source programming model. Code for quantum computers can be written\nin special kernels, similar to GPU code in CUDA. There are frontends to write code in C++ and\nPython. To parallelize the classical parts of the code, CUDA Quantum can be combined with\nconventional programming models such as OpenMP [12]. The quantum kernels are compiled\ninto a quantum intermediate representation that can be executed on different backends. For\nexample, compiler flags can be used to switch between execution on a simulator and on real\nquantum hardware.\n2.3\nQPU Extension for OpenCL\nThe Open Computing Language (OpenCL) [28] is an open source API for heterogeneous systems.\nIt was originally developed to program GPUs, but in the meantime offers support for additional\naccelerators. To execute code on an accelerator, kernels can be written in a subset of the C99\nstandard [29]. These kernels can be offloaded to the accelerator via a standardized API.\nReference [30] extends OpenCL for QPUs. Quantum circuits are described on gate level with\na syntax that resembles the C implementation of Qulacs [31]. The kernel is loaded in the main\nprogram, compiled and offloaded to the QPU with a series of commands. Currently the imple-\nmentation only supports simulators and no real quantum hardware. Example implementations\nfor the Variational Quantum Eigensolver [32] and Shor’s algorithm [7] can be found at [33].\n2.4\nQuingo\nReference [34] assumes a refined Heterogeneous Quantum-Classical Computation (HQCC) model\nfor near term quantum hardware. Int this model, the hardware consists of a classical computer\nconnected to a quantum coprocessor. The latency of the connection is so high that no real-time\nfeedback with interleaved classical operations can take place due to the limited coherence time\n3\n\n\nof the qubits. The coprocessor in turn consists of a quantum control processor that controls\nthe qubits but can also perform classical operations, and because it is connected to the qubits\nwith very low latency, it can be used for feedback loops in the quantum circuit and for inter-\nleaved quantum classical operations. However, the separate classical computer usually has more\ncomputing power than the quantum control processor.\nThe user is asked to write two programs: one program in a classical programming language\nsuch as Python or C++ that runs on the classical computer. The second program describes the\nquantum operations, as well as classical operations such as feedback loops that are closely related\nto the quantum operations and should therefore run on the quantum control processor. For the\nlater, [34] introduces a custom programming language that is influenced by OpenCL [28] called\nQuingo. It allows the usage of quantum as well as classical operations that are both executed on\nthe quantum control processor. The user is responsible for minimizing classical operations on\nthe quantum control processor and performing classical operations that are too computational\nextensive for the quantum control processor, on the separate classical computer. Qingo provides\na compiler that compiles the code to eQASM [35], a quantum assembly language.\n2.5\nQCCP\nQCCP is a task flow programming model for classical-quantum hybrid computing [36]. It allows\nfunctions in Python to be annotated with decorators for classical or quantum tasks. From the\ndependencies, QCCP builds a Direct Acyclic Graph (DAG). At runtime, there are two levels\nof schedulers: A workflow scheduler sends tasks to the classical and quantum backends, where\nthey are executed by the respective local schedulers that manage the tasks on each backend.\nThis approach is similar to our work in the sense that we also model dependencies at the task\nlevel. However, instead of creating a novel framework, we extend the well-established OmpSs-2\nframework.\n3\nOmpSs-2 Programming Model\nOmpSs-2 is a data-flow programming model, which can be used to parallelize C, C++ and\nFORTRAN applications through the use of a set of compiler directives [11]. OmpSs-2 is task-\nbased, and a task is the minimum unit of work that can be scheduled by the programming\nmodel. Tasks are primarily synchronized using data dependencies, which let users describe the\nprogram as a DAG of tasks. This information is later used by the runtime, which will ensure\na task execution order which guarantees the absence of data races and the equivalence with\na sequential version. The data-flow model of OmpSs-2 is similar to OpenMP Tasking, but is\noriented towards the inclusion of features that prevent the need for global synchronization points.\nDuring program execution, tasks are created online, and are submitted for execution as soon\nas they become ready (all of their dependencies have been satisfied). OmpSs-2 also supports\ndevice tasks, that are offloaded to accelerators and thus do not occupy any CPU core. The\ncurrent implementation includes support for GPUs through CUDA, and FPGAs. Device tasks\nget offloaded to the appropiate accelerator when their dependencies are fulfilled, and then the\n4\n\n\n2\n1\n0\n3\n4\n5\n6\nCPU0\nCPU1\nDevice\n0\n1\n2\n3\n4\n5\n6\nDevice task\nCPU task\nTime\nFigure 1: An example of the OmpSs-2 task graph executed on a heterogeneous platform. Tasks executing on\ndevices (in this example, task 3) can stablish fine-grained data dependencies with host tasks. At runtime, their\noffloading is overlapped with host execution, and dependencies cause asynchronous release of dependant tasks,\nas depicted by the dashed lines in the execution trace.\nOmpSs-2 runtime will periodically check for their completion. As soon as the device task is\ncompleted, its dependencies will be released, and any tasks which depend on their completion\nwill be submitted for execution. This process is shown in Figure 1, where CPU and device tasks\noverlap their execution using dependencies.\nDevice tasks are defined in the source code by using the device clause in a task declaration,\nsuch as shown in Listing 1. In this example, the saxpy task is defined in CUDA in a separate file,\nand only the declaration is included in the OmpSs-2 code, along with a device(cuda) clause.\nThe data dependencies on the buffers will synchronize the host-side init_buffer tasks with\nthe GPU-side saxpy task, without requiring any explicit CUDA calls. The device task will be\nlaunched directly to an available GPU by the OmpSs-2 runtime, which will also poll the device\nto determine when the task has finished.\nThis data-flow mechanism for offloading tasks to accelerator allows for seamless integration\nin heterogeneous applications, and offers overlapping capabilities between offloaded operations\nand host tasks. This approach is the one that will be exploited in order to implement QPU\noffloading in OmpSs-2 programs.\n4\nOmpSs-2 QPU Extension\nFor the OmpSs-2 QPU extension, we extend the OmpSs-2 Clang compiler and the Nanos6 run-\ntime, which together implement the OmpSs-2 programming model. The goal is to support an\noffloading mechanism for QPUs, similar to the already supported GPU offloading. Since com-\nputing on a quantum computer is fundamentally different from computing on a CPU or GPU, we\nare not trying to translate C++ code for the quantum computer. Instead, we use a widely used\nlanguage for quantum computers called Open Quantum Assembly Language (OpenQASM) [37].\n5\n\n\n1\n// Defined\nin\nkernel . cu\n2 #pragma oss\ntask\ndevice ( cuda )\nin (x [ n ] ,\ny [ n ] )\ninout ( a [ n ] )\nndrange ( . . . )\n3\n__global__ void\nsaxpy ( double ∗a ,\ndouble ∗x ,\ndouble ∗y ,\nint n) ;\n4\n5\n// CPU Task\n6 #pragma oss\ntask\nout (x [ n ] )\n7\nvoid\ni n i t _ b u f f e r ( double ∗x ,\nint n) ;\n8\n9\nint\nmain ()\n{\n10\ndouble ∗a ,\n∗x ,\n∗y ;\n11\nint n ;\n12\n//\n[ . . . ]\n13\ni n i t _ b u f f e r (a ,\nn) ;\n14\ni n i t _ b u f f e r (x ,\nn) ;\n15\ni n i t _ b u f f e r (y ,\nn) ;\n16\n17\n// Saxpy\nw i l l\nbe\ntransparently\no ff lo ad ed\nto a GPU and synchronized\nwith\nthe\n18\n//\ni n i t _ b u f f e r\ninstances .\n19\nsaxpy (a ,\nx ,\ny ,\nn) ;\n20 #pragma oss\ntaskwait\n21\n}\nListing 1: OmpSs-2 device task offloading example. The saxpy function is declared as CUDA device\ntask (line 2). When called in line 19, it is offloaded to the GPU.\nIn the C++ code, a function for the quantum computer part is declared, but not implemented,\nand marked with a pragma as a QPU task. The function is implemented in an OpenQASM file\nwith the function name as the filename. This allows both traditional HPC users and quantum\ncomputing specialists to implement their respective code in a familiar language, and the two\nparts of the code can be easily brought together.\nThe OmpSs-2 interface to declare a QPU task is defined as follows:\n#pragma oss task device(qpu) [clause [...]]\nnew-line\nvoid qpu_kernel_name(int shots, qpu_result_t *results [,qpu_parameters_t *p\n[,const char *extension]]);\nThe pragma to offload tasks to the QPU is #pragma oss task device(qpu). This is usually\nfollowed by declarations to model the data dependencies as shown in Section 3 for the CUDA\ntasks. A function declared as a QPU task must receive at least two parameters, with two optional\nadditional parameters, as defined in Table 1. Moreover, the function name must match with an\nOpenQASM file located in a specific folder alongside the OmpSs-2 program.\nThe first parameter is the number of measurements the quantum computer should perform,\nthe second parameter is a pointer to the results structure. This structure is filled by the Nanos6\nruntime with the results of the quantum computer, which can then be used in the subsequent\nprogram. In addition to the two mandatory parameters, there are two optional parameters. The\nfirst optional parameter is a structure that can contain values for parameters in the OpenQASM\nfile. We use the OpenQASM 2.0 standard, which does not support the use of parameters by\ndefault. However, we allow the use of parameters in the OpenQASM code using the syntax\n$[x], where x enumerates the parameters, as shown in [38]. These parameters are replaced at\nruntime, before offloading to the quantum computer, by the values in the parameter structure\n6\n\n\nTable 1: Parameters for QPU device offloading tasks in OmpSs-2.\nType\nDirection\nMandatory\nUse\n0\nint\nInput\nYes\nNumber of measurements the quan-\ntum computer should perform\n1\nqpu_results_t *\nOutput\nYes\nPointer to the results structure, con-\ntaining the output from the quantum\ncomputer\n2\nqpu_parameters_t *\nInput\nNo\nValues to substitute specified parame-\nters in the OpenQASM file\n3\nconst char *\nInput\nNo\nString to be appended to the Open-\nQASM file\npassed to the function. The use of parameters whose value can be set at runtime is important,\nfor example, for variational algorithms, as shown in the example in Section 5.3. The second\noptional parameter is a string that is appended to the OpenQASM code from the file. This\nparameter can be used either if several circuits are to be executed which differ only slightly, e.g.\nbecause measurements are made in a different basis, or if the circuit is to be changed at runtime.\nIf there is no file with OpenQASM code or the file is empty, only this string is used. An example\nfor the use of this extension mechanism can also be found in Section 5.3.\nThere is no additional parameter to set the initial state, since we consider the state prepa-\nration to be part of the quantum circuit. The initial state is either fixed and can be set in\nthe OpenQASM code by fixed operations at the beginning of the circuit, or we have an initial\nstate that varies at runtime, which can be achieved by parameters in the OpenQASM code.\nFor example, we can apply the gate Rx(θi) to the ith qubit and set either θi = 0 or θi = π at\nruntime, depending on whether we want to prepare the initial state |0⟩or |1⟩for qubit i.\nFigure 2 provides a brief overview of our architecture. At the top, we see that the classical\nand quantum sources are processed separately by a classical and quantum compiler toolchain.\nThe runtime is shown at the bottom. The Nanos6 scheduler executes classical tasks on the\nHPC cluster and offloads quantum tasks to a backend capable of processing them.\nIn our\nexperimental setup, the backend is a simulator, but it could be a real quantum computer. The\nfollowing sections explain the different components in more detail.\n4.1\nCompiler\nWe extend the OmpSs-2 clang compiler to process the pragma device (qpu). For functions\nprovided with this pragma, no implementation is expected during linking. Instead, a call to\nthe Nanos6 runtime is inserted at the appropriate place, which takes care of offloading to the\nQPU. Only the classical sources are processed by the clang compiler. The quantum sources\nrequire a separate compiler toolchain. For this project, we use the TKET compiler developed\nby Quantinuum [39] to compile from an OpenQASM file with arbitrary gates to an OpenQASM\nfile with gates in the native gate set of a device. We chose the TKET compiler because of its\nmodular structure and easy extensibility. There are several frontends to read files in different\ncommon quantum computing formats and backends can be added for custom quantum hardware\n7\n\n\nHPC Cluster\nBackend (Simulator)\nClassical Sources\nOmpSs-2 Clang\nClassical Executable\nQuantum Sources\nTKET Compiler\nOpenQASM\nCompiler\nClassical Tasks\nNanos6\nQuantum Tasks\nRun\nOffload\nto QC\nRuntime\nFigure 2: (Top) Compilation toolchains that process classical and quantum resources separately. The link is\ncreated by the fact that the function name in the classic code must be identical to the filename of the OpenQASM\nfile. (Bottom) The Nanos6 runtime runs classical tasks on the HPC cluster, if their dependencies are satisfied.\nQuantum tasks are offloaded to the backend, which is in our case a simulator.\nor simulators. However, any other quantum compiler capable of outputting OpenQASM code\ncan also be used.\n4.2\nRuntime\nFor the runtime, we extend the Nanos6 runtime of OmpSs-2 with the ability to offload Open-\nQASM code to a quantum computer. The Nanos6 runtime receives the name of the called func-\ntion and loads the file ./qasm/<filename>.qasm. If this file is found, its contents are loaded. If\nthere are parameters in the OpenQASM file, they are overwritten with the given values, and if\nthe function call has a qasm extension, it is extended to the end of the OpenQASM code. The\nruntime then establishes a socket communication with the backend to send the number of shots\nand the circuit to be executed. The backend receives the job and returns a job ID. The runtime\npolls the backend for the status of all started jobs and requests the results when a job is finished.\nThe network connectivity of the quantum computer fits well into the loosely integrated\nclient-server model, where the quantum hardware is a standalone machine (server) that can be\naccessed by multiple computing nodes (clients) [40]. Since quantum computers are currently a\nscarce resource and node-level integration is difficult, this model fits well with currently available\nhardware. If at some point a tighter integration of quantum hardware becomes possible, for\nexample via a PCIe expansion card, the implementation in the Nanos6 runtime could be changed\nto accommodate the new architecture.\n4.3\nBackend\nIn our experimental setup, we use a simulator as the backend. The simulator acts as a quantum\ncomputer that sits on the network and can be queried at a specific IP address and port. Once\nconnected, the simulator can be requested to do three things: receive a new job, send the status\nof an existing job, and return the results of a completed job. When a new job is sent, the\n8\n\n\nsimulator assigns a job ID and stores the OpenQASM code and the required number of shots in\na dictionary. The ID is stored in a queue and also sent back to the client. A separate thread\nprocesses the jobs in the queue and stores the results. The client can use the ID to ask for\nthe job status, which is either “queued”, “running”, “completed” or “failed”, and also to ask for\nthe results when the job is completed. To simulate the OpenQASM code, we use the QASM\nsimulator from the IBM Qiskit framework [41]. In this setup, a quantum compiler would not be\nneeded, since the simulator is able to handle all commonly used gates. However, we designed\nthe architecture with a real quantum computer in mind, and therefore, also present a solution\nfor quantum compilation as a standard framework.\nIn our setup, the queue is processed according to a simple FIFO principle. This principle\nworks well when the execution time of a quantum job is much smaller than the granularity of the\nbatch scheduler [42]. This is the case, for example, with superconducting quantum hardware,\nwhere gate times are on the order of tens to hundreds of nanoseconds [43, 44]. For slower quantum\nhardware, such as trapped ion processors with gate times on the order of microseconds [43],\nmore sophisticated scheduling methods may be useful to prevent the quantum hardware from\nblocking for too long. This use case is not our focus, but does not preclude use with OmpSs-2\nif the backend is adapted accordingly.\n4.4\nInterconnect\nThe quantum computer is simulated on the same device that runs the classical program in\nour setup. However, we discuss what kind of interconnect would be needed for a real setup.\nThe amount of data sent to the quantum computer depends on the size of the circuit. Today’s\nquantum hardware can only perform a limited number of operations before the errors accumulate\ntoo much or the coherence of the qubits is lost, and the number of qubits is also limited to a few\nhundred at most. Hence, the circuits are currently relatively short. In our sample applications\nin Section 5, between 10 B and 10 kB of data are sent to the quantum computer per offloading\noperation. The amount of data sent back depends on the number of shots and the measured\noutput distribution. Because the backend sends the data back to the runtime in the form of\na dictionary, with the measured state as the key and the number of shots as the value, the\nsize increases as the number of different results increases. If we assume that a maximum of\n106 shots are used, and it is unlikely in a reasonable quantum algorithm that they are evenly\ndistributed over all possible states, the data to be sent back remains in the range of kilobytes,\nmaximum megabytes. The number of offloading operations can range from one to thousands.\nOverall, however, this does not result in data volumes that challenge the bandwidths of today’s\ninterconnects, which are in the range of hundreds of gigabits per second [45].\nWe also do not expect latency to be an issue.\nFor example, superconducting quantum\ncomputers require tens to hundreds of nanoseconds to perform a 2-qubit operation. [43, 44].\nAssuming a circuit with a 2-qubit operations depth of 10, a shot takes hundreds nanoseconds to\nmicroseconds, not including the time required for setup, 1-qubit gates, and measurements. When\nwe run 103 to 106 shots, we get a run time of hundreds of microseconds to seconds, which is orders\nof magnitude higher than the single-digit microsecond latency of today’s interconnects [45]. Also,\n9\n\n\nin many applications, we can offload multiple kernels in parallel to hide the latency. An example\nof this is shown in Section 5.2.\nIn future applications, we can expect the required bandwidth to increase as wider and deeper\nquantum circuits can be run on quantum computers. For example, the famous Shor’s algo-\nrithm [7] is expected to require something on the order of 1012 gates to break a 2048 bit RSA\nencryption [46]. If we assume that the description of each gate requires a few bytes in the Open-\nQASM file, this would mean a data transfer in the terabyte range. However, circuits of this\nsize could be compressed very efficiently because they mostly consist of a few recurring gates.\nFor future error correction schemes, low latency is required because the classical computations\nfor error correction must be much faster than the decoherence times of the qubits. But we as-\nsume that error correction will be performed very close to the quantum hardware, on specialized\nhardware such as FPGAs, and not as part of the application implemented with OmpSs-2. We\nconclude that there are no exceptional requirements for the interconnection between classical\nand quantum hardware and that state-of-the-art solutions are well suited for this task.\n5\nApplication Examples\nIn this section, we present four examples to show how the OmpSs-2 QPU extension can be used\nand the types of applications that can be realized. The first example is a minimal working\nexample that shows the basic use of the device(qpu) pragma.\nThe second example shows\nthe use of the optional parameters explained in Section 4. Examples three and four are more\nextensive and show how easily existing third-party libraries can be integrated into the program.\n5.1\nRandom Number Generation\nThe simplest example and a kind of “hello world” example for quantum circuits is a coin flip.\nWe can see the OpenQASM part of the code in Listing 2. By simply applying a Hadamard gate,\nwe create a superposition and perform a measurement. We expect to measure the states 0 and\n1 each with the probability 0.5. In the C++ code, shown in Listing 3, we define a task to print\nthe results (line 1) and one to run the quantum code on the quantum computer (line 6), which\nis annotated with device(qpu).\nTo model the dependencies between the tasks, we use the pragmas provided by OmpSs-\n2. For the coin flip task, the results object is an output dependency, as the task writes the\nresults to memory. For the print results task, the results are an input dependency, as they are\nnot modified by this task. It is the user’s responsibility to fully model the dependencies with\npragma annotations. We run the example with 100,000 shots and the result is 50,083 times state\n0 and 49,917 times state 1. Due to the probabilistic nature of the quantum computer, this result\nmay change from run to run.\n5.2\nEnergy Landscape Plotting\nFor this example we use the possibility to parameterize quantum circuits. The OpenQASM file\ncontains a circuit called mean-field ansatz [47] with the two parameters θ0 and θ1. The circuit\n10\n\n\n1\nqreg q [ 1 ] ;\n2\ncreg\nc [ 1 ] ;\n3\nh q [ 0 ] ;\n4\nmeasure q [ 0 ] −> c [ 0 ] ;\nListing 2: Coin flip example OpenQASM code. The quantum computer is used to create random\nbinary numbers.\n1 #pragma oss\ntask\nin (∗r e s u l t s )\n2\nvoid\nprint_results ( qpu_result_t ∗r e s u l t s ) {\n3\n//\nprint\nthe\nr e s u l t s\n4\n}\n5\n6 #pragma oss\ntask\ndevice (qpu)\nout (∗r e s u l t s )\n7\nvoid\ncoin_flip ( int\nshots ,\nqpu_result_t∗\nr e s u l t s ) ;\n8\n9\nint\nmain ()\n{\n10\nqpu_result_t ∗r = ( qpu_result_t\n∗) malloc ( s i z e o f ( qpu_result_t ) ) ;\n11\ncoin_flip (NUM_SHOTS,\nr ) ;\n12\nprint_results ( r ) ;\n13 #pragma oss\ntaskwait\n14\n}\nListing 3: Coin flip example C++ code.\nWe annotate the function coin_flip with the pragma\ndevice(qpu) to offload it to the quantum computer.\ndiagram for this example is shown in Figure 3. In the OpenQASM file we use the symbol $[x]\nfor the parameters, where x enumerates the parameters. Listing 4 shows the excerpt from the\nOpenQASM file of the example. We apply an Rz gate to the qubits q0 and q2, where the rotation\nangles are $[0] and $[1].\nThe goal of this program is to calculate the expectation value of the mean-field ansatz for\ndifferent values of θ0 and θ1. To calculate the expectation value, we have to measure in different\nbases. This means that the same circuit is run several times with different additional rotations\nbefore the measurement. To avoid having to write several OpenQASM files that differ only\nslightly, we use the qasm extension feature. We iterate through an array of extensions and call\nq0\nRx(π\n2 )\nRz(θ0)\nRx(π\n2 )\nq1\nRy(π\n2 )\nRy(−π\n2 )\nq2\nRx(π\n2 )\nRz(θ1)\nRx(π\n2 )\nq3\nRy(π\n2 )\nRy(−π\n2 )\nFigure 3: Circuit diagram of the mean-field ansatz for four qubits. The two parameters θ0 and θ1 can be freely\nselected.\n11\n\n\n1\n//\n. . .\n2\nrz ( $ [ 0 ] )\nq [ 0 ] ;\n3\nrz ( $ [ 1 ] )\nq [ 2 ] ;\n4\n//\n. . .\nListing 4: Part of the mean-field ansatz with two parameters.\nthe quantum computer with a different extension each time. In Listing 5, line 14 we can see the\ndefinition of the extensions. We run this circuit for 32 different values of θ0 and θ1 to obtain a\ntotal of 1024 expectation values. They form an energy landscape, which is plotted in Figure 4.\n0\nπ\n2\nπ\n3π\n2\n2π\n0\nπ\n2\nπ\n3π\n2\n2π\n−6\n−4\n−2\n0\n2\nθ1\nθ0\nE(θ0, θ1)\nFigure 4: Expectation value E for different angles θ0 and θ1.\nThe code in Listing 5 offloads the circuits sequentially. It means that the circuit with the first\nOpenQASM extension is offloaded, and only after the results are sent back from the backend\nand further processed in the calc_energy function, the next circuit is offloaded. Since we are\nsimulating a single quantum computer in our backend, this approach is feasible. However, the\nstrength of OmpSs-2 is that we can do the offloading asynchronously. This can help to hide\nthe latency even if there is only one quantum computer processing the circuits. But the main\nadvantage is that in a setup with multiple quantum computers, the circuits are processed in\nparallel.\nIn Listing 6, we can see a modified version of the code. We create as many result struct\nobjects as there are OpenQASM extensions (line 11). The taskwait pragma is not called inside\nthe inner loop, instead we model the dependencies for the parameters and the total energy.\nThe calc_energy function is declared as a task that performs a reduction by summing the\nenergy values of the 18 different circuits (line 2). This means that once the first quantum circuit\nis offloaded, the next one can be sent directly to the quantum computer without waiting for\nthe results of the first one. The taskwait pragma on line 49 prevents the main function from\nexiting before all tasks have finished. In our experimental setup, we only simulate one quantum\ncomputer. Nevertheless the runtime for the parameter scan is reduced by 14%, if we use the\nparallel version, since we can hide the latency. This improvement certainly depends on the size\n12\n\n\n1 #pragma oss\ntask\ndevice (qpu)\nin (∗p)\nout (∗r e s u l t s )\nin (∗extension )\n2\nvoid\nansatz ( int\nshots ,\nqpu_result_t ∗r e s u l t s ,\nqpu_parameters_t ∗p ,\nconst\nchar\n∗extension ) ;\n3\n4 # pragma oss\ntask\nin (∗r e s u l t s )\nout (∗energy )\n5\nvoid\ncalc_energy ( qpu_result_t ∗r e s u l t s ,\ndouble ∗energy ) {\n6\n//\n. . .\n7\n}\n8\n9\nint\nmain ()\n{\n10\n//\n. . .\n11\nqpu_parameters_t ∗p = ( qpu_parameters_t ∗) malloc ( s i z e o f ( qpu_parameters_t ) ) ;\n12\n//\n. . .\n13\n//\narray\nof qasm extensions\n14\nconst\nchar ∗qasm_extensions [ ] = {\n15\n\"ry ( pi /2) q [ 0 ] ; \\ nry ( pi /2) q [ 1 ] ; \\ nmeasure q [ 0 ] −> c [ 0 ] ; \\ nmeasure q [ 1 ] −> c\n[ 1 ] ; \" ,\n16\n\"ry ( pi /2) q [ 0 ] ; \\ nry ( pi /2) q [ 2 ] ; \\ nmeasure q [ 0 ] −> c [ 0 ] ; \\ nmeasure q [ 2 ] −> c\n[ 2 ] ; \" ,\n17\n\"ry ( pi /2) q [ 0 ] ; \\ nry ( pi /2) q [ 3 ] ; \\ nmeasure q [ 0 ] −> c [ 0 ] ; \\ nmeasure q [ 3 ] −> c\n[ 3 ] ; \" ,\n18\n//\n. . .\n19\n}\n20\ni n i t i a l i z e _ p a r a m e t e r s (p) ;\n21\ndouble ∗energy = ( double\n∗) malloc ( s i z e o f ( double ) ) ;\n22\ndouble\nstep_size = (2 ∗M_PI) /\nsteps ;\n23\nf o r\n( size_t\ni = 0;\ni < steps ;\ni++) {\n24\np−>parameters [ 0 ] = i\n∗step_size ;\n25\nf o r\n( size_t\nj = 0;\nj < steps ;\nj++) {\n26\np−>parameters [ 1 ] = j\n∗step_size ;\n27\ndouble\ntotal_energy = 0 . ;\n28\nf o r\n( size_t k = 0; k < num_ansaetze ;\nk++) {\n29\nansatz (num_shots ,\nr , p ,\nqasm_extensions [ k ] ) ;\n30\ncalc_energy ( r ,\nenergy ) ;\n31 #pragma oss\ntaskwait\n32\ntotal_energy += ∗energy ;\n33\n}\n34\n//\nprint\nenergy\nf o r\ncurrent\nparameters\n35\n}\n36\n}\n37\n//\nf r e e\nresources\n38\n}\nListing 5: C++ code for the sequential parameter scan. The offloading is done sequentially.\n13\n\n\nof the circuits, as well as the latency and bandwidths of the connection between runtime and\nbackend.\n5.3\nVariational Algorithm\nIn variational algorithms, a circuit called ansatz is implemented on the quantum computer.\nThe goal of the algorithm is to find the lowest expectation value of ⟨Ψ(θ)| H |Ψ(θ)⟩, where\nΨ(θ) is the parametrized ansatz and H is the problem Hamiltonian.\nTo do this, we use a\nclassical optimization algorithm on classical hardware that adjusts the parameters and offloads\nthe execution of the ansatz onto the quantum computer. In Figure 5, we see that this results\nin a loop in which updated parameters are sent to the quantum computer and the measured bit\nstrings are returned. Variational algorithms play an important role in the Noisy Intermediate\nScale Quantum (NISQ) era [48] because they allow problems to be solved with shorter and\ntherefore less error-prone circuits. They are used, for example, to find the ground state energy\nof molecules [49, 50] or to solve combinatorial optimization problems [51, 52].\nCPU\nQPU\nmeasured\nbitstrings\nupdated\nparameters\nFigure 5: Schematic representation of the execution of variational algorithms. The CPU optimizes the parameters\nof the quantum circuit, the QPU returns the bit strings of the current measurements.\nIn this example, we want to find the lowest expectation value of the circuit from Section 5.2.\nTo do this, we use the widely used NLopt library [53], which contains a large number of opti-\nmization algorithms. Listing 7 shows the C++ code for this example. In the main function we\nset the optimization algorithm, DIviding RECTangles (DIRECT) [54] in our case and set the\nobjective function. We also define bounds for the parameters from 0 to 2π and set a stopping\ncriteria (not shown). In the objective function, we call the quantum computer and calculate\nthe expectation value similar to the example in Section 5.2. Calling opt.optimize starts the\noptimizer which calls the objective function, which in turn calls the quantum computer. This\nexample shows how easy it is to use 3rd party libraries with OmpSs-2. With the quantum ex-\ntension, it is also easy to outsource parts of existing algorithms to a quantum computer without\nhaving to implement the algorithms from scratch.\nWe run the example with 10,000 shots per evaluation of the circuit. The optimizer finds\na minimum of −5.94.\nTheoretically the minimum is −6.\nTo find a more precise value, we\ncan increase the number of shots and decrease the relative tolerance of the stopping criterion.\nHowever, this also increases run time.\n14\n\n\n1\n//\n. . .\n2 #pragma oss\ntask\nin (∗r e s u l t s )\nreduction (+:\n[ 1 ] energy )\n3\nvoid\ncalc_energy ( qpu_result_t ∗r e s u l t s ,\ndouble ∗energy ) {\n4\n//\n. . .\n5\n}\n6\n7\nint\nmain ()\n{\n8\n//\n. . .\n9\nqpu_parameters_t ∗p = ( qpu_parameters_t ∗) malloc ( s i z e o f ( qpu_parameters_t ) ) ;\n10\n//\ndefine\na\nr e s u l t\ns t r u c t\nf o r\nevery\nansatz\n11\nqpu_result_t ∗r [ num_ansaetze ] ;\n12\nf o r\n( size_t\ni = 0;\ni < num_ansaetze ;\ni++) {\n13\nr [ i ] = ( qpu_result_t\n∗) malloc ( s i z e o f ( qpu_result_t ) ) ;\n14\n}\n15\n16\n//\narray\nof qasm extensions\n17\n//\n. . .\n18\n19\n//\narray\nof\ne n e r g i e s\n20\ndouble ∗energy [ num_ansaetze ] ;\n21\nf o r\n( size_t\ni = 0;\ni < num_ansaetze ;\ni++) {\n22\nenergy [ i ] = ( double\n∗) malloc ( s i z e o f ( double ) ) ;\n23\n}\n24\n//\n. . .\n25\nf o r\n( size_t\ni = 0;\ni < steps ;\ni++) {\n26 #pragma oss\ntask\nout (∗p)\n27\n{\n28\np−>parameters [ 0 ] = i\n∗step_size ;\n29\n}\n30\nf o r\n( size_t\nj = 0;\nj < steps ;\nj++) {\n31 #pragma oss\ntask\nout (∗p)\n32\n{\n33\np−>parameters [ 1 ] = j\n∗step_size ;\n34\n}\n35 #pragma oss\ntask\nout ( total_energy )\n36\n{\n37\ntotal_energy = 0.0 f ;\n38\n}\n39\nf o r\n( size_t k = 0; k < num_ansaetze ;\nk++) {\n40\nansatz (num_shots ,\nr [ k ] , p ,\nqasm_extensions [ k ] ) ;\n41\ncalc_energy ( r [ k ] ,\nenergy [ k ] ) ;\n42\n}\n43 #pragma oss\ntask\nin ( total_energy )\n44\n{\n45\n//\nprint\nenergy\n46\n}\n47\n}\n48\n}\n49 #pragma oss\ntaskwait\n50\n}\nListing 6: C++ code for the parallel parameter scan (see results in Figure 4). The offloading in line\n26 is done in parallel for all OpenQASM extensions.\n15\n\n\n1\n//\n. . .\n2 #pragma oss\ntask\ndevice (qpu)\nin (∗p)\nout (∗r e s u l t s )\nin (∗extension )\n3\nvoid\nansatz ( int\nshots ,\nqpu_result_t ∗r e s u l t s ,\nqpu_parameters_t ∗p ,\nconst\nchar\n∗extension ) ;\n4\n5 #pragma oss\ntask\nin (∗r e s u l t s )\nout (∗energy )\n6\nvoid\ncalc_energy ( qpu_result_t ∗r e s u l t s ,\ndouble ∗energy ) {\n7\n//\n. . .\n8\n}\n9\n10\ndouble\nevaluate_energy ( const\nstd : : vector<double> &x ,\nstd : : vector<double> &grad\n,\nvoid ∗func_data ) {\n11\n//\n. . .\n12\nf o r\n( size_t k = 0; k < num_ansaetze ;\nk++) {\n13\nansatz (num_shots ,\nr , p ,\nqasm_extensions [ k ] ) ;\n14\ncalc_energy ( r ,\nenergy ) ;\n15 #pragma oss\ntaskwait\n16\ntotal_energy += ∗energy ;\n17\n}\n18\n//\n. . .\n19\nreturn\ntotal_energy ;\n20\n}\n21\n22\nint\nmain ()\n{\n23\nnlopt : : opt opt ( nlopt : :GN_DIRECT_L,\n2) ;\n24\n//\n. . .\n25\nopt . set_min_objective ( evaluate_energy , NULL) ;\n26\n// run\noptimization\nand\nprint\nr e s u l t\n27\ntry {\n28\nnlopt : : r e s u l t\nr e s u l t = opt . optimize (x ,\nminf ) ;\n29\n//\nprint\nr e s u l t\n30\n} catch\n( std : : exception &e ) {\n31\n//\nprint\ne r r o r\n32\n}\n33\n}\nListing 7: C++ part of the variational algorithm. We use the NLopt library for optimization.\n16\n\n\nUnfold\nQC\nConv\nStack\nFC\nSoft-\nmax\nFigure 6: The image depicts a process where the input image is divided into 2x2 patches, which translates to a\nkernel size of (2,2) and a stride of 2. A quantum convolution (QC Conv) is applied to each patch, generating 4\nfeatures per patch. For quantum convolution we use the higher order encoding basic entangling layer outlined\nin [56]. These features are stacked into a single tensor, which is then processed by a fully connected layer (FC)\nto map the features to prediction classes, followed by a softmax activation for the output.\n5.4\nQuantum Convolution\nQuantum machine learning (QML) is a highly active area of research with ongoing advance-\nments [55]. Although the potential for quantum advantage in machine learning remains uncer-\ntain, it serves as an intriguing example to demonstrate our programming model. The size of\nmodern neural networks has increased dramatically, leading to the conclusion that fully QML\nalgorithms are unlikely to emerge in the near future [55]. Instead, hybrid quantum-classical al-\ngorithms are more plausible. In such hybrid approaches, it is crucial to efficiently distribute the\ncomputational load across various subsystems, such as CPUs, GPUs, and, in this case, QPUs.\nTo evaluate the applicability of the OmpSs-2 extension in QML, we replicate the quantum\ncomputing convolutional neural network described in [56]. This example provides a valuable\ntesting opportunity, involving rapid and frequent interleaved computations between classical\nand quantum hardware. While the example itself features a small neural network that does\nnot require HPC infrastructure, the ever-growing computational demands of neural networks in\ngeneral are shifting their execution and training into the realm of HPC, as evidenced by the\ndevelopment of new AI-focused supercomputers like Jupiter [57, 58]. The OmpSs-2 framework\nis designed to operate in such environments, making this extension an ideal fit for large-scale\nand scalable QML algorithms in the future.\n5.4.1\nNetwork Architecture and Implementation\nConvolutional Neural Networks (CNNs) [59, 60] are a class of deep learning models widely used\nfor tasks such as image recognition. A CNN typically consists of convolutional layers, pooling\nlayers, and fully connected layers. The convolutional layer relies on trainable kernel matrices\nto extract features from images by convolving these filters over the input data. The polling\nlayer summarizes data, and the fully connected layer serves as the classifier, combining the\nlearned features to produce the output. In the quantum version, the convolutional operation is\ntranslated into a quantum convolution, where a quantum circuit is designed to generate image\nfeatures by leveraging the principles of quantum computing. The architecture of the network,\nincluding the quantum convolutional component, is depicted in Figure 6, providing an overview\nof how classical and quantum computations are integrated within the model.\nSimilar to [56], we simulate the quantum circuit. For simplicity, the training of the neural\nnetwork is implemented in Python using the PyTorch [61] package. Unlike [56], we implemented\nthe circuit simulation as PyTorch module. This approach involves calculating the unitary ma-\n17\n\n\ntrix corresponding to the quantum circuit and then determining the resulting probabilistic state\nvector. This implementation enables highly parallelized training of the network on GPUs, sig-\nnificantly improving efficiency. The enhanced efficiency allows us to test the network on much\nlarger datasets.\n5.4.2\nTraining and Comparison\nFor the training dataset, we use the widely known dataset MNIST CIFAR-10 [62]. As a reference\nto [56], we briefly summarize the performance of the quantum CNN and a classical CNN. The\nclassical CNN has the same structure as the quantum CNN, but the convolution operation is a\nstandard classical convolution with the same kernel size, stride, and four output channels. The\nother difference is that the output is activated using the rectified linear unit (ReLU) function.\nAll networks are trained using the ADAM optimizer [63] with the following hyper parameters:\nlearning rate γ = 0.001, β1 = 0.9, β2 = 0.999, and ϵ = 10−8. Training is conducted for 50\nepochs, repeated 20 times, and the optimal number of epochs is selected based on the best\naverage performance on the validation dataset. The final evaluation is performed on the test\ndataset. For the classical CNN, we obtain an average out-of-sample accuracy of 95.77% with\na standard deviation of 2.02%. The quantum CNN performs slightly worse with an average\nout-of-sample accuracy of 90.58% and a standard deviation of 5.05%.\n5.4.3\nImplementation with OmpSs-2\nWe use PyTorch’s C++ frontend to test one of the trained networks with OmpSs-2. Figure 7\ngives a high-level overview of our setup. In the Python code, we store the network parameters\nof the trained network in a json file. We read the model data of the fully trained network into\nthe C++ implementation and do only the inference with OmpSs-2. To do this, we implement a\nnetwork consisting of a standard fully connected layer and a custom quantum convolution layer.\nThis quantum convolution layer makes a call to the quantum computer in its forward function.\nWe evaluate this network on the test dataset and get an accuracy of 95.02%, which is in the\nexpected range. This example shows that it is possible to implement more extensive examples\nthat rely heavily on third-party libraries such as PyTorch.\nMNIST\nCIFAR-10\nTraining\nPyTorch\nPython\nmodel.json\nInference\nPyTorch\nC++/OmpSs-2\nResults\nFigure 7: High level overview of the QML example. The training is done with the PyTorch Python frontend.\nThe resulting model is written to a json file, which is read into the C++ implementation that uses OmpSs-2 for\noffloading to the quantum computer.\n18\n\n\n6\nConclusion and Future Work\nWe presented an extension of the OmpSs-2 framework to support quantum computers. The\nextension allows to offload functions from the classical code to a networked quantum computer.\nThe quantum code is written in OpenQASM, which is well established in the field of quantum\ncomputing, while the HPC code can be kept in a classical HPC language such as C++. Therefore,\nour solution provides a modular approach to hybrid quantum-classical computing that allows\nboth quantum and HPC specialists to work in their familiar environments.\nPortions of the\nexisting classical code can be incrementally ported to the quantum computer without having to\ncompletely rewrite the code. Only the quantum part needs to be implemented in a quantum-\nspecific language. We showed four applications of different sizes to demonstrate the strength of\nthe framework.\nFor future work, we want to improve performance through various measures. The Open-\nQASM file could be preloaded at the start of the program and not only when the function is\nactually called. It could also be reused instead of being reloaded from the file when the same\nfunction is called again. We also plan to introduce an abstraction layer for the backends to allow\neasier support for new quantum computers. To make the framework easier to use, we would\nlike to provide the structures for storing results and parameters with convenience functions. A\nfurther step could be to develop a library for a specific use case, such as variational algorithms,\nthat contains the necessary OpenQASM and C++ code. In the current NISQ era, error mitiga-\ntion [64, 65] plays an important role to improve the results obtained from the error-prone device\nvia post-processing. It would be convenient for users to implement the classical and quantum\nparts, for example, of matrix-based error mitigation [66, 67, 68] as a function for users to call. So\nfar, the framework has only been tested on a simulator. In Section 5.2 we showed an example,\nwhere the execution of multiple kernels can be parallelized. It would be interesting to test this\ncode in an environment with several simulators or real devices to see how well the parallelization\nworks. There could also be a configuration where there are interdependencies between several\ndifferent types of quantum computers [69]. Such a setup would be interesting to test, as it would\ntake advantage of OmpSs-2 strengths in modeling dependencies.\nReferences\n[1] R.\nP.\nFeynman,\n“Simulating\nphysics\nwith\ncomputers,”\nInternational\nJournal\nof\nTheoretical\nPhysics,\nvol.\n21,\nno.\n6,\npp.\n467–488,\n06\n1982.\n[Online].\nAvailable:\nhttps://doi.org/10.1007/BF02650179\n[2] D. Deutsch, “Quantum theory, the church–turing principle and the universal quantum com-\nputer,” Proceedings of the Royal Society of London. A. Mathematical and Physical Sciences,\nvol. 400, no. 1818, pp. 97–117, 1985.\n[3] J. A. Jones and M. Mosca, “Implementation of a quantum algorithm on a nuclear magnetic\nresonance quantum computer,” The Journal of chemical physics, vol. 109, no. 5, pp. 1648–\n1653, 1998.\n19\n\n\n[4] I. L. Chuang, N. Gershenfeld, and M. Kubinec, “Experimental implementation of fast\nquantum searching,” Phys. Rev. Lett., vol. 80, pp. 3408–3411, Apr 1998. [Online]. Available:\nhttps://link.aps.org/doi/10.1103/PhysRevLett.80.3408\n[5] IBM, “IBM Quantum,” 2025. [Online]. Available: https://quantum.ibm.com/\n[6] Amazon Web Services, “Amazon Braket,” 2025. [Online]. Available: https://aws.amazon.\ncom/braket/\n[7] P. W. Shor, “Algorithms for quantum computation: discrete logarithms and factoring,” in\nProceedings 35th annual symposium on foundations of computer science.\nIeee, 1994, pp.\n124–134.\n[8] L. K. Grover, “A fast quantum mechanical algorithm for database search,” in Proceedings\nof the Twenty-Eighth Annual ACM Symposium on Theory of Computing, ser. STOC ’96.\nNew York, NY, USA: Association for Computing Machinery, 1996, p. 212–219. [Online].\nAvailable: https://doi.org/10.1145/237814.237866\n[9] T.\nG.\nDraper,\n“Addition\non\na\nquantum\ncomputer,”\n2000.\n[Online].\nAvailable:\nhttps://arxiv.org/abs/quant-ph/0008033\n[10] K. Michielsen,\nM. Nocon,\nD. Willsch,\nF. Jin,\nT. Lippert,\nand H. De Raedt,\n“Benchmarking gate-based quantum computers,” Computer Physics Communications, vol.\n220, pp. 44–55, 2017. [Online]. Available: https://www.sciencedirect.com/science/article/\npii/S0010465517301935\n[11] J. M. Perez, V. Beltran, J. Labarta, and E. Ayguadé, “Improving the integration of task\nnesting and dependencies in openmp,” in 2017 IEEE International Parallel and Distributed\nProcessing Symposium (IPDPS), 2017, pp. 809–818.\n[12] L. Dagum and R. Menon, “Openmp: an industry standard api for shared-memory program-\nming,” IEEE Computational Science and Engineering, vol. 5, no. 1, pp. 46–55, 1998.\n[13] B. Heim, M. Soeken, S. Marshall, C. Granade, M. Roetteler, A. Geller, M. Troyer, and\nK. Svore, “Quantum programming languages,” Nature Reviews Physics, vol. 2, no. 12, pp.\n709–722, Dec 2020. [Online]. Available: https://doi.org/10.1038/s42254-020-00245-7\n[14] S. Lopez Alarcón, E. Wong, T. S. Humble, and E. Dumitrescu, “Quantum programming\nparadigms and description languages,” Computing in Science & Engineering, vol. 25, no. 6,\npp. 33–38, 2023.\n[15] E.\nKnill,\n“Conventions\nfor\nquantum\npseudocode,”\n6\n1996.\n[Online].\nAvailable:\nhttps://www.osti.gov/biblio/366453\n[16] P. Selinger, “A brief survey of quantum programming languages,” in Functional and Logic\nProgramming, Y. Kameyama and P. J. Stuckey, Eds.\nBerlin, Heidelberg: Springer Berlin\nHeidelberg, 2004, pp. 1–6.\n20\n\n\n[17] S. J. GAY, “Quantum programming languages: survey and bibliography,” Mathematical\nStructures in Computer Science, vol. 16, no. 4, p. 581–600, 2006.\n[18] A. McCaskey, E. Dumitrescu, D. Liakh, M. Chen, W. Feng, and T. Humble, “A language\nand hardware independent approach to quantum–classical computing,” SoftwareX, vol. 7,\npp. 245–254, 2018. [Online]. Available: https://www.sciencedirect.com/science/article/pii/\nS2352711018300700\n[19] A. J. McCaskey, D. I. Lyakh, E. F. Dumitrescu, S. S. Powers, and T. S. Humble, “Xacc:\na system-level software infrastructure for heterogeneous quantum–classical computing*,”\nQuantum Science and Technology, vol. 5, no. 2, p. 024002, feb 2020. [Online]. Available:\nhttps://dx.doi.org/10.1088/2058-9565/ab6bf6\n[20] D. Claudino, A. J. McCaskey, and D. I. Lyakh, “A backend-agnostic, quantum-classical\nframework for simulations of chemistry in c++,” vol. 4, no. 1, oct 2022. [Online]. Available:\nhttps://doi.org/10.1145/3523285\n[21] T. M. Mintz, A. J. McCaskey, E. F. Dumitrescu, S. V. Moore, S. Powers, and P. Lougovski,\n“Qcor: A language extension specification for the heterogeneous quantum-classical model\nof computation,” J. Emerg. Technol. Comput. Syst., vol. 16, no. 2, mar 2020. [Online].\nAvailable: https://doi.org/10.1145/3380964\n[22] A. Mccaskey, T. Nguyen, A. Santana, D. Claudino, T. Kharazi, and H. Finkel, “Extending\nc++ for heterogeneous quantum-classical computing,” ACM Transactions on Quantum\nComputing, vol. 2, no. 2, jul 2021. [Online]. Available: https://doi.org/10.1145/3462670\n[23] C. team, “Clang: a c language family frontend for llvm,” 2024, https://docs.rigetti.com/qcs\n[Accessed: Aug 28, 2024].\n[24] A. Hayashi, A. Adams, J. Young, A. McCaskey, E. Dumitrescu, V. Sarkar, and T. M.\nConte, “Enabling multi-threading in heterogeneous quantum-classical programming mod-\nels,” in 2023 IEEE International Parallel and Distributed Processing Symposium Workshops\n(IPDPSW), 2023, pp. 509–516.\n[25] T. Nguyen and A. J. McCaskey, “Extending python for quantum-classical computing via\nquantum just-in-time compilation,” ACM Transactions on Quantum Computing, vol. 3,\nno. 4, jul 2022. [Online]. Available: https://doi.org/10.1145/3544496\n[26] J.-S. Kim, A. McCaskey, B. Heim, M. Modani, S. Stanwyck, and T. Costa, “Cuda quantum:\nThe platform for integrated quantum-classical computing,” in 2023 60th ACM/IEEE Design\nAutomation Conference (DAC), 2023, pp. 1–4.\n[27] J. Nickolls, I. Buck, M. Garland, and K. Skadron, “Scalable parallel programming with cuda:\nIs cuda the parallel programming model that application developers have been waiting for?”\nQueue, vol. 6, no. 2, pp. 40–53, 2008.\n21\n\n\n[28] J. E. Stone, D. Gohara, and G. Shi, “Opencl: A parallel programming standard for hetero-\ngeneous computing systems,” vol. 12, no. 3, p. 66–73, may 2010.\n[29] ISO, C99 Standard, 1999, iSO/IEC 9899:1999. [Online]. Available: https://www.iso.org/\nstandard/29237.html\n[30] J. Vázquez-Pérez, C. Piñeiro, J. C. Pichel, T. F. Pena, and A. Gómez, “Qpu integration in\nopencl for heterogeneous programming,” The Journal of Supercomputing, pp. 1–22, 2024.\n[31] Y. Suzuki, Y. Kawase, Y. Masumura, Y. Hiraga, M. Nakadai, J. Chen, K. M. Nakanishi,\nK. Mitarai, R. Imai, S. Tamiya, T. Yamamoto, T. Yan, T. Kawakubo, Y. O. Nakagawa,\nY. Ibe, Y. Zhang, H. Yamashita, H. Yoshimura, A. Hayashi, and K. Fujii, “Qulacs: a fast\nand versatile quantum circuit simulator for research purpose,” Quantum, vol. 5, p. 559,\nOct. 2021. [Online]. Available: https://doi.org/10.22331/q-2021-10-06-559\n[32] A. Peruzzo, J. McClean, P. Shadbolt, M.-H. Yung, X.-Q. Zhou, P. J. Love, A. Aspuru-\nGuzik, and J. L. O’Brien, “A variational eigenvalue solver on a photonic quantum\nprocessor,” Nature Communications, vol. 5, no. 1, p. 4213, Jul 2014. [Online]. Available:\nhttps://doi.org/10.1038/ncomms5213\n[33] J.\nVázquez-Pérez.\n(2024)\nOpenclqpu\nsamples.\nAvailable:\nhttps://github.com/\njorgevazquezperez/OpenCLQPU/tree/main/samples.\n[34] X. Fu, J. Yu, X. Su, H. Jiang, H. Wu, F. Cheng, X. Deng, J. Zhang, L. Jin, Y. Yang,\nL. Xu, C. Hu, A. Huang, G. Huang, X. Qiang, M. Deng, P. Xu, W. Xu, W. Liu, Y. Zhang,\nY. Deng, J. Wu, and Y. Feng, “Quingo: A programming framework for heterogeneous\nquantum-classical computing with nisq features,”\nACM Transactions on Quantum\nComputing, vol. 2, no. 4, dec 2021. [Online]. Available: https://doi.org/10.1145/3483528\n[35] X. Fu, L. Riesebos, M. A. Rol, J. van Straten, J. van Someren, N. Khammassi, I. Ashraf,\nR. F. L. Vermeulen, V. Newsum, K. K. L. Loh, J. C. de Sterke, W. J. Vlothuizen, R. N.\nSchouten, C. G. Almudever, L. DiCarlo, and K. Bertels, “eqasm: An executable quantum\ninstruction set architecture,” in 2019 IEEE International Symposium on High Performance\nComputer Architecture (HPCA), 2019, pp. 224–237.\n[36] Q. Du,\nJ. Xu,\nY. Zhu,\nH. Lian,\nQ. Xiong,\nD. Zheng,\nY. Liu,\nZ. Tu,\nand\nZ. Shan, “Qccp:\na taskflow programming model for emerging computing scenario,”\nEPJ Quantum Technology,\nvol. 12,\nno. 1,\np. 23,\nFeb 2025. [Online]. Available:\nhttps://doi.org/10.1140/epjqt/s40507-025-00318-5\n[37] A. W. Cross, L. S. Bishop, J. A. Smolin, and J. M. Gambetta, “Open quantum assembly\nlanguage,” 2017. [Online]. Available: https://arxiv.org/abs/1707.03429\n[38] C. Gaberle, “Design and implementation of a quantum circuit preparation algorithm,” 2023,\nunpublished thesis, Goethe University Frankfurt.\n22\n\n\n[39] S. Sivarajah, S. Dilkes, A. Cowtan, W. Simmons, A. Edgington, and R. Duncan, “Tket: A\nretargetable compiler for nisq devices,” Quantum Science and Technology, vol. 6, 11 2020.\n[40] K. A. Britt and T. S. Humble, “High-performance computing with quantum processing\nunits,” J. Emerg. Technol. Comput. Syst., vol. 13, no. 3, Mar. 2017. [Online]. Available:\nhttps://doi.org/10.1145/3007651\n[41] A. Javadi-Abhari, M. Treinish, K. Krsulich, C. J. Wood, J. Lishman, J. Gacon, S. Martiel,\nP. D. Nation, L. S. Bishop, A. W. Cross, B. R. Johnson, and J. M. Gambetta, “Quantum\ncomputing with qiskit,” 2024. [Online]. Available: https://arxiv.org/abs/2405.08810\n[42] P. Viviani,\n“Demistifying hpc-quantum integration:\nit’s all about scheduling,”\nin\nProceedings of the 2024 Workshop on High Performance and Quantum Computing\nIntegration, ser. HPQCI ’24.\nNew York, NY, USA: Association for Computing Machinery,\n2024, p. 1–3. [Online]. Available: https://doi.org/10.1145/3659996.3673223\n[43] P. Gerbert and F. Rueß, “The next decade in quantum computing and how to play,” Boston\nConsulting Group, p. 5, 2018.\n[44] IBM, “Compute resources,” 2025, https://quantum.ibm.com/services/resources [Accessed:\nJan 31, 2025].\n[45] A. Tekin, A. Tuncer Durak, C. Piechurski, D. Kaliszan, F. Aylin Sungur, F. Robertsén,\nand P. Gschwandtner, “State-of-the-art and trends for computing and interconnect network\nsolutions for hpc and ai,” PRACE, Tech. Rep., 2021.\n[46] J. Yamaguchi, M. Yamazaki, A. Tabuchi, T. Honda, T. Izu, and N. Kunihiro, “Estimation\nof shor’s circuit for 2048-bit integers based on quantum simulator,” Cryptology ePrint\nArchive, Paper 2023/092, 2023. [Online]. Available: https://eprint.iacr.org/2023/092\n[47] M. S. Jattana, F. Jin, H. De Raedt, and K. Michielsen, “Improved variational quantum\neigensolver via quasidynamical evolution,” Phys. Rev. Appl., vol. 19, p. 024047, Feb 2023.\n[Online]. Available: https://link.aps.org/doi/10.1103/PhysRevApplied.19.024047\n[48] J. Preskill, “Quantum computing in the nisq era and beyond,” Quantum, vol. 2, p. 79, 2018.\n[49] A. Peruzzo, J. McClean, P. Shadbolt, M.-H. Yung, X.-Q. Zhou, P. J. Love, A. Aspuru-\nGuzik, and J. L. O’Brien, “A variational eigenvalue solver on a photonic quantum\nprocessor,” Nature Communications, vol. 5, no. 1, p. 4213, Jul 2014. [Online]. Available:\nhttps://doi.org/10.1038/ncomms5213\n[50] J. Tilly, H. Chen, S. Cao, D. Picozzi, K. Setia, Y. Li, E. Grant, L. Wossnig, I. Rungger,\nG. H. Booth, and J. Tennyson, “The variational quantum eigensolver:\nA review of\nmethods and best practices,” Physics Reports, vol. 986, pp. 1–128, 2022, the Variational\nQuantum Eigensolver:\na review of methods and best practices. [Online]. Available:\nhttps://www.sciencedirect.com/science/article/pii/S0370157322003118\n23\n\n\n[51] E. Farhi,\nJ. Goldstone,\nand S. Gutmann,\n“A quantum approximate optimization\nalgorithm,” 2014. [Online]. Available: https://arxiv.org/abs/1411.4028\n[52] K.\nBlekos,\nD.\nBrand,\nA.\nCeschini,\nC.-H.\nChou,\nR.-H.\nLi,\nK.\nPandya,\nand\nA. Summer,\n“A review on quantum approximate optimization algorithm and its\nvariants,”\nPhysics\nReports,\nvol.\n1068,\npp.\n1–66,\n2024,\na\nreview\non\nQuantum\nApproximate Optimization Algorithm and its variants. [Online]. Available:\nhttps:\n//www.sciencedirect.com/science/article/pii/S0370157324001078\n[53] S. G. Johnson, “The nlopt nonlinear-optimization package,” 2024, accessed on: 17. Dec\n2024. [Online]. Available: http://github.com/stevengj/nlopt\n[54] D. R. Jones, C. D. Perttunen, and B. E. Stuckman, “Lipschitzian optimization without\nthe lipschitz constant,” Journal of Optimization Theory and Applications, vol. 79, no. 1,\npp. 157–181, Oct 1993. [Online]. Available: https://doi.org/10.1007/BF00941892\n[55] D. Peral-García, J. Cruz-Benito, and F. J. García-Peñalvo, “Systematic literature review:\nQuantum machine learning and its applications,” Computer Science Review, vol. 51, p.\n100619, 2024.\n[56] A. Matic, M. Monnet, J. Lorenz, B. Schachtner, and T. Messerer, “Quantum-classical con-\nvolutional neural networks in radiological image classification,” 04 2022.\n[57] M. Dumiak, “Exascale comes to europe: Germany will host jupiter, europe’s entry into the\nrealm of exascale supercomputing,” IEEE Spectrum, vol. 60, no. 1, pp. 50–51, 2023.\n[58] A. Herten, S. Achilles, D. Alvarez, J. Badwaik, E. Behle, M. Bode, T. Breuer, D. Caviedes-\nVoullième, M. Cherti, A. Dabah, S. E. Sayed, W. Frings, A. Gonzalez-Nicolas, E. B. Gregory,\nK. H. Mood, T. Hater, J. Jitsev, C. M. John, J. H. Meinke, C. I. Meyer, P. Mezentsev, J.-\nO. Mirus, S. Nassyr, C. Penke, M. Römmer, U. Sinha, B. v. S. Vieth, O. Stein, E. Suarez,\nD. Willsch, and I. Zhukov, “Application-driven exascale: The jupiter benchmark suite,”\nin SC24: International Conference for High Performance Computing, Networking, Storage\nand Analysis, 2024, pp. 1–45.\n[59] Y. LeCun, Y. Bengio et al., “Convolutional networks for images, speech, and time series,”\nThe handbook of brain theory and neural networks, vol. 3361, no. 10, p. 1995, 1995.\n[60] A. Krizhevsky, I. Sutskever, and G. E. Hinton, “Imagenet classification with deep convolu-\ntional neural networks,” Communications of the ACM, vol. 60, pp. 84–90, 2012.\n[61] A. Paszke, S. Gross, F. Massa, A. Lerer, J. Bradbury, G. Chanan, T. Killeen, Z. Lin,\nN. Gimelshein, L. Antiga, A. Desmaison, A. Köpf, E. Yang, Z. DeVito, M. Raison, A. Tejani,\nS. Chilamkurthy, B. Steiner, L. Fang, J. Bai, and S. Chintala, “Pytorch: An imperative style,\nhigh-performance deep learning library,” 2019.\n[62] L. Deng, “The mnist database of handwritten digit images for machine learning research,”\nIEEE Signal Processing Magazine, vol. 29, no. 6, pp. 141–142, 2012.\n24\n\n\n[63] D. Kingma and J. Ba, “Adam: A method for stochastic optimization,” International Con-\nference on Learning Representations, 12 2014.\n[64] Y. Li and S. C. Benjamin, “Efficient variational quantum simulator incorporating active\nerror minimization,” Phys. Rev. X, vol. 7, p. 021050, Jun 2017. [Online]. Available:\nhttps://link.aps.org/doi/10.1103/PhysRevX.7.021050\n[65] Z. Cai, R. Babbush, S. C. Benjamin, S. Endo, W. J. Huggins, Y. Li, J. R. Mcclean, and\nT. E. O’Brien, “Quantum error mitigation,” REVIEWS OF MODERN PHYSICS, vol. 95,\nno. 4, DEC 13 2023.\n[66] Y. Chen, M. Farahzad, S. Yoo, and T.-C. Wei, “Detector tomography on ibm quantum\ncomputers and mitigation of an imperfect measurement,” Phys. Rev. A, vol. 100, p. 052315,\nNov 2019. [Online]. Available: https://link.aps.org/doi/10.1103/PhysRevA.100.052315\n[67] M. S. Jattana, F. Jin, H. De Raedt, and K. Michielsen, “General error mitigation for\nquantum circuits,” Quantum Information Processing, vol. 19, pp. 1–17, 2020.\n[68] P. Döbler, J. Pflieger, F. Jin, H. D. Raedt, K. Michielsen, T. Lippert, and M. S.\nJattana, “Scalable general error mitigation for quantum circuits,” 2024. [Online]. Available:\nhttps://arxiv.org/abs/2411.07916\n[69] M. S. Jattana, “Quantum annealer accelerates the variational quantum eigensolver in a\ntriple-hybrid algorithm,” Physica Scripta, vol. 99, no. 9, p. 095117, aug 2024. [Online].\nAvailable: https://dx.doi.org/10.1088/1402-4896/ad6aea\n25\n\n\n",
  "metadata": {
    "source_file": "dataset/pdfs/arxiv_2502.21104v1.pdf",
    "total_pages": 25,
    "title": "Extending the OmpSs-2 Programming Model for Hybrid Quantum-Classical Programming",
    "authors": [
      "Philip Döbler",
      "David Álvarez",
      "Lucas J. Menger",
      "Thomas Lippert",
      "Vicenç Beltran",
      "Manpreet Singh Jattana"
    ],
    "abstract": "The OmpSs-2 programming model is used in HPC programs to parallelize code and\noffload code to accelerators. In this work, we extend the offloading capability\nto quantum computers. We explain the necessary changes to the Clang compiler\nand the Nanos6 runtime, which are both part of OmpSs-2. In addition, we develop\na simulator that simulates a quantum computer in the network and receives the\njobs offloaded by the runtime. Four detailed examples show how our programming\nmodel can be used to write hybrid quantum-classical software. The examples are\nrandom number generation, a parameter scan using the mean-field ansatz, a\nvariational algorithm using this ansatz, and handwritten digit recognition\nusing a hybrid convolutional neural network.",
    "published_date": "2025-02-28",
    "source": "arxiv"
  }
}