{
  "id": "arxiv_2502.21012v1",
  "text": "JOURNAL OF LATEX CLASS FILES, VOL. 14, NO. 8, AUGUST 2021\n1\nFedDyMem: Efficient Federated Learning with\nDynamic Memory and Memory-Reduce for\nUnsupervised Image Anomaly Detection\nSilin Chen, Kangjian Di, Yichu Xu, Han-Jia Ye, Wenhan Luo, Ningmu Zou†\nAbstract—Unsupervised image anomaly detection (UAD) has\nbecome a critical process in industrial and medical applications,\nbut it faces growing challenges due to increasing concerns over\ndata privacy. The limited class diversity inherent to one-class\nclassification tasks, combined with distribution biases caused by\nvariations in products across and within clients, poses significant\nchallenges for preserving data privacy with federated UAD.\nThus, this article proposes an efficient federated learning method\nwith dynamic memory and memory-reduce for unsupervised\nimage anomaly detection, called FedDyMem. Considering all\nclient data belongs to a single class (i.e., normal sample) in\nUAD and the distribution of intra-class features demonstrates\nsignificant skewness, FedDyMem facilitates knowledge sharing\nbetween the client and server through the client’s dynamic\nmemory bank instead of model parameters. In the local clients,\na memory generator and a metric loss are employed to improve\nthe consistency of the feature distribution for normal samples,\nleveraging the local model to update the memory bank dynam-\nically. For efficient communication, a memory-reduce method\nbased on weighted averages is proposed to significantly decrease\nthe scale of memory banks. On the server, global memory is\nconstructed and distributed to individual clients through k-\nmeans aggregation. Experiments conducted on six industrial and\nmedical datasets, comprising a mixture of six products or health\nscreening types derived from eleven public datasets, demonstrate\nthe effectiveness of FedDyMem.\nIndex Terms—Federated learning, unsupervised anomaly de-\ntection, feature distribution shift, communication efficiency, dy-\nnamic memory bank.\nI. INTRODUCTION\nU\nNSUPERVISED image anomaly detection has achieved\nsignificant success in various domains, such as industrial\ninspection [1] and medical disease recognition [2]. However,\nthese methods highly depend on the availability of large-\nscale datasets for centralized training. Industrial companies\nand healthcare organizations often have practical limitations\nin collecting and aggregating raw data, which significantly\nchallenges centralized learning approaches [3], [4]. Recently,\n† corresponding authors.\nSilin Chen and Kangjian Di are the School of Integrated Circuits, Nanjing\nUniversity, Suzhou, China. Email: {silin.chen, kangjiandi}@smail.nju.edu.cn.\nYichu Xu and Han-Jia Ye are with both the National Key Laboratory for\nNovel Software Technology, Nanjing University, Nanjing, 210023, China and\nthe School of Artificial Intelligence, Nanjing University, Nanjing, 210023,\nChina. Email: {xuyc, yehj}@lamda.nju.edu.cn.\nWenhan Luo is with the Hong Kong University of Science and Technology,\nClear Water Bay, Hong Kong. Email: whluo.china@gmail.com.\nNingmu Zou is with both the School of Integrated Circuits, Nanjing\nUniversity, Suzhou, China and the Interdisciplinary Research Center for\nFuture Intelligent Chips (Chip-X), Nanjing University, Suzhou, China. Email:\nnzou@nju.edu.cn.\nFig. 1. Illustration of federated learning in UAD. As shown on the left, for the\nsame product anomaly detection, an intra-class distribution bias exists between\nlocal models, caused by each client possessing varying and incomplete subsets\nof product types. As shown in the top right, federated UAD aims to establish a\nsingle decision boundary for one-class classification within the global model.\nExamples of type differences in anomaly detection for different products are\nshown in the right down.\nfederated learning has been developed as a privacy-preserving\nparadigm for machine learning, providing collaborative model\ntraining across distributed devices while maintaining raw data\nlocally and not transmitting to central servers [5], [6]. Thus, the\nintegration of local training and global aggregation strategies\nhas garnered significant attention in industrial and healthcare\ndomains, enabling data privacy protection [7]–[9].\nFederated learning is applicable to both supervised and\nunsupervised learning scenarios. Recent developments in un-\nsupervised federated learning have shown significant progress\n[10]. These methods are often focused on learning a general\nrepresentation or prototype by self-supervised learning (SSL)\nwhile keeping private data decentralized and unlabeled. Some\nmethods continue to rely on local updates and aggregation of\nmodel parameters to train a global model for representation\ngeneration [11], [12]. Alternatively, other approaches take ad-\nvantage of representation sharing, using knowledge distillation\n(KD) to construct a robust representation space [13]–[15].\nHowever, these methods are designed to obtain a more efficient\nrepresentation by SSL and require local fine-tuning through a\nsupervised linear evaluation protocol [11] following federated\nlearning. Consequently, existing approaches in unsupervised\nfederated learning are inadequate for addressing the UAD task.\nWith the advancements in UAD using deep learning,\narXiv:2502.21012v1  [cs.DC]  28 Feb 2025\n\n\nJOURNAL OF LATEX CLASS FILES, VOL. 14, NO. 8, AUGUST 2021\n2\nreconstruction-based methods [16]–[18] have emerged as\nprominent strategies by learning to accurately reconstruct\nnormal samples while minimizing reconstruction loss, thereby\nenabling the identification of anomalies as deviations from\nexpected reconstructions. Intuitively, integrating reconstruction\nloss functions to locally optimize the model, followed by\naggregating the model weights through federated learning ap-\nproaches, presents a promising avenue for enabling federated\nlearning in UAD. However, as shown in Fig. 1, the intra-\nclass distribution bias within the normal sample class, caused\nby variations in products, is also an important issue in UAD\n[19]. Similarly, data heterogeneity in federated learning can\nlead to significant performance degradation and convergence\nchallenges, primarily due to inconsistencies in local updates\nand optimization dynamics [20], [21]. Recently, most of the\ncurrent federated learning methods focus on addressing the\nchallenges posed by data heterogeneity [22]–[27]. To address\nthe feature shift challenge in federated learning, some methods\nhave proposed incorporating local constraints by the global\nmodel or gradient information, thereby mitigating discrepan-\ncies across clients [20], [22], [23], [28], [29]. Despite these\nefforts, the significant intra-class feature distribution bias in\nUAD results in insufficient global information to effectively\ncapture the representations and knowledge of diverse products\n[30]. Meanwhile, other researchers have addressed this issue\nby synthesizing data [31], [32]. However, sharing additional\ndata among clients inherently increases the risk of data privacy\nleakage [33]. Recent approaches have increasingly emphasized\nprototype-learning methods to tackle the challenges posed\nby inconsistent data distributions. These methods construct\ncategory-specific global and local prototypes by leverag-\ning feature alignment, effectively addressing generalization\ngaps across local clients [26], [27], [34], [35]. Nevertheless,\nreconstruction-based loss functions in UAD often lead to\noverfitting on local features of normal samples [36]. The use of\na single category hinders effective global feature aggregation\nand prevents normal representations from achieving a compact\ndistribution. As a result, the aggregated prototypes deviate\nfrom the desired global distribution of normal samples.\nFurthermore, communication between clients in federated\nlearning is limited by network bandwidth, unreliable connec-\ntions, and varying device statuses. Consequently, designing\ncommunication-efficient algorithms is crucial to overcome\nthese challenges [37]. Existing methods primarily tackle this\nissue by either decreasing the total number of communication\nrounds required for model convergence or reducing the data\nuploaded during each communication round [38]. To acceler-\nate global convergence, some approaches leverage mechanisms\nsuch as localized model updates [39] and gradient optimiza-\ntion enhancements [40], effectively reducing the number of\ncommunication rounds. To reduce the data uploaded, methods\nsuch as model compression [41]–[43] and selective client\nparticipation [44] have been extensively explored to minimize\ncommunication overhead. In this article, we aim to enhance the\nefficiency of federated learning by minimizing communication\noverhead through effective data reduction.\nTo summarize, federated UAD must address the following\nkey challenges: 1) enabling each client to perform end-to-\nend unsupervised anomaly detection without the reliance on\nadditional labeled data or supervised fine-tuning, utilizing\nonly one-class (normal) samples as the basis for training. 2)\nmitigating significant distribution biases in normal sample data\nacross clients, which arise due to the heterogeneous product\ntypes or health screening modalities within the federated learn-\ning framework. 3) ensuring efficient communication between\nclients and the central server to minimize overhead. This\narticle introduces FedDyMem, an efficient federated learn-\ning framework with dynamic memory and memory-reduce,\nspecifically designed to tackle the aforementioned challenges\nin federated UAD. FedDyMem facilitates knowledge transfer\nin federated learning by sharing the memory bank instead of\nmodel parameters among clients. Specifically, it constructs a\nlocal memory bank using the limited dataset of normal samples\navailable at each client. To address the challenge of intra-class\ndistribution bias in different clients, a memory generator and a\nmetric loss function are introduced to improve the consistency\nof normal feature distributions. Then the local memory bank\nis dynamically updated by the local client model before\nuploading. To mitigate distribution bias during aggregation,\nFedDyMem employs k-means clustering to extract general\ndistribution from different clients, thereby ensuring effective\naggregation without confusion. Considering communication\nefficiency, a memory-reduce method is proposed to decrease\nthe scale of memory banks during dynamic updates. To\nconstruct diverse data for our experiments, we categorize the\n11 public datasets into six distinct types based on their inherent\ncharacteristics. We then evaluate our proposed method sepa-\nrately on six product or health screening types, achieving state-\nof-the-art performance in each case. The major contributions\nof this article are summarized as follows:\n• To the best of our knowledge, FedDyMem is the first\nfederated learning framework designed specifically for\nunsupervised image anomaly detection. This framework\nfacilitates collaborative training using only normal sam-\nples available on the client side. To ensure privacy-\npreserving knowledge sharing, we introduce a dynamic\nmemory bank as an alternative to exchanging model\nparameters.\n• To address the significant distribution biases of normal\nsamples across clients, we incorporate a memory genera-\ntor and a metric loss function that improve the consistency\nof feature distributions. Additionally, we employ k-means\nclustering during the aggregation phase to reduce inter-\nclient discrepancies and mitigate potential ambiguities.\n• To improve communication efficiency, we propose a\nmemory-reduce method based on a dynamic weighted\naverage. This method substantially decreases the size of\nthe memory bank, thereby minimizing communication\noverhead while preserving performance.\n• We have collected eleven image anomaly detection\ndatasets from various industrial and medical domains.\nThese datasets are further divided into six datasets de-\npending on the type of product or health screening. Com-\nprehensive experiments demonstrate that FedDyMem\nachieves excellent federated UAD performance.\n\n\nJOURNAL OF LATEX CLASS FILES, VOL. 14, NO. 8, AUGUST 2021\n3\nII. RELATED WORK\nA. Unsupervised Image Anomaly Detection\nThe objective of UAD is to identify whether a given sample\nis anomalous and to precisely localize the anomaly regions,\nusing a training dataset that comprises only normal samples\n[1]. The reconstruction-based methods are significant in UAD,\nwhich assumes that anomalous samples cannot be accurately\nreconstructed by feature learning models trained exclusively\non normal samples [17], [18], [45]–[48]. In contrast to tradi-\ntional UAD approaches, which rely on a single, centralized\ntraining dataset, federated UAD requires the efficient aggrega-\ntion of information from samples distributed across multiple\nclients. Reconstruction-based methods, however, typically rely\nsolely on normal samples within the training set and fail\nto capture key characteristics of out-of-distribution samples.\nAnother widely utilized approach for anomaly detection is\nthe memory bank-based method. SPADE [49] proposed a\nsemantic pyramid structure to construct a pixel-level feature\nmemory, effectively facilitating anomaly detection. PaDiM\n[50] employed Gaussian distributions derived from normal\nsamples as the memory bank and utilized the Mahalanobis\ndistance as the anomaly metric. PatchCore [51] introduced\nlocal neighborhood aggregation to expand the receptive field\nof the memory bank while preserving resolution. Additionally,\nPatchCore implemented a greedy core-set subsampling strat-\negy to reduce the memory bank size without significant perfor-\nmance degradation. PNI [52] further advanced the paradigm\nby integrating spatial and neighborhood information into the\nmemory bank construction, thereby improving its capacity to\nrepresent normal samples comprehensively. These methods\nextract features from normal images and store them within\na feature memory bank. During testing, the sample queries\nthe memory bank to retrieve feature corresponding to the\nk-nearest neighbors. However, the memory banks are non-\ntrainable, limiting their capacity to learn information across\nlocal clients in the federated learning.\nB. Federated Learning\nThe federated learning can be divided into supervised-based\nand unsupervised-based methods. In unsupervised federated\nlearning, most existing methods focused on representation\nlearning or prototype-based learning, which aimed to learn\ngood feature representations from unlabeled data to facilitate\ndownstream machine learning tasks [11]–[15]. However, these\nmethods depend on aligning local representations with global\nrepresentations, a task that proves challenging for UADs con-\nstrained to a single category. ProtoFL [53] was proposed to in-\ntegrate federated learning with prototyping for addressing one-\nclass classification. However, its two-stage fine-tuning method,\nwhich utilizes normalizing flow for representation learning,\nintroduces unnecessary computational overhead and ignores\ndistribution bias among clients in UAD. Furthermore, most\nunsupervised federated learning approaches require supervised\nfine-tuning, which limits their applicability to UAD.\nFedAvg [54] is a foundational approach in federated learn-\ning that enables the training of a global model by aggregating\nparameters from locally trained models. Despite its effec-\ntiveness, the performance of FedAvg degrades significantly\nwith high data heterogeneity. FedProx [22] and SCAFFOLD\n[20] demonstrated enhanced performance through a global\npenalty term, effectively addressing and mitigating discrepan-\ncies. Other methods have now been developed to address the\ndata heterogeneity with the personalized model. FedBN [23]\nmitigates data heterogeneity challenges in federated learning\nby maintaining BN parameters that are specific to each client’s\nlocal model. APPLE [29] aggregates client models locally\nby learning precise weight updates instead of relying on ap-\nproximations. Recent approaches address generalization gaps\nacross local clients by leveraging feature alignment to con-\nstruct category-specific global and local prototypes [26], [27],\n[34], [35]. Nevertheless, the aforementioned methods face\nsignificant challenges in UAD, including high communication\noverhead, insufficient representation diversity and pronounced\nintra-class distribution bias.\nIII. PRELIMINARY\nA. Typical Federated Learning\nIn the typical federated learning, such as FedAvg [54],\nthere\nexist\nN\nclients\n{Cn}N\nn=1\nwith\ntheir\nindividual\ndatasets {Dn = (Xn, Yn) ∼Pn(X, Y)}N\nn=1 and local models\n{f n(·; Wn): Xn →Yn}N\nn=1, where n is the index for the\nclient, (Xn, Yn) denotes a set of samples and labels on the n-\nth client, Pn(X, Y) represent the joint distribution of samples\nand labels. The objective of the typical federated learning\nis to facilitate collaborative training of a global model WG\nthat generalizes effectively across the entire dataset D while\nensuring data privacy. The global training optimization target\nis:\nmin L(WG)\nWG\n∆=\nN\nX\nn=1\nznLn(Wn),\n(1)\nwhere the zn denotes the weight coefficient which is computed\nas |Dn|\n|D| in FedAvg, where the |D| = SN\nn=1 Dn. The empirical\nloss Ln(Wn) of the n-th client can be formulated as:\nLn(Wn) = E(x∈Xn,y∈Yn)∼Pn(X,Y)[ℓ(f n(x; Wn), y)],\n(2)\nwhere ℓ(·, ·) denotes the loss function on the clients. Follow-\ning the local updates, the server S performs aggregation of\nmultiple local models’ parameters to derive the global model\nas WG ←PN\nn=1 znWn.\nB. Federated UAD\nAs shown in Fig. 1, each client in UDA could be an\nindustrial manufacturing enterprise, an organizational entity\nor a healthcare institution, etc. that faces the challenges of\nlarge raw abnormal data. Consequently, the training dataset\navailable at the n-th client is denoted as:\nDtrain\nn\n= (Xn, Yn) ∼Pn(X), ∀y ∈Yn, y = 0,\n(3)\nand the test dataset is denoted as\nDtest =\n[N\nn=1 Dtest\nn\n, where\n(4)\nDtest\nn\n= (Xn, Yn) ∼Pn(X, Y), ∃y ∈Yn, y = 1,\n\n\nJOURNAL OF LATEX CLASS FILES, VOL. 14, NO. 8, AUGUST 2021\n4\nFig. 2. Overview of our proposed FedDyMem framework. During the training phase, a pre-trained feature extractor is employed to extract features from the\nlocal training dataset, which are subsequently projected to the target domain using a projection layer. The projected features are processed through a memory\ngenerator to construct the local memory bank. In the initialization, the memory bank is further refined and reduced in size by the memory-reduce method.\nThe server collects the local memory banks from multiple clients and aggregates them into a unified global memory bank. During the inference phase, the\nclient utilizes the unified global memory bank to generate anomaly score maps for the test images.\nwhere a label y = 0 indicates a normal sample, while y = 1\ndenotes an anomalous sample. In practical scenarios, as shown\nin Fig. 1, the distribution of client samples for the same\nproduct is different in training dataset:\n∃xm∈Dtrain\nm\n,xn∈Dtrain\nn\nPm(xm) ̸= Pn(xn), while m ̸= n. (5)\nWe refer to this variation as the intra-class distribution bias.\nConsistent with typical federated learning, our global opti-\nmization objective remains as defined in 1. However, due to\nthe absence of anomalous samples in the Dtrain, the local\nmodel f n(·; Wn) cannot effectively model Xn →Yn. Thus,\nthe empirical loss of the n-th client in UAD is formulated as:\nLn(Wn) = E(x∈Xn)∼Pn(X)[ℓ(f n(x; Wn))],\n(6)\nwhere ℓ(·) denotes the local loss function for individual clients.\nIt requires the n-th local model f n(·; Wn) to approximate\nthe normal sample distribution, i.e., Pn(X train) , under the\ncondition of intra-class bias (refer to 5). For the federated\nUAD, shown in Fig. 1, the global model’s objective in one-\nclass classification task is to generalize across all clients by\nconstructing P({X train\nn\n}N\nn=1). During the testing phase, the\nresult of a sample xtest ∈Dtest can be expressed as follows:\n1(xtest) =\n(\n0,\nif f(xtest; WG) ∼P({X train\nn\n}N\nn=1)\n1,\notherwise.\n(7)\nIV. METHODOLOGY\nA. Overview\nIn this article, we propose an efficient federated learning\nwith dynamic memory and memory-reduce for UAD, called\nFedDyMem. FedDyMem aims to train model parameters on\ndatasets with locally inconsistent feature distributions and\ngenerate a global memory bank that produces uniform distri-\nbutions, thereby achieving high performance on global Dtest.\nOn the n-th client, as shown in Fig. 2, the feature extractor,\nprojection layer, and memory generator collaboratively gener-\nate high-quality memory representations {Mn,i,t}|Dtrain\nn\n|\ni=0\nin\nthe training workflow, where i denotes the i-th sample in\nDtrain\nn\nand t denotes the t-th rounds. During the initialization\nphase (t = 0), all memory features {Mn,i,0}|Dtrain\nn\n|\ni=0\nextracted\nfrom training samples are processed through memory-reduce\nbefore being send directly to the server. The local memory\nbank M′n,0 synchronizes with the aggregated memory bank\n¯\nM0\nagg\n←−{Mn,0\nreduce}N\nn=0 received from the server. After\ninitialization, the extracted memory feature for sample i,\ndenoted as Mn,i,t, is utilized in subsequent rounds to compute\nthe local loss ℓ. This computation is performed in conjunction\nwith the local memory bank M′n,t−1, which is obtained from\nthe server aggregation during the previous round. Following\nlocal training, the final updated memory features Mn,i,t\nare reduced by the memory-reduce and sent to the server,\nsummarized as {Mn,i,t}|Dtrain\nn\n|\ni=0\n→Mn,t\nreduce. On the server,\nrepresentation sharing [15], [34], [53] provides distinct advan-\n\n\nJOURNAL OF LATEX CLASS FILES, VOL. 14, NO. 8, AUGUST 2021\n5\nAlgorithm 1 Memory Generator for the sample xn\ni on Client\nn at Round t.\nInput: n, t,xn\ni ∈Dtrain\nn\n, F(·), Pn(·, WP), Gn(·, WG; G).\nOutput: Mi.\n1: {F(i,l)}\nL\nl=1 ←F(xn\ni ), where L is determined by F;\n2: ˜Fi ←Compute by Equation (8);\n3: Pi ←Compute by Equation (9);\n4: Mi ←Gn(Pi, WG; G) with Equation (10) (11);\n5: return Mi\ntages over parameter aggregation in addressing heterogeneity\nin unsupervised federated learning, as parameter aggregation\nmethods suffer from privacy and intellectual property (IP) con-\ncerns [55]–[57] and introduce high communication overhead.\nTherefore, FedDyMem employs a memory bank sharing to\nensure data privacy. In the t-th round, the server receives N\nlocal memory banks, denoted as {Mn,t\nreduce}N\nn=0. As shown in\nFig. 2, FedDyMem employs K-means clustering algorithm,\nwhere K corresponds to the capacity of the local memory,\nto aggregate the diverse local memory banks into a unified\nglobal memory bank, represented as\n¯\nMt agg\n←−{Mn,t\nreduce}N\nn=0.\nThe global memory bank\n¯\nMt is subsequently distributed to\nall clients to update their respective local memory banks.\nConsequently, at any round t, for all n ∈N, the local memory\nbanks are synchronized such that M′n,t =\n¯\nMt. During the\ntesting phase, the extracted memory features Mi are compared\nagainst the memory bank ¯\nM using the nearest neighbor search,\nand the anomaly score Ai is computed based on the resulting\nmetric, following the anomaly score function in [51], [58].\nB. Methodology for Obtaining Mn,i,t\nLocally, FedDyMem employs a frozen CNN model F(·)\npre-trained on ImageNet to extract multi-level hierarchical\nfeatures. Motivated by [51], FedDyMem performs multi-level\nfeature fusion on the extracted features. As shown in Fig. 3, for\na given sample xn\ni ∈RH×W ×3 which is from the n-th client’s\nDn, the extracted features are hierarchically organized into L\nlayers (e.g., L = 5 in the case of ResNet [59]). We define\nFi,l ∈RHl×Wl×Cl as the output features of the l-th layer,\nobtained from F(xn\ni ), where i denotes the i-th sample from\nlocal dataset, l ∈L denotes the l-th layer and Hl, Wl, Cl are\nthe size and channel of the feature map. In multi-level feature\nfusion, we employ a straightforward approach combining up-\nsampling and feature concatenation to extract features from\npre-trained CNNs. This process can be expressed as follows:\n˜Fi = fconcat({fup(Fi,l, (H0, W0))}L\nl=0),\n(8)\nwhere fconcat(·) represents the concatenation operation,\nfup(·, (H, W)) denotes bilinear interpolation to the spatial di-\nmensions (H, W). Feature extractors pretrained on large-scale\nnatural image datasets often exhibit significant distribution\nshifts when applied to industrial or medical images. To address\nthis issue, we introduce a projection layer P(·, WP) designed\nto adapt the extracted features to the anomaly detection do-\nmain. As shown in Fig. 3, the projection layer is implemented\nFig. 3. The feature extraction stage in FedDyMem. Multi-level features are\nextracted using a pretrained CNN combined with multi-level feature fusion.\nThese features are then projected into the anomaly detection domain through a\nprojection layer. Subsequently, memory features are generated using a memory\ngenerator.\nas a 1 × 1 convolutional layer, enabling the output Pi of the\nprojection to be computed as follows:\nPi = σ(fconv( ˜Fi, W1×1)),\n(9)\nwhere fconv(·, Wq×q) denotes q × q convolution layer, σ(·)\ndenotes the activation function.\nThe memory bank-based approach [49]–[51] has demon-\nstrated significant performance in UAD. However, the memory\nbanks utilized in these existing methods are non-trainable,\nmeaning they remain unchanged following initialization. Due\nto the local bias in feature distributions for federated UAD,\nusing the static memory bank will lead to overfitting on\ndomain-specific data, increasing the risk of error. Furthermore,\nexisting methods operate mainly on a discrete feature space,\nwhich increases the variations in feature distributions between\nclients for normal samples [60]. In this article, we propose\na memory generator that integrates spatial information and\nensures the continuity of feature space. As shown in Fig. 3,\nthe memory generator G(·, WG; G) utilizes a coordinate con-\nvolution layer fcoorconv(·, W1×1) to encode spatial location\ninformation by incorporating additional coordinate channels,\nthereby facilitating the network’s ability to learn spatial trans-\nformations more effectively [61]. For the projected feature Pi,\nthe result of the coordinate convolution ˆ\nPi ∈RH×W ×C is\ncomputed as\nˆ\nPi = fcoorconv(fconcat({Pi, X, Y}), W1×1),\nwhere X and Y represent the Cartesian coordinates of the\nfeature map. Then, to enhance the continuity of the memory\nbank, the memory generator utilizes a grid-based approach to\nconstruct a continuous feature space. We define a trainable grid\nspace as G ∈RHG×W G×C, where HG and W G are hyper-\nparameters indicating the size of the continuous space. The\nmemory generator maps ˆ\nPi to pixel-wise coordinates ˙Pi ∈\nRH×W ×2 through a mapping function ϕ(·, W): RH×W ×C →\nRH×W ×2, implemented through two 1 × 1 convolutional\nlayers in our memory generator. A sample function s(·, ·) is\nemployed to extract features from the continuous space G\nat specific coordinate values (pi\nx, pi\ny) ∈˙Pi. The normalized\n\n\nJOURNAL OF LATEX CLASS FILES, VOL. 14, NO. 8, AUGUST 2021\n6\nFig. 4. Illustration of Memory-reduce.\ncoordinates are computed as follows:\n˜pi\nx = (pi\nx + 1)\n2\n·(W G−1),\n˜pi\ny = (pi\ny + 1)\n2\n·(HG−1), (10)\nand the result of s(G, ˙Pi) is defined as Oi. Each pixel value\nin Oi can be sampled as:\nOi\nxy =\n1\nX\nm=0\n1\nX\nn=0\nwmnG⌊˜piy⌋+m,⌊˜pix⌋+n, where\n(11)\nwmn = (1 −|˜pi\nx −(\n\u0004\n˜pi\nx\n\u0005\n+ n)|)(1 −|˜pi\ny −(\n\u0004\n˜pi\ny\n\u0005\n+ m)|),\nwhere ⌊·⌋represents the floor operation. Finally, the features\nOi, sampled from the continuous feature space, are con-\ncatenated with the coordinate convolution outputs ˆPi. This\nconcatenated tensor is then passed through a convolutional\nlayer to generate the memory feature Mi ∈RH×W ×C for\nclient n at round t. The complete procedure for obtaining the\nmemory feature is presented in Algorithm 1.\nC. Computation of Local Metric Loss: ℓ(Mn,i,t, M′n,t−1)\nConsidering the bias in feature distributions across clients,\nthe training objective is to optimize the local memory gener-\nator to produce normal features that are more closely aligned\nwith the shared global memory bank. FedDyMem introduces\na simple metric loss to optimize the parameters of both the\nmemory generator and the projection layer, thereby facilitating\nclient models in generating consistent and high-quality mem-\nory features. Specifically, the local memory bank for round\nt is denoted as M′n,t−1 = {m′\nd}D\nd=0 ∈RD×C, where its\nsize is reduced to D after the initialization on the n-th client\nand global aggregation by the server (details of memory-\nreduce and aggregation are provided in Section IV-D and\nSection IV-E). Similar to the patch-based memory bank, the\nmemory features Mn,i,t can be expressed as a collection of\npatch features, {m(h,w) ∈RC}H,W\nh=0,w=0. The loss function ℓ\nis defined as follow:\nℓ(Mn,i,t, M′n,t−1)\n=\n1\nHWK\nH,W\nX\nh,w\nK\nX\nk\nmax(0, dis(m(h,w), m′\nk) −th),\n(12)\nwhere the function dis(·, ·) represents the Euclidean distance\nmetric in this article, th is a hyperparamter to mitigate over-\nfitting. Specifically, we employ a K-nearest neighbor (KNN)\nAlgorithm 2 Memory Reduce for the {Mn,i,t}|Dtrain\nn\n|\ni=0\non\nClient n at Round t.\nInput: n, t, {Mn,i,t}|Dtrain\nn\n|\ni=0\n, M′n,t−1.\nOutput: Mn,0\nreduce.\n1: for i = 0 to\n\f\fDtrain\nn\n\f\f do\n2:\nif t >0 then\n3:\nwi,t ←Compute by Equation (15) with Mn,i,t and\nM′n,t−1;\n4:\nelse\n5:\nwi,t ←1;\n6:\nend if\n7: end for\n8:\n¯\nMn,i,t\nreduce ←Compute by Equation (14) with {wi,t}N\ni=0\nand {Mn,i,t}N\ni=0;\n9: if t >0 then\n10:\nα ←1/(t + 1);\n11:\nMn,t\nreduce ←Compute by Equation (16) with\n¯\nMn,i,t\nreduce,\nM′n,t−1 and α;\n12: else\n13:\nMn,t\nreduce ←¯\nMn,i,t\nreduce;\n14: end if\n15: return Mn,t\nreduce\nsearch to retrieve the top K closest features from the memory\nbank corresponding to the generated features. Therefore, k\ndenotes the index in top K. FedDyMem uses the metric loss\nfunction to align the local features with the global memory\nbank. Following local training, the local memory bank is\nupdated once before being uploaded to the server. This ensures\nthat the local memory bank closely approximates the global\nmemory bank in feature space.\nD. Memory-reduce for {Mn,i,t}|Dtrain\nn\n|\ni=0\n→Mn,t\nreduce\nThe earlier memory-based methods [49], [51] involved\nstoring all sample memory features from the training dataset\nDtrain\nn\nwithin the memory bank. Accordingly, the capacity\nof the memory bank scales proportionally with the size of\nthe local dataset. For federated UAD, the large-scale dataset\nsignificantly challenges communication efficiency. Moreover,\nthe varying sizes of memory banks also introduce challenges\nin the aggregation process. Motivated by this, FedDyMem\nincorporates a memory-reduce method to compress the col-\nlected memory features from the local dataset. The objective\nof memory-reduce can be expressed as follows:\n{Mn,i,t}|Dtrain\nn\n|\ni=0\n∈R|Dtrain\nn\n|×H×W ×C\n→Mn,t\nreduce ∈RH×W ×C,\n(13)\nwhere Mn,i,t represents the memory feature extracted by\nclient n for the i-th sample in the training dataset Dtrain\nn\n, H\nand W denote the spatial dimensions of the memory feature,\nand C indicates the number of feature channels.\nTo address the memory bank size issue, [58] employs\nan Exponential Moving Average (EMA) method. However,\nthe reduced memory bank remains sensitive to the sequence\n\n\nJOURNAL OF LATEX CLASS FILES, VOL. 14, NO. 8, AUGUST 2021\n7\nAlgorithm 3 Aggregation on Server S for Round t.\nInput: t ,{Mn,t\nreduce}N\nn=0.\nOutput:\n¯\nMt.\n1: m ←[];\n2: H, W, C ←Mn,t\nreduce.size();\n3: K ←HW;\n4: for n = 0 to N do\n5:\n{mn\n(h,w)}(H,W )\n(h=0,w=0) ←fresize(Mn,t\nreduce, (HW, C));\n6:\nm ←m ∪{mn\n(h,w)}(H,W )\n(h=0,w=0);\n7: end for\n8: {ck ∈RC}K\nk=0 ←K-means(m);\n9:\n¯\nMt ←fresize({ck}K\nk=0, (H, W, C));\n10: return\n¯\nMt\nin which input samples are processed. In this article, we\nintroduce a dynamic weighted average, called memory-reduce,\nthat optimizes memory size while preserving sample order\nindependence and effectively correlating with the number of\ncommunication rounds. As shown in Fig. 4, we aggregate all\nmemory features, denoted as {Mn,i,t}|Dtrain\nn\n|\ni=0\nand apply a dy-\nnamic weighted averaging operation to compute the\n¯\nMn,i,t\nreduce\nas:\n¯\nMn,i,t\nreduce =\n|Dtrain\nn\n|\nX\ni=0\nwi,tMn,i,t/\n|Dtrain\nn\n|\nX\ni=0\nwi,t,\n(14)\nwhere the dynamic weight wi,t is computed as:\nwi,t =\n(\n1,\nif t = 0\n∥Mn,i,t −M′n,t−1∥2,\notherwise.\n(15)\nHere, the dynamic weight wi,t is influenced by the distance\nbetween the reduced memory representation Mn,i,t and the\nprevious memory bank M′n,t−1.\nAfter computing\n¯\nMn,i,t\nreduce, a round-based EMA (rEMA)\nmethod is employed to update the memory bank. This ap-\nproach ensures smoother and more stable updates during the\ntraining process. The update rule is defined as:\nMn,t\nreduce = α ¯\nMn,i,t\nreduce + (1 −α)M′n,t−1\n(16)\nwhere α represents the exponential decay rate, dynamically\ncalculated as α = 1/(t + 1). The Memory-reduce is detailed\nin Algorithm 2.\nE.\n¯\nMt agg\n←−{Mn,t\nreduce}N\nn=0 on Server\nAt round t, the server S collects the newly generated\nmemory banks from N clients, denoted as {Mn,t\nreduce}N\nn=0 ∈\nRN×H×W ×C.\nThe\nobjective\nof\nthe\nserver\nis\nto\nag-\ngregate these memory banks into a unified, representa-\ntive memory bank\n¯\nMt. This process is formalized as\nS(·, ·): RN×H×W ×C\n→\nRH×W ×C. Representation-based\nfederated learning approaches, such as those proposed in\n[34], [63], utilize weighted aggregation of class prototypes\nduring model updates. However, significant feature bias in the\nearly training stages leads to aggregated memory that deviates\nsignificantly from the client-specific memory, which often\ncontains incomplete product types. This misalignment hinders\nAlgorithm 4 Initialization at Round 0.\nInput: {Dtrain\nn\n}\nN\nn=0, F(·), Pn(·, WP), Gn(·, WG; G).\nOutput: {M′n,0}\nN\nn=0\n1: for each client n in parallel do\n2:\nInitialize\nWP,\nWG\nrandomly\nfor\nPn(·, WP),\nGn(·, WG; G);\n3:\nInitialize G by Xavier normal initialization method [62]\nfor Gn(·, WG; G);\n4:\nfor i = 0 to\n\f\fDtrain\nn\n\f\f do\n5:\nMi ←Compute by Algorithm 1 with t = 0, n, xn\ni ,\nF(·), WP, WG, G;\n6:\nend for\n7:\n{Mn,i,0}|Dtrain\nn\n|\ni=0\n←[M0, M1, · · · ];\n8:\nMn,0\nreduce ←Compute by Algorithm 2 with n, t = 0\nand {Mn,i,0}|Dtrain\nn\n|\ni=0\n;\n9:\nWP,n,0 ←WP, WG,n,0 ←WG, Gn,0 ←G\n10: end for\n11: {Mn,0\nreduce}N\nn=0 ←[M0,0\nreduce, M1,0\nreduce, · · · ];\n12:\n¯\nM0\n←Compute by Algorithm 3 with t = 0 and\n{Mn,0\nreduce}N\nn=0;\n13: for n = 0 to N do\n14:\nM′n,0 ←¯\nM0;\n15: end for\n16: return {M′n,0}\nN\nn=0 ←[M′0,0, M′1,0, · · · ]\nconvergence, posing a challenge for clients with limited data\ndiversity. Thus, we employ a clustering-based approach to\naggregate the collected memory banks effectively. Specifically,\nthe memory features are represented as N × H × W patch\nfeatures, denoted by mn\n(h,w) ∈RC. These patch features are\nsubsequently clustered using the K-means algorithm, where\nthe number of clusters, K, corresponds to H × W. The\nclustering results indicate the overall distribution and similarity\nrelationships between the patch-level features stored across all\nbanks at the current stage of the process. Cluster centers de-\nscribe the representative features of a memory bank. Let ck ∈\nRC denote the center of the k-th cluster, serving as a global\nmemory bank updated by ¯\nMt = fresize({ck}K\nk=0, (H, W, C))\nand shared across individual clients, ∀n ∈N, M′n,t =\n¯\nMt.\nThe aggregation methodology is outlined in Algorithm 3,\nwhile the comprehensive training procedure for FedDyMem\nis presented in Algorithm 5.\nF. Privacy Preserving Discussion\nFedDyMem facilitates the exchange of statistical informa-\ntion, i.e., memory banks, between the clients and the server, in-\nstead of transmitting model parameters, thereby enhancing pri-\nvacy protection [34]. The memory features that are transmitted\nare derived from multi-layer low-dimension representations,\nwhich is an irreversible process [65]. In practice, additional\nprivacy-preserving techniques can be incorporated into the\nFedDyMem framework to further improve system reliability\n[66] and ensure robust data protection [67].\n\n\nJOURNAL OF LATEX CLASS FILES, VOL. 14, NO. 8, AUGUST 2021\n8\nAlgorithm 5 Training for FedDyMem.\nInput: N Clients {Cn}N\nn=1 with {Dtrain\nn\n}\nN\nn=0, one server S,\nthe number of rounds T, the local epochs E.\n1: {M′n,0}\nN\nn=0 ←Initialization by Algorithm 4;\n2: for t = 1 to T do\n3:\nfor each client n in parallel do\n4:\nMn,t\nreduce ←ClientUpdate(n, t, E, Dtrain\nn\n);\n5:\nend for\n6:\n{Mn,t\nreduce}N\nn=0 ←Collection all memory bank from N\nclients;\n7:\n¯\nMt ←Upload {Mn,t\nreduce}N\nn=0 to S and computed by\nAlgorithm 3;\n8: end for\n9: Save all well trained {WP,n,T , WG,n,T , Gn,T }N\nn=0 and\n¯\nMT locally.\nClientUpdate(n, t, E, Dtrain\nn\n):\n10: for e = 0 to E do\n11:\nfor i = 0 to\n\f\fDtrain\nn\n\f\f do\n12:\nMi ←Compute by Algorithm 1 with t, n, xn\ni ;\n13:\nℓ←Compute loss by Equation (12) with Mi and\nM′n,t−1;\n14:\nUpdate {WP,n,t, WG,n,t, Gn,t} by ℓand Adam\nOptimizer [64];\n15:\nend for\n16: end for\n17: {Mn,i,t}|Dtrain\nn\n|\ni=0\n←[M0, M1, · · · ];\n18: Mn,t\nreduce ←Compute by Algorithm 2 with n, t and\n{Mn,i,t}|Dtrain\nn\n|\ni=0\n;\n19: return Mn,t\nreduce\nV. CONVERGENCE ANALYSIS\nWe provide the convergence analysis for FedDyMem con-\nsidering the non-convex nature of its loss function. Some com-\nmon assumptions based on existing frameworks are reasonably\npresented below:\nAssumption 1 (Piecewise L2-Lipschitz Smooth). Let\ndis(m(h,w), m′\nk) = th denote the discontinuity point. For any\nt, t′ > 0, there exists L > 0 satisfying:\n∥∇ℓ(Mn,i,t, M′n,t−1) −∇ℓ(Mn,i,t′, M′n,t′−1)∥2\n≤L∥Mn,i,t −Mn,i,t′∥2.\n(17)\nAssumption 2 (Bounded Gradients). The gradients of the\nloss function are bounded, i.e., there exists G > 0 satisfying:\n∥∇ℓ(Mn,i,t, M′n,t−1)∥2 ≤G.\n(18)\nAssumption 3 (Unbiased Gradient and Bounded Vari-\nance). The stochastic gradient gt is an unbiased estimate\nof the true gradient, i.e., E[gt] = ∇ℓ(Mn,i,t, M′n,t−1).\nFurthermore, the variance of gt is bounded, i.e., there exists\nσ2 > 0 satisfying:\nE[∥gt −∇ℓ(Mn,i,t, M′n,t−1)∥2\n2] ≤σ2.\n(19)\nAssumption 4. Based on the loss function’s structure, the\nhyperparameter th is constrained as:\nth ∈\n\nmin\nh,w,k dis(m(h,w), m′\nk),\n1\nHWK\nH,W,K\nX\nh,w,k\ndis(m(h,w), m′\nk)\n\n\n, ensuring the loss function ℓremains finite and satisfies the\noperational properties in Assumptions 1-4.\nTheorem 1 (Loss Reduction). For any client, after every\ncommunication round, when the learning rate satisfies 0 < η <\n2\nL, and letting Mt = Mn,i,t, M′ = M′n,t−1, the expected\nloss after T iterations satisfies:\nE[ℓ(MT , M′)] ≤ℓ(Mn,i,1, M′n,0) + Tη2Lσ2\n2\n−\n\u0012\nη −η2L\n2\n\u0013 T −1\nX\nt=1\nE[∥∇ℓ(Mt, M′)∥2\n2].\n(20)\nProof. For each iteration, based on the Assumptions above,\nthe loss function satisfies:\nE[ℓ(Mt+1, M′)] ≤E[ℓ(Mt, M′)] −ηE[∥∇ℓ(Mt, M′)∥2\n2]\n+ η2L\n2 E[∥∇ℓ(Mt, M′)∥2\n2]\n≤E[ℓ(Mt, M′)] + η2Lσ2\n2\n−\n\u0012\nη −η2L\n2\n\u0013\nE[∥∇ℓ(Mt, M′)∥2\n2].\nAfter T iterations, we obtain:\nE[ℓ(MT , M′)] ≤ℓ(Mn,i,1, M′n,0) + Tη2Lσ2\n2\n−\n\u0012\nη −η2L\n2\n\u0013 T −1\nX\nt=1\nE[∥∇ℓ(Mt, M′)∥2\n2].\nTheorem\n1\nexpresses\nthat\nby\nappropriately\nselecting\nη\nand\nσ,\nthe\npenalty\nterm\nT η2Lσ2\n2\nin\nthe\nloss\nde-\nscent inequality can be controlled, such that the term\n−\n\u0010\nη −η2L\n2\n\u0011 PT −1\nt=1 E\n\u0002\n∥∇ℓ(Mt, M′)∥2\n2\n\u0003\nplays a dominant\nrole in the gradient descent of the loss function. In the\nsubsequent Theorem 2, we provide the convergence results\nof the model.\nTheorem 2 (FedDyMem Convergence). Based on the\nprevious assumptions and Theorem 1, when th satisfies the\nconstraint in Assumption 4, for any ϵ >\nηLσ2\n2(η−η2L\n2\n), there exists:\nT = ℓ(Mn,i,1, M′n,0) −ℓ\nϵ\n\u0010\nη −η2L\n2\n\u0011\n,\nsuch that for t > T,\n1\nT\nT −1\nX\nt=1\nE[∥∇ℓ(Mn,i,t, M′n,t−1)∥2\n2] ≤ϵ.\n(21)\n\n\nJOURNAL OF LATEX CLASS FILES, VOL. 14, NO. 8, AUGUST 2021\n9\nProof. From Theorem 1, we have:\nE[ℓ(MT , M′)] ≤ℓ(Mn,i,1, M′n,0) + Tη2Lσ2\n2\n−\n\u0012\nη −η2L\n2\n\u0013 T −1\nX\nt=1\nE[∥∇ℓ(Mt, M′)∥2\n2].\nSince ℓ(M, M′) has a non-negative lower bound ℓ, satis-\nfying 0 < ℓ< ℓ, we write:\nℓ≤ℓ(MT , M′)\n≤ℓ(Mn,i,1, M′n,0) + Tη2Lσ2\n2\n−\n\u0012\nη −η2L\n2\n\u0013 T −1\nX\nt=1\nE[∥∇ℓ(Mt, M′)∥2\n2].\nAfter rearranging and simplifying:\n1\nT\nT −1\nX\nt=1\nE[∥∇ℓ(Mt, M′)∥2\n2] ≤ℓ(Mn,i,1, M′n,0) −ℓ\nT(η −η2L\n2 )\n+\nηLσ2\n2(η −η2L\n2 )\n.\nLetting this upper bound be less than or equal to ϵ, we solve\nfor T:\nT ≥ℓ(Mn,i,1, M′n,0) −ℓ\nϵ(η −η2L\n2 )\n.\nVI. EXPERIMENTS\nAll experiments presented in this article were implemented\nand conducted using the PyTorch framework. Model training\nwas performed on a high-performance computing system\nequipped with AMD EPYC 9554 64-core processors and eight\nNVIDIA GeForce RTX A6000 GPUs, each possessing 48 GB\nof memory, to ensure accelerated computation.\nA. Experimental Settings\n1) Datasets: In this article, we combined 6 image anomaly\ndetection datasets containing different types of data, covering\nvarious industrial inspection scenarios and medical imaging\ndomains, to evaluate the performance of FedDyMem. These\ndatasets are as follows:\n• Mixed-Brain-AD(Brain): We combined 3 brain im-\nage diagnostic datasets, including Brain-Tumor [2],\nBraTS2021 1 [68] and HeadCT 2 [69]. These datasets,\nconsisting of both MRI and CT images, were distributed\nacross different clients in a heterogeneous manner to\nrepresent a mixture of various image types.\n• Mixed-ChestXray-AD(X-ray): Three diagnostic chest\nX-ray datasets, including ChestXRay2017 [70], RSNA3\n[71], and VinDr-CXR4 [72], were employed in this ar-\nticle. These datasets were derived from distinct medical\ninstitutions, ensuring a diverse and heterogeneous data\ndistribution, which is essential for the federated UAD.\n1https://www.kaggle.com/datasets/masoudnickparvar/brain-tumor-mri-\ndataset\n2https://www.kaggle.com/datasets/felipekitamura/head-ct-hemorrhage\n3https://www.kaggle.com/c/rsna-pneumonia-detection-challenge\n4https://www.kaggle.com/c/vinbigdata-chest-xray-abnormalities-detection\nFig. 5. Summary of the dataset distribution on five clients. The relative sizes\nof the pie in the chart illustrate the total data volume across individual clients.\nDistinct colors within each pie represent different product types.\n• Mixed-PCB-AD(PCB): We investigate 2 datasets con-\ntaining PCB anomalies, namely VisA [73] and VISION\n[74] , and integrate them to create the Mixed-PCB dataset.\nThe VisA dataset includes six different types of PCB\nproducts, while the VISION dataset encompasses two\ntypes. Consequently, the Mixed-PCB-AD dataset pro-\nvides a total of 8 distinct types of PCB product images,\nfacilitating simulation in federated UAD.\n• MVTec\n[75]: In this article, we utilize 5 texture\nclasses(carpet, grid, leather, tile, and wood) from the\nMVTec dataset, which includes mask annotations, to\nsimulate industrial federated anomaly detection scenarios.\n• MetalPartsAD(MPDD) [76]: The MPDD comprises im-\nages of 6 types of metal parts, each captured under\nvarying conditions of spatial orientation, object posi-\ntioning, and camera distance. These images are further\ncharacterized by diverse lighting intensities and non-\nhomogeneous backgrounds, providing a comprehensive\ndataset for our federated UAD.\n• TextureAD-Wafer(Wafer) [19]: TextureAD-Wafer com-\nprises a dataset of 14 distinct wafer products, each\nimaged using an industrial-grade, high-resolution optical\ncamera. This dataset also explores these wafer products\nunder various optical conditions, thus providing a rich\nfederated UAD simulate environment with diverse feature\ndistributions.\n2) Scenes with Feature Distribution Bias: In this article,\nwe aim to simulate heterogeneous feature distributions across\n5 clients by all samples from the same normal categories with\ndifferent product types. We employ a Dirichlet distribution\nto allocate data, where each product type, though labeled as\nnormal, is distributed to various clients. We set the Dirichlet\nparameter α\n=\n0.1 to accentuate the variances in data\ndistribution across clients, thus simulating more realistic and\nchallenging multi-client scenarios typically encountered in\nfederated UAD. Fig. 5 illustrates the results of this partitioning\napproach across all datasets.\n3) Implementation Details: The frozen feature extractor\nused in our experiments is the Wide-ResNet-50 model pre-\ntrained on the ImageNet dataset. For FedDyMem, the hy-\nperparameters HG and W G are set to 8, and th is set to\n0.01. All baseline models are constructed using the Wide-\nResNet-50, with all parameters comprehensively aggregated.\nThe parameter K for the KNN algorithm is set to 3. For a\n\n\nJOURNAL OF LATEX CLASS FILES, VOL. 14, NO. 8, AUGUST 2021\n10\nFig. 6. Illustration of the loss curves across five clients evaluated on four datasets, demonstrating convergence trends and performance variability within our\nexperiments.\nfair comparison with other state-of-the-art methods, we ensure\nconsistency in the training parameters used in our experiments.\nSpecifically, the learning rate is set to 1×10−3, with a total of\n200 communication rounds. The local epoch is set to 1, and\nthe batch size is 10. We utilize the Adam optimizer with a\nweight decay of 5 × 10−4 and a momentum of 1. All images\nin the dataset were preprocessed by cropping and resizing to a\nresolution of 224 × 224 pixels using the bicubic interpolation\nmethod.\n4) Evaluation Metric: For the evaluation of anomaly de-\ntection, we adopt the Area Under the Receiver Operating\nCharacteristic Curve (AUROC), ensuring a comprehensive\nassessment of our proposed model in alignment with prior\nstudies. Image-level anomaly detection performance is quanti-\nfied using the standard AUROC metric, denoted as Image-\nlevel AUROC(I-AUROC). Additionally, to assess anomaly\nlocalization, we compute the Pixel-level AUROC(P-AUROC).\nTo further enhance the evaluation of anomaly localization\ncapabilities, we calculate the Per-Region Overlap (PRO) at\nthe pixel level, providing a more granular and comprehensive\nanalysis. These metrics are widely used in previous work [2],\n[17], [36], [51].\nB. Convergence Curves\nIn this section, we present a detailed analysis of the train-\ning loss curves for FedDyMem in comparison with baseline\nmodels across four datasets including Brain, Wafer, PCB, and\nX-ray. The loss curves for all 5 clients are illustrated in Fig. 6\nover 200 communication rounds, providing insights into the\nperformance and convergence behavior of the models. First,\nFedDyMem demonstrates a significantly faster convergence\nrate across all datasets, achieving near-convergence within\nonly a few communication rounds. This rapid convergence\nshows the efficiency and robustness of FedDyMem in dis-\ntributed learning scenarios, making it particularly suitable\nfor real-world applications where communication efficiency is\ncritical. Second, FedDyMem exhibits smoother convergence\ncompared to the baseline models. As shown in the zoomed-\nin view of the later communication rounds in Fig. 6, the\nloss curves of the baseline models have less stable optimiza-\ntion dynamics. In contrast, FedDyMem maintains consistent\nand stable convergence, highlighting its superior optimization\nprocess. Moreover, FedDyMem consistently achieves lower\nfinal loss values across all datasets, outperforming baseline\nmodels in terms of both accuracy and stability. This supe-\nrior performance can be attributed to FedDyMem’s dynamic\nmemory bank mechanism, which facilitates superior global\ngeneralization. The experimental results substantiate the con-\nvergence analysis presented in Section V, further validating\nthe efficiency of FedDyMem in federated learning settings.\n\n\nJOURNAL OF LATEX CLASS FILES, VOL. 14, NO. 8, AUGUST 2021\n11\nTABLE I\nCOMPARISON OF IMAGE-AUROC (%) RESULTS ON SIX DATASET\nMethods\nCommunication Parameters\nWafer\nPCB\nMVTec\nMPDD\nBrain\nX-ray\nLocal\n-\n57.35(±0.71)\n51.89(±0.76)\n75.94(±0.39)\n54.39(±0.77)\n50.66(±0.87)\n61.02(±0.58)\nFedAvg\nModel Paramters:\n≈10.66M,\n(SCAFFOLD)\n≈10.66M * 2\n63.91(±0.36)\n54.18(±0.33)\n80.32(±0.81)\n61.87(±0.76)\n50.16(±0.63)\n61.48(±0.56)\nFedProx\n63.98(±0.51)\n54.11(±0.48)\n80.22(±0.78)\n61.83(±0.61)\n50.47(±0.34)\n61.45(±0.66)\nFedPHP\n63.94(±0.56)\n54.13(±0.36)\n80.19(±0.62)\n61.80(±0.63)\n50.38(±0.39)\n61.45(±0.37)\nAPPLE\n65.92(±0.33)\n56.79(±0.65)\n82.43(±0.51)\n61.03(±0.77)\n50.82(±0.45)\n68.47(±0.51)\nFedBN\n63.89(±0.35)\n54.09(±0.79)\n80.13(±0.77)\n61.90(±0.61)\n50.04(±0.54)\n61.45(±0.72)\nSCAFFOLD\n66.53(±0.85)\n63.56(±0.30)\n83.26(±0.37)\n59.41(±0.80)\n49.90(±0.52)\n72.52(±0.52)\nDBE\n64.12(±0.49)\n53.78(±0.38)\n79.78(±0.90)\n61.78(±0.51)\n50.06(±0.85)\n62.77(±0.61)\nOurs\nMemory Size: ≈5.62M\n71.96(±0.32)\n83.34(±0.45)\n99.24(±0.36)\n83.93(±0.77)\n89.27(±0.45)\n80.30(±0.36)\nTABLE II\nCOMPARISON OF ABNORMAL LOCATION CAPABILITY ON FOUR DATASETS\nMethods\nWafer\nPCB\nMVTec\nMPDD\nP-AUROC(%)\nPRO(%)\nP-AUROC(%)\nPRO(%)\nP-AUROC(%)\nPRO(%)\nP-AUROC(%)\nPRO(%)\nLocal\n58.27(±1.20)\n47.76(±0.52)\n68.12(±1.11)\n45.86(±1.31)\n72.63(±0.98)\n56.97(±0.48)\n87.02(±1.05)\n51.31(±0.73)\nFedAvg\n66.56(±0.70)\n67.00(±0.30)\n69.30(±0.34)\n54.04(±0.57)\n76.16(±0.73)\n53.35(±1.49)\n91.67(±0.94)\n55.07(±1.25)\nFedProx\n66.41(±0.74)\n67.25(±0.33)\n69.10(±1.28)\n54.04(±1.28)\n76.08(±1.28)\n53.62(±0.70)\n91.59(±1.02)\n54.96(±1.16)\nFedPHP\n66.44(±1.38)\n67.16(±0.38)\n69.11(±0.42)\n54.23(±1.16)\n76.03(±0.57)\n53.37(±0.47)\n91.56(±0.73)\n54.86(±1.42)\nAPPLE\n69.88(±0.95)\n69.02(±0.42)\n71.34(±0.85)\n60.11(±1.45)\n78.06(±1.08)\n54.14(±1.16)\n92.12(±1.19)\n55.84(±0.76)\nFedBN\n66.32(±0.57)\n67.16(±0.68)\n68.91(±0.82)\n54.21(±1.07)\n75.92(±1.34)\n53.48(±0.79)\n91.59(±0.38)\n54.92(±0.82)\nSCAFFOLD\n68.75(±1.19)\n68.74(±1.03)\n77.18(±0.54)\n66.43(±0.58)\n80.81(±0.35)\n55.79(±1.30)\n93.47(±0.74)\n58.71(±0.84)\nDBE\n66.95(±1.07)\n68.46(±1.05)\n72.95(±1.35)\n57.89(±0.75)\n76.18(±0.89)\n53.86(±0.58)\n92.66(±1.36)\n55.76(±0.95)\nOurs\n78.40(±1.31)\n74.91(±0.54)\n96.03(±0.79)\n81.09(±1.31)\n97.04(±0.56)\n86.81(±1.13)\n98.97(±1.39)\n79.43(±1.15)\nFig. 7.\nIllustration of I-AUROC test accuracy comparing FedDyMem and\nbaseline models.\nC. Performance Comparisons with Existing Methods\nTo demonstrate the superior performance of FedDyMem,\nwe conducted extensive comparative analyses with 8 baseline\nmodels. These include the basic federated learning algo-\nrithm FedAvg [54], the regularization-based FedProx [22], the\npersonalized-based FedPHP [77] and APPLE [29]. Addition-\nally, we compared against domain-skew-oriented methods such\nas FedBN [23] and SCAFFOLD [20], as well as the model-\nsplitting method DBE [35] and a purely local training scheme\n(Local).\n1) Training Process: Fig. 7 illustrates the I-AUROC perfor-\nmance of the FedDyMem training process in comparison with\nbaseline models on all datasets. FedDyMem achieves superior\ntesting accuracy compared to other baseline models, while\nalso exhibiting a more stable training process. Specifically,\nthe baseline models exchange parameters exclusively during\ncommunication rounds, introducing a distribution bias for\nmemory features. This limitation prevents the models from\nachieving suboptimal solutions.\n2) Communication Cost: In federated learning, communi-\ncation efficiency is crucial for practical deployment, especially\nin bandwidth-constrained or latency-sensitive environments.\nAs shown in Table I, most existing methods (e.g., FedAvg,\nFedProx, APPLE) require extensive communication of full\nmodel parameters, which amount to approximately 10.66 MB\nper communication round. In contrast, our approach only\nrequires the exchange of a memory bank of approximately\n5.62MB during each communication round. This substantially\nreduces communication overhead, enabling faster convergence\nin settings with limited communication resources.\n3) Anomaly Detection: As shown in Table I, the perfor-\nmance of FedDyMem is evaluated across six datasets and com-\npared with a set of baseline models. Conventional federated\nlearning methods such as FedAvg, FedProx, and FedPHP show\nsimilar performance, typically outperforming the Local, but\nremaining below 65% AUROC on most datasets (e.g., 64% on\nWafer). APPLE and FedBN show improvements over FedAvg-\nlike methods (e.g., 65.92% AUROC on Wafer for APPLE), but\ntheir effectiveness decreases on more challenging datasets such\nas Brain, where AUROC remains below 51%. SCAFFOLD\nachieves relatively better results (e.g., 72.52% on X-ray), but\nprovides limited gains on PCB, Brain, and MPDD. Similarly,\nDBE shows incremental improvements across all benchmarks\nbut fails to match our method. In contrast, our proposed\n\n\nJOURNAL OF LATEX CLASS FILES, VOL. 14, NO. 8, AUGUST 2021\n12\nTABLE III\nABLATION STUDY OF STRUCTURE FOR FEDDYMEM.\n+Projection\n+Memory Generator\n+K-means\nI-AUROC (%)\nP-AUROC (%)\nWafer\nPCB\nMVTec\nMPDD\nBrain\nX-ray\nWafer\nPCB\nMVTec\nMPDD\n-\n-\n-\n67.69\n69.58\n85.86\n70.41\n69.03\n68.92\n70.23\n83.23\n85.22\n94.19\n✓\n-\n-\n68.93\n74.10\n87.27\n78.28\n74.95\n72.71\n74.29\n89.26\n90.84\n95.77\n✓\n✓\n-\n70.96\n81.26\n92.76\n81.05\n85.94\n78.12\n77.01\n94.97\n96.10\n97.96\n✓\n✓\n✓\n71.96\n83.34\n99.24\n83.93\n89.27\n80.30\n78.40\n96.03\n97.04\n98.97\nFig. 8. Impact of different local epochs on clients.\napproach consistently achieves the highest I-AUROC scores\nacross all six anomaly detection benchmarks. Specifically, our\nmethod achieves 71.96% for Wafer, 83.34% for PCB, 99.24%\nfor MVTec, 83.93% for MPDD, 89.27% for Brain, and 80.30%\nfor X-ray.\n4) Anomaly Localization: As shown in Table II we evaluate\nthe abnormal localization performance on four datasets (Wafer,\nPCB, MVtec, and MPDD), as the Brain and X-ray do not\nprovide region-level labels. To measure both detection capabil-\nity and localization accuracy, each method is evaluated using\ntwo metrics, P-AUROC and PRO. The baseline method Local\nexhibits the lowest overall performance, with approximately\n58.27% in P-AUROC and 47.76% in PRO on the Wafer\ndataset, and similar results across the other datasets. This\nproves that there are distribution bias in the raw dataset. For\nthe federated learning approaches, FedAvg, FedProx, and Fed-\nPHP demonstrate closely aligned performance improvements.\nAPPLE delivers further performance gains, achieving a P-\nAUROC of up to 69.88% on the Wafer dataset. In contrast,\nour proposed method achieves superior performance across all\nevaluated datasets and metrics. These consistent and robust\nimprovements highlight the effectiveness and adaptability of\nour approach in tackling federated anomaly localization tasks\nacross diverse application scenarios.\nD. Ablation Study\n1) Impact of Local Training Epochs: Fig. 8 illustrates the\nimpact of varying the number of local training epochs (E)\non the performance of federated learning across all datasets.\nA clear trend emerges where increasing E generally results\nFig. 9.\nQualitative comparison of FedAvg and our proposed method. The\nresults were obtained from a randomly selected client using a global memory\nbank.\nin a performance decline. For example, in the Wafer dataset,\naccuracy drops from 71.96% at E = 1 to 69.92% at E = 5.\nSimilarly, the PCB dataset demonstrates a decrease in per-\nformance, with accuracy falling from 83.34% at E = 1 to\n82.65% at E = 5. MPDD, Brain, and X-ray also exhibit\ngradual performance degradation with higher E values. This\nphenomenon can be attributed to the heterogeneous data dis-\ntribution across clients. As the number of local training epochs\nincreases, the local models tend to overfit their respective\nclient datasets, leading to a decrease in the effectiveness of\nthe globally aggregated memory features.\n2) Effect of Projection Layer: The ablation study is pre-\nsented in Table III shows the significant impact of incorpo-\nrating a projection layer on the performance of the proposed\nFedDyMem framework. The baseline configuration used for\ncomparison consists of memory-reduction and memory feature\naverage aggregation mechanisms, without additional architec-\ntural enhancements. Specifically, introducing the projection\nlayer improves both I-AUROC and P-AUROC metrics across\nall datasets. For example, the I-AUROC for Wafer increases\nfrom 67.69% to 68.93%, and the P-AUROC improves from\n70.23% to 74.29%. These results demonstrate that the projec-\ntion layer effectively enhances feature representations.\n3) Effect of Memory Generator: The integration of the\nmemory generator significantly improves the anomaly detec-\ntion performance of FedDyMem across different datasets. For\nexample, the memory generator increases the I-AUROC from\n68.93% to 70.96% on the wafer dataset and from 74.10% to\n81.26% on the PCB dataset. A similar trend is observed for\n\n\nJOURNAL OF LATEX CLASS FILES, VOL. 14, NO. 8, AUGUST 2021\n13\nP-AUROC, with increases from 74.29% to 77.01% on Wafer\nand from 89.26% to 94.97% on PCB. These improvements\ndemonstrate the ability of the memory generator to effectively\nrefine feature representations.\n4) Effect of K-means: The addition of K-means to the\nFedDyMem framework resulted in a consistent improvement\nacross all evaluated metrics. When combined with the projec-\ntion layer and memory generator, K-means further improves I-\nAUROC, achieving increases such as from 70.96% to 71.96%\nfor Wafer and from 81.26% to 83.34% for PCB. Similarly,\nP-AUROC improves significantly with values such as Wafer\nfrom 77.01% to 78.40% and PCB from 94.97% to 96.03%.\nE. Qualitative Results\nFig. 9 provides a qualitative comparison of the prediction\nresults between FedAvg and the proposed FedDyMem method\nunder an identical experimental setting. The FedDyMem ap-\nproach exhibits a notable improvement in prediction qual-\nity, with substantially fewer noisy regions evident in the\nresults. Following the methodology in [58], the anomaly score\nheatmaps are upsampled to match the spatial resolution of the\ninput image and subsequently refined using Gaussian filtering\nwith σ = 4, ensuring smoother and more coherent boundaries.\nFurthermore, min-max normalization is applied to standardize\nthe range of anomaly scores, facilitating clearer visualization\nand interpretation of the results.\nVII. CONCLUSION\nIn this article, we propose a efficient federated learning with\ndynamic memory and memory-reduce, called FedDyMem to\naddress the federated UAD problem. To tackle the challenges\nposed by multi-client data distribution bias in real-world\nindustrial and medical scenarios, FedDyMem introduces a\nmemory generator and a loss function based on distance met-\nrics to dynamically generate high-quality memory banks. To\nenhance communication efficiency, a memory-reduce method\nis incorporated to decrease the size of the memory banks,\nthereby minimizing communication costs. During the aggre-\ngation phase, K-means is employed on the server to mitigate\nambiguity and confusion across memory banks from different\nclients. Extensive experimental results demonstrate that the\nproposed method significantly outperforms existing baselines.\nFuture work will focus on optimizing the model heterogeneity\nadaptation to further enhance the scalability and generalization\nof the proposed framework.\nREFERENCES\n[1] G. Xie, J. Wang, J. Liu, J. Lyu, Y. Liu, C. Wang, F. Zheng, and\nY. Jin, “Im-iad: Industrial image anomaly detection benchmark in\nmanufacturing,” IEEE Transactions on Cybernetics, 2024.\n[2] Y. Cai, W. Zhang, H. Chen, and K.-T. Cheng, “Medianomaly: A\ncomparative study of anomaly detection in medical images,” arXiv\npreprint arXiv:2404.04518, 2024.\n[3] G. Yang, Z. Yang, S. Cui, C. Song, J. Wang, and H. Wei, “Clustering\nfederated learning for wafer defects classification on statistical heteroge-\nneous data,” IEEE Transactions on Instrumentation and Measurement,\n2024.\n[4] Y. Wu, C. Desrosiers, and A. Chaddad, “Facmic: Federated adaptative\nclip model for medical image classification,” in International Conference\non Medical Image Computing and Computer-Assisted Intervention.\nSpringer, 2024, pp. 531–541.\n[5] X.-C. Li and D.-C. Zhan, “Fedrs: Federated learning with restricted\nsoftmax for label distribution non-iid data,” in Proceedings of the 27th\nACM SIGKDD conference on knowledge discovery & data mining, 2021,\npp. 995–1005.\n[6] S. Saha, A. Hota, A. K. Chattopadhyay, A. Nag, and S. Nandi,\n“A multifaceted survey on privacy preservation of federated learning:\nprogress, challenges, and opportunities,” Artificial Intelligence Review,\nvol. 57, no. 7, p. 184, 2024.\n[7] Y. Zhao, Q. Liu, P. Liu, X. Liu, and K. He, “Medical federated\nmodel with mixture of personalized and shared components,” IEEE\nTransactions on Pattern Analysis and Machine Intelligence, 2024.\n[8] W. Li, K. Fan, K. Yang, Y. Yang, and H. Li, “Pbfl: Privacy-preserving\nand byzantine-robust federated learning empowered industry 4.0,” IEEE\nInternet of Things Journal, 2023.\n[9] R. Zhang, H. Li, L. Tian, M. Hao, and Y. Zhang, “Vertical federated\nlearning across heterogeneous regions for industry 4.0,” IEEE Transac-\ntions on Industrial Informatics, 2024.\n[10] Y. Jin, Y. Liu, K. Chen, and Q. Yang, “Federated learning without full\nlabels: A survey,” arXiv preprint arXiv:2303.14453, 2023.\n[11] W. Zhuang, X. Gan, Y. Wen, S. Zhang, and S. Yi, “Collaborative\nunsupervised visual representation learning from decentralized data,” in\n2021 IEEE/CVF International Conference on Computer Vision.\nIEEE,\n2021, pp. 4892–4901.\n[12] X. Liao, W. Liu, C. Chen, P. Zhou, F. Yu, H. Zhu, B. Yao, T. Wang,\nX. Zheng, and Y. Tan, “Rethinking the representation in federated un-\nsupervised learning with non-iid data,” in Proceedings of the IEEE/CVF\nConference on Computer Vision and Pattern Recognition, 2024, pp.\n22 841–22 850.\n[13] S. Han, S. Park, F. Wu, S. Kim, C. Wu, X. Xie, and M. Cha, “Fedx:\nUnsupervised federated learning with cross knowledge distillation,” in\nEuropean Conference on Computer Vision.\nSpringer, 2022, pp. 691–\n707.\n[14] E. S. Lubana, C. I. Tang, F. Kawsar, R. P. Dick, and A. Mathur,\n“Orchestra: Unsupervised federated learning via globally consistent\nclustering,” in Proc. International Conference on Machine Learning,\n2022.\n[15] C. Zhang, Y. Xie, T. Chen, W. Mao, and B. Yu, “Prototype sim-\nilarity distillation for communication-efficient federated unsupervised\nrepresentation learning,” IEEE Transactions on Knowledge and Data\nEngineering, 2024.\n[16] P. Bergmann, S. L¨owe, M. Fauser, D. Sattlegger, and C. Steger, “Improv-\ning unsupervised defect segmentation by applying structural similarity to\nautoencoders,” in Proceedings of the 14th International Joint Conference\non Computer Vision, Imaging and Computer Graphics Theory and\nApplications.\nSCITEPRESS-Science and Technology Publications,\n2019.\n[17] Y. Liang, J. Zhang, S. Zhao, R. Wu, Y. Liu, and S. Pan, “Omni-frequency\nchannel-selection representations for unsupervised anomaly detection,”\nIEEE Transactions on Image Processing, 2023.\n[18] S. Dai, Y. Wu, X. Li, and X. Xue, “Generating and reweighting dense\ncontrastive patterns for unsupervised anomaly detection,” in Proceedings\nof the AAAI Conference on Artificial Intelligence, vol. 38, no. 2, 2024,\npp. 1454–1462.\n[19] T. Lei, S. Chen, B. Wang, Z. Jiang, and N. Zou, “Adapted-moe: Mixture\nof experts with test-time adaption for anomaly detection,” arXiv preprint\narXiv:2409.05611, 2024.\n[20] S. P. Karimireddy, S. Kale, M. Mohri, S. Reddi, S. Stich, and A. T.\nSuresh, “Scaffold: Stochastic controlled averaging for federated learn-\ning,” in International conference on machine learning.\nPMLR, 2020,\npp. 5132–5143.\n[21] Y. Zhao, M. Li, L. Lai, N. Suda, D. Civin, and V. Chandra, “Federated\nlearning with non-iid data,” arXiv preprint arXiv:1806.00582, 2018.\n[22] T. Li, A. K. Sahu, M. Zaheer, M. Sanjabi, A. Talwalkar, and V. Smith,\n“Federated optimization in heterogeneous networks,” Proceedings of\nMachine learning and systems, vol. 2, pp. 429–450, 2020.\n[23] X. Li, M. Jiang, X. Zhang, M. Kamp, and Q. Dou, “Fedbn: Feder-\nated learning on non-iid features via local batch normalization,” arXiv\npreprint arXiv:2102.07623, 2021.\n[24] M. Jiang, Z. Wang, and Q. Dou, “Harmofl: Harmonizing local and\nglobal drifts in federated learning on heterogeneous medical images,” in\nProceedings of the AAAI Conference on Artificial Intelligence, vol. 36,\nno. 1, 2022, pp. 1087–1095.\n[25] X.-C. Li, Y.-C. Xu, S. Song, B. Li, Y. Li, Y. Shao, and D.-C. Zhan,\n“Federated learning with position-aware neurons,” in Proceedings of the\nIEEE/CVF Conference on Computer Vision and Pattern Recognition,\n2022, pp. 10 082–10 091.\n\n\nJOURNAL OF LATEX CLASS FILES, VOL. 14, NO. 8, AUGUST 2021\n14\n[26] T. Zhou, Y. Yuan, B. Wang, and E. Konukoglu, “Federated feature\naugmentation and alignment,” IEEE Transactions on Pattern Analysis\nand Machine Intelligence, 2024.\n[27] Y. Dai, Z. Chen, J. Li, S. Heinecke, L. Sun, and R. Xu, “Tackling\ndata heterogeneity in federated learning with class prototypes,” in\nProceedings of the AAAI Conference on Artificial Intelligence, vol. 37,\nno. 6, 2023, pp. 7314–7322.\n[28] A. Fallah, A. Mokhtari, and A. Ozdaglar, “Personalized federated\nlearning with theoretical guarantees: A model-agnostic meta-learning\napproach,” Advances in neural information processing systems, vol. 33,\npp. 3557–3568, 2020.\n[29] J. Luo and S. Wu, “Adapt to adaptation: Learning personalization for\ncross-silo federated learning,” in IJCAI: proceedings of the conference,\nvol. 2022.\nNIH Public Access, 2022, p. 2166.\n[30] W. Huang, M. Ye, Z. Shi, H. Li, and B. Du, “Rethinking federated\nlearning with domain shift: A prototype view,” in 2023 IEEE/CVF Con-\nference on Computer Vision and Pattern Recognition (CVPR).\nIEEE,\n2023, pp. 16 312–16 322.\n[31] D. C. Nguyen, M. Ding, P. N. Pathirana, A. Seneviratne, and A. Y.\nZomaya, “Federated learning for covid-19 detection with generative\nadversarial networks in edge cloud computing,” IEEE Internet of Things\nJournal, vol. 9, no. 12, pp. 10 257–10 271, 2021.\n[32] Z. Li, Y. Sun, J. Shao, Y. Mao, J. H. Wang, and J. Zhang, “Feature\nmatching data synthesis for non-iid federated learning,” IEEE Transac-\ntions on Mobile Computing, 2024.\n[33] Z. Li, Z. Lin, J. Shao, Y. Mao, and J. Zhang, “Fedcir: Client-invariant\nrepresentation learning for federated non-iid features,” IEEE Transac-\ntions on Mobile Computing, 2024.\n[34] Y. Tan, G. Long, L. Liu, T. Zhou, Q. Lu, J. Jiang, and C. Zhang,\n“Fedproto: Federated prototype learning across heterogeneous clients,”\nin Proceedings of the AAAI Conference on Artificial Intelligence, vol. 36,\nno. 8, 2022, pp. 8432–8440.\n[35] J. Zhang, Y. Hua, J. Cao, H. Wang, T. Song, Z. Xue, R. Ma, and H. Guan,\n“Eliminating domain bias for federated learning in representation space,”\nAdvances in Neural Information Processing Systems, vol. 36, 2024.\n[36] Z. You, L. Cui, Y. Shen, K. Yang, X. Lu, Y. Zheng, and X. Le, “A\nunified model for multi-class anomaly detection,” Advances in Neural\nInformation Processing Systems, vol. 35, pp. 4571–4584, 2022.\n[37] O. R. A. Almanifi, C.-O. Chow, M.-L. Tham, J. H. Chuah, and\nJ. Kanesan, “Communication and computation efficiency in federated\nlearning: A survey,” Internet of Things, vol. 22, p. 100742, 2023.\n[38] T. Li, A. K. Sahu, A. Talwalkar, and V. Smith, “Federated learning:\nChallenges, methods, and future directions,” IEEE signal processing\nmagazine, vol. 37, no. 3, pp. 50–60, 2020.\n[39] T. Li, A. K. Sahu, M. Zaheer, M. Sanjabi, A. Talwalkar, and V. Smith,\n“Federated optimization in heterogeneous networks,” Proceedings of\nMachine learning and systems, vol. 2, pp. 429–450, 2020.\n[40] Z. Yang, W. Bao, D. Yuan, N. H. Tran, and A. Y. Zomaya, “Federated\nlearning with nesterov accelerated gradient,” IEEE Transactions on\nParallel and Distributed Systems, vol. 33, no. 12, pp. 4863–4873, 2022.\n[41] D. Rothchild, A. Panda, E. Ullah, N. Ivkin, I. Stoica, V. Braverman,\nJ. Gonzalez, and R. Arora, “Fetchsgd: Communication-efficient feder-\nated learning with sketching,” in International Conference on Machine\nLearning.\nPMLR, 2020, pp. 8253–8265.\n[42] N. Shlezinger, M. Chen, Y. C. Eldar, H. V. Poor, and S. Cui, “Uveqfed:\nUniversal vector quantization for federated learning,” IEEE Transactions\non Signal Processing, vol. 69, pp. 500–514, 2020.\n[43] J. Li, C. Li, J. Fan, and T. Huang, “Online distributed stochastic gradient\nalgorithm for non-convex optimization with compressed communica-\ntion,” IEEE Transactions on Automatic Control, 2023.\n[44] J. Xu and H. Wang, “Client selection and bandwidth allocation in\nwireless federated learning networks: A long-term perspective,” IEEE\nTransactions on Wireless Communications, vol. 20, no. 2, pp. 1188–\n1200, 2020.\n[45] P. Bergmann, S. L¨owe, M. Fauser, D. Sattlegger, and C. Steger, “Improv-\ning unsupervised defect segmentation by applying structural similarity\nto autoencoders,” arXiv preprint arXiv:1807.02011, 2018.\n[46] V. Zavrtanik, M. Kristan, and D. Skoˇcaj, “Draem-a discriminatively\ntrained reconstruction embedding for surface anomaly detection,” in\nProceedings of the IEEE/CVF international conference on computer\nvision, 2021, pp. 8330–8339.\n[47] J. Jiang, J. Zhu, M. Bilal, Y. Cui, N. Kumar, R. Dou, F. Su, and X. Xu,\n“Masked swin transformer unet for industrial anomaly detection,” IEEE\nTransactions on Industrial Informatics, vol. 19, no. 2, pp. 2200–2209,\n2022.\n[48] D. Wu, S. Fan, X. Zhou, L. Yu, Y. Deng, J. Zou, and B. Lin, “Unsu-\npervised anomaly detection via masked diffusion posterior sampling,”\narXiv preprint arXiv:2404.17900, 2024.\n[49] N. Cohen and Y. Hoshen, “Sub-image anomaly detection with deep\npyramid correspondences,” arXiv preprint arXiv:2005.02357, 2020.\n[50] T. Defard, A. Setkov, A. Loesch, and R. Audigier, “Padim: a patch dis-\ntribution modeling framework for anomaly detection and localization,”\nin International Conference on Pattern Recognition.\nSpringer, 2021,\npp. 475–489.\n[51] K. Roth, L. Pemula, J. Zepeda, B. Sch¨olkopf, T. Brox, and P. Gehler,\n“Towards total recall in industrial anomaly detection,” in Proceedings of\nthe IEEE/CVF conference on computer vision and pattern recognition,\n2022, pp. 14 318–14 328.\n[52] J. Bae, J.-H. Lee, and S. Kim, “Pni: Industrial anomaly detection\nusing position and neighborhood information,” in Proceedings of the\nIEEE/CVF International Conference on Computer Vision, 2023, pp.\n6373–6383.\n[53] H. Kim, Y. Kwak, M. Jung, J. Shin, Y. Kim, and C. Kim, “Protofl: Unsu-\npervised federated learning via prototypical distillation,” in Proceedings\nof the IEEE/CVF International Conference on Computer Vision, 2023,\npp. 6470–6479.\n[54] B. McMahan, E. Moore, D. Ramage, S. Hampson, and B. A. y Arcas,\n“Communication-efficient learning of deep networks from decentralized\ndata,” in Artificial intelligence and statistics.\nPMLR, 2017, pp. 1273–\n1282.\n[55] Q. Li, Z. Wen, Z. Wu, S. Hu, N. Wang, Y. Li, X. Liu, and B. He, “A\nsurvey on federated learning systems: Vision, hype and reality for data\nprivacy and protection,” IEEE Transactions on Knowledge and Data\nEngineering, vol. 35, no. 4, pp. 3347–3366, 2021.\n[56] L. Wang, M. Wang, D. Zhang, and H. Fu, “Model barrier: A compact un-\ntransferable isolation domain for model intellectual property protection,”\nin Proceedings of the IEEE/CVF Conference on Computer Vision and\nPattern Recognition, 2023, pp. 20 475–20 484.\n[57] J. Zhang, Y. Liu, Y. Hua, and J. Cao, “Fedtgp: Trainable global\nprototypes with adaptive-margin-enhanced contrastive learning for data\nand model heterogeneity in federated learning,” in Proceedings of the\nAAAI Conference on Artificial Intelligence, vol. 38, no. 15, 2024, pp.\n16 768–16 776.\n[58] S. Lee, S. Lee, and B. C. Song, “Cfa: Coupled-hypersphere-based fea-\nture adaptation for target-oriented anomaly localization,” IEEE Access,\nvol. 10, pp. 78 446–78 454, 2022.\n[59] K. He, X. Zhang, S. Ren, and J. Sun, “Deep residual learning for image\nrecognition,” in Proceedings of the IEEE conference on computer vision\nand pattern recognition, 2016, pp. 770–778.\n[60] J. C. Lee, T. Kim, E. Park, S. S. Woo, and J. H. Ko, “Continuous\nmemory representation for anomaly detection,” in European Conference\non Computer Vision.\nSpringer, 2025, pp. 438–454.\n[61] R. Liu, J. Lehman, P. Molino, F. Petroski Such, E. Frank, A. Sergeev,\nand J. Yosinski, “An intriguing failing of convolutional neural networks\nand the coordconv solution,” Advances in neural information processing\nsystems, vol. 31, 2018.\n[62] X. Glorot and Y. Bengio, “Understanding the difficulty of training\ndeep feedforward neural networks,” in Proceedings of the thirteenth\ninternational conference on artificial intelligence and statistics.\nJMLR\nWorkshop and Conference Proceedings, 2010, pp. 249–256.\n[63] Y. Tan, G. Long, J. Ma, L. Liu, T. Zhou, and J. Jiang, “Federated learning\nfrom pre-trained models: A contrastive learning approach,” Advances in\nneural information processing systems, vol. 35, pp. 19 332–19 344, 2022.\n[64] D. P. Kingma, “Adam: A method for stochastic optimization,” arXiv\npreprint arXiv:1412.6980, 2014.\n[65] J. Li, F. Li, L. Zhu, H. Cui, and J. Li, “Prototype-guided knowledge\ntransfer for federated unsupervised cross-modal hashing,” in Proceedings\nof the 31st ACM International Conference on Multimedia, 2023, pp.\n1013–1022.\n[66] K. Bonawitz, V. Ivanov, B. Kreuter, A. Marcedone, H. B. McMahan,\nS. Patel, D. Ramage, A. Segal, and K. Seth, “Practical secure aggregation\nfor privacy-preserving machine learning,” in proceedings of the 2017\nACM SIGSAC Conference on Computer and Communications Security,\n2017, pp. 1175–1191.\n[67] S. Zhang, W. Yuan, and H. Yin, “Comprehensive privacy analysis on\nfederated recommender system against attribute inference attacks,” IEEE\nTransactions on Knowledge and Data Engineering, 2023.\n[68] U. Baid, S. Ghodasara, S. Mohan, M. Bilello, E. Calabrese, E. Colak,\nK. Farahani, J. Kalpathy-Cramer, F. C. Kitamura, S. Pati et al., “The\nrsna-asnr-miccai brats 2021 benchmark on brain tumor segmentation and\nradiogenomic classification,” arXiv preprint arXiv:2107.02314, 2021.\n\n\nJOURNAL OF LATEX CLASS FILES, VOL. 14, NO. 8, AUGUST 2021\n15\n[69] M. Salehi, N. Sadjadi, S. Baselizadeh, M. H. Rohban, and H. R.\nRabiee, “Multiresolution knowledge distillation for anomaly detection,”\nin Proceedings of the IEEE/CVF conference on computer vision and\npattern recognition, 2021, pp. 14 902–14 912.\n[70] D. S. Kermany, M. Goldbaum, W. Cai, C. C. Valentim, H. Liang, S. L.\nBaxter, A. McKeown, G. Yang, X. Wu, F. Yan et al., “Identifying\nmedical diagnoses and treatable diseases by image-based deep learning,”\ncell, vol. 172, no. 5, pp. 1122–1131, 2018.\n[71] X. Wang, Y. Peng, L. Lu, Z. Lu, M. Bagheri, and R. M. Summers,\n“Chestx-ray8: Hospital-scale chest x-ray database and benchmarks on\nweakly-supervised classification and localization of common thorax\ndiseases,” in Proceedings of the IEEE conference on computer vision\nand pattern recognition, 2017, pp. 2097–2106.\n[72] H. Q. Nguyen, K. Lam, L. T. Le, H. H. Pham, D. Q. Tran, D. B. Nguyen,\nD. D. Le, C. M. Pham, H. T. Tong, D. H. Dinh et al., “Vindr-cxr: An\nopen dataset of chest x-rays with radiologist’s annotations,” Scientific\nData, vol. 9, no. 1, p. 429, 2022.\n[73] Y. Zou, J. Jeong, L. Pemula, D. Zhang, and O. Dabeer, “Spot-the-\ndifference self-supervised pre-training for anomaly detection and seg-\nmentation,” in European Conference on Computer Vision.\nSpringer,\n2022, pp. 392–408.\n[74] H. Bai, S. Mou, T. Likhomanenko, R. G. Cinbis, O. Tuzel, P. Huang,\nJ. Shan, J. Shi, and M. Cao, “Vision datasets: A benchmark for vision-\nbased industrial inspection,” arXiv preprint arXiv:2306.07890, 2023.\n[75] P. Bergmann, M. Fauser, D. Sattlegger, and C. Steger, “Mvtec ad–a\ncomprehensive real-world dataset for unsupervised anomaly detection,”\nin Proceedings of the IEEE/CVF conference on computer vision and\npattern recognition, 2019, pp. 9592–9600.\n[76] S. Jezek, M. Jonak, R. Burget, P. Dvorak, and M. Skotak, “Deep\nlearning-based defect detection of metal parts: evaluating current meth-\nods in complex conditions,” in 2021 13th International congress on\nultra modern telecommunications and control systems and workshops\n(ICUMT).\nIEEE, 2021, pp. 66–71.\n[77] X.-C. Li, D.-C. Zhan, Y. Shao, B. Li, and S. Song, “Fedphp: Federated\npersonalization with inherited private models,” in Joint European Con-\nference on Machine Learning and Knowledge Discovery in Databases.\nSpringer, 2021, pp. 587–602.\n\n\n",
  "metadata": {
    "source_file": "dataset/pdfs/arxiv_2502.21012v1.pdf",
    "total_pages": 15,
    "title": "FedDyMem: Efficient Federated Learning with Dynamic Memory and Memory-Reduce for Unsupervised Image Anomaly Detection",
    "authors": [
      "Silin Chen",
      "Kangjian Di",
      "Yichu Xu",
      "Han-Jia Ye",
      "Wenhan Luo",
      "Ningmu Zou"
    ],
    "abstract": "Unsupervised image anomaly detection (UAD) has become a critical process in\nindustrial and medical applications, but it faces growing challenges due to\nincreasing concerns over data privacy. The limited class diversity inherent to\none-class classification tasks, combined with distribution biases caused by\nvariations in products across and within clients, poses significant challenges\nfor preserving data privacy with federated UAD. Thus, this article proposes an\nefficient federated learning method with dynamic memory and memory-reduce for\nunsupervised image anomaly detection, called FedDyMem. Considering all client\ndata belongs to a single class (i.e., normal sample) in UAD and the\ndistribution of intra-class features demonstrates significant skewness,\nFedDyMem facilitates knowledge sharing between the client and server through\nthe client's dynamic memory bank instead of model parameters. In the local\nclients, a memory generator and a metric loss are employed to improve the\nconsistency of the feature distribution for normal samples, leveraging the\nlocal model to update the memory bank dynamically. For efficient communication,\na memory-reduce method based on weighted averages is proposed to significantly\ndecrease the scale of memory banks. On the server, global memory is constructed\nand distributed to individual clients through k-means aggregation. Experiments\nconducted on six industrial and medical datasets, comprising a mixture of six\nproducts or health screening types derived from eleven public datasets,\ndemonstrate the effectiveness of FedDyMem.",
    "published_date": "2025-02-28",
    "source": "arxiv"
  }
}