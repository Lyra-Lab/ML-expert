{
  "id": "arxiv_2502.21105v1",
  "text": "Max van Haren et al, Parameter-Dependent Feedforward Control: A Kernel-Based Learning Approach,\nIn preparation for journal submission, uploaded March 3, 2025\nParameter-Varying Feedforward Control: A Kernel-Based Learning Approach⋆,⋆⋆\nMax van Harena,∗, Lennart Blankenb,a, Tom Oomena,c\naDepartment of Mechanical Engineering, Control Systems Technology Section, Eindhoven University of Technology, Groene Loper 5, Eindhoven, 5612 AE, The\nNetherlands.\nbSioux Technologies, Esp 130, Eindhoven, 5633 AA, The Netherlands.\ncDelft Center for Systems and Control, Delft University of Technology, Mekelweg 2, Delft, 2628 CN, The Netherlands.\nAbstract\nThe increasing demands for high accuracy in mechatronic systems necessitate the incorporation of parameter variations in feed-\nforward control. The aim of this paperis to develop a data-driven approach for direct learning of parameter-varying feedforward\ncontrol to increase tracking performance. The developed approach is based on kernel-regularized function estimation in conjunc-\ntion with iterative learning to directly learn parameter-varying feedforward control from data. This approach enables high tracking\nperformance for feedforward control of linear parameter-varying dynamics, providing flexibility to varying reference tasks. The\ndeveloped framework is validated on a benchmark industrial experimental setup featuring a belt-driven carriage.\nKeywords: Feedforward control, Iterative learning control, Kernel regularization, Mechatronic systems, Motion control, Linear\nparameter-varying\n1. Introduction\nFeedforward control is capable of suppressing known dis-\nturbances in motion control, specifically a reference trajectory.\nFeedforward control is widely applied in numerous applica-\ntions, including nanopositioning [1] and robotics [2]. The ref-\nerence tracking performance of feedforward control is directly\ndetermined by the accuracy of estimating the system’s inverse\ndynamics [3].\nAs systems are designed progressively more\ncomplex, accurately describing their inverse dynamics becomes\nincreasingly challenging.\nIncreasing complex dynamics in mechatronic systems can ef-\nfectively be modeled using Linear Parameter-Varying (LPV)\ndescriptions [4, 5].\nForward LPV models can be identified\nthrough various methods [6, 7, 8, 9]. The tracking performance\nof inversion-based LPV feedforward control is then directly de-\ntermined by the quality of the identified forward LPV model\n[10, 11, 12]. The two-step approach of forward LPV identifica-\ntion and inversion often degrades performance due to the intri-\ncate link between tracking performance and inverse quality, and\nproperties such as stability are not guaranteed since inversion is\ntypically done through optimization methods.\nThe limitations of inversion-based feedforward control for\nLPV systems have led to several approaches that directly opti-\n⋆This work is part of the research programme VIDI with project number\n15698, which is (partly) financed by the Netherlands Organisation for Scientific\nResearch (NWO).\n⋆⋆This research has received funding from the ECSEL Joint Undertaking un-\nder grant agreement 101007311 (IMOCO4.E). The Joint Undertaking receives\nsupport from the European Union Horizon 2020 research and innovation pro-\ngramme.\n∗Corresponding author.\nEmail address: m.j.v.haren@tue.nl (Max van Haren)\nmize the feedforward controller based on the tracking perfor-\nmance. In [13], LPV feedforward controllers are directly deter-\nmined based on input-output data, while [14] optimizes an LPV\nfeedforward controller using Iterative Learning Control (ILC)\n[15]. Both [13] and [14] restrict the dependence on the schedul-\ning sequence to a generally unknown predefined structure, re-\nsulting in limited tracking performance. Furthermore, [16] em-\nploys a neural network to directly identify an LPV feedforward\ncontroller. However, its practical applicability remains limited\ndue to the added complexity of estimating the zero dynamics\nof LPV systems and since the neural network is not directly\ncapable of utilizing physical insights, which can improve esti-\nmation quality. Overall, the applicability of current approaches\nfor direct optimization of LPV feedforward controllers based on\ntracking performance is limited, as the structure of the depen-\ndency on the scheduling sequence must be known in advance,\nand no physical insights can be utilized.\nAlthough several techniques have been developed for LPV\nfeedforward control, there is currently no method that directly\noptimizes the tracking performance without constraining the\ndependence on the scheduling sequence, while also allow-\ning for the incorporation of physical insights. In this paper,\nfeedforward parameter functions are identified through kernel-\nregularized function estimation [17], and the estimates are re-\nfined by iteratively minimizing the tracking error. The main ad-\nvantage of kernel-regularized function estimation is that it does\nnot restrict the estimated function to a specific structure, but is\nsearched over a possibly infinite-dimensional functional space\nthat admits a finite-dimensional representation [17]. Further-\nmore, physical insights of the system can be utilized through\nhigh-level properties of the estimated function, such as peri-\nodicity. Additionally, the iterative nature enhances estimation\nPreprint submitted to Elsevier\nMarch 3, 2025\narXiv:2502.21105v1  [eess.SY]  28 Feb 2025\n\n\nquality, improving tracking performance. The following contri-\nbutions are distinguished.\nC1) Iteratively learning the feedforward parameter functions,\nwhich enhances estimation quality and improves tracking\nperformance.\nC2) Identifying feedforward parameter functions through\nkernel-regularized estimation, allowing any dependence\non the scheduling sequence to be modeled.\nC3) Experimental characterization and validation of the devel-\noped framework for a low-cost belt-driven carriage, which\nexhibits position-dependent behavior.\nThis work extends earlier research presented in [18, 19] by gen-\neralizing these studies to iteratively learn continuous parameter\nvariations and apply a generic parameterization in the feedfor-\nward controller, including experimental validation.\nNotation. The discrete-time index is denoted by k ∈Z[0,N−1].\nThe amount of samples in a measurement period is equal to N.\nScalars and row and column vectors are denoted by lowercase\nletters, e.g., x. Matrices are denoted by capitals, e.g., X. Func-\ntions and time-dependent signals are denoted explicitly, e.g.,\nx(k). Time-dependent signals are vectorized as\nx =\nh\nx⊤(0)\nx⊤(1)\n. . .\nx⊤(N −1)\ni⊤.\n(1)\nSystems are denoted calligraphically, e.g., H. LPV systems are\ndescribed using the discrete-time state-space\nH (ρ) :\n\nx(k + 1)\n= A(ρ(k))x(k) + B(ρ(k))u(k),\ny(k)\n= C(ρ(k))x(k) + D(ρ(k))u(k),\n(2)\nwith scheduling sequence ρ(k). The response of system H(ρ)\nto input u(k) is denoted with y(k) = H(ρ)u(k). Let x(k) = 0\nfor k = 0, and u(k) = 0 for k < 0 and k ≥N, to obtain the\nfinite-time LPV convolution\n\ny(0)\ny(1)\n...\ny(N−1)\n\n|   {z   }\ny\n=\n\nD (ρ (0))\n0\n· · ·\n0\nC (ρ (1)) B (ρ (0))\nD (ρ (1)) · · ·\n0\n...\n...\n...\n...\nC (ρ (N−1))QN−2\nk=1 A (ρ (k))B (ρ (0))\n· · ·\n· · · D (ρ (N−1))\n\n|                                                                         {z                                                                         }\nH\n\nu(0)\nu(1)\n...\nu(N−1)\n\n|    {z    }\nu\n, (3)\nwith LPV convolution matrix H. Linear Time-Invariant (LTI)\nsystems are described using the forward shift operator qu(k) =\nu(k + 1).\n2. Problem Formulation\nIn this section, a motivating application and the problem set-\nting are shown for LPV feedforward control. Finally, the prob-\nlem addressed in this paperis defined.\n2.1. Motivating Application\nThe problem addressed in this paperis directly motivated by\nthe belt-driven carriage in Figure 1, which represents a trans-\nmission used regularly for mechatronic systems. Specifically,\nu\ny\nRotary encoder\nBLAC motor\nLinear guide\nCarriage\nIdler pulley\nPulley\nLinear encoder\nTiming belt\n(a) Photograph of experimental setup.\ny\nu\nL\n2R\n(b) Sketch of experimental setup.\nFigure 1: Experimental setup considered, where the position of the belt-driven\ncarriage y is to be controlled using the input to the motor u.\nthe belt-driven carriage in Figure 1 exhibits position-dependent\ndynamics, which are commonly observed in mechatronic sys-\ntems and can be accurately modeled using LPV system de-\nscriptions.\nThe objective of the setup is to accurately posi-\ntion the carriage in the y-direction by using the BrushLess AC\n(BLAC) motor. The BLAC motor is connected to the carriage\nvia a toothed pulley and a timing belt. The belt-driven car-\nriage suffers from position-dependent dynamics due to several\neffects, including pulley out-of-roundness, pulley-teeth inter-\nactions, motor cogging, misalignment of the linear guide, and\nposition-dependent drivetrain stiffness [20, Section 4.2], which\nis shown in Example 1.\nExample 1 By modeling the timing belt in Figure 1 as an elas-\ntic element under pretension with Young’s modulus E and cross-\nsectional area A, the perceived stiffness at the driven pulley is\nk(ρ) =\nEA\n1\n2L + ρR\n+\nEA\n1 1\n2L −ρR\n,\n(4)\nfor scheduling ρ being the angular rotation of the driven pul-\nley, resulting in quasi-LPV behavior. The system is modeled as\na mass-spring system with continuous-time inverse dynamics\n[19]\nu(t) =\n\u0012\nmR + J\nR\n\u0013 d2y (t)\ndt2\n+ mJ\nR\nd2\ndt2\n \n1\nk (ρ (t))\nd2y (t)\ndt2\n!\n=\nX\ni∈{2,3,4}\ndiy(t)\ndti θi (ρ(t)) ,\n(5)\nconsisting of derivatives of the desired output diy(t)\ndti\nand LPV\nparameter functions θi (ρ(t)).\nLPV descriptions of complex mechatronic systems, including\nbelt-driven carriages such as the system in Figure 1, directly\nmotivate the development of parameter-varying feedforward\ncontrol.\n2\n\n\nG\nC\n-\nr\ne\nu\nf\nρ\ny\nν\nFigure 2: Control structure considered.\n2.2. Problem Setting\nThe control structure is seen in Figure 2. The considered\nclass of LPV systems G is described using the convolution in\n(3). The system is operating in feedback with LTI controller C,\nas seen in Figure 2. The tracking error, assuming zero initial\nstate and error, is given by the interconnection of the system G\nand controller C by\ne(k) = S (ρ) (r(k) −ν(k)) −J (ρ) f(k),\n(6)\nwith LPV sensitivity S(ρ) and process sensitivity J(ρ). LTI\nfeedforward is not capable of compensating for the LPV dy-\nnamics in (6), resulting in residual error. Motivated by the in-\nverse dynamics of LPV systems, for example (5) in Example 1,\nthe goal in this paperis to decrease the tracking error using the\nparameter-varying feedforward signal\nf(k) = ψ (r (k)) θ(ρ(k)),\n(7)\nwith basis functions ψ (r (k)) ∈R1×nθ and feedforward param-\neter functions θ(ρ(k)) ∈Rnθ×1. The feedforward parameteriza-\ntion (7) is flexible to task variations due to the dependency on\nr(k) in the basis function ψ(r(k)).\n2.3. Problem Definition\nThe problem considered in this paperis as follows. Given a\nreference signal r(k), corresponding choice of basis functions\nψ (r (k)) ∈R1×nθ, a model of the system b\nG, and the measured\nscheduling sequence ρ(k), determine the nθ feedforward param-\neter functions θ(ρ(k)) ∈Rnθ×1, such that the tracking error (6) is\nminimized using the feedforward parameterization (7).\n3. Learning Feedforward Parameter Functions\nIn this section, feedforward parameter functions are iter-\natively learned through kernel-regularized estimation.\nThe\nnon-parametric nature of kernel-regularized estimation enables\nmodeling any dependence on the scheduling sequence, and it-\nerative learning improves estimation quality, both contributing\nto C1 and C2. Furthermore, the design of kernels and the de-\nveloped procedure are presented.\n3.1. Iterative Learning of Feedforward Parameter Functions\nThe key idea is to iteratively learn the feedforward parameter\nfunctions θ(ρ(k)) in (7) such that the tracking performance is\nminimized. Hence, the feedforward parameters are iteratively\nupdated over iterations or trials j as\nθ j+1(ρ∗) = θ j(ρ∗) + θ∆\nj (ρ∗),\n(8)\nwith some arbitrary scheduling value ρ∗. The tracking error is\ndirectly reduced by learning the function θ∆\nj (ρ∗) iteratively by\nminimizing the predicted tracking error in the next trial. To\nachieve this, the error (6) in the next trial ˆej+1 for feedforward\nsignal (7) is predicted by assuming a trial-invariant scheduling\nsequence ρj+1 = ρj, reference signal r j+1 = r j and noise ν j+1 =\nν j, i.e.,\nˆej+1(k) = S\n\u0010\nρj\n\u0011 \u0010\nrj(k) −ν j(k)\n\u0011\n−b\nJ\n\u0010\nρj\n\u0011\nψ\n\u0010\nr j (k)\n\u0011\nθ j+1\n\u0010\nρj (k)\n\u0011\n,\n(9)\nwhere b\nJ\n\u0010\nρj\n\u0011\nis a model of the true system J\n\u0010\nρj\n\u0011\n, determined\nusing the measured scheduling sequence ρj. Predicting this er-\nror based on past data is enabled by substituting ej from (6),\nresulting in\nˆe j+1(k) = ej(k) −b\nJ\n\u0010\nρj\n\u0011\nψ\n\u0010\nrj (k)\n\u0011 \u0010\nθ j+1\n\u0010\nρj (k)\n\u0011\n−θ j\n\u0010\nρj (k)\n\u0011\u0011\n= ej(k) −b\nJ\n\u0010\nρj\n\u0011\nψ\n\u0010\nrj (k)\n\u0011\nθ∆\nj\n\u0010\nρj (k)\n\u0011\n.\n(10)\nThe iterative procedure is effective since it directly minimizes\nthe regularized least-squares tracking error, and uses next to the\nmodel of the process sensitivity the measured data, thus reduc-\ning the requirements on the modeling quality [21].\n3.2. Iterative Kernel-Regularized Learning of Feedforward Pa-\nrameter Functions\nUnlike traditional estimation methods that restrict the esti-\nmated function θ∆\nj (ρ∗) in (8) to a specific structure, the function\nθ∆\nj (ρ∗) is estimated in a possibly infinite-dimensional function\nspace H and can be evaluated at any arbitrary ρ∗∈R. Specif-\nically, the feedforward parameter functions are estimated by it-\neratively minimizing the predicted least-squares tracking error\n(10) with a regularization term J to prevent overfitting and ill-\nposedness, i.e.,\nmin\nθ∆\nj ∈H\nN−1\nX\nk=0\nˆe2\nj+1(k) + γJ\n\u0010\nθ∆\nj\n\u0011\n.\n(11)\nThe regularizer J can be chosen to penalize unwanted behav-\nior of the estimated functions θ∆\nj . For example, the energy of\nthe estimated functions θ∆\nj can be reduced by penalizing with\nJ(θ∆\nj ) =\nR \u0010\nθ∆\nj (ρ)\n\u0011⊤θ∆\nj (ρ) dρ.\nProperties of the estimated function are effectively enforced\nthrough designing H as a Hilbert space, and choosing the reg-\nularizer as the squared norm in this space,\nmin\nθ∆\nj ∈H\nN−1\nX\nk=0\nˆe2\nj+1(k) + γ∥θ∆\nj ∥2\nH ,\n(12)\nwith\nReproducing\nKernel\nHilbert\nSpace\n(RKHS)\nnorm\n∥θ∆\nj ∥2\nH =\nD\nθ∆\nj , θ∆\nj\nE\nH [17]. The RKHS H is associated with\na kernel function that is capable of reproducing every function\n3\n\n\nin the space, in this case the nθ × nθ kernel function matrix\nK (ρ∗, ρ) =\n\nk11 (ρ∗, ρ)\nk12 (ρ∗, ρ)\n· · ·\nk1nθ (ρ∗, ρ)\nk21 (ρ∗, ρ)\nk22 (ρ∗, ρ)\n· · ·\nk2nθ (ρ∗, ρ)\n...\n...\n...\n...\nknθ1 (ρ∗, ρ)\nknθ2 (ρ∗, ρ)\n· · ·\nknθnθ (ρ∗, ρ)\n\n, (13)\nwhere each kernel function kij describes the correlation be-\ntween feedforward parameters i and j. As a result, the kernel\nfunctions enable to enforce desired properties of the estimated\nfunction θ∆\nj (ρ∗), such as smoothness or periodicity.\nRemark 2 Cross-correlation between different feedforward pa-\nrameters, which is commonly observed for motion systems [19],\nis directly enabled by setting kij , 0 ∀i , j.\nSince the kernel-regularized estimates of the feedforward pa-\nrameter functions are estimated in the possibly infinite dimen-\nsional space H , the function estimates are not restricted to a\nspecific class of functions and are thus capable of modeling any\nfeedforward parameter function.\nAlthough the feedforward parameter functions are modeled\nin a possibly infinite dimensional space H , it admits a finite-\ndimensional solution through the representer theorem [17, (63)]\nθ∆\nj (ρ∗) =\nN−1\nX\nk=0\nK\n\u0010\nρ∗, ρj(k)\n\u0011\nψ⊤\u0010\nrj (k)\n\u0011 b\nJ\n\u0010\nρj\n\u0011\nˆc j(k),\n(14)\nwhere kernel function matrix K(ρ∗, ρj(k)) ∈Rnθ×nθ is de-\ntermined with (13).\nThe (modified) representers ˆc j\n=\nh\nˆc j(0)\nˆcj(1)\n· · ·\nˆc j(N −1)\ni⊤∈RN are given by [17, (64)\nand (70b)]\nˆc j =\n\u0010bJ jΨjKjΨ⊤\nj bJ⊤\nj + γIN\n\u0011−1 ej,\n(15)\nwith convolution matrix bJj ∈RN×N of LPV system b\nJ evalu-\nated at the measured scheduling sequence ρj using (3), and the\nkernel matrix Kj ∈RNnθ×Nnθ is evaluated by\nKj =\n\nK\n\u0010\nρj(0), ρj(0)\n\u0011\nK\n\u0010\nρj(0), ρj(1)\n\u0011\n· · ·\nK\n\u0010\nρj(0), ρj(N−1)\n\u0011\nK\n\u0010\nρj(1), ρj(0)\n\u0011\nK\n\u0010\nρj(1), ρj(1)\n\u0011\n· · ·\nK\n\u0010\nρj(1), ρj(N−1)\n\u0011\n...\n...\n...\n...\nK\n\u0010\nρj (N−1) , ρj (0)\n\u0011\nK\n\u0010\nρj (N−1) , ρj (1)\n\u0011\n· · · K\n\u0010\nρj (N−1) , ρj (N−1)\n\u0011\n\n.\n(16)\nNote that the feedforward parameters for the next trial in (14)\nare calculated based on the scheduling sequence measured in\nthe current trial. The basis function matrix Ψ j ∈RN×Nnθ is\nconstructed such that fj = Ψjθ j as\nΨj =\n\nψ\n\u0010\nrj (0)\n\u0011\n0\n· · ·\n0\n0\nψ\n\u0010\nr j (1)\n\u0011\n· · ·\n0\n...\n...\n...\n...\n0\n· · ·\n0\nψ\n\u0010\nr j (N −1)\n\u0011\n\n.\n(17)\nThe feedforward parameters for the next trial (8) are esti-\nmated by propagating the feedforward update using the repre-\nsenter theorem (14) over the trials, resulting in\nθ j+1 (ρ∗) =\nj\nX\ni=0\nN−1\nX\nk=0\nK (ρ∗, ρi(k)) ˆci(k).\n(18)\nKernel-regularized learning of LPV feedforward parameter\nfunctions in (18) estimates the functions without restricting the\ndependence on the scheduling sequence, while allowing for the\nincorporation of prior knowledge.\nRemark 3 For the special case where the scheduling sequence\nduring iterative learning is constant, i.e., ρj(k) = ρ(k) ∀j, the\nparameter update (18) simplifies to\nθ j+1 (ρ∗) = θ j (ρ∗) +\nN−1\nX\nk=0\nK (ρ∗, ρ(k)) ˆcj(k).\n(19)\nRemark 4 The convergence of learning feedforward parameter\nfunctions (18) is primarily influenced by\n1. the quality of model b\nJ;\n2. the choice of kernel functions in (13); and\n3. the regularization coefficient γ in (12) and (15).\nGenerally, the regularization parameter γ can be increased to\nensure convergence of the framework. Furthermore, ILC with\nbasis functions and its associated convergence properties [22]\nare recovered by K (ρ∗, ρ) = I and γ = 0.\n3.3. Design of Kernel Functions\nThe developed update law requires the design of kernel func-\ntions ki j (ρ∗, ρ) in matrix K (ρ∗, ρ) in (13). Many different kernel\nfunctions are possible, and the suitable choice depends on the\nproblem at hand. Three examples of high-level properties that\ncan be enforced on the feedforward parameters through the use\nof kernel functions are the following.\n1. Constant feedforward parameter functions are realized by\nthe constant kernel\nkc\ni j (ρ∗, ρ) = σ2,\n(20)\nwith hyperparameter σ2 determining the average distance\nof the function to its mean. The constant kernel recovers\nLTI ILC with basis functions [21], where Tikhonov regu-\nlarized estimates are used for the feedforward parameters.\n2. Smooth feedforward parameter functions are estimated us-\ning the squared-exponential kernel\nkS E\ni j (ρ∗, ρ) = σ2 exp\n \n−(ρ∗−ρ)2\n2ℓ2\n!\n,\n(21)\nwhere σ2 has the same function as for the kernel (20), and\nthe hyperparameter ℓdetermines the level of smoothness\nof the estimated function.\n4\n\n\n3. Periodic feedforward parameter functions are realized\nthrough the periodic kernel\nkper\nij (ρ∗, ρ) = σ2 exp\n \n−2 sin2 (π |ρ∗−ρ| /p)\nℓ2\n!\n,\n(22)\nwhere σ2 and ℓhave the same role as in the squared-\nexponential kernel (21), and the hyperparameter p forces\nthe feedforward parameter functions to be periodic with\nperiod p.\nIn addition, multiple kernels can be combined such that they\nhave the properties of various kernels, and can be trivially ex-\ntended for multidimensional inputs [23, 24].\nRemark 5 The LPV feedforward signal should in some cases\nbe dynamically dependent, meaning that it should be dependent\non derivatives or time-shifted values of ρ [16, 19]. The kernel\nfunctions can be straightforwardly extended by using these val-\nues as additional input to the kernel.\n3.4. Procedure\nThe developed procedure that iteratively learns feedforward\nparameter functions through kernel-regularized estimation is\nsummarized in Procedure 6.\nProcedure 6 (Iterative kernel-regularized learning of LPV\nfeedforward parameters)\nInputs: Model b\nJ, reference signal r j, choice of basis functions\nin ψ, which (measured) signals are the scheduling sequence ρj,\nkernel function matrix K(ρ∗\nj, ρj) from (13) and corresponding\nhyperparameters.\n1. Initialize θ0 (ρ∗), e.g., θ0 (ρ∗) = 0 ∀ρ∗.\n2. For j ∈Z[0,Ntrial−1]\n(a) Compute basis functions ψ(rj(k)) in (7) using the ref-\nerence rj(k), and construct basis function matrix Ψ j\nusing (17).\n(b) Compute fj(k) with (7).\n(c) Apply fj(k) and rj(k) to the system in Figure 2, and\nmeasure error ej(k) and scheduling sequence ρj(k).\n(d) Construct convolution matrix bJj using (3) with model\nb\nJ and measured scheduling sequence ρj(k).\n• If no LPV model is available, set b\nJ\n\u0010\nρj\n\u0011\nto an\nLTI approximate, i.e., b\nJ(q).\n(e) Determine kernel matrix K j based on measured\nscheduling sequence ρj using (16).\n(f) Calculate the representers ˆc j for trial j using (15).\n(g) Compute the feedforward parameters for the next\ntrial j + 1 based on the current measured schedul-\ning sequence ρj, meaning θj+1(ρj(k)), using (18).\n0\n0.2\n0.4\n0.6\n0.8\n1\n0\n0.1\n0.2\n0.3\nFigure 3: Reference r (\n), scaled reference velocity ˙r (\n), and scaled refer-\nence acceleration (\n) applied to the experimental setup.\n4. Experimental Setup Characterization\nIn this section, the experimental setup is introduced and char-\nacterized, leading to an appropriate parameter-varying feedfor-\nward parameterization, hence contributing to C3. Specifically,\nseveral preliminary experiments are performed to determine\nwhich feedforward structure and kernels will be used.\n4.1. Experimental Setup\nThe experimental setup considered is a 1 degree-of-freedom\nbelt-driven carriage, which is mounted on a linear guide, as\nshown in Section 2.1 and Figure 1.\nThe BLAC motor is\nequipped with a rotary encoder having a resolution of 8192\ncounts per revolution, in addition to a linear encoder on the lin-\near guide with a resolution of 100 nm. The timing belt has a\ntooth pitch of 2 mm, which is made of rubber with an added\ncarbon fiber core for additional stiffness. The pulleys have 15\nteeth per revolution, and hence, a circumference of 0.03 m. The\ndistance between the pulleys is L = 0.3 m. The goal is to track a\nthird-order scanning motion with the carriage using the input to\nthe motor u, consisting of a large constant velocity part, which\nis seen in Figure 3. The performance is evaluated during con-\nstant velocity, since this type of drivetrain is typically used in\nscanning applications such as printing systems.\nThe control scheme in Figure 2 is used, where the LTI feed-\nback controller is a discrete-time lead filter with an additional\nlow-pass filter described by the transfer function\nC(q) =\n2169q−1 −381q−2 −1747q−3\n1 −2.421q−1 + 1.961q−2 −0.5337q−3 .\n(23)\nThe settings during experimentation are shown in Table 1.\nTable 1: Experimental settings.\nVariable\nAbbrevation\nValue\nUnit\nSampling time\nTs\n2.5 · 10−4\ns\nNumber of samples\nN\n4630\n-\nReference stroke\n-\n0.171\nm\nMaximum velocity\n-\n0.2\nm/s\nMaximum acceleration\n-\n4\nm/s2\n5\n\n\n0\n0.2\n0.4\n0.6\n0.8\n1\n0\n0.25\n0.5\n0.75\n1\n1.25\n10-3\n0.5\n0.55\n0.6\n0.65\n0.7\n0.75\n8.5\n9\n9.5\n10\n10-4\nFigure 4: During constant velocity (\n), the experimental tracking error for 5\nrepetitions of the reference in Figure 3 with zero feedforward fj = 0 (\n) and\ntheir sample mean (\n) show highly repeatable position-dependent effects.\n4.2. Characterization of Position-Dependent Dynamics\nThe tracking error with zero feedforward f j = 0 for 5 repe-\ntitions of the reference in Figure 3 is shown in Figure 4. The\nfollowing is observed from the tracking error in Figure 4.\n• The tracking error is highly repeatable, and hence, an iter-\native approach is suitable.\n• The large offset in the tracking error indicates that both\nCoulomb and viscous friction feedforward might be nec-\nessary.\n• During acceleration, the error reaches its maximum, moti-\nvating the need for acceleration feedforward.\n• The tracking error has a period of 0.15 s during a constant\nvelocity of 0.2 m/s, resulting in a spatial period of 0.03 m,\nwhich is the circumference of the pulley.\nThe spatial periodic effect is further analyzed with a power\nspectrum of the tracking error during constant velocity as a\nfunction of the number of pulley revolutions in Figure 5. The\nspatial power spectrum shows that during constant velocity, the\nerror is dominated by the zero frequency, the fundamental fre-\nquency [1/rev], its second harmonic [2/rev] and marginally by\nits fourth harmonic [4/rev]. The zero frequency contribution\nis mainly caused by the lack of Coulomb friction feedforward,\nwhich is also seen from the constant offset of the tracking error\nin Figure 4. The fundamental frequency, and second and fourth\nharmonic are most likely caused due position-dependent effects\nintroduced by pulley out-of-roundness or motor cogging.\n5. Experimental Application\nIn this section, both LTI feedforward control and the devel-\noped LPV feedforward control methods are compared on the\nexperimental setup, further contributing to C3. Both the learn-\ning procedure and the tracking results are shown.\n0\n1\n2\n4\n6\n9\n15 16\n10-13\n10-12\n10-11\n10-10\n1\n2\n10-11\n10-10\n10-9\n10-9\nFigure 5: Power spectrum of the tracking error during constant velocity for 5\ntimes tracking the reference in Figure 3 with zero feedforward f j = 0 (\n) and\ntheir sample mean (\n) shows highly repetitive behavior in spatial domain.\n101\n102\n103\n-180\n-150\n-120\n-90\n-60\nFigure 6: The LTI model b\nG(q) (\n) is constructed to approximate the measured\nfrequency response function (\n) of the experimental belt-driven carriage.\n5.1. Experimental Learning Settings\nThe model of the process sensitivity b\nJ is determined by us-\ning a simplified LTI model of the system G in feedback with the\ncontroller C in (23). The simplified LTI model b\nG is determined\nby using the measured frequency response function in Figure 6.\nAs a result, the simplified LTI model b\nG consists of a mass with\na damper attached to the fixed world, and is discretized with a\nzero order hold, resulting in\nb\nG(q) =\n2.82q−1 + 2.798q−2\n1 −1.978q−1 + 0.9775q−2 · 10−8.\n(24)\nAfter interconnecting b\nG with the controller C from (23), the LTI\nmodel of the process sensitivity is\nb\nJ(q) =\n2.82q−1−4.029q−2−1.244q−3+ 3.982q−4−1.493q−5\n1−4.399q−1+7.727q−2−6.779q−3+ 2.972q−4−0.522q−5 ·10−8.\n(25)\nThe reference tracking task is constant during learning r j =\nr ∀j and the same as in Section 4.1, shown in Figure 3. The\nreference signal is used as scheduling sequence ρj = r ∀j, since\nthis is relatively close to the position of the carriage y, and it is\nknown in advance of the tracking experiment.\nThe observations in Section 4.2 motivate using viscous fric-\ntion, Coulomb friction, and acceleration feedforward in (7),\n6\n\n\nFigure 7: Surface plot of kernel function kper\n22 (ρ∗, ρ) evaluated at a scheduling\nsequence ρ∗, ρ ∈R[0.08,0.16] ( ), which enforces a smooth and periodic function\nhaving a period of p = 0.03 m.\nwhich is widely applied in feedforward control [25], i.e.,\nf j (k) = θa\nj (ρ (k)) ¨r (k) + θv\nj (ρ (k)) ˙r (k) + θc\nj (ρ (k)) sign (˙r (k)) ,\n(26)\nwith discrete-time derivatives ¨r(k) and ˙r(k). The corresponding\nbasis functions and feedforward parameters from (7) are\nψ (r (k)) =\n\u0014\u0012\nq−q−1\n2Ts\n\u00132\nr(k)\nq−q−1\n2Ts r(k)\nsign\n\u0012\nq−q−1\n2Ts r(k)\n\u0013\u0015\n,\nθ j (ρ (k)) =\nh\nθa\nj (ρ (k))\nθv\nj (ρ (k))\nθc\nj (ρ (k))\ni⊤,\n(27)\nwhere discrete-time derivatives ¨r(k) and ˙r(k) from (26) are com-\nputed using the central difference. The 3 × 3 kernel function\nmatrix (13) is defined such that the estimated feedforward pa-\nrameters θj (ρ (k)) do not correlate, and the acceleration and\nCoulomb friction feedforward parameter functions are enforced\nto be constant using the kernel (20), i.e.,\nK (ρ∗, ρ) =\n\nkc (ρ∗, ρ)\n0\n0\n0\nk22 (ρ∗, ρ)\n0\n0\n0\nkc (ρ∗, ρ)\n.\n(28)\nThe hyperparameters of the constant kernels for the accelera-\ntion and coulomb friction feedforward parameter functions are\nrespectively σ2 = 1 and σ2 = 3. The amount of trials is set to\n10 and the regularization coefficient γ from (12) to γ = 5·10−5.\nLTI feedforward control and the developed LPV feedforward\ncontrol are compared by using a constant or varying viscous\nfriction feedforward parameter function. Specifically, the com-\npared methods use the following kernel functions for the vis-\ncous friction feedforward parameter.\n• LTI feedforward: constant kernel from (20), k22 (ρ∗, ρ) =\nkc (ρ∗, ρ), with hyperparameter σ2 = 20.\n• LPV feedforward: periodic kernel from (22), k22 (ρ∗, ρ) =\nkper\n22 (ρ∗, ρ) , with hyperparameters σ2 = 20, ℓ= 1 m and\np = 3 · 10−2 m.\n0\n0.25\n5\n0.2\n10\n15\n10\n0.15\n9\n20\n8\n7\n6\n5\n0.1\n4\n3\n2\n1\n0.05\nFigure 8: Feedforward parameter function θv\nj(ρ(k)) over the trials estimated by\nthe developed LPV feedforward method ( ) and LTI feedforward method θv\nj\n(\n).\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n0\n2\n4\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n0\n0.4\n0.8\n1.2\nFigure 9: Constant feedforward parameters θc\nj and θa\nj estimated by LTI feedfor-\nward control (\n) and LPV feedforward control (\n).\nThe spatial periodic effect of the tracking error in Section 4.2\nmotivates to select k22 being periodic in the pulley circumfer-\nence. A surface plot of the kernel function kper\n22 is shown in\nFigure 7. LTI feedforward control recovers LTI ILC with basis\nfunctions [21], where Tikhonov regularization is used to esti-\nmate the feedforward parameters.\n5.2. Experimental Results\nThe learned viscous, Coulomb, and acceleration feedforward\nparameter functions are shown in Figure 8 and Figure 9.\nThe\nviscous friction feedforward parameter function clearly shows\nthe periodic behavior enforced by the periodic kernel.\nThe\nCoulomb friction and acceleration feedforward parameters do\nnot show any significant difference between the LTI and LPV\nfeedforward methods.\nThe feedforward signal in the final trial from (26) using the\n7\n\n\n0\n0.2\n0.4\n0.6\n0.8\n1\n0\n2\n4\n6\n8\n0.5\n0.6\n0.7\n0.8\n5.2\n5.4\n5.6\nFigure 10: The feedforward signal during the final trial f10 shows the periodic\neffect obtained by the LPV feedforward signal (\n) compared to the LTI feed-\nforward signal (\n).\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n10-4\n10-3\n8\n9\n10\n2\n3\n4\n10-5\nFigure 11: The RMS error during constant velocity converges faster and to\na lower value for the developed iterative kernel-regularized estimates of LPV\nparameters (\n) compared to the LTI feedforward parameters (\n).\nfeedforward parameters from Figure 8 and Figure 9 for the ref-\nerence in Figure 3 is shown in Figure 10.\nThe reference tracking performance is illustrated through the\nRoot-Mean-Squared (RMS) tracking errors in Figure 11, the\ntracking error in the final trial in Figure 12, and the power spec-\ntrum of the final tracking error in Figure 13. The following\nobservations are made concerning the tracking performance.\n• The RMS error during constant velocity decreased from\n3.85·10−5 m for LTI feedforward parameters to 2.2·10−5 m,\nwhich is an improvement of 43 %, as shown in Figure 11.\n• Figure 12 demonstrates the improved tracking accuracy.\nIn addition, it shows a reduction of the maximum absolute\nerror during constant velocity in the final trial, with ∥e10∥∞\ndecreasing from 8.1 · 10−5 m to 6.1 · 10−5 m, which is an\nimprovement of 25 %.\n• The amplitude of the first and second harmonic are de-\ncreased by respectively a factor 6 and 2.3 in terms of their\npower, as shown in Figure 13.\nThe observations show that learning feedforward parameter\nfunctions using the developed iterative kernel-regularized esti-\nmator increases performance significantly for motion systems.\n0\n0.2\n0.4\n0.6\n0.8\n1\n-1\n-0.5\n0\n0.5\n1\n10-4\nFigure 12: During constant velocity (\n), the tracking error in the final\ntrial e10 is reduced by the developed iterative kernel-regularized estimates of\nLPV feedforward parameters (\n) compared to the LTI feedforward parame-\nters (\n).\n0\n1\n2\n4\n6\n9\n10-13\n10-12\n10-11\n10-10\n10-9\n1\n2\n4\n2\n4\n6\n8\n10\n10-10\n0\nFigure 13: The power of the tracking error for the final trial e10 is significantly\nlower for the developed LPV feedforward control (\n) compared to LTI feed-\nforward control (\n) and zero feedforward fj = 0 (\n).\n6. Conclusions\nThe results in this paperenable data-driven learning of\nparameter-variations in feedforward control, which can signifi-\ncantly improve the tracking performance of LPV systems. The\nkey idea is to iteratively learn LPV feedforward parameter func-\ntions using kernel-regularized estimation. Kernel-regularized\nfunction estimation is advantageous since it is non-parametric,\nmeaning no specific structure needs to be enforced on the de-\npendency on the scheduling sequence. The iterative learning\napproach directly optimizes the tracking error, which enhances\nthe estimation quality without the need for accurate system\nmodels. The developed framework is experimentally validated\non a belt-driven motion system, demonstrating effective com-\npensation of position-dependent drivetrain dynamics. The de-\nveloped method demonstrates significant potential for industrial\napplications, particularly in mechatronic systems, by enabling\nimproved tracking performance.\n8\n\n\nReferences\n[1] G. M. Clayton, S. Tien, K. K. Leang, Q. Zou, S. Devasia, A Review\nof Feedforward Control Approaches in Nanopositioning for High-Speed\nSPM, Journal of Dynamic Systems, Measurement, and Control 131 (6)\n(2009). https://doi.org/10.1115/1.4000158.\n[2] M. Grotjahn, B. Heimann, Model-based Feedforward Control in Indus-\ntrial Robotics, The International Journal of Robotics Research 21 (1)\n(2002) 45–60. https://doi.org/10.1177/027836402320556476.\n[3] S. Devasia, Should model-based inverse inputs be used as feedforward\nunder plant uncertainty?, IEEE Transactions on Automatic Control 47\n(11) (2002). https://doi.org/10.1109/TAC.2002.804478.\n[4] M. Groot Wassink, M. van de Wal, C. Scherer, O. Bosgra, LPV control\nfor a wafer stage: beyond the theoretical solution, Control Engineering\nPractice 13 (2) (2005). https://doi.org/10.1016/j.conengprac.\n2004.03.008.\n[5] C. Hoffmann, H. Werner, A survey of linear parameter-varying control\napplications validated by experiments or high-fidelity simulations, IEEE\nTransactions on Control Systems Technology 23 (2) (2015) 416–433.\nhttps://doi.org/10.1109/TCST.2014.2327584.\n[6] B. Bamieh, L. Giarré, Identification of linear parameter varying models,\nInternational Journal of Robust and Nonlinear Control 12 (9) (2002) 841–\n853. https://doi.org/10.1002/rnc.706.\n[7] F. Previdi, M. Lovera, Identification of non-linear parametrically vary-\ning models using separable least squares, International Journal of\nControl 77 (16) (2004) 1382–1392.\nhttps://doi.org/10.1080/\n0020717041233318863.\n[8] R.\nTóth,\nModeling\nand\nIdentification\nof\nLinear\nParameter-\nVarying Systems, Springer, 2010.\nhttps://doi.org/10.1007/\n978-3-642-13812-6.\n[9] Y. Zhao, B. Huang, H. Su, J. Chu, Prediction error method for identifica-\ntion of LPV models, Journal of Process Control 22 (1) (2012) 180–193.\nhttps://doi.org/10.1016/j.jprocont.2011.09.004.\n[10] J. Theis, H. Pfifer, A. Knoblach, F. Saupe, H. Werner, Linear Parameter-\nVarying Feedforward Control: A Missile Autopilot Design, in: Proceed-\nings of the AIAA Guidance, Navigation, and Control Conference, 2015.\nhttps://doi.org/10.2514/6.2015-2001.\n[11] R. de Rozario, T. Oomen, M. Steinbuch, Iterative Learning Control and\nfeedforward for LPV systems: Applied to a position-dependent motion\nsystem, in: Proceedings of the American Control Conference, 2017, pp.\n3518–3523. https://doi.org/10.23919/ACC.2017.7963491.\n[12] T. Bloemers, I. Proimadis, Y. Kasemsinsup, R. Toth, Parameter-\nDependent Feedforward Strategies for Motion Systems, in: Proceedings\nof the American Control Conference, 2018, pp. 2017–2022.\nhttps:\n//doi.org/10.23919/ACC.2018.8431116.\n[13] M. Butcher, A. Karimi, Data-driven tuning of linear parameter-varying\nprecompensators, International Journal of Adaptive Control and Signal\nProcessing 21 (2009). https://doi.org/10.1002/acs.1151.\n[14] R. de Rozario, R. Pelzer, S. Koekebakker, T. Oomen, Accommodating\nTrial-Varying Tasks in Iterative Learning Control for LPV Systems, Ap-\nplied to Printer Sheet Positioning, in: Proceedings of the American Con-\ntrol Conference, 2018, pp. 5213–5218. https://doi.org/10.23919/\nACC.2018.8430906.\n[15] D. A. Bristow, M. Tharayil, A. G. Alleyne, A survey of iterative learning\ncontrol, IEEE Control Systems 26 (3) (2006) 96–114. https://doi.\norg/10.1109/MCS.2006.1636313.\n[16] J. Kon, J. van de Wijdeven, D. Bruijnen, R. Tóth, M. Heertjes, T. Oomen,\nDirect Learning for Parameter-Varying Feedforward Control: A Neural-\nNetwork Approach, in: Proceedings of the 62nd IEEE Conference on\nDecision and Control, 2023, pp. 3720–3725. https://doi.org/10.\n1109/CDC49753.2023.10383877.\n[17] G. Pillonetto, F. Dinuzzo, T. Chen, G. De Nicolao, L. Ljung, Kernel meth-\nods in system identification, machine learning and function estimation:\nA survey, Automatica 50 (3) (2014) 657–682. https://doi.org/10.\n1016/j.automatica.2014.01.001.\n[18] M. van Haren, M. Poot, J. Portegies, T. Oomen, Position-Dependent Snap\nFeedforward: A Gaussian Process Framework, in: Proceedings of the\nAmerican Control Conference, 2022, pp. 4778–4783. https://doi.\norg/10.23919/ACC53348.2022.9867449.\n[19] M. van Haren, L. Blanken, T. Oomen, A kernel-based identification ap-\nproach to LPV feedforward: With application to motion systems, in: Pro-\nceedings of the 22nd World Congress of the IFAC, 2023, pp. 6063–6068.\nhttps://doi.org/10.1016/j.ifacol.2023.10.662.\n[20] R. Perneder, I. Osborne, Handbook Timing Belts, Springer, 2012. https:\n//doi.org/10.1007/978-3-642-17755-2.\n[21] S. H. van der Meulen, R. L. Tousain, O. H. Bosgra, Fixed Structure\nFeedforward Controller Design Exploiting Iterative Trials: Application\nto a Wafer Stage and a Desktop Printer, Journal of Dynamic Systems,\nMeasurement, and Control 130 (5) (2008) 051006/1–051006/16. https:\n//doi.org/10.1115/1.2957626.\n[22] J. van de Wijdeven, O. Bosgra, Using basis functions in iterative learning\ncontrol: analysis and design theory, International Journal of Control 83\n(4) (2010). https://doi.org/10.1080/00207170903334805.\n[23] C. E. Rasmussen, Gaussian Processes for Machine Learning, MIT Press,\n2006.\n[24] D. K. Duvenaud, Automatic Model Construction with Gaussian Pro-\ncesses, Ph.D. thesis, University of Cambridge (2014).\n[25] M. Steinbuch, R. Merry, M. Boerlage, M. Ronde, M. van de Molen-\ngraft, Advanced Motion Control Design, in: The Control Handbook, Con-\ntrol System Applications, 2nd Edition, CRC Press, 2010, pp. 27/1–25.\nhttps://doi.org/10.1201/b10382-35.\nMax van Haren is currently working toward the\nPh.D. degree in mechanical engineering with the\nControl Systems Technology section, Eindhoven\nUniversity of Technology. He received the M.Sc.\ndegree (cum laude) in mechanical engineering in\n2021 from the Eindhoven University of Technol-\nogy, Eindhoven, The Netherlands. His research in-\nterests include control and identification of mecha-\ntronic systems, including sampled-data, multirate,\nand linear parameter-varying systems.\nLennart Blanken is currently a System Designer\nMechatronics with Sioux Technologies, Eindhoven,\nThe Netherlands. Additionally, he is an assistant\nprofessor with the Department of Mechanical Engi-\nneering at the Eindhoven University of Technology.\nHe received the M.Sc. degree (cum laude) and Ph.D.\ndegree in mechanical engineering from the Eind-\nhoven University of Technology, Eindhoven, The\nNetherlands, in 2015 and 2019, respectively. His re-\nsearch interests include advanced feedforward control, learning control, repeti-\ntive control, and their applications to mechatronic systems.\nTom Oomen is full professor with the Department\nof Mechanical Engineering at the Eindhoven Uni-\nversity of Technology. He is also a part-time full\nprofessor with the Delft University of Technology.\nHe received the M.Sc. degree (cum laude) and Ph.D.\ndegree from the Eindhoven University of Technol-\nogy, Eindhoven, The Netherlands. He held visiting\npositions at KTH, Stockholm, Sweden, and at The\nUniversity of Newcastle, Australia. He is a recip-\nient of the 7th Grand Nagamori Award, the Corus\nYoung Talent Graduation Award, the IFAC 2019 TC\n4.2 Mechatronics Young Research Award, the 2015 IEEE Transactions on Con-\ntrol Systems Technology Outstanding Paper Award, the 2017 IFAC Mechatron-\nics Best Paper Award, the 2019 IEEJ Journal of Industry Applications Best\nPaper Award, and recipient of a Veni and Vidi personal grant. He is currently\na Senior Editor of IEEE Control Systems Letters (L-CSS) and Co-Editor-in-\nChief of IFAC Mechatronics, and he has served on the editorial board of IEEE\nTransactions on Control Systems Technology. He has also been vice-chair for\nIFAC TC 4.2 and a member of the Eindhoven Young Academy of Engineering.\nHis research interests are in the field of data-driven modeling, learning, and\ncontrol, with applications in precision mechatronics.\n9\n\n\n",
  "metadata": {
    "source_file": "dataset/pdfs/arxiv_2502.21105v1.pdf",
    "total_pages": 9,
    "title": "Parameter-Varying Feedforward Control: A Kernel-Based Learning Approach",
    "authors": [
      "Max van Haren",
      "Lennart Blanken",
      "Tom Oomen"
    ],
    "abstract": "The increasing demands for high accuracy in mechatronic systems necessitate\nthe incorporation of parameter variations in feedforward control. The aim of\nthis paper is to develop a data-driven approach for direct learning of\nparameter-varying feedforward control to increase tracking performance. The\ndeveloped approach is based on kernel-regularized function estimation in\nconjunction with iterative learning to directly learn parameter-varying\nfeedforward control from data. This approach enables high tracking performance\nfor feedforward control of linear parameter-varying dynamics, providing\nflexibility to varying reference tasks. The developed framework is validated on\na benchmark industrial experimental setup featuring a belt-driven carriage.",
    "published_date": "2025-02-28",
    "source": "arxiv"
  }
}