{
  "id": "arxiv_2502.21099v1",
  "text": "arXiv:2502.21099v1  [math.OC]  28 Feb 2025\nAdaptive Accelerated Proximal Gradient Methods with Variance Reduction for\nComposite Nonconvex Finite-Sum Minimization\nGanzhao Yuan 1\nAbstract\nThis paper proposes AAPG-SPIDER, an Adap-\ntive Accelerated Proximal Gradient (AAPG)\nmethod with variance reduction for minimizing\ncomposite nonconvex ﬁnite-sum functions.\nIt\nintegrates three acceleration techniques: adap-\ntive stepsizes,\nNesterov’s extrapolation, and\nthe recursive stochastic path-integrated estima-\ntor SPIDER. While targeting stochastic ﬁnite-\nsum problems, AAPG-SPIDER simpliﬁes to\nAAPG in the full-batch, non-stochastic setting,\nwhich is also of independent interest.\nTo our\nknowledge, AAPG-SPIDER and AAPG are\nthe ﬁrst learning-rate-free methods to achieve\noptimal iteration complexity for this class of\ncomposite minimization problems. Speciﬁcally,\nAAPG achieves the optimal iteration complexity\nof O(Nǫ−2), while AAPG-SPIDER achieves\nO(N +\n√\nNǫ−2) for ﬁnding ǫ-approximate sta-\ntionary points, where N is the number of compo-\nnent functions. Under the Kurdyka-Lojasiewicz\n(KL) assumption, we establish non-ergodic con-\nvergence rates for both methods.\nPreliminary\nexperiments on sparse phase retrieval and lin-\near eigenvalue problems demonstrate the supe-\nrior performance of AAPG-SPIDER and AAPG\ncompared to existing methods.\n1. Introduction\nWe consider the following composite nonconvex ﬁnite-sum\nminimization problem (where ‘≜’ denotes deﬁnition):\nmin\nx\nf(x) + h(x), where f(x) ≜1\nN\nN\nX\ni=1\nfi(x).\n(1)\nHere, x ∈Rn. The function f(·) is assumed to be dif-\nferentiable, possibly nonconvex. The function h(x) is as-\n1Peng Cheng Laboratory, China. Correspondence to: Ganzhao\nYuan <yuangzh@pcl.ac.cn>.\nsumed to be closed, proper, lower semi-continuous, poten-\ntially nonconvex, and possibly nonsmooth. Furthermore,\nwe assume the generalized proximal operator of h(x) is\neasy to compute.\nProblem (1) has diverse applications in machine learn-\ning. The function f(x) captures empirical loss, includ-\ning neural network activations, while nonsmooth regular-\nization h(x) prevents overﬁtting and improves generaliza-\ntion. It incorporates prior information, such as structured\nsparsity, low-rank properties, discreteness, orthogonality,\nand non-negativity, enhancing model accuracy. These ca-\npabilities extend to various applications, including sparse\nphase retrieval (Cai et al., 2024; Shechtman et al., 2014),\neigenvalue problems (Wen & Yin, 2013), ℓ2-weight decay\nin neural networks (Zhang et al., 2019), and network quan-\ntization (Bai et al., 2019).\nStochastic Gradient Descent and Variance Reduction\nMethods.\nIn many applications, the ﬁnite-sum min-\nimization problem often involves both n and N be-\ning large.\nFirst-order methods have become the stan-\ndard choice for solving Problem (1) due to their efﬁ-\nciency. Vanilla gradient descent (GD) requires O(Nǫ−2)\ngradient evaluations,\nwhile Stochastic Gradient De-\nscent (SGD) demands O(Nǫ−4) gradient computations\nin total (Ghadimi & Lan, 2013; Ghadimi et al., 2016;\nGhadimi & Lan, 2016).\nTo harness the advantages of\nboth GD and SGD, the variance reduction (VR) frame-\nwork (Johnson & Zhang, 2013; Schmidt et al., 2013) was\nintroduced.\nThis framework combines the faster con-\nvergence of GD with the lower per-iteration complex-\nity of SGD by decomposing the ﬁnite-sum structure into\nmanageable components.\nVR methods generate low-\nvariance gradient estimates by balancing periodic full-\ngradient computations with stochastic mini-batch gradi-\nents. Notable approaches, including SAGA (Defazio et al.,\n2014; J. Reddi et al., 2016), SVRG (Johnson & Zhang,\n2013; Li & Li, 2018), SARAH (Nguyen et al., 2017), SPI-\nDER (Fang et al., 2018), SNVRG (Zhou et al., 2020), and\nPAGE (Li et al., 2021), have been developed. While earlier\nwork achieved an iteration complexity of O(N +N 2/3ǫ−2)\nwith a suboptimal dependence on N, recent methods\n(Fang et al., 2018; Pham et al., 2020) have improved this\n\n\nTable 1: Comparison among existing methods for composite nonconvex funite-sum minimization. The notation ˜O(·) hides\npolylogarithmic factors, while O(·) hides constants.\nAdaptive\nStepsize\nNonconvex\nh(x)\nNesterov\nExtrapol.\nDiagonal\nPrecond.\nIteration\nCom-\nplexity\nLast-Iterate Con-\nvergence Rate\nAPG (Li & Lin, 2015)\n✘\n✔\n✔\n✘\nO(N/ǫ)\n✔\nProxSVRG (J. Reddi et al., 2016)\n✘\n✘\n✔\n✘\nO(N + N 2/3ǫ−2)\nunknown\nSVRG-APG (Li et al., 2017)\n✘\n✔\n✔\n✘\nunknowna\n✔\nSPIDER (Fang et al., 2018)\n✘\n✘\n✘\n✔\nO(N +\n√\nNǫ−2)\nunknown\nSpiderBoost (Wang et al., 2019)\n✘\n✔\n✔\n✘\nO(N +\n√\nNǫ−2)\nunknown\nProxSARAH (Pham et al., 2020)\n✘\n✘\n✘\n✘\nO(N +\n√\nNǫ−2)\nunknown\nAdaGrad-Norm (Ward et al., 2020)\n✔\n✘\n✘\n✘\nO(Nǫ−2)\nunknown\nAGD (Kavis et al., 2022a)\n✔\n✘\n✔\n✘\nO(Nǫ−2)\nunknown\nADA-SPIDER (Kavis et al., 2022b)\n✔\n✘\n✘\n✘\n˜O(N +\n√\nNǫ−2)\nunknown\nAAPG [ours]\n✔\n✔\n✔\n✔\nO(Nǫ−2)\n✔[Theorem 4.8]\nAAPG-SPIDER [ours]\n✔\n✔\n✔\n✔\nO(N +\n√\nNǫ−2)\n✔[Theorem 4.13]\nNote a: This work only demonstrates that any cluster point is a critical point but fail to establish the iteration complexity.\nto the optimal iteration complexity of O(N + N 1/2ǫ−2).\nAdaptive Stepsizes.\nThe choice of stepsize is crit-\nical in optimization, affecting both convergence speed\nand stability.\nTraditional ﬁxed or manually tuned step-\nsizes often underperform on complex non-convex prob-\nlems, resulting in suboptimal outcomes.\nAdaptive step-\nsize methods (McMahan & Streeter, 2010; Duchi et al.,\n2011), such as Adam (Kingma & Ba, 2015; Chen et al.,\n2022), and AdaGrad (Duchi et al., 2011), mitigate these\nissues by dynamically adjusting the stepsize based on\ngradient information.\nRecent advancements, including\nPolyak stepsize (Wang et al., 2023; Jiang & Stich, 2024),\nBarzilai-Borwein\nstepsize\n(Zhou et al.,\n2024),\nscaled\nstepsize (Oikonomidis et al., 2024),\nand D-adaptation\n(Defazio & Mishchenko, 2023), have primarily focused on\nconvex optimization. This work extends adaptive stepsize\ntechniques (Duchi et al., 2011) to address composite non-\nconvex ﬁnite-sum minimization problems.\nNesterov Extrapolation. Nesterov’s extrapolation method\nis a foundational technique in optimization, celebrated\nfor its ability to accelerate gradient-based algorithms\n(Nesterov, 2003; Beck & Teboulle, 2009). By incorporat-\ning a momentum-based step, it achieves an optimal con-\nvergence rate for smooth convex functions, outperform-\ning traditional gradient descent. This technique has been\nextended to solve nonconvex problems (Ghadimi & Lan,\n2016; Li & Lin, 2015; Yang, 2023; Qian & Pan, 2023), par-\nticularly in training deep neural networks (Sutskever et al.,\n2013), where it enhances convergence efﬁciency while\nkeeping the computational cost nearly unchanged.\nDiagonal Preconditioner. Diagonal preconditioners are\nemployed by popular adaptive gradient methods such as\nADAM. Unlike identity or full matrix preconditioners, di-\nagonal preconditioners approximate the preconditioning\nmatrix using only its diagonal elements, greatly reducing\ncomputational cost while preserving the key beneﬁts of\nadaptivity. By adjusting learning rates for each parameter\nbased on gradient history, diagonal preconditioners assign\nhigher learning rates to parameters with less frequent up-\ndates. This adaptive mechanism is especially beneﬁcial for\nlarge-scale problems involving sparse or structured models\n(Duchi et al., 2011; Yun et al., 2021).\nTheory on Nonconvex Optimization. (i) Iteration com-\nplexity.\nWe aim to establish the iteration complex-\nity (or oracle complexity) of nonconvex optimization al-\ngorithms, i.e., the number of iteration required to ﬁnd\nan ǫ-approximate ﬁrst-order stationary point ˙x satisfying\ndist(0, ∂(f + g)( ˙x)) ≤ǫ. However, the iteration complex-\nity of adaptive stepsize methods for solving Problem (1) re-\nmains unknown. Existing related work, such as AdaGrad-\nNorm (Ward et al., 2020), AGD (Kavis et al., 2022a),\nand ADA-SPIDER (Kavis et al., 2022b), addresses the\nspecial case h(·)\n=\n0, while methods such as APG\n(Li & Lin, 2015), ProxSVRG (J. Reddi et al., 2016), Spi-\nder (Fang et al., 2018), SpiderBoost (Wang et al., 2019),\nand ProxSARAH (Pham et al., 2020) rely on non-adaptive\nstepsizes.\nOur proposed methods, AAPG-SPIDER and\nAAPG, with and without variance reduction, respectively,\naddress the general case where h(x) is nonconvex, using\nan adaptive stepsize strategy. Additionally, our methods\nexploit Nesterov’s extrapolation and leverage diagonal pre-\nconditioner techniques. (ii) Last-iterate convergence rate.\nThe work of (Attouch & Bolte, 2009) establishes a uni-\nﬁed framework to prove the convergence rates of descent\nmethods under the Kurdyka-Lojasiewicz (KL) assumption\nfor problem (1). Recent works (Qian & Pan, 2023; Yang,\n2023) extend this to nonmonotone descent methods. In-\nspired by these works, we establish the optimal iteration\ncomplexity and derive non-ergodic convergence rates for\n\n\nour methods.\nContributions. We provide a detailed comparison of ex-\nisting methods for composite nonconvex ﬁnite-sum min-\nimization in Table 1.\nOur main contributions are sum-\nmarized as follows. (i) We proposes AAPG-SPIDER, an\nAdaptive Accelerated Proximal Gradient method with vari-\nance reduction for composite nonconvex ﬁnite-sum opti-\nmization. It integrates adaptive stepsizes, Nesterov’s ex-\ntrapolation, and the SPIDER estimator for fast conver-\ngence. In the full-batch setting, it simpliﬁes to AAPG,\nwhich is of independently signiﬁcant (see Section 2).\n(ii) We show that AAPG-SPIDER and AAPG are the\nﬁrst learning-rate-free methods achieving optimal iteration\ncomplexity for this class of composite minimization prob-\nlems (see Section 3). (iii) Under the Kurdyka-Lojasiewicz\n(KL) assumption, we establish non-ergodic convergence\nrates for both methods (see Section 4). (iv) We validate\nour approaches through experiments on sparse phase re-\ntrieval and the linear eigenvalue problem, showcasing its\neffectiveness (see Section 5).\nNotations. Vector operations are performed element-wise.\nSpeciﬁcally, for any x, y ∈Rn, the operations (x + y),\n(x −y), (x ⊙y), and (x ÷ y) represent element-wise\naddition, subtraction, multiplication, and division, respec-\ntively. We use ∥x∥v to denote the generalized vector norm,\ndeﬁned as ∥x∥v =\npP\ni=1 x2\ni vi. The notations, techni-\ncal preliminaries, and relevant lemmas are provided in Ap-\npendix Section A.\n2. The Proposed Algorithms\nThis section provides the proposed AAPG-SPIDER algo-\nrithm, an Adaptive Accelerated Proximal Gradient method\nwith variance reduction for solving Problem (1). Notably,\nAAPG-SPIDER reduces to AAPG in the full-batch, non-\nstochastic setting.\nFirst of all, our algorithms are based on the following as-\nsumptions imposed on Problem (1).\nAssumption 2.1. The generalized proximal operator:\nProxh(a; v) ≜arg minx h(x)+ 1\n2∥x−a∥2\nv can be exactly\nand efﬁciently for all a, v ∈Rn.\nRemark 2.2. (i) Assumption 2.1 is commonly employed\nin nonconvex proximal gradient methods. (ii) When v =\n1, the diagonal preconditioner reduces to the identity\npreconditioner.\nAssumption 2.1 holds for certain func-\ntions of h(x).\nCommon examples include capped-ℓ1\npenalty (Zhang, 2010b), log-sum penalty (Candes et al.,\n2008), minimax concave penalty (Zhang, 2010a), Geman\npenalty (Geman & Yang, 1995), ℓp regularization with p ∈\n{0, 1\n2, 2\n3, 1}, and indicator functions for cardinality con-\nstraints, orthogonality constraints in matrices, and rank\nconstraints in matrices. (iii) When v is a general vector, the\nvariable metric operator can still be evaluated for certain\ncoordinate-wise separable functions of h(x). Examples in-\ncludes the ℓp norm with p ∈{0, 1\n2, 2\n3, 1} (with or without\nbound constraints) (Yun et al., 2021) and W-shaped regu-\nlarizer (Bai et al., 2019).\nGiven any solution yt, we use the SPIDER estimator, intro-\nduced by (Fang et al., 2018), to approximate its stochastic\ngradient:\ngt =\n\u001a ∇f(yt),\nmod(t, q) = 0;\ngt−1 + ˜∆t,\nelse.\n(2)\nwhere ˜∆t ≜∇f(yt; It)−∇f(yt−1; It). Here, ∇f(y; It)\nrepresents the average gradient computed over the ex-\namples in It at the point y.\nThe mini-batch It is se-\nlected uniformly at random (with replacement) from the set\n{1, 2, ..., N} with |It| = b for all t.\nThe algorithm, AAPG, and its variant, AAPG-SPIDER,\nform an adaptive proximal gradient optimization frame-\nwork designed for composite optimization problems. This\nframework initializes parameters and iteratively updates\nthe solution by computing gradients (either directly or via a\nvariance-reduced SPIDER estimator) and applying a prox-\nimal operator.\nBoth algorithms dynamically update the\nstepsize factor vt based on a combination of past differ-\nences in iterates. Additionally, the algorithm incorporates\nmomentum-like updates through the extrapolation parame-\nter σt to improve convergence speed. These algorithms are\ndesigned for efﬁcient and adaptive optimization in both de-\nterministic and stochastic settings. We present AAPG and\nAAPG-SPIDER in Algorithm 1.\nAlgorithm 1 AAPG and AAPG-SPIDER\n1: Initialize x0. Let x−1 = x0.\n2: Let v > 0, α > 0, β ≥0, and θ ∈[0, 1).\n3: Set v0 = v1, y0 = x0, σ−1 = θ.\n4: for t = 0 to T do\n5:\nOption AAPG: Compute gt = ∇f(yt).\n6:\nOption AAPG-SPIDER: Compute gt using (2).\n7:\nLet xt+1 ∈Proxh(yt−gt÷vt; vt), dt ≜xt+1−xt.\n8:\nLet st ≜α∥rt∥2\n2 + βrt ⊙rt, where rt ≜vt ⊙dt.\n9:\nSet vt+1 =\n√\nvt ⊙vt + st.\n10:\nLet σt ≜θ(1 −σt−1) · min(vt ÷ vt+1).\n11:\nSet yt+1 = xt+1 + σtdt.\n12: end for\nRemark 2.3. (i) The recursive update rule for vt, given\nby vt+1 =\n√\nvt ⊙vt + st, can be equivalently expressed\nas vt+1 =\nq\nv0 ⊙v0 + Pt\ni=0 st.\n(ii) The ﬁrst-order\noptimality condition of xt+1 is 0 ∈∂h(xt+1) + vt ⊙\n(xt+1 −at), where at = yt −gt ÷ vt. (iii) We exam-\nine the special case where h(·) = 0 and β = θ = 0 for\n\n\nAAPG, which leads to yt = xt and vt ⊙(xt+1 −xt) =\n−gt.\nConsequently, the update rule for vt reduces to\nvt+1 =\nq\n(v0)2 + α Pt\ni=0 ∥gi∥2\n2, which is essentially a\nlazy update of AdaGrad-Norm (Ward et al., 2020) that\nvt+1 =\nq\n(v0)2 + α Pt+1\ni=0 ∥gi∥2\n2.\n(iv) We address the\nnon-smoothness of h(x) using its (generalized) proximal\noperator, the basis of proximal gradient methods, which\nupdate the parameter via the gradient of f(x) followed by\na (generalized) proximal mapping of h(x). (v) The proxi-\nmal mapping step incorporates an extrapolated point, com-\nbining the current and previous points, following the Nes-\nterov’s extrapolation method.\n3. Iteration Complexity\nThis section details the oracle complexity of AAPG\nand AAPG-SPIDER. AAPG-SPIDER generates a ran-\ndom output xt with t\n=\n{0, 1, . . .}, based on the\nobserved realizations of the random variable ςt−1\n≜\n{I0, I1, . . . , It−1}. The expectation of a random variable\nis denoted by Eςt−1[·] = E[·], where the subscript is omit-\nted for simplicity.\nIn the sequel of the paper, we make the following assump-\ntions.\nAssumption 3.1. Each fj(·) is L-smooth, meaning that\n∥∇fj(x) −∇fj(˜x)∥≤L∥x −˜x∥for all j ∈[N]. This\nproperty extends to f(x), which is also L-smooth.\nAssumption 3.2. Let {xt}T\nt=0 be generated by Algorithm\n1, with ∥xt∥≤x for all t.\nRemark 3.3. Assumption 3.1 is a standard requirement\nin the convergence analysis of nonconvex algorithms. As-\nsumption 3.2 is satisﬁed if the function (f + h)(x) is coer-\ncive or if h(x) includes the indicator of a compact set.\nWe now provide an initial theoretical analysis applicable to\nboth algorithms, followed by a detailed, separate analysis\nfor each.\n3.1. Initial Theoretical Analysis\nWe ﬁrst establish key properties of vt and σt utilized in\nAlgorithm 1.\nLemma 3.4. (Proof in Section B.1, Properties of vt) We\ndeﬁne Rt ≜Pt\ni=0 ∥ri∥2\n2 ∈R. For all t ≥0, we have:\n(a)\np\nv2 + αRt ≤vt+1 ≤\np\nv2 + (α + β)Rt ≜Vt+1.\n(b)\nmax(vt)\nmin(vt) ≤˙κ ≜1 +\np\nβ/α.\n(c)\nmin(vt+1)\nmin(vt)\n≤¨κ ≜1 + 2 ˙κx√α + β.\nLemma 3.5. (Proof in Section B.2, Properties of σt) For\nall t ≥0, we have the following results.\n(a) θ(1 −θ)/(˙κ¨κ) ≤σt ≤θ.\n(b) (σt−1 −1)vt + σtvt+1 ≤−(1 −θ)2vt.\nWe let ¯x ∈arg minx F(x), where F(x) ≜f(x) + h(x).\nWe now derive an approximate sufﬁcient descent condition\nfor the sequence\nZt ≜E[F(xt) −F(¯x) + 1\n2∥xt −xt−1∥2\nσt−1(vt+L)].\nLemma 3.6. (Proof in Section B.3, Properties of Zt) We\ndeﬁne c1 ≜1\n2( 1−θ\n˙κ )2, c2 ≜3L\n2 . We have:\nZt+1 −Zt ≤E[⟨dt, ∇f(yt) −gt⟩+ c2St\n2 −c1St\n1],\n(3)\nwhere St\n1 ≜\n∥rt∥2\n2\nmin(vt), St\n2 ≜\n∥rt∥2\n2\nmin(vt)2 .\nWe now derive the upper bounds for the summation of the\nterms St\n1 and St\n2 as referenced in Lemma 3.6.\nLemma 3.7. (Proof in Section B.4) We deﬁne Vt as in\nLemma 3.4. We have the following results.\n(a) PT\nt=0 St\n1 ≤s1VT +1, where s1 ≜2¨κ.\n(b) PT\nt=0 St\n2 ≤s2\np\nVT +1, where s2 ≜4¨κ2\nα v−1/2.\n3.2. Analysis for AAPG\nThis subsection provides the convergence analysis of\nAAPG.\nThe following lemma is crucial to our analysis.\nLemma 3.8. (Proof in Section B.5, Boundedness of Zt and\nVt) We have the following results for all t ≥0:\n(a) It holds Zt ≤Z for some positive constant Z.\n(b) It holds Vt ≤v for some positive constant v.\nFinally, we present the following results on iteration com-\nplexity.\nTheorem 3.9. (Proof in Section B.6, Iteration Complex-\nity). Let the sequence {xt}T\nt=0 be generated by AAPG.\n(a) We have PT\nt=0 ∥xt+1 −xt∥2\n2 ≤X ≜1\nα((v/v)2 −1).\n(b) We have\n1\nT +1\nPT\nt=0 ∥∇f(xt+1) + ∂h(xt+1)∥\n=\nO(1/\n√\nT). In other words, there exists ¯t ∈[T ] such\nthat ∥∇f(x¯t) + ∂h(x¯t)∥≤ǫ, provided T ≥O( 1\nǫ2 ).\nRemark 3.10. Theorem 3.9 establishes the ﬁrst optimal it-\neration complexity result for learning-rate-free methods in\ndeterministically minimizing composite functions.\n3.3. Analysis for AAPG-SPIDER\nThis subsection provides the convergence analysis of\nAAPG-SPIDER.\nWe ﬁx q ≥1. For all t ≥0, we denote rt ≜⌊t\nq ⌋+ 1 1,\nleading to (rt −1)q ≤t ≤rtq −1.\n1For example, if q = 3 and t ∈{0, 1, 2, 3, 4, 5, 6, 7, 8, 9},\nthen the corresponding values of rt are {1, 1, 1, 2, 2, 2, 3, 3, 3, 4}.\n\n\nWe introduce an auxiliary lemma from (Fang et al., 2018).\nLemma 3.11. (Lemma 1 in (Fang et al., 2018)) The SPI-\nDER estimator produces a stochastic gradient gt that, for\nall t with (rt −1)q ≤t ≤rtq −1, we have: E[∥gt −\n∇f(yt)∥2\n2] −∥gt−1 −∇f(yt−1)∥2\n2 ≤\nL2\nb Yt−1, where\nYi ≜E[∥yi+1 −yi∥2\n2].\nBased on Lemma 3.6, we have the following results for\nAAPG-SPIDER.\nLemma 3.12. (Proof in Appendix B.7) For any positive\nconstant φ, we deﬁne c1 ≜\n1\n2( 1−θ\n˙κ )2, c′\n2 ≜\n(3+φ)L\n2\n,\nc3 ≜\nL\n2φ\nq\nb. We deﬁne Yi ≜E[∥yi+1 −yi∥2\n2]. For all t\nwith (rt −1)q ≤t ≤rtq −1, we have:\n(a) E[∥gt −∇f(yt)∥2\n2] ≤L2\nb\nPt−1\ni=(rt−1)q Yi.\n(b) Zt+1 −Zt + E[c1St\n1 −c′\n2St\n2] ≤c3\nq\nPt−1\ni=(rt−1)q Yi.\nBased on Lemma 3.7, we obtain the following results.\nLemma 3.13. (Proof in Appendix B.8) We deﬁne Vt ≜\nmin(vt), and Yi ≜E[∥yi+1 −yi∥2\n2]. We have:\n(a) PT\nt=0 VtYt ≤u1E[VT +1], where u1 ≜(8 + 2¨κ)s1.\n(b) PT\nt=0 Yt ≤u2E[\np\nVT +1], where u2 ≜10s2.\nThe following lemma simpliﬁes the analysis by reducing\ndouble summations involving Vi and Yi to single sum-\nmations, thereby facilitating the bounding of cumulative\nterms.\nLemma 3.14. (Proof in Appendix B.9) We deﬁne Yi ≜\nE[∥yi+1 −yi∥2\n2], Vi ≜min(vi), and q′ ≜q¨κq−1. For\nall t with (rt −1)q ≤t ≤rtq −1, we have:\n(a) Pt\nj=(rt−1)q[Vj\nPj−1\ni=(rj−1)q Yi] ≤q′ Pt−1\ni=(rt−1)q ViYi.\n(b) Pt\nj=(rt−1)q[Pj−1\ni=(rj−1)q Yi] ≤(q −1) Pt−1\ni=(rt−1)q Yi.\n(c) PT\nt=0[Pt−1\ni=(rt−1)q Yi] ≤(q −1) PT\nt=1 Yt.\nWe derive the following critical lemma, which is analogous\nto Lemma 3.8.\nLemma 3.15. (Proof in Appendix B.10, Boundedness of\nZt and Vt) We have the following results for all t ≥0:\n(a) It holds E[Zt] ≤Z for some positive constant Z.\n(b) It holds E[Vt] ≤v for some positive constant v.\nFinally, we provide the following results on iteration com-\nplexity.\nTheorem 3.16. (Proof in Section B.11, Iteration Complex-\nity). Let the sequence {xt}T\nt=0 be generated by Algorithm\n1.\n(a) We have E[PT\nt=0 ∥xt+1 −xt∥2\n2] ≤X ≜1\nα((v/v)2 −\n1).\n(b) We have E[\n1\nT +1\nPT\nt=0 ∥∇f(xt+1) + ∂h(xt+1)∥] ≤\nO(1/\n√\nT). In other words, there exists ¯t ∈[T ] such\nthat E[∥∇f(x¯t) + ∂h(x¯t)∥] ≤ǫ, provided T ≥1\nǫ2 .\n(c) Assume b = q =\n√\nN. The total stochastic ﬁrst-order\noracle complexity required to ﬁnd an ǫ-approximate\ncritical point, satisfying E[∥∇f(x¯t) + ∂h(x¯t)∥] ≤ǫ,\nis given by O(N +\n√\nNǫ−2).\nRemark 3.17. (i) The work of (Kavis et al., 2022b) intro-\nduces the ﬁrst learning-rate-free variance-reduced method,\nADA-SPIDER, for solving Problem (1) with h(·)\n=\n0. However, its oracle complexity, ˜O(N +\n√\nNǫ−2), is\nsub-optimal. In contrast, the proposed AAPG-SPIDER\nsuccessfully eliminates the logarithmic factor in ADA-\nSPIDER, achieving optimal iteration complexity. (ii) The-\norem 3.16 establishes the ﬁrst optimal iteration complexity\nresult for learning-rate-free methods in minimizing com-\nposite ﬁnite-sum functions.\n4. Convergence Rate\nThis section presents the convergence rates of AAPG\nand AAPG-SPIDER, leveraging the non-convex analysis\ntool known as the Kurdyka-Lojasiewicz (KL) assumption\n(Attouch et al., 2010; Bolte et al., 2014; Li & Lin, 2015;\nLi et al., 2023; Qian & Pan, 2023).\nWe make the following additional assumptions.\nAssumption 4.1. The function Z(x, x′, σ, v) ≜F(x) −\nF(¯x) + 1\n2∥x −x′∥2\nσ(v+L) is a KL function with respect to\nW ≜{x, x′, σ, v}.\nWe\npresent\nthe\nfollowing\nuseful\nlemma,\ndue\nto\n(Attouch et al., 2010; Bolte et al., 2014).\nLemma 4.2. (Kurdyka-Łojasiewicz Inequality). For a KL\nfunction Z(W) with W ∈dom(Z), there exists ˜η ∈\n(0, +∞), ˜σ ∈[0, 1), a neighborhood Υ of W∞, and a con-\ntinuous concave desingularization function ϕ(s) ≜˜cs1−˜σ\nwith ˜c > 0 and s ∈[0, ˜η) such that, for all W ∈Υ satisfy-\ning Z(W) −Z(W∞) ∈(0, ˜η), it holds that:\nϕ′(Z(W) −Z(W∞)) · dist(0, ∂Z(W)) ≥1.\nRemark 4.3. All semi-algebraic and subanalytic functions\nsatisfy the KL assumption.\nExamples of semi-algebraic\nfunctions include real polynomial functions, ∥x∥p for p ≥\n0, the rank function, the indicator function of Stiefel man-\nifolds, the positive-semideﬁnite cone, and matrices with\nconstant rank.\nWe provide the following lemma on subgradient bounds at\neach iteration.\nLemma 4.4.\n(Proof in Appendix C.1,\nSubgradient\nLower Bound for the Iterates Gap) We deﬁne Wt =\n{xt, xt−1, σt−1, vt}. We have ∥∂Z(Wt+1)∥≤ϑ(∥xt+1−\nxt∥+ ∥xt −xt−1∥).\n\n\n4.1. Analysis for AAPG\nThis subsection presents the convergence rate for AAPG.\nWe deﬁne Xt ≜∥xt−xt−1∥. We deﬁne St ≜P∞\nj=t Xj+1.\nThe following assumption is used in the analysis.\nAssumption 4.5. There exists a sufﬁciently large index t⋆\nsuch that ξ ≜c1 min(vt⋆) −c2 > 0.\nRemark 4.6. Assumption 4.5 holds if min(vt⋆) > c2\nc1 =\n3 ˙κ2L\n(1−θ)2 , which requires min(vt⋆) to be over a multiple of L\nand is relatively mild.\nWe establish a ﬁnite-length property of AAPG, which is\nsigniﬁcantly stronger than the result in Theorem 3.9.\nTheorem 4.7. (Proof in Appendix C.2, Finite-Length\nProperty). We deﬁne ϕt ≜ϕ(Z(Wt) −Z(W∞)). We\ndeﬁne ϑ in Lemma 4.4. We deﬁne ξ in Assumption 4.5.\nFor all t ≥t⋆, we have:\n(a) It holds that X2\nt+1 ≤ϑ\nξ (Xt + Xt−1)(ϕt −ϕt+1).\n(b) It holds that ∀i ≥t, Si ≤̟(Xi+Xi−1)+̟ϕi, where\n̟ > 0 is some constant.\nThe sequence {Xj}∞\nj=t\nhas the ﬁnite length property that St is always upper-\nbounded by a certain constant.\n(c) For all t ≥0, we have: ∥xt −x∞∥≤St.\nFinally, we establish the last-iterate convergence rate for\nAAPG.\nTheorem 4.8. (Proof in Appendix C.3, Convergence\nRate). There exists t′ such that for all t ≥t′, we have:\n(a) If ˜σ = 0, then the sequence xt converges in a ﬁnite\nnumber of steps.\n(b) If ˜σ ∈(0, 1\n2], then there exist ˙ς ∈(0, 1) such that\n∥xt −x∞∥= O( ˙ςt).\n(c) If ˜σ ∈( 1\n2, 1), then it follows that ∥xt −x∞∥≤\nO(t−˙ς), where ˙ς ≜\n1−˜σ\n2˜σ−1 > 0.\nRemark 4.9. Under Assumption 4.2, with the desingular-\nizing function ϕ(t) = ˜ct1−˜σ for some ˜c > 0 and ˜σ ∈[0, 1),\nTheorem 4.8 establishes that AAPG converges in a ﬁnite\nnumber of iterations when ˜σ = 0, achieves linear con-\nvergence for ˜σ ∈(0, 1\n2], and exhibits sublinear conver-\ngence for ˜σ ∈( 1\n2, 1) in terms of the gap ∥xt −x∞∥.\nThese ﬁndings are consistent with the results reported in\n(Attouch et al., 2010).\n4.2. Analysis for AAPG-SPIDER\nThis subsection presents the convergence rate for AAPG-\nSPIDER. We deﬁne Xi ≜\nqPiq−1\nj=iq−q ∥dj∥2\n2, and St ≜\nP∞\nj=t Xj. The following assumption is introduced.\nAssumption 4.10. There exists a sufﬁciently large index t⋆\nsuch that ξ ≜c1 min(vt⋆)−c′\n2 −2ξ′ > 0, where ξ′ ≜5c3,\n{c′\n2, c3} are deﬁned in Lemma 3.12.\nRemark 4.11. Assume q = b and φ = 1, we have c3 = L\n2\nand c′\n2 = 2L. Assumption 4.10 is satisﬁed if min(vt⋆) >\n10c3+c′\n2\nc1\n= 14 ˙κ2L\n(1−θ)2 , requiring min(vt⋆) to exceed a multiple\nof L, which is relatively mild.\nWe now establish the ﬁnite-length property of AAPG-\nSPIDER.\nTheorem 4.12. (Proof in Appendix C.4, Finite-Length\nProperty).\nAssume q ≥2.\nWe deﬁne ϑ in Lemma\n4.4. We deﬁne {ξ, ξ′} in Assumption 4.10. We let ϕt ≜\nϕ(Z(Wt) −Z(W∞)). We have:\n(a) It holds that X2\nrt+ ξ′\nξ (X2\nrt−X2\nrt−1) ≤2qϑ\nξ (ϕ(rt−1)q−\nϕrtq)(Xrt −Xrt−1).\n(b) It holds that ∀i ≥1, Si ≤̟Xi−1 + ̟ϕ(i−1)q, where\n̟ > 0 is some constant.\nThe sequence {Xt}∞\nt=0\nhas the ﬁnite length property that St is always upper-\nbounded by a certain constant.\n(c) For all t ≥1, we have: ∥xtq −x∞∥≤√qSt+1.\nFinally, we establish the last-iterate convergence rate for\nAAPG-SPIDER.\nTheorem 4.13. (Proof in Appendix C.5, Convergence\nRate). Assume q ≥2. There exists t′ such that for all\nt ≥t′, we have:\n(a) If ˜σ = 0, then the sequence xt converges in a ﬁnite\nnumber of steps in expectation.\n(b) If ˜σ ∈(0, 1\n2], then there exist ˙τ ∈[0, 1) such that\nE[∥xtq −x∞∥] ≤O( ˙τ t).\n(c) If ˜σ ∈( 1\n2, 1), then it follows that E[∥xtq −x∞∥] ≤\nO(t−˙τ), where ˙τ ≜\n1−˜σ\n2˜σ−1 > 0.\nRemark 4.14. (i) Theorem 4.13 mirrors Theorem 4.8,\nand AAPG-SPIDER shares similar convergence rate as\nAAPG. (ii) Unlike AAPG, which is assessed at every it-\neration xt, the convergence rate of AAPG-SPIDER is\nevaluated only at speciﬁc checkpoints xtq, where q ≥2.\n(iii) No existing work examines the last-iterate convergence\nrate of VR methods, except for the SVRG-APG method\n(Li et al., 2017), a double-looped approach. However, its\nreliance on objective-based line search limits its practical-\nity for stochastic optimization, and its (Q-linear) conver-\ngence rate is established only for the speciﬁc case where\nthe KL exponent is 1/2. Importantly, their results do not\nextend to our AAPG-SPIDER method.\n5. Experiments\nThis section presents numerical comparisons of AAPG-\nSPIDER for solving the sparse phase retrieval problem\nand AAPG for addressing the linear eigenvalue problem,\nbenchmarked against state-of-the-art methods on both real-\nworld and synthetic datasets.\n\n\nAll methods are implemented in MATLAB and tested on\nan Intel 2.6 GHz CPU with 64 GB of RAM. The experi-\nments are conducted on a set of 8 datasets, including both\nrandomly generated data and publicly available real-world\ndatasets.\nDetails on the data generation process can be\nfound in Appendix Section D. We compare the objective\nvalues of all methods after running for T seconds, where\nT is chosen to be sufﬁciently large to ensure the conver-\ngence of the compared methods. The code is provided in\nthe supplemental material.\n5.1. AAPG-SPIDER on Sparse Phase Retrieval\nSparse phase retrieval seeks to recover a signal x\n∈\nRn from magnitude-only measurements yi = |⟨x, Ai⟩|2,\nwhere Ai ∈Rn are known measurement vectors and yi\nare their squared magnitudes. To address this problem, we\nincorporate sparsity regularization, resulting in the follow-\ning optimization model: minx h(x)+ 1\nN\nPN\ni=1(⟨x, Ai⟩2−\nyi)2. The regularization term h(x) enforces sparsity us-\ning the capped-ℓ1 penalty (Zhang, 2010b) while incorpo-\nrating bound constraints. It is deﬁned as h(x) ≜ιΩ(x) +\n˙λ∥max(|x|, τ)∥1, where Ω≜{x | ∥x∥∞≤˙r} with ˙r, ˙λ >\n0.\n◮Compared Methods.\nWe compare AAPG-SPIDER\nwith three state-of-the-art general-purpose algorithms de-\nsigned to solve Problem (1). (i) ProxSARAH (Pham et al.,\n2020), (ii) SpiderBoost and its Nesterov’s extrapola-\ntion version SpiderBoost-M (Wang et al., 2019), and\n(iii) SGP-SPIDER a sub-gradient projection method\n(Yang et al., 2020) using the SPIDER estimator.\n◮Experimental Settings.\nWe set the parameters for\nthe optimization problem as ( ˙r, ˙δ) = (10, 0.1) and vary\n˙λ ∈{0.01, 0.001}. For ProxSARAH, and SpiderBoost,\nand SpiderBoost-M, SGP-SPIDER, we report results us-\ning a ﬁxed step size of 0.1. For AAPG-SPIDER, we use\nthe parameter conﬁguration (v, α, β) = (0.05, 0.01, 1),\nand evaluate its performance for different values of θ ∈\n{0, 0.1, 0.5, 0.9}.\n◮Experimental Results.\nThe experimental results de-\npicted in Figures 1 and 2 offer the following insights. (i)\nThe proposed method, AAPG-SPIDER, converges more\nquickly than the other methods. (i) AAPG-SPIDER-(θ)\nconsistently outperforms AAPG-SPIDER-(0), particularly\nwhen θ is close to, but less than, 1.\n5.2. AAPG on Linear Eigenvalue Problem\nGiven a symmetric matrix C ∈R ˙d× ˙d and an arbitrary or-\nthogonal matrix V ∈R ˙d× ˙r, the trace of VTCV is mini-\nmized when the columns of V forms an orthogonal basis\nfor the eigenspace corresponding to the ˙d smallest eigen-\nvalues of C. Let λ1 ≤. . . ≤λn < 0 be the eigenval-\nues of C. The problem of ﬁnding the r smallest eigen-\nvalues can be formulated as: minV∈R ˙d× ˙r tr(VTCV) +\ntr(C), s.t. XTX = I ˙d.\n◮Compared Methods. We compare AAPG with three\nstate-of-the-art methods: APG (Li & Lin, 2015), FOForth\n(Gao et al., 2018), and OptM (Wen & Yin, 2013). For FO-\nForth, different retraction strategies are employed to han-\ndle the orthogonality constraint, resulting in several vari-\nants: FOForth-GR, FOForth-P, and FOForth-QR. Sim-\nilarly, for OptM, both QR and Cayley retraction strate-\ngies are utilized, giving rise to two variants: OptM-QR\nand OptM-Cayley.\nIt is worth noting that both FO-\nForth and OptM incorporate the Barzilai-Borwein non-\nmonotonic line search in their implementations.\n◮Experimental Settings. For both OptM and FOForth,\nwe utilize the implementations provided by their respective\nauthors, using the default solver settings. For AAPG, we\nconﬁgure the parameters as (v, α, β) = (0.001, 0.001, 0).\nThe performance of all methods is evaluated with varying\n˙r ∈{20, 50}.\n◮Experimental Results. Figures 3 and 4 show the com-\nparisons of objective values for different methods with\nvarying ˙r ∈{20, 50}. Several conclusions can be drawn.\n(i) The methods OptM, FOForth, and APG generally\ndeliver comparable performance, with none consistently\nachieving better results than the others.\n(i) The pro-\nposed AAPG method typically demonstrates superior per-\nformance compared to all other methods. (iii) AAPG-(θ)\nconsistently achieves better results than AAPG-(0), partic-\nularly when θ is close to, but less than, 1. This underscores\nthe importance of Nesterov’s extrapolation strategy in ad-\ndressing composite minimization problems.\n6. Conclusions\nThis paper introduces AAPG-SPIDER, an Adaptive Ac-\ncelerated Proximal Gradient method that leverages vari-\nance reduction to address the composite nonconvex ﬁnite-\nsum minimization problem.\nAAPG-SPIDER combines\nadaptive stepsizes, Nesterov’s extrapolation, and the SPI-\nDER estimator to achieve enhanced performance. In the\nfull-batch, non-stochastic setting, it reduces to AAPG. We\nshow that AAPG attains an optimal iteration complex-\nity of O(N/ǫ2), while AAPG-SPIDER achieves O(N +\n√\nN/ǫ2) for ﬁnding ǫ-approximate stationary points, mak-\ning them the ﬁrst learning-rate-free methods to achieve op-\ntimal iteration complexity for this class of problems. Un-\nder the Kurdyka-Lojasiewicz (KL) assumption, we estab-\nlish non-ergodic convergence rates for both methods. Pre-\nliminary experiments on sparse phase retrieval and linear\neigenvalue problems demonstrate the superior performance\nof AAPG-SPIDER and AAPG over existing methods.\n\n\n0\n2\n4\n6\n8\n10\n−4\n10\n−3\n10\n−2\n10\n−1\n10\n0\nTime (seconds)\nRelative Objective\n \n \nProxSARAH\nSpiderBoost\nSpiderBoost−M\nSGP−Spider\nAAPG−Spider(0)\nAAPG−Spider(0.1)\nAAPG−Spider(0.5)\nAAPG−Spider(0.9)\n(a) tdt2-9000-1000\n0\n2\n4\n6\n8\n10\n−4\n10\n−3\n10\n−2\n10\n−1\n10\n0\nTime (seconds)\nRelative Objective\n \n \nProxSARAH\nSpiderBoost\nSpiderBoost−M\nSGP−Spider\nAAPG−Spider(0)\nAAPG−Spider(0.1)\nAAPG−Spider(0.5)\nAAPG−Spider(0.9)\n(b) 20news-10000-1000\n0\n2\n4\n6\n8\n10\n−4\n10\n−3\n10\n−2\n10\n−1\n10\n0\nTime (seconds)\nRelative Objective\n \n \nProxSARAH\nSpiderBoost\nSpiderBoost−M\nSGP−Spider\nAAPG−Spider(0)\nAAPG−Spider(0.1)\nAAPG−Spider(0.5)\nAAPG−Spider(0.9)\n(c) sector-6412-1000\n0\n2\n4\n6\n8\n10\n−4\n10\n−3\n10\n−2\n10\n−1\n10\n0\nTime (seconds)\nRelative Objective\n \n \nProxSARAH\nSpiderBoost\nSpiderBoost−M\nSGP−Spider\nAAPG−Spider(0)\nAAPG−Spider(0.1)\nAAPG−Spider(0.5)\nAAPG−Spider(0.9)\n(d) mnist-2000-784\nFigure 1: The convergence curve of the compared methods for sparse phase retrieval with ˙λ = 0.01.\n0\n2\n4\n6\n8\n10\n−4\n10\n−3\n10\n−2\n10\n−1\nTime (seconds)\nRelative Objective\n \n \nProxSARAH\nSpiderBoost\nSpiderBoost−M\nSGP−Spider\nAAPG−Spider(0)\nAAPG−Spider(0.1)\nAAPG−Spider(0.5)\nAAPG−Spider(0.9)\n(a) tdt2-9000-1000\n0\n2\n4\n6\n8\n10\n−4\n10\n−3\n10\n−2\n10\n−1\nTime (seconds)\nRelative Objective\n \n \nProxSARAH\nSpiderBoost\nSpiderBoost−M\nSGP−Spider\nAAPG−Spider(0)\nAAPG−Spider(0.1)\nAAPG−Spider(0.5)\nAAPG−Spider(0.9)\n(b) 20news-10000-1000\n0\n2\n4\n6\n8\n10\n−4\n10\n−3\n10\n−2\n10\n−1\nTime (seconds)\nRelative Objective\n \n \nProxSARAH\nSpiderBoost\nSpiderBoost−M\nSGP−Spider\nAAPG−Spider(0)\nAAPG−Spider(0.1)\nAAPG−Spider(0.5)\nAAPG−Spider(0.9)\n(c) sector-6412-1000\n0\n2\n4\n6\n8\n10\n−3\n10\n−2\n10\n−1\nTime (seconds)\nRelative Objective\n \n \nProxSARAH\nSpiderBoost\nSpiderBoost−M\nSGP−Spider\nAAPG−Spider(0)\nAAPG−Spider(0.1)\nAAPG−Spider(0.5)\nAAPG−Spider(0.9)\n(d) mnist-2000-784\nFigure 2: The convergence curve of the compared methods for sparse phase retrieval with ˙λ = 0.001.\n0\n1\n2\n3\n4\n5\n6\n10\n−4\n10\n−3\n10\n−2\n10\n−1\nTime (seconds)\nRelative Objective\n \n \nOptM−QR\nOptM−Cayley\nAPG\nFOForth−GR\nFOForth−P\nFOForth−QR\nAAPG(0)\nAAPG(0.1)\nAAPG(0.5)\nAAPG(0.9)\n(a) tdt2-3000-3000\n0\n1\n2\n3\n4\n5\n6\n10\n−4\n10\n−3\n10\n−2\n10\n−1\nTime (seconds)\nRelative Objective\n \n \nOptM−QR\nOptM−Cayley\nAPG\nFOForth−GR\nFOForth−P\nFOForth−QR\nAAPG(0)\nAAPG(0.1)\nAAPG(0.5)\nAAPG(0.9)\n(b) 20news-5000-1000\n0\n1\n2\n3\n4\n5\n6\n10\n−4\n10\n−3\n10\n−2\n10\n−1\nTime (seconds)\nRelative Objective\n \n \nOptM−QR\nOptM−Cayley\nAPG\nFOForth−GR\nFOForth−P\nFOForth−QR\nAAPG(0)\nAAPG(0.1)\nAAPG(0.5)\nAAPG(0.9)\n(c) sector-6000-1000\n0\n1\n2\n3\n4\n5\n6\n10\n−4\n10\n−3\n10\n−2\n10\n−1\nTime (seconds)\nRelative Objective\n \n \nOptM−QR\nOptM−Cayley\nAPG\nFOForth−GR\nFOForth−P\nFOForth−QR\nAAPG(0)\nAAPG(0.1)\nAAPG(0.5)\nAAPG(0.9)\n(d) mnist-5000-784\nFigure 3: The convergence curve of the compared methods for linear eigenvalue problems with ˙r = 20.\n0\n1\n2\n3\n4\n5\n6\n10\n−4\n10\n−3\n10\n−2\n10\n−1\nTime (seconds)\nRelative Objective\n \n \nOptM−QR\nOptM−Cayley\nAPG\nFOForth−GR\nFOForth−P\nFOForth−QR\nAAPG(0)\nAAPG(0.1)\nAAPG(0.5)\nAAPG(0.9)\n(a) tdt2-3000-3000\n0\n1\n2\n3\n4\n5\n6\n10\n−4\n10\n−3\n10\n−2\n10\n−1\nTime (seconds)\nRelative Objective\n \n \nOptM−QR\nOptM−Cayley\nAPG\nFOForth−GR\nFOForth−P\nFOForth−QR\nAAPG(0)\nAAPG(0.1)\nAAPG(0.5)\nAAPG(0.9)\n(b) 20news-5000-1000\n0\n1\n2\n3\n4\n5\n6\n10\n−4\n10\n−3\n10\n−2\n10\n−1\nTime (seconds)\nRelative Objective\n \n \nOptM−QR\nOptM−Cayley\nAPG\nFOForth−GR\nFOForth−P\nFOForth−QR\nAAPG(0)\nAAPG(0.1)\nAAPG(0.5)\nAAPG(0.9)\n(c) sector-6000-1000\n0\n1\n2\n3\n4\n5\n6\n10\n−3\n10\n−2\n10\n−1\nTime (seconds)\nRelative Objective\n \n \nOptM−QR\nOptM−Cayley\nAPG\nFOForth−GR\nFOForth−P\nFOForth−QR\nAAPG(0)\nAAPG(0.1)\nAAPG(0.5)\nAAPG(0.9)\n(d) mnist-5000-784\nFigure 4: The convergence curve of the compared methods for linear eigenvalue problems with ˙r = 50.\nReferences\nAttouch, H. and Bolte, J. On the convergence of the prox-\nimal algorithm for nonsmooth functions involving ana-\nlytic features. Mathematical Programming, 116(1-2):5–\n16, 2009.\n\n\nAttouch, H., Bolte, J., Redont, P., and Soubeyran, A. Prox-\nimal alternating minimization and projection methods\nfor nonconvex problems: An approach based on the\nkurdyka-lojasiewicz inequality. Mathematics of Oper-\nations Research, 35(2):438–457, 2010.\nBai, Y., Wang, Y., and Liberty, E. Proxquant: Quantized\nneural networks via proximal operators. In International\nConference on Learning Representations (ICLR), 2019.\nBeck, A. and Teboulle, M.\nA fast iterative shrinkage-\nthresholding algorithm for linear inverse problems.\nSIAM Journal on Imaging Sciences, 2(1):183–202,2009.\nBertsekas, D. Convex optimization algorithms. Athena Sci-\nentiﬁc, 2015.\nBolte, J., Sabach, S., and Teboulle, M. Proximal alternating\nlinearized minimization for nonconvex and nonsmooth\nproblems. Mathematical Programming, 146(1-2):459–\n494, 2014.\nCai, J., Long, Y., Wen, R., and Ying, J. A fast and provable\nalgorithm for sparse phase retrieval.\nIn International\nConference on Learning Representations (ICLR), 2024.\nCandes, E. J., Wakin, M. B., and Boyd, S. P.\nEnhanc-\ning sparsity by reweighted ℓ1 minimization. Journal of\nFourier analysis and applications, 14:877–905, 2008.\nChen, C., Shen, L., Zou, F., and Liu, W. Towards practi-\ncal adam: Non-convexity, convergence theory, and mini-\nbatch acceleration.\nJournal of Machine Learning Re-\nsearch, 23(229):1–47, 2022.\nDefazio, A. and Mishchenko, K. Learning-rate-free learn-\ning by d-adaptation. In International Conference on Ma-\nchine Learning (ICML), volume 202, pp. 7449–7479,\n2023.\nDefazio, A., Bach, F., and Lacoste-Julien, S.\nSaga: A\nfast incremental gradient method with support for non-\nstrongly convex composite objectives. Advances in Neu-\nral Information Processing Systems (NeurlPS), 27, 2014.\nDuchi, J., Hazan, E., and Singer, Y. Adaptive subgradient\nmethods for online learning and stochastic optimization.\nJournal of Machine Learning Research, 12(7), 2011.\nFang, C., Li, C. J., Lin, Z., and Zhang, T. Spider: Near-\noptimal non-convex optimization via stochastic path-\nintegrated differential estimator. Advances in Neural In-\nformation Processing Systems (NeurlPS), 31, 2018.\nGao, B., Liu, X., Chen, X., and Yuan, Y.-x. A new ﬁrst-\norder algorithmic framework for optimization problems\nwith orthogonality constraints. SIAM Journal on Opti-\nmization, 28(1):302–332, 2018.\nGeman, D. and Yang, C. Nonlinear image recovery with\nhalf-quadratic regularization. IEEE transactions on Im-\nage Processing, 4(7):932–946, 1995.\nGhadimi, S. and Lan, G. Stochastic ﬁrst- and zeroth-order\nmethods for nonconvex stochastic programming. SIAM\nJournal on Optimization, 23(4):2341–2368, 2013.\nGhadimi, S. and Lan, G.\nAccelerated gradient methods\nfor nonconvex nonlinear and stochastic programming.\nMathematical Programming, 156(1):59–99, 2016.\nGhadimi, S., Lan, G., and Zhang, H. Mini-batch stochastic\napproximation methods for nonconvex stochastic com-\nposite optimization. Mathematical Programming, 155\n(1-2):267–305, 2016.\nJ. Reddi, S., Sra, S., Poczos, B., and Smola, A. J. Proximal\nstochastic methods for nonsmooth nonconvex ﬁnite-sum\noptimization. In Advances in Neural Information Pro-\ncessing Systems (NeurlPS), volume 29, 2016.\nJiang, X. and Stich, S. U. Adaptive sgd with polyak step-\nsize and line-search: Robust convergence and variance\nreduction. Advances in Neural Information Processing\nSystems (NeurlPS), 36, 2024.\nJohnson, R. and Zhang, T. Accelerating stochastic gradient\ndescent using predictive variance reduction. In Advances\nin Neural Information Processing Systems, volume 26,\n2013.\nKavis, A., Levy, K. Y., and Cevher, V. High probability\nbounds for a class of nonconvex algorithms with ada-\ngrad stepsize. In International Conference on Learning\nRepresentations (ICLR), 2022a.\nKavis, A., Skoulakis, S., Antonakopoulos, K., Dadi, L. T.,\nand Cevher, V.\nAdaptive stochastic variance reduc-\ntion for non-convex ﬁnite-sum minimization. Advances\nin Neural Information Processing Systems, 35:23524–\n23538, 2022b.\nKingma, D. P. and Ba, J. Adam: A method for stochastic\noptimization. In International Conference on Learning\nRepresentations (ICLR), 2015.\nLi, H. and Lin, Z. Accelerated proximal gradient methods\nfor nonconvex programming. Advances in Neural Infor-\nmation Processing Systems (NeurlPS), 28, 2015.\nLi, Q., Zhou, Y., Liang, Y., and Varshney, P. K. Conver-\ngence analysis of proximal gradient with momentum for\nnonconvex optimization. In International Conference on\nMachine Learning (ICML), pp. 2111–2119, 2017.\nLi, X., Milzarek, A., and Qiu, J.\nConvergence of ran-\ndom reshufﬂing under the kurdyka–lojasiewicz inequal-\nity. SIAM Journal on Optimization, 33(2):1092–1120,\n2023.\n\n\nLi, Z. and Li, J.\nA simple proximal stochastic gra-\ndient method for nonsmooth nonconvex optimization.\nAdvances in Neural Information Processing Systems\n(NeurlPS), 31, 2018.\nLi, Z., Bao, H., Zhang, X., and Richtarik, P. Page: A simple\nand optimal probabilistic gradient estimator for noncon-\nvex optimization. In International Conference on Ma-\nchine Learning (ICML), pp. 6286–6295, 2021.\nMcMahan, H. B. and Streeter, M. J. Adaptive bound opti-\nmization for online convex optimization. In Conference\non Learning Theory (COLT), pp. 244–256, 2010.\nMordukhovich, B. S. Variational analysis and generalized\ndifferentiation i: Basic theory.\nBerlin Springer, 330,\n2006.\nNesterov, Y. Introductory lectures on convex optimization:\nA basic course, volume 87. Springer Science & Business\nMedia, 2003.\nNguyen, L. M., Liu, J., Scheinberg, K., and Takac, M.\nSarah: A novel method for machine learning problems\nusing stochastic recursive gradient.\nIn International\nConference on Machine Learning (ICML), pp. 2613–\n2621, 2017.\nOikonomidis, K., Laude, E., Latafat, P., Themelis, A., and\nPatrinos, P.\nAdaptive proximal gradient methods are\nuniversal without approximation. In International Con-\nference on Machine Learning (ICML), volume 235, pp.\n38663–38682, 2024.\nPham, N. H., Nguyen, L. M., Phan, D. T., and Tran-Dinh,\nQ. Proxsarah: An efﬁcient algorithmic framework for\nstochastic composite nonconvex optimization. Journal\nof Machine Learning Research, 21(110):1–48, 2020.\nQian, Y. and Pan, S. Convergence of a class of nonmono-\ntone descent methods for kurdyka-lojasiewicz optimiza-\ntion problems. SIAM Journal on Optimization, 33(2):\n638–651, 2023.\nRockafellar, R. T. and Wets., R. J.-B. Variational analysis.\nSpringer Science & Business Media, 317, 2009.\nSchmidt, M., Le Roux, N., and Bach, F. Minimizing ﬁnite\nsums with the stochastic average gradient. arXiv, 2013.\nShechtman, Y., Beck, A., and Eldar, Y. C. Gespar: Efﬁcient\nphase retrieval of sparse signals. IEEE Transactions on\nSignal Processing, 62(4):928–938, 2014.\nSutskever, I., Martens, J., Dahl, G., and Hinton, G.\nOn the importance of initialization and momentum in\ndeep learning. In International Conference on Machine\nLearning (ICML), pp. 1139–1147, 2013.\nWang, X., Johansson, M., and Zhang, T.\nGeneralized\npolyak step size for ﬁrst order optimization with momen-\ntum. In International Conference on Machine Learning\n(ICML), pp. 35836–35863. PMLR, 2023.\nWang, Z., Ji, K., Zhou, Y., Liang, Y., and Tarokh, V. Spi-\nderboost and momentum: Faster variance reduction al-\ngorithms. Advances in Neural Information Processing\nSystems (NeurlPS), 32, 2019.\nWard, R., Wu, X., and Bottou, L. Adagrad stepsizes: Sharp\nconvergence over nonconvex landscapes. Journal of Ma-\nchine Learning Research, 21(219):1–30, 2020.\nWen, Z. and Yin, W. A feasible method for optimization\nwith orthogonality constraints. Mathematical Program-\nming, 142(1-2):397, 2013.\nYang, L. Proximal gradient method with extrapolation and\nline search for a class of non-convex and non-smooth\nproblems. Journal of Optimization Theory and Applica-\ntions, 200(1):68–103, 2023.\nYang, Y., Yuan, Y., Chatzimichailidis, A., van Sloun, R. J.,\nLei, L., and Chatzinotas, S. Proxsgd: Training structured\nneural networks under regularization and constraints. In\nInternational Conference on Learning Representations\n(ICLR), 2020.\nYun, J., Lozano, A. C., and Yang, E.\nAdaptive prox-\nimal gradient methods for structured neural networks.\nAdvances in Neural Information Processing Systems\n(NeurlPS), 34:24365–24378, 2021.\nZhang, C.-H.\nNearly unbiased variable selection under\nminimax concave penalty. The Annals of Statistics, pp.\n894–942, 2010a.\nZhang, G., Wang, C., Xu, B., and Grosse, R. B. Three\nmechanisms of weight decay regularization. In Interna-\ntional Conference on Learning Representations (ICLR),\n2019.\nZhang, T. Analysis of multi-stage convex relaxation for\nsparse regularization. Journal of Machine Learning Re-\nsearch, 11(3), 2010b.\nZhou, D., Xu, P., and Gu, Q. Stochastic nested variance\nreduction for nonconvex optimization. The Journal of\nMachine Learning Research, 21(1):4130–4192, 2020.\nZhou, D., Ma, S., and Yang, J. Adabb: Adaptive barzilai-\nborwein method for convex optimization. arXiv preprint\narXiv:2401.08024, 2024.\n\n\nAppendix\nThe organization of the appendix is as follows:\nAppendix A provides notations, technical preliminaries, and relevant lemmas.\nAppendix B offers proofs related to Section 3.\nAppendix C contains proofs related to Section 4.\nAppendix D includes additional experiments details and results.\nA. Notations, Technical Preliminaries, and Relevant Lemmas\nA.1. Notations\nIn this paper, bold lowercase letters represent vectors, and uppercase letters denote real-valued matrices. The following\nnotations are used throughout this paper.\n• [n]: The set {1, 2, ..., n}.\n• ∥x∥: Euclidean norm, deﬁned as ∥x∥= ∥x∥2 =\np\n⟨x, x⟩.\n• ⟨a, b⟩: Euclidean inner product, given by ⟨a, b⟩= P\ni aibi.\n• ⟨a, b⟩v : Generalized inner product, deﬁned as ⟨a, b⟩v = P\ni aibivi.\n• ∥x∥v: Generalized vector norm, deﬁned as ∥x∥v =\npP\ni=1 x2\ni vi.\n• a ≤α: For a ∈Rn and α ∈R, this means ai ≤α for all i ∈n.\n• ιΩ(x) : Indicator function of a set Ωwith ιΩ(x) = 0 if x ∈Ωand otherwise +∞.\n• E[v]: Expected value of the random variable v.\n• {Ai}∞\ni=0, {Bi}∞\ni=0: sequences indexed by the integers i = 0, 1, 2, 3, . . ..\n• dist(Ω, Ω′) : distance between two sets with dist(Ω, Ω′) ≜infw∈Ω,w′∈Ω′ ∥w −w′∥.\n• ∥∂h(x)∥: distance from the origin to ∂h(x) with ∥∂h(x)∥= infy∈∂h(x) ∥y∥= dist(0, ∂h(x)).\n• AT : the transpose of the matrix A.\n• b: The mini-batch size parameter of AAPG-SPIDER.\n• q: The frequency parameter of AAPG-SPIDER (that determines when the full gradient is computed).\nA.2. Technical Preliminaries\nWe introduce key concepts from nonsmooth analysis, focusing on the Fr´echet subdifferential and the limiting (Fr´echet)\nsubdifferential (Mordukhovich, 2006; Rockafellar & Wets., 2009; Bertsekas, 2015). Let F : Rn →(−∞, +∞] be an\nextended real-valued, not necessarily convex function. The domain of F(·) is deﬁned as dom(F) ≜{x ∈Rn : |F(x)| <\n+∞}. The Fr´echet subdifferential of F at x ∈dom(F), denoted as ˆ∂F(x), is given by\nˆ∂F(x) ≜{v ∈Rn : lim\nz→x inf\nz̸=x\nF(z) −F(x) −⟨v, z −x⟩\n∥z −x∥\n≥0}.\nThe limiting subdifferential of F(·) at x ∈dom(F), denoted ∂F(x), is deﬁned as:\n∂F(x) ≜{v ∈Rn : ∃xk →x, F(xk) →F(x), vk ∈ˆ∂F(xk) →v, ∀k}.\nIt is important to note that ˆ∂F(x) ⊆∂F(x). If F(·) is differentiable at x, then ˆ∂F(x) = ∂F(x) = {∇F(x)}, where\n∇F(x) represents the gradient of F(·) at x. For convex function F(·), both ˆ∂F(x) and ∂F(x) reduce to the classical\nsubdifferential for convex functions: ˆ∂F(x) = ∂F(x) = {v ∈Rn : F(z) −F(x) −⟨v, z −x⟩≥0, ∀z ∈Rn}.\n\n\nA.3. Relevant Lemmas\nWe provide a set of useful lemmas, each independent of context and speciﬁc methodologies.\nLemma A.1. (Pythagoras Relation) For any vectors a, v, x, x+ ∈Rn, we have:\n1\n2∥x −a∥2\nv −1\n2∥x+ −a∥2\nv = 1\n2∥x −x+∥2\nv + ⟨a −x+, x+ −x⟩v.\nLemma A.2. For all a, b ≥0 and c, d > 0, we have: a+b\nc+d ≤max( a\nc , b\nd).\nProof. We consider two cases: (i) a\nc ≥b\nd. We derive: b ≤ad\nc , leading to a+b\nc+d ≤a+ ad\nc\nc+d = a\nc · c+d\nc+d = a\nc . (ii) a\nc < b\nd. We\nhave: a ≤bc\nd , resulting in a+b\nc+d ≤\nbc\nd +b\nc+d = b\nd · c+d\nc+d = b\nd.\nLemma A.3. Assume ax2 ≤bx + c, where b, c, x ≥0 and a > 0. Then, we have: x ≤\np\nc/a + b/a.\nProof. Given the quadratic equality ax2 ≤bx + c, we have b−\n√\nb2+4ac\n2a\n≤x ≤\nb+\n√\nb2+4ac\n2a\n. Since x ≥0, we have\n0 ≤x ≤b+\n√\nb2+4ac\n2a\n≤b+b+2√ac\n2a\n= b/a +\np\nc/a, where the last inequality uses\n√\na + d ≤√a +\n√\nd for all a, d ≥0.\nLemma A.4. Assume that {Ai}n\ni=0 and {Bi}n+1\ni=0 are two non-negative sequences with A0 ≤A1 ≤. . . ≤An. Then, we\nhave:\nPn\nt=0 At(Bt −Bt+1) ≤[maxn\ni=0 Ai] · [maxn\nj=0 Bj].\nProof. We have:\nPn\nt=0 At(Bt −Bt+1)\n=\n[Pn\nt=1(At −At−1)Bt] + A0B0 −AnBn+1\n①\n≤\n[Pn\nt=1(At −At−1)Bt] + A0B0\n②\n≤\n[Pn\nt=1(At −At−1)] · [maxn\nj=0 Bj] + A0[maxn\nj=0 Bj]\n=\nAn[maxn\nj=0 Bj],\nwhere step ①uses An, Bn+1 ≥0; step ②uses {At}n\nt=0 is non-decreasing.\nLemma A.5. We let c > 0 and St ≜Pt\ni=0 Ai, where {Ai}∞\ni=0 and {Si}∞\ni=0 are two non-negative sequences. We have:\nPt\ni=0 Ai/√c + Si ≤2√c + St.\nProof. This lemma extends the result of Lemma 5 in (McMahan & Streeter, 2010).\nInitially, we deﬁne h(x) ≜\nx\n√y + 2√y −x −2√y, where y > x ≥0. We have ∇h(x) = y−1/2 −(y −x)−1/2 ≤0.\nTherefore, h(x) is non-increasing for all x ≥0. Given h(0) = 0, it holds that\nh(x) ≜\nx\n√y + 2√y −x −2√y ≤0.\n(4)\nWe complete the proof of the lemma using mathematical induction. (i) The lemma holds t = 0. (ii) Now, ﬁx some t and\nassume that the lemma holds for t −1. We proceed as follows:\nPt\ni=0 Ai/√c + Si\n=\nAt/√c + St + Pt−1\ni=0 Ai/√c + Si\n①\n≤\nAt/\np\nc + St + 2\np\nc + St−1\n②\n≤\nAt/\np\nc + St + 2\np\nc + St −At\n③\n≤\n2\np\nc + St,\n\n\nwhere step ①uses the inductive hypothesis that the conclusion of this lemma holds for t −1; step ②uses St ≜Pt\ni=0 Ai;\nstep ③uses Inequality (4) with x = At ≥0 and y = c + St > 0.\nLemma A.6. Let c > 0 and St ≜Pt\ni=0 Ai, where {Ai}∞\ni=0 and {Si}∞\ni=0 are two non-negative sequences. We have\nPt\ni=0\nAi\nc+Si ≤log(1 + St/c) ≤(c+St)p\npcp\n−1, where p ∈(0, 1].\nProof. Notably, the ﬁrst inequality that Pt\ni=0\nAi\nc+Si ≤log(1 + St/c) corrects Lemma 4.2 in (Kavis et al., 2022a) and\nLemma 3.2 in (Ward et al., 2020). Speciﬁcally, the claims Pt\ni=0\nAi\nPi\nj=0 Aj ≤1 + log(1 + Pt\ni=0 Ai) in (Kavis et al., 2022a)\nand Pt\ni=0\nAi\nPi\nj=0 Aj ≤1 + log(Pt\ni=0 Ai) in (Ward et al., 2020) are incorrect. Consider a counterexample where t = 1 and\nA0 = A1 = 1/4. In this case, we have 1/4\n1/4 +\n1/4\n1/4+1/4 > 1 + log(1 + 1/4 + 1/4) > 1 + log(1/4 + 1/4).\nPart (a). We complete the proof for the ﬁrst inequality Pt\ni=0\nAi\nc+Si ≤log(1 + St/c) using mathematical induction.\nFirst, we consider g(x) ≜\nx\nc+x −log(1 + x\nc ) with x ≥0. We have ∇g(x) = −\nx\n(x+c)2 ≤0. Since g(0) = 0 −log(1) = 0,\nit follows that for all x ≥0,\ng(x) ≜\nx\nc+x −log(1 + x\nc ) ≤0\n(5)\nSecond, we prove that y\nz + log( z−y\nz ) ≤0 for all 0 ≤y < z. We deﬁne x ≜y\nz ∈[0, 1), and it sufﬁces to prove that\np(x) ≜x + log(1 −x) ≤0 for all x ∈[0, 1). Given ∇p(x) = −\nx\n1−x ≤0 and p(0) = 0, we have p(x) ≤0 for all x ≥0.\nWe now consider t = 0. We have\nA0\nc+S0 −log(1 + S0\nc )\n①=\nA0\nc+A0 −log(1 + A0\nc )\n②\n≤0,\nwhere step ①uses A0 = S0; step ②uses g(A0) ≤0 for all A0 ≥0. We conclude that the conclusion of this lemma holds\nfor t = 0.\nNow, ﬁx some t and assume that the lemma holds for t −1. We derive:\nPt\ni=0\nAi\nc+Si\n=\nAt\nc+St + Pt−1\ni=0\nAi\nc+Si\n①\n≤\nAt\nc+St + log(1 + St−1\nc )\n②=\nAt\nc+St + log(1 + St−At\nc\n)\n=\nlog(1 + St\nc ) +\nAt\nc+St + log(1 + St−At\nc\n) −log(1 + St\nc )\n③=\nlog(1 + St\nc ) +\nAt\nc+St + log( c+St−At\nc+St\n)\n④\n≤\nlog(1 + St\nc ),\nwhere step ①uses the inductive hypothesis that the conclusion of this lemma holds for t −1; step ②uses St ≜Pt\ni=0 Ai;\nstep ③uses log(a) −log(b) = log( a\nb ) for all a, b > 0; step ④uses the inequality y\nz + log( z−y\nz ) ≤0 for all 0 ≤y < z,\nwhere y = At and z = c + St.\nPart (b). Now, we prove that h(b) ≜log(1 + b\nc) −(c+b)p\npcp\n+ 1 ≤0 for all p ∈(0, 1] and b ≥0. Since ∇h(b) =\n1\nc+b(1 −(c+b)p\ncp\n) ≤0 and h(0) = log(1) −1/p + 1 ≤0, we have h(b) ≤0 for all b ≥0. Applying b = St, we ﬁnish the\nproof of this lemma.\nLemma A.7. Let {Zt}∞\nt=0 be a non-negative sequence satisfying Zt+1 ≤a + b\np\nmaxt\ni=0 Zi for all t ≥0, where a, b ≥0.\nIt follows that Zt ≤Z for all t ≥0, where Z ≜max(Z0, c) and c ≜( 1\n2(b +\n√\nb2 + 4a))2. Furthermore, an alternative\nvalid upper bound for Zt is given by Z+ ≜max(Z0, 2b2 + 2a).\n\n\nProof. We deﬁne Mt ≜max0≤i≤t Zi for all t ≥0.\nPart (a). For all t ≥0, we have:\nMt+1\n①= max(Mt, Zt+1)\n②\n≤max(Mt, a + b\np\nMt),\nwhere step ①uses the deﬁnition of Mt; step ②uses We have Zt+1 ≤a + b√Mt, which is the assumption of this lemma.\nPart (b). We establish a ﬁxed-point upper bound that the sequence Mt cannot exceed such that Mt ≤M. For M to be a\nvalid upper bound, it should satisfy the recurrence relation: M = a + b\n√\nM. This is because if Mt ≤M, then we have:\nMt+1 ≤a + b√Mt ≤a + b\n√\nM ≤M, which would imply by induction that Mt ≤M for all t ≥0. Solving the quadratic\nequation M = a + b\n√\nM yields a positive root ( 1\n2(b +\n√\nb2 + 4a))2 ≜c. Taking into account the case M0, for all t ≥0,\nwe have Mt ≤max(M0, c) = max(Z0, c) ≜Z.\nPart (c). We verify that Zt ≤Z for all t ≥0 using mathematical induction. (i) The conclusion holds for t = 0. (ii) Assume\nthat Zt ≤Z holds for some t. We now show that it also holds for t + 1. We have:\nZt+1\n①\n≤a + b\np\nMt\n②\n≤a + b√c\n③= c,\nwhere step ①uses the assumption of this lemma that Zt+1 ≤a + b\np\nmaxt\ni=0 Zi; step ②uses Mt ≤c; step ③uses the fact\nthat x = c is the positive root for the equation a + b√x = x. Therefore, we conclude that Zt ≤max(Z0, c) ≜Z for all\nt ≥0.\nPart (d). Finally, we have: c ≜( 1\n2(b +\n√\nb2 + 4a))2 ≤( 1\n2(b + b + 2√a)2 = (b + √a)2 ≤2b2 + 2a. Hence, Z+ ≜\nmax(Z0, 2b2 + 2a) is also a valid upper bound for Zt.\nLemma A.8. Assume that (Xt+1)2 ≤(Xt + Xt−1)(Pt −Pt+1) and Pt ≥Pt+1, where {Xt, Pt}∞\nt=0 are two nonnegative\nsequences. Then, for all i ≥0, we have: P∞\nj=i Xj+1 ≤Xi + Xi−1 + 4Pi.\nProof. We deﬁne Wt ≜Pt −Pt+1, where t ≥0.\nFirst, for any i ≥0, we have:\nPT\nt=i Wt = PT\nt=i(Pt −Pt+1) = Pi −PT +1\n①\n≤Pi,\n(6)\nwhere step ①uses Pi ≥0 for all i.\nSecond, we obtain:\nXt+1\n①\n≤\np\n(Xt + Xt−1)Wt\n②\n≤\nq\nθ\n4(Xt + Xt−1)2 + (Wt)2/θ, ∀θ > 0\n③\n≤\n√\nθ\n2 (Xt + Xt−1) +\np\n1/θ · Wt, ∀θ > 0.\n(7)\nHere, step ①uses (Xt+1)2 ≤(Xt + Xt−1)(Pt −Pt+1) and Wt ≜Pt −Pt+1; step ②uses the fact that ab ≤θ\n4a2 + 1\nθb2\nfor all α > 0; step ③uses the fact that\n√\na + b ≤√a +\n√\nb for all a, b ≥0.\nAssume θ < 1. Telescoping Inequality (7) over t from i to T , we obtain:\np\n1/θ PT\nt=i Wt\n≥\n\u0010PT\nt=i Xt+1\n\u0011\n−\n√\nθ\n2\n\u0010PT\nt=i Xt\n\u0011\n−\n√\nθ\n2\n\u0010PT\nt=i Xt−1\n\u0011\n=\n\u0010\nXT +1 + XT + PT −2\nt=i Xt+1\n\u0011\n−\n√\nθ\n2\n\u0010\nXi + XT + PT −2\nt=i Xt+1\n\u0011\n−\n√\nθ\n2\n\u0010\nXi−1 + Xi + PT −2\nt=i Xt+1\n\u0011\n= XT +1 + XT −\n√\nθ\n2 (Xi + XT + Xi−1 + Xi) + (1 −\n√\nθ) PT −2\nt=i Xt+1\n①\n≥0 + XT (1 −\n√\nθ\n2 ) −\n√\nθ\n2 (Xi + Xi−1 + Xi) + (1 −\n√\nθ) PT −2\nt=i Xt+1\n②\n≥−\n√\nθ(Xi + Xi−1) + (1 −\n√\nθ) PT −2\nt=i Xt+1,\n\n\nwhere step ①uses XT +1 ≥0; step ②uses 1 −\n√\nθ\n2 > 0. This leads to:\nPT −2\nt=i Xt+1\n≤\n(1 −\n√\nθ)−1 · {\n√\nθ(Xi + Xi−1) +\nq\n1\nθ\nPT\nt=i Wt}\n①=\n(Xi + Xi−1) + 4 PT\nt=i Wt\n②=\n(Xi + Xi−1) + 4Pi,\nstep ①uses the fact that (1 −\n√\nθ)−1 ·\n√\nθ = 1 and (1 −\n√\nθ)−1 ·\np\n1/θ = 4 when θ = 1/4; step ②uses Inequality (6).\nLetting T →∞, we conclude this lemma.\nLemma A.9. Assume that X2\nj + γ(X2\nj −X2\nj−1) ≤(P(j−1)q −Pjq)(Xj −Xj−1) for all j ≥1, where γ > 0 is a constant,\nq ≥1 is an integer, and {Xj, Pj}∞\nj=0 are two nonnegative sequences with P(j−1)q ≥Pjq. Then, for all i ≥1, we have:\nP∞\nj=i Xj ≤γ′Xi−1 + γ′P(i−1)q, where γ′ ≜16(γ + 1).\nProof. We deﬁne P ≜P(i−1)q, and γ′ ≜16(γ + 1).\nUsing the recursive formulation, we derive the following results:\nXj\n≤\nq\nγ\n1+γ X2\nj−1 +\n1\n1+γ · (P(j−1)q −Pjq)(Xj + Xj−1)\n①\n≤\nq\nγ\n1+γ Xj−1 +\nq\n1\n1+γ · p(Xj + Xj−1) · (P(j−1)q −Pjq)\n②\n≤\nq\nγ\n1+γ Xj−1 +\nq\n1\n1+γ\nq\nτ(Xj + Xj−1)2 +\n1\n4τ (P(j−1)q −Pjq)2\n③\n≤\nq\nγ\n1+γ Xj−1 +\nq\nτ\n1+γ (Xj + Xj−1) +\nq\n1\n4τ(1+γ) ·\n\u0000P(j−1)q −Pjq\n\u0001\n,\nwhere steps ①and ③uses\n√\na + b ≤√a +\n√\nb for all a, b ≥0; step ②uses ab ≤τa2 +\n1\n4τ b2 for all a, b ∈R, and τ > 0.\nThis further leads to:\n√1 + γXj ≤√γXj−1 + √τ(Xj + Xj−1) +\nq\n1\n4τ ·\n\u0000P(j−1)q −Pjq\n\u0001\n.\nSumming the inequality above over j from i to T yields:\n0\n≤\n(−√1 + γ + √τ) PT\nj=i Xj + (√γ + √τ) PT\nj=i Xj−1 +\nq\n1\n4τ · (P(i−1)q −PT q)\n①\n≤\n(−√1 + γ + √τ) PT\nj=i Xj + (√γ + √τ) PT −1\nj=i−1 Xj +\nq\n1\n4τ · P\n=\n(−√γ + 1 + √γ + 2√τ) PT −1\nj=i Xj + (√γ + √τ)Xi−1 + (√τ −√1 + γ)XT +\nq\n1\n4τ · P\n②=\n(−\n1\n2√γ+1 + 2√τ) PT −1\nj=i Xj + (√γ + √τ)Xi−1 + (√τ −√1 + γ)XT +\nq\n1\n4τ · P\n③\n≤\n−\n1\n4√γ+1\nPT −1\nj=i Xj + (√γ +\n1\n8√γ+1)Xi−1 + 4√1 + γ · P,\nwhere step ①uses the deﬁnition of P; step ②uses the fact that √γ + 1 −√γ ≥\n1\n2√γ+1 for all γ > 0; step ③uses the\nchoice that τ =\n1\n64(γ+1), which leads to √τ −√1 + γ ≤0.\nFinally, we obtain:\nPT −1\nj=i Xj\n≤\n4\np\nγ + 1 ·\n\u0010\n(√γ +\n1\n8√γ+1)Xi−1 + 4\np\n1 + γ · P\n\u0011\n≤\n(4(γ + 1) + 1\n2)Xi−1 + 16(γ + 1)P\n≤\nγ′Xi−1 + γ′P.\n\n\nLemma A.10. Assume that St ≤c(St−1 −St)u, where c > 0, u ∈(0, 1), and {St}∞\nt=0 is a nonnegative sequence. Then\nwe have ST ≤O(T −ς), where ς =\nu\n1−u.\nProof. We deﬁne τ ≜1\nu −1 > 0, and g(s) = s−τ−1.\nUsing the inequality St ≤c(St−1 −St)u, we obtain:\nc1/u(St−1 −St) ≥(St)1/u ①= (St)τ+1 ②=\n1\ng(St),\n(8)\nwhere step ①uses 1/u = τ + 1; step ②uses the deﬁnition of g(·).\nWe let κ > 1 be any constant, and examine two cases for g(St)/g(St−1).\nCase (1). g(St)/g(St−1) ≤κ. We deﬁne f(s) ≜−1\nτ · s−τ. We derive:\n1\n①\n≤\nc1/u · (St−1 −St) · g(St)\n②\n≤\nc1/u · (St−1 −St) · κg(St−1)\n③\n≤\nc1/u · κ\nR St−1\nSt\ng(s)ds\n④=\nc1/u · κ · (f(St−1) −f(St))\n⑤=\nc1/u · κ · 1\nτ · ([St]−τ −[St−1]−τ),\nwhere step ①uses Inequality (8); step ②uses g(St) ≤κg(St−1); step ③uses the fact that g(s) is a nonnegative and\nincreasing function that (a −b)g(a) ≤\nR a\nb g(s)ds for all a, b ∈[0, ∞); step ④uses the fact that ∇f(s) = g(s); step ⑤\nuses the deﬁnition of f(·). This leads to:\n[St]−τ −[St−1]−τ ≥\nτ\nκc1/u .\n(9)\nCase (2). g(St)/g(St−1) > κ. We have:\ng(St) > κg(St−1)\n①⇒\n[St]−(τ+1) > κ · [St−1]−(τ+1)\n②⇒\n([St]−(τ+1))\nτ\nτ+1 > κ\nτ\nτ+1 · ([St−1]−(τ+1))\nτ\nτ+1\n⇒\n[St]−τ > κ\nτ\nτ+1 · [St−1]−τ,\n(10)\nwhere step ①uses the deﬁnition of g(·); step ②uses the fact that if a > b > 0, then a ˙τ > b ˙τ for any exponent ˙τ ≜\nτ\nτ+1 ∈\n(0, 1). For any t ≥1, we derive:\n[St]−τ −[St−1]−τ\n①\n≥\n(κ\nτ\nτ+1 −1) · [St−1]−τ\n②\n≥\n(κ\nτ\nτ+1 −1) · [S0]−τ,\n(11)\nwhere step ①uses Inequality (10); step ②uses τ > 0 and St−1 ≤S0 for all t ≥1.\nIn view of Inequalities (9) and (11), we have:\n[St]−τ −[St−1]−τ ≥min(\nτ\nκc1/u , (κ\nτ\nτ+1 −1) · [S0]−τ)\n|\n{z\n}\n≜¨c\n.\n(12)\nTelescoping Inequality (12) over t from 1 to T , we have:\n[ST ]−τ −[S0]−τ ≥T ¨c.\nThis leads to:\nST = [S−τ\nT ]−1/τ ≤O([T ]−1/τ).\n\n\nLemma A.11. Assume that St ≤c(St−2 −St)u, where a > 0, u ∈(0, 1), and {St}∞\nt=0 is a nonnegative sequence. Then\nwe have ST ≤O(T −ς), where ς =\nu\n1−u > 0.\nProof. We analyze two cases under the condition St ≤c(St−2 −St)u for all t ≥0.\nCase (1). t ∈{0, 2, 4, 6, . . .}. We deﬁne the sequence { ¨St}T\nt=0 as ¨Si = S2i for i ≥0. It follows that ¨Sj ≤c( ¨Sj−1 −¨Sj)u\nfor all j ≥1. By applying Lemma A.10, we obtain ¨ST ≤O(T −ς), leading to ST = O( ¨S(T/2)) ≤O(( T\n2 )−ς) = O(T −ς).\nCase (2). t ∈{1, 3, 5, 7, . . .}. We deﬁne the sequence { ˙St}T\nt=0 as ˙Si = S2i+1 for i ≥0. It follows that ˙Sj ≤c( ˙Sj−1−˙Sj)u\nfor all j ≥1. By applying Lemma A.10, we have ˙ST ≤O(T −ς), resulting in ST = O( ¨S[(T −1)/2]) ≤O(( T −1\n2 )−ς) =\nO(T −ς).\nB. Proof of Section 3\nB.1. Proof of Lemma 3.4\nProof. We deﬁne Rt ≜Pt\ni=0 ∥ri∥2\n2 ∈R, where rt ≜vt ⊙dt, and dt ≜xt+1 −xt.\nWe deﬁne st ≜α∥rt∥2\n2 + βrt ⊙rt ∈Rn.\nPart (a). We notice that the recursive update rule for vt, given by vt+1 =\n√\nvt ⊙vt + st, can be equivalently expressed\nas vt+1 =\nq\nv0 ⊙v0 + Pt\ni=0 st. We derive:\nvt+1 ⊙vt+1 = (v0) ⊙(v0) + α Pt\ni=0 ∥ri∥2\n2\n|\n{z\n}\n= Rt\n·1 + β Pt\ni=0 ri ⊙ri\n|\n{z\n}\n≤Rt · 1\n.\nThis results in the following lower and upper bounds for vt+1 for all t ≥0:\np\nv2 + αRt ≤vt+1 ≤\np\nv2 + (α + β)Rt.\nPart (b). For all t ≥1, we derive:\nmax(vt)\nmin(vt)\n①\n≤\nq\nv2+(α+β)Rt−1\nv2+αRt−1\n②\n≤\nq\nmax( v2\nv2 , (α+β)Rt−1\nαRt−1\n) =\nq\nmax(1, α+β\nα ) ≤1 +\np\nβ/α,\n(13)\nwhere step ①uses Part (a) of this lemma; step ②uses Lemma A.2 that a+b\nc+d ≤max( a\nc , b\nd) for all a, b, c, d > 0. Clearly,\nInequality (13) is valid for t = 1 as well.\nPart (c). For all t ≥0, we derive the following results:\nmin(vt+1)\nmin(vt)\n①=\nq\nmin(vt⊙vt+α∥rt∥2\n2·1+βrt⊙rt)\nmin(vt⊙vt)\n②\n≤\nq\nmin(vt⊙vt)+(α+β)∥rt∥2\n2\nmin(vt⊙vt)\n③\n≤\nq\nmin(vt⊙vt)+(α+β) max(vt)2∥xt+1−xt∥2\n2\nmin(vt⊙vt)\n④\n≤\nq\nmin(vt⊙vt)+4(α+β) max(vt)2x2\nmin(vt⊙vt)\n⑤\n≤\np\n1 + 4(α + β)˙κ2x2\n≤1 + 2 ˙κx√α + β ≜¨κ,\nwhere step ①uses the update rule for vt+1 that vt+1 =\n√\nvt ⊙vt + st; step ②uses the fact that rt ⊙rt ≤∥rt∥2\n2;\nstep ③uses rt ≜vt ⊙dt with dt ≜xt+1 −xt; step ④uses ∥xt+1 −xt∥≤∥xt+1∥+ ∥xt∥≤2x; step ⑤uses\nmax(vt)/ min(vt) ≤˙κ for all t.\n\n\nB.2. Proof of Lemma 3.5\nProof. We deﬁne σt ≜θ(1 −σt−1) · min(vt ÷ vt+1), where t ≥0.\nPart (a). We now prove that σt ∈[0, θ]. We complete the proof using mathematical induction. First, we consider t = 0,\nwe have:\nσ0\n=\nmin(vt ÷ vt+1) · θ(1 −σ−1)\n①=\nmin(vt ÷ vt+1) · θ(1 −θ)\n②\n≤θ(1 −θ)\n③\n≤θ,\nwhere step ①uses σ−1 = θ; step ②uses min(vt ÷ vt+1) ∈(0, 1]; step ③uses θ ∈[0, 1). Second, we ﬁx some t and\nassume that σt−1 ∈[0, θ]. We analyze the following term for all t ≥1:\nσt ≜θ(1 −σt−1) · min(vt ÷ vt+1).\nGiven σt−1 ∈[0, θ], min(vt ÷ vt+1) ∈(0, 1], and θ ∈[0, 1), we conclude that σt ∈[0, θ].\nWe now establish the lower bound for σt. For all t ≥0, we have:\nσt\n≜\nθ(1 −σt−1) · min(vt ÷ vt+1)\n①\n≥\nθ(1 −θ) · min(vt ÷ vt+1)\n②\n≥\nθ(1 −θ) ·\nmin(vt)\nmax(vt+1)\n=\nθ(1 −θ) · min(vt+1)\nmax(vt+1) ·\nmin(vt)\nmin(vt+1)\n③\n≥\nθ(1 −θ) · 1\n˙κ · 1\n¨κ,\nwhere step ①uses σt−1 ≤θ; step ②uses min(a ÷ b) ≥min(a)\nmax(b) for all a ≥0 and b > 0; step ③uses min(vt+1)\nmax(vt+1) ≥1\n˙κ and\nmin(vt)\nmin(vt+1) ≥1\n¨κ for all t, as shown in Lemma 3.4(b,c).\nPart (b). For all t ≥0, we derive the following results:\n(σt−1 −1)vt + σtvt+1\n①=\n(σt−1 −1)vt + θ(1 −σt−1) · min(vt ÷ vt+1)vt+1\n②\n≤\n(σt−1 −1)vt + θ(1 −σt−1)vt\n=\n−(1 −θ)(1 −σt−1)vt\n③\n≤\n−(1 −θ)(1 −θ)vt\n=\n−(1 −θ)2vt,\nwhere step ①uses the choice for σt for all t ≥0; step ②uses min(a ÷ v)v ≤a for all a, v ∈Rn with v > 0; step ③uses\nσt−1 ≤θ < 1 for all t ≥0.\nB.3. Proof of Lemma 3.6\nProof. We let ¯x ∈arg minx F(x), where F(x) ≜f(x) + h(x).\nWe deﬁne Qt ≜E[⟨dt, ∇f(yt) −gt⟩], where dt ≜xt+1 −xt. We deﬁne at ≜yt −gt ÷ vt.\nWe deﬁne Zt ≜E[F(xt) −F(¯x) + 1\n2∥xt −xt−1∥2\nσt−1(vt+L)]. We deﬁne X t ≜1\n2∥xt −xt−1∥2\nσt−1(vt+L).\nUsing the optimality of xt+1 ∈arg minx h(x) + 1\n2∥x −at∥2\nvt, we have the following inequality:\nE[h(xt+1) + 1\n2∥xt+1 −at∥2\nvt] ≤E[h(xt) + 1\n2∥xt −at∥2\nvt].\n(14)\n\n\nGiven f(x) is L-smooth, we have:\nf(xt+1) ≤f(xt) + ⟨xt+1 −xt, ∇f(xt)⟩+ L\n2 ∥xt+1 −xt∥2\n2.\n(15)\nAdding Inequalities (14) and (15) together yields:\nE[F(xt+1) −F(xt) −L\n2 ∥xt+1 −xt∥2\n2]\n≤E[⟨xt+1 −xt, ∇f(xt)⟩+ 1\n2∥xt −at∥2\nvt −1\n2∥xt+1 −at∥2\nvt]\n①= E[⟨xt+1 −xt, ∇f(xt)⟩+ 1\n2∥xt −xt+1∥2\nvt + ⟨at −xt+1, xt+1 −xt⟩vt]\n②= E[⟨xt+1 −xt, ∇f(xt) −∇f(yt, ξt)⟩+ 1\n2∥xt −xt+1∥2\nvt + ⟨yt −xt+1, xt+1 −xt⟩vt]\n③= Qt + ⟨xt+1 −xt, ∇f(xt) −∇f(yt)⟩] + E[ 1\n2∥xt −yt∥2\nvt −1\n2∥yt −xt+1∥2\nvt]\n④\n≤Qt + E[L∥xt+1 −xt∥∥xt −yt∥+ 1\n2∥xt −yt∥2\nvt −1\n2∥yt −xt+1∥2\nvt]\n⑤= Qt + E[σt−1L∥xt+1 −xt∥∥xt −xt−1∥\n+ (σt−1)2\n2\n∥xt −xt−1∥2\nvt −1\n2∥xt+1 −xt −σt−1(xt −xt−1)∥2\nvt]\n= Qt + E[σt−1L∥xt+1 −xt∥∥xt −xt−1∥−1\n2∥xt+1 −xt∥2\nvt + σt−1⟨xt+1 −xt, xt −xt−1⟩vt]\n⑥\n≤Qt + E[ σt−1L\n2\n∥xt+1 −xt∥2\n2 + σt−1L\n2\n∥xt −xt−1∥2\n2\n−1\n2∥xt+1 −xt∥2\nvt + σt−1\n2 ∥xt+1 −xt∥2\nvt + σt−1\n2 ∥xt −xt−1∥2\nvt]\n= Qt + E[−1\n2∥xt+1 −xt∥2\nvt + 1\n2∥xt −xt−1∥2\nσt−1(vt+L)\n|\n{z\n}\n≜X t\n+ 1\n2∥xt+1 −xt∥2\nσt−1(vt+L)],\n(16)\nwhere step ①uses the Pythagoras Relation as in Lemma A.1 that x+ = xt+1, x = xt, a = at, and v = vt; step ②uses\nat ≜yt −∇f(yt) ÷ vt; step ③the deﬁnition of Qt, and the Pythagoras Relation as in Lemma A.1 that x+ = xt+1,\nx = xt, a = yt, and v = vt; step ④uses L-smoothness of f(·); step ⑤uses yt+1 −xt+1 = σt(xt+1 −xt); step ⑥uses\nab ≤a2\n2 + b2\n2 for all a, b ∈R, and ⟨a, b⟩v ≤1\n2∥a∥2\nv + 1\n2∥b∥2\nv for all a, b, v ∈Rn with v ≥0.\nWe deﬁne Zt ≜E[F(xt) −F(¯x) + 1\n2∥xt −xt−1∥2\nσt−1(vt+L)]. Given Inequality (16), we have the following inequalities\nfor all t ≥0:\nZt+1 −Zt −Qt\n≤E[ L\n2 ∥xt+1 −xt∥2\n2 −1\n2∥xt+1 −xt∥2\nvt + 1\n2∥xt+1 −xt∥2\nσt−1(vt+L) + X t+1]\n①= E[ L\n2 ∥xt+1 −xt∥2\n2 −1\n2∥xt+1 −xt∥2\nvt + 1\n2∥xt+1 −xt∥2\n[σt−1vt+σt−1L+σtvt+1+σtL]]\n= E[ L+σt−1L+σtL\n2\n∥xt+1 −xt∥2\n2 + 1\n2∥xt+1 −xt∥2\n[σt−1vt+σtvt+1−vt]]\n②\n≤E[ 3L\n2 ∥xt+1 −xt∥2\n2 −1\n2(1 −θ)2∥xt+1 −xt∥2\nvt]\n③\n≤E[ 3L\n2\n|{z}\n≜c2\n·\n1\nmin(vt)2 ∥vt ⊙(xt+1 −xt)∥2\n2\n|\n{z\n}\n≜St\n2\n] −E[ 1\n2( 1−θ\n˙κ )2\n|\n{z\n}\n≜c1\n·\n1\nmin(vt)∥vt ⊙(xt+1 −xt)∥2\n2\n|\n{z\n}\n≜St\n1\n],\nwhere step ①uses the deﬁnition of X t ≜1\n2∥xt −xt−1∥2\nσt−1(vt+L); step ②uses σt ≤1 for all t ≥0, and σtvt+1 +\n(σt−1 −1)vt ≤−(1 −θ)2vt for all t ≥0 as shown in Lemma 3.5(b); step ③uses the following two inequalities for all\nd ∈Rn with d = xt+1 −xt:\n∥d∥2\n2 ≤\n1\nmin(vt)2 ∥vt ⊙d∥2\n2,\n∥d∥2\nvt ˙κ2 ≥∥d∥2\nvt max(vt)2\nmin(vt)2 ≥∥d∥2\n2 · min(vt) · max(vt)2\nmin(vt)2 = ∥d∥2\n2 · max(vt)2\nmin(vt) ≥∥vt ⊙d∥2\n2 ·\n1\nmin(vt).\n\n\nB.4. Proof of Lemma 3.7\nProof. We deﬁne Vt+1 ≜\np\nv2 + (α + β)Rt, where Rt ≜Pt\ni=0 ∥ri∥2\n2.\nPart (a). We derive the following results:\nPT\nt=0\n∥rt∥2\n2\nmin(vt)\n=\nPT\nt=0\n∥rt∥2\n2\nmin(vt+1) · min(vt+1)\nmin(vt)\n①\n≤\n¨κ · PT\nt=0\n∥rt∥2\n2\n√\nv2+α Pt\nj=0 ∥rj∥2\n2\n②\n≤\n2¨κ ·\nq\nv2 + α PT\nt=0 ∥rt∥2\n2,\n≤\n2¨κ\n|{z}\n≜s1\n·\nq\nv2 + (α + β) PT\nt=0 ∥rt∥2\n2\n|\n{z\n}\n≜VT +1\n,\nwhere step ①uses Lemma 3.4(c) that min(vt+1)/ min(vt) ≤¨κ, and Lemma 3.4(a); step ②uses Lemma A.5.\nPart (b). We have the following results:\nPT\nt=0\n∥rt∥2\n2\nmin(vt)2\n=\nPT\nt=0\n∥rt∥2\n2\nmin(vt+1)2 · ( min(vt+1)\nmin(vt) )2\n①\n≤\n¨κ2\nα · PT\nt=0\n∥rt∥2\n2\nv2/α+Pt\nj=0 ∥rj∥2\n2\n②\n≤\n¨κ2\nα · (v2/α+PT\nt=0 ∥rt∥2\n2)1/4\n1/4·(v2/α)1/4\n=\n4¨κ2\nα·v1/2 · (v2 + α PT\nt=0 ∥rt∥2\n2)1/4\n③\n≤\n4¨κ2\nα·v1/2\n| {z }\n≜s2\n· (v2 + (α + β) PT\nt=0 ∥rt∥2\n2)1/4\n|\n{z\n}\n≜√\nVT +1\n,\nwhere step ①uses Lemma 3.4(a) and Lemma 3.4(c); step ②uses Lemma A.6 with p = 1/4; step ③uses β ≥0.\nB.5. Proof of Lemma 3.8\nProof. We deﬁne Vt+1 ≜\np\nv2 + (α + β)Rt, where Rt ≜Pt\ni=0 ∥ri∥2\n2.\nWe deﬁne rt ≜vt ⊙dt, where dt ≜xt+1 −xt.\nInitially, for the full-batch, deterministic setting where ∇f(yt) = gt, we obtain from Lemma 3.6 that\n0 ≤Zt −Zt+1 +\nc2∥rt∥2\n2\nmin(vt)2 −c1∥rt∥2\n2\nmin(vt)\n(17)\nMultiplying both sides of Inequality (17) by min(vt) yields:\n0 ≤−c1∥rt∥2\n2 + min(vt)(Zt −Zt+1) + c2∥rt∥2\n2\nmin(vt).\nSumming this inequality over t from t = 0 to T , we obtain:\n0\n≤\n−c1\nPT\nt=0 ∥rt∥2\n2 + PT\nt=0 min(vt)(Zt −Zt+1) + c2\nPT\nt=0\n∥rt∥2\n2\nmin(vt)\n①\n≤\n−c1\nPT\nt=0 ∥rt∥2\n2 + (maxT\nt=0 Zt) · min(vT ) + c2s1VT +1\n②\n≤\n−\nc1\nα+β [(VT +1)2 −v2] + (maxT\nt=0 Zt) · VT +1 + c2s1VT +1,\nwhere step ①uses Lemma A.4 with Ai = min(vi) for all i ∈[T ] with A1 ≤A2 ≤. . . ≤AT , and Bj = Zj for all j ≥0,\nand Lemma 3.7 that PT\nt=0 St\n1 ≤s1VT +1; step ②uses the deﬁnition of VT , along with the facts that vt ≤vt+1 ≤Vt+1\n\n\nand Zi ≥0. This leads to the following quadratic inequality for all T ≥0:\nc1\nα+β (VT +1)2 ≤\n\u0000c2s1 + maxT\nt=0 Zt\n\u0001\n· VT +1 +\nc1\nα+β v2.\nApplying Lemma A.3 with a =\nc1\nα+β, b = c2s1 + maxT\nt=0 Zt, c =\nc1\nα+β v2, and x = VT +1 yields:\nVT +1\n≤\np\nc/a + b/a\n=\nv + α+β\nc1\n·\n\u0000c2s1 + maxT\nt=0 Zt\n\u0001\n=\nv + α+β\nc1\n· c2s1\n|\n{z\n}\n≜w1\n+ α+β\nc1\n|{z}\n≜w2\n· maxT\nt=0 Zt,\n(18)\nThe upper bound for VT +1 is established in Inequality (18), but it depends on the unknown variable (maxT\nt=0 Zt).\nPart (a). We now show that (maxT\nt=0 Zt) is always bounded above by a universal constant Z. Dropping the negative term\n−c1∥rt∥2\n2\nmin(vt) on the right-hand side of Inequality (17) and summing over t from t = 0 to T yields:\nZT +1\n≤\nZ0 + c2\nPT\nt=0\n∥rt∥2\n2\nmin(vt)2\n①\n≤\nZ0 + c2s2\np\nVT +1\n②\n≤\nZ0 + c2s2\np\nw1 + w2 maxT\nt=0 Zt\n②\n≤\nZ0 + c2s2√w1\n|\n{z\n}\n≜˙a\n+ c2s2\n√w2\n|\n{z\n}\n≜˙b\n·\np\nmaxT\nt=0 Zt\n④\n≤\nmax(Z0, 2˙b2 + 2˙a)\n⑤=\n2˙b2 + 2˙a ≜Z,\n(19)\nwhere step ①uses Lemma 3.7(b); step ②uses Inequality (18); step ③uses\n√\na + b ≤√a +\n√\nb for all a, b ≥0; step ④\nuses Lemma A.7 with a = ˙a and b = ˙b; step ⑤uses the fact that ˙a ≥Z0.\nPart (b). We derive the following inequalities for all T ≥0:\nVT +1\n①\n≤\nw1 + w2\np\nmaxT\nt=0 Zt\n②\n≤\nw1 + w2Z ≜v,\nwhere step ①uses Inequality (18); step ②uses Inequality (19).\nB.6. Proof of Theorem 3.9\nProof. Part (a). We have the following inequalities:\nPT\nt=0 ∥xt+1 −xt∥2\n2\n①\n≤\n1\nv2 min(vt)2 PT\nt=0 ∥xt+1 −xt∥2\n2\n②\n≤\n1\nv2\nPT\nt=0 ∥vt ⊙(xt+1 −xt)∥2\n2\n③=\n1\nv2\nPT\nt=0 ∥rt∥2\n2 =\n1\nv2 RT\n④\n≤\n1\nv2 1\nα(v2 −v2) ≜X,\n(20)\nwhere step ①uses vt ≥v; step ②uses min(v)∥d∥≤∥d∥v for all v, d ∈Rn with v ≥0; step ③uses the deﬁnition of\nrt ≜vt ⊙dt; step ④uses Lemma 3.4(a) that v2 + αRt ≤(vt+1)2 ≤v2 for all t.\n\n\nPart (b). First, by the ﬁrst-order necessarily condition of xt+1 that xt+1 ∈Proxh(y −gt ÷ vt; vt) = arg minx h(x) +\n1\n2∥x −(y −gt ÷ vt)∥2\nvt, we have:\n0 ∈∂h(xt+1) + gt + vt ⊙(xt+1 −yt).\n(21)\nSecond, we obtain:\n∥∇f(xt+1) + ∂h(xt+1)∥\n①=\n∥∇f(xt+1) −∇f(yt) −vt ⊙(xt+1 −yt)∥\n②\n≤\nL∥yt −xt+1∥+ max(vt)∥yt −xt+1∥\n③=\n(L + max(vt)) · ∥xt + σt−1(xt −xt−1) −xt+1∥\n④\n≤\n(L + v) · (∥xt −xt+1∥+ ∥xt −xt−1∥),\n(22)\nwhere step ①uses Equality (21) with gt = ∇f(y), as in AAPG; step ②uses the triangle inequality, the fact that f(y) is\nL-smooth, and ∥vt ⊙a∥≤max(vt)∥a∥for all a ∈Rn; step ③uses yt = xt + σt−1(xt −xt−1); step ④uses vt ≤v, the\ntriangle inequality, and σt−1 ≤1 for all t.\nThird, we obtain the following results:\nPT\nt=0 ∥∂h(xt+1) + ∇f(xt+1)∥2\n2\n①\n≤\n2(L + v)2 · PT\nt=0(∥xt+1 −xt∥2\n2 + ∥xt −xt−1∥2\n2)\n=\n2(L + v)2 · {PT\nt=0 ∥xt+1 −xt∥2\n2 + PT −1\nt=−1 ∥xt+1 −xt∥2\n2}\n=\n2(L + v)2 · {∥x−1 −x0∥2\n2 −∥xT +1 −xT ∥2\n2 + 2 PT\nt=0 ∥xt+1 −xt∥2\n2}\n②\n≤\n2(L + v)2 · PT\nt=0 ∥xt+1 −xt∥2\n2\n③\n≤\n2(L + v) · X = O(1),\n(23)\nwhere step ①uses Inequality (22); step ②uses the choice x−1 = x0 as shown in Algorithm 1, and −∥xT +1 −xT ∥≤0;\nstep ③uses Inequality (20).\nFinally, using the inequality ∥a∥2\n2 ≥\n1\nT +1(∥a∥1)2 for all a ∈RT +1, we deduce from Inequality (23) that\n1\nT +1\nPT\nt=0 ∥∂h(xt+1) + ∇f(xt+1)∥= O(\n1\n√T +1).\nB.7. Proof of Lemma 3.12\nProof. We deﬁne c1 ≜1\n2( 1−θ\n˙κ )2, c′\n2 ≜(3+φ)L\n2\n, and c3 ≜L\n2φ\nq\nb, where φ > 0 can be any constant.\nWe deﬁne Zt ≜F(xt) −F(¯x) + 1\n2∥xt −xt−1∥2\nσt−1(vt+L).\nWe deﬁne Yi ≜E[∥yi+1 −yi∥2\n2].\nWe deﬁne St\n1 ≜\n∥rt∥2\n2\nmin(vt), and St\n2 ≜\n∥rt∥2\n2\nmin(vt)2 .\nPart (a). Telescoping the inequality E[∥gt −∇f(yt)∥2\n2] −∥gt−1 −∇f(yt−1)∥2\n2 ≤L2\nb E[∥yt −yt−1∥2\n2] (as stated in\nLemma 3.11) over t from (rt −1)q + 1 to t, where t ≤rtq −1, we obtain:\nE[∥gt −∇f(yt)∥2\n2]\n≤\nE[∥g(rt−1)q −∇f(y(rt−1)q)∥2\n2] + L2\nb\nPt\ni=(rt−1)q+1 E[∥yi −yi−1∥2\n2]\n①=\n0 + L2\nb\nPt−1\ni=(rt−1)q E[∥yi+1 −yi∥2\n2]\n|\n{z\n}\n≜Yi\n,\n(24)\n\n\nwhere step ①uses gj = ∇f(yj) when j is a multiple of q. Notably, Inequality (24) holds for every t of the form\nt = (rt −1)q, since at these points we have gt = ∇f(yt).\nPart (b). For all t with (rt −1)q ≤t ≤rtq −1, we have:\nZt+1 −Zt + c1St\n1\n①\n≤\nE[⟨dt, ∇f(yt) −gt⟩+ c2St\n2\n=\nE[⟨dt, ∇f(yt) −gt⟩+\n3L\n2 min(vt)2 ∥rt∥2\n2\n②\n≤\n3L\n2 min(vt)2 ∥rt∥2\n2 + φL\n2 ∥dt∥2\n2 +\n1\n2φL∥∇f(yt) −gt∥2\n2\n③\n≤\n3L\n2 min(vt)2 ∥rt∥2\n2 +\nφL\n2 min(vt)2 ∥rt∥2\n2 +\nL\n2bφ · Pt−1\ni=(rt−1)q Yi\n=\n(3+φ)L\n2\n| {z }\n≜c′\n2\n·\n1\nmin(vt)2 ∥rt∥2\n2\n|\n{z\n}\nSt\n2\n+ L\n2φ\nq\nb\n|{z}\n≜c3\n· 1\nq\nPt−1\ni=(rt−1)q Yi,\nwhere step ①uses Lemma 3.6; step ②uses ⟨a, b⟩≤φL\n2 ∥a∥2\n2 +\n1\n2φL∥b∥2\n2 for all a, b ∈Rn, and φ > 0; step ③uses\nmin(vt)∥dt∥≤∥dt ⊙vt∥, and Inequality (24).\nB.8. Proof of Lemma 3.13\nProof. We deﬁne Vt ≜min(vt), and Yi ≜E[∥yi+1 −yi∥2\n2].\nFirst, we have the following results:\n∥yt+1 −yt∥2\n2\n①=\n∥(xt+1 + σtdt) −(xt + σt−1dt−1)∥2\n2\n=\n∥(1 + σt)dt −σt−1dt−1∥2\n2\n②\n≤\n[(1 + τ)∥(1 + σt)dt∥2\n2 + (1 + 1/τ)∥σt−1dt−1∥2\n2], ∀τ > 0\n③\n≤\n4(1 + τ)∥dt∥2\n2 + (1 + 1/τ)∥dt−1∥2\n2,\n(25)\nwhere step ①uses yt+1 = xt+1 + σtdt; step ②uses ∥a + b∥2\n2 ≤(1 + τ)∥a∥2\n2 + (1 + 1/τ)∥b∥2\n2 for all τ > 0; step ③uses\nσt ≤θ < 1.\nSecond, we obtain the following inequalities:\nmin(vt)∥yt+1 −yt∥2\n2\n①=\nmin(vt) · [4(1 + τ)∥dt∥2\n2 + (1 + 1/τ)∥dt−1∥2\n2]\n②\n≤\n4(1 + τ) min(vt)∥dt∥2\n2 + (1 + 1/τ)¨κ min(vt−1)∥dt−1∥2\n2\n③\n≤\n(4 + ¨κ)\n\u0000min(vt)∥dt∥2\n2 + min(vt−1)∥dt−1∥2\n2\n\u0001\n,\n(26)\nwhere step ①uses Inequality (25); step ②uses min(vt) ≤min(vt−1)¨κ, as shown in Lemma 3.4(c); step ③uses the choice\nτ = ¨κ\n4 .\n\n\nPart (a). We have the following inequities:\nPT\nt=0 min(vt)∥yt+1 −yt∥2\n2\n①\n≤\n(4 + ¨κ)\n\u0010PT\nt=0 min(vt)∥dt∥2\n2 + PT\nt=0 min(vt−1)∥dt−1∥2\n2\n\u0011\n=\n(4 + ¨κ)\n\u0010PT\nt=0 min(vt)∥dt∥2\n2 + PT −1\nt=−1 min(vt)∥dt∥2\n2\n\u0011\n②=\n(4 + ¨κ)\n\u0010PT\nt=0 min(vt)∥dt∥2\n2 + PT −1\nt=0 min(vt)∥dt∥2\n2\n\u0011\n≤\n(8 + 2¨κ)\n\u0010PT\nt=0 min(vt)∥dt∥2\n2\n\u0011\n③\n≤\n(8 + 2¨κ) PT\nt=0 min(vt) ·\n1\nmin(vt)2 ∥vt ⊙dt∥2\n2\n④\n≤\n(8 + 2¨κ) · s1\n|\n{z\n}\n≜u1\n·VT +1,\n(27)\nwhere step ①uses Inequality (26); step ②uses d−1 = x0 −x−1 = 0; step ③uses min(vt)∥dt∥≤∥vt ⊙dt∥; step ④uses\nPT\nt=0 St\n1 ≤s1VT +1 with St\n1 ≜\n∥rt∥2\n2\nmin(vt), as shown in Lemma 3.7(a).\nPart (b). We obtain the following inequities:\nPT\nt=0 ∥yt+1 −yt∥2\n2\n①\n≤\nPT\nt=0\n\u00008∥dt∥2\n2 + 2∥dt−1∥2\n2\n\u0001\n②=\n8\n\u0010PT\nt=0 ∥dt∥2\n2\n\u0011\n+ 2\n\u0010PT\nt=1 ∥dt−1∥2\n2\n\u0011\n=\n8\n\u0010PT\nt=0 ∥dt∥2\n2\n\u0011\n+ 2\n\u0010PT −1\nt=0 ∥dt∥2\n2\n\u0011\n≤\n10\n\u0010PT\nt=0 ∥dt∥2\n2\n\u0011\n③\n≤\n10\n\u0010PT\nt=0\n1\nmin(vt)2 ∥vt ⊙dt∥2\n2\n\u0011\n④\n≤\n10 · s2\n| {z }\n≜u2\n·\np\nVT +1,\nwhere step ①uses Inequality (25) with τ = 1; step ②uses d−1 = x0 −x−1 = 0; step ③uses min(vt)∥dt∥≤∥vt ⊙dt∥;\nstep ④uses PT\nt=0 St\n2 ≤s2\np\nVT +1 with St\n2 ≜\n∥rt∥2\n2\nmin(vt)2 , as shown in Lemma 3.7(b).\nB.9. Proof of Lemma 3.14\nProof. We deﬁne Vt ≜min(vt), where {Vj}∞\n0 is non-decreasing. We deﬁne q′ ≜q¨κq−1.\nFor any integer t ≥0, we derive the following inequalities:\nt −(rt −1)q\n①= t −(⌊t\nq ⌋+ 1 −1)q = t −⌊t\nq⌋q\n②\n≤q −1,\n(28)\nwhere step ①uses rt ≜⌊t\nq ⌋+ 1; step ②uses the fact that t −⌊t\nq⌋q ≤q −1 for all integer t ≥0 and q ≥1.\nPart (a). For any t with t ≥(rt −1)q, we have the following results:\nmin(vt)\nmin(v(rt−1)q)\n=\nmin(v(rt−1)q+1)\nmin(v(rt−1)q) · min(v(rt−1)q+2)\nmin(v(rt−1)q+1) . . . ·\nmin(vt)\nmin(vt−1)\n①\n≤\n¨κq−1,\n(29)\n\n\nwhere step ①uses the fact that the product length is at most ([t] −[(rt −1)q + 1] + 1) and Inequality (28).\nFor all t with (rt −1)q ≤t ≤rtq −1, we have:\nPt\nj=(rt−1)q\n\u0010\nVj · Pj−1\ni=(rj−1)q Yi\n\u0011\n①\n≤\nPt\nj=(rt−1)q\n\u0010\nVj · Pt−1\ni=(rj−1)q Yi\n\u0011\n②=\nPt\nj=(rt−1)q\n\u0010\nVj · Pt−1\ni=(rt−1)q Yi\n\u0011\n③=\nPt−1\ni=(rt−1)q\n\u0010\nYi · Pt\nj=(rt−1)q Vj\n\u0011\n④\n≤\nPt−1\ni=(rt−1)q\n\u0010\nYi · Pt\nj=(rt−1)q Vt\n\u0011\n⑤\n≤\nqVt\nPt−1\ni=(rt−1)q Yi\n⑥\n≤\nq(¨κq−1V(rt−1)q) Pt−1\ni=(rt−1)q Yi\n⑦\n≤\nq¨κq−1\n| {z }\n≜q′\n· Pt−1\ni=(rt−1)q ViYi,\nwhere step ①uses j ≤t for all j ∈[(rt −1)q, t]; step ②uses rj = rt for all j ∈[(rt −1)q, t] with t ∈[(rt −1)q, rtq −1];\nstep ③uses the fact that Pj\nj=j(aj\nPi\ni=i bi) = Pi\ni=i(bi\nPj\nj=j aj) for all i ≤i and j ≤j; step ④uses Vj ≤Vt as j ≤t;\nstep ⑤uses t −(rt −1)q ≤q; step ⑥uses Inequality (29); step ⑦uses i ≥(rt −1)q.\nPart (b). For all t with (rt −1)q ≤t ≤rtq −1, we have:\nPt\nj=(rt−1)q\nPj−1\ni=(rj−1)q Yi\n①=\nPt−1\ni=(rt−1)q(t −i)Yi\n②\n≤\n([t −1] −[(rt −1)q] + 1) · Pt−1\ni=(rt−1)q Yi\n③\n≤\n(q −1) Pt−1\ni=(rt−1)q Yi,\nwhere step ①uses basic reduction; step ②uses step ②uses i ≥(rt −1)q; step ③uses Inequality (28).\nPart (c). We have the following results:\nPT\nt=0[Pt−1\ni=(rt−1)q Yi]\n①\n≤\n([t −1] −[(rt −1)q] + 1) PT\nt=0 Yt\n≤\n(q −1) PT\nt=0 Yt,\nstep ①uses the fact that the length of the summation is ([t −1] −[(rt −1)q] + 1); step ②uses Inequality (28).\nB.10. Proof of Lemma 3.15\nProof. We deﬁne Vj = min(vj) and Yi ≜E[∥yi+1 −yi∥2\n2].\nWe deﬁne St\n1 ≜\n∥rt∥2\n2\nmin(vt), and St\n2 ≜\n∥rt∥2\n2\nmin(vt)2 .\nPart (a). For all t with (rt −1)q ≤t ≤rtq −1, we have from Lemma 3.12:\nZt+1 −Zt ≤E[c′\n2 ·\n1\nmin(vt)2 ∥rt∥2\n2\n|\n{z\n}\n≜St\n2\n−\nc1\nmin(vt)∥rt∥2\n2 + c3\nq · Pt−1\ni=(rt−1)q Yi].\n(30)\nMultiplying both sides by min(vt) yields:\n0 ≤min(vt)[Zt −Zt+1] + E[c′\n2 ·\n1\nmin(vt)∥rt∥2\n2\n|\n{z\n}\n≜St\n1\n−c1∥rt∥2\n2 + c3\nq · min(vt) · Pt−1\ni=(rt−1)q Yi].\n(31)\n\n\nTelescoping Inequality (31) over t from (rt −1)q to t with t ≤rtq −1, we have:\n0\n≤\nPt\nj=(rt−1)q\n\u0000Vj(Zj −Zj+1) + E[c′\n2St\n1 −c1∥rj∥2\n2]\n\u0001\n+ c3\nq\nPt\nj=(rt−1)q[Vj · Pj−1\ni=(rj−1)q Yi]\n①\n≤\nPrtq−1\nj=(rt−1)q\n\u0010\nVj(Zj −Zj+1) + E[c′\n2St\n1 −c1∥rj∥2\n2 + c3\nq · q′ · VjYj]\n\u0011\n|\n{z\n}\n≜Uj\n,\nwhere step ①uses Lemma 3.14(a). We further derive the following results:\nrt = 1, 0 ≤Pq−1\nj=0 Uj\nrt = 2, 0 ≤P2q−1\nj=q Uj\nrt = 3, 0 ≤P3q−1\nj=2q Uj\n. . .\nrt = s, 0 ≤Psq−1\nj=sq Uj.\nAssume that T = sq, where s ≥0 is an integer. Summing all these inequalities together yields:\n0\n≤\nPT −1\nt=0 Ut\n①=\nPT −1\nt=0 Vt(Zt −Zt+1) + c′\n2E[PT −1\nt=0 St\n1] −c1E[PT −1\nt=0 ∥rt∥2\n2\n|\n{z\n}\n≜RT −1\n] + c3\nq · q′ · PT −1\nt=0 VtYt\n②\n≤\nVT −1[maxT −1\nt=0 Zt] + c′\n2s1E[VT ] −c1E[RT −1] + c3\nq · q′ · PT −1\nt=0 VtYt\n③\n≤\nVT [maxT −1\nt=0 Zt] + c′\n2s1E[VT ] −\nc1\nα+β E[V2\nT −v2] + c3\nq · q′ · u1 · E[VT −1]\n④\n≤\nE[VT ][maxT −1\nt=0 Zt] + c′\n2s1E[VT ] −\nc1\nα+β (E[VT ])2 +\nc1\nα+β v2 + c3\nq · q′ · u1 · E[VT ],\n(32)\nwhere step ①uses the deﬁnition of Ut; step ②uses Lemma A.4, and Lemma 3.7(a); step ③uses the upper bound for RT\nthat RT ≜(V2\nT +1 −v2)/(α + β), as shown in Lemma 3.4(a); step ④uses Vt+1 ≤vt+1 ≤Vt+1 (as shown in Lemma\n3.4(a)), and the fact that (E[v])2 ≤E[v2] for any random variable v (which is a direct consequence of the Cauchy-Schwarz\ninequality in probability theory).\nWe have from Inequality (32):\nc1\nα+β(E[VT ])2 ≤\n\u0010\nc3\nq q′u1 + [maxT −1\nt=0 Zt] + c′\n2s1\n\u0011\n· E[VT ] +\nc1\nα+β v2.\nBy applying Lemma A.3 with the parameters a =\nc1\nα+β , b = c3\nq q′u1 + [maxT −1\nt=0 Zt] + c′\n2s1, c =\nc1\nα+β v2, and x = E[VT ],\nwe have, for all T ≥0:\nE[VT ]\n≤\np\nc/a + b/a = v + α+β\nc1\n· ( c3\nq q′u1 + [\nT −1\nmax\nt=0 Zt] + c′\n2s1)\n=\np\nc/a + b/a = v + α+β\nc1\n· ( c3\nq q′u1 + c′\n2s1)\n|\n{z\n}\n≜w1\n+ α+β\nc1\n|{z}\n≜w2\n·[\nT −1\nmax\nt=0 Zt].\n(33)\nThe upper bound for E[VT ] is established in Inequality (33); however, it involves an unknown variable (maxT −1\nt=0 Zt).\nPart (b). We now prove that (maxT −1\nt=0 Zt) is always bounded above by a universal constant Z. Dropping the negative\nterm −\nc1\nmin(vt)∥rt∥2\n2 on the right-hand side of Inequality (30), and summing over t from (rt −1)q to t where t ≤rtq −1\nyields:\n0\n≤\nE[Pt\nj=(rt−1)q (Zj −Zj+1 + c′\n2St\n2) + c3\nq\nPt\nj=(rt−1)q\nPj−1\ni=(rj−1)q Yi]\n①\n≤\nE[Pt\nj=(rt−1)q[Zj −Zj+1] + c′\n2St\n2 + c3\nq−1\nq\nPt\nj=(rt−1)q Yi]\n≤\nE[Pt\nj=(rt−1)q [Zj −Zj+1] + c′\n2St\n2 + c3\nPt\nj=(rt−1)q Yi\n|\n{z\n}\n≜Ki\n],\n\n\nwhere step ①uses Lemma 3.14(b). We further derive the following results:\nrt = 1, 0 ≤E[Pq−1\nj=0 Kj]\nrt = 2, 0 ≤E[P2q−1\nj=q Kj]\nrt = 3, 0 ≤E[P3q−1\nj=2q Kj]\n. . .\nrt = s, 0 ≤E[Psq−1\nj=sq Kj].\nAssume that T = sq, where s ≥0 is an integer. Summing all these inequalities together yields:\nZT\n≤\nZT + E[PT −1\nt=0 Kt]\n①=\nZT + E[PT −1\nt=0 (Zt −Zt+1)] + c′\n2E[PT −1\nt=0 St\n2] + c3\nPT −1\nt=0 Yt]\n②\n≤\nZT + (Z0 −ZT ) + c′\n2s2E[√VT ] + c3u2E[√VT ]\n=\nZ0 + (c′\n2s2 + c3u2) · E[√VT ]\n③\n≤\nZ0 + (c′\n2s2 + c3u2) ·\np\nE[VT ]\n④\n≤\nZ0 + (c′\n2s2 + c3u2) ·\nq\nw1 + w2 maxT −1\nt=0 Zt\n⑤\n≤\nZ0 + (c′\n2s2 + c3u2) · √w1\n|\n{z\n}\n≜˙a\n+ (c′\n2s2 + c3u2) · √w2\n|\n{z\n}\n≜˙b\n·\nq\nmaxT −1\nt=0 Zt\n⑥\n≤\nmax(Z0, 2˙b2 + 2˙a) = 2˙b2 + 2˙a ≜Z,\n(34)\nwhere step ①uses the deﬁnition of Kt; step ②uses PT\nt=0 S2\nt ≤s2\np\nVT +1 (as shown in Lemma 3.7(b)), and PT −1\nt=0 Yt ≤\nu2E[\np\nVT +1] (as shown in Lemma 3.13(b)); step ③uses E[√x] ≤\np\nE[x] for all x ≥0, which can be derived by Jensen’s\ninequality for the convex function f(x) = −√x with x ≥0; step ④uses Inequality (33); step ⑤uses\n√\na + b ≤√a +\n√\nb\nfor all a, b ≥0; step ⑥uses Lemma A.7.\nPart (c). Finally, we derive the following inequalities for all T ≥0:\nE[VT ]\n①\n≤\nw1 + w2 · [maxT\nt=0 Zt]\n②\n≤\nw1 + w2Z ≜v,\nwhere step ①uses Inequality (33); step ②uses Inequality (34).\nB.11. Proof of Theorem 3.16\nProof. We deﬁne Yi ≜E[∥yi+1 −yi∥2\n2].\nPart (a). We have the following inequality:\nE[PT\nt=0 ∥xt+1 −xt∥2\n2]\n≤\n1\nv2 1\nα(v2 −v2) ≜X,\n(35)\nwhere we employ the same strategies used in deriving Inequality (20).\nPart (b). First, we have the following inequalities:\nPT\nt=0 E[∥gt −∇f(yt)∥2\n2]\n①\n≤\nPT\nt=0\n\u0010\nL2\nb\nPt−1\ni=(rt−1)q Yi\n\u0011\n②\n≤\nL2\nb · (q −1) · PT\nt=0 Yi\n③\n≤\nL2\nb · (q −1) · u2\np\nVT +1\n④\n≤\nL2\nb · (q −1) · u2\n√\nV = O(1),\n(36)\n\n\nwhere step ①uses Lemma 3.12(a); step ②uses Lemma 3.14(c); step ③uses Lemma 3.13(b); step ④uses Vt ≤V for all t.\nSecond, we obtain the following results:\nPT\nt=0 ∥yt −xt+1∥2\n2\n①=\nPT\nt=0 ∥xt + σt−1(xt −xt−1) −xt+1∥2\n2\n②\n≤\nPT\nt=0(∥xt −xt+1∥2\n2 + ∥xt −xt−1∥2\n2)\n=\nPT\nt=0 ∥xt −xt+1∥2\n2 + PT −1\nt=−1 ∥xt+1 −xt∥2\n2\n③\n≤\n2 PT\nt=0 ∥xt −xt+1∥2\n2\n④\n≤\n2X = O(1),\n(37)\nwhere step ①uses yt = xt + σt−1(xt −xt−1); step ②uses σt−1 ≤1 for all t; step ③uses x−1 = x0; step ④uses\nInequality (35),\nThird, we have the following inequalities:\nE[PT\nt=0 ∥∂h(xt+1) + ∇f(xt+1)∥2\n2]\n①=\nE[PT\nt=0 ∥∇f(xt+1) −gt −vt ⊙(xt+1 −yt)∥2\n2]\n=\nE[PT\nt=0 ∥[∇f(xt+1) −∇f(yt)] + [∇f(yt) −gt] −vt ⊙(xt+1 −yt)∥2\n2]\n②\n≤\n3E[PT\nt=0 ∥∇f(xt+1) −∇f(yt)∥2\n2 + PT\nt=0 ∥∇f(yt) −gt∥2\n2 + PT\nt=0 ∥vt ⊙(xt+1 −yt)∥2\n2]\n③\n≤\nE[3L PT\nt=0 ∥xt+1 −yt∥2\n2 + 3 PT\nt=0 ∥∇f(yt) −gt∥2\n2 + 3v PT\nt=0 ∥xt+1 −yt∥2\n2]\n③\n≤\nO(1) + O(1) + O(1) = O(1),\n(38)\nwhere step ①uses the ﬁrst-order necessarily optimality condition that 0 ∈∂h(xt+1) + gt + vt ⊙(xt+1 −yt); step ②uses\n∥a + b + c∥2\n2 ≤3(∥a∥2\n2 + ∥b∥2\n2 + ∥c∥2\n2) for all a, b, c ∈Rn; step ③uses Inequalities (37) and (36).\nFourth, using the inequality ∥a∥2\n2 ≥\n1\nT +1(∥a∥1)2 for all a ∈RT +1, we deduce from Inequality (38) that\nE[\n1\nT +1\nPT\nt=0 ∥∂h(xt+1) + ∇f(xt+1)∥] = O(\n1\n√T +1).\nIn other words, there exists ¯t ∈[T ] such that E[∥∇f(x¯t) + ∂h(x¯t)∥] ≤ǫ, provided T ≥\n1\nǫ2 .\nPart (c). Let b denote the mini-batch size, and q the frequency parameter of AAPG-SPIDER. Assume the algorithm\nconverges in T = O( 1\nǫ2 ) iteration. When mod(t, q) = 0, the full-batch gradient ∇f(yt) is computed in O(N) time,\noccurring ⌈T\nq ⌉times; when mod(t, q) ̸= 0, the mini-batch gradient is computed in b time, occurring (T −⌈T\nq ⌉) times.\nHence, the total stochastic ﬁrst-order oracle complexity is:\nN · ⌈T\nq ⌉+ b · (T −⌈T\nq ⌉)\n≤\nN · T +q\nq\n+ b · T\n①\n≤\nN · T +\n√\nN\n√\nN\n+\n√\nN · T\n②=\n√\nN · O( 1\nǫ2 ) + N +\n√\nN · O( 1\nǫ2 ),\nwhere step ①uses the choice that q = b =\n√\nN; step ②uses T = O( 1\nǫ2 ).\nC. Proof for Section 4\nC.1. Proof of Lemma 4.4\nProof. We deﬁne Wt = {xt, xt−1, σt−1, vt}, and W ≜{x, x−, σ, v}.\n\n\nWe deﬁne Z(x, x′, σ, v) ≜F(x) −F(¯x) + 1\n2∥x −x′∥2\nσ(v+L).\nFirst, we derive the following inequalities:\n∥∂xZ(Wt+1)∥\n①=\n∥∇f(xt+1) + ∂h(xt+1) + σt(xt+1 −xt) ⊙(vt+1 + L)∥\n②=\n∥∇f(xt+1) −∇f(yt) −vt ⊙(xt+1 −yt) + σt(xt+1 −xt) ⊙(vt+1 + L)∥\n③\n≤\n(L + max(vt))∥xt+1 −yt∥+ (L + max(vt+1))∥xt+1 −xt∥\n④\n≤\n(L + V)(∥xt+1 −yt∥+ ∥xt+1 −xt∥)\n⑤=\n(L + V)(∥xt+1 −xt −σt−1(xt −xt−1)∥+ ∥xt+1 −xt∥)\n⑥\n≤\n(L + V)(∥xt −xt−1∥+ 2∥xt+1 −xt∥),\n(39)\nwhere step ①uses the deﬁnition of Z(·, ·, ·, ·); step ②uses the ﬁrst-order necessarily condition of xt+1 that xt+1 ∈\nProxh(y −∇f(yt) ÷ vt; vt) = arg minx h(x) + 1\n2∥x −(y −∇f(yt) ÷ vt)∥2\nvt, which leads to:\n0 ∈∂h(xt+1) + ∇f(yt) + vt ⊙(xt+1 −yt);\nstep ③uses L-smoothness of f(x), and σt ≤1; step ④uses max(vt) ≤V, as shown in Lemma 3.8; step ⑤uses\nyt = xt + σt−1(xt −xt−1); step ⑥uses σt ≤1.\nSecond, we obtain the following result:\n∥∂x′Z(Wt+1)∥+ |∂σZ(Wt+1)| + ∥∂vZ(Wt+1)∥\n①=\n\u0000σt∥(xt −xt+1) ⊙(vt+1 + L)∥\n\u0001\n+\n\u0000 1\n2∥xt −xt+1∥2\nvt+1\n\u0001\n+\n\u0010\nσt\n2 (xt −xt+1) ⊙(xt −xt+1)\n\u0011\n②\n≤\n(L + V)∥xt −xt+1∥+ 1\n2V2x∥xt −xt+1∥+ 1\n22x∥xt −xt+1∥\n=\n(L + V + Vx + x)∥xt −xt+1∥,\n(40)\nwhere step ①uses the deﬁnition of Z(·, ·, ·, ·); step ②uses max(vt) ≤V, and σt ≤1.\nFinally, we have:\n∥∂Z(Wt+1)∥\n=\nq\n∥∂xZ(Wt+1)∥2\n2 + ∥∂x′Z(Wt+1)∥2\n2 + |∂σZ(Wt+1)|2 + ∥∂vZ(Wt+1)∥2\n2\n①\n≤\n∥∂xZ(Wt+1)∥+ ∥∂x′Z(Wt+1)∥+ |∂σZ(Wt+1)| + ∥∂vZ(Wt+1)∥\n②\n≤\n2(L + V)∥xt+1 −xt∥+ (2L + 2V + Vx + x)∥xt −xt+1∥\n③\n≤\nϑ∥xt+1 −xt∥+ ϑ∥xt −xt+1∥,\nwhere step ①uses ∥x∥≤∥x∥1 for all x ∈R4; step ②uses Inequalities (39) and (40); step ③uses the choice ϑ ≜\n2L + 2V + Vx + x.\nC.2. Proof of Theorem 4.7\nProof. We deﬁne Wt = {xt, xt−1, σt−1, vt}, and W ≜{x, x−, σ, v}.\nWe deﬁne Z(W) ≜F(x) −F(¯x) + 1\n2∥x −x−∥2\nσ(v+L), and Z(Wt) ≜F(xt) −F(¯x) + 1\n2∥xt −xt−1∥2\nσt−1(vt+L).\nWe deﬁne Zt ≜Z(Wt) and Z∞≜Z(W∞).\nWe deﬁne ξ ≜c1 min(vt⋆) −c2 > 0. We assume that t ≥t⋆.\n\n\nFirst, since the desingularization function ϕ(·) is concave, we have: ϕ(b) −ϕ(a) + (a −b)ϕ′(a) ≤0. Applying this\ninequality with a = Zt −Z∞and b = Zt+1 −Z∞, we have:\n0\n≥\n[Zt −Zt+1] · ϕ′(Zt −Z∞) + ϕ(Zt+1 −Z∞) −ϕ(Zt −Z∞)\n|\n{z\n}\n≜ϕt+1−ϕt\n①\n≥\n[Zt −Zt+1] ·\n1\ndist(0,∂Z(Wt)) + ϕt+1 −ϕt\n②\n≥\n[Zt −Zt+1] ·\n1\nϑ(∥xt−xt−1∥+∥xt−1−xt−2∥) + ϕt+1 −ϕt,\n(41)\nwhere step ①uses Lemma 4.2 that\n1\nϕ′(Z(Wt)−Z(W∞)) ≤dist(0, ∂Z(Wt)), which is due to our assumption that Z(W) is a\nKL function; step ②uses Lemma 4.4 that ∥∂Z(Wt+1)∥≤ϑ(∥xt+1 −xt∥+ ∥xt −xt−1∥).\nPart (a). We derive the following inequalities:\n∥xt+1 −xt∥2\n2\n①\n≤\n1\nmin(vt)2 · ∥vt ⊙(xt+1 −xt)∥2\n2\n②\n≤\n1\nξ min(vt)2 · ∥rt∥2\n2 · ξ\n③=\n1\nξ min(vt)2 · ∥rt∥2\n2 · (c1 min(vt⋆) −c2)\n④\n≤\n1\nξ min(vt)2 · ∥rt∥2\n2 · (c1 min(vt) −c2)\n⑤=\n1\nξ\n\u0010\nc1∥rt∥2\n2\nmin(vt) −\nc2∥rt∥2\n2\nmin(vt)2\n\u0011\n= 1\nξ\n\u0000c1St\n1 −c2St\n2\n\u0001\n⑥\n≤\n1\nξ\n\u0000Zt −Zt+1\u0001\n= 1\nξ\n\u0000Z(Wt) −Z(Wt+1)\n\u0001\n⑦\n≤\nϑ\nξ (ϕt −ϕt+1) · (∥xt −xt−1∥+ ∥xt−1 −xt−2∥),\n(42)\nwhere step ①uses ∥dt∥min(vt) ≤∥dt ⊙vt∥; step ②uses vt ⊙(xt+1 −xt) = vt; step ③uses the deﬁnition of ξ; step\n④uses t ≥t⋆; step ⑤uses the deﬁnitions of {St\n2, St\n1}; step ⑥uses Lemma 3.6 with gt = ∇f(yt); step ⑦uses Inequality\n(41).\nPart (b). In view of Inequality (42), we apply Lemma A.8 with Pt = ϑ\nξ ϕt (satisfying Pt ≥Pt+1). Then for all i ≥t,\nSt ≜P∞\nj=t Xj+1 ≤̟(Xt + Xt−1) + ̟ϕt,\nwhere ̟ = max(1, 4ϑ\nξ ).\nPart (c). For any T ≥t ≥0, we have:\n∥xt −xT ∥\n①\n≤PT −1\nj=t ∥xj −xj+1∥,\nwhere step ①uses the triangle inequality. Letting T →∞yields: ∥xt −x∞∥≤P∞\nj=t ∥xj −xj+1∥= P∞\nj=t Xj+1 = St.\nC.3. Proof of Theorem 4.8\nProof. We deﬁne ϕt ≜ϕ(st), where st ≜Z(Wt) −Z(W∞).\nWe deﬁne Xt+1 ≜∥xt+1 −xt∥, and Si = P∞\nj=i Xj+1.\nFirst, Theorem 4.7(c) implies that establishing the convergence rate of ST is sufﬁcient to demonstrate the convergence of\n∥xT −x∞∥.\nSecond, we obtain the following results:\n1\nϕ′(st)\n①\n≤\n∥∂Z(Wt)∥F\n②\n≤\nϑ(∥xt −xt−1∥+ ∥xt−1 −xt−2∥),\n(43)\n\n\nwhere step ①uses uses Lemma 4.2 that ϕ′(Z(Wt) −Z(W∞)) · ∥∂Z(Wt)∥≥1; step ②uses Lemma 4.4.\nThird, using the deﬁnition of St, we derive:\nSt\n≜\nP∞\nj=t Xj+1\n①\n≤\n̟(Xt + Xt−1) + ̟ · ϕt\n②=\n̟(Xt + Xt−1) + ̟ · ˜c · {[st]˜σ}\n1−˜σ\n˜σ\n③=\n̟(Xt + Xt−1) + ̟ · ˜c · {˜c(1 −˜σ) ·\n1\nϕ′(st)}\n1−˜σ\n˜σ\n④\n≤\n̟(Xt + Xt−1) + ̟ · ˜c · {˜c(1 −˜σ) · ϑ · (Xt + Xt−1)}\n1−˜σ\n˜σ\n⑤=\n̟(Xt + Xt−1) + ̟ · ˜c · {˜c(1 −˜σ) · ϑ · (St−2 −St)}\n1−˜σ\n˜σ\n=\n̟(St−2 −St) + ̟ · ˜c · [˜c(1 −˜σ)ϑ]\n1−˜σ\n˜σ\n|\n{z\n}\n≜¨κ\n·{St−2 −St}\n1−˜σ\n˜σ ,\n(44)\nwhere step ①uses Theorem 4.7(b); step ②uses the deﬁnitions that ϕt ≜ϕ(st), and ϕ(s) = ˜cs1−˜σ; step ③uses ϕ′(s) =\n˜c(1 −˜σ) · [s]−˜σ, leading to [st]˜σ = ˜c(1 −˜σ) ·\n1\nϕ′(st); step ④uses Inequality (43); step ⑤uses the fact that Xt = St−1 −St,\nresulting in St−2 −St = (St−1 −St) + (St−2 −St−1) = Xt −Xt−1.\nFinally, we consider three cases for ˜σ ∈[0, 1).\nPart (a). We consider ˜σ = 0. We have the following inequalities:\nϑ(∥xt −xt−1∥+ ∥xt−1 −xt−2∥)\n①\n≥\n1\nϕ′(st)\n②=\n1\n˜c(1−˜σ)·[st]−˜σ\n③= 1\n˜c,\n(45)\nwhere step ①from Inequality (43); step ②uses ϕ′(s) = ˜c(1 −˜σ) · [s]−˜σ; step ③uses ˜σ = 0.\nSince ∥xt −xt−1∥+ ∥xt−1 −xt−2∥→0, and ϑ, c > 0, Inequality (45) results in a contradiction (∥xt −xt−1∥+ ∥xt−1 −\nxt−2∥) ≥\n1\n˜cϑ > 0. Therefore, there exists t′ such that ∥xt −xt−1∥= 0 for all t > t′ > t⋆, ensuring that the algorithm\nterminates in a ﬁnite number of steps.\nPart (b). We consider ˜σ ∈(0, 1\n2]. We deﬁne u ≜1−˜σ\n˜σ\n∈[1, ∞).\nWe have: St−2 −St = Xt + Xt−1 = ∥xt −xt−1∥+ ∥xt−1 −xt−2∥≤4x ≜R.\nFor all t ≥t′ > t⋆, we have from Inequality (44):\nSt\n≤\n̟(St−2 −St) + (St−2 −St)\n1−˜σ\n˜σ\n· ¨κ\n①\n≤\n̟(St−2 −St) + (St−2 −St) · Ru−1 · ¨κ\n|\n{z\n}\n≜˜κ\n≤\nSt−2 ·\n˜κ+̟\n˜κ+̟+1,\n(46)\nwhere step ①uses the fact that xu\nx ≤Ru−1 for all u ≥1, and x ∈(0, R]. By induction we obtain for even indices\nS2T ≤S0 ·\n\u0010\n˜κ+̟\n˜κ+̟+1\n\u0011T\n,\nand similarly for odd indices (up to a constant shift). In other words, the sequence {St}∞\nt=0 converges Q-linearly at the rate\nSt = O( ˙ςt), where ˙ς ≜\nq\n˜κ+̟\n˜κ+̟+1.\nPart (c). We consider ˜σ ∈( 1\n2, 1). We deﬁne u ≜1−˜σ\n˜σ\n∈(0, 1), and ς ≜\n1−˜σ\n2˜σ−1 > 0.\nWe have: St−2 −St = Xt + Xt−1 = ∥xt −xt−1∥+ ∥xt−1 −xt−2∥≤4x ≜R.\nWe obtain: St−1 −St = Xt∥xt −xt−1∥≤2x < R.\n\n\nFor all t ≥t′ > t⋆, we have from Inequality (44):\nSt\n≤\n¨κ · (St−2 −St)\n1−˜σ\n˜σ\n+ ̟(St−2 −St)\n①=\n¨κ(St−2 −St)u + ̟(St−2 −St)u · (Xt)1−u\n②\n≤\n¨κ(St−2 −St)u + ̟(St−2 −St)u · R1−u\n=\n(St−2 −St)u · (¨κ + ̟R1−u)\n|\n{z\n}\n≜˙κ\n③\n≤\nO(T −\nu\n1−u ) = O(T −ς),\nwhere step ①uses the deﬁnition of u and the fact that St−1 −St = Xt; step ②uses the fact that maxx∈(0,R] x1−u ≤R1−u\nif u ∈(0, 1) and R > 0; step ③uses Lemma A.11 with c = ˙κ.\nC.4. Proof of Theorem 4.12\nProof. We deﬁne Wt = {xt, xt−1, σt−1, vt}, and W ≜{x, x−, σ, v}.\nWe deﬁne Z(W) ≜Z(x, x−, σ, v) ≜F(x) −F(¯x) + 1\n2∥x −x−∥2\nσ(v+L).\nWe deﬁne Zt ≜Z(Wt) ≜Z(xt, xt−1, σt−1, vt) ≜F(xt) −F(¯x) + 1\n2∥xt −xt−1∥2\nσt−1(vt+L).\nWe deﬁne Xi ≜\nqPiq−1\nj=iq−q ∥xj+1 −xj∥2\n2.\nWe deﬁne ξ ≜c1 min(vt⋆) −c′\n2 −3ξ′ > 0, where ξ′ ≜5c3.\nWe deﬁne rt ≜(rt −1)q, and rt ≜rtq −1. We assume that q ≥2.\nWe deﬁne St\n1 ≜\n∥rt∥2\n2\nmin(vt), St\n2 ≜\n∥rt∥2\n2\nmin(vt)2 .\nFirst, since ϕ(·) is a concave desingularization function, we have: ϕ(b) + (a −b)ϕ′(a) ≤ϕ(a). Applying the inequality\nabove with a = Zt −Z∞and b = Zt+1 −Z∞, we have:\nϕ(Zt −Z∞) −ϕ(Zt+1 −Z∞) ≜ϕt −ϕt+1\n≥\n(Zt −Zt+1) · ϕ′(Zt −Z∞)\n①\n≥\n(Zt −Zt+1) ·\n1\ndist(0,∂Z(Wt))\n②\n≥\n(Zt −Zt+1) ·\n1\nϑ(∥xt−xt−1∥+∥xt−1−xt−2∥),\n(47)\nstep ①uses the inequality that\n1\nϕ′(Z(Wt)−Z(W∞)) ≤dist(0, ∂Z(Wt)), which is due to Lemma 4.2 since Z(W) is a KL\nfunction by our assumption; step ②uses Lemma 4.4.\nSecond, we have the following inequalities:\n∥yt+1 −yt∥2\n2\n=\n∥(xt+1 + σtdt) −(xt + σt−1dt−1)∥2\n2\n=\n∥xt+1 −xt + σtdt −σt−1dt−1∥2\n2\n=\n∥(1 + σt)dt −σt−1dt−1∥2\n2\n①\n≤\n(1 + τ)(1 + σt)2∥dt∥2\n2 + (1 + 1/τ)∥σt−1dt−1∥2\n2, ∀τ > 0\n②\n≤\n5∥dt∥2\n2 + 5∥dt−1∥2\n2,\n(48)\nwhere step ①uses ∥a + b∥2\n2 ≤(1 + τ)∥a∥2\n2 + (1 + 1/τ)∥b∥2\n2 for all τ > 0; step ②uses τ = 1/4 and σt ≤1.\n\n\nPart (a). For all t with rt ≤t ≤rt, we have from Lemma 3.12:\nZt+1 −Zt\n≤\n−c1∥rt∥2\n2\nmin(vt)\n| {z }\n=c1St\n1\n+ c′\n2∥rt∥2\n2\nmin(vt)2\n|\n{z\n}\n=c′\n2St\n2\n+ c3\nq\nPt−1\ni=(rt−1)q E[∥yi+1 −yi∥2\n2]\n①\n≤\n−\n\u0010\nc1 min(vt⋆)∥rt∥2\n2\nmin(vt)2\n−\nc′\n2∥rt∥2\n2\nmin(vt)2\n\u0011\n+ c3\nq\nPt−1\ni=(rt−1)q E[∥yi+1 −yi∥2\n2]\n②=\n−(ξ + 3ξ′) ·\n∥rt∥2\n2\nmin(vt)2 + c3\nq\nPt−1\ni=(rt−1)q E[∥yi+1 −yi∥2\n2]\n③\n≤\n−(ξ + 3ξ′) · ∥dt∥2\n2 + c3\nq\nPt−1\ni=(rt−1)q E[∥yi+1 −yi∥2\n2],\n(49)\nwhere step ①uses the deﬁnition of min(vt) ≥min(vt⋆) for all t ≥t⋆; step ②uses the deﬁnition of ξ ≜c1 min(vt⋆) −\nc′\n2 −3ξ′ > 0, which leads to c1 min(vt⋆) −c′\n2 = ξ + 3ξ′; step ③uses ∥rt∥= ∥vt ⊙dt∥≥min(vt)∥dt∥.\nTelescoping Inequality (49) over t from rt to rt, we have:\nZ\n≜\nPrt\nj=rt E[Zj −Zj+1]\n≥\n(ξ + 3ξ′) Prt\nj=rt ∥dj∥2\n2 −c3\nq\nPrt\nj=rt\nPj−1\ni=(rj−1)q E[∥yi+1 −yi∥2\n2]\n①\n≥\n(ξ + 3ξ′) Prt\nj=rt ∥dj∥2\n2 −5c3\nPrt\nj=rt(∥dj∥2\n2 + ∥dj−1∥2\n2)\n②=\n(ξ + 2ξ′) Prt\nj=rt ∥dj∥2\n2 −ξ′ Prt\nj=rt ∥dj−1∥2\n2\n=\n(ξ + 2ξ′) Prt\nj=rt ∥dj∥2\n2 −ξ′ Prt−1\nj=rt−1 ∥dj∥2\n2\n=\n−ξ′∥drt−1∥2\n2 + (ξ + 2ξ′)∥drt∥2\n2 + (ξ + 2ξ′ −ξ′) Prt−1\nj=rt ∥dj∥2\n2\n③\n≥\n−ξ′∥drt−1∥2\n2 + [min(ξ + 2ξ′, ξ + 2ξ′ −ξ′) Prt\nj=rt ∥dj∥2\n2]\n④\n≥\n−ξ′ Prt−q\nj=rt−q ∥dj∥2\n2\n|\n{z\n}\n≜(Xrt−1)2\n+(ξ + ξ′) · [Prt\nj=rt ∥dj∥2\n2]\n|\n{z\n}\n≜(Xrt)2\n=\n−ξ′(X2\nrt−1 −X2\nrt) + ξX2\nrt,\n(50)\nwhere step ①uses Lemma 3.14(b) and q−1 < q; step ②uses ξ′ ≜5c3; step ③uses the fact that ab+cd ≥min(a, c)(b+d)\nfor all a, b, c, d ≥0; step ④uses ∥drt−1∥2\n2 = Prt−1\nj=rt−1 ∥dj∥2\n2 ≤Prt−q\nj=rt−q ∥dj∥2\n2 since rt−1 = rt−q and rt−1 ≥rt−q.\nNow now focus on the upper bound for Z in Inequality (50). We derive:\nZ\n≜\nPrt\nj=rt E[Zj −Zj+1] = Prt\nj=rt[Z(Wj) −Z(Wj+1)]\n①\n≤\nϑ · Prt\nj=rt(ϕj −ϕj+1) · (∥xj −xj−1∥+ ∥xj−1 −xj−2∥)\n②\n≤\nϑ√q · (Prt\nj=rt(ϕj −ϕj+1)) · (Prt\nj=rt ∥xt −xt−1∥+ Prt\nj=rt ∥xt−1 −xt−2∥)\n③=\nϑ√q · (ϕrt −ϕrt+1) · (Prt−1\nj=rt−1 ∥dt∥+ Prt−2\nj=rt−2 ∥dt∥)\n④=\nϑ√q · (ϕ(rt−1)q −ϕrtq) ·\n\u0010\n(2[Prt−2\nj=rt ∥dt∥] + ∥drt−1∥) + ∥drt−2∥+ 2∥drt−1∥\n\u0011\n⑤\n≤\nϑ√q · (ϕ(rt−1)q −ϕrtq) ·\n\u0010\n2[Prt\nj=rt ∥dt∥] + ∥drt−2∥+ 2∥drt−1∥\n\u0011\n≤\nϑ√q · (ϕ(rt−1)q −ϕrtq) ·\n\u0010\n2[Prt\nj=rt ∥dt∥] + 2[Prt−1\nj=rt−2 ∥dj∥]\n\u0011\n⑥=\nϑ√q · (ϕ(rt−1)q −ϕrtq) · 2\n\u0010\n[Prt\nj=rt ∥dt∥] + [Prt−p\nj=rt−p ∥dj∥]\n\u0011\n⑦=\nϑ√q · (ϕ(rt−1)q −ϕrtq) · 2√q · (\nqPrt\nj=rt ∥dt∥2\n2\n|\n{z\n}\n≜Xrt\n+\nqPrt−q\nj=rt−q ∥dt∥2\n2\n|\n{z\n}\n≜Xrt−1\n),\n(51)\n\n\nwhere step ①uses Inequality (47); step ②uses ⟨a, b⟩≤√q∥a∥1∥b∥1 for all a, b ∈Rq; step ③uses dt = xt+1 −xt; step\n④uses rt ≜(rt −1)q, and rt ≜rtq −1; step ⑤uses (2[Prt−2\nj=rt ∥dt∥] + ∥drt−1∥) ≤2[Prt−1\nj=rt ∥dt∥] ≤2[Prt\nj=rt ∥dt∥];\nstep ⑥uses rt −1 = rt −p and p ≥2; step ⑦uses ∥a∥1 ≤√q∥a∥for all a ∈Rq.\nCombining Inequalities (50) and (51) yields:\nX2\nrt + ξ′\nξ (X2\nrt −X2\nrt−1) ≤2qϑ\nξ\n· (ϕ(rt−1)q −ϕrtq)(Xrt −Xrt−1).\nPart (b). Applying Lemma A.9 with j = rt, Pjq = 2qϑ\nξ ϕjq with Pt ≥Pt+1, we have:\n∀i ≥1, P∞\nt=i Xt\n|\n{z\n}\n≜Si\n≤16( ξ′\nξ + 1)\n|\n{z\n}\n≜̟\n·Xi−1 + 16( ξ′\nξ + 1)\n|\n{z\n}\n≜̟\n·ϕ(i−1)q.\nPart (c). We let Xi ≜\nqPiq−1\nj=iq−q ∥xj+1 −xj∥2\n2, St ≜P∞\nj=t Xj. For any s > i ≥1, we have:\n∥xiq −xsq∥\n①\n≤\nPsq−1\nj=iq ∥xj+1 −xj∥\n②=\nPs−i\nk=1\n\u0010P(k+i)q−1\nl=(k+i)q−q ∥xl+1 −xl∥\n\u0011\n③\n≤\n√q Ps−i\nk=1\nqP(k+i)q−1\nl=(k+i)q−q ∥xl+1 −xl∥2\n2\n|\n{z\n}\n≜Xk+i\n=\n√q Ps−i\nk=1 Xk+i\n=\n√q Ps\nk=1+i Xk,\nwhere step ①uses the triangle inequality; step ②uses basic reduction; step ③uses ∥x∥1 ≤√q∥x∥for all x ∈Rq. Letting\ns →∞yields:\n∥xiq −x∞∥≤√q P∞\nk=1+i Xk = √qSi+1.\nC.5. Proof of Theorem 4.13\nProof. We deﬁne ϕt ≜ϕ(st), where st ≜Z(Wt) −Z(W∞).\nWe let Xi ≜\nqPiq−1\nj=iq−q ∥xj+1 −xj∥2\n2, St ≜P∞\nj=t Xj.\nSecond, we obtain the following results:\n1\nϕ′(s(t−1)q)\n①\n≤\n∥∂Z(W(t−1)q)∥F\n②\n≤\nϑ(∥x(t−1)q −x(t−1)q−1∥+ ∥x(t−1)q−1 −x(t−1)q−2∥)\n(52)\n=\nϑ P(t−1)q−1\nj=(t−1)q−2 ∥xj+1 −xj∥\n③\n≤\nϑ P(t−1)q−1\nj=(t−1)q−q ∥xj+1 −xj∥\n④\n≤\nϑ√q ·\nqP(t−1)q−1\nj=(t−1)q−q ∥xj+1 −xj∥2\n2\n|\n{z\n}\n≜Xt−1\n,\n(53)\nwhere step ①uses Lemma 4.2 that ϕ′(Z(Wt) −Z(W∞)) · ∥∂Z(Wt)∥≥1; step ②uses Lemma 4.4; step ③uses q ≥2;\nstep ④uses ∥x∥1 ≤√q∥x∥for all x ∈Rq.\n\n\nThird, using the deﬁnition of St, we derive:\nSt\n≜\nP∞\nj=t Xj\n①\n≤\n̟Xt−1 + ̟ϕ(t−1)q\n②=\n̟Xt−1 + ̟ · ˜c · {[s(t−1)q]˜σ}\n1−˜σ\n˜σ\n③=\n̟Xt−1 + ̟ · ˜c · {˜c(1 −˜σ) ·\n1\nϕ′(s(t−1)q)}\n1−˜σ\n˜σ\n④\n≤\n̟Xt−1 + ̟ · ˜c · {˜c(1 −˜σ) · ϑ√qXt−1}\n1−˜σ\n˜σ\n⑤=\n̟(St−1 −St) + ̟ · ˜c · [˜c(1 −˜σ)ϑ√q]\n1−˜σ\n˜σ\n|\n{z\n}\n≜¨κ\n·{St−1 −St}\n1−˜σ\n˜σ ,\n(54)\nwhere step ①uses Theorem 4.7(b); step ②uses the deﬁnitions that ϕt ≜ϕ(st), and ϕ(s) = ˜cs1−˜σ; step ③uses ϕ′(s) =\n˜c(1−˜σ)·[s]−˜σ, leading to [st]˜σ = ˜c(1−˜σ)·\n1\nϕ′(st); step ④uses Inequality (53); step ⑤uses the fact that Xt−1 = St−1−St.\nFinally, we consider three cases for ˜σ ∈[0, 1).\nPart (a). We consider ˜σ = 0. We deﬁne At ≜∥x(t−1)q −x(t−1)q−1∥+ ∥x(t−1)q−1 −x(t−1)q−2∥. We have:\nϑAt\n①\n≥\n1\nϕ′(s(t−1)q)\n②=\n1\n˜c(1−˜σ)·[s(t−1)q]−˜σ\n③= 1\n˜c,\n(55)\nwhere step ①from Inequality (52); step ②uses ϕ′(s) = ˜c(1 −˜σ) · [s]−˜σ; step ③uses ˜σ = 0.\nSince At →0, and ϑ, c > 0, Inequality (55) results in a contradiction At ≥\n1\n˜cϑ > 0. Therefore, there exists t′ such that\n∥xt −xt−1∥= 0 for all t > t′ > t⋆, ensuring that the algorithm terminates in a ﬁnite number of steps.\nPart (b). We consider ˜σ ∈(0, 1\n2]. We deﬁne u ≜1−˜σ\n˜σ\n∈[1, ∞).\nWe have: St−1 −St = Xt−1 =\nqP(t−1)q−1\nj=(t−1)q−q ∥xj+1 −xj∥2\n2 ≤\np\nq(2x)2 ≜R.\nFor all t ≥t′ > t⋆, we have from Inequality (54):\nSt\n≤\n̟(St−1 −St) + (St−1 −St)\n1−˜σ\n˜σ\n· ¨κ\n①\n≤\n(St−1 −St)(̟ + Ru−1 · ¨κ\n|\n{z\n}\n≜˜κ\n)\n≤\nSt−1 ·\n˜κ\n˜κ+1,\n(56)\nwhere step ①uses the fact that xu\nx ≤Ru−1 for all u ≥1, and x ∈(0, R]. By induction we obtain\nST ≤S0 · (\n˜κ\n˜κ+1)T .\nIn other words, the sequence {St}∞\nt=0 converges Q-linearly at the rate St = O( ˙τ t), where ˙τ ≜\n˜κ\n˜κ+1.\nPart (c). We consider ˜σ ∈( 1\n2, 1). We deﬁne u ≜1−˜σ\n˜σ\n∈(0, 1), and ˙ς ≜\n1−˜σ\n2˜σ−1 > 0.\nWe have: St−1 −St = Xt−1 =\nqP(t−1)q−1\nj=(t−1)q−q ∥xj+1 −xj∥2\n2 ≤\np\nq(2x)2 ≜R.\n\n\nFor all t ≥t′ > t⋆, we have from Inequality (54):\nSt\n≤\n¨κ(St−1 −St)\n1−˜σ\n˜σ\n+ ̟(St−1 −St)\n①=\n¨κ(St−1 −St)u + γ1(St−1 −St)u · (Xt−1)1−u\n②\n≤\n¨κ(St−1 −St)u + γ1(St−1 −St)u · R1−u\n=\n(St−1 −St)u · (¨κ + γ1R1−u)\n|\n{z\n}\n≜˙κ\n③\n≤\nO(T −\nu\n1−u ) = O(T −˙ς),\nwhere step ①uses the deﬁnition of u and the fact that St−1 −St = Xt−1; step ②uses the fact that x1−u ≤R1−u for all\nx ∈(0, R], u ∈(0, 1), and R > 0; step ③uses Lemma A.10 with c = ˙κ.\nD. Additional Experiment Details and Results\nThis section provides additional details and results from the experiments.\nD.1. Datasets\nWe utilize eight datasets in our experiments, comprising both randomly generated data and publicly available real-\nworld data.\nThese datasets are represented as data matrices D ∈\nR ˙m× ˙d.\nThe dataset names are as follows:\n‘tdt2- ˙m- ˙d’, ‘20news- ˙m- ˙d’, ‘sector- ˙m- ˙d’, ‘mnist- ˙m- ˙d’, ‘cifar- ˙m- ˙d’, ‘gisette- ˙m- ˙d’, ‘cnncaltech- ˙m- ˙d’, and ‘randn- ˙m- ˙d’.\nHere, randn(m, n) refers to a function that generates a standard Gaussian random matrix with dimensions m × n.\nThe matrix D ∈R ˙m× ˙d is constructed by randomly selecting\n˙m examples and\n˙d dimensions from the original\nreal-world datasets available at http://www.cad.zju.edu.cn/home/dengcai/Data/TextData.html and\nhttps://www.csie.ntu.edu.tw/˜cjlin/libsvm/. We normalize the data matrix D to ensure it has a unit\nFrobenius norm using the operation D ←D/∥D∥F. (i) For the linear eigenvalue problem, we generate the data matrix C\nusing the formula C = −DTD. (ii) For the sparse phase retrieval problem, we use the matrix D as the measurement matrix\nA ∈Rm×n. The observation vector y ∈Rm is generated as follows: A sparse signal x ∈Rn is created by randomly\nselecting a support set of size 0.1n, with its values sampled from a standard Gaussian distribution. The observation vector\ny is then computed as y = u + 0.001 · ∥u∥· randn(m, 1), where u = (Ax) ⊙(Ax).\nD.2. Projection on Orthogonality Constraints\nWhen h(x) = ιM(mat(x)) with M ≜{V | VTV = I}, the computation of the generalized proximal operator reduces to\nsolving the following optimization problem:\n¯x ∈arg minx\nµ\n2 ∥x −x′∥2\n2, s.t. mat(x) ∈M ≜{V | VTV = I}.\nThis corresponds to the nearest orthogonal matrix problem, whose optimal solution is given by ¯x = vec( ˆU ˆVT), where\nmat(x′) = ˆUDiag(s) ˆUT represents the singular value decomposition (SVD) of mat(x′). Here, vec(V) denotes the vector\nformed by stacking the column vectors of V with vec(V) ∈Rd′×r′, and mat(x) converts x ∈R(d′·r′)×1 into a matrix\nwith mat(vec(V)) = V with mat(x) ∈Rd′×r′.\nD.3. Proximal Operator for Generalized Capped ℓ1 Norm\nWhen h(x) = ˙λ∥max(|x|, ˙τ)∥1 + ιΩ(x), where Ω≜{x | ∥x∥∞≤˙r}, the generalized proximal operator reduces to\nsolving the following nonconvex optimization problem:\n¯x ∈arg minx∈Rn ˙λ∥max(|x|, ˙τ)∥1 + 1\n2∥x −a∥2\nc, s.t. −˙r ≤x ≤˙r.\nThis problem decomposes into n dependent sub-problems:\n¯xi ∈arg minx qi(x) ≜ci\n2 (x −ai)2 + ˙λ| max(|x|, ˙τ)|, s. t. −˙r ≤x ≤˙r.\n(57)\n\n\nTo simplify, we deﬁne P(x) ≜max(−˙r, min( ˙r, x)) and identify seven cases for x.\n(a) x1 = 0, x2 = −˙r, and x3 = ˙r.\n(b) ˙r > x4 > 0 and |x4| ≥˙τ. Problem (57) reduces to ¯xi ∈arg minx qi(x) ≜ci\n2 (x −ai)2 + ˙λx. The optimality\ncondition gives x4 = ai −˙λ/ci, and incorporating bound constraints yields x4 = P(ai −˙λ/ci).\n(c) ˙r > x5 > 0 and |x5| < ˙τ. Problem (57) simpliﬁes to ¯xi ∈arg minx qi(x) ≜ci\n2 (x −ai)2, leading to x5 = P(ai).\n(d) −˙r < x6 < 0 and |x6| ≥˙τ. Problem (57) reduces to ¯xi ∈arg minx qi(x) ≜ci\n2 (x −ai)2 −˙λx. The optimality\ncondition gives x6 = ai + ˙λ/ci, and incorporating bound constraints results in x6 = P(ai + ˙λ/ci).\n(e) −˙r < x7 < 0 and |x7| < ˙τ. Problem (57) simpliﬁes to ¯xi ∈arg minx qi(x) ≜ci\n2 (x −ai)2, leading to x7 = P(ai),\nidentical to x5.\nThus, the one-dimensional sub-problem in Problem (57) has six critical points, and the optimal solution is computed as:\n¯xi = arg min\nx qi(x), s. t. x ∈{x1, x2, x3, x4, x5, x6}.\nD.4. Additional Experiment Results\nWe present the experimental results for AAPG-SPIDER on the sparse phase retrieval problem in Figures 5 and 6, and for\nAAPG on the linear eigenvalue problem in Figures 7 and 8. The key ﬁndings are as follows: (i) The proposed method\nAAPG does not outperform on dense, randomly generated datasets labeled as ‘randn-10000-1000’ and ‘randn-2000-500’.\nThese results align with the widely accepted understanding that adaptive methods typically excel on sparse, structured\ndatasets but may perform less efﬁciently on dense datasets (Kingma & Ba, 2015; Duchi et al., 2011; Ward et al., 2020).\n(ii) Overall, except for the dense and randomly generated datasets on the linear eigenvalue problem, the proposed method\nachieves state-of-the-art performance compared to existing methods in both deterministic and stochastic settings. These\nresults reinforce the conclusions presented in the main paper.\n\n\n0\n2\n4\n6\n8\n10\n12\n10\n−4\n10\n−3\n10\n−2\n10\n−1\n10\n0\nTime (seconds)\nRelative Objective\n \n \nProxSARAH\nSpiderBoost\nSpiderBoost−M\nSGP−Spider\nAAPG−Spider(0)\nAAPG−Spider(0.1)\nAAPG−Spider(0.5)\nAAPG−Spider(0.9)\n(a) cifar-10000-1000\n0\n2\n4\n6\n8\n10\n12\n10\n−4\n10\n−3\n10\n−2\n10\n−1\n10\n0\nTime (seconds)\nRelative Objective\n \n \nProxSARAH\nSpiderBoost\nSpiderBoost−M\nSGP−Spider\nAAPG−Spider(0)\nAAPG−Spider(0.1)\nAAPG−Spider(0.5)\nAAPG−Spider(0.9)\n(b) gisette-5000-1000\n0\n2\n4\n6\n8\n10\n12\n10\n−4\n10\n−3\n10\n−2\n10\n−1\n10\n0\nTime (seconds)\nRelative Objective\n \n \nProxSARAH\nSpiderBoost\nSpiderBoost−M\nSGP−Spider\nAAPG−Spider(0)\nAAPG−Spider(0.1)\nAAPG−Spider(0.5)\nAAPG−Spider(0.9)\n(c) cnncaltech-3000-1000\n0\n2\n4\n6\n8\n10\n−4\n10\n−3\n10\n−2\n10\n−1\n10\n0\nTime (seconds)\nRelative Objective\n \n \nProxSARAH\nSpiderBoost\nSpiderBoost−M\nSGP−Spider\nAAPG−Spider(0)\nAAPG−Spider(0.1)\nAAPG−Spider(0.5)\nAAPG−Spider(0.9)\n(d) randn-10000-1000\nFigure 5: The convergence curve of the compared methods for sparse phase retrieval with ˙λ = 0.01.\n0\n2\n4\n6\n8\n10\n12\n10\n−3\n10\n−2\n10\n−1\nTime (seconds)\nRelative Objective\n \n \nProxSARAH\nSpiderBoost\nSpiderBoost−M\nSGP−Spider\nAAPG−Spider(0)\nAAPG−Spider(0.1)\nAAPG−Spider(0.5)\nAAPG−Spider(0.9)\n(a) cifar-10000-1000\n0\n2\n4\n6\n8\n10\n12\n10\n−3\n10\n−2\n10\n−1\nTime (seconds)\nRelative Objective\n \n \nProxSARAH\nSpiderBoost\nSpiderBoost−M\nSGP−Spider\nAAPG−Spider(0)\nAAPG−Spider(0.1)\nAAPG−Spider(0.5)\nAAPG−Spider(0.9)\n(b) gisette-5000-1000\n0\n2\n4\n6\n8\n10\n12\n10\n−3\n10\n−2\n10\n−1\nTime (seconds)\nRelative Objective\n \n \nProxSARAH\nSpiderBoost\nSpiderBoost−M\nSGP−Spider\nAAPG−Spider(0)\nAAPG−Spider(0.1)\nAAPG−Spider(0.5)\nAAPG−Spider(0.9)\n(c) cnncaltech-3000-1000\n0\n2\n4\n6\n8\n10\n−4\n10\n−3\n10\n−2\n10\n−1\nTime (seconds)\nRelative Objective\n \n \nProxSARAH\nSpiderBoost\nSpiderBoost−M\nSGP−Spider\nAAPG−Spider(0)\nAAPG−Spider(0.1)\nAAPG−Spider(0.5)\nAAPG−Spider(0.9)\n(d) randn-10000-1000\nFigure 6: The convergence curve of the compared methods for sparse phase retrieval with ˙λ = 0.001.\n0\n1\n2\n3\n4\n5\n6\n10\n−3\n10\n−2\n10\n−1\nTime (seconds)\nRelative Objective\n \n \nOptM−QR\nOptM−Cayley\nAPG\nFOForth−GR\nFOForth−P\nFOForth−QR\nAAPG(0)\nAAPG(0.1)\nAAPG(0.5)\nAAPG(0.9)\n(a) cifar-5000-1000\n0\n1\n2\n3\n4\n5\n6\n10\n−4\n10\n−3\n10\n−2\n10\n−1\nTime (seconds)\nRelative Objective\n \n \nOptM−QR\nOptM−Cayley\nAPG\nFOForth−GR\nFOForth−P\nFOForth−QR\nAAPG(0)\nAAPG(0.1)\nAAPG(0.5)\nAAPG(0.9)\n(b) gisette-6000-3000\n0\n2\n4\n6\n8\n10\n10\n−4\n10\n−3\n10\n−2\n10\n−1\nTime (seconds)\nRelative Objective\n \n \nOptM−QR\nOptM−Cayley\nAPG\nFOForth−GR\nFOForth−P\nFOForth−QR\nAAPG(0)\nAAPG(0.1)\nAAPG(0.5)\nAAPG(0.9)\n(c) cnncaltech-2000-1000\n0\n1\n2\n3\n4\n5\n6\n10\n−4\n10\n−3\n10\n−2\nTime (seconds)\nRelative Objective\n \n \nOptM−QR\nOptM−Cayley\nAPG\nFOForth−GR\nFOForth−P\nFOForth−QR\nAAPG(0)\nAAPG(0.1)\nAAPG(0.5)\nAAPG(0.9)\n(d) randn-3000-1000\nFigure 7: The convergence curve of the compared methods for linear eigenvalue problems with ˙r = 20.\n0\n1\n2\n3\n4\n5\n6\n10\n−4\n10\n−3\n10\n−2\n10\n−1\nTime (seconds)\nRelative Objective\n \n \nOptM−QR\nOptM−Cayley\nAPG\nFOForth−GR\nFOForth−P\nFOForth−QR\nAAPG(0)\nAAPG(0.1)\nAAPG(0.5)\nAAPG(0.9)\n(a) cifar-5000-1000\n0\n1\n2\n3\n4\n5\n6\n10\n−4\n10\n−3\n10\n−2\n10\n−1\nTime (seconds)\nRelative Objective\n \n \nOptM−QR\nOptM−Cayley\nAPG\nFOForth−GR\nFOForth−P\nFOForth−QR\nAAPG(0)\nAAPG(0.1)\nAAPG(0.5)\nAAPG(0.9)\n(b) gisette-6000-3000\n0\n2\n4\n6\n8\n10\n10\n−4\n10\n−3\n10\n−2\n10\n−1\nTime (seconds)\nRelative Objective\n \n \nOptM−QR\nOptM−Cayley\nAPG\nFOForth−GR\nFOForth−P\nFOForth−QR\nAAPG(0)\nAAPG(0.1)\nAAPG(0.5)\nAAPG(0.9)\n(c) cnncaltech-2000-1000\n0\n1\n2\n3\n4\n5\n6\n10\n−4\n10\n−3\n10\n−2\nTime (seconds)\nRelative Objective\n \n \nOptM−QR\nOptM−Cayley\nAPG\nFOForth−GR\nFOForth−P\nFOForth−QR\nAAPG(0)\nAAPG(0.1)\nAAPG(0.5)\nAAPG(0.9)\n(d) randn-3000-1000\nFigure 8: The convergence curve of the compared methods for linear eigenvalue problems with ˙r = 50.\n\n\n",
  "metadata": {
    "source_file": "dataset/pdfs/arxiv_2502.21099v1.pdf",
    "total_pages": 38,
    "title": "Adaptive Accelerated Proximal Gradient Methods with Variance Reduction for Composite Nonconvex Finite-Sum Minimization",
    "authors": [
      "Ganzhao Yuan"
    ],
    "abstract": "This paper proposes {\\sf AAPG-SPIDER}, an Adaptive Accelerated Proximal\nGradient (AAPG) method with variance reduction for minimizing composite\nnonconvex finite-sum functions. It integrates three acceleration techniques:\nadaptive stepsizes, Nesterov's extrapolation, and the recursive stochastic\npath-integrated estimator SPIDER. While targeting stochastic finite-sum\nproblems, {\\sf AAPG-SPIDER} simplifies to {\\sf AAPG} in the full-batch,\nnon-stochastic setting, which is also of independent interest. To our\nknowledge, {\\sf AAPG-SPIDER} and {\\sf AAPG} are the first learning-rate-free\nmethods to achieve optimal iteration complexity for this class of\n\\textit{composite} minimization problems. Specifically, {\\sf AAPG} achieves the\noptimal iteration complexity of $\\mathcal{O}(N \\epsilon^{-2})$, while {\\sf\nAAPG-SPIDER} achieves $\\mathcal{O}(N + \\sqrt{N} \\epsilon^{-2})$ for finding\n$\\epsilon$-approximate stationary points, where $N$ is the number of component\nfunctions. Under the Kurdyka-Lojasiewicz (KL) assumption, we establish\nnon-ergodic convergence rates for both methods. Preliminary experiments on\nsparse phase retrieval and linear eigenvalue problems demonstrate the superior\nperformance of {\\sf AAPG-SPIDER} and {\\sf AAPG} compared to existing methods.",
    "published_date": "2025-02-28",
    "source": "arxiv"
  }
}