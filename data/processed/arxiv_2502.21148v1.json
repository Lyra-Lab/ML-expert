{
  "id": "arxiv_2502.21148v1",
  "text": "Applications of Enhanced Sampling Methods to Biomolecular Self-Assembly: A Review \n \nMason Hooten*,1, Het Patel*,2, Yiwei Shao*,2, Rishabh Kumar Singh*,2, and Meenakshi Dutt**,2 \n \n1 Biomedical Engineering, Rutgers, The State University of New Jersey, Piscataway, New \nJersey 08854 \n2 Chemical and Biochemical Engineering, Rutgers, The State University of New Jersey, \nPiscataway, New Jersey 08854 \n* equal contributors \n** corresponding author: meenakshi.dutt@rutgers.edu \n \n \nAbstract \n \nThis review article discusses some common enhanced sampling methods in relation to the \nprocess of self-assembly of biomolecules. An introduction to self-assembly and its challenges is \ncovered followed by a brief overview of the methods and analysis for replica-exchange molecular \ndynamics, umbrella sampling, metadynamics, and machine learning based techniques. \nApplications of select methods towards peptides, proteins, polymers, nucleic acids, and \nsupramolecules are discussed. Finally, a short discussion of the future directions of some of these \nmethods is provided.  \n \nSection 1 - Introduction \n \nThe self-assembly of biomolecules to form biomolecular assemblies and materials is ubiquitous \nboth in nature and the laboratory. A mechanistic understanding of molecular self-assembly is \nessential to a wide range of disciplines within biomedical sciences for applications such as \ncrystallization or drug delivery (Whitesides and Grzybowski 2002). The molecular mechanisms \nunderlying the process of self-assembly can be elucidated via molecular simulation techniques \nsuch as Molecular Dynamics (MD). The spatiotemporal scales resolved by these simulation \ntechniques with current computational resources are limited when attempting to explore \nprocesses with extended time scales (Hollingsworth and Dror 2018). These limitations can lead \nto insufficient sampling of a broad range of conformations (Bernardi et. al. 2015) and \nconfigurational states, thereby impacting characterization of the system. To overcome these \nchallenges, enhanced sampling methods have been employed to provide a deeper understanding \nof the mechanisms and pathways underlying the self-assembly process. This is done by parsing \nthe jagged free energy landscape of biomolecules and properly sampling a broad range of \nconformations and configurations (Bernardi et. al. 2015). This review covers a selection of \nenhanced sampling techniques that have been used to provide a mechanistic insight into the \nprocess of self-assembly of biomolecules.  \n \nSection 2: Background and Motivation \n \n\n\nSelf-Assembly: Definition \nSelf-assembly is the autonomous organization of components into structured, functional \narrangements without external guidance (Whitesides and Grzybowski 2002). Self-assembly falls \ninto two primary types: static and dynamic. In static self-assembly, structures remain stable once \nformed, driven by minimization of the free energy. Conversely, dynamic self-assembly requires \ncontinuous energy input, allowing structures to exist transiently or evolve over time. Yet, while \nthermodynamics often drives the process by favoring lower free energy states, the resulting \nstructures may not always represent global or even local minima of the free energy. \nWhitelamâ€™s (Whitelam and Jack 2014) definition of self-assembly focused on it being an \nintrinsically disordered nonequilibrium process. Near-equilibrium assembly emphasizes \nthermodynamic factors, whereas far-from-equilibrium assembly relies heavily on dynamic effects, \nwhere conditions such as controlled parameters are crucial to achieving stable ordered structures. \nComputational approaches are essential for studying self-assembly due to their ability to resolve \nthe underlying processes and mechanisms arising from the interplay between key physical \ninteractions. Advanced algorithms and rare-event sampling techniques, such as forward-flux and \ntransition-path sampling, enhance the sampling of complex systems, especially those with \nmultiple ordered structures and vital for capturing transient phenomena. Despite their inherent \napproximations, such as coarse-grained models and simplified solvent interactions, \ncomputational approaches provide valuable qualitative insights that complement experimental \nfindings, such as those associated with hydrophobic or hydrodynamic effects (Ardekani et al. \n2024). Hence, these approaches provide an efficient and low-cost avenue for designing and \npredicting the formation and behavior of complex systems, which may be expensive or \nchallenging to replicate experimentally. \nThese self-assembly processes, governed by molecular and supramolecular interactions, are \ncentral to various natural and synthetic systems, each characterized by unique thermodynamic \nand kinetic principles: \n(1) Self-assembly of peptides involves the spontaneous organization of amino acid \nsequences into ordered nanostructures, such as fibrils, micelles, and hydrogels. \nThermodynamic driving forces include enthalpic contributions from hydrogen bonding and \nvan der Waals interactions, as well as entropic gains from solvent structuring and chain \nmobility. (Tantakitti 2016; Freeman 2018) Yan et al. (2016) noted that such a process is \nprimarily driven by thermodynamics, characterized by various non-covalent interactions, \nand is significantly modulated by kinetics, due to external conditions such as salt \nconcentration, pH and temperature. The kinetics of peptide self-assembly are influenced \nby nucleation mechanisms and growth rates, which determine the pathway and \nmorphology of the resultant structures (Zhang et al. 2019; Chen et al. 2022). The interplay \nof thermodynamics and kinetics often contribute to kinetic adjustments that disrupt the \nequilibrium of the thermodynamic driving forces or alter energy barriers, ultimately leading \nto a kinetically trapped state. \n(2) In polymeric systems, self-assembly enables the formation of nanostructured materials \nwith tailored properties. Yan et al. (2013) noted that hierarchical arrangements due to \nintermolecular interactions define the properties of polymer nanocomposites, while the \n\n\nmovement of nanoparticles affects the behavior of the polymer components. Key factors \nin these systems include: the interaction between nanoparticles and polymers, long-range \nforces (such as van der Waals or electrostatic forces) between particles, nanoparticle size \nand shape, and the composition and molecular structure of the polymers. The challenge \nin designing these materials lies in understanding how to leverage the intricate balance \nbetween entropy and enthalpy to achieve the resulting structures. Computational \napproaches have provided insights into the thermodynamic stability and kinetic pathways \nunderlying self-assembly, particularly under external fields such as electric or magnetic \nfields. Interactions between polymer chains and nanoparticles have contributed to the \nformation of hierarchical structures (Yadav et al.  2020; Bhendale and Singh 2023).  \n(3) Self-assembly of lipids results in the formation of micelles, bilayers, and other structures, \ngoverned by the hydrophobic effect and molecular packing parameters. These systems \nare known to be highly sensitive to external stimuli, including temperature, pH, and ionic \nstrength (Zhang et al. 2014; Grzelczak et al 2019). One prominent subarea of study, \ncolloidal self-assembly, leverages inter-particle dynamics, including but not limited to van \nder Waals interactions, electrostatic interactions, hydrophobic forces and solvation force. \nLi et al. (2008) suggested that the many-body interactions of coupled particles are better \ndescribed in their molecular models compared to continuum theories, which are normally \naccompanied by adequate approximation to reduce the computational cost of simulations. \nSimilarly, crystallization-driven self-assembly, often mediated by block copolymers, \nenables the formation of well-defined structures with precise functional properties (Nguyen \net al. 2021). Polymer-assisted crystallization and crystallization-driven self-assembly are \ninfluenced by the thermodynamics and kinetics of biomolecular interactions, including \ndimerization. Zheng et al. (2021) investigated the interplay of factors like entropy, \nenthalpy, and molecular architecture as crucial parameters for controlling the assembly \nprocess. \n(4) Self-assembly of proteins underpins numerous biological phenomena, including amyloid \nfibril formation and viral capsid assembly. The thermodynamics of protein assembly \ninvolve the minimization of free energy through hydrophobic and electrostatic interactions. \nKinetic factors, such as nucleation rates and conformational changes, determine the \nefficiency and specificity of assembly processes. (Zerovnik et al. 2016). For example, \nAsherie et al. (2016) reported that the formation of amyloid fibrils involved crucial \nconformational changes and various pathways. Tezcan et al. (2021) highlighted that \nprotein self-assembly, distinct from protein folding, can be pathway-dependent, resulting \nin varying structural outcomes depending on the environmental conditions. While \ncomputational modeling is a powerful tool in the design of supramolecular protein \naggregates, it often relies on a trial-and-error approach to address challenges related to \npolar interactions and dynamic pathways. \nSelf-assembly: Underlying Processes \nThe self-organization of molecules into assemblies naturally follows through complex hierarchical \npathways. Beyond the prescription of building patterned structures from their constituents, one by \none, to a certain template, most self-assemblies are formed through the aggregation of clusters, \nwith multiple non-covalent intermolecular interactions â€“ like hydrogen bonding, pi-pi stacking, \n\n\nelectrostatics and van der Waals forces â€“ underlying the process. Self-assembly, driven without \nany external energy supply, is mainly guided by thermal fluctuations from the solvent molecules. \nThe components fluctuate and undergo conformational changes through diffusion in solution \nwithout dissipating energy (Whitelam and Jack 2015). \nDispersed monomers in the solution adhering to statistical mechanics are ideally expected to \nachieve conformations with ever-lower free energy and form assemblies but this is rarely \nwitnessed on experimental timescales. Rather some components first self-assemble as \nmetastable structures that may or may not relax to form a thermodynamically stable assembly on \nexperimental or computational timescales. As discussed earlier, self-assembly can happen either \nnear \nequilibrium \nor \nfar \nfrom \nequilibrium. \nWhile \nnear-equilibrium \nself-assembly \nis \nthermodynamically controlled, far-from-equilibrium self-assembly is kinetically controlled. Most \nstatic assemblies that require no dissipation of energy are near equilibrium. Whereas dynamic \nassemblies dissipate energy, going downhill far from equilibrium in the free energy landscape \n(Whitesides and Grzybowski 2002). Though far from equilibrium self-assembly is kinetically \nfrustrated, the interplay of stronger interaction driven by large fluctuation and specificity for \nproductive binding leads to faster kinetics than near equilibrium. Whereas reversibility or detailed \nbalance and low energy impetus slows down the kinetics. \nAs revealed by experiments and computer simulations, two important factors act as control \nparameters for many self-assemblies: 1) thermodynamic favorability towards forming an ordered, \nstable structure, and 2) conditions allowing the random arrangements to organize into an ordered \nstructure. Such requirements may be inhibited due to an imbalance in the strength of interaction \nand specificity of binding. If the interactions between components are too specific, it impedes \nproductive binding. Non-specific interactions lead to partial reversibility whereby intermediate \nstructures can transiently break bonds to correct the nascent defects of growing assemblies. This \nerror correction mechanism makes for a necessary condition for robust self-assembly (Whitelam, \nFeng et al. 2009; Whitelam 2010). Overly strong interactions do not allow for adequate relaxation \ntime leading to malformed aggregates. The non-specific interactions lead to kinetic frustration \nwhile the specific interaction leads to thermodynamic frustration, hence the competition between \nthermodynamics and kinetics decides the viable phase space for self-assembly (Whitelam, Feng \net al. 2009; Whitelam 2010). \nThe timescales to explore self-assembly pathways in molecular simulations are usually limited to \nthe nanosecond range with a system size of a few 100 monomers (Frederix, Patmanidis, et al. \n2018). Most all-atom simulations are unable to capture all the dynamic stages in a self-assembly \nprocess. Enhanced sampling techniques help capture not only the overall morphologies of \nthousands of monomers but also the various manifolds of kinetic pathways from one structure to \nthe other. The main idea is to use biasing potentials along certain reaction coordinates (RCs) to \neffectively reduce the energy barrier on the free energy landscape such that all relevant \nthermodynamics states are spanned. The choice of collective variables (CVs) and the enhanced \nsampling method are of immense importance in reconciling the complex interplay of \nthermodynamics and kinetics.   \n \n\n\nSection 3 - Methods and Theory \n \nReplica-Exchange Molecular Dynamics \nReplica exchange (RE) is an algorithm for enhancing sampling by exchanging structural \ninformation between simulations, in an ensemble of simulations that vary in terms of an \ninstrumental parameter. This parameter usually modulates system energy, with the effect that RE \nis able to overcome high energetic barriers, sampling broadly over energy landscapes with many \ndegrees of freedom where traditional sampling may encounter kinetically trapped microstates.  \n \nThe application of RE to MD (REMD) (Sugita 1999; Nymeyer 2004) is a common strategy for \ninvestigating biomolecules. In REMD, a set of MD parameterizations representing an ensemble \nof thermodynamic states is prepared in which each state parameterization takes on a different \nvalue of a particular parameter, often temperature. Chemically identical systems of atoms â€“ \ntermed replicas â€“ are simulated in parallel in the ensemble of states, and periodically attempts \nare made to exchange system configurations between pairs of states. \n \nFor example, consider a pair of thermodynamic states m and n with reciprocal temperature Î²m \nand Î²n, respectively. Prior to an exchange, these states contain atomistic configurations x and y, \nrespectively. The probability of exchanging x and y between m and n is calculated as a function \nof the potential energy E, such that swaps will only be completed if the end state is consistent \nwith the target thermodynamic ensemble. Equation (1) expresses the weighted difference in \npotential energy between replicas, and an exchange attempt is accepted or rejected via the \nMetropolis criterion shown in equation (2). \n \n \n \nIn the typical REMD simulation, repeated rounds of MD are punctuated by exchange steps, shown \nschematically in Figure 1. The result of these exchange steps is that each system of atoms \nconducts a random walk through the prescribed temperature space, as exemplified in Figure 2. \nThe result is a more robust exploration of the energy surface, and therefore the structural \nensemble, at lower energy states.  \n \n \n\n\n \nFigure 1. Schematic representation of REMD showing MD time elapsing between periodic RE \nattempts. Reprinted from the Amber reference manual (Case 2005; Amber Manuals 2025). \n \n \nFigure 2. Time series of (a) temperature and (b) potential energy for a single replica over the \ncourse of a REMD simulation. Reprinted from reference (Sugita 1999) with permission from \nElsevier. \n \n \nTemperature is the most common dimension over which replicas are designed to vary, but REMD \nmay be implemented using a variety of other dimensions including charge states, center of mass \n(COM) distance in umbrella sampling, and the simulated Hamiltonian. REMD of unconstrained \n\n\nMD simulations has led to significant results in the study of self-assembly of biomolecules such \nas peptides, lipids, and proteins. The combination of REMD with other techniques, including \numbrella sampling, has also been used to characterize the energy of interaction between \nindividual molecules in targeted structures of interest such as amyloid protofibrils and peptides \nembedded in lipid membranes. Although REMD is the most commonly reported RE approach in \nbiomolecular simulations, there are examples of RE applied to a variety of stochastic and \ndynamical simulation techniques, including Wang-Landau energy sampling (Vogel 2014; Wang \n2001) and dissipative particle dynamics (DPD) (Kobayashi 2019). \n \nTemperature is by far the most commonly reported REMD parameter in studies concerning \nbiomolecular aggregation (Anand 2008; Baumketner 2005; Cecchini 2004; De Simone 2010; Mu \n2012; Rissanou 2013; Sieradzan 2012; Soto 2006; Takeda 2008; Tamamis 2009; Xiong 2019), \nand temperature REMD (T-REMD) is implemented in a variety of MD software packages \n(Abraham 2015; Brooks 2009; Case 2005; The PLUMED Consortium 2019). REMD has also been \ncombined with umbrella sampling (see next section) in studies of oligomerization, where replicas \nvary on the constrained intermolecular COM distance (i.e., umbrella distance) (Martel 2017; Wolf \n2008).  \n \nHamiltonian REMD (H-REMD), extends T-REMD by directly acting on the functional form of the \nHamiltonian, such that the effects of temperature increase may be confined only to a subsystem. \nFor example, it may be desirable to enhance the structure of the solute (e.g. a protein) but not the \nsolvent, a technique sometimes called solute tempering (ST) (Lockhart 2023). Multidimensional \nREMD algorithms have also been developed, where replicas vary simultaneously over multiple \nparameters, such as temperature plus umbrella distance (Gee 2011; Jeon 2013; Jeon 2014) or \ntemperature plus protonation state of amino acid side chains (Morrow 2012). Other models which \nhave been used to study biomolecular assembly with RE include dissipative particle dynamics \n(DPD) (Kobayashi 2004) and Monte Carlo sampling routines (Urano 2015; Vogel 2014). \n \nUmbrella Sampling \nAn understanding of the interactions, organization and packing of the molecules within equilibrium \nself-assembled structures is imperative. For instance, investigations of the supramolecular self-\nassembly of biomolecules provide a fundamental understanding of the origins of the properties of \nthese structures (Levin et. al. 2020). Further, it allows one to probe the effect of altering \nenvironmental conditions on the design and creation of new supramolecules which yield novel \nself-assembled structures with desired set of characteristics. Unfortunately, in biomolecular self-\nassembly it is challenging to determine which specific physical forces or chemical effects result in \nthe formation of a given structure (Yu and Schatz 2013). This requires the estimation of the free \nenergy as it is highly correlated to common biochemical events and interactions (Kastner 2011). \nYu and Schatz stated that parsing the free energy differences of a biomolecule is crucial when \nattempting to study the conformational changes of molecules within self-assembled structures \n(Yu and Schatz 2013). Calculations of the difference in free energy of unlikely conformations, \nmetastable states, and other rare events can be performed via umbrella sampling (Kastner 2011). \nUmbrella sampling was originally developed by Torrie and Valleau in 1976 as an effective means \nto calculate the free energy differences during phase transitions as traditional numerical \n\n\nintegration methods were inefficient during these events (Torrie and Valleau 1976). Currently, \numbrella sampling is often used to probe a variety of processes including self-assembly, with \nmany methods and variants proposed over the years (Hansen and Gunsteren 2014). It is often a \ncomplementary technique applied alongside REMD and Metadynamics. Umbrella sampling \nattempts to sample unlikely molecular conformations and overcome steep potential wells by \nleveling the energy landscape through the use of a biasing potential. This bias is an additional \nterm in the potential energy equation that should ideally make it easier for a molecule to explore \nvarious regions of the potential energy landscape in the duration of a MD simulation (Mills and \nAndricioaei 2008). Unfortunately, the potential energy landscape is unknown beforehand, so \ndetermining the bias that should be added is challenging. Harmonic biases are frequently used, \nhowever there are other variants including an adaptive bias (Kastner 2011). Finally, the sampling \ntechnique is applied on a RC of choice. The sampling method can be performed on the entire \nrange of the RC or the RC can be split into increments and a simulation can be run on each \nincrement. These split increments and independent simulations are known as windows which can \ncontain their own bias and are eventually combined and averaged using histogram techniques \nsuch as the weighted histogram analysis method (WHAM). Taken from Justin A. Lemkulâ€™s \nGROMACS tutorials website, Figure 3 shows a nice illustration of the concept of windows. \n \n \nFigure 3. Umbrella sampling schematic of molecule pulling (Lemkul 2018). \n \nIn Figure 3, the red sphere is being slowly pulled away from the blue sphere. The reaction \ncoordinate is the distance between spheres and the entire distance range to be studied is split \ninto increments or â€œwindowsâ€. In each of these windows a bias is applied and a simulation is \nperformed. On the bottom is the ideal configuration histogram for each window, where each \nconfiguration overlaps so that a continuous energy function can be calculated from WHAM. \n \n\n\nThe concept of umbrella sampling is discussed in detail in the original paper by Torrie and Valleau. \nThe mathematics shown here is a brief re-statement of the work presented in the review article \nby Kastner. The umbrella sampling bias term, W, is added towards the potential energy and \ndepends on the RC of choice ğœ‰. \n \nğ¸ğ‘ğ‘–ğ‘ğ‘ ğ‘’ğ‘‘(ğ‘Ÿ) =  ğ¸ğ‘¢ğ‘›ğ‘ğ‘–ğ‘ğ‘ ğ‘’ğ‘‘(ğ‘Ÿ) +  ğ‘Š(ğœ‰)                                                        (3) \n \nIn equation (3), r is radius and E represents potential energy. Since the energy of a molecule is \ncorrelated to the Boltzman distribution, the unbiased and biased energies can be expressed in \nterms of probability distribution functions. \n \nğ‘ƒğ‘¢ğ‘›ğ‘ğ‘–ğ‘ğ‘ ğ‘’ğ‘‘ = 4 ğ‘’ğ‘¥ğ‘(âˆ’ğ›½ğ¸ğ‘¢ğ‘›ğ‘ğ‘–ğ‘ğ‘ ğ‘’ğ‘‘)ğœ¹(ğœ‰(ğ‘Ÿ) âˆ’ğ‘Ÿ) ğ‘‘!ğ‘Ÿ/ 4 ğ‘’ğ‘¥ğ‘(âˆ’ğ›½ğ¸ğ‘¢ğ‘›ğ‘ğ‘–ğ‘ğ‘ ğ‘’ğ‘‘) ğ‘‘!ğ‘Ÿ          (4) \nğ‘ƒğ‘ğ‘–ğ‘ğ‘ ğ‘’ğ‘‘ = 4 ğ‘’ğ‘¥ğ‘(âˆ’ğ›½ğ¸ğ‘ğ‘–ğ‘ğ‘ ğ‘’ğ‘‘)ğœ¹(ğœ‰(ğ‘Ÿ) âˆ’ğ‘Ÿ) ğ‘‘!ğ‘Ÿ/ 4 ğ‘’ğ‘¥ğ‘(âˆ’ğ›½ğ¸ğ‘ğ‘–ğ‘ğ‘ ğ‘’ğ‘‘) ğ‘‘!ğ‘Ÿ                   (5) \n \n \nIn equations (4) and (5), P denotes a probability distribution, N is the number of atoms in the \nsystem, and ğ›½ is the reciprocal temperature. Utilizing equation (3), the Ebiased term in equation \n(5) can be represented as the sum of the unbiased energy and the bias term W. Also, since the \nintegral is of radius, the biased term can be taken outside the integral. This results in equation \n(6). \n \nğ‘ƒğ‘ğ‘–ğ‘ğ‘ ğ‘’ğ‘‘ = ğ‘’ğ‘¥ğ‘(âˆ’ğ›½ğ‘Š) 4 ğ‘’ğ‘¥ğ‘(âˆ’ğ›½ğ¸ğ‘¢ğ‘›ğ‘ğ‘–ğ‘ğ‘ ğ‘’ğ‘‘)ğœ¹(ğœ‰(ğ‘Ÿ) âˆ’ğ‘Ÿ) ğ‘‘!ğ‘Ÿ/ 4 ğ‘’ğ‘¥ğ‘(âˆ’ğ›½ğ¸ğ‘ğ‘–ğ‘ğ‘ ğ‘’ğ‘‘) ğ‘‘!ğ‘Ÿ     (6) \n \nThere is now a common integral term of exp(-ğ›½*Eunbiased)ğ›¿(ğœ‰(ğ‘Ÿ) âˆ’ğ‘Ÿ) in equations (4) and (6), \nwhich can be used to relate the two distributions, resulting in \n \n ğ‘ƒğ‘¢ğ‘›ğ‘ğ‘–ğ‘ğ‘ ğ‘’ğ‘‘ =  ğ‘ƒğ‘ğ‘–ğ‘ğ‘ ğ‘’ğ‘‘\nâˆ—ğ‘’ğ‘¥ğ‘(ğ›½ğ‘Š) 4 exp(âˆ’ğ›½ğ¸ğ‘¢ğ‘›ğ‘ğ‘–ğ‘ğ‘ ğ‘’ğ‘‘) exp(âˆ’ğ›½ğ‘¤) ğ‘‘!ğ‘Ÿ           \n/ 4 ğ‘’ğ‘¥ğ‘(âˆ’ğ›½ğ¸ğ‘¢ğ‘›ğ‘ğ‘–ğ‘ğ‘ ğ‘’ğ‘‘) ğ‘‘!ğ‘Ÿ                                                                                                  (7)  \n \nFrom statistical mechanics an average for a general property X is given by \n \n< ğ‘‹> = 4 ğ‘’ğ‘¥ğ‘(âˆ’ğ›½ğ¸)ğ‘‹ ğ‘‘!ğ‘Ÿ / 4 ğ‘’ğ‘¥ğ‘(âˆ’ğ›½ğ¸) ğ‘‘!ğ‘Ÿ                                             (8) \n \nThis definition in the unbiased distribution, equation 7, is given by \n \nğ‘ƒğ‘¢ğ‘›ğ‘ğ‘–ğ‘ğ‘ ğ‘’ğ‘‘ =  ğ‘ƒğ‘ğ‘–ğ‘ğ‘ ğ‘’ğ‘‘âˆ—ğ‘’ğ‘¥ğ‘(ğ›½ğ‘Š) < ğ‘’ğ‘¥ğ‘(âˆ’ğ›½ğ‘Š) >                                      (9) \n\n\n \nThe Helmholtz free energy, A, is given by \n \nğ´ = âˆ’1/ğ›½âˆ—ğ‘™ğ‘›(ğ‘ƒ)                                                                      (10) \n \nUsing the definition of the Helmholtz free energy on equation (9) followed by some algebraic \nmanipulation results in \n \nğ´ = âˆ’1/ğ›½âˆ—ğ‘™ğ‘›(ğ‘ƒğ‘ğ‘–ğ‘ğ‘ ğ‘’ğ‘‘) âˆ’ ğ‘Š âˆ’ 1/ğ›½âˆ—ğ‘™ğ‘›(< ğ‘’ğ‘¥ğ‘(âˆ’ğ›½ğ‘Š) >)                 (11) \n \nHence, the free energy can be determined from the selection of bias W added to the energy.  \n \nThe difficulty in umbrella sampling lies in the selection of a bias and the RCs (Kastner 2011). \nIdeally the biased term would level the energy curve to allow for easier access to unlikely \nconformations, however, this is unknown since the goal is to calculate the free energy differences. \nKastner notes that there are two commonly applied types of biasing potentials: harmonic bias and \nadaptive bias. Harmonic bias applies a harmonic term with tunable strength and reference \ndisplacement. The equation for this is shown below. \n \nğ‘Š(ğœ‰) =  0.5ğ¾(ğœ‰âˆ’ğœ‰ğ‘Ÿğ‘’ğ‘“ğ‘’ğ‘Ÿğ‘’ğ‘›ğ‘ğ‘’)\"                                                               (12) \n \nIt is common to adjust the constant K to a value that just allows the dynamics to overcome barriers. \nA very large constant will overrepresent high energy states and also result in a narrow harmonic \nfunction term with little overlap within the windows. This makes analysis and integration difficult. \nIn harmonic bias umbrella sampling it is also common to split the range of the RC into separate \nwindows so that the harmonic bias can be applied in each window. WHAM is commonly used \nboth for the analysis of trajectories and calculation of free energies. Since the bias term to be \nadded is unknown, another approach is to begin with an initial guess and iteratively adjust the \nbias so that it leads to a flatter energy landscape. This is commonly known as adaptive bias. \n \nMetadynamics \nWhile umbrella sampling effectively uses a fixed harmonic bias potential W to focus sampling on \nspecific regions of the configuration space for systems with known energy barriers, it shows \nlimited applicability for complex systems. This technique lacks the dynamic adaptability to target \npotential energy landscapes with multiple local minima separated by large energy barriers often \nencountered in processes such as biomolecular self-assembly.  \nMetadynamics (MetaD), an enhanced sampling technique developed by Laio and Parrinello in \n2002, (Laio and Parrinello 2002) overcomes these limitations by introducing a history-dependent \nbiasing potential, which flattens the free energy surface and facilitates the crossing of energy \nbarriers. The authors have reasoned that these traditional methods often struggle to escape local \nminima in the free energy surface due to high energy barriers, limiting their effectiveness in \nstudying processes like protein folding. Metadynamics enables cost-efficient exploration of rare \nevents and thermodynamic properties in systems inaccessible through standard MD simulations.  \n\n\nMetadynamics addresses this by employing coarse-grained, non-Markovian dynamics in a space \ndefined by collective coordinates. A key feature of this method is the inclusion of a bias potential, \ntypically implemented as a sum of Gaussian functions. These Gaussians \"fill\" the free-energy \nwells over time, flattening the landscape and enabling the system to escape local minima. This \niterative process not only facilitates the exploration of the free energy surface but also allows its \nquantitative reconstruction as a function of the chosen collective coordinate, providing insights \ninto the thermodynamics and kinetics of the system under investigation. \nThe method's fundamental principles, assumptions, and procedures are outlined for the 2002 \nstudy (Laio  and Parrinello 2002), later recognized as the standard metadynamics approach \n(Standard MetaD). Bussi and Laio (2020) summarized the foundational steps, noting that the \nsuccess of metadynamics depends significantly on the selection of the CVs and biasing. This \nmethodology assumes a finite set of n relevant CVs, si, to describe the system's free energy \nsurface, F(s). Forces guiding the exploration of the free energy surface are defined as: \nğ¹# = âˆ’ğœ•ğ¹ / ğœ•ğ‘ #                                                                          (13) \nTo estimate these forces, an ensemble of P replicas is generated, each constrained to a specific \nsi value using Lagrange multipliers. The average force is evaluated as Fi=âŸ¨Î»iâŸ©, where Î»i are the \nmultipliers. \nThe exploration employs a coarse-grained dynamics approach, using the evolution equation: \nğœ#%&' = ğœ#% + ğ›¿ğœ(ğœ™#\n% / |ğœ™%|)                                                             (14)  \nwhere Ïƒi=si/Î”si are scaled variables, Ï•i=FiÎ”si are scaled forces, and Î´Ïƒ is a stepping parameter. \nThis equation represents the steepest descent in the free energy surface. To enhance sampling, \nthe \nhistory-dependent \nbias \nis \nintroduced \nby \nreplacing \nthe \nforces \nFi \nwith \nFi+âˆ‘kW*exp(âˆ’|sâˆ’sk|2/(2Î´s2)), based on:  \nğœ™# â†’ğœ™# âˆ’ğœ•\nğœ•ğœ#\nğ‘ŠY\n%, (%\nZ\n#\nğ‘’)|+\" )+\"\n#,|$\n\",+$\n                                                           (15)  \nwhere W and Î´s are respectively the height and width of Gaussian functions. The Gaussians \ndiscourage revisiting previously sampled regions and enabling transitions between them. For \nlarge t (and especially if the width of the Gaussians is sufficiently small compared to the length of \na \ntypical \nvariation \nof \nV), \nthe \nfree \nenergy \nsurface \ncan \nbe \nreconstructed \nas \nF(s)â‰ˆâˆ’âˆ‘kW*exp(âˆ’|sâˆ’sk|2/(2Î´s2)), where: \nâˆ’Y\n%, (%\nğ‘Šğ‘’)|+)+%,|$\n\",+$\nâ†’ ğ‘‰(ğ‘ )                                                                       (16) \n\n\nThe efficiency of the method scales with (1/Î´Ïƒ)n, and judicious choices of Î”si, W, and Î´Ïƒ balance \naccuracy and efficiency. The Gaussian height W satisfies: (W/Î´Ïƒ)e-1/2=Î±âŸ¨FâŸ©1/2, with Î±<1, typically \naround 0.5 from their test systems.  \nIt is also noted that while their early examples focus on biomolecules, they have yet to highlight \nthe application of metadynamics in assembly processes. However, the versatility of \nmetadynamics is reflected in its variability of scaling different bias potentials to different scientific \nproblems. Therefore, they suggested adaptive parameter selection for future improvements to \nbetter fit local free energy surface features. \nLater research expanded metadynamics subcategories to refine its performance and expand its \napplicability. Gao et al. (2019) categorized metadynamics as CV-based sampling that employs \npredefined CVs to guide the simulation. The equilibrium distribution, p0(s), and the free energy, \nF(s), are derived from the Boltzmann distribution, allowing the system to sample less probable \nstates effectively. Therefore, some of the most prominent derivatives of metadynamics have been \nfocusing on enhancing sampling efficiency.  \nBias-exchange metadynamics (BE-MetaD) extends the method to high-dimensional systems by \nemploying parallel simulations with different CVs, broadening the sampled configuration space.  \n(Piana and Laio, 2007) The method utilizes multiple replicas running at the same temperature, \neach biased by a different CV. These replicas periodically exchange conformations and enhance \ndiffusion in the CV space within the system trajectory. The results are not direct multidimensional \nfree energy surfaces but rather low-dimensional projections along different CVs. \nWell-tempered metadynamics (WT-MetaD) was also developed (Barducci et al., 2008) to improve \nstability by reducing artifacts and oversampling. This method gradually reduces the height of the \nGaussian functions as the bias potential grows, ensuring convergence of V(s). The height of the \nGaussian functions decreases as Ï‰(t)=Ï‰/(1+Î²Î³-1V(s,t)), where Î³ is the bias factor. This refinement \nallows WT-MetaD to reconstruct accurate free energy surfaces even for systems with high energy \nbarriers. \nMultiple walkers metadynamics (MW-MetaD) employs parallel trajectories, or â€œwalkers,â€ that \nshare a common CV and deposit Gaussian functions into a shared bias potential. This \nparallelization accelerates exploration by distributing sampling efforts similar to REMD (Williams-\nNoonan et al. 2023). \nVariationally enhanced sampling (VES) introduces a functional approach to optimize the bias \npotential (Valsson and Parrinello 2014). The functional ğ›º[ğ‘‰(ğ‘ )], often defined as the Kullback-\nLeibler divergence, minimizes the difference between the target distribution and the actual \ndistribution. The bias potential in VES is represented as V(s)=âˆ‘k akÏ•k(s), where Ï•k(s) are basis \nfunctions and ak are parameters optimized using stochastic gradient descent. This method allows \ndynamic optimization of the bias potential, bridging enhanced sampling methods with machine \nlearning techniques. \n\n\nOther developments, such as parallel-tempered metadynamics and on-the-fly parameter \noptimization, integrate multicanonical simulations to achieve a uniform sampling of states across \nenergy levels.  \nParallel-tempered metadynamics (PT-MetaD) combines replica exchange Monte Carlo with \nadaptive biasing in MetaD to enhance sampling efficiency in Molecular Dynamics simulations \n(Bussi et al. 2006). Gaussians are deposited along selected CVs at a frequency 1/ğœG, \nprogressively flattening the free-energy landscape: \nğ‘‰#(ğ‘ ; ğ‘¡) = ğ‘‰#(ğ‘ ; ğ‘¡âˆ’ğ›¿ğ‘¡) + ğ‘¤#ğ‘’\n)(. ).\"(%))$\n\"+%\n$\n                                                      (17)  \nThe Gaussian height wi is scaled with temperature, typically following wi âˆ Ti. This ensures that \nhigher-temperature replicas rapidly explore the free-energy surface, allowing low-temperature \nreplicas to decorrelate faster. The CVs used for biasing include the gyration radius of the \nbackbone and the number of hydrogen bonds. A geometric temperature distribution is also \nemployed for constant acceptance ratios across replicas to maximize exchange efficiency.  \nExpanding on BE-MetaD, the development of Parallel Bias Metadynamics (PB-MetaD) also \nutilizes parallelization to apply multiple bias potentials, following the WT-MetaD form, across \ndifferent CVs. PB-MetaD introduces a discrete variable Î· that toggles bias potentials \ncorresponding to the active CV, to prevent bias contamination. By weighting the deposited \nGaussians by the conditional probability P(Î· | R), it allows straightforward reweighting to recover \nhigh-dimensional free-energy landscapes (Pfaendtner and Bonomi 2015). \nComparing these methods reveals distinct advantages tailored to different simulation challenges. \nTo address bias convergence issues for Standard MetaD, WT-MetaD focuses on ensuring reliable \nfree energy reconstruction, while MW-MetaD and BE-MetaD enhance efficiency through \nparallelization. Later developments of MetaD â€” VES, On-the-fly parameter optimization, PT-\nMetaD and PB-MetaD â€” reduce non-ergodic sampling through adaptive biasing, where bias \npotentials evolve based on system response, showing joint interest in the field to balance both \naspects and introducing prospective machine learning-based optimization, offering more powerful \ntools for modern simulations. (Invernizzi and Parrinello 2022; Zerze et al. 2023) \nSurrogate Models in Enhanced Sampling of Self-assembly Process using ML \nTechniques  \n \nStudying biomolecular self-assembly in silico poses numerous challenges such as estimating \ncomplex free energy landscapes, slow transitions between different metastable states, and \nsampling the long time scale of a self-assembly process. The two major limitations in molecular \nsimulations as highlighted by Karplus et al (Karplus and Petsko 1990), are the approximations in \nthe potential energy functions and the lengths of the simulations. The first introduces systematic \nerrors and the second statistical errors, respectively. The first can be addressed by developing \naccurate force fields informed by quantum mechanical calculations or experiments for various \nmolecular chemical species. The second requires the use of novel enhanced sampling techniques \n\n\nin order to capture and simplify the complex rugged free energy landscape of proteins and other \nmacromolecules. ML models provide an organic framework for high-fidelity enhanced sampling \nmethods as most of the problems in ML also overlap with approaches in MD under different names \nlike dimensionality reduction, depositing biasing potential, and capturing tractable, intractable \nprobability densities (Mehdi, Smith et al. 2024). \n \nSimulations of long timescale phenomena like nucleation, and self-assembly accumulate \noverhead sampling costs of crossing metastable transition barriers, and hence require strategies \nto accurately describe reaction RCs or CVs for biasing potentials. Various deep learning models \nhave been used to leverage artificial neural networks (ANN) in order to learn the optimal \nsubmanifold of the free energy landscape by discovery of CVs such that only dominant metastable \nstates or slow dynamics are captured. \n \nBased on Markov State Model (MSM), Mardt et al. (Mardt, Pasquali et al. 2018) developed a \ndeep learning framework utilizing a variational approach for the Markov process (VAMPnet) which \ncombines all the tasks of MSM, featurization of short MD trajectories, dimensionality reduction of \nfeatures and clustering into microstates. VAMPnet relies on time-lagged configurational MD data \nas input in two deep networks (i.e., Siamese neural network)(Figure 4) combined by maximizing \nVAMP-2 score (eq 19) following the optimization of latent variable sets related to each other by \nthe Koopman operator (eq 18).  \n \nğ¸[ğœ’' (ğ‘¥%&0 )] â‰ˆğ¾1 ğ¸[ğœ’2(ğ‘¥% )]                                                          (18) \n \nğ‘… e \" [ğœ’' , ğœ’2 ] = gh ğ¶22\n)'/\" ğ¶2' ğ¶''\n)'/\"  hg                                          (19) \n \nwhere \n ğ¶22 = ğ¸% [ ğœ’2 (ğ‘¥% )  ğœ’2 (ğ‘¥% ) ]  \n \n, \n \n \nğ¶2' = ğ¸% [ \n ğœ’2 (ğ‘¥% ) \n ğœ’' (ğ‘¥%&0 )] \n \n, \nğ¶'' =\nğ¸%&0 [  ğœ’' (ğ‘¥%&0 )  ğœ’' (ğ‘¥%&0 )]   \n \n \n \nFigure 4: Siamese neural network of VAMnet containing two sub-networks with same weights \n(Mardt, Pasquali et al. 2018). \n\n\n \n \nVAMPnets can be used to identify CVs corresponding to the slow modes of self-assembly by \nappropriately selecting a lag time, which can be determined based on the autocorrelation time \ndecay of relevant order parameters, such as cluster size, radial distribution functions, or pairwise \ndistances. However, VAMPnets are utilized to learn discrete metastable stable states as output \nand since meaningful enhanced sampling requires continuous, interpretable RCs, this limits its \napplication. Chen et al. (Chen, Sidky et al. 2019) proposed state-free VAMPnet (SRV) where the \ngoal is not to partition the state space but to learn a continuous non-linear function of the input \ndata that serves as a basis for approximating eigenvalues of transfer operator within a variational \napproach for conformational (VAC) dynamic framework. SRV consists of a Siamese neural \nnetwork where a pair of time-lagged configurations are fed into the same architecture having the \nsame weights. The non-linear mapping of latent variables from the lobes is plugged in the \ngeneralized eigenvalue equation of the transfer operator and overall the model is trained to \nminimize the loss function ğ¿= ğ›´# ğ‘”(ğœ†4)\nn, where ğœ†# is eigenvalue and ğ‘” is a monotonically \ndecreasing function of the eigenvalue. \n \nAnother approach utilizing the VAC dynamics is Deep-TICA (Deep-Time Lagged Independent \nComponent Analysis) by Bonati et al (Bonati, Piccini et al. 2021), which enables efficient sampling \nof rare events, such as molecular conformational changes and crystallization, enhancing \nsimulation convergence for studying complex phenomena. In TICA, the eigenfunction of the \ntransfer operator is constructed as a linear combination of descriptors of the system (eq 20). A \ndetailed balance condition makes the transfer operator a self-adjoint matrix. The matrix elements \nare computed by time auto-correlation of the descriptors in a generalized eigenvalue problem (eq \n21). \n ğœ“4\nn(ğ‘…) = ğ›´56' ğ›¼#5 ğ‘‘5 (ğ‘…)                                                          (20) \nğ¶(ğœ) ğ›¼#  = ğœ† q ğ¶(0) ğ›¼#                                                                 (21) \n \nwhere   ğ¶#5(ğœ) = < ğ‘‘# (ğ‘…% ) ğ‘‘5(ğ‘…%&0 ) > \n             ğ¶#5(0) = < ğ‘‘# (ğ‘…% ) ğ‘‘5 (ğ‘…%) > \n \nDeep-TICA consists of ANN that takes time-lagged descriptors as input and non-linearizes the \nlinear TICA method by outputting the autocorrelation coefficient as a function of latent variables \nwhich is further plugged in the generalized eigenvalue equation. The whole problem becomes \nmaximization of eigenvalues such that errors are back propagated using a loss function, ğ¿=\n âˆ’ğ›´# ğœ† q(ğœƒ), where ğœƒ represents a set of parameters, namely weights and biases of ANN. The Deep-\nTICA method is instrumental in learning slow modes from a biased timescale starting from \nsuboptimal CVs, nevertheless combining both the trajectories, one that of the initial descriptive \nRCs and the other corresponding to the learned RCs, posing a non-trivial challenge.  \n \nAnother unsupervised nonlinear reduction technique for uncovering CVs is diffusion maps \n(dMaps), which compute the embedding of high-dimensional data into low-dimensional space \nwhose coordinates can be computed from eigenvectors and eigenvalues of a diffusion operator \n\n\non the data (Coifman, Lafon et al. 2005) (Ferguson, Panagiotopoulos et al. 2011). Ferguson et al \n(Long and Ferguson 2014) employed dMap to study the kinetics and thermodynamics of self-\nassembly pathways of patchy colloidal particles using Brownian dynamics. In order to implement \ndMap on simulation data, a suitable cluster distance matrix has to be defined to measure the \nkinetic proximity of clusters to be formed in terms of cluster similarity. Since such a metric must \nbe rotational and permutation invariant and give insights into the local structure of the clusters, \nthe cluster similarity problem was transformed into a graph similarity problem using a spectral \ngraph matching algorithm. Unlike other ANN models, dMap uses a Gaussian kernel to generate \na right-stochastic Markov matrix from the symmetric matrix of pairwise cluster similarities (eq 22) \n \nğ´#5  =  ğ‘’ğ‘¥ğ‘ sâˆ’\n7$\"&\n\"8 t                                                               (22) \n \nWhere ğ‘‘#5 is cluster distance or cluster similarity metric between ith and jth cluster and ğœ€ is the \nbandwidth of gaussian. Following row normalization of A matrix, it can transformed into a Markov \nmatrix M as shown below (eq 23-24) \n \nğ·#5  =     ğ›´ !96' ğ´#9   ,   ğ‘–ğ‘“ ğ‘–= ğ‘—                                                (23) \n                               , ğ‘œğ‘¡â„ğ‘’ğ‘Ÿğ‘¤ğ‘–ğ‘ ğ‘’                    \n      \nğ‘€ = ğ·)' ğ´                                                                            (24) \n \nThe eigenvectors of the M matrix are discrete estimations of the eigenfunctions of the Fokker-\nPlank operator, describing a diffusion process over the data. The collective modes above the \nspectral gap of eigenvalues steer the long-time evolution of the system. Projecting the ith cluster \nalong the ith component of these eigenvectors gives the slow, dominant mode dynamics driving \nself-assembly. However, dMaps suffer from two main limitations (Sidky, Chen et al. 2020), first is \nthe assumption that diffusive dynamics over the high-dimensional data may or may not be a good \napproximation of the true molecular dynamics. The second is that the dMaps donâ€™t define an \nexplicit mapping from atomic coordinates to the low-dimensional CVs, rendering it incompatible \nwith enhanced sampling methods like umbrella sampling or metadynamics which require the \ngradients of atomic coordinates with respect to atomic coordinates. \n \nSome of the dMap-based enhanced sampling methods are diffusion-map-directed MD (DM-d-\nDM) (Rohrdanz, Zheng et al. 2011) and intrinsic map dynamics (iMapD) (Chiavazzo, Covino et \nal. 2017). DM-d-MD method enhances sampling at the frontier of explored space, initiating an \nunbiased simulation rather than imposing artificial bias. The local scaling of the gaussian kernel \nwidth ğœ€ around a certain configuration is performed through multidimensional scaling that reduces \nhigh dimensional configurational space to a â€œlocally flatâ€ low dimensional space (Rohrdanz, Zheng \net al. 2011). The parameter ğœ€ determines how noise in a highly variable conformational density is \nreduced. If ğœ€ is too small the results will be all noise in a â€œlocally flatâ€ region and if ğœ€ is too large, \nregions will be artificially flat. In iMapD, similar to DM-d-DM, the short simulation runs are \nembedded using dMaps, but the boundary of the explored space is extended outwards by a \ncertain amount using local principal component analysis (PCA). The new unbiased simulation is \n\n\nproduced from the extended region; in this iMap method, it is said to tunnel through the free \nenergy landscape. Though both of these methods can approximate true MD over the energy \nbarrier by not letting molecules tumble downward from the energy barrier, the resulting CVs are \nstill discontinuous and non-differential. This can be overcome using ANN-based diffusion net \n(DNETS) (Mishne, Shaham et al. 2019), which trains an ANN encoder to learn functional maps \nfrom atomic coordinates to a low-dimensional dMap. \n  \nSelf-assembly conventionally studied in only thermodynamic terms is insufficient to give a full \nstatistical description of the major underlying kinetic pathways (Conti and Cecchini 2016) (Conti, \nDel Rosso et al. 2016) (Palma, Cecchini et al. 2012). Kinetic network models (KNMs) (Liu, Qiu et \nal. 2022) can be deployed to study the kinetic control of self-assembly by combining many MD \nsimulation trajectories like the Markov state model. However, KNMs suffer from two major \nchallenges for their applications in the process of self-assembly (Liu, Xue et al. 2023). First, the \nselected features that are descriptive of self-assembly should be invariant to permutations and \nrotational symmetries in the system. Second, self-assembly is typically an energetically downhill \nprocess in a free energy landscape that can involve the trajectory of monomer aggregation from \nout-of-equilibrium states with insufficient sampling of the dissociation of monomers. This is \nopposed to the way KNMs extract slow CVs by imposing detailed, balanced conditions. \nGraphVAMPnet (Liu, Xue et al. 2023) resolves these issues by combining the workflow of high-\ndimensional dynamic graph embedding of the molecules and VAMPnet operating on the time-\nlagged graph-embedded conformations of molecules as inputs. The graph representation of \nmolecules in GraphVAMPnet is based on the SchNet framework (SchÃ¼tt, Sauceda et al. 2018) \nwith the notion that the particles with the same permutation and rotational symmetries should \nbelong to the same node embedding. The edges between the nodes are defined by an extensible \npairwise gaussian vector (Eq(8)) characterized by a cut-off distance between pairwise particles in \nthe nearest neighbor region. \n \n ğ‘’#59  =  ğ‘’ğ‘¥ğ‘sâˆ’\n(7\"& ) :')\n+$\nt                                                       (25) \n \nwhere ğ‘’#59 is the kth element of edge vector ğ‘’#5 , ğ‘‘#5 is the pairwise distance between node i and \nnode j, and ğ‘9 is the center of the expansion.  \n \nAll node vectors and edge vectors in the graph at a particular layer are mapped into the same \ndimension by dense layers. These are further input into the attention-weighted continuous \nconvolution layer in which the local interaction of each particle with its surroundings is obtained \nthrough attention weights. Attention weight is representative of the relative importance of all \nadjacent particles of a central particle in a convolution. The local interactions on particles obtained \nfrom this layer are projected back and added to the original node vectors while the edge vectors \nremain the same. The time-lagged conformations sent through this graph neural network are \npassed onto the Siamese neural network (i.e., weights in two ANNs are the same) of the \nVAMPnet. The set of lagged features is transformed in the hidden layers to optimize the singular \nvalue decomposition problem using the Koopman operator. The optimally approximated leading \nsingular function of the Koopman operator corresponds to the slowest CV of the reduced kinetic \n\n\nspace. While the graph neural network ensures that the systemâ€™s local and global interaction \nenvironment is captured following permutation and rotational invariance, VAMpnet allows for \npartial reversibility of the formation of self-assemblies, exhibiting the true dynamics of the system. \n \nThe cooperative, collective interaction steering self-assembly of molecules can also be captured \nby Transition Path Sampling (TPS). The transition paths (TPs) are special trajectory segments \nthat capture the rare event reorganization going through the infrequent, rapid transitions between \ndifferent metastable states. Since TPs are stochastic in nature, hence they require a probabilistic \nframework using the committor function. A committor function ğ‘.(ğ‘¥) represents the probability that \na trajectory enters state S first, with S = A or B, where x is a vector feature of the starting point X \nin the configuration space. The committor to a target state reports on the progress of the reaction \nand predicts the trajectory in a Markovian way, thus making it an ideal RC. Jung et al. (Jung, \nCovino et al. 2023) designed an iterative algorithm to learn the committor of rare events using a \nneural network in a way similar to reinforcement learning. The committor probability is encoded \nin the dense layers of the neural network, where the transition path is progressively weighed in \nfavor of the reactant from many attempts to maximize the committors along trajectories by using \nnegative log-likelihood of it as a loss function. The neural network architecture is pyramidal so as \nto arrange the features in a resolution hierarchy, from the highest possible resolution of the \ncartesian coordinates of atomic positions to a singular quantity of committor. The mechanism has \nbeen successfully applied to study ion association in solution and protein-membrane assembly \n(Jung, Covino et al. 2023). \n \nThe use of autoencoder architecture offers a promising role in the construction of low-dimensional \nfree energy where a somewhat complete separation of timescales can be achieved. These \narchitectures consist of encoder-decoder multilayer perceptrons in which the encoder section \ncompresses the input data to a lower dimensional space also known as latent space and the \ndecoder section reconstructs the reduced data to its original size. The objective of the learning \nprocess is to minimize the deviation between the input and reconstructed data. The input data as \nstructural descriptors of the molecular system must abide by simple symmetries like invariance \nwith respect to translation, rotation, and permutation. Appeldorn et al (Appeldorn, Lemcke et al. \n2022) employed a neural network autoencoder called EncoderMap (Lemke and Peter 2019) in \norder to study the self-assembly of two complementary single-stranded DNA. They used \ncomplementary base pair distance as the input structural features, which are mapped onto a latent \nspace in the neural network, and an MSM is constructed in this space. This allows for the \ninspection of the latent space coordinates as order parameters.  \n \nSection 4 - Applications \n \nApplication of Enhanced Sampling Techniques to Different Biomolecular Systems \n \n(1) Peptides \nREMD has been used in numerous studies concerned with the self-assembly of short peptide \nchains encompassing between 4 and 30 amino acid residues. Most of these studies are related \n\n\nto amyloids or amyloidogenic fragments (Anand 2008; Baumketner 2005; Cecchini 2004; Gee \n2011; Jeon 2012; Martel 2017; Takeda 2008), chosen for their relevance to human diseases \nincluding Alzheimer's Disease (AD). REMD has also been used to examine phenylalanine-\ncontaining peptides which form self-assembled peptide nanostructures (Jeon 2014; Rissanou \n2013; Tamamis 2009; Xiong 2019); transmembrane and membrane-bound peptides (Kokubo \n2004; Martel 2017; Urano 2015); the formation of peptide dimers and oligomers (Baumketner \n2005; Gee 2011; Jeon 2012; Soto 2010; Takedo 2008; Wolf 2008), and protein-ligand binding \n(Lockhart 2023). \n \nAs previously noted, the challenge of identifying the forces driving the self-assembly of \nbiomolecules, such as peptides, requires estimating free energy differences using either a single \numbrella sampling method or combining methods such as umbrella sampling with REMD. Yu and \nSchatz applied umbrella sampling in conjunction with targeted MD to understand the factors which \ndrive the self-assembly of peptide amphiphiles to form micelles (Yu and Schatz 2013). The study \ndetermined the driving force to be enthalpic, in particular electrostatic interactions followed by van \nder Waals interactions. The mechanism of self-assembly was determined from the potential of \nmean force (PMF) (Yu and Scatz 2013).  \n \nWolf et. al. 2008 investigated the mechanism underlying the self-assembly of peptides into \namyloid fibrils, and found that the final amyloid fibril composition was governed by \nthermodynamics. The study reported a first order phase transition, which was linked to the \nformation of amyloid fibrils. The authors used the free energy landscape to predict the final \ncomposition of the self-assembled amyloid fibrils and compare their findings to experiments. In \nthis study, REMD was used alongside umbrella sampling with a harmonic bias to calculate the \nPMF, and was observed to provide a tenfold increase to speed compared to traditional umbrella \nsampling. \n \nJeon and Shell (2014) examined the self-assembly of cyclo-diphenylalanine (cyclo-FF) in vacuum \nand compared it to the assembly of linear FF peptides in water. The study applied umbrella \nsampling replica-exchange MD (U-REMD) with harmonic constraints to study the interaction \nbetween cyclo-FF molecules and determine the PMF. Cyclo-FF molecules assembled to form a \nladder-like structure due to electrostatic and van der Waals interactions in the backbone. The \nauthors noted that this was different from the assembly of linear FF in water where the driving \nforces were arising from the hydrophobic effect and electrostatic interactions of the sidechains. \nLaio et al. (2012) used BE-MetaD to explore the aggregation process of 18 chains of 8-valine \n(VAL8) in a disordered state to an ordered Î²-sheet structure. The BE-MetaD simulation was run \nfor 4340 ns, with 8 replicas biased by 8 different CVs, each corresponding to different features of \namyloid aggregation (such as parallel/antiparallel Î²-strands and packing of Î²-sheets). \nConvergence of the bias potential was monitored, and free energy estimates were derived using \nWHAM. The system explored hundreds of configurations. The results revealed distinct free \nenergy minima for structures rich in antiparallel Î²-sheets and those with more parallel Î²-strands. \nBy highlighting a complex, non-trivial aggregation pathway, this method provided valuable insights \n\n\ninto the formation of amyloid-like structures and the influence of peptide sequences on the \ndynamics of aggregation, such as the transition from antiparallel to parallel Î²-sheets. \nMore recently, Pfaendtner and Sampath (2019) employed Parallel-Tempering Metadynamics in \nthe Well-Tempered Ensemble (PTMetaD-WTE) to investigate the binding behavior of the LKÎ±14 \npeptide on crystalline and amorphous silica surfaces. The assumptions underlying the use of \nPTMetaD-WTE in this research include the hypothesis that peptide binding to the surface is \ngoverned by electrostatic interactions and that the peptide adopts a helical structure upon \nadsorption. By focusing on CVs related to the peptide's interaction with the surface and its \nconformation, the method allowed for the efficient exploration of the peptide's conformational \nlandscape and its binding affinity to the silica surface. The use of PTMetaD-WTE facilitated the \nanalysis of peptide binding on both crystalline and amorphous surfaces, highlighting the \ndifferences in binding strength and conformational diversity between the two surface types.  \n(2) Proteins \nFormation of quaternary structure in protein complexes has been studied with REMD (Siradzan \n2012). The long time scales associated with spontaneous self-assembly require the simulated \nsystems to be placed under constraints â€“ such as fixing the COM distance between two molecules \nâ€“ to allow examination of the conformation ensembles and energetics associated with close \ncontact between particles. The analysis of constrained or biased MD simulations can provide key \ninformation about the processes underlying self-assembly. Constrained systems are often used \nto characterize a PMF, binding free energy, or another energy surface. Such energy surfaces may \nbe used for developing coarse-grained potentials. \n \nYuan et al. (2020) employed metadynamics simulations to investigate the dissociation \nmechanisms of AG10 and tafamidis from the thyroxine-binding sites of the TTR tetramer. By \nanalyzing the dissociation pathways, the study identified key interactions, such as salt bridges \nand hydrogen bonds, crucial for the dissociation of AG10. Whereas the dissociation of tafamidis \ninvolved more intricate interactions, including cation-Ï€ and hydrogen bond formations. The \nsimulations revealed two major energy wells for the drug dissociation pathways, showing that \ntafamidis has a stronger binding affinity. AG10 exhibits more contacts with the target protein, while \ntafamidis exhibits a more complex multistep unbinding process involving three energy wells. \nWell-tempered metadynamics (WT-MetaD) was used by Xu et al. (2022) to study the binding \nmechanism between the supramolecular tweezer CLR01 and the lysine residues on the 14-3-3Ïƒ \nprotein. This was done by enhancing the sampling of binding conformations and calculating \nbinding free energies. The study employed WT-MetaD to explore the thermodynamics and \nkinetics of this interaction, with two CVs chosen to track the distance and coordination number \nbetween the tweezer and lysine residues. This method allowed for the construction of a \ncomprehensive free energy surface that helped identify binding sites with different affinities for \nthe tweezer. Among the 17 lysine residues on 14-3-3Ïƒ, 8 sites were found to form inclusion \ncomplexes, with some exhibiting strong binding (K214) and others showing moderate binding. \nThe simulation results, which aligned well with experimental measurements, revealed that spatial \nhindrance around the lysine residues was the key factor influencing binding.  \n\n\nSalvalaglio et al. (2022) used Parallel-Tempering Metadynamics with Well-Tempered Ensemble \n(PTMetaD-WTE), to enhance the exploration of DHH1N's conformational ensemble by \naccelerating sampling of its free energy landscape. Through biased simulations using CVs such \nas CÎ±â€“CÎ± and CÎ³â€“CÎ³ contacts, backbone hydrogen bonds, and structural parameters, PTMetaD-\nWTE effectively mapped the protein's configurational states, revealing the intrinsic disorder of \nDHH1N. The analysis of the one-dimensional free energy profiles highlighted a primary global \nminimum corresponding to a largely disordered state, consistent across CHARMM36m and \nCHARMM22* force fields. Two-dimensional free energy surfaces further confirmed a weakly \nfunneled landscape with distinct metastable states, providing insight into the proteinâ€™s \nconformational flexibility. Complementary BE-MetaD simulations reinforced these findings by \nexpanding the sampling of residue-residue interactions and secondary structure motifs, \nparticularly revealing Î²-strand formation linked to specific residue contacts in CHARMM36m. \nOverall, PTMetaD-WTE helped detail a statistically robust representation of DHH1Nâ€™s free energy \nlandscape, capturing its disordered nature while elucidating subtle force-field-dependent \nstructural propensities. \n(3) Polymers \nUmbrella sampling with harmonic potentials was utilized to calculate the free energy between \ndifferent aggregates of an amphiphile and polyethylene glycol (PEG) polymer (Brunel et. al. 2019). \nThe authors found that the inclusion of PEG side chains created strong repulsive barriers, \nresulting in the aggregates to transition from spheres to larger vesicles. Weaker repulsive barriers \nled to formation of smaller vesicles and tubular nanostructures. \nIn Mu et al. (2017), well-tempered metadynamics (WT-MetaD) significantly enhanced the \nexploration of the free energy surface of TXB-LII binding, overcoming the limitations of unbiased \nMD simulations. Due to the high flexibility of both TXB and LII, the binding landscape is rugged, \ncharacterized by numerous local minima arising from the presence of highly polar residues along \nwith the polar ring motif in TXB. Unbiased MD simulations, despite being run for 200 ns across \nthree independent repeats, failed to identify a stable binding mode, with configurations often \ngetting trapped in local minima for extended periods. The study employs PTMetaD-WTE to \nefficiently explore the free energy landscape of GB1 dimerization under different crowding \nconditions by biasing key RCs. The convergence of the PTMetaD-WTE simulation was verified \nthrough the diffusion of the CV and decay of the Gaussian height at 300 K, indicating that the \nenhanced sampling successfully overcame energy barriers and provided a more complete free \nenergy surface. The simulations reveal that lysozyme crowders destabilize GB1 dimers, \nparticularly the side-by-side configuration, by shifting the free energy minimum to a state where \ncrowders disrupt native interactions. Comparative simulations with truncated LII analogs (C15P \nand C15PP) demonstrated that the pyrophosphate and GlcNAc-1 groups were essential for stable \nTXB binding, reinforcing the importance of electrostatic complementarity. Overall, PTMetaD-WTE \nnot only facilitated the identification of stable TXB-LII binding modes but also provided \nmechanistic insights into the molecular determinants of affinity and specificity.  \nHirokawa et al. (2018) used WT-MetaD simulations to understand the binding kinetics of \namantadine and adamantyl bromothiophene to M2 channels (S31 and N31 mutants). \nMetadynamics identified the binding of amantadine to the S31 M2 channel as characterized by \n\n\nthree steps (L1, TS, L2), together with the free energy profiles to map these transitions. Similar \ninsights were gained for adamantyl bromothiophene, which showed more complex binding \ndynamics. For adamantyl bromothiophene, the metadynamics simulations also helped elucidate \nits dual binding mode in S31 and N31 M2 channels, which could not be captured by conventional \nmethods. The broad, funnel-shaped energy profiles indicated differences in binding kinetics \nbetween the two M2 mutants. \nIn Parrinello et al. (2013), metadynamics played a critical role in understanding the dimerization \nand trimerization processes of fibritin by probing protein-protein interactions. For the dimerization \nprocess, metadynamics was used to apply bias to two configurational CVs: the distance between \nthe COM of the monomers and the number of specific monomerâ€“monomer contacts. The analysis \nof the dimer's structural ensemble suggested that various configurations, including an almost \nantiparallel dimer arrangement, were thermodynamically favored, even in the absence of a third \nmonomer. For the trimerization process, the PTMetaD-WTE approach was also applied, using \nsimilar biasing CVs. The results revealed a funnel-shaped free-energy landscape, strongly biased \ntoward the formation of the experimental trimeric structure, with minimal structural heterogeneity \ncompared to the dimerization process. The trimer's binding free energy closely matched \nexperimental values. \nFrom the studies of Eslami and MÃ¼ller-Plathe (2024), adaptive-numerical-bias metadynamics was \nemployed to investigate the self-assembly of triblock Janus nanoparticles into open and close-\npacked 3D colloidal crystals. This method progressively adds adaptive biasing potentials to the \nsystem's unbiased potential energy, enabling efficient traversal of high-energy barriers between \nphases. A key assumption in this approach is that suitable order parameters can distinguish \ndifferent phases, guiding the simulation toward relevant regions of the free-energy surface. The \nuse of bond-orientational order parameters based on spherical harmonics, allowed for precise \ncharacterization of local crystalline order, distinguishable between phases. The metadynamics \nsimulations revealed that the free-energy barriers for nucleation of open lattices are generally \nlower than those for denser lattices, a finding attributed to the lower density mismatch between \nthe liquid and open crystalline phases. By iteratively refining the biasing potential, the \nmetadynamics approach successfully mapped the free-energy basins of different phases and \nidentified transition pathways, offering valuable insights into the nucleation and growth of colloidal \ncrystals. \n(4) Nucleic Acids \nIn the research of the 22-nt monomolecular DNA G4 sequence folding process, Moraca et al. \n(2020) employed Well-Tempered Metadynamics (WT-MetaD) simulations to overcome the time-\nscale limitations inherent in molecular simulations and to accelerate the exploration of rare events \nduring the formation of the G4 structure. WT-MetaD allowed the identification of significant \nmetastable states, which are crucial for understanding the folding process of G4 DNA. The \nsimulations focused on two key CVs: the coordination of Hoogsteen hydrogen bonds within the \nG-tetrads and the Ï€-Ï€ stacking interactions among the guanines of the G-triplets. WT-MetaD was \ninstrumental in revealing an ensemble of conformations that had previously been undetectable, \nparticularly those involving partial G-tetrad planes and varying degrees of strand slippage. The \nsimulation results showed that vertical slippage of G-triplets was a key mechanism in G4 folding, \n\n\nwith two adjacent G-triplets exhibiting a higher probability of slippage than opposites. The studyâ€™s \nfindings also supported the hypothesis that the formation of G-triad intermediates, involving \nslippage and incomplete G-tetrads, could play a crucial role in the early and late stages of G4 \nformation and disruption. By reweighting the sampling data from the WT-MetaD simulation, the \nauthors were able to construct a free energy surface that highlighted the stability and probability \nof various G4 conformations.  \n \nFerrarini et al. (2023) employed WT-MetaD to obtain a detailed description of the free energy \nlandscape of ZnÂ²âº binding to ATP  for the self-assembly of materials exhibiting non-equilibrium \nbehaviors, which involved identifying distinct coordination modes between ZnÂ²âº and phosphate \noxygens in the ATP triphosphate chain. By using WT-MetaD, the simulations provided insight into \nthe most stable ZnÂ²âºâ€“ATP binding mode and were essential in understanding how the \nconformational flexibility of the triphosphate chain influences the stability of the binding. This \nmethod enabled a robust analysis of free energy differences and coordination geometries, thereby \nrefining the understanding of ZnÂ²âº coordination in ATP and informing future coarse-grained \nsimulations examining assembly/disassembly processes. \nIn Wang et al. (2024), WT-MetaD played a central role in unraveling the pH-dependent assembly \nmechanism of the TLR3Ã—4/dsRNA signaling complex by enabling in-depth exploration of its free \nenergy landscape. To incorporate environmental pH effects, the study combined metadynamics \nwith constant pH MD (CpHMD), enabling the investigation of dynamics underlying pH-dependent \nassembly. This hybrid approach was crucial for analyzing the protonation states of titratable \nresidues. Four CpHMD-metadynamics simulations were conducted based on pH values, focusing \non combinations of RCs. Convergence was confirmed using block-analysis techniques and the \nplateauing of the PMF curves, highlighting the robustness of the methodology. The metadynamics \nsimulations provided critical insights into the stability of the TLR3Ã—4/dsRNA signaling complex. \nThe results demonstrated that the complex remains stable under acidic conditions (pH 6.0) but \ndisassembles in basic environments (pH 7.4). \nIn Zerze et al. (2023), two advanced sampling techniques, MM-OPES and PTWTE-WTM, were \ncompared for atomistic RNA simulations, specifically focusing on the GAGA tetraloop. Both \nmethods aimed to explore the free energy landscape of the tetraloop by investigating its various \nfolding states: unfolded, folded, and misfolded. Specifically, the MM-OPES technique utilized \nmultiple thermodynamic temperatures to balance sampling efficiency with accuracy. One of the \nkey assumptions of MM-OPES is that high temperatures aid in improving ergodicity, allowing for \nmore efficient exploration of the system's conformational space, a concept borrowed from parallel \ntempering. The study found that temperature sets with a minimum temperature near 300 K and a \nmaximum temperature above 350 K were most effective for this system, with lower maximum \ntemperatures failing to explore critical regions of the free energy landscape. MM-OPES results \nshowed high accuracy in reproducing the free energy landscape obtained from PTWTE-WTM \nsimulations for many temperature sets. Whereas PTWTE-WTM demonstrated better sampling at \nthe folded state. The authors highlighted that the reduced cost of MM-OPES, approximately four \ntimes less computationally expensive than PTWTE-WTM while yielding similar results, further \ndemonstrated its potential for practical applications in biomolecular simulations. \n\n\n(5) Supramolecules \nStandard metadynamics has been employed for predicting free energy surfaces in situations like \nligand docking. Gervasio et al. (2005) noted that the adaptation of metadynamics for docking \nincluded selecting metavariables that could balance efficiency with accuracy, such as ligand-\nreceptor distance and angles related to their orientation. The metadynamics trajectory was used \nto test various docking configurations, refine ligand positioning, and compute the binding free \nenergy (Î”G_binding). It is found that the method reduced the need for high-dimensional search \nspaces, which are typically computationally expensive. These results were normally compared \nwith experimental data with satisfying alignment. \nIn Pavan et al. (2021), WT-MetaD simulations were used to investigate the dynamics of \nnanoparticle (NP) unbinding and escape from surface receptors. WT-MetaD improved the \nunderstanding of the free energy barriers and characteristic time scales associated with NP \ndetachment, in both fine-grained coarse-grained (fCG) models and all-atom simulations. By \nselecting the number of contacts between NP beads and receptor beads as the CV, the \nresearchers applied a bias to overcome the free energy barriers associated with NP detachment. \nThe simulations were run with a bias factor of 10 and Gaussian kernels. The characteristic time \nscale for NP unbinding was obtained by fitting the unbiased transition times to a Poissonian \ndistribution. This provided insights into the dynamics of NP-receptor interactions, with a specific \nfocus on the rate of NP detachment and the influence of receptor density on the unbinding \nprocess. Further refinement of the approach was achieved by running MW-MetaD simulations, \nwhich allowed for the parallel exploration of the NP behavior on surfaces with varying receptor \ndensities. The results from these simulations were consistent regardless of whether long-range \nelectrostatics were treated using Particle Mesh Ewald summation, demonstrating the robustness \nof the methodology in modeling NP chemotactic behavior.  \nBiswas et. al (2023) used the Parallel Tempering Metadynamics with Well-Tempered Ensemble \n(PTMetaD-WTE) approach to investigate the dimerization of GB1 monomers under varying \nconditions of molecular crowding. PTMetaD-WTE introduced efficient exploration of the \nconformational space associated with protein-protein interactions. The study assumed that the \nrelevant RCs are sufficient descriptors of the dimerization process, allowing the free energy \nlandscape to be reconstructed, and providing insights into the thermodynamic favorability of dimer \nformation. The results demonstrated that, in the absence of crowders, both the side-by-side and \ndomain-swapped dimers can form with relative ease. However, when lysozyme crowders are \nintroduced, the simulations reveal a destabilization effect, particularly for the side-by-side dimer. \nThis is evidenced by a state where a lysozyme molecule is intercalated between GB1 monomers, \neffectively reducing the number of direct intermonomer contacts. The observed destabilization \neffect from PTMetaD-WTE assisted simulation underscores the role of excluded volume \ninteractions and possible weak attractive interactions between lysozyme and GB1 in modulating \nprotein association equilibria in crowded environments. \nKlauda and Bodosa (2024)â€™s usage of 2-dimensional WT-MetaD revealed critical details about \nthe binding pathways, such as distinct metastable states (B1, B2, and B3 for BTMA) and their \nassociated interactions, including salt bridges and Ï€-cation interactions. It identified energy \nbarriers and key residues stabilizing ligand binding, shedding light on the differences in pathways \n\n\nfor the smaller, more flexible BTMA and the bulkier TPP. To enhance accuracy, umbrella sampling \nwas also used to extend the free energy landscape analysis, providing precise measurements of \nchanges in free energy due to solvation (Î”Gsolv). The free-energy landscape analysis yielded \nmeasurements of Î”Gbind and Î”Gcalc which closely matched experimental isothermal titration \ncalorimetry (ITC) values, validating the computational approach. \nUse of Enhanced Sampling Techniques to Analyze Trajectories from \nBiomolecular Systems \n \n(1) Replica-Exchange Molecular Dynamics \nThe performance of an REMD algorithm is often discussed in terms of the observed probability of \na successful exchange, where a very low exchange probability will increase the computational \ncost of exploring the energy landscape. Once adequate sampling of the energy landscape is \nestablished by a suitable exchange probability â€“ and thus, good replica mixing â€“ simulations are \ntypically analyzed in terms of the convergence of the target energetics or conformational \nensemble. \n \nThe convergence is typically checked by plotting the free energy surfaces as a function of a low \nnumber of structural parameters, such as monomer radius of gyration (Rg) or nematic order \nparameters in the assemblies. Temperature- or distance-dependent PMFs may be calculated, \nproviding another characteristic of aggregation propensities than what would normally be \navailable from conventional MD simulations. \n \nVarious distributions of structural metrics may also be used to examine convergence of the \nconformational ensemble or close-packed aggregate structure, including radial distribution \nfunctions, intermolecular coordination distances, angles, or Rg. Contact maps may be used to \ncharacterize and compare protein conformation or aggregate packing. In unconstrained studies \nwhere an atomistic reference of the target structure is available, such as crystallographic \ncoordinates of a bound protein, the simulated similarity to the target structure may be calculated \nin terms of root mean square displacement (RMSD) of the simulated atoms, observed Hydrogen-\nbonding, or secondary structure. \n \n(2) Umbrella Sampling \nPopular methods to analyze umbrella sampling simulations and determine free energy are WHAM \nand umbrella integration (Kastner 2011). In WHAM, the distribution in each window is given a \nweight and a weighted average distribution is calculated. The weights are assigned so that the \nstatistical error is minimized. Alternatively, in umbrella integration the mean force is averaged \nthroughout the windows.  \n \n(3) Metadynamics \nApplication of metadynamics procedures rely heavily on its balance between precision of fuller \nfree energy profiles and lower time cost compared to other enhanced sampling methods, \nespecially when dealing with systems of complex degrees of freedoms. From its inception, the \nauthors (Piana and Laio 2007) highlighted BE-MetaDâ€™s efficiency in sampling the folded state of \n\n\nTrp-cage test case, in a few nanoseconds and provided a detailed reconstruction of the free \nenergy surface in a fraction of the time compared to REMD. The authors conclude that BE-MetaD \nsignificantly improves the exploration of complex free energy landscapes with reduced \ncomputational cost, demonstrating its potential in biologically relevant applications. \n \nSuch advantages are further accentuated in the popularity of WT-MetaD, where customization of \nmultiple CVs further allows for analysis of conformational changes and kinetic coordinates. \nRecent studies explore the methodâ€™s benefits in monitoring and constructing assembly pathways. \nYuan et al. (2020) explored the dissociation pathways in detail by constructing free-energy profiles \nand landscapes based on two key CVs: coordination number and distance between ligand and \nreceptor. The simulations also highlighted significant differences in the dissociation energy \nbarriers, with tafamidis having a lower barrier to dissociation, indicating a greater tendency to \ndissociate compared to AG10 despite its stronger binding affinity. \nIn Ferranari et al. (2023), the complex energy landscape associated with different coordination \nmodes of ZnÂ²âº to the phosphate groups was difficult to characterize due to the high energy barriers \nbetween different configurations. WT-MetaD played a crucial role in providing an accurate \nstructural and energetic description of ZnÂ²âº, by selecting CVs for the coordination number of ZnÂ²âº \nto phosphate oxygens. For larger systems, Sakai (2018) employed the WT-MetaD method to \nexplore free energy landscapes and define the interaction pathways of the ligands as they enter \nthe M2 channel pore.  \nWang et al. (2024) demonstrated a key strength of this approach to be the careful selection of \nCVs, which acted as RCs to represent critical interactions within the signaling complex. These \nincluded the coordination between TLR3 and dsRNA (RC1), intradimer coordination within TLR3 \ndimers (RC2), and interdimer coordination between dimers (RC3). These variables captured the \nessential configurational changes during the assembly and disassembly processes, allowing \nprecise monitoring of the system. The study also showcased the versatility and power of \nmetadynamics in tackling complex biological problems involving large biomolecular systems, \nincluding other pH-sensitive protein assemblies. \nWith increase in computing capacities, incorporation of multiple enhanced sampling methods, \nespecially metadynamics method, has become the prospective approach. These methods target \nbetter scaling and holistic thermodynamics and kinetic representation of specific systems of \ninterest. \nBonomi et al. (2013) combined the PT-MetaD scheme with the well-tempered ensemble (WTE) \napproach to mitigate the high computational cost of simulating protein binding with explicit \nsolvents. The simulation revealed a complex free-energy landscape with a global minimum \nindicating favorable monomerâ€“monomer interaction. The simulation also allowed the calculation \nof the binding free energy of the dimer, which agreed with experimental estimates, albeit with a \nhigher simulated affinity due to differences in the definitions of the native state. Klauda et al. \n(2024) employed a 2-dimensional WT-MetaD protocol, which allowed them to investigate both the \nspatial and orientational degrees of freedom of the ligands BTMA and TPP. Using eight walkers \n\n\nto significantly enhance the sampling efficiency, they overcame challenges such as ligand \ntrapping in specific orientations or states.  \n(4) ML Techniques \nThe application of artificial Intelligence (AI) methods targeted particularly towards self-assembly \nis limited in the scope of directly handling a multitude of kinetic pathways of self-assembly. \nHowever, there has been considerable progress in finding the right order parameter (Sidky, Chen \net al. 2020) that can be used to accelerate MD simulations of self-assembly in tandem with \nenhanced sampling techniques.  \n \nGraphVAMPnets by Liu et al (Liu, Xue et al. 2023) has been used to build a KNM to study the \nkinetics of the self-assembly of hexaphenylsilole (HPS) in dimethylsulfoxide (DMSO) solvent (Liu, \nKalin et al. 2024). HPS shows aggregation-induced emission (AIE), a phenomenon observed in \nmolecules that exhibit enhanced fluorescence emission when they aggregate in the solution or \nthe solid state. For each metastable state uncovered through the kinetic model, the AIE \nfluorescence intensity was estimated using QM/MM calculation on representative conformations. \nThe overall intensity was determined by averaging across different states, weighted by population \neach time and was found to match the experimentally observed fluorescence intensity. \nAdditionally, HPS aggregation through the KNM affirmed classical nucleation growth theory in \nwhich the clusters spontaneously grow beyond a certain critical size as shown by the steady \nrelative fluorescence intensity values after some time for different initial concentrations.  \n \nGraphVAMPnet was also initially applied to the aggregation of two hydrophobic molecules (pdb \nid: 9d9f) in water and the self-assembly of patchy particles (Liu, Xue et al. 2023). The learned \nCVs of the hydrophobic molecules showed distinct binding states on the free energy surface. The \nstates described proper orientational correlation and monotonic decrease in solvent accessible \nsurface area towards stable valleys as the free energy decreased, indicating hydrophobic collapse \nof the molecules. For self-assembly of patch particles, the KNM lumped all microstates into five \nmajor macrostates when projected onto the learned  two dimensional CV space corresponding to \ndifferent ring-like structures that eventually formed stable 12 pentagonal rings.     \n \nFerguson et al. (Long and Ferguson 2014) used dMap to understand the self-assembly of \nanisotropic patchy colloidal particles that favor forming tetrahedral and icosahedral clusters. \nBrownian dynamics of patchy colloidal particles along dMAp coordinates revealed distinct \nmechanisms of the growth of icosahedral clusters: one from the sequential monomeric addition \nand another from the budding of the disordered liquid structure. Whereas tetrahedral clusters are \nassembled through two other distinct pathways: either through the chains of stacked interlocking \ndimers and trimers formation or through the stacked interlocking trigonal planar trimers formation.  \n \nHerringer et al (Herringer, Dasetty et al. 2023) used permutational invariant network for enhanced \nsampling (PINES) that integrates permutationally invariant vector featurization with Molecular \nEnhanced Sampling using Autoencoders (MESA) (Chen and Ferguson 2018) to discover \nsymmetry-adapted slow CVs. The network design employs a maximum mean discrepancy-\nWasserstein autoencoder (MMD-WAE) (Zhao, Song et al. 2017) with the loss function consisting \n\n\nof a mean-squared error (MSE) term to enable reconstruction and a maximum mean discrepancy \nterm to regularize latent space. The method was applied to look into the assembly/disassembly \nof a 13 atom Argon cluster as well as other systems, along with PB-MetaD enhanced sampling \nusing learned CVs.  \n \nBonati et al. (Bonati, Piccini et al. 2021) used Deep-TICA with OPES (Invernizzi and Parrinello \n2020) simulation to study silicon crystallization which is a first-order phase transition hindered by \na large free energy barrier. Similarly, this method can also be applied to crystallization-driven self-\nassembly of block copolymers through a first-order phase transition. Qiu et al (Qiu, Oâ€™Connor et \nal. 2023) used the variational autoencoder-based flux approach to efficiently lump parallel kinetic \npathways elucidated from the Markov state model (MSM) and Transition Path Theory (TPT) into \ndistinct metastable path channels. These channels helped comprehend the molecular mechanism \nunderlying the conformational changes in the system. Latent space path clustering (LPC) was \nemployed to understand the aggregation of two hydrophobic molecules (pdb id: 9d9f) in water.  \n \nEvolutionary reinforcement learning was used by Whitelam  (Whitelam and Tamblyn 2020) to \noptimally control parameters such as temperature and chemical potential to guide the self-\nassembly process. A disk model was employed to simulate real-world systems, like colloidal self-\nassembly, effectively capturing competition between polymorph formation and far-from-\nequilibrium dynamics. \n \nSection 5 - Conclusions and Outlook  \n \nBiomolecular assembly plays a critical role in physiology and the technology supporting health \ncare. Despite its ubiquity in nature and laboratory, identifying thermodynamically stable self-\nassembled structures within a global minima or structures of rare molecular conformation is \ndifficult through computational methods. This is due to a variety of reasons pertaining to limitations \nin time scale and energy barriers. In addition, determining free energy differences between these \nconformational states to identify driving forces is just as difficult. Since traditional computational \nmethods cannot parse these biomolecular states and energy differences, non-traditional or \nâ€œenhancedâ€ methods have to be applied. These methods consist of REMD, metadynamics, \numbrella sampling, and ML/AI.  \n \nReplica exchange is a robust and well-tested technique to enhance sampling of macromolecular \nconformations and intermolecular interactions in biomolecular systems. The simplicity of the core \nidea of RE has allowed for a fascinating variety of implementations, allowing researchers to \njudiciously modulate system energy by harnessing a variety of model features, especially in MD \nmodels. Such experiments have led to a number of findings relevant to supramolecular self-\nassembly in biomolecules, including the identification of assembly pathways for amyloid peptide \naggregates and protein quaternary structures. Umbrella sampling is a versatile method that aims \nto determine free energy differences and determine possible driving forces underlying self-\nassembly. It can be applied stand alone or combined with other techniques such as REMD. \nNotable papers applied umbrella sampling to peptides and polymer systems to determine the \nmechanisms underlying self-assembly and the contributions from each type of force. Aside from \n\n\nincorporating other enhanced sampling methods and quantum mechanics to further expand its \napplicability and improve continuity across resolutions, recent innovations in metadynamics \nemphasize collaboration with both intradisciplinary and interdisciplinary topics. One of the most \ndiscussed is the area of pattern recognition. Sampath et al. (2020) suggested developments in \nmodeling techniques incorporating metadynamics that have advanced our understanding of the \nmolecular recognition patterns in systems that are dictated by self-assembly, exemplifying \nsystems such as biomineralizing peptides, hierarchical peptoid assemblies, and large protein \nassemblies. While also pointing out prospects with additions in statistical learning and AI, the \nintegration of ML to optimize CVs (Bonati et al. 2021) and hybrid approaches combining \nmetadynamics with experimental data represent promising advancements. \n \nWhile this review article discusses some commonly used enhanced sampling methods, there are \nseveral other methods, for example, adaptive bias implementations such as variationally \nenhanced sampling and Wang-Landau (Henin et. al. 2022). Similarly, complementary to adaptive \nbias potential methods, there are also adaptive bias force methods which seek to add a force \ncomponent to level the free energy barriers. Other implementations include adaptive sampling \nand simulated annealing (Henin et. al. 2022; Bernardi et. a. 2015).  \n \nIt can even be argued that coarse-graining is an enhanced sampling method for resolving the \nself-assembly process (Spiwok et. al. 2015). Coarse-graining a set of atoms into a bead to act as \na â€œpseudo atomâ€ reduces the degrees of freedom, smoothens the potential energy landscape, \nand increases the timescale of the simulation (Aydin et. a. 2014; Aydin and Dutt 2014; Spiwok et. \nal. 2015; Aydin and Dutt 2016; Mushnoori et. al. 2018; Mushnoori et. al. 2020; Banerjee et. al. \n2021; Banerjee and Dutt 2023; Mushnoori et. al. 2023; Banerjee et. al. 2024). This approach \nallows for sampling of new conformations although not at atomistic resolution. To address this, \nthere are, however, backmapping and clustering methods to assess the similarity between \ncoarse-grained and atomistic self-assembled structures (Banerjee et. al. 2021; Banerjee and Dutt \n2023; Hooten et. al. 2023). A recent study performed bottom-up coarse graining of tri-\nphenylalanine to extend the simulation time from nanoseconds to microseconds and assessed \nthe final coarse-grained structure using backmapping (Hooten et. al. 2023).  \n \nFinally, even though enhanced sampling greatly aids the understanding of self-assembled \nbiomolecular materials, self-assembly is not yet solved. There are still limitations in time scale \nand length scale that need to be addressed. Improvements in computer architecture and compute \npower can slowly address these concerns over the years (Spiwok et. al. 2015). Additionally, there \nhas been a push to intermix and combine a variety of enhanced sampling techniques to form \nbetter combined sampling methods. There has also been a push to combine ML and AI in \nconjunction with a variety of enhanced sampling techniques to discover CVs that optimally span \nfree energy surface submanifold, accounting for long-lived, dominant metastable states of kinetic \npathways  (Sidky, Chen et al. 2020) (Mehdi, Smith et al. 2024). Furthermore, there are several \nongoing efforts to decouple the enhanced sampling techniques from the respective software and \ndevelop efficient enhanced sampling implementations that are universal so that they can be used \non data from community-based molecular simulation packages.  \n \n\n\nGiven the prevalence of the process of self-assembly in a wide range of disciplines, there \ncontinues to be numerous efforts to develop unique methods and iterate upon them to advance \nthese disciplines. This review aims to provide an introduction to some common enhanced \nsampling methods which are applied to develop a fundamental understanding of the process of \nself-assembly, and provides an outlook on how some of these techniques can potentially evolve. \n \nReferences: \n1. Abraham, M.  J.; Murtola, T.; Schulz, R.; PÃ¡ll, S.; Smith, J. C.; Hess, B.;  Lindahl, E. \nGROMACS: High Performance Molecular Simulations through Multi-Level Parallelism \nfrom Laptops to Supercomputers. SoftwareX 2015, 1â€“2, 19â€“25. \nhttps://doi.org/10.1016/j.softx.2015.06.001. \n2. Amber Manuals 2025. https://ambermd.org/Manuals.php (accessed 2025-02-17). \n3. Anand, P.; Nandel, F. S.; Hansmann, U. H. E. The Alzheimer Î²-Amyloid (AÎ²1â€“39) Dimer \nin an Implicit Solvent. The Journal of Chemical Physics 2008, 129 (19), 195102. \nhttps://doi.org/10.1063/1.3021062. \n4. Appeldorn, J. r. H.; Lemcke, S.; Speck, T.; Nikoubashman, A. Employing artificial neural \nnetworks to identify reaction coordinates and pathways for self-assembly. The Journal of \nPhysical Chemistry B 2022, 126 (27), 5007-5016. \nhttps://doi.org/10.1021/acs.jpcb.2c02232 \n5. Aydin, F.; Dutt, M. Bioinspired Vesicles Encompassing Two-Tail Phospholipids: Self-\nAssembly and Phase Segregation via Implicit Solvent Coarse-Grained Molecular \nDynamics. The Journal of Physical Chemistry B 2014, 118 (29), 8614â€“8623. \nhttps://doi.org/10.1021/jp503376r. \n6. Aydin, F.; Dutt, M. Surface Reconfiguration of Binary Lipid Vesicles via Electrostatically \nInduced Nanoparticle Adsorption. The Journal of Physical Chemistry B 2016, 120 (27), \n6646â€“6656. https://doi.org/10.1021/acs.jpcb.6b02334. \n7. Aydin, F.; Ludford, P.; Dutt, M. Phase Segregation in Bio-Inspired Multi-Component \nVesicles Encompassing Double Tail Phospholipid Species. Soft Matter 2014, 10 (32), \n6096â€“6108. https://doi.org/10.1039/c4sm00998c. \n8. Baftizadeh, F.; Biarnes, X.; Pietrucci, F.; Affinito, F.; Laio, A. Multidimensional View of \nAmyloid Fibril Nucleation in Atomistic Detail. Journal of the American Chemical Society \n2012, 134 (8), 3886â€“3894. https://doi.org/10.1021/ja210826a. \n9. Banerjee, A.; Dutt, M. A Hybrid Approach for Coarse-Graining Helical Peptoids: \nSolvation, Secondary Structure, and Assembly. The Journal of Chemical Physics 2023, \n158 (11). https://doi.org/10.1063/5.0138510. \n10. Banerjee, A.; Hooten, M.; Srouji, N.; Welch, R.; Shovlin, J.; Dutt, M. A Perspective on \nCoarse-Graining Methodologies for Biomolecules: Resolving Self-Assembly over \nExtended Spatiotemporal Scales. Frontiers in soft matter 2024, 4. \nhttps://doi.org/10.3389/frsfm.2024.1361066. \n11. Banerjee, A.; Lu, C. Y.; Dutt, M. A Hybrid Coarse-Grained Model for Structure, Solvation \nand Assembly of Lipid-like Peptides. Physical Chemistry Chemical Physics 2021, 24 (3), \n1553â€“1568. https://doi.org/10.1039/d1cp04205j. \n\n\n12. Barducci, A.; Bonomi, M.; Prakash, M. K.; Parrinello, M. Free-Energy Landscape of \nProtein Oligomerization from Atomistic Simulations. Proceedings of the National \nAcademy of Sciences 2013, 110 (49). https://doi.org/10.1073/pnas.1320077110. \n13. Barducci, A.; Bussi, G.; Parrinello, M. Well-Tempered Metadynamics: A Smoothly \nConverging and Tunable Free-Energy Method. Physical Review Letters 2008, 100 (2). \nhttps://doi.org/10.1103/physrevlett.100.020603. \n14. Baumketner, A.; Shea, J.-E. Free Energy Landscapes for Amyloidogenic Tetrapeptides \nDimerization. Biophysical Journal 2005, 89 (3), 1493â€“1503.  \n15. Bernardi, R. C.; Melo, M. C. R.; Schulten, K. Enhanced Sampling Techniques in \nMolecular Dynamics Simulations of Biological Systems. Biochimica et Biophysica Acta \n(BBA) - General Subjects 2015, 1850 (5), 872â€“877. \nhttps://doi.org/10.1016/j.bbagen.2014.10.019. \n16. Bodosa, J.; Klauda, J. B. Metadynamics Study of Lipid-Mediated Antibacterial Toxin \nBinding to the EmrE Multiefflux Protein. The Journal of Physical Chemistry B 2024, 128 \n(36), 8712â€“8723. https://doi.org/10.1021/acs.jpcb.4c02807. \n17. Bonati, L.; Piccini, G.; Parrinello, M. Deep learning the slow modes for rare events \nsampling. Proceedings of the National Academy of Sciences 2021, 118 (44), \ne2113533118.  https://doi.org/10.1073/pnas.2113533118 \n18. Brooks, B. R.; Brooks, C. L.; Mackerell, A. D.; Nilsson, L.; Petrella, R. J.; Roux, B.; Won, \nY.; Archontis, G.; Bartels, C.; Boresch, S.; Caflisch, A.; Caves, L.; Cui, Q.; Dinner, A. R.; \nFeig, M.; Fischer, S.; Gao, J.; Hodoscek, M.; Im, W.; Kuczera, K.; Lazaridis, T.; Ma, J.; \nOvchinnikov, V.; Paci, E.; Pastor, R. W.; Post, C. B.; Pu, J. Z.; Schaefer, M.; Tidor, B.; \nVenable, R. M.; Woodcock, H. L.; Wu, X.; Yang, W.; York, D. M.; Karplus, M. CHARMM: \nThe Biomolecular Simulation Program. J Comput Chem 2009, 30 (10), 1545â€“1614. \nhttps://doi.org/10.1002/jcc.21287. \n19. Bussi, G.; Gervasio, F. L.; Laio, A.; Parrinello, M. Free-Energy Landscape for Î² Hairpin \nFolding from Combined Parallel Tempering and Metadynamics. Journal of the American \nChemical Society 2006, 128 (41), 13435â€“13441. https://doi.org/10.1021/ja062463w. \n20. Bussi, G.; Laio, A. Using Metadynamics to Explore Complex Free-Energy Landscapes. \nNature Reviews Physics 2020, 2 (4), 200â€“212. https://doi.org/10.1038/s42254-020-\n0153-0. \n21. Case, D. A.; Cheatham III, T. E.; Darden, T.; Gohlke, H.; Luo, R.; Merz Jr., K. M.; \nOnufriev, A.; Simmerling, C.; Wang, B.; Woods, R. J. The Amber Biomolecular \nSimulation Programs. Journal of Computational Chemistry 2005, 26 (16), 1668â€“1688. \nhttps://doi.org/10.1002/jcc.20290. \n22. Cecchini, M.; Rao, F.; Seeber, M.; Caflisch, A. Replica Exchange Molecular Dynamics \nSimulations of Amyloid Peptide Aggregation. The Journal of Chemical Physics 2004, \n121 (21), 10748â€“10756. https://doi.org/10.1063/1.1809588. \n23. Chen, J.; Zou, X. Self-Assemble Peptide Biomaterials and Their Biomedical \nApplications. Bioactive Materials 2019, 4, 120â€“131. \nhttps://doi.org/10.1016/j.bioactmat.2019.01.002. \n24. Chen, W.; Ferguson, A. L. Molecular enhanced sampling with autoencoders: On-the-fly \ncollective variable discovery and accelerated free energy landscape exploration. Journal \n\n\nof computational chemistry 2018, 39 (25), 2079-2102. \nhttps://doi.org/10.1021/acs.jctc.3c00923 \n25. Chen, W.; Sidky, H.; Ferguson, A. L. Nonlinear discovery of slow molecular modes using \nstate-free reversible VAMPnets. The Journal of chemical physics 2019, 150 (21). \nhttps://doi.org/10.1063/1.5092521 \n26. Chiara Lionello; Gardin, A.; Cardellini, A.; Bochicchio, D.; Manisha Shivrayan; \nFernandez, A.; S. Thayumanavan; Pavan, G. M. Toward Chemotactic Supramolecular \nNanoparticles: From Autonomous Surface Motion Following Specific Chemical Gradients \nto Multivalency-Controlled Disassembly. ACS Nano 2021, 15 (10), 16149â€“16161. \nhttps://doi.org/10.1021/acsnano.1c05000. \n27. Chiavazzo, E.; Covino, R.; Coifman, R. R.; Gear, C. W.; Georgiou, A. S.; Hummer, G.; \nKevrekidis, I. G. Intrinsic map dynamics exploration for uncharted effective free-energy \nlandscapes. Proceedings of the National Academy of Sciences 2017, 114 (28), E5494-\nE5503. https://doi.org/10.1073/pnas.1621481114 \n28. Coifman, R. R.; Lafon, S.; Lee, A. B.; Maggioni, M.; Nadler, B.; Warner, F.; Zucker, S. W. \nGeometric diffusions as a tool for harmonic analysis and structure definition of data: \nDiffusion maps. Proceedings of the national academy of sciences 2005, 102 (21), 7426-\n7431. https://doi.org/10.1073/pnas.0500334102 \n29. Conti, S.; Cecchini, M. Predicting molecular self-assembly at surfaces: a statistical \nthermodynamics and modeling approach. Physical Chemistry Chemical Physics 2016, \n18 (46), 31480-31493. https://doi.org/10.1039/C6CP05249E \n30. Conti, S.; Del Rosso, M. G.; Ciesielski, A.; Weippert, J.; BÃ¶ttcher, A.; Shin, Y.; Melinte, \nG.; Ersen, O.; Casiraghi, C.; Feng, X. Perchlorination of Coronene Enhances its \nPropensity for Self-Assembly on Graphene. ChemPhysChem 2016, 17 (3), 352-357. \nhttps://doi.org/10.1002/cphc.201501113 \n31. De Simone, A.; Derreumaux, P. Low Molecular Weight Oligomers of Amyloid Peptides \nDisplay Î²-Barrel Conformations: A Replica Exchange Molecular Dynamics Study in \nExplicit Solvent. The Journal of Chemical Physics 2010, 132 (16), 165103. \nhttps://doi.org/10.1063/1.3385470. \n32. Eslami, H.; MÃ¼ller-Plathe, F. Metadynamics Simulations of Three-Dimensional \nNanocrystals Self-Assembled from Triblock Janus Nanoparticles: Implications for Light \nFiltering. ACS Applied Nano Materials 2024, 7 (15), 18045â€“18055. \nhttps://doi.org/10.1021/acsanm.4c03858. \n33. Ferguson, A. L.; Panagiotopoulos, A. Z.; Kevrekidis, I. G.; Debenedetti, P. G. Nonlinear \ndimensionality reduction in molecular simulation: The diffusion map approach. Chemical \nPhysics Letters 2011, 509 (1-3), 1-11. https://doi.org/10.1016/j.cplett.2011.04.066 \n34. Frederix, P. W.; Patmanidis, I.; Marrink, S. J. Molecular simulations of self-assembling \nbio-inspired supramolecular systems and their connection to experiments. Chemical \nSociety Reviews 2018, 47 (10), 3470-3489. https://doi.org/10.1039/C8CS00040A \n35. Freeman, R.; Han, M.; Ãlvarez, Z.; Lewis, J. A.; Wester, J. R.; Stephanopoulos, N.; \nMcClendon, M. T.; Lynsky, C.; Godbe, J. M.; Sangji, H.; Luijten, E.; Stupp, S. I. \nReversible Self-Assembly of Superstructured Networks. Science 2018, 362 (6416), 808â€“\n813. https://doi.org/10.1126/science.aat6141. \n\n\n36. Gear, C. W.; Kevrekidis, I. G.; Theodoropoulos, C. â€œCoarseâ€ Integration/Bifurcation \nAnalysis via Microscopic Simulators: Micro-Galerkin Methods. Computers & Chemical \nEngineering 2002, 26 (7-8), 941â€“963. https://doi.org/10.1016/s0098-1354(02)00020-0. \n37. Gee, J.; Shell, M. S. Two-Dimensional Replica Exchange Approach for Peptideâ€“Peptide \nInteractions. The Journal of Chemical Physics 2011, 134 (6), 064112. \nhttps://doi.org/10.1063/1.3551576. \n38. Gervasio, F. L.; Laio, A.; Parrinello, M. Flexible Docking in Solution Using \nMetadynamics. Journal of the American Chemical Society 2005, 127 (8), 2600â€“2607. \nhttps://doi.org/10.1021/ja0445950. \n39. Grzelczak, M.; Liz-MarzÃ¡n, L. M.; Klajn, R. Stimuli-Responsive Self-Assembly of \nNanoparticles. Chemical Society Reviews 2019, 48 (5), 1342â€“1361. \nhttps://doi.org/10.1039/c8cs00787j. \n40. Hansen, N.; Wilfred. Practical Aspects of Free-Energy Calculations: A Review. Journal \nof Chemical Theory and Computation 2014, 10 (7), 2632â€“2647. \nhttps://doi.org/10.1021/ct500161f. \n41. HÃ©nin, J.; LeliÃ¨vre, T.; Shirts, M.; Valsson, O.; Delemotte, L. Enhanced Sampling \nMethods for Molecular Dynamics Simulations [Article V1.0]. \nhttps://arxiv.org/pdf/2202.04164. \n42. Herringer, N. S.; Dasetty, S.; Gandhi, D.; Lee, J.; Ferguson, A. L. Permutationally \nInvariant Networks for Enhanced Sampling (PINES): Discovery of Multimolecular and \nSolvent-Inclusive Collective Variables. Journal of Chemical Theory and Computation \n2023, 20 (1), 178-198. https://doi.org/10.1021/acs.jctc.3c00923 \n43. Hollingsworth, S. A.; Dror, R. O. Molecular Dynamics Simulation for All. Neuron 2018, 99 \n(6), 1129â€“1143. https://doi.org/10.1016/j.neuron.2018.08.011. \n44. Hooten, M.; Banerjee, A.; Dutt, M. Multiscale, Multiresolution Coarse-Grained Model via \na Hybrid Approach: Solvation, Structure, and Self-Assembly of Aromatic Tripeptides. \nJournal of Chemical Theory and Computation 2023, 20 (4), 1689â€“1703. \nhttps://doi.org/10.1021/acs.jctc.3c00458. \n45. Invernizzi, M.; Parrinello, M. Exploration vs Convergence Speed in Adaptive-Bias \nEnhanced Sampling. Journal of Chemical Theory and Computation 2022, 18 (6), 3988â€“\n3996. https://doi.org/10.1021/acs.jctc.2c00152. \n46. Invernizzi, M.; Parrinello, M. Rethinking metadynamics: from bias potentials to probability \ndistributions. The journal of physical chemistry letters 2020, 11 (7), 2731-2736. \nhttps://doi.org/10.1021/acs.jpclett.0c00497 \n47. J.A. Lemkul (2018) \"From Proteins to Perturbed Hamiltonians: A Suite of Tutorials for the \nGROMACS-2018 Molecular Simulation Package, v1.0\" Living J. Comp. Mol. Sci. 1 (1): \n5068. \n48. Jeon, J.; Shell, M. S. Charge Effects on the Fibril-Forming Peptide KTVIIE: A Two-\nDimensional Replica Exchange Simulation Study. Biophysical Journal 2012, 102 (8), \n1952â€“1960. https://doi.org/10.1016/j.bpj.2012.03.019. \n49. Jeon, J.; Shell, M. S. Self-Assembly of Cyclo-Diphenylalanine Peptides in Vacuum. J. \nPhys. Chem. B 2014, 118 (24), 6644â€“6652. https://doi.org/10.1021/jp501503x. \n50. Jung, H.; Covino, R.; Arjun, A.; Leitold, C.; Dellago, C.; Bolhuis, P. G.; Hummer, G. \nMachine-guided path sampling to discover mechanisms of molecular self-organization. \n\n\nNature Computational Science 2023, 3 (4), 334-345. \nhttps://doi.org/10.1038/s43588-023-00428-z \n51. Karplus, M.; Petsko, G. A. Molecular dynamics simulations in biology. Nature 1990, 347 \n(6294), 631-639. https://doi.org/10.1038/347631a0 \n52. KÃ¤stner, J. Umbrella Sampling. Wiley Interdisciplinary Reviews: Computational \nMolecular Science 2011, 1 (6), 932â€“942. https://doi.org/10.1002/wcms.66. \n53. Kobayashi, Y.; Nomura, K.; Kaneko, T.; Arai, N. Replica Exchange Dissipative Particle \nDynamics Method on Threadlike Micellar Aqueous Solutions. J. Phys.: Condens. Matter \n2019, 32 (11), 115901. https://doi.org/10.1088/1361-648X/ab579c. \n54. Kokubo, H.; Okamoto, Y. Self-Assembly of Transmembrane Helices of \nBacteriorhodopsin by a Replica-Exchange Monte Carlo Simulation. Chemical Physics \nLetters 2004, 392 (1), 168â€“175. https://doi.org/10.1016/j.cplett.2004.04.112. \n55. Laio, A.; Parrinello, M. Escaping Free-Energy Minima. Proceedings of the National \nAcademy of Sciences of the United States of America 2002, 99 (20), 12562â€“12566. \nhttps://doi.org/10.1073/pnas.202427399. \n56. Lemke, T.; Peter, C. Encodermap: Dimensionality reduction and generation of molecule \nconformations. Journal of chemical theory and computation 2019, 15 (2), 1209-1215. \nhttps://doi.org/10.1021/acs.jctc.8b00975 \n57. Levin, A.; Hakala, T. A.; Schnaider, L.; Bernardes, G. J. L.; Gazit, E.; Knowles, T. P. J. \nBiomimetic Peptide Self-Assembly for Functional Materials. Nature Reviews Chemistry \n2020, 4 (11), 615â€“634. https://doi.org/10.1038/s41570-020-0215-y. \n58. Li, L.; Casalini, T.; Paolo Arosio; Matteo Salvalaglio. Modeling the Structure and \nInteractions of Intrinsically Disordered Peptides with Multiple Replica, Metadynamics-\nBased Sampling Methods and Force-Field Combinations. Journal of Chemical Theory \nand Computation 2022, 18 (3), 1915â€“1928. https://doi.org/10.1021/acs.jctc.1c00889. \n59. Li, P.; Shi, M.; Wang, Y.; Liu, Q.; Du, X.; Wang, X. PH-Dependent Assembly and \nStability of Toll-like Receptor 3/DsRNA Signaling Complex: Insights from Constant PH \nMolecular Dynamics and Metadynamics Simulations. Advanced Science 2024. \nhttps://doi.org/10.1002/advs.202411445. \n60. Li, Q.; Jonas, U.; Zhao, X. S.; Kappl, M. The Forces at Work in Colloidal Self-Assembly: \nA Review on Fundamental Interactions between Colloidal Particles. Asia-Pacific Journal \nof Chemical Engineering 2008, 3 (3), 255â€“268. https://doi.org/10.1002/apj.144. \n61. Liu, B.; Qiu, Y.; Goonetilleke, E. C.; Huang, X. Kinetic network models to study \nmolecular self-assembly in the wake of machine learning. MRS Bulletin 2022, 47 (9), \n958-966. https://doi.org/10.1557/s43577-022-00415-1 \n62. Liu, B.; Xue, M.; Qiu, Y.; Konovalov, K. A.; Oâ€™Connor, M. S.; Huang, X. GraphVAMPnets \nfor uncovering slow collective variables of self-assembly dynamics. The Journal of \nChemical Physics 2023, 159 (9). https://doi.org/10.1063/5.0158903 \n63. Liu, Y.; Liu, Y.; Chan-Park, M. B.; Mu, Y. Binding Modes of Teixobactin to Lipid II: \nMolecular Dynamics Study. Scientific Reports 2017, 7 (1). \nhttps://doi.org/10.1038/s41598-017-17606-5. \n64. Liu, Z.; Kalin, M. L.; Liu, B.; Cao, S.; Huang, X. Kinetic network models to elucidate \naggregation dynamics of aggregation-induced emission systems. Aggregate 2024, 5 (1), \ne422. https://doi.org/10.1002/agt2.422 \n\n\n65. Lockhart, C.; Luo, X.; Olson, A.; Delfing, B. M.; Laracuente, X. E.; Foreman, K. W.; \nPaige, M.; Kehn-Hall, K.; Klimov, D. K. Can Free Energy Perturbation Simulations \nCoupled with Replica-Exchange Molecular Dynamics Study Ligands with Distributed \nBinding Sites? J. Chem. Inf. Model. 2023, 63 (15), 4791â€“4802. \nhttps://doi.org/10.1021/acs.jcim.3c00631. \n66. Long, A. W.; Ferguson, A. L. Nonlinear machine learning of patchy colloid self-assembly \npathways and mechanisms. The Journal of Physical Chemistry B 2014, 118 (15), 4228-\n4244. https://doi.org/10.1021/jp500350b  \n67. Mangesh Bhendale; Singh, J. K. Molecular Insights on Morphology, Composition, and \nStability of Mixed Micelles Formed by Ionic Surfactant and Nonionic Block Copolymer in \nWater Using Coarse-Grained Molecular Dynamics Simulations. Langmuir 2023, 39 (14), \n5031â€“5040. https://doi.org/10.1021/acs.langmuir.3c00045. \n68. Mardt, A.; Pasquali, L.; Wu, H.; NoÃ©, F. VAMPnets for deep learning of molecular \nkinetics. Nature communications 2018, 9 (1), 5. https://doi.org/10.1038/s41467-017-\n02388-1 \n69. Martel, A.; Antony, L.; Gerelli, Y.; Porcar, L.; Fluitt, A.; Hoffmann, K.; Kiesel, I.; Vivaudou, \nM.; Fragneto, G.; De Pablo, J. J. Membrane Permeation versus Amyloidogenicity: A \nMultitechnique Study of Islet Amyloid Polypeptide Interaction with Model Membranes. J. \nAm. Chem. Soc. 2017, 139 (1), 137â€“148. https://doi.org/10.1021/jacs.6b06985. \n70. McManus, J. J.; Charbonneau, P.; Zaccarelli, E.; Asherie, N. The Physics of Protein \nSelf-Assembly. Current Opinion in Colloid & Interface Science 2016, 22, 73â€“79. \nhttps://doi.org/10.1016/j.cocis.2016.02.011. \n71. Mehdi, S.; Smith, Z.; Herron, L.; Zou, Z.; Tiwary, P. Enhanced sampling with machine \nlearning. Annual Review of Physical Chemistry 2024, 75. \nhttps://doi.org/10.1146/annurev-physchem-083122-125941 \n72. Mills, M.; Ioan Andricioaei. An Experimentally Guided Umbrella Sampling Protocol for \nBiomolecules. Journal of Chemical Physics 2008, 129 (11). \nhttps://doi.org/10.1063/1.2976440. \n73. Mishne, G.; Shaham, U.; Cloninger, A.; Cohen, I. Diffusion nets. Applied and \nComputational Harmonic Analysis 2019, 47 (2), 259-285. \nhttps://doi.org/10.1016/j.acha.2017.08.007 \n74. Morrow, B. H.; Koenig, P. H.; Shen, J. K. Atomistic Simulations of pH-Dependent Self-\nAssembly of Micelle and Bilayer from Fatty Acids. The Journal of Chemical Physics \n2012, 137 (19), 194902. https://doi.org/10.1063/1.4766313. \n75. Mu, X.; Eckes, K. M.; Nguyen, M. M.; Suggs, L. J.; Ren, P. Experimental and \nComputational Studies Reveal an Alternative Supramolecular Structure for Fmoc-\nDipeptide Self-Assembly. Biomacromolecules 2012, 13 (11), 3562â€“3571. \nhttps://doi.org/10.1021/bm301007r. \n76. Mushnoori, S.; Lu, C. Y.; Schmidt, K.; Dutt, M. A Coarse-Grained Molecular Dynamics \nStudy of Phase Behavior in Co-Assembled Lipomimetic Oligopeptides. Journal of \nMolecular Graphics and Modelling 2023, 125, 108624. \nhttps://doi.org/10.1016/j.jmgm.2023.108624. \n\n\n77. Mushnoori, S.; Schmidt, K.; Nanda, V.; Dutt, M. Designing Phenylalanine-Based Hybrid \nBiological Materials: Controlling Morphology Via Molecular Composition. Organic & \nBiomolecular Chemistry 2018, 16 (14), 2499â€“2507. https://doi.org/10.1039/c8ob00130h. \n78. Nguyen, M.; Qiu, Y.; Vaikuntanathan, S. Organization and Self-Assembly Away from \nEquilibrium: Toward Thermodynamic Design Principles. Annual Review of Condensed \nMatter Physics 2021, 12 (1), 273â€“290. https://doi.org/10.1146/annurev-conmatphys-\n031218-013309. \n79. Nymeyer, H.; Gnanakaran, S.; GarcÃ­a, A. E. Atomic Simulations of Protein Folding, \nUsing the Replica Exchange Algorithm. In Methods in Enzymology; Numerical Computer \nMethods, Part D; Academic Press, 2004; Vol. 383, pp 119â€“149. \nhttps://doi.org/10.1016/S0076-6879(04)83006-4. \n80. Palma, C.-A.; Cecchini, M.; SamorÃ¬, P. Predicting self-assembly: from empirism to \ndeterminism. Chemical Society Reviews 2012, 41 (10), 3713-3730. \nhttps://doi.org/10.1039/C2CS15302E \n81. Pfaendtner, J.; Bonomi, M. Efficient Sampling of High-Dimensional Free-Energy \nLandscapes with Parallel Bias Metadynamics. Journal of Chemical Theory and \nComputation 2015, 11 (11), 5062â€“5067. https://doi.org/10.1021/acs.jctc.5b00846. \n82. Piana, S.; Laio, A. A Bias-Exchange Approach to Protein Folding. The Journal of \nPhysical Chemistry B 2007, 111 (17), 4553â€“4559. https://doi.org/10.1021/jp067873l. \n83. Pradhan, S.; Rath, R.; Biswas, M. GB1 Dimerization in Crowders: A Multiple Resolution \nApproach. Journal of Chemical Information and Modeling 2023, 63 (5), 1570â€“1577. \nhttps://doi.org/10.1021/acs.jcim.3c00012. \n84. Prasheel Nakate; Dandekar, R.; Ardekani, A. M. Coarse-Grained Simulations of \nConcentration-Dependent Molecular Self-Assembly of Polysorbate 80 in Water. Physics \nof Fluids 2024, 36 (9). https://doi.org/10.1063/5.0228414. \n85. Qiu, Y.; Oâ€™Connor, M. S.; Xue, M.; Liu, B.; Huang, X. An efficient path classification \nalgorithm based on variational autoencoder to identify metastable path channels for \ncomplex conformational changes. Journal of chemical theory and computation 2023, 19 \n(14), 4728-4742. https://doi.org/10.1021/acs.jctc.3c00318 \n86. Rahimi, K.; Piaggi, P. M.; Zerze, G. H. Comparison of On-The-Fly Probability Enhanced \nSampling and Parallel Tempering Combined with Metadynamics for Atomistic \nSimulations of RNA Tetraloop Folding. The Journal of Physical Chemistry B 2023, 127 \n(21), 4722â€“4732. https://doi.org/10.1021/acs.jpcb.3c00117. \n87. Rissanou, A. N.; Georgilis, E.; Kasotakis, E.; Mitraki, A.; Harmandaris, V. Effect of \nSolvent on the Self-Assembly of Dialanine and Diphenylalanine Peptides. J. Phys. \nChem. B 2013, 117 (15), 3962â€“3975. https://doi.org/10.1021/jp311795b. \n88. Rocca, R.; Ferruccio Palazzesi; Amato, J.; Costa, G.; Ortuso, F.; Pagano, B.; Randazzo, \nA.; Novellino, E.; Alcaro, S.; Moraca, F.; Artese, A. Folding Intermediate States of the \nParallel Human Telomeric G-Quadruplex DNA Explored Using Well-Tempered \nMetadynamics. Scientific Reports 2020, 10 (1). https://doi.org/10.1038/s41598-020-\n59774-x. \n89.  Rohrdanz, M. A.; Zheng, W.; Maggioni, M.; Clementi, C. Determination of reaction \ncoordinates via locally scaled diffusion map. The Journal of chemical physics 2011, 134 \n(12). https://doi.org/10.1063/1.3569857 \n\n\n90. Rossi, E.; Ferrarini, A.; Marialore Sulpizi. Modeling of Minimal Systems Based on ATP-\nZn Coordination for Chemically Fueled Self-Assembly. Physical Chemistry Chemical \nPhysics 2023, 25 (8), 6102â€“6111. https://doi.org/10.1039/d2cp05516c. \n91. Sakai, Y.; Kawaguchi, A.; Nagata, K.; Hirokawa, T. Analysis by Metadynamics \nSimulation of Binding Pathway of Influenza Virus M2 Channel Blockers. Microbiology \nand Immunology 2018, 62 (1), 34â€“43. https://doi.org/10.1111/1348-0421.12561. \n92. Sampath, J.; Alamdari, S.; Pfaendtner, J. Closing the Gap between Modeling and \nExperiments in the Self-Assembly of Biomolecules at Interfaces and in Solution. \nChemistry of Materials 2020, 32 (19), 8043â€“8059. \nhttps://doi.org/10.1021/acs.chemmater.0c01891. \n93. Sampath, J.; Pfaendtner, J. Amphiphilic Peptide Binding on Crystalline vs. Amorphous \nSilica from Molecular Dynamics Simulations. Molecular Physics 2019, 117 (23-24), \n3642â€“3650. https://doi.org/10.1080/00268976.2019.1657192. \n94. SchÃ¼tt, K. T.; Sauceda, H. E.; Kindermans, P.-J.; Tkatchenko, A.; MÃ¼ller, K.-R. Schnetâ€“a \ndeep learning architecture for molecules and materials. The Journal of Chemical Physics \n2018, 148 (24). https://doi.org/10.1063/1.5019779 \n95. Sidky, H.; Chen, W.; Ferguson, A. L. Machine learning for collective variable discovery \nand enhanced sampling in biomolecular simulation. Molecular Physics 2020, 118 (5), \ne1737742. https://doi.org/10.1080/00268976.2020.1737742 \n96. Sieradzan, A. K.; Liwo, A.; Hansmann, U. H. E. Folding and Self-Assembly of a Small \nProtein Complex. J. Chem. Theory Comput. 2012, 8 (9), 3416â€“3422. \nhttps://doi.org/10.1021/ct300528r. \n97. Soto, P.; Baumketner, A.; Shea, J.-E. Aggregation of Polyalanine in a Hydrophobic \nEnvironment. The Journal of Chemical Physics 2006, 124 (13), 134904. \nhttps://doi.org/10.1063/1.2179803. \n98. Srinivas Mushnoori; Lu, C. Y.; Schmidt, K.; Zang, E.; Dutt, M. Peptide-Based Vesicles \nand Droplets: A Review. Journal of Physics Condensed Matter 2020, 33 (5), 053002â€“\n053002. https://doi.org/10.1088/1361-648x/abb995. \n99. Sugita, Y.; Okamoto, Y. Replica-Exchange Molecular Dynamics Method for Protein \nFolding. Chemical Physics Letters 1999, 314 (1â€“2), 141â€“151. \nhttps://doi.org/10.1016/S0009-2614(99)01123-9. \n100. \nTakeda, T.; Klimov, D. K. Replica Exchange Simulations of the Thermodynamics \nof AÎ² Fibril Growth. Biophysical Journal 2009, 96 (2), 442â€“452. \nhttps://doi.org/10.1016/j.bpj.2008.10.008. \n101. \nTaler-VerÄiÄ, A.; HasanbaÅ¡iÄ‡, S.; BerbiÄ‡, S.; Stoka, V.; Turk, D.; Å½erovnik, E. \nProline Residues as Switches in Conformational Changes Leading to Amyloid Fibril \nFormation. International Journal of Molecular Sciences 2017, 18 (3), 549. \nhttps://doi.org/10.3390/ijms18030549. \n102. \nTamamis, P.; Adler-Abramovich, L.; Reches, M.; Marshall, K.; Sikorski, P.; \nSerpell, L.; Gazit, E.; Archontis, G. Self-Assembly of Phenylalanine Oligopeptides: \nInsights from Experiments and Simulations. Biophysical Journal 2009, 96 (12), 5020â€“\n5029. https://doi.org/10.1016/j.bpj.2009.03.026. \n103. \nTantakitti, F.; Boekhoven, J.; Wang, X.; Kazantsev, R. V.; Yu, T.; Li, J.; Zhuang, \nE.; Zandi, R.; Ortony, J. H.; Newcomb, C. J.; Palmer, L. C.; Shekhawat, G. S.; de la \n\n\nCruz, M. O.; Schatz, G. C.; Stupp, S. I. Energy Landscapes and Functions of \nSupramolecular Systems. Nature Materials 2016, 15 (4), 469â€“476. \nhttps://doi.org/10.1038/nmat4538. \n104. \nThe PLUMED Consortium. Promoting Transparency and Reproducibility in \nEnhanced Molecular Simulations. Nature methods 2019, 16 (8), 670â€“673. \n105. \nTorrie, G. M.; Valleau, J. P. Nonphysical Sampling Distributions in Monte Carlo \nFree-Energy Estimation: Umbrella Sampling. Journal of Computational Physics 1977, 23 \n(2), 187â€“199. https://doi.org/10.1016/0021-9991(77)90121-8. \n106. \nUrano, R.; Okamoto, Y. Observation of Helix Associations for Insertion of a \nRetinal Molecule and Distortions of Helix Structures in Bacteriorhodopsin. The Journal of \nChemical Physics 2015, 143 (23), 235101. https://doi.org/10.1063/1.4935964. \n107. \nValsson, O.; Parrinello, M. Variational Approach to Enhanced Sampling and Free \nEnergy Calculations. Physical Review Letters 2014, 113 (9). \nhttps://doi.org/10.1103/physrevlett.113.090601. \n108. \nVogel, T.; Li, Y. W.; WÃ¼st, T.; Landau, D. P. Scalable Replica-Exchange \nFramework for Wang-Landau Sampling. Phys. Rev. E 2014, 90 (2), 023302. \nhttps://doi.org/10.1103/PhysRevE.90.023302. \n109. \nVojtÄ›ch Spiwok; Zoran Å uÄ‡ur; Petr HoÅ¡ek. Enhanced Sampling Techniques in \nBiomolecular Simulations. Biotechnology Advances 2015, 33 (6), 1130â€“1140. \nhttps://doi.org/10.1016/j.biotechadv.2014.11.011. \n110. \nWang, F.; Landau, D. P. Efficient, Multiple-Range Random Walk Algorithm to \nCalculate the Density of States. Phys. Rev. Lett. 2001, 86 (10), 2050â€“2053. \nhttps://doi.org/10.1103/PhysRevLett.86.2050. \n111. \nWang, J.; Liu, K.; Xing, R.; Yan, X. Peptide Self-Assembly: Thermodynamics and \nKinetics. Chemical Society Reviews 2016, 45 (20), 5589â€“5604. \nhttps://doi.org/10.1039/c6cs00176a. \n112. \nWhitelam, S.; Feng, E. H.; Hagan, M. F.; Geissler, P. L. The role of collective \nmotion in examples of coarsening and self-assembly. Soft matter 2009, 5 (6), 1251-\n1262. https://doi.org/10.1039/B810031D \n113. \nWhitelam, S.; Jack, R. L. The statistical mechanics of dynamic pathways to self-\nassembly. Annual review of physical chemistry 2015, 66 (1), 143-163. \nhttps://doi.org/10.1146/annurev-physchem-040214-121215 \n114. \nWhitelam, S.; Tamblyn, I. Learning to grow: Control of material self-assembly \nusing evolutionary reinforcement learning. Physical Review E 2020, 101 (5), 052604. \nhttps://doi.org/10.1103/PhysRevE.101.052604 \n115. \nWhitelam, S. Control of pathways and yields of protein crystallization through the \ninterplay of nonspecific and specific attractions. Physical review letters 2010, 105 (8), \n088102. https://doi.org/10.1103/PhysRevLett.105.088102 \n116. \nWhitesides, G. M.; Grzybowski, B. Self-assembly at all scales. Science 2002, \n295 (5564), 2418-2421. https://doi.org/10.1126/science.1070821 \n117. \nWilliams-Noonan, B. J.; Kamboukos, A.; Nevena Todorova; Yarovsky, I. Self-\nAssembling Peptide Biomaterials: Insights from Spontaneous and Enhanced Sampling \nMolecular Dynamics Simulations. Chemical Physics Reviews 2023, 4 (2). \nhttps://doi.org/10.1063/5.0142302. \n\n\n118. \nWolf, M. G.; Jongejan, J. A.; Laman, J. D.; de Leeuw, S. W. Rapid Free Energy \nCalculation of Peptide Self-Assembly by REMD Umbrella Sampling. J. Phys. Chem. B \n2008, 112 (43), 13493â€“13498. https://doi.org/10.1021/jp804285e. \n119. \nXiong, Q.; Jiang, Y.; Cai, X.; Yang, F.; Li, Z.; Han, W. Conformation Dependence \nof Diphenylalanine Self-Assembly Structures and Dynamics: Insights from Hybrid-\nResolution Simulations. ACS Nano 2019, 13 (4), 4455â€“4468. \nhttps://doi.org/10.1021/acsnano.8b09741. \n120. \nXu, W.; Zheng, Y.; Pan, P. Crystallization-Driven Self-Assembly of \nSemicrystalline Block Copolymers and End-Functionalized Polymers: A Minireview. \nJournal of Polymer Science 2021, 60 (15), 2136â€“2152. \nhttps://doi.org/10.1002/pol.20210789. \n121. \nYadav, S.; Sharma, A. K.; Kumar, P. Nanoscale Self-Assembly for Therapeutic \nDelivery. Frontiers in Bioengineering and Biotechnology 2020, 8. \nhttps://doi.org/10.3389/fbioe.2020.00127. \n122. \nYan, L.-T.; Xie, X.-M. Computational Modeling and Simulation of Nanoparticle \nSelf-Assembly in Polymeric Systems: Structures, Properties and External Field Effects. \nProgress in Polymer Science 2013, 38 (2), 369â€“405. \nhttps://doi.org/10.1016/j.progpolymsci.2012.05.001. \n123. \nYang, Y. I.; Shao, Q.; Zhang, J.; Yang, L.; Gao, Y. Q. Enhanced Sampling in \nMolecular Dynamics. The Journal of Chemical Physics 2019, 151 (7), 070902. \nhttps://doi.org/10.1063/1.5109531. \n124. \nYu, T.; Schatz, G. C. Free Energy Profile and Mechanism of Self-Assembly of \nPeptide Amphiphiles Based on a Collective Assembly Coordinate. The Journal of \nPhysical Chemistry B 2013, 117 (30), 9004â€“9013. https://doi.org/10.1021/jp404835q. \n125. \nZhang, S.-Y.; Regulacio, M. D.; Han, M.-Y. Self-Assembly of Colloidal One-\nDimensional Nanocrystals. Chemical Society Reviews 2014, 43 (7), 2301. \nhttps://doi.org/10.1039/c3cs60397k. \n126. \nZhang, X.; Gong, C.; Ozioma Udochukwu Akakuru; Su, Z.; Wu, A.; Wei, G. The \nDesign and Biomedical Applications of Self-Assembled Two-Dimensional Organic \nBiomaterials. Chemical Society Reviews 2019, 48 (23), 5564â€“5595. \nhttps://doi.org/10.1039/c8cs01003j. \n127. \nZhao, S.; Song, J.; Ermon, S. Infovae: Information maximizing variational \nautoencoders. arXiv preprint arXiv:1706.02262 2017. \nhttps://doi.org/10.48550/arXiv.1706.02262 \n128. \nZhou, S.; Ge, S.; Zhang, W.; Zhang, Q.; Yuan, S.; Lo, G. V.; Dou, Y. \nConventional Molecular Dynamics and Metadynamics Simulation Studies of the Binding \nand Unbinding Mechanism of TTR Stabilizers AG10 and Tafamidis. ACS Chemical \nNeuroscience 2020, 11 (19), 3025â€“3035. \nhttps://doi.org/10.1021/acschemneuro.0c00338. \n129. \nZhou, X.; Shi, M.; Wang, X.; Xu, D. Exploring the Binding Mechanism of a \nSupramolecular Tweezer CLR01 to 14-3-3Ïƒ Protein via Well-Tempered Metadynamics. \nFrontiers in Chemistry 2022, 10. https://doi.org/10.3389/fchem.2022.921695. \n\n\n130. \nZhu, J.; Avakyan, N.; Kakkis, A.; Hoffnagle, A. M.; Han, K.; Li, Y.; Zhang, Z.; \nChoi, T. S.; Na, Y.; Yu, C.-J.; Tezcan, F. A. Protein Assembly by Design. Chemical \nReviews 2021, 121 (22), 13701â€“13796. https://doi.org/10.1021/acs.chemrev.1c00308. \n \n\n\n",
  "metadata": {
    "source_file": "dataset/pdfs/arxiv_2502.21148v1.pdf",
    "total_pages": 40,
    "title": "Applications of Enhanced Sampling Methods to Biomolecular Self-Assembly: A Review",
    "authors": [
      "Mason Hooten",
      "Het Patel",
      "Yiwei Shao",
      "Rishabh Kumar Singh",
      "Meenakshi Dutt"
    ],
    "abstract": "This review article discusses some common enhanced sampling methods in\nrelation to the process of self-assembly of biomolecules. An introduction to\nself-assembly and its challenges is covered followed by a brief overview of the\nmethods and analysis for replica-exchange molecular dynamics, umbrella\nsampling, metadynamics, and machine learning based techniques. Applications of\nselect methods towards peptides, proteins, polymers, nucleic acids, and\nsupramolecules are discussed. Finally, a short discussion of the future\ndirections of some of these methods is provided.",
    "published_date": "2025-02-28",
    "source": "arxiv"
  }
}