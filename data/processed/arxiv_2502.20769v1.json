{
  "id": "arxiv_2502.20769v1",
  "text": "INFORMATION BOTTLENECK-GUIDED HETEROGENEOUS GRAPH\nLEARNING FOR INTERPRETABLE NEURODEVELOPMENTAL\nDISORDER DIAGNOSIS\nYueyang Li1,†, Lei Chen1,†, Wenhao Dong1, Shengyu Gong1, Zijian Kang1, Boyang Wei1, Weiming Zeng1,*, Hongjie\nYan2, Lingbin Bian3, Wai Ting Siok3, and Nizhuan Wang3,*\n1Lab of Digital Image and Intelligent Computation, Shanghai Maritime University, Shanghai 201306, China\n2Department of Neurology, Affiliated Lianyungang Hospital of Xuzhou Medical University, Lianyungang 222002\n3Department of Chinese and Bilingual Studies, The Hong Kong Polytechnic University, Hung Hom, Kowloon, Hong\nKong Special Administrative Region, China\n†Co-first authors\n*Correspondence: wangnizhuan1120@gmail.com; zengwm86@163.com\nABSTRACT\nDeveloping interpretable models for diagnosing neurodevelopmental disorders (NDDs) is highly\nvaluable yet challenging, primarily due to the complexity of encoding, decoding and integrating\nimaging and non-imaging data. Many existing machine learning models struggle to provide compre-\nhensive interpretability, often failing to extract meaningful biomarkers from imaging data, such as\nfunctional magnetic resonance imaging (fMRI), or lacking mechanisms to explain the significance of\nnon-imaging data. In this paper, we propose the Interpretable Information Bottleneck Heterogeneous\nGraph Neural Network (I²B-HGNN), a novel framework designed to learn from fine-grained local\npatterns to comprehensive global multi-modal interactions. This framework comprises two key\nmodules. The first module, the Information Bottleneck Graph Transformer (IBGraphFormer) for\nlocal patterns, integrates global modeling with brain connectomic-constrained graph neural networks\nto identify biomarkers through information bottleneck-guided pooling. The second module, the\nInformation Bottleneck Heterogeneous Graph Attention Network (IB-HGAN) for global multi-modal\ninteractions, facilitates interpretable multi-modal fusion of imaging and non-imaging data using\nheterogeneous graph neural networks. The results of the experiments demonstrate that I²B-HGNN\nexcels in diagnosing NDDs with high accuracy, providing interpretable biomarker identification and\neffective analysis of non-imaging data.\nKeywords Information Bottleneck · Heterogeneous Graph Learning · Interpretability · Multi-modal · fMRI ·\nNon-imaging data.\n1\nIntroduction\nNeurodevelopmental disorders (NDDs), such as autism spectrum disorder (ASD) and attention deficit hyperactivity\ndisorder (ADHD), significantly affect cognitive and social development, posing major challenges for affected individuals\n[1]. Unlike traditional behavioral assessments, which can be subjective and lead to diagnostic delays, computer-aided\ndiagnosis that integrates imaging data, such as functional magnetic resonance imaging (fMRI), offers a precise, objective\nand data-driven approach to diagnosing NDDs [2]. fMRI provides direct insights into brain activity and connectivity,\nenabling researchers to map active brain regions during tasks or at rest and identify biomarkers associated with\ndisorders like ASD and ADHD. Integrating this imaging data into computer-aided models can thus enhance diagnostic\naccuracy and efficiency. However, developing interpretable diagnostic models remains challenging, as it requires\nbalancing biomarker interpretability with the effective integration of multi-modal imaging and non-imaging data [3].\narXiv:2502.20769v1  [cs.CV]  28 Feb 2025\n\n\nRunning Title for Header\nAlthough graph neural networks (GNNs) have shown promise in analyzing functional brain connectomes [4], many\nlack mechanisms to clarify the importance of non-imaging features in diagnosis.\nLeveraging brain network analysis and multi-modal data fusion is important for developing interpretable models of\nNDDs. Graph-based methods, which treat brain regions as nodes and functional connectivity (FC) as edges, can extract\nbiomarkers but have limited predictive power [5]. In contrast, population graph approaches improve diagnostic accuracy\nby modeling intersubject phenotypic similarity but may compromise biomarker reliability by focusing on individual-\nlevel representations [4, 6]. Conventional homogeneous graph models restrict the use of non-imaging data by only\nmapping it to edge weights, limiting their ability to fully utilize such data. This highlights the need for heterogeneous\ngraph structures to better integrate diverse data types [7]. Although GNNs can effectively model FC, they struggle to\ncapture global FC for identifying distributed biomarkers in brain network analysis [2]. Transformer-based models excel\nat capturing global FC but lack GNNs’ ability to model region-wise FC patterns [8]. Existing hybrid architectures\n[9] attempt to combine these strengths but face challenges in integrating non-imaging data while maintaining robust\nbrain network modeling capabilities. Heterogeneous graph methods often rely on simplified subject relationships,\nfailing to fully integrate fMRI and non-imaging data and lacking mechanisms to ensure structural consistency in multi-\nmodal feature learning [10]. Interpretability approaches also struggle with modeling heterogeneous brain networks\nand integrating multi-modal features, as post-hoc methods often fail to reveal cross-modal interactions due to their\ndetachment from model decisions [11]. These limitations underscore the need for a unified theoretical framework to\nguide feature extraction and cross-modal interaction modeling. The information bottleneck (IB) principle [12] provides\nan ideal theoretical foundation by enabling optimal compression of FC patterns while preserving diagnostically relevant\ninformation, addressing these challenges through minimal yet sufficient biomarker identification and cross-modal\nrelationship preservation.\nTo systematically address these challenges, we present the Interpretable Information Bottleneck Heterogeneous Graph\nNeural Network (I²B-HGNN), which introduces a novel information bottleneck framework for interpretable NDD\ndiagnosis. I²B-HGNN employs the IB principle to guide learning of local FC patterns and global multi-modal\ninteractions. The Information Bottleneck Graph Transformer (IBGraphFormer) employs information compression to\nextract minimal sufficient biomarkers from brain functional networks while maintaining essential FC patterns through\ntransformer-GNN integration. Based on these identified biomarkers, the Information Bottleneck Heterogeneous Graph\nAttention Network (IB-HGAN) extends the compression principle to guide multi-modal fusion using meta-path-based\npopulation graphs. Graph isomorphism testing ensures structural consistency [13], while the IB-HGAN adaptively\nregularizes cross-modal interactions to preserve diagnostically relevant information from both imaging and non-imaging\ndata. By integrating IBGraphFormer’s biomarker identification with non-imaging data attribution, the IB-HGAN\noptimizes diagnostic accuracy and model interpretability through information-theoretic principles.\nOverall, we present three main contributions as follows:\n1) Integrated Information Bottleneck Framework: We propose an architecture that applies IB principles to\nbrain connectivity modeling and multi-modal fusion. This framework identifies biomarkers while preserving\ninteractions between non-imaging features, effectively addressing the accuracy-interpretability trade-off.\n2) Interpretable Biomarker Identification: The IBGraphFormer combines the transformer’s global attention\nwith GNNs using an IB mechanism. This allows for interpretable biomarker extraction through information-\ntheoretic compression, preserving essential features of the brain’s functional network.\n3) Theoretically Principled Multi-modal Integration: The IB-HGAN employs an information-theoretic ap-\nproach to heterogeneous graph learning. By using meta-path-based population graphs and graph isomorphism\ntests, it ensures neurobiologically valid feature interactions, enabling explicit attribution of both imaging and\nnon-imaging features in diagnostic decisions.\n2\nMethod\n2.1\nIBGraphFormer\n1) Brain Connectomic Graphs Construction: We construct brain connectomic graphs from fMRI time series features\nX ∈RN×f, where N denotes the number of regions of interest (ROIs) and f represents the feature dimension. Brain\nconnectomic graph G = (V, E, A) consists of the ROI node set V, FC edge set E, and adjacency matrix A. To\ncapture intrinsic FC patterns, we employ a neural mapping layer fI that projects input features into latent embeddings\nZ(0) = fI(X), where Z(0) ∈RN×d serves as the initial node features.\n2) Distribution-aware Global Attention GraphFormer: The IBGraphFormer integrates a distribution-aware global\nattention mechanism with GNNs to capture both long-range dependencies and local FC patterns. The global attention\n2\n\n\nRunning Title for Header\nFigure 1: Illustration of our I²B-HGNN for NDD diagnosis.\nmodule quantifies cross-ROI influences as:\n{Q, K, V} = {fQ, fK, fV }(Z(0)),\n{ ˜Q, ˜K} = {Q/∥Q∥F , K/∥K∥F }\n(1)\nwhere fQ, fK, fV denote learnable feature transformation functions, and ∥· ∥F denotes the Frobenius norm for\nnormalizing attention distributions. The attention-weighted feature aggregation process is:\nZ = λD−1\n\u0014\nV + 1\nN\n˜Q( ˜K⊤V)\n\u0015\n+ (1 −λ)Z(0)\n(2)\nwhere λ balances feature contributions and D = diag\n\u0010\n1 + 1\nN ˜Q( ˜K⊤e)\n\u0011\nprevents over-smoothing, with e ∈RN being\nthe all-one column vector and diag(·) creating an N × N diagonal matrix. To integrate structural information, we devise\na learnable fusion mechanism:\nZO = (1 −γ)Z + γGCN(Z(0), A)\n(3)\nwhere γ is a learnable parameter that adaptively balances global attention features with residual graph convolution\nnetwork (GCN) local FC patterns features.\n3) BIB-Pooling: To identify diagnostically relevant biomarkers from the integrated features, we develop the Biomarker-\noriented Information Bottleneck Pooling (BIB-Pooling) layer based on the IB principle [12]. Formally, for input\nvariable X and target variable Y , the IB principle seeks to find a minimal sufficient statistic T by minimizing:\nLIB = I(X; T) −βI(T; Y )\n(4)\nwhere I(·; ·) denotes mutual information and β controls the trade-off between compression and prediction. Following\nthis principle, we implement a variational approximation mapping integrated features ZO to biomarker representations\nT:\nT = µϕ(ZO) + σϕ(ZO) ⊙ϵ,\nϵ ∼N(0, I)\n(5)\nLBIB = Eqϕ(T|ZO)[log p(Y |T)] −βIBKL(qϕ(T|ZO)||p(T))\n(6)\nwhere µϕ and σϕ parameterize the encoding distribution qϕ(T|ZO), and p(T) is a standard normal prior. The first term\nmaximizes biomarker predictive power, while the KL divergence term enforces a complexity constraint [14], ensuring\nretention of essential diagnostic information. This theoretically-grounded approach enables the identification of sparse\nyet clinically meaningful biomarkers.\n3\n\n\nRunning Title for Header\nAlgorithm 1 Information Bottleneck Guided Heterogeneous Graph Attention\nRequire: Meta-path node representations {Zp}P\np=1, Meta-path subgraphs {Gp}P\np=1\nEnsure: Integrated node representation ZH\n1: Compute structural equivalence Sij using Eq.(8)\n2: for each meta-path p do\n3:\nEstimate mutual information I(X; Zp) and I(Zp; Y )\n4:\nˆαp = q⊤tanh(WZp + b)e−βHI(X;Zp)\n5: end for\n6: α = softmax( ˆα)\n7: for isomorphic meta-paths (i, j) do\n8:\nαi = αj {Enforce structural consistency}\n9: end for\n10: Aggregate features: ZH = PP\np=1 αpZp\n11: Compute LHG using Eq.(9)\n12: return ZH, LHG\n2.2\nIB-HGAN\nBuilding upon the biomarker representations T ∈RN×d extracted by IBGraphFormer, IB-HGAN aims to achieve\ninterpretable multi-modal integration through IB guided heterogeneous graph learning. We formulate the integration as\na variational IB problem:\nLHIB = Eqϕ(ZH|T,Xnon)[log p(Y |ZH)] −βHKL(qϕ(ZH|T, Xnon)||p(ZH))\n(7)\nwhere Xnon represents non-imaging features, ZH denotes the integrated representations, and qϕ is the approximation of\nthe optimal encoding distribution.\n1) Heterogeneous Population Graph Construction: We construct a heterogeneous population graph GH = (V, E, R)\nto capture multi-modal diagnostic relationships. Each subject node vi ∈V contains biomarker representations Ti\nfrom IBGraphFormer and four types of demographic features: site xsite\ni , sex xsex\ni , age xage\ni , and handedness xhand\ni\n. We\nestablish four meta-path based subgraphs {Gp}4\np=1 with their corresponding adjacency matrices {Ap}4\np=1 to model\ndistinct behavioral and demographic relationships between subjects.\n2) Meta-path Structural Equivalence Learning: For consistent feature integration, we employ the Weisfeiler-\nLehman (WL) graph isomorphism test to identify structurally equivalent meta-paths [13], which iteratively aggregates\nneighboring node labels to refine node representations. Based on these iterations, the structural equivalence between\nmeta-paths Gi and Gj is quantified as:\nSij = 1\nK\nK\nX\nk=1\nI[c(k)(Gi) ≡c(k)(Gj)]\n(8)\nwhere K is the maximum iteration number, c(k)(G) denotes the colored labels at iteration k, and I[·] is the indicator\nfunction.\n3) Information Bottleneck Guided Attention: The IB principle guides the learning of meta-path importance and\nfeature integration by enforcing minimal sufficient statistics across modalities, where the attention mechanism detailed\nin Algorithm 1 adaptively weighs meta-path specific representations. Through mutual information estimation and WL\ntest constraints, ensuring each meta-path preserves diagnostically relevant information while removing redundancy,\nenabling the model to quantify path-specific contributions and maintain structural consistency. The resulting sparse\nattention weights not only highlight the most informative paths, but also provide interpretable insights into how different\nnon-imaging features influence the diagnosis through their respective meta-paths.\nThe learning process is guided by a joint optimization objective that balances information compression with structural\npreservation:\nLHG = LHIB + µLstruct + κLsparse\n(9)\nwhere Lstruct = P\ni,j Sij∥ZHi −ZHj∥2 enforces structural consistency between isomorphic meta-paths, and Lsparse =\n∥α∥1 promotes selective attention.\nFinally, the overall loss function of I²B-HGNN combines the classification loss with local and global information\nbottleneck constraints:\nL = Lcla + ζLBIB + ωLHG\n(10)\nwhere Lcla is the cross-entropy loss, ζ and ω are balancing parameters.\n4\n\n\nRunning Title for Header\nTable 1: Diagnostic results (mean ± std) for competing methods on both datasets.\nDataset\nType\nMethod\nACC(%)\nAUC(%)\nF1(%)\nABIDE-I\nB.GCN\nBrainGNN\n66.76 ± 3.81\n69.39 ± 2.76\n67.21 ± 1.94\nContrastPool\n70.40 ± 2.74\n70.29 ± 3.48\n68.03 ± 2.31\nRGTNet\n73.21 ± 1.86\n75.10 ± 2.54\n72.69 ± 2.75\nP.GCN\nInceptionGCN\n69.43 ± 1.26\n72.90 ± 0.97\n70.25 ± 1.36\nLG-GNN\n73.27 ± 1.76\n75.37 ± 1.55\n74.26 ± 1.94\nDGTN\n76.71 ± 1.66\n79.54 ± 1.83\n77.21 ± 1.72\nOurs\nI²B-HGNN\n78.64 ± 1.58\n82.03 ± 2.37\n80.45 ± 1.73\nADHD-200\nB.GCN\nBrainGNN\n65.16 ± 3.81\n67.19 ± 2.86\n65.71 ± 2.04\nContrastPool\n69.16 ± 2.85\n71.19 ± 2.26\n67.71 ± 3.04\nRGTNet\n72.19 ± 1.25\n75.42 ± 2.46\n70.50 ± 1.49\nP.GCN\nInceptionGCN\n67.76 ± 2.81\n70.39 ± 2.36\n69.71 ± 1.94\nLG-GNN\n72.35 ± 1.48\n76.12 ± 1.86\n74.63 ± 1.69\nDGTN\n75.45 ± 1.98\n80.72 ± 1.96\n79.63 ± 2.31\nOurs\nI²B-HGNN\n77.31 ± 1.14\n82.63 ± 1.53\n81.94 ± 0.98\nTable 2: Ablation studies regarding each key component of our I²B-HGNN.\nIBGraphFormer\nIB-HGAN\nDataset\nMetric\nw/o Attention\nw/o LBIB\nw/o LHIB\nw/o Lstruct\nw/o Lsparse\nABIDE-I\nACC(%)\n76.10\n74.09\n72.75\n77.26\n76.25\nADHD-200\n75.29\n74.56\n73.32\n76.76\n75.20\n3\nExperiments and Results\n3.1\nExperimental Setup\n1) Datasets and Preprocessing: We evaluated I²B-HGNN on two publicly accessible datasets. The ABIDE-I dataset\nfrom 20 sites, with 403 ASD and 468 healthy control (HC) individuals. The ADHD-200 dataset from four sites,\nwith 218 ADHD and 364 HC individuals. We preprocessed fMRI data using C-PAC [15] and Athena [16] pipelines,\nrespectively. Each brain was parcellated into 116 ROIs using the AAL1 atlas [17].\n2) Implementation Details and Competing Methods: I²B-HGNN was implemented in PyTorch and trained on an\nNVIDIA RTX 2080Ti GPU with Adam optimizer [18]. The model was trained with an initial learning rate of 0.01 for\n300 epochs. In the IBGraphFormer, the IB balance parameter was set to 0.8. In the IB-HGAN, the balance parameters for\nmutual information and graph isomorphism constraints were empirically set to 0.1. To quantify diagnostic performance,\nwe used established metrics: accuracy (ACC), area under the receiver operating characteristic curve (AUC), and F1\nscore (F1).\nFor comparison, we categorized competing methods into two groups: Brain Connectomic-Graph Models (B.GCN),\nincluding BrainGNN [2], ContrastPool [5] and RGTNet [19], and Population-Graph Models (P.GCN), including Incep-\ntionGCN [20], LG-GNN [9] and DGTN [21]. The number of non-imaging features and the values of hyperparameters\nfor each method were set according to their original publications. All evaluations were performed using 10-fold\ncross-validation, with the data split into training, validation and test sets in an 8:1:1 ratio.\n3.2\nResults\n1) Classification Performance and Ablation Study: As shown in Table 1, I²B-HGNN outperforms all methods across\nall metrics on both datasets. Population graph-based methods exhibit more stable performance with lower standard\ndeviations by capturing global associations, while multi-modal approaches integrating information from multi-modal\nsources outperform single-modal methods.\nTo quantify the contribution of each component, we conducted ablation experiments. Table 2 shows that removing\nthe distribution-aware global attention (reverting to residual GCN) reduced ACC, confirming its ability to capture\ncrucial long-range FC patterns. Similarly, eliminating BIB-Pooling (w/o LBIB) degraded performance, validating its\neffectiveness in biomarker identification. For IB-HGAN, removing the IB-guided heterogeneous graph loss (LHIB)\nhighlighted its critical role in enforcing minimal sufficient statistics during multi-modal integration. Performance\nalso declined without structural consistency constraints (Lstruct) or sparsity regularization (Lsparse), demonstrating their\n5\n\n\nRunning Title for Header\nFigure 2: Explanation results on ASD and ADHD datasets.\ncomplementary roles in maintaining representation equivalence across isomorphic meta-paths and promoting selective\nattention to diagnostically relevant pathways.\n2) Explanation Analysis: The interpretability results demonstrate how I²B-HGNN achieves theoretically-principled\nexplanations by visualizing biomarkers in brain regions and the interactions of multi-modal features. Figure 2 a) and c)\nvisualize the top 30 informative ROIs identified by the BIB-Pooling layer for ADHD and ASD, using IB principle-based\nnormalized mutual information quantification. The highest-relevance regions include the shared anterior cingulate gyrus\n(ACG.R) and disorder-specific areas such as the precentral gyrus (PreCG.L) for ADHD and the fusiform gyrus (FFG.L)\nfor ASD. These findings align with key neural circuits involved in attention control and social cognition, which are\ncentral to NDD pathology [22, 23]. Figure 2 b) and d) reveal distinct neurobiological signatures in ASD and ADHD\nthrough interactive patterns of cross-modal information. ASD shows stronger site-related correlations with posterior\nbrain regions, while ADHD exhibits pronounced age-sex interactions with frontal-insular networks [24, 25]. Meta-\npath interactions demonstrate how demographic factors influence diagnosis through graph isomorphism-constrained\ninformation channels. Attribution analysis confirms theoretical predictions that age and sex contribute most significantly\nto both disorders, reflecting neurodevelopmental trajectories [26]. This interpretability framework balances biomarker\nsparsity with diagnostic relevance while preserving crucial cross-modal relationships underlying the pathophysiology of\nNDDs.\n4\nConclusion\nIn this paper, we introduce the Interpretable Information Bottleneck Heterogeneous Graph Neural Network (I²B-HGNN),\na novel framework that leverages the Information Bottleneck (IB) principle to guide both local functional connectivity\npattern learning and global multi-modal integration in brain network analysis. To address the accuracy-interpretability\ntrade-off, we developed a progressive learning architecture systematically grounded in IB principles. Our approach\ndemonstrates how IB principles can effectively guide heterogeneous graph learning for interpretable neurodevelopmental\ndisorder diagnosis, enabling simultaneous biomarker identification and non-imaging feature attribution. Experimental\nresults confirm that I²B-HGNN achieved both high diagnostic accuracy and comprehensive model interpretability.\nAcknowledgments\nThis work was supported by the Hong Kong Polytechnic University Faculty Reserve Fund (Project ID: P0053738), and\nthe Hong Kong Polytechnic University Start-up Fund (Project ID: P0053210).\n6\n\n\nRunning Title for Header\nReferences\n[1] Anita Thapar, Miriam Cooper, and Michael Rutter. Neurodevelopmental disorders. The Lancet Psychiatry,\n4(4):339–346, 2017.\n[2] Xiaoxiao Li, Yuan Zhou, Nicha Dvornek, Muhan Zhang, Siyuan Gao, Juntang Zhuang, Dustin Scheinost,\nLawrence H Staib, Pamela Ventola, and James S Duncan. BrainGNN: Interpretable brain graph neural network\nfor fmri analysis. Medical Image Analysis, 74:102233, 2021.\n[3] Yueyang Li, Weiming Zeng, Wenhao Dong, Luhui Cai, Lei Wang, Hongyu Chen, Hongjie Yan, Lingbin Bian,\nand Nizhuan Wang. MHNet: Multi-view high-order network for diagnosing neurodevelopmental disorders using\nresting-state fMRI. Journal of Imaging Informatics in Medicine, pages 1–21, 2025.\n[4] Sarah Parisot, Sofia Ira Ktena, Enzo Ferrante, Matthew Lee, Ricardo Guerrerro Moreno, Ben Glocker, and Daniel\nRueckert. Spectral graph convolutions for population-based disease prediction. In Medical Image Computing\nand Computer Assisted Intervention- MICCAI 2017: 20th International Conference, Quebec City, QC, Canada,\nSeptember 11-13, 2017, Proceedings, Part III 20, pages 177–185. Springer, 2017.\n[5] Jiaxing Xu, Qingtian Bian, Xinhang Li, Aihu Zhang, Yiping Ke, Miao Qiao, Wei Zhang, Wei Khang Jeremy Sim,\nand Balázs Gulyás. Contrastive graph pooling for explainable classification of brain networks. IEEE Transactions\non Medical Imaging, 2024.\n[6] Luhui Cai, Weiming Zeng, Hongyu Chen, Hua Zhang, Yueyang Li, Hongjie Yan, Lingbin Bian, and Nizhuan\nWang. MM-GTUNets: Unified multi-modal graph deep learning for brain disorders prediction. arXiv preprint\narXiv:2406.14455, 2024.\n[7] Xiao Wang, Houye Ji, Chuan Shi, Bai Wang, Yanfang Ye, Peng Cui, and Philip S Yu. Heterogeneous graph\nattention network. In The world wide web conference, pages 2022–2032, 2019.\n[8] Wenhao Dong, Yueyang Li, Weiming Zeng, Lei Chen, Hongjie Yan, Wai Ting Siok, and Nizhuan Wang. STAR-\nFormer: A novel spatio-temporal aggregation reorganization transformer of fMRI for brain disorder diagnosis.\narXiv preprint arXiv:2501.00378, 2024.\n[9] Hao Zhang, Ran Song, Liping Wang, Lin Zhang, Dawei Wang, Cong Wang, and Wei Zhang. Classification of\nbrain disorders in rs-fMRI via local-to-global graph neural networks. IEEE transactions on Medical Imaging,\n42(2):444–455, 2022.\n[10] Lizhen Shao, Cong Fu, and Xunying Chen. A heterogeneous graph convolutional attention network method for\nclassification of autism spectrum disorder. BMC bioinformatics, 24(1):363, 2023.\n[11] Konstantin Hemker, Nikola Simidjievski, and Mateja Jamnik. HEALNet: Multimodal fusion for heterogeneous\nbiomedical data. Advances in Neural Information Processing Systems, 37:64479–64498, 2025.\n[12] Naftali Tishby, Fernando C Pereira, and William Bialek. The information bottleneck method. arXiv preprint\nphysics/0004057, 2000.\n[13] Nino Shervashidze, Pascal Schweitzer, Erik Jan Van Leeuwen, Kurt Mehlhorn, and Karsten M Borgwardt.\nWeisfeiler-lehman graph kernels. Journal of Machine Learning Research, 12(9):2539–2561, 2011.\n[14] Zhengru Fang, Senkang Hu, Jingjing Wang, Yiqin Deng, Xianhao Chen, and Yuguang Fang. Prioritized information\nbottleneck theoretic framework with distributed online learning for edge video analytics. IEEE Transactions on\nNetworking, pages 1–17, 2025.\n[15] Cameron Craddock, Sharad Sikka, Brian Cheung, Ranjeet Khanuja, Satrajit S Ghosh, Chaogan Yan, Qingyang\nLi, Daniel Lurie, Joshua Vogelstein, Randal Burns, et al. Towards automated analysis of connectomes: The\nconfigurable pipeline for the analysis of connectomes (c-pac). Front Neuroinform, 42(10.3389), 2013.\n[16] Pierre Bellec, Carlton Chu, Francois Chouinard-Decorte, Yassine Benhajali, Daniel S Margulies, and R Cameron\nCraddock. The neuro bureau adhd-200 preprocessed repository. Neuroimage, 144:275–286, 2017.\n[17] Edmund T Rolls, Chu-Chung Huang, Ching-Po Lin, Jianfeng Feng, and Marc Joliot. Automated anatomical\nlabelling atlas 3. Neuroimage, 206:116189, 2020.\n[18] Diederik P Kingma. Adam: A method for stochastic optimization. arXiv preprint arXiv:1412.6980, 2014.\n[19] Yibin Wang, Haixia Long, Tao Bo, and Jianwei Zheng. Residual graph transformer for autism spectrum disorder\nprediction. Computer Methods and Programs in Biomedicine, 247:108065, 2024.\n[20] Anees Kazi, Shayan Shekarforoush, S Arvind Krishna, Hendrik Burwinkel, Gerome Vivar, Karsten Kortüm, Seyed-\nAhmad Ahmadi, Shadi Albarqouni, and Nassir Navab. InceptionGCN: receptive field aware graph convolutional\nnetwork for disease prediction. In Information Processing in Medical Imaging: 26th International Conference,\nIPMI 2019, Hong Kong, China, June 2–7, 2019, Proceedings 26, pages 73–85. Springer, 2019.\n7\n\n\nRunning Title for Header\n[21] Zihao Guan, Jiaming Yu, Zhenshan Shi, Xiumei Liu, Renping Yu, Taotao Lai, Changcai Yang, Heng Dong, Riqing\nChen, and Lifang Wei. Dynamic graph transformer network via dual-view connectivity for autism spectrum\ndisorder identification. Computers in Biology and Medicine, 174:108415, 2024.\n[22] Ayesha K Sadozai, Carter Sun, Eleni A Demetriou, Amit Lampit, Martha Munro, Nina Perry, Kelsie A Boulton,\nand Adam J Guastella. Executive function in children with neurodevelopmental conditions: a systematic review\nand meta-analysis. Nature Human Behaviour, pages 1–10, 2024.\n[23] Michael J Kofler, Elia F Soto, Leah J Singh, Sherelle L Harmon, Emma M Jaisle, Jessica N Smith, Kathleen E\nFeeney, and Erica D Musser. Executive function deficits in attention-deficit/hyperactivity disorder and autism\nspectrum disorder. Nature Reviews Psychology, 3(10):701–719, 2024.\n[24] Priyanka Sigar, Nicholas Kathrein, Elijah Gragas, Lauren Kupis, Lucina Q Uddin, and Jason S Nomi. Age-related\nchanges in brain signal variability in autism spectrum disorder. Molecular Autism, 16(1):8, 2025.\n[25] Luke J Norman, Gustavo Sudre, Jolie Price, and Philip Shaw. Subcortico-cortical dysconnectivity in ADHD: a\nvoxel-wise mega-analysis across multiple cohorts. American Journal of Psychiatry, 181(6):553–562, 2024.\n[26] Sofia Santos, Helena Ferreira, Joao Martins, Joana Gonçalves, and Miguel Castelo-Branco. Male sex bias in\nearly and late onset neurodevelopmental disorders: Shared aspects and differences in Autism Spectrum Disorder,\nAttention Deficit/hyperactivity Disorder, and Schizophrenia. Neuroscience & Biobehavioral Reviews, 135:104577,\n2022.\n8\n\n\n",
  "metadata": {
    "source_file": "dataset/pdfs/arxiv_2502.20769v1.pdf",
    "total_pages": 8,
    "title": "Information Bottleneck-Guided Heterogeneous Graph Learning for Interpretable Neurodevelopmental Disorder Diagnosis",
    "authors": [
      "Yueyang Li",
      "Lei Chen",
      "Wenhao Dong",
      "Shengyu Gong",
      "Zijian Kang",
      "Boyang Wei",
      "Weiming Zeng",
      "Hongjie Yan",
      "Lingbin Bian",
      "Wai Ting Siok",
      "Nizhuan Wang"
    ],
    "abstract": "Developing interpretable models for diagnosing neurodevelopmental disorders\n(NDDs) is highly valuable yet challenging, primarily due to the complexity of\nencoding, decoding and integrating imaging and non-imaging data. Many existing\nmachine learning models struggle to provide comprehensive interpretability,\noften failing to extract meaningful biomarkers from imaging data, such as\nfunctional magnetic resonance imaging (fMRI), or lacking mechanisms to explain\nthe significance of non-imaging data. In this paper, we propose the\nInterpretable Information Bottleneck Heterogeneous Graph Neural Network\n(I2B-HGNN), a novel framework designed to learn from fine-grained local\npatterns to comprehensive global multi-modal interactions. This framework\ncomprises two key modules. The first module, the Information Bottleneck Graph\nTransformer (IBGraphFormer) for local patterns, integrates global modeling with\nbrain connectomic-constrained graph neural networks to identify biomarkers\nthrough information bottleneck-guided pooling. The second module, the\nInformation Bottleneck Heterogeneous Graph Attention Network (IB-HGAN) for\nglobal multi-modal interactions, facilitates interpretable multi-modal fusion\nof imaging and non-imaging data using heterogeneous graph neural networks. The\nresults of the experiments demonstrate that I2B-HGNN excels in diagnosing NDDs\nwith high accuracy, providing interpretable biomarker identification and\neffective analysis of non-imaging data.",
    "published_date": "2025-02-28",
    "source": "arxiv"
  }
}