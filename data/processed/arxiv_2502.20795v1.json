{
  "id": "arxiv_2502.20795v1",
  "text": "Plan2Align: Predictive Planning Based Test-Time Preference Alignment\nin Paragraph-Level Machine Translation\nKuang-Da Wang1,†\nTeng-Ruei Chen1,†\nYu Heng Hung1\nShuoyang Ding2\nYueh-Hua Wu2\nYu-Chiang Frank Wang2\nChao-Han Huck Yang2\nWen-Chih Peng1\nPing-Chun Hsieh1\n1National Yang Ming Chiao Tung University\n2NVIDIA\n{gdwang.cs10@,raychen.cs12@,wcpeng@cs.,pinghsieh@}nycu.edu.tw\n{hucky,krisw,shuoyangd}@nvidia.com\n†equal contribution\nAbstract\nMachine Translation (MT) has been predomi-\nnantly designed for sentence-level translation\nusing transformer-based architectures. While\nnext-token prediction based Large Language\nModels (LLMs) demonstrate strong capabili-\nties in long-text translation, non-extensive lan-\nguage models often suffer from omissions and\nsemantic inconsistencies when processing para-\ngraphs. Existing preference alignment methods\nimprove sentence-level translation but fail to\nensure coherence over extended contexts due\nto the myopic nature of next-token generation.\nWe introduce Plan2Align, a test-time alignment\nframework that treats translation as a predictive\nplanning problem, adapting Model Predictive\nControl to iteratively refine translation outputs.\nExperiments on WMT24 Discourse-Level Lit-\nerary Translation show that Plan2Align signif-\nicantly improves paragraph-level translation,\nachieving performance surpassing or on par\nwith the existing training-time and test-time\nalignment methods on LLaMA-3.1 8B.\n1\nIntroduction\nMachine Translation (MT) has primarily leveraged\ntransformer-based encoder-decoder neural architec-\ntures, as exemplified by models like M2M-100 (Fan\net al., 2021) and MT5 (Xue et al., 2021). However,\nthe emergence of Large Language Models (LLMs),\nsuch as the GPT series (Brown et al., 2020; Achiam\net al., 2023), LLaMAs (Touvron et al., 2023a,b),\nand Gemma (Team et al., 2024), has demonstrated\nremarkable efficacy in a wide range of NLP tasks\n(Stiennon et al., 2020; Hendrycks et al., 2021; Sri-\nvastava et al., 2023; Yu et al., 2024; Zhong et al.,\n2024), including multilingual translation.\nThis\nprogress has led to increasing interest in leveraging\nLLMs for MT, particularly for handling long-form\ntext. LLMs excel at long-text translation due to\ntheir ability to model dependencies across extended\ncontexts, enabling improved coherence and fluency.\nModels such as Tower (Alves et al., 2024) and\nGPT-4o (OpenAI, 2024) have demonstrated state-\nof-the-art performance, surpassing traditional MT\nsystems in both fluency and contextual consistency.\nAgent\nSelect Best Action\nObservation\n“小提琴的聲音宛轉悠\n揚，配合餐廳昏暗的情\n調，浪漫又迷人。”\nThe violin's sound is gentle and playful, matching the \nrestaurant's dim atmosphere, romantic and captivating.\nThe violin's sweet tone harmonizes with the restaurant's \ndark atmosphere, romantic and captivating.\n5\n5\n10\n2\nTrajectory Optimization\nEnvironment\n5\nLLM\n“小提琴的聲音宛轉悠\n揚，配合餐廳昏暗的情\n調，浪漫又迷人。”\nThe violin's lovely tone resonates with the restaurant's \nsubdued ambiance, radiating romance and fascination.\nThe violin's sweet harmonies blend with the restaurant's \ndark atmosphere, exuding romance and charm.\nSource\nSelect The Best Translation\n10\n2\n7\n(Improve upon the \nbest translation.)\nTranslation Optimization\nFigure 1: Machine translation via predictive planning\nfrom the perspective of trajectory optimization.\nHowever, non-extensive (i.e., smaller than 10B)\nLLMs often struggle with long-text translation, ex-\nhibiting sentence omissions, semantic inconsisten-\ncies, and hallucinations (Wu et al., 2024). These\nlimitations stem from the myopic nature of next-\ntoken prediction, where local fluency is prioritized\nat the cost of global coherence, leading to degraded\ntranslation quality in extended discourse. One-\npass translation remains inherently limited, as it\nlacks iterative refinement, making it prone to over-\ntranslation, under-translation, and compounding\nerrors (Mandya et al., 2020). While traditional\nMT systems incorporate techniques such as re-\nranking, iterative decoding, and constrained beam\nsearch to improve coherence and fidelity, LLM-\nbased MT operates purely in a next-token predic-\ntion paradigm, lacking an explicit self-correction\nmechanism (Hadj Ameur et al., 2019; Feng et al.,\n2024). As a result, errors introduced early in the\ngeneration process propagate across extended text\nspans, leading to semantic drift, loss of contextual\n1\narXiv:2502.20795v1  [cs.CL]  28 Feb 2025\n\n\ndependencies, and degraded translation quality in\nlong-form content.\nRecent research has investigated preference\nalignment as a means to improve translation quality\nin small-scale LLMs, leveraging preference data\nto guide optimization. Methods such as CPO (Xu\net al., 2024b) and WAP (Wu et al., 2024) have\nshown promising results in aligning translations to\npreferences. However, existing methods face two\nfundamental challenges in long-text translation:\n1. Preference alignment techniques operate at\nspecific granularity levels; when applied at the\nlong-text level, they often struggle to preserve\nsentence coherence across paragraphs.\n2. Unlike training-time alignment, which re-\nquires costly fine-tuning, testing-time align-\nment methods must incorporate a technique\nto recover from past errors or low-quality an-\nswers caused by compounding errors during\ninference. This is crucial because these past\nmistakes can lead to further errors, as earlier\nresponses influence the generation of answers\nto subsequent questions (Mandya et al., 2020).\nTo address these challenges,\nwe propose\nPlan2Align, a test-time alignment method that\nemploys a self-rewriting framework based on the\nprinciple of Model Predictive Control (MPC), a\nclassic predictive planning method for trajectory\noptimization (Rao, 2014) widely used in robotics\n(Tassa et al., 2012, 2014; Nagabandi et al., 2020)\nand motion planning (Ji et al., 2016). Rather than\nfine-tuning LLMs, Plan2Align iteratively refines\ntranslations by integrating high-quality segments\nfrom previous iterations at test time, enhancing\ncoherence and fluency in long-text translation.\nThis study focuses on paragraph-level MT,\nwhere translation quality is evaluated beyond iso-\nlated sentences. Specifically, we define context-\nlevel as a group of adjacent, semantically related\nsentences, while a paragraph consists of multiple in-\nterconnected contexts. Ensuring high-quality trans-\nlation at the context level is crucial for maintain-\ning coherence and accuracy at the paragraph level.\nSpecifically, this study is twofold: (i) to develop\na test-time alignment method that matches or sur-\npasses fine-tuning approaches, and (ii) to enhance\nparagraph-level translation by improving consis-\ntency and fidelity across context-level translations.\nAs a predictive planning method, MPC opti-\nmizes a sequence of decisions by continuously\nadjusting future actions based on past observa-\ntions (Camacho and Bordons, 2007; Kouvaritakis\nand Cannon, 2016). Inspired by this, we draw\nan analogy between trajectory optimization and\ntranslation optimization, where prior translations\ninform subsequent refinements, and recast MT as\nan iterative optimization process rather than a one-\npass mapping. Figure 1 illustrates this correspon-\ndence, highlighting the intuition behind our ap-\nproach. While LLMs excel in contextual under-\nstanding, their one-pass translations remain subop-\ntimal. By iteratively leveraging high-quality past\ntranslations, our method enhances coherence and\ndiscourse integrity, improving overall quality.\nHowever, directly applying MPC to paragraph-\nlevel MT is impractical when entire paragraph-\nlevel translation histories are fed into small-scale\nLLMs due to their limited contextual capacity. To\nadapt MPC to paragraph-level MT, we introduce\ntwo novel mechanisms: (i) Model-predictive con-\ntext alignment: We modify MPC to selectively re-\ntain high-quality contexts from multiple paragraph-\nlevel translations with the help of a context buffer,\ninstead of relying on a single best trajectory. This\nensures effective accumulation and utilization of\ntranslation experience for aligning source and trans-\nlation contexts. (ii) Self-rewriting tasks: We re-\ndefine MT as a self-rewriting task, a structured\nprompting mechanism that enhances discourse co-\nherence, enables each iteration to build upon prior\nhigh-quality translations, and ultimately improves\nfluency and consistency. By integrating these two\nstrategies, Plan2Align achieves efficient translation\nrefinement within a limited number of iterations.\nTo validate our approach, we apply Plan2Align\nto LLaMA-3.1 8B on the WMT’24 Discourse-\nLevel Literary Translation Benchmark, using 6K\nparagraph-level preference data for test-time align-\nment. Our method demonstrates substantial im-\nprovements, achieving performance on par with\nor surpassing training-time alignment methods\nwhile outperforming existing test-time alignment\napproaches. Plan2Align bridges the gap in LLM-\nbased paragraph-level translation, introducing a\nnovel test-time alignment framework that ensures\nhigh translation quality while maintaining context-\nlevel consistency. Moreover, our test-time align-\nment method can augment other fine-tuning ap-\nproaches, leveraging a small number of iterations\nat test time to achieve even better translation per-\nformance.\n2\n\n\n2\nRelated Work\n2.1\nDocument-Level Machine Translation\nDocument-level neural machine translation can be\nbroadly divided into two categories: the sentence-\nto-sentence (sen2sen) approach and the document-\nto-document (doc2doc) approach (Maruf et al.,\n2022; Wang et al., 2023). Translation on a sentence-\nby-sentence basis, even with augmented contexts,\nremains inadequate for fully capturing coherence\nand consistency within texts (Fernandes et al.,\n2023). Various methods demonstrate the impor-\ntance of context in translation; (Wu et al., 2023)\nprocess context within different components of\nthe same encoder, while (Voita et al., 2018) use\nattention distributions to integrate context aware-\nness. We are exploring a translation method that\neffectively bridges the gap between sentence-level\nand document-level approaches, aiming to harness\nmore contextual information than sentence-level\ntranslation while avoiding the extensive resource\ndemands of full document-level translation.\n2.2\nPreference Alignmnet for LLMs\nLarge language models (LLMs) often misalign\nwith human preferences. Traditional approaches\nsuch as supervised fine-tuning (SFT) (Ziegler et al.,\n2019), reinforcement learning from human feed-\nback (RLHF) (Ouyang et al., 2022), direct policy\noptimization (DPO) (Rafailov et al., 2023), and\nsimple preference optimization (SimPO) (Meng\net al., 2024) refine models post-training but de-\nmand significant computational resources. Test-\ntime alignment offers a lightweight alternative by\nmodifying outputs during inference without alter-\ning model parameters. Prior methods include In-\nferAligner (Wang et al., 2024b) for cross-model\nguidance, ARGS (Khanov et al., 2024) with dy-\nnamic reward-based adjustment, TreeBoN (Qiu\net al., 2024) leveraging tree-search in Best-of-N\nSampling, and RAIN (Li et al., 2024) and URIAL\n(Lin et al., 2024) employing advanced prompt engi-\nneering. However, these approaches struggle when\nearly responses are suboptimal, hindering subse-\nquent outputs. To address this, Plan2Align intro-\nduces an MPC framework that enables predictive\nplanning, effectively accumulating and leveraging\nhigh-quality experience to optimize response gen-\neration. By integrating structured foresight into\ntest-time alignment, Plan2Align mitigates early-\nstage errors, leading to more reliable and adaptable\nmodel outputs.\n3\nMethodology\nIn this section, we introduce the Plan2Align frame-\nwork (Figure 2). We describe how predictive plan-\nning enables preference alignment, the operational\nsequence of the framework, and how final transla-\ntions are produced.\n3.1\nTest-Time Preference Alignment via\nPredictive Planning\nOur key idea is to recast MT as trajectory optimiza-\ntion and thereby employ predictive planning for\niterative translation refinement.\nMachine Translation as Trajectory Optimiza-\ntion.\nThe goal of trajectory optimization is to find\nan optimal sequence of actions a∗= (a∗\n1, · · · , a∗\nT )\nsuch that the expected trajectory-wise utility is max-\nimized (Chua et al., 2018; Lowrey et al., 2019).\nMore specifically: Let st denote the state of the\nenvironment at the t-th step and let s1 be the initial\nstate. Consider an environment with Markov transi-\ntion dynamics, where the state st+1 is independent\nof the past history given the current state st and\naction at. Let J (a, s) denote the utility function\nof the sequences a and s. Then, the search for a∗\ncan be formulated as\na∗= arg max\na1:T E\n\u0002\nJ (a1:T , s1:T )|s1\n\u0003\n,\n(1)\nwhere T is the planning horizon and the expectation\nis over all the randomness in the environment.\nOne can interpret translation as an instance of\ntrajectory optimization by (i) treating the source\nparagraph as the initial state s1, (ii) treating each\nat as the t-th segment of the translation, and (iii)\nsetting st+1 as the concatenation of the source para-\ngraph and the translations up to the t-th segment.\nModel Predictive Control.\nIn general, direct op-\ntimization of (1) requires searching over all possi-\nble action sequences of length T and is compu-\ntationally intractable. As a predictive planning\nmethod, MPC approximately solves (1) by itera-\ntively solving local optimization problems (Hansen\net al., 2022), instead of globally optimizing the\ntotal utility in one pass. Specifically, MPC sequen-\ntially determines the action of each time step t by\nestimating the optimal subsequence a∗\nt:t+H given\nthe current state st, i.e.,\nΠMPC(st) = arg max\nat:t+H E\n\u0002\nJ (at:t+H, st:t+H)|st\n\u0003\n,\n(2)\n3\n\n\nContext Buffer\nsrc_ctx [0]\nsrc_ctx [1]\nsrc_ctx [2]\nmt_ctx [0]\nmt_ctx [1]\nmt_ctx [2]\nSource Context\nUpdate The Best MT Context\n石小白歪著頭思考了一會，攤手道：“就這樣。”\n(Stone White thought for a moment, shrugged, and said, “That's it.” )  \n梨子眼睛一瞪，什麼叫就這樣？\n(Li Zi's eyes widened in surprise, what did Stone White mean by that? )  \nSelf-Rewriting Task Input (Align in Sentence-Level)\nmt_ctx [0]\nmt_ctx [1]\nSource\n [    …    ]\n [    …    ]\n [    …    ]\n [    …    ]\n [    …    ]\n [    …    ]\n [    …    ]\nTranslation\n [    …    ]\n [    …    ]\n [    …    ]\n [    …    ]\n [    …    ]\n [    …    ]\n [    …    ]\nContext Alignment\nTranslations\nTranslations\nTranslations\nv.s.\nmt_ctx [2]\nUpdated MT Context\nmt_ctx [0]\nmt_ctx [1]\nmt_ctx [2]\nLLM\nReward Model \nBuffer Threshold\nctx [0]\nctx [1]\nSampling\nReference\nContexts\n(e.g., mt_ctx[1])\n還有呢？\nFigure 2: The framework of Plan2Align. To leverage past high-quality translations for preference alignment,\nPlan2Align transforms the translation task into a self-rewriting process. The LLM refines its translations by\nrevisiting previous outputs, segmenting the paragraph-level result, and aligning at the context level. A reward model,\ntrained on preference data, selects optimal contexts to update the context buffer. Through iterative refinement, the\nbetter context buffer improves context quality and generates better rewriting inputs, achieving both paragraph-level\npreference alignment and context-level coherence.\nand then executing the first action of ΠMPC(st). In\npractice, MPC solves (2) by employing a learned\npredictive dynamics model to generate multiple H-\nstep predictive rollouts {(a(i)\nt:t+H, s(i)\nt:t+H)}K\ni=1 and\nobtain an approximate maximizer by taking the\nmaximum of J (a(i)\nt:t+H, s(i)\nt:t+H) over the rollouts.\nPredictive Planning for Preference Alignment.\nIn paragraph-level MT, we adopt the principle\nof predictive planning in MPC for preference\nalignment. Figure 2 illustrates the framework of\nPlan2Align. Specifically: (i) We train a reward\nmodel on preference data.\nThis reward model,\nwhich plays the role of utility function in MPC,\nassesses translation context quality and serves as\na guiding function to align paragraph-level trans-\nlations with preferences. By integrating MPC, we\niteratively refine translations, ensuring alignment\nwith both linguistic quality and contextual consis-\ntency. (ii) The LLM itself can serve as a predictive\ndynamics model as the next state can be obtained\nby appending the newly generated translation seg-\nment to the current state. (iii) To enable MPC for\nparagraph-level MT while ensuring strong context-\nlevel performance, we further introduce two key\nmechanisms for accumulating and utilizing high-\nquality translation experiences as described in the\nnext two subsections.\n3.1.1\nContext Alignment and Context Buffer\nA fundamental challenge in using MPC in\nparagraph-level MT is: How to continuously accu-\nmulate and retain valuable translation experience?\nA high-scoring translated paragraph does not neces-\nsarily indicate that every part of it is of high quality.\nMoreover, non-extensive LLMs struggle to identify\nand leverage high-quality contexts from translated\nparagraphs due to their limited long-text compre-\nhension capabilities.\nInstead of direct MPC application in MT, we\nmodify MPC to selectively retain high-quality con-\ntexts from multiple paragraph-level translations in-\nstead of relying on a single best trajectory. This\nensures effective accumulation and utilization of\ntranslation experience. To achieve this, we estab-\nlish a context buffer, which stores high-quality\ncontext extracted from multiple paragraph-level\ntranslation experiences.\nIn our implementation, each context unit con-\nsists of three sentences, represented in the buffer\nas key-value pairs in a dictionary structure: source\ncontexts (src_ctx) as keys and corresponding trans-\nlation contexts (mt_ctx) as values. To comprehen-\nsively capture contextual dependencies, the context\nbuffer is constructed using a sliding-window mech-\nanism. Specifically, for a given paragraph, the first\nthree sentences form src_ctx[0], while sentences\n2-4 constitute src_ctx[1], and so forth. The transla-\ntion contexts are structured in the same manner.\nEach translation is aligned through context align-\nment, establishing correspondences between source\nand translation contexts. We evaluate the aligned\nsource and translation context pairs using a reward\nmodel trained on given preference data. Our goal\nis to ensure that the context buffer retains only\nhigh-quality contexts. The reward model assesses\ncandidate context-level translations and selectively\nretains only the best ones. When a selected transla-\ntion context surpasses a predefined buffer threshold\n4\n\n\nand a matching source context already exists in the\ncontext buffer, a comparison is performed. If the\nnew context falls below the threshold or does not\nsurpass the quality of the existing context in the\nbuffer, it is not stored.\nThrough this approach, in each iteration, the\nsystem filters high-quality contexts, continuously\nrefining the context buffer and ensuring that subse-\nquent translations improve over time.\n3.1.2\nTranslations from Self-Rewriting Tasks\nTo leverage high-quality contexts in the context\nbuffer for translation improvement, we frame the\ntranslation task as a self-rewriting task. To increase\nthe diversity of translation outputs generated by\nthe LLM, thereby enriching the context buffer with\nmore varied contexts, we sample reference contexts\nfrom the buffer to construct the self-rewriting task\ninput, rather than using the entire buffer content.\nBy providing LLMs with pre-aligned content as\ninput for self-rewriting, they can refine paragraph-\nlevel translations using past high-quality contexts\nwhile maintaining context-level coherence.\n3.2\nFinal Translation from Context Buffer\nThe final translation generation differs from con-\ntext buffer updates. In this phase, the stored high-\nquality contexts, covering nearly the entire para-\ngraph, serve as reference translations. Unlike the\nself-rewriting task, which aligns individual sen-\ntences, this final translation generation stage con-\nstructs the reference translation by incorporating all\nrelevant content from the context buffer and feed-\ning it along with the source paragraph into the LLM.\nThe LLM then improves the reference translation\nbased on the source, preventing overlapping transla-\ntion artifacts and ensuring fluency. Since this step\ninvolves refining a single high-quality reference\ntranslation with the source text, even non-extensive\nLLMs can handle the task effectively.\n3.3\nThe Details of Context Alignment\nSince the final translation relies on the quality of\nthe context buffer, improving its quality is crucial.\nTherefore, continuously updating the context buffer\nto retain the most valuable translation experience\nis essential. To achieve this, context alignment\nmust ensure proper pairing between source and\ntranslation contexts, allowing the reward model to\neffectively filter out low-quality translations and\nretain only the most reliable ones.\nHowever, there is no well-established method\nto effectively extract contextual information in\nparagraph-level MT. To address this, we propose\na simple yet effective approach for context align-\nment, which consists of three key steps: (i) Sen-\ntence Segmentation: We utilize the SpaCy (Hon-\nnibal et al., 2020) toolkit to segment paragraphs\ninto a list of sentences. (ii) Sentence Alignment:\nWe use VecAlign (Thompson and Koehn, 2020)\nto dynamically search for the optimal alignment\nbetween sentences. Since LLMs may introduce\nhallucinations, leading to sentence omissions or\nover-translations (resulting in extra sentences), we\ninsert any unaligned translation sentences into their\noriginal positions and add empty strings on the\nsource side as placeholders. (iii) Contextual Sliding\nWindow Construction: To capture the contextual\nstructure at the paragraph level, we adopt a sliding\nwindow approach with a window size of 3, forming\nthe context-level aligned source-translation pairs.\n4\nExperiments\n4.1\nTranslation Dataset\nCompared to sentence-level MT, paragraph-level\nMT has received significantly less attention, and\nmany translation models struggle to process long-\ncontext inputs. For example, Post and Junczys-\nDowmunt (2024) investigated a long-context train-\ning paradigm for machine translation but restrict\nthe maximum sequence length to 256. ALMA\n(Xu et al., 2024a,b) restricted their post-training\ndatasets to a maximum sequence length of 512.\nTo address this limitation and ensure a suitable\nbenchmark for paragraph-level MT, we use the\nlatest WMT’24 Discourse-Level Literary Trans-\nlation benchmark (Wang et al., 2024a) for our ex-\nperiments. This dataset allows for evaluating how\nwell translation methods preserve contextual re-\nlationships during translation. The available lan-\nguage pairs include: Chinese →English, Chinese\n→German, and Chinese →Russian.\nTo ensure that the input length remains within\nthe context window of our selected LLMs, we seg-\nment each instance from the training and validation\nsets into chunks of up to 1024 tokens. This prepro-\ncessing ensures that paragraph-level MT tasks are\neffectively handled within the model’s constraints.\nBut as the readers shall see, our methodology is\neasy to extend to even longer context given LLM\ntranslation capability is up to par.\n5\n\n\nzh →en\nzh →ru\nzh →de\nMethods\nTest-Time\nCW-COMET ↑\nCW-KIWI ↑\nd-BLEU ↑\n1-0/0-1 Ratio ↓\nCW-COMET ↑\nCW-KIWI ↑\nd-BLEU ↑\n1-0/0-1 Ratio ↓\nCW-COMET ↑\nCW-KIWI ↑\nd-BLEU ↑\n1-0/0-1 Ratio ↓\nGPT-4o 2024-08-06\n-\n94.58\n73.06\n27.77\n0.10\n93.74\n54.20\n19.89\n0.00\n94.54\n54.55\n21.93\n0.00\nQwen-2.5 (14B)\n-\n94.43\n72.44\n25.14\n0.18\n90.47\n50.13\n18.09\n3.08\n92.98\n50.02\n19.30\n1.24\nLlama-3.1 (8B)\n×\n84.36\n58.27\n20.74\n10.47\n86.28\n34.32\n8.30\n4.19\n88.97\n39.49\n11.05\n4.43\nLlama-3.1SFT\n×\n93.54\n67.16\n22.28\n0.34\n89.11\n43.99\n13.59\n1.92\n93.47\n47.39\n16.12\n0.19\nLlama-3.1SimPO\n×\n91.74\n62.31\n20.20\n1.66\n84.56\n41.66\n11.30\n2.53\n93.40\n46.47\n14.39\n0.00\nLlama-3.1DPO\n×\n90.23\n62.09\n20.50\n1.33\n82.15\n38.91\n11.69\n6.62\n93.48\n46.09\n14.20\n0.00\nLlama-3.1Plan2AlignSFT\n-\n93.05\n68.27\n21.53\n1.46\n91.71\n41.09\n10.52\n2.16\n93.94\n43.41\n12.12\n0.00\nLlama-3.1RAIN\n✓\n58.52\n36.39\n13.60\n37.18\n66.29\n31.75\n7.93\n27.79\n67.43\n31.69\n10.38\n27.15\nLlama-3.1ARGS\n✓\n63.99\n41.62\n11.09\n31.53\n43.03\n19.57\n2.78\n32.96\n51.97\n23.23\n3.76\n40.01\nLlama-3.1Best-of-60\n✓\n90.97\n65.41\n21.66\n3.58\n84.86\n48.93\n5.02\n3.89\n82.74\n38.55\n10.78\n10.78\nLlama-3.1Vanlia MPC\n✓\n89.79\n58.40\n7.30\n4.55\n82.83\n35.18\n7.19\n10.26\n83.67\n38.46\n10.82\n10.63\nLlama-3.1Plan2Align\n✓\n94.13\n67.06\n21.17\n0.20\n91.23\n40.11\n10.69\n1.49\n92.60\n44.62\n14.23\n1.44\nTable 1: Results on the test set of WMT24 literary translation shared task (zh→xx translation directions). Results are\nseparated into three groups: SoTA and base models, training-time alignment methods, test-time alignment methods.\nFor the two groups showing results from alignment methods, best numbers in respective groups are boldfaced, and\nbest numbers among all alignment methods are also underlined. Proposed methods are highlighted .\n4.2\nPreference Data and Model Training\nPreference data is crucial for training alignment\nmethods and for training the reward model used in\nPlan2Align. The preference data is derived from\nthe training set of the dataset. Specifically, each in-\nstance is segmented into paragraphs of up to 1024\ntokens. From each translation direction, we sam-\nple 2K paragraphs, resulting in a total of 6K para-\ngraphs for constructing the preference data. We\ngenerate translation outputs using LLaMA-3.1-8B-\nInstruct, Gemma-2-9B, and GPT-4o. The trans-\nlations are then evaluated using MetricX-24-XL\n(Juraska et al., 2024), a reference-free quality esti-\nmation (QE) model. The QE scores help us select\nhigh-quality translations: the translation with the\nhighest score is designated as the preferred transla-\ntion, while the one with the lowest score is consid-\nered not preferred. The translation with a middle\nscore is disregarded. The resulting preference data\nis used to train the reward model in Plan2Align,\nenabling it to assess context quality. The trained re-\nward model achieves a final accuracy of 88.53% on\nthe validation set. Further details on the formation\nof preference data can be found in Appendix A.\n4.3\nEvaluation Metrics\nWe focus on optimizing LLM-based paragraph-\nlevel MT models to mitigate contextual inconsis-\ntencies, hallucinations, and omissions. However,\nwhile model-based metrics have taken over string-\nbased metrics as the state-of-the-art, all model-\nbased metrics (e.g. COMET) are still only trained\nwith sentence-level data, and machine translation\nevaluation on paragraph-level remains an open\nquestion.\nA prior work (Deutsch et al., 2023)\nargued that existing metrics generalize well to\nparagraph-level, but the test set in that work is\na mere concatenation of existing datasets trans-\nlated by sentence-level models, and does not take\ninto account the context-level improvements we\nare aiming at. In fact, in our preliminary study, we\nobserved serious pathological behaviors of these\nmetrics when evaluating our paragraph-level out-\nputs (see Appendix E). This calls for a significant\nrework of the existing evaluation paradigm.\nThe changes we’ve made to our machine transla-\ntion evaluation paradigm are as follows:\nContextual Sliding Window.\nInstead of sim-\nply feeding the source, translation and reference\nsentences into COMET1 and COMET-KIWI (the\nreference-free version)2, we follow Vernikos et al.\n(2022) and add aligned and concatenated context\nas inputs to the model-based metrics. We call these\nmetrics CW-COMET and CW-KIWI. We use the\nsame context size of 3 as described in Section 3.3.\nSentence Segmentation and Alignment.\nSimi-\nlar to IWSLT evaluation paradigm for speech trans-\nlation (Ahmad et al., 2024), we propose to treat\nsentence segmentation and alignment as part of the\nevaluation for our paragraph-level evaluation. We\nfollow the same general procedure as described in\nSection 3.3. We handle sentence alignment differ-\nently according to whether the metric requires ref-\nerence input. Misaligned sentences remain in their\noriginal positions, with empty strings as placehold-\ners where necessary. If a sliding window contains\nonly empty strings on the one side, a default score\nof zero is given. This penalizes over-translation\nand omission, aligning with our research objec-\ntives. We verified the validity of our paradigm via\na sanity check. Details are in Appendix D.\n1Unbabel/wmt22-comet-da\n2Unbabel/wmt22-cometkiwi-da\n6\n\n\nIn addition to reporting model-based metrics,\nbecause over- and under-translations usually cre-\nate significant misalignments across sentences, we\ntrack them by reporting the ratio of 1-0 and 0-1\nalignments (1-0/0-1 Ratio), which represents the\nproportion of windows in the source or translation\nthat fail to align. This is evaluated on our sentence-\nsegmented and sentence-aligned test set. We also\nreport document-level BLEU (d-BLEU) as some\nprevious work has done, even it does not correlate\nwell with human judgments (Deutsch et al., 2023)\nand should only be treated as an auxiliary metric.\n4.4\nBaselines\nWe evaluate all training-time alignment methods\non LLaMA-3.1-8B-Instruct and also use it as the\nbackbone model for test-time alignment methods,\nincluding Plan2Align. This ensures consistency in\ncomparing the effectiveness and aligns with our\nfocus on small-scale LLMs. Additionally, we com-\npare these results against the original LLaMA-3.1-\n8B-Instruct to further assess improvements and\nchanges, serving as the baseline for performance.\nImplementation details of Plan2Align, including\nparameters and prompt design, are in Appendix C.\nGPT-4o and Qwen-2.5-14B.\nWe select GPT-4o\nas the upper bound for performance. GPT-4o is not\noptimized for translation, but closely approaches\nthat of specialized translation systems (Shahriar\net al., 2024). Its precedent model, GPT-4, was the\ntop-ranked model for 5 langauge pairs in WMT24\ngeneral machine translation shared task (Kocmi\net al., 2024). In addition, we also include Qwen-\n2.5-14B for comparison, as it demonstrates strong\nperformance in Chinese language contexts.\nTest-Time\nAlignment\nModels.\nWe\nselect\nARGS (Khanov et al., 2024) and RAIN (Li\net al., 2024) as they both represent test-time\nalignment methods similar to Plan2Align but\nwith distinct operational mechanisms. ARGS is\nselected for its reward-guiding method similar\nto Plan2Align’s;\nhowever, while Plan2Align\nevaluates the entire context with a reward model,\nARGS dynamically recalculates scores for each\ntoken during generation.\nOn the other hand,\nRAIN is selected for its ability to score newly\ngenerated tokens and perform auto-regressive\nself-evaluation,\nrequiring a start-from-scratch\nsearch and backward progression.\nTo better\nobserve the benefits brought by MPC, we also\ncompare it with Best-of-N and Vanilla MPC. The\nimplementation details of test-time alignments, are\navailable in Appendix B.1.\nTraining-Time Alignment Models.\nWe also\ncompare Plan2Align with various training-time\nalignment methods. We consider SFT directly on\nthe same preference dataset. Moreover, we include\nSimPO for comparison as it serves as a strong\nbenchmark for training-time alignment in general.\nWe also consider DPO as it serves as a mainstream\nrepresentative of the training-time-alignment series,\nwith training details available in Appendix B.2.\n4.5\nQuantitative Results\nWe present the primary results for zh→xx in Ta-\nble 1. Our primary goal is not to outperform all\nmodels but rather to maximize the utility of existing\nmodels, approaching or even surpassing training-\ntime alignment methods. Since training-time meth-\nods have direct exposure to real paragraph data,\ndirect comparisons to test-time methods would be\nunfair. Instead, we emphasize whether Plan2Align\ncan consistently improve existing model perfor-\nmance. We summarize the observations as follows:\nPlan2Align Outperforms Existing Test-Time\nAlignment Methods.\nTable 1 demonstrates that\nPlan2Align outperforms test-time alignment base-\nlines across all translation directions. This is pri-\nmarily because paragraph-level MT requires gen-\nerating long outputs, and existing methods such as\nARGS and RAIN guide the decoding process at the\ntoken level through a reward model. These meth-\nods struggle with error accumulation, where poor\nearly-context translations negatively affect subse-\nquent generations. Additionally, Table 2 highlights\nthe efficiency of Plan2Align compared to ARGS\nand RAIN, detailing the time required for each ap-\nproach across iterations. Since Plan2Align operates\ndirectly at the context level, it generates complete\ntranslated paragraphs without additional decoding\noverhead, making it both faster and more effective.\nPlan2Align Closes the Performance Gap Be-\ntween Test-Time and Training-Time Alignment\nMethods.\nFor zh→en, Plan2Align significantly\nenhances LLaMA-3.1’s performance, surpassing\ntraining-time methods in CW-COMET, demon-\nstrating that test-time alignment can effectively\nbridge the gap with training-time approaches. For\nzh→ru, while CW-COMET achieves the best per-\nformance, CW-KIWI lags behind training-time\nmethods, likely due to KIWI-22’s limitations in this\n7\n\n\nlanguage pair, preventing it from reflecting CW-\nCOMET’s improvements. Notably, Plan2Align\nsurpasses Qwen in CW-COMET, highlighting its\neffectiveness in low-resource settings such as Rus-\nsian, where Qwen may not be fully optimized. De-\nspite LLaMA-3.1’s limited Russian proficiency,\nPlan2Align’s self-rewriting and planning-based\nalignment mitigate these weaknesses, improving\ntranslation quality. For zh→de, while Plan2Align\ndoes not surpass training-time and SoTA models,\nit exhibits only a small performance gap. Cru-\ncially, Plan2Align is model-agnostic and seam-\nlessly integrates with existing architectures. Apply-\ning it to the strongest training-time model (SFT)\n(i.e., Llama-3.1Plan2AlignSFT), further enhances per-\nformance, bringing it closer to SoTA levels.\nBest-of-N, Vanilla MPC, and Plan2Align.\nAs\ndiscussed in Section 1, non-extensive LLMs strug-\ngle to generate high-quality paragraph translations\nin a single pass.\nThis limitation renders Best-\nof-N ineffective for paragraph-level MT, while\ndirectly applying MPC (i.e., Vanilla MPC) fails\ndue to the model’s difficulty in selecting opti-\nmal contexts for subsequent translations. Table 1\nshows that Best-of-N improves translation qual-\nity but does not enhance the model’s fundamen-\ntal capabilities. Its effectiveness remains limited\nby randomness, making it an inefficient approach.\nEven with N = 60 (six times the number of\niterations in Plan2Align), it still underperforms\ncompared to Plan2Align across all translation di-\nrections.\nVanilla MPC achieves improvements\nfor zh→en, but its effectiveness diminishes in\nzh→ru and zh→de, sometimes even falling below\nLLaMA-3.1’s baseline performance. This suggests\nthat for less familiar languages, LLMs struggle\nto extract meaningful improvements. Plan2Align\novercomes this limitation through context align-\nment and self-rewriting, enabling the effective ap-\nplication of MPC to paragraph-level MT.\nImpact of Iteration Number in MPC.\nAs iter-\nations increase, the context buffer expands, and\nPlan2Align selects more reference contexts. How-\never, over-translation and omission often prevent\nperfect semantic alignment. Using excessive refer-\nence contexts in the self-rewriting task can overload\nthe LLM, making it harder to extract meaningful\ninsights due to overlapping semantics. To isolate\ntranslation difficulty effects, we focus on zh →en\nperformance. Table 3 shows that while increasing\nreference contexts improves translation initially,\nAVG. Time Consumed\nMethods\nzh→en\nzh→de\nzh→ru\nARGS\n1686\n2343\n2035\nRAIN\n4639\n5518\n4454\nPlan2Align\n311\n313\n424\nTable 2: Average execution time (in seconds) per para-\ngraph for three test-time alignment methods on the val-\nidation set. Plan2Align, with an iteration number of\n3, is significantly faster than ARGS and RAIN since it\navoids token-level alignment. Tests are conducted on a\nsingle NVIDIA RTX 6000 Ada Generation GPU.\nIteration\nCW-COMET ↑\nCW-KIWI ↑\nd-BLEU ↑\n1-0/0-1 Ratio ↓\nPlan2Align\n1\n93.28\n66.89\n20.99\n0.32\n2\n93.82\n66.72\n20.75\n0.52\n3\n94.13\n67.06\n21.17\n0.20\n4\n93.95\n66.19\n20.81\n0.38\n5\n93.97\n66.59\n21.09\n0.35\nVanilla MPC\n1\n89.79\n58.40\n17.30\n4.55\n2\n88.00\n56.26\n16.45\n6.42\n3\n83.92\n53.08\n15.11\n10.70\n4\n84.66\n53.60\n15.26\n9.93\n5\n84.93\n54.03\n15.48\n9.68\nTable 3: Performance of Plan2Align and Vanilla MPC\nacross different iterations on the zh →en task.\nexcessive references (iteration = 4) degrade per-\nformance due to semantic ambiguity. Interestingly,\nVanilla MPC exhibits an even sharper decline that is\nstarting at iteration = 2, even in the simpler zh →en\ntask. This supports our hypothesis that LLMs can-\nnot directly leverage MPC effectively. Small-scale\nmodels struggle to extract useful contexts, leading\nto error accumulation and deteriorating translations.\nPlan2Align overcomes this limitation through struc-\ntured context alignment and self-rewriting, ensur-\ning stable improvements in paragraph-level MT.\n5\nConclusion\nIn this paper, we introduced Plan2Align, a new\nform of model predictive planning framework for\ntest-time preference alignment in paragraph-level\nmachine translation. By recasting translation as\na trajectory optimization problem and leveraging\na self-rewriting mechanism, our approach effec-\ntively addresses key challenges such as semantic\ndrift, omissions, and incoherence that arise in one-\npass, next-token generation. Our results suggest\nthat predictive planning can robustly accumulate\nand utilize high-quality translation contexts, paving\nthe way for further improvements in long-form ma-\nchine translation. Future work will explore broader\nlanguage pairs and the integration of training-time\nstrategies to further enhance translation quality.\nOur code will be open source under MIT license.\n8\n\n\nLimitation\nOne of our limitation lies in the scope of transla-\ntion languages. Our experiments have focused on\nlanguage pairs (e.g., Chinese to English, German,\nand Russian) from reproducible benchmarks, and\nwhile these choices provide valuable insights, they\ncould potentially not encompass the full linguistic\ndiversity present in the other translation tasks. Lan-\nguages with complex morphologies, low-resource\nlanguages, or those with radically different syn-\ntactic structures may present challenges that our\ncurrent formulation of context alignment and itera-\ntive refinement does not fully address. Future work\nhas been scheduled to explore a broader set of lan-\nguages to ensure that the method generalizes well\nand does not inadvertently favor certain language\nfamilies or linguistic features over others.\nEthical and Societal Considerations\nWhile\nPlan2Align is designed to enhance translation co-\nherence and quality, its deployment raises impor-\ntant ethical and societal considerations. First, there\nis an inherent risk of bias amplification. The re-\nward model, which drives context selection dur-\ning test-time alignment, is trained on preference\ndata that may itself contain implicit biases. If not\ncarefully audited and diversified, this could lead\nto translations that systematically favor dominant\nlinguistic norms or cultural perspectives, marginal-\nizing underrepresented human dialects. In sum, by\nfocusing on a limited set of languages and model\narchitectures, there is a risk of reinforcing exist-\ning digital divides. If high-quality translation tools\nare predominantly developed for well-resourced\nlanguages and large-scale models, speakers of low-\nresource or underrepresented languages may be\nleft behind. As researchers and practitioners, it is\na long-term developing responsibility to prioritize\ninclusivity and fairness, ensuring that technological\nadvances in machine translation benefit a diverse\nresearch community.\nAcknowledgment\nThis research has been sup-\nported by NVIDIA grant and technical involvement\nfrom NVIDIA Taiwan AI R&D Center (TRDC).\nReferences\nJosh Achiam, Steven Adler, Sandhini Agarwal, Lama\nAhmad, Ilge Akkaya, Florencia Leoni Aleman,\nDiogo Almeida, Janko Altenschmidt, Sam Altman,\nShyamal Anadkat, et al. 2023. GPT-4 Technical Re-\nport. arXiv preprint arXiv:2303.08774.\nIbrahim Said Ahmad, Antonios Anastasopoulos, Ondˇrej\nBojar, Claudia Borg, Marine Carpuat, Roldano\nCattoni, Mauro Cettolo, William Chen, Qianqian\nDong, Marcello Federico, Barry Haddow, Dávid Ja-\nvorský, Mateusz Krubi´nski, Tsz Kin Lam, Xutai Ma,\nPrashant Mathur, Evgeny Matusov, Chandresh Mau-\nrya, John McCrae, Kenton Murray, Satoshi Naka-\nmura, Matteo Negri, Jan Niehues, Xing Niu, Atul Kr.\nOjha, John Ortega, Sara Papi, Peter Polák, Adam\nPospíšil, Pavel Pecina, Elizabeth Salesky, Nivedita\nSethiya, Balaram Sarkar, Jiatong Shi, Claytone Sika-\nsote, Matthias Sperber, Sebastian Stüker, Katsuhito\nSudoh, Brian Thompson, Alex Waibel, Shinji Watan-\nabe, Patrick Wilken, Petr Zemánek, and Rodolfo Ze-\nvallos. 2024. Findings of the IWSLT 2024 Evaluation\nCampaign. In Proceedings of the 21st International\nConference on Spoken Language Translation (IWSLT\n2024), pages 1–11, Bangkok, Thailand (in-person\nand online). Association for Computational Linguis-\ntics.\nDuarte Miguel Alves, José Pombal, Nuno M Guerreiro,\nPedro Henrique Martins, João Alves, Amin Farajian,\nBen Peters, Ricardo Rei, Patrick Fernandes, Sweta\nAgrawal, Pierre Colombo, José G. C. de Souza, and\nAndre Martins. 2024. Tower: An Open Multilingual\nLarge Language Model for Translation-Related Tasks.\nIn First Conference on Language Modeling.\nTom Brown, Benjamin Mann, Nick Ryder, Melanie\nSubbiah, Jared D Kaplan, Prafulla Dhariwal, Arvind\nNeelakantan, Pranav Shyam, Girish Sastry, Amanda\nAskell, et al. 2020. Language Models are Few-shot\nLearners. Advances in neural information processing\nsystems, 33:1877–1901.\nE. F. Camacho and C. Bordons. 2007. Constrained\nModel Predictive Control, pages 177–216. Springer\nLondon, London.\nKurtland Chua, Roberto Calandra, Rowan McAllis-\nter, and Sergey Levine. 2018. Deep Reinforcement\nLearning in a Handful of Trials using Probabilistic\nDynamics Models. Advances in neural information\nprocessing systems, 31.\nDaniel Deutsch, Juraj Juraska, Mara Finkelstein, and\nMarkus Freitag. 2023. Training and Meta-Evaluating\nMachine Translation Evaluation Metrics at the Para-\ngraph Level. In Proceedings of the Eighth Confer-\nence on Machine Translation, pages 996–1013, Sin-\ngapore. Association for Computational Linguistics.\nAngela Fan, Shruti Bhosale, Holger Schwenk, Zhiyi\nMa, Ahmed El-Kishky, Siddharth Goyal, Mandeep\nBaines, Onur Celebi, Guillaume Wenzek, Vishrav\nChaudhary, Naman Goyal, Tom Birch, Vitaliy\nLiptchinsky, Sergey Edunov, Michael Auli, and Ar-\nmand Joulin. 2021. Beyond English-Centric Multi-\nlingual Machine Translation. J. Mach. Learn. Res.\nZhaopeng Feng, Yan Zhang, Hao Li, Bei Wu, Jiayu Liao,\nWenqiang Liu, Jun Lang, Yang Feng, Jian Wu, and\nZuozhu Liu. 2024. Tear: Improving LLM-based Ma-\nchine Translation with Systematic Self-refinement.\nPreprint.\n9\n\n\nPatrick Fernandes, Kayo Yin, Emmy Liu, André Mar-\ntins, and Graham Neubig. 2023. When Does Transla-\ntion Require Context? A Data-driven, Multilingual\nExploration. In Proceedings of the 61st Annual Meet-\ning of the Association for Computational Linguistics\n(Volume 1: Long Papers), pages 606–626, Toronto,\nCanada. Association for Computational Linguistics.\nMohamed Seghir Hadj Ameur, Ahmed Guessoum, and\nFarid Meziane. 2019. Improving Arabic Neural Ma-\nchine Translation via N-best List Re-ranking. ma-\nchine translation, 33:279–314.\nNicklas A Hansen, Hao Su, and Xiaolong Wang. 2022.\nTemporal Difference Learning for Model Predictive\nControl. In International Conference on Machine\nLearning, pages 8387–8406.\nDan Hendrycks, Collin Burns, Steven Basart, Andy Zou,\nMantas Mazeika, Dawn Song, and Jacob Steinhardt.\n2021. Measuring Massive Multitask Language Un-\nderstanding. In International Conference on Learn-\ning Representations.\nMatthew Honnibal, Ines Montani, Sofie Van Lan-\ndeghem, and Adriane Boyd. 2020. spaCy: Industrial-\nstrength Natural Language Processing in Python.\nEdward J Hu, yelong shen, Phillip Wallis, Zeyuan Allen-\nZhu, Yuanzhi Li, Shean Wang, Lu Wang, and Weizhu\nChen. 2022. LoRA: Low-Rank Adaptation of Large\nLanguage Models. In International Conference on\nLearning Representations.\nYuchen Hu, Chen Chen, Chao-Han Yang, Ruizhe Li,\nDong Zhang, Zhehuai Chen, and EngSiong Chng.\n2024. GenTranslate: Large Language Models are\nGenerative Multilingual Speech and Machine Trans-\nlators. In Proceedings of the 62nd Annual Meeting of\nthe Association for Computational Linguistics (Vol-\nume 1: Long Papers), pages 74–90, Bangkok, Thai-\nland. Association for Computational Linguistics.\nJie Ji, Amir Khajepour, Wael William Melek, and Yan-\njun Huang. 2016. Path Planning and Tracking for Ve-\nhicle Collision Avoidance Based on Model Predictive\nControl With Multiconstraints. IEEE Transactions\non Vehicular Technology, 66(2):952–964.\nJuraj Juraska, Daniel Deutsch, Mara Finkelstein, and\nMarkus Freitag. 2024.\nMetricX-24: The Google\nSubmission to the WMT 2024 Metrics Shared Task.\nIn Proceedings of the Ninth Conference on Machine\nTranslation, pages 492–504, Miami, Florida, USA.\nAssociation for Computational Linguistics.\nMaxim Khanov, Jirayu Burapacheep, and Yixuan Li.\n2024. ARGS: Alignment as Reward-Guided Search.\nIn The Twelfth International Conference on Learning\nRepresentations.\nTom Kocmi, Eleftherios Avramidis, Rachel Bawden,\nOndˇrej Bojar, Anton Dvorkovich, Christian Feder-\nmann, Mark Fishel, Markus Freitag, Thamme Gowda,\nRoman Grundkiewicz, Barry Haddow, Marzena\nKarpinska, Philipp Koehn, Benjamin Marie, Christof\nMonz, Kenton Murray, Masaaki Nagata, Martin\nPopel, Maja Popovi´c, Mariya Shmatova, Steinthór\nSteingrímsson, and Vilém Zouhar. 2024. Findings\nof the WMT24 general machine translation shared\ntask: The LLM era is here but MT is not solved yet.\nIn Proceedings of the Ninth Conference on Machine\nTranslation, pages 1–46, Miami, Florida, USA. As-\nsociation for Computational Linguistics.\nBasil Kouvaritakis and Mark Cannon. 2016. Model Pre-\ndictive Control. Switzerland: Springer International\nPublishing, 38:13–56.\nYuhui Li, Fangyun Wei, Jinjing Zhao, Chao Zhang,\nand Hongyang Zhang. 2024. RAIN: Your Language\nModels Can Align Themselves without Finetuning.\nIn The Twelfth International Conference on Learning\nRepresentations.\nBill Yuchen Lin, Abhilasha Ravichander, Ximing Lu,\nNouha Dziri, Melanie Sclar, Khyathi Chandu, Chan-\ndra Bhagavatula, and Yejin Choi. 2024. The Unlock-\ning Spell on Base LLMs: Rethinking Alignment via\nIn-Context Learning. In The Twelfth International\nConference on Learning Representations.\nIlya Loshchilov and Frank Hutter. 2019. Decoupled\nWeight Decay Regularization. In International Con-\nference on Learning Representations.\nKendall Lowrey, Aravind Rajeswaran, Sham Kakade,\nEmanuel Todorov, and Igor Mordatch. 2019. Plan\nOnline, Learn Offline: Efficient Learning and Explo-\nration via Model-Based Control. In International\nConference on Learning Representations.\nAngrosh Mandya, James O’ Neill, Danushka Bollegala,\nand Frans Coenen. 2020. Do Not Let the History\nHaunt You: Mitigating Compounding Errors in Con-\nversational Question Answering. In Proceedings of\nthe Twelfth Language Resources and Evaluation Con-\nference, pages 2017–2025, Marseille, France. Euro-\npean Language Resources Association.\nSameen Maruf, Fahimeh Saleh, and Gholamreza Haffari.\n2022. A Survey on Document-level Neural Machine\nTranslation: Methods and Evaluation. ACM Comput-\ning Surveys, 54(2):45:1–45:36.\nYu Meng, Mengzhou Xia, and Danqi Chen. 2024.\nSimPO: Simple Preference Optimization With a\nReference-Free Reward. In The Thirty-eighth An-\nnual Conference on Neural Information Processing\nSystems.\nAnusha Nagabandi, Kurt Konolige, Sergey Levine, and\nVikash Kumar. 2020. Deep Dynamics Models for\nLearning Dexterous Manipulation. In Conference on\nRobot Learning, pages 1101–1112. PMLR.\nOpenAI. 2024. Hello GPT-4o (API version 4o-0211).\nAccessed: 2025-02-14.\nLong Ouyang, Jeffrey Wu, Xu Jiang, Diogo Almeida,\nCarroll L. Wainwright, Pamela Mishkin, Chong\nZhang, Sandhini Agarwal, Katarina Slama, Alex Ray,\n10\n\n\nJohn Schulman, Jacob Hilton, Fraser Kelton, Luke\nMiller, Maddie Simens, Amanda Askell, Peter Welin-\nder, Paul F. Christiano, Jan Leike, and Ryan Lowe.\n2022. Training Language Models to Follow Instruc-\ntions with Human Feedback. In Advances in Neural\nInformation Processing Systems.\nMatt Post and Marcin Junczys-Dowmunt. 2024. Eval-\nuation and Large-Scale Training for Contextual Ma-\nchine Translation. In Proceedings of the Ninth Con-\nference on Machine Translation, pages 1125–1139,\nMiami, Florida, USA. Association for Computational\nLinguistics.\nJiahao Qiu, Yifu Lu, Yifan Zeng, Jiacheng Guo, Ji-\nayi Geng, Huazheng Wang, Kaixuan Huang, Yue\nWu, and Mengdi Wang. 2024. TreeBoN: Enhancing\nInference-Time Alignment with Speculative Tree-\nSearch and Best-of-N Sampling.\nComputing Re-\nsearch Repository.\nRafael Rafailov, Archit Sharma, Eric Mitchell, Christo-\npher D Manning, Stefano Ermon, and Chelsea Finn.\n2023. Direct Preference Optimization: Your Lan-\nguage Model is Secretly a Reward Model. In Thirty-\nseventh Conference on Neural Information Process-\ning Systems.\nAnil V. Rao. 2014. Trajectory Optimization: A Sur-\nvey, pages 3–21. Springer International Publishing,\nCham.\nSakib Shahriar, Brady D. Lund, Nishith Reddy Man-\nnuru, Muhammad Arbab Arshad, Kadhim Hayawi,\nRavi Varma Kumar Bevara, Aashrith Mannuru, and\nLaiba Batool. 2024. Putting GPT-4o to the Sword:\nA Comprehensive Evaluation of Language, Vision,\nSpeech, and Multimodal Proficiency. Computing\nResearch Repository, abs/2407.09519.\nAarohi Srivastava, Abhinav Rastogi, Abhishek Rao,\nAbu Awal Md Shoeb, Abubakar Abid, Adam Fisch,\nAdam R. Brown, Adam Santoro, Aditya Gupta,\nAdrià Garriga-Alonso, Agnieszka Kluska, Aitor\nLewkowycz, Akshat Agarwal, Alethea Power, Alex\nRay, Alex Warstadt, Alexander W. Kocurek, Ali\nSafaya, Ali Tazarv, Alice Xiang, Alicia Parrish,\nAllen Nie, Aman Hussain, Amanda Askell, Amanda\nDsouza, Ambrose Slone, Ameet Rahane, Ananthara-\nman S. Iyer, Anders Johan Andreassen, Andrea\nMadotto, Andrea Santilli, Andreas Stuhlmüller, An-\ndrew M. Dai, Andrew La, Andrew Kyle Lampinen,\nAndy Zou, Angela Jiang, Angelica Chen, Anh Vuong,\nAnimesh Gupta, Anna Gottardi, et al. 2023. Beyond\nthe Imitation Game: Quantifying and Extrapolating\nthe Capabilities of Language Models. Transactions\non Machine Learning Research. Featured Certifica-\ntion.\nNisan Stiennon, Long Ouyang, Jeffrey Wu, Daniel\nZiegler, Ryan Lowe, Chelsea Voss, Alec Radford,\nDario Amodei, and Paul F Christiano. 2020. Learn-\ning to Summarize with Human Feedback. Advances\nin Neural Information Processing Systems, 33:3008–\n3021.\nYuval Tassa, Tom Erez, and Emanuel Todorov. 2012.\nSynthesis and Stabilization of Complex Behaviors\nthrough Online Trajectory Optimization. In 2012\nIEEE/RSJ International Conference on Intelligent\nRobots and Systems, pages 4906–4913. IEEE.\nYuval Tassa, Nicolas Mansard, and Emo Todorov. 2014.\nControl-limited Differential Dynamic Programming.\nIn 2014 IEEE International Conference on Robotics\nand Automation (ICRA), pages 1168–1175. IEEE.\nGemma Team, Morgane Riviere, Shreya Pathak,\nPier Giuseppe Sessa, Cassidy Hardin, Surya Bhupati-\nraju, Léonard Hussenot, Thomas Mesnard, Bobak\nShahriari, Alexandre Ramé, et al. 2024. Gemma 2:\nImproving Open Language Models at a Practical Size.\narXiv preprint arXiv:2408.00118.\nBrian Thompson and Philipp Koehn. 2020. Exploiting\nSentence Order in Document Alignment. In Proceed-\nings of the 2020 Conference on Empirical Methods\nin Natural Language Processing (EMNLP), pages\n5997–6007, Online. Association for Computational\nLinguistics.\nHugo Touvron, Thibaut Lavril, Gautier Izacard, Xavier\nMartinet, Marie-Anne Lachaux, Timothée Lacroix,\nBaptiste Rozière, Naman Goyal, Eric Hambro, Faisal\nAzhar, et al. 2023a.\nLLaMA: Open and Effi-\ncient Foundation Language Models. arXiv preprint\narXiv:2302.13971.\nHugo Touvron, Louis Martin, Kevin Stone, Peter Al-\nbert, Amjad Almahairi, Yasmine Babaei, Nikolay\nBashlykov, Soumya Batra, Prajjwal Bhargava, Shruti\nBhosale, et al. 2023b.\nLlama 2: Open Founda-\ntion and Fine-tuned Chat Models. arXiv preprint\narXiv:2307.09288.\nGiorgos Vernikos, Brian Thompson, Prashant Mathur,\nand Marcello Federico. 2022. Embarrassingly Easy\nDocument-Level MT Metrics: How to Convert Any\nPretrained Metric into a Document-Level Metric. In\nProceedings of the Seventh Conference on Machine\nTranslation (WMT), pages 118–128, Abu Dhabi,\nUnited Arab Emirates (Hybrid). Association for Com-\nputational Linguistics.\nElena Voita, Pavel Serdyukov, Rico Sennrich, and Ivan\nTitov. 2018. Context-Aware Neural Machine Trans-\nlation Learns Anaphora Resolution. In Proceedings\nof the 56th Annual Meeting of the Association for\nComputational Linguistics (Volume 1: Long Papers),\npages 1264–1274, Melbourne, Australia. Association\nfor Computational Linguistics.\nLongyue Wang, Siyou Liu, Chenyang Lyu, Wenxiang\nJiao, Xing Wang, Jiahao Xu, Zhaopeng Tu, Yan Gu,\nWeiyu Chen, Minghao Wu, Liting Zhou, Philipp\nKoehn, Andy Way, and Yulin Yuan. 2024a. Findings\nof the WMT 2024 Shared Task on Discourse-Level\nLiterary Translation. In Proceedings of the Ninth\nConference on Machine Translation, pages 699–700,\nMiami, Florida, USA. Association for Computational\nLinguistics.\n11\n\n\nLongyue Wang, Chenyang Lyu, Tianbo Ji, Zhirui Zhang,\nDian Yu, Shuming Shi, and Zhaopeng Tu. 2023.\nDocument-Level Machine Translation with Large\nLanguage Models. In The 2023 Conference on Em-\npirical Methods in Natural Language Processing.\nPengyu Wang, Dong Zhang, Linyang Li, Chenkun Tan,\nXinghao Wang, Mozhi Zhang, Ke Ren, Botian Jiang,\nand Xipeng Qiu. 2024b. InferAligner: Inference-\nTime Alignment for Harmlessness through Cross-\nModel Guidance. In Proceedings of the 2024 Confer-\nence on Empirical Methods in Natural Language Pro-\ncessing, pages 10460–10479, Miami, Florida, USA.\nAssociation for Computational Linguistics.\nMinghao Wu, George Foster, Lizhen Qu, and Gholam-\nreza Haffari. 2023. Document Flattening: Beyond\nConcatenating Context for Document-Level Neural\nMachine Translation. In Proceedings of the 17th\nConference of the European Chapter of the Associa-\ntion for Computational Linguistics, pages 448–462,\nDubrovnik, Croatia. Association for Computational\nLinguistics.\nQiyu Wu, Masaaki Nagata, Zhongtao Miao, and Yoshi-\nmasa Tsuruoka. 2024. Word Alignment as Prefer-\nence for Machine Translation. In Proceedings of\nthe 2024 Conference on Empirical Methods in Natu-\nral Language Processing, pages 3223–3239, Miami,\nFlorida, USA. Association for Computational Lin-\nguistics.\nHaoran Xu, Young Jin Kim, Amr Sharaf, and Hany Has-\nsan Awadalla. 2024a. A Paradigm Shift in Machine\nTranslation: Boosting Translation Performance of\nLarge Language Models. In The Twelfth Interna-\ntional Conference on Learning Representations.\nHaoran Xu, Amr Sharaf, Yunmo Chen, Weiting Tan,\nLingfeng Shen, Benjamin Van Durme, Kenton Mur-\nray, and Young Jin Kim. 2024b. Contrastive Prefer-\nence Optimization: Pushing the Boundaries of LLM\nPerformance in Machine Translation. In Forty-first\nInternational Conference on Machine Learning.\nLinting Xue, Noah Constant, Adam Roberts, Mihir Kale,\nRami Al-Rfou, Aditya Siddhant, Aditya Barua, and\nColin Raffel. 2021. mT5: A Massively Multilingual\nPre-trained Text-to-Text Transformer. In Proceed-\nings of the 2021 Conference of the North American\nChapter of the Association for Computational Lin-\nguistics: Human Language Technologies, pages 483–\n498, Online. Association for Computational Linguis-\ntics.\nJifan Yu, Xiaozhi Wang, Shangqing Tu, Shulin Cao,\nDaniel Zhang-Li, Xin Lv, Hao Peng, Zijun Yao, Xi-\naohan Zhang, Hanming Li, Chunyang Li, Zheyuan\nZhang, Yushi Bai, Yantao Liu, Amy Xin, Kaifeng\nYun, Linlu GONG, Nianyi Lin, Jianhui Chen, Zhili\nWu, Yunjia Qi, Weikai Li, Yong Guan, Kaisheng\nZeng, Ji Qi, Hailong Jin, Jinxin Liu, Yu Gu, Yuan\nYao, Ning Ding, Lei Hou, Zhiyuan Liu, Xu Bin,\nJie Tang, and Juanzi Li. 2024.\nKoLA: Carefully\nBenchmarking World Knowledge of Large Language\nModels. In The Twelfth International Conference on\nLearning Representations.\nYaowei Zheng, Richong Zhang, Junhao Zhang, Yanhan\nYe, Zheyan Luo, Zhangchi Feng, and Yongqiang Ma.\n2024. LlamaFactory: Unified Efficient Fine-Tuning\nof 100+ Language Models. In Proceedings of the\n62nd Annual Meeting of the Association for Compu-\ntational Linguistics (Volume 3: System Demonstra-\ntions).\nWanjun Zhong, Ruixiang Cui, Yiduo Guo, Yaobo Liang,\nShuai Lu, Yanlin Wang, Amin Saied, Weizhu Chen,\nand Nan Duan. 2024. AGIEval: A Human-Centric\nBenchmark for Evaluating Foundation Models. In\nFindings of the Association for Computational Lin-\nguistics: NAACL 2024, pages 2299–2314, Mexico\nCity, Mexico. Association for Computational Lin-\nguistics.\nDaniel M. Ziegler, Nisan Stiennon, Jeffrey Wu, Tom\nBrown, Alec Radford, Dario Amodei, Paul Chris-\ntiano, and Geoffrey Irving. 2019. Fine-Tuning Lan-\nguage Models from Human Preferences.\narXiv\npreprint arXiv:1909.08593.\n12\n\n\nA\nDetails of Preference Data\nWe used MetricX-24-XL to labeled our pairwise\npreference datasets, the Chinese sources sentences\nare from WMT’24 Discourse-Level Literary Trans-\nlation benchmark, we employed LLaMA-3.1-8B-\nInstruct, Gemma-2-9B, and GPT-4o to generate\ntranslations across three language pairs; each lan-\nguage pair has 2000 records, with a maximum\nlength of 1024 tokens. The distribution of pref-\nerences, indicating the number of translation is the\nbest translation among the three,indicating the num-\nber of translation is the best translation among the\nthree, given that MetricX-24 scores range from 0\nto 25, where 0 is the best and 25 is the worst. We\nremoved translations scoring above 20, and if two\nout of three translations in a paragraph exceeded\nthis threshold, we did not use that paragraph. The\ndetails are in Table 4. Our test-time setting, pre-\ntrained models, and preference data will be open\nsource under MIT license.\nLLaMA Wins\nGemma Wins\nGPT4 Wins\nzh→en\n310\n421\n1269\nzh→de\n82\n99\n1814\nzh→ru\n32\n127\n1680\nTable 4: The statistics of winning translations for each\nlanguage pairs evaluated by MetricX-24.\nB\nImplementation Details of Baselines\nB.1\nTest-Time Alignment Methods\nB.1.1\nARGS\nWe follow the setting of ARGS, We adopt the\nARGS-greedy method in ARGS as our baseline.\nFollowing the setting of ARGS-greedy. We set w to\n1.5 and k to 10. For fairness, we replaced the back-\nbone model with the same LLaMA3.1-8B-Instruct\nas Plan2Align, and the reward model was also re-\nplaced with the reward model used by Plan2Align.\nAlthough ARGS settings indicate that using ARGS-\ngreedy results in answers more closely aligned with\nthe characteristics specified in the reward model,\nARGS uses the weighted sum of logit of the token\nand the reward for token generation. Given that\nthe number of tokens generated by ARGS-greedy\ndoes not exceed those produced by Plan2Align and\nRAIN, we included ARGS-stochastic for compar-\nison and conducted best-of-n to optimize results,\nthe choice of n was determined based on the aver-\nage number of tokens required by Plan2Align and\nRAIN to generate a single translation.\nHowever, ARGS-stochastic’s best-of-n did not sur-\npass ARGS-greedy in performance, leading us to\nultimately select ARGS-greedy as the baseline.\nB.1.2\nRAIN\nIn RAIN, we also replaced the backbone model\nwith LLaMA3.1-8B-Instruct and replaced the self-\nevaluation prompt in RAIN with text in the Fig-\nure 3. For parameters in RAIN, we set value thresh-\nold V to 0.8 as the default setting of RAIN. We\ntry four combinations of maximum and minimum\nnumber of search iterations for finding the param-\neter that generates the required number of tokens\nclose to Plan2Align, which are [10,20]. The de-\ntailed configuration of the tokens generated in each\nparameter pairs is in Table 5.\n(MinT,MaxT)\nAVG. tokens\n[6,12]\n6575\n[8,16]\n8972\n[10,20]\n13401\n[12,24]\n17291\nTable 5: The average number of tokens required to\ngenerate a translation for RAIN in each maximum and\nminimum number of search iterations pairs.\nB.1.3\nVanilla MPC\nVanilla MPC applies MPC directly to paragraph-\nlevel machine translation (MT) by selecting the\nbest output from the previous iteration and refining\nit. We conduct six iterations, with performance re-\nsults presented in Table 6. The best performance for\neach language pair (iteration = 1, 2, 4 for zh→en,\nzh→ru, and zh→de, respectively) is reported in\nTable 1. The results show that even in the zh→en\ntranslation direction, performance continues to de-\ncline over iterations. For more challenging lan-\nguage pairs (zh→ru and zh→de), LLMs struggle\nto extract useful contexts, preventing sustained im-\nprovement and leading to unstable performance.\nB.2\nTraining-Time Alignment Methods\nWe choose LLaMA3.1-8B-Instruct as our exper-\niments’ backbone model, including the reward\nmodel and training-time methods. We utilize one\nNVIDIA RTX 6000 Ada Generation GPU to train\nmodels with the LLaMA Factory library3 (Zheng\net al., 2024).\nFor the training setups, the SFT\nmodel is trained on preferred data from the pref-\nerence dataset, while the Reward Model, DPO,\n3https://github.com/hiyouga/LLaMA-Factory\n13\n\n\nIteration\nCW-COMET ↑\nCW-KIWI ↑\nd-BLEU ↑\n1-0/0-1 Ratio ↓\nzh-en\n1\n89.79\n58.40\n17.30\n4.55\n2\n88.00\n56.26\n16.45\n6.42\n3\n83.92\n53.08\n15.11\n10.70\n4\n84.66\n53.60\n15.26\n9.93\n5\n84.93\n54.03\n15.48\n9.68\n6\n84.48\n52.91\n15.12\n10.08\nzh-en\n1\n73.80\n30.83\n5.54\n20.00\n2\n82.83\n35.18\n7.19\n10.26\n3\n77.08\n34.08\n6.15\n16.40\n4\n79.56\n33.25\n6.21\n13.74\n5\n78.35\n33.31\n6.34\n15.35\n6\n78.35\n33.37\n5.43\n15.24\nzh-en\n1\n83.06\n39.00\n10.89\n11.19\n2\n80.88\n36.74\n8.95\n13.03\n3\n79.79\n36.72\n9.70\n14.51\n4\n83.67\n38.46\n10.82\n10.63\n5\n82.72\n38.54\n10.25\n11.40\n6\n79.35\n35.87\n9.54\n14.87\nTable 6: Performance of Vanilla MPC across different\niterations.\nand SimPO are trained on the full preference data\nthat includes inputs, good translations, and bad\ntranslations. All models are configured with an\nidentical set of hyperparameters: they utilize the\nAdamW(Loshchilov and Hutter, 2019) optimizer\nand feature gradient accumulation steps fixed at\n8, with a cutoff length of 2048. The maximum\nallowable gradient norm is restricted to 1.0 to en-\nsure training stability. All training procedures are\nconducted using bf16 precision, each model under-\ngoes a single epoch of training with a batch size of\n2, and the LoRA(Hu et al., 2022) rank and LoRA\nalpha parameters are set to 16 across all models.\nThe learning rates for the models are: Rewarg\nModel at 1e-5, SFT at 2e-5, and both DPO and\nSimPO at 1e-6 as suggested by (Rafailov et al.,\n2023) and (Meng et al., 2024).\nAdditionally,\nSimPO utilizes a beta and gamma of 2.5, which\naligns with its setup, whereas SFT and DPO use a\nbeta of 0.1 also followed by (Rafailov et al., 2023).\nWhen Plan2Align serves as a generic method, we\nalso plan to connect the method for multi-agent\n(i.e., cascaded) based translation system (Hu et al.,\n2024) in the future.\nC\nImplementation Details of Plan2Align\nIn this section, we describe our parameter settings\nand prompt design, as well as the impact of differ-\nent prompts on the final translation generation. Our\nfull approach is outlined in Algorithm 1.\nC.1\nParameter Setting\nTo generate diverse translations for comparison,\nwe design three distinct system prompts for the\nself-rewriting task, resulting in three translation\noutputs per iteration. The context alignment win-\ndow size is set to 3, the context buffer threshold\nis fixed at 2, and the iteration number is set to\n3. When constructing the self-rewriting task in-\nput from the context buffer, we employ a sampling\nstrategy to enhance translation diversity and iden-\ntify more valuable contexts: As the number of it-\nerations increases, the content within the context\nbuffer expands. Consequently, we adaptively in-\ncrease the number of reference contexts selected\nby Plan2Align. Specifically, we tie the number of\nreference contexts to the current iteration count\nusing the formula: reference context number =\ncurrent iteration number + 5.\nC.2\nPrompt Design\nHere is the prompt configuration for generating\ntranslations in Plan2Align: Figure 4 displays our\nprompt template for the self-rewriting task within\nPlan2Align.\nWe employ three distinct system\nprompts that yield three types of translations:\nsentence-by-sentence translation, precise transla-\ntion, and imaginative translation. These prompts\ncater to different translation needs within the con-\ntext buffer, allowing us to extract the most effective\nparts. Additionally, we use a context prompt to\nensure the quality of the translations produced. Fig-\nures 5 and 6 showcase the prompts used for generat-\ning the final translations in Plan2Align. The distinc-\ntions between these two prompts, Reference and\nAnnotation, are further explored in Section C.2.1.\nC.2.1\nImpact of Final Translation Task\nIn Plan2Align, final translation generation differs\nfrom context buffer updates.\nThe final transla-\ntion is produced by assembling buffer-stored con-\ntexts in source sentence order, forming a reference\ntranslation (Reference). Conversely, during con-\ntext buffer updates, translated sentences are an-\nnotated beneath their corresponding source sen-\ntences (Annotation). Table 7 shows that the Refer-\nence approach outperforms Annotation in zh→ru\nand zh→de. However, for zh→en, the Annota-\ntion method generally performs better. This dif-\nference arises because annotating each source sen-\ntence with context buffer information and refining\nsegments independently, although not requiring ex-\nplicit alignment, demands higher semantic under-\nstanding. This makes it effective for zh→en but\nburdensome for the other two translation directions.\nIn contrast, the Reference approach offers greater\nflexibility in refining the entire paragraph.\n14\n\n\nAlgorithm 1 Plan2Align\nInputs: Source x, number of MPC iterations N, base model LM, reward model r\nOutput: Translation result yfinal\n1: Initial buffer B\n2: for k = 0 →N −2 do\n3:\ny ←LM\n\u0000x, prompt in Figure 4\n\u0001\n// Translation from 3 system prompt\n4:\n(Wx, Wy) ←Make source and translation into aligned context windows\n// See Section 3.1.1\n5:\nfor all (wx, wy) ∈(Wx, Wy) do\n6:\nreward ←r(wx, wy)\n// Compute rewards for each window pair\n7:\nUpdate the best window at each position to put into Buffer B\n// Window selection\n8:\nend for\n9:\nyfinal ←LM\n\u0000sentences in B, prompts in Figures 5\n\u0001\n10: end for\n11: return yfinal\nPrompt Type\nCW-COMET ↑\nCW-KIWI ↑\nd-BLEU ↑\n1-0/0-1 Ratio ↓\nzh-en\nAnnotation\n94.02\n67.83\n22.16\n0.38\nReference\n94.13\n67.06\n21.17\n0.20\nzh-ru\nAnnotation\n80.58\n35.42\n10.09\n12.83\nReference\n91.23\n40.11\n10.69\n1.49\nzh-de\nAnnotation\n80.25\n37.27\n9.09\n13.54\nReference\n92.60\n44.62\n10.69\n1.44\nTable 7: Performance of Plan2Align across two different\nfinal translation tasks.\nD\nEvaluation Sanity Check\nTo verify the validity of our sentence segmentation\nand alignment approach in the context of machine\ntranslation evaluation, we conduct an evaluation us-\ning the test set for WMT24 general machine trans-\nlation translation shared task, as it is a sentence-\naligned dataset. We select Zh-En and En-Zh trans-\nlation data for our sanity check. Specifically, we\nconcatenate sentences with spaces to simulate para-\ngraph structures while ensuring that each paragraph\ndoes not exceed 1024 tokens, resulting in a total of\n1181 paragraphs. In addition, we simulate imper-\nfect alignments with under- and over-translations\nby creating two extra scenarios: (1) randomly drop-\nping 10% of source sentences and (2) randomly\ndropping 10% of target sentences.\nFor simplicity, we do not generate system transla-\ntion and directly evaluate the source-reference pair\nusing KIWI-22. For our evaluation paradigm to be\nvalid, the score distribution should change similarly\nwhen over- and under-translations are introduced.\nWe also track the change in sentence pairs in our\nsanity check, but we expect that to change with\ndropped sentences because one-to-many and many-\nto-one alignments may be generated.\nTable 8 presents the alignment performance un-\nder different conditions. It can be seen that our\nscore distribution reacts similarly to the score calcu-\nlated with the ground-truth alignment when under-\nand over-translation errors are introduced. This\ndemonstrates that our evaluation method effectively\ncaptures semantic alignment and validates the ap-\nplicability of CW-COMET and CW-KIWI in re-\nflecting context-level translation quality.\nScenario\n# Pairs\nMean\nStd.\nPerfectly Aligned\n22956\n78.03\n7.77\nOur Alignment\n22310\n77.07\n9.79\nDrop 10% (Source)\n22956\n73.68\n15.20\nOur Alignment\n21222\n73.81\n14.20\nDrop 10% (Target)\n22956\n75.25\n11.78\nOur Alignment\n21433\n74.97\n11.94\nTable 8: Alignment performance across different con-\nditions. The change in our score maintains high consis-\ntency with the score calculated with perfect alignment.\nE\nMetricX Scoring Failure Cases\nHere are three failure cases for metricX-24, each il-\nlustrated with different models and language pairs:\nRAIN Model, zh-ru Pair.\nThe translation output\nappears nonsensical (see Figure 7), yet metricX-24\nawarded it a score of 8.76, indicating a seemingly\nbetter translation under a metric where lower scores\ndenote superior results.\nARGS Model, zh-de Pair.\nAs shown in Figure 8,\nARGS produced repetitive phrases without com-\npleting the translation from the original zh-de text,\nreaching the max token limit. Despite this, it re-\nceived a score of 8.47 from metricX-24.\nLLaMA3.1 Model, zh-en Pair.\nAs shown in Fig-\nure 9, the translation did not start from the begin-\nning of the text, and the meaning conveyed was\nincomplete. Nevertheless, metricX-24 gave it a\nhigh score of 9.85, which inaccurately suggests a\nless effective translation.\n15\n\n\n[INST]\nConsider the following source text (Source) and its translation (Translation). \nDetermine if the translation is accurate. \nTranslations that deviate from the objective meaning of the source text, introduce \nspeculative content, or alter the intended meaning are considered inaccurate.\n<generated text>\nOptions:\n(A) The translation is accurate.\n(B) The translation is inaccurate.[/INST]\nThe evaluation is: (\n[INST]\nConsider the following source text (Source) and its translation (Translation). \nDetermine if the translation is accurate. \nTranslations that deviate from the objective meaning of the source text, introduce \nspeculative content, or alter the intended meaning are considered inaccurate.\n<generated text>\nOptions:\n(A) The translation is inaccurate.\n(B) The translation is accurate.[/INST]\nThe evaluation is: (\nFigure 3: Prompt templates for RAIN.\n16\n\n\nprocessed_source = [                             \n相反，眼前的這只手臂纖細瘦弱，因為常年沒有照射到太陽的緣故，皮膚有些病態的蒼白。\n                               \n這是現實中自己的身體，他很清楚這一點。                                                                   \n但是，自己怎麽會受了傷的？                                                                             \n而且，這里也不象是醫院啊？                                                                             \n羅德擡頭望去，整個房間看起來好像是個艙室，沒有燈，也沒有電話，更沒有呼叫鈴。\n                                  \n一張木桌，兩把椅子以及一個                                                                             \n(A blonde-haired girl in a white robe walked in, her eyes wide with surprise as she gazed at \nRod, who was half-sitting up. )                                                                   \n固定在墻邊的櫃子就是這里的全部家當。                                                                    \n不知道為什麽，羅德覺得自己似乎在什麽地方見到過這個場景似的。                                                \n(For some reason, Rod felt that he had seen this scene before, as if it were familiar to him. ) \n \n                                                                                                   \n而就在羅德仔細打量這個房間時，門忽然打開了。                                                             \n(Just as Rod was scrutinizing the room, the door suddenly swung open. ) \n…\n]\nsystem_prompts = [\n\"You are a meticulous translator. Provide a literal, word-for-word translation that \npreserves the structure and meaning of each individual word.\",\n\"You are a professional translator. Deliver a clear, formal, and precise translation that \nfaithfully conveys the original meaning.\",\n\"You are a creative and expressive translator. Render the text in a vivid and imaginative \nway, as if narrating a captivating story.\"\n]\ncontext_prompt = \nf\"Below is a specialized, intermediate translation task. The input text is a mix of Chinese and \npartial {language} translations. In the text, some Chinese sentences are already followed by \npreliminary {language} translations enclosed in parentheses. These provided translations are rough \nreferences – they may be incomplete, inconsistent, or not fully aligned with the original \nmeaning. Your task is to produce an improved {language} translation according to the following \nguidelines:\n \n1. **Refinement:** For sections with existing {language} translations (in parentheses), refine and \npolish them so that they are fluent, accurate, and coherent, fully capturing the meaning of the \ncorresponding Chinese text.\n2. **Completion:** For sections that remain untranslated, translate the Chinese text accurately \nand naturally in the specified style.\n3. **Translation Order and Structure Preservation:** Maintain the original order and structure of \nthe text. Every Chinese sentence must appear in the same sequence as in the source text, with its \ncorresponding {language} translation (if available) inserted immediately after it. Do not \nrearrange or reorder any part of the text.\n4. **Consistency:** Ensure a uniform tone and style across the entire translation, adhering to \nthe translator role specified.\n5. **Final Output:** Provide the final output as a single, well-structured {\nlanguage} text. Do not \ninclude any extraneous commentary, explanations, annotations, or headers – output only the \ntranslation in the correct order.\nNote: This translation is an intermediate version that may later be merged with other \ntranslations. Focus on clarity, coherence, and fidelity to the source text.\nHere is the input data for translation:\\n{processed_source}\\n\\n\nApply the above guidelines to produce an improved, coherent translation that strictly follows the \noriginal order of the text.\"\ninput_messages = [\n                {\"role\": \"system\", \"content\": prompt},\n                {\"role\": \"user\", \"content\": context_prompt}\n            ]\nFigure 4: Prompt template used for self-rewriting task in Plan2Align and an actual example.\n17\n\n\nsource_sentence =  [                                                                                  \n相反，眼前的這只手臂纖細瘦弱，因為常年沒有照射到太陽的緣故，皮膚有些病態的蒼白。\n                               \n這是現實中自己的身體，他很清楚這一點。                                                                   \n但是，自己怎麽會受了傷的？                                                                             \n而且，這里也不象是醫院啊？                                                                             \n羅德擡頭望去，整個房間看起來好像是個艙室，沒有燈，也沒有電話，更沒有呼叫鈴。\n                                  \n一張木桌，兩把椅子以及一個固定在墻邊的櫃子就是這里的全部家當。                                              \n不知道為什麽，羅德覺得自己似乎在什麽地方見到過這個場景似的。                                                \n而就在羅德仔細打量這個房間時，門忽然打開了。                                                             \n...\n]\ninitial_translation = [                             \nContrary to this, the arm that was right in front of him was slender and weak, pale-skinned due \nto a lack of sunlight for a long time. \nThis was his own body in the real world, a fact he was well aware of. \nBut how did he end up injured?                                                 \nAnd besides, this doesn't look like a hospital at all! \nRod lifted his head to take in the room, which resembled a cramped compartment.  There were no \nlights, no phones, and no alarm bells. \nThere was only a wooden table, two chairs, and a cabinet fixed to the wall. \nFor some reason, Rod felt that he had seen this scene before, as if it were familiar to him. \nJust as Rod was scrutinizing the room, the door suddenly swung open. \n…\n]\nrewrite_prompt = \nf\"Below is an initial translation of a Chinese text into {language}. This translation may \ninclude omissions, inaccuracies, or awkward phrasing. Your task is to produce a refined \nversion that is fluent, accurate, and coherent, while faithfully preserving the full \nmeaning of the original Chinese text.\\n\\n\"\n### Instructions:\\n\n1. Ensure that every detail in the original Chinese text is accurately represented.\\n\n2. Correct any grammatical errors, unnatural expressions, or inconsistencies.\\n\n3. Improve the natural flow so that the translation reads as if written by a native \nspeaker.\\n\n4. Do not add, omit, or change any essential details from the source text.\\n\n5. Output only the final refined translation without any additional commentary.\\n\\n\n### Original Chinese Text:\\n{source_sentence}\\n\\n\"\n### Initial {language} Translation:\\n{initial_translation}\\n\\n\"\n### Refined Translation:\"\ninput_messages = [\n                {\"role\": \"system\", \"content\" \"You are a helpful translator and only output \nthe result.\"},\n                {\"role\": \"user\", \"content\": rewrite_prompt}\n            ]\nFigure 5: Prompt used for generating final translation in Plan2Align (the Reference version of the prompt in\nSection C.2.1) and an actual example.\nrewrite_prompt = \nf\"The following text is a bilingual translation generated from overlapping sliding windows. \nEach Chinese sentence is followed by its corresponding {language} translation. Your task is \nto refine the {language} portions for improved fluency, clarity, and accuracy. Do not \ninclude the Chinese text in your output, only the refined {language} translation.\\n\\n\"\n### Initial Translation ({language} only):\\n{initial_bilingual}\\n\\n\n### Refined Translation:\"\ninput_messages = [\n                {\"role\": \"system\", \"content\" \"You are a helpful translator and only output \nthe result.\"},\n                {\"role\": \"user\", \"content\": rewrite_prompt}\n            ]\nFigure 6: Applying the concept of the self-rewriting task to generate the final translation prompt (the Annotation\nversion of the prompt in Section C.2.1).\n18\n\n\n而三皇女……她總是一副急色猥瑣的模樣，破壞了原本的美感，這會兒臉上沒有什麽表情，那份美頓時顯現出來了，眼尾輕挑，艷\n色幾乎令人不敢直視。\n少年看得微微呆住，那句誇讚不由自主便說出了口。如果放在其他貴女那里，這算得上逾距了，但對喜歡調戲男子的三皇女來\n說，\n卻是情趣。\n三皇女瞥了他一眼，果然沒訓斥他有失規矩。少年心里一喜，動作更殷勤了一些，小心地挽好皇女的長發。\n只是，直到梳妝快結束，今天一直隱隱期待著的調戲，也並沒有到來。少年咬了咬嘴唇，小心試探道：\n“殿下……可是心情不好？”\n身為男子，還是侍從，為自己的貴女排憂解難，溫柔安撫，是件很正常的事。以往的三皇女，也總是喜歡這樣溫柔小意的伺候。\n但今天顯然不一樣。三皇女沒有露出一絲心情不好的表情，看起來和往常一樣，但偏偏對他冷淡了許多：\n“沒有。”連回答都如此簡單。\n少年咬唇，仔細想了想，小聲安慰道，“殿下勿需擔心，彌心郎君只是心氣高些，他早晚會知道殿下的好的。”\n喻楚挑了挑眉。葉彌心——是丞相府的公子。也是劇情中那個所謂的美少年。\n身份的尊貴養出他絕好的氣度，容貌又俊美，身形修長好看。\n京都不知道多少女人暗暗垂涎他，卻礙於身份，搶不能搶，勾搭吧，人家又心氣高，至今沒人能勾搭到手。\n三皇女也是垂涎大軍中的一員。雖說不敢直接逼丞相的公子嫁她，但她仗著身份，總是沒臉沒皮地實施勾搭大計。結果\n……也可想\n而知。\n< SRC >\n3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3\n.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.\n3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3\n.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.\n3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3\n.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3\n< MT >\nFigure 7: Case 1: Failed evaluation on RAIN, zh-ru, metricX score: 8.76, produced nonsensical output.\n喬修說出了她的名字，這個角色可以說是貫穿了魔獸世界整個故事的女主角，同樣也是《爐石傳說》這個遊戲‘法師’這個職業的\n代表。\n“她和你是什麽關系…”希里稍微沈默了一會，還是沒忍住向喬修問出了這個問題。\n“關系？”喬修在第一時間楞了一下，吉安娜只是遊戲中的一個虛擬人物，喬修和她並沒有任何的關系，但作為一個魔獸玩家，喬\n修覺得這麽回答也不太對。\n“我想應該是曾經一起作戰的同伴。”\n喬修當初玩魔獸世界玩的是聯盟陣營，和吉安娜同處一個陣營，以遊戲玩家這一身份而言，喬修確實算得上是和吉安娜一起作戰過\n的同伴。\n希里沒說話，她看了一眼吉安娜的肖像畫，突然又想起了之前在城堡里面睡覺時，偶爾偷聽到的喬修和澤那斯的對話，她記得喬修\n曾說了一句‘我已經有喜歡的人了’。\n喬修能猜得到希里在想什麽，但喬修沒有刻意的去解釋，只是把視線看向了吉安娜的肖像畫上。\n魔導機械中投影的畫作是希里根據喬修的原稿臨摹的，希里所畫出來的效果再次讓喬修意識到了\n……希里壓根就不適合當一個魔法\n師！\n喬修只是簡單告訴了希里一些上色和構圖的技巧，就讓希里照著他給的原稿在魔導機械上重新繪制。\n最後希里畫出來的結果雖然比起‘專業’還有一定距離，但起碼已經步入了‘還能用’的範疇。\n最重要的一點是希里的作畫沒有受到這個時代的影響，這個時代的繪畫都是以油畫為主，畫作的畫風更加貼近《蒙娜麗莎》的微笑\n那種感覺，還有中-國的水墨畫風格，這種風格的作畫，喬修曾在白荊花爵士的劇院中看見過，聽白荊花爵士\n說，這幅畫的畫家來\n自於一個名為‘大夏’的國家。\n但無論是油畫還是水墨畫都與地球上現代的CG風格不同，但希里的畫作中喬修沒有找到一絲‘覆古’的感覺。\n“你將來真的沒考慮過從事繪畫方面的職業嗎？”\n喬修上下檢視著吉安娜·普羅德摩爾的原畫，一些細小的細節還有不少瑕疵，但這些經過喬修的修改還是能\n夠接受。\n如果希里按照這個進度繼續練習下去，希里一定能成為一位優秀的遊戲原畫師。\n“我…不知道。”\n< SRC >\nJochead nannte ihren Namen, eine Figur, die wie ein Faden durch das gesamte \"Welt von \nWarcraft\"-Epos zieht und auch die Hauptdarstellerin des Spiels \"Hearthstone\" ist. Ebenso ist \nsie die Vertreterin des Berufs \"Magier\".\"Hast du mit ihr irgendeine Beziehung...?\" Hilara \nschwieg für einen Moment, aber sie konnte sich nicht zurückhalten und die Frage nach Jocheads \nAntwort.\"Beziehung?\" Jochead schwieg zunächst überrascht. Jaina war nur ein fiktiver Charakter \nim Spiel, und Jochead hatte mit ihr keine Beziehung. Als \"Welt von \nWarcraft\"-Spielzeugspielespieler fühlte Jochead jedoch, dass solch eine Antwort nicht ganz \nangemessen war.\"Ich denke, es ist wahrscheinlich, dass wir ehemalige Verbündete waren.\"In der \nVergangenheit spielte Jochead \"Welt von Warcraft\"-Spielzeugspielespiele für die \nAllianz-Allianz-Allianz-Allianz-Allianz-Allianz-Allianz-Allianz-Allianz-Allianz-Allianz-Allianz\n-Allianz-Allianz-Allianz-Allianz-Allianz-Allianz-Allianz-Allianz-Allianz-Allianz-Allianz-Allian\nz-Allianz-Allianz-Allianz-Allianz-Allianz-Allianz-Allianz-Allianz-Allianz-Allianz-Allianz-Allia\nnz-Allianz-Allianz-Allianz-Allianz-Allianz-Allianz-Allianz-Allianz-Allianz-Allianz-Allianz-Alli\nanz-Allianz-Allianz-Allianz-Allianz-Allianz-Allianz-Allianz-Allianz-Allianz-Allianz-Allianz-All\nianz-Allianz-Allianz-Allianz-Allianz-Allianz-Allianz-Allianz-Allianz-Allianz-Allianz-Allianz-..\n.\n< MT >\nFigure 8: Case 2: Failed evaluation on ARGS, zh-de, metricX-qe: 8.47, produced incomplete translation and\nrepeated words and sentences\n19\n\n\n今天沒被要求伺候，少了討好皇女的機會，但從情感上來說，他就算身份低微，也未嘗沒幻想過一個貌美有才的妻主，而不是一個\n猥瑣的草包。內心應該慶幸才對……\n少年低聲應是，隨即退了出去。但不知為什麽，退到外間停下之後，他又鬼使神差地看了眼屏風。\n那後面映出一個曼妙的女子身影，隨意慵懶的穿衣動作，竟讓人有些……面紅心跳。\n少年忽然想，其實三皇女也不錯，雖然人很猥瑣，還是個草包，但確實長得漂亮，而且身份高貴啊\n……\n以後，還是盡力取悅她吧。他默默下了決心，臉色又紅了一些，低下頭，恭敬地垂首站立。\n第181章 女尊第一花魁（2）\n喻楚絲毫不知道外間小侍從的心思，只是翻著原主的記憶，哭笑不得地想，原主雖然放蕩，但還好\n……第一次還在呢。\n她把原主的記憶梳理了一遍。在這個女尊男卑的世界，原主的身份也很尊貴，是王朝的三皇女。就是人品差了點，沒用了點，急色\n了點，其他還是挺好的……嘛。\n二皇女早夭，女皇陛下只有大皇女和三皇女兩個女兒，對大皇女管教比較嚴格，對小女兒就是真的溺愛了。這也是三皇女最大的靠\n山。要不是女皇寵原主，就憑大皇女的手段，原主早不知道死多少次了。\n而原主的心願，也和大皇女有關。\n原主是放蕩不羈的性格，愛好各種美人，從沒想過爭奪王位，只想等大姐繼位之後，當個閒散的親王。大皇女卻不放過她。\n這位好姐姐知道妹妹愛美男，特意派了個美少年引誘她，三皇女被對方的氣質與美貌迷得神魂顛倒，最後被哄得一杯毒酒下肚，才\n得知真相。\n美少年是她姐姐的人，並不喜歡她，不過是逢場作戲，虛與委蛇而已。她敬重的姐姐，更是要她的命。所以她不甘心。\n她的心願就是報覆這對男女。她要讓為了繼位殺害自己的大姐，這輩子都得不到皇位，讓那個欺騙自己感情的少年，這輩子都得不\n到愛情。\n喻楚想，這可咋整。皇位還算簡單，但愛情？她怎麽確保那人得不到愛情？劇情都不\n說了嗎，人家和大皇女兩情相悅啊！\n< SRC >\nShe flipped through the memories of the original owner, crying and laughing in dismay. \"I'm \nglad he's still in his first affair. He's definitely much better off than he was in his past \nlife.\"\nShe organised the memories of the original owner, recalling his life in a world of female \ndominance and male servitude. The original owner had been the king's third princess, second in \nline to the throne. While she had been spoiled by her mother, the empress, her older sister, \nthe second princess, had been given strict treatment.\nIn her memories, the third princess was just as flawed as her sister, lacking any kind of sense \nof loyalty or duty, prone to whims and impulsiveness.\n< MT >\nFigure 9: Case 3: Failed evaluation on LLaMA3.1-8B, zh-en, metricX-qe: 9.85, did not start the translation from\nthe beginning and the meaning is incomplete.\n20\n\n\n",
  "metadata": {
    "source_file": "dataset/pdfs/arxiv_2502.20795v1.pdf",
    "total_pages": 20,
    "title": "Plan2Align: Predictive Planning Based Test-Time Preference Alignment in Paragraph-Level Machine Translation",
    "authors": [
      "Kuang-Da Wang",
      "Teng-Ruei Chen",
      "Yu Heng Hung",
      "Shuoyang Ding",
      "Yueh-Hua Wu",
      "Yu-Chiang Frank Wang",
      "Chao-Han Huck Yang",
      "Wen-Chih Peng",
      "Ping-Chun Hsieh"
    ],
    "abstract": "Machine Translation (MT) has been predominantly designed for sentence-level\ntranslation using transformer-based architectures. While next-token prediction\nbased Large Language Models (LLMs) demonstrate strong capabilities in long-text\ntranslation, non-extensive language models often suffer from omissions and\nsemantic inconsistencies when processing paragraphs. Existing preference\nalignment methods improve sentence-level translation but fail to ensure\ncoherence over extended contexts due to the myopic nature of next-token\ngeneration. We introduce Plan2Align, a test-time alignment framework that\ntreats translation as a predictive planning problem, adapting Model Predictive\nControl to iteratively refine translation outputs. Experiments on WMT24\nDiscourse-Level Literary Translation show that Plan2Align significantly\nimproves paragraph-level translation, achieving performance surpassing or on\npar with the existing training-time and test-time alignment methods on\nLLaMA-3.1 8B.",
    "published_date": "2025-02-28",
    "source": "arxiv"
  }
}