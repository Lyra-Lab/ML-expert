{
  "id": "arxiv_2502.20703v1",
  "text": "1\nA Quantum-Empowered SPEI Drought Forecasting\nAlgorithm Using Spatially-Aware Mamba Network\nPo-Wei Tang, Student Member, IEEE, Chia-Hsiang Lin, Senior Member, IEEE,\nJian-Kai Huang, Student Member, IEEE, and Alfredo R. Huete\nAbstract—Due to the intensifying impacts of extreme cli-\nmate changes, drought forecasting (DF), which aims to predict\ndroughts from historical meteorological data, has become in-\ncreasingly critical for monitoring and managing water resources.\nThough drought conditions often exhibit spatial climatic coher-\nence among neighboring regions, benchmark deep learning-based\nDF methods overlook this fact and predict the conditions on\na region-by-region basis. Using the Standardized Precipitation\nEvapotranspiration Index (SPEI), we designed and trained a\nnovel and transformative spatially-aware DF neural network,\nwhich effectively captures local interactions among neighboring\nregions, resulting in enhanced spatial coherence and prediction\naccuracy. As DF also requires sophisticated temporal analysis,\nthe Mamba network, recognized as the most accurate and\nefficient existing time-sequence modeling, was adopted to extract\ntemporal features from short-term time frames. We also adopted\nquantum neural networks (QNN) to entangle the spatial features\nof different time instances, leading to refined spatiotemporal\nfeatures of seven different meteorological variables for effectively\nidentifying short-term climate fluctuations. In the last stage\nof our proposed SPEI-driven quantum spatially-aware Mamba\nnetwork (SQUARE-Mamba), the extracted spatiotemporal fea-\ntures of seven different meteorological variables were fused to\nachieve more accurate DF. Validation experiments across El\nNi˜no, La Ni˜na, and normal years demonstrated the superiority\nof the proposed SQUARE-Mamba, remarkably achieving an\naverage improvement of more than 9.8% in the coefficient\nof determination index (R2) compared to baseline methods,\nthereby illustrating the promising roles of the temporal quantum\nentanglement and Mamba temporal analysis to achieve more\naccurate DF.\nIndex Terms—Drought Forecasting, Quantum Computing,\nMamba Deep Learning, Climatic Research Unit (CRU) Data,\nStandardized Precipitation Evapotranspiration Index (SPEI),\nSustainable Development Goals (SDGs).\nThis study was supported in part by the Emerging Young Scholar Program\n(namely, the 2030 Cross-Generation Young Scholars Program) of National\nScience and Technology Council (NSTC), Taiwan, under Grant NSTC 113-\n2628-E-006-003; and in part by the Ph.D. Students Study Abroad Program\nof NSTC under Grant NSTC 113-2917-I-006-011. We thank the National\nCenter for Theoretical Sciences (NCTS) and the National Center for High-\nperformance Computing (NCHC) for providing the computing resources.\n(Corresponding author: Chia-Hsiang Lin.)\nPo-Wei Tang is with the Institute of Computer and Communication Engi-\nneering, Department of Electrical Engineering, National Cheng Kung Univer-\nsity, Tainan 70101, Taiwan (R.O.C.) (e-mail: q38091526@gs.ncku.edu.tw).\nChia-Hsiang Lin. Lin is with the Department of Electrical Engineering, and\nwith the Miin Wu School of Computing, National Cheng Kung University,\nTainan 70101, Taiwan (R.O.C.) (e-mail: chiahsiang.steven.lin@gmail.com).\nJian-Kai Huang is with the Institute of Computer and Communication En-\ngineering, Department of Electrical Engineering, National Cheng Kung Uni-\nversity, Tainan 70101, Taiwan (R.O.C.) (e-mail: q36121147@gs.ncku.edu.tw).\nAlfredo\nR.\nHuete\nis\nwith\nthe\nSchool\nof\nLife\nSciences,\nUniver-\nsity of Technology Sydney, Sydney, NSW 2007, Australia (e-mail: Al-\nfredo.Huete@uts.edu.au).\nI. INTRODUCTION\nExtreme climate changes have altered precipitation patterns,\nleading to more frequent and severe drought occurrences.\nConsequently, many regions worldwide have experienced sig-\nnificant agricultural losses and water supply challenges [1],\n[2]. Nevertheless, these widespread impacts cannot be at-\ntributed solely to climatic changes. Human activities, including\nurbanization, deforestation, and agricultural expansion, also\nplay a critical role in modifying hydrological processes and\nland surfaces, thereby influencing the frequency and severity\nof droughts in human-altered regions such as America, Brazil,\nChina, Spain, and Australia [3]. Recent literature indicates\nthat urban areas are expected to accommodate an additional 2\nbillion people by 2030, significantly increasing pressure on\nglobal water resources [4], [5]. Moreover, more than 27%\nof the world’s largest cities are projected to face severe\nwater shortages, potentially exhausting their available water\nsupplies by 2050 [6]. Beyond water scarcity, drought presents\ncritical challenges for agriculture, industry, public health, and\necosystems [7]–[10].\nGiven these widespread impacts, accurate drought fore-\ncasting (DF) has become an urgent task, aligning with the\nobjectives of the United Nations Sustainable Development\nGoals (SDGs) 6, 11, 12, 13, and 15 [11]. In light of this\nurgency, it is essential to understand the different types of\ndroughts, as each has distinct causes and impacts. Specif-\nically, droughts can be categorized into four main types:\nmeteorological drought, caused by a prolonged scarcity of\nprecipitation; agricultural drought, resulting from insufficient\nsoil moisture, which adversely affects crop yields; hydrological\ndrought, characterized by a significant reduction in streamflow\nand groundwater levels; and socioeconomic drought, which\noccurs when water scarcity leads to severe economic and\nsocial impacts [12]. To better understand drought conditions\nand mitigate their adverse effects, researchers have developed\nvarious drought indices to assess drought severity.\nFor example, McKee et al. [13] proposed the Standardized\nPrecipitation Index (SPI) to assess wet and dry conditions\nbased on precipitation data. The SPI measures the deviation\nof observed precipitation from the long-term historical mean\nover different time scales, such as 1, 3, 6, or 12 months. First,\nprecipitation data is fitted to a gamma distribution to model\nthe precipitation probability distribution, after which the cu-\nmulative probability of the precipitation values is determined.\narXiv:2502.20703v1  [eess.SP]  28 Feb 2025\n\n\n2\nThen, the cumulative probability is transformed into a standard\nnormal distribution (with a mean of zero and a standard\ndeviation of one) using an inverse standard normal function.\nFinally, the resulting value represents the SPI for the specific\nprecipitation data point. Positive SPI values indicate wetter-\nthan-average conditions, while negative values reflect drier-\nthan-average conditions. Larger absolute values correspond to\nmore severe deviations from the long-term historical mean.\nBy\nincorporating\npotential\nevapotranspiration\n(PET),\nVicente-Serrano et al. [14], [15] proposed an enhanced\nversion of the SPI, known as the Standardized Precipitation\nEvapotranspiration Index (SPEI). Unlike the SPI, the SPEI\naccounts\nfor\nthe\ninfluence\nof\ntemperature\non\ndrought\nconditions, providing a more comprehensive assessment.\nIn\naddition\nto\ndeveloping\ndrought\nindices\nbased\non\nmeteorological data, Huete [16] proposed the Soil-Adjusted\nVegetation Index (SAVI), an optical greenness measure of\nvegetation health, derived from remote sensing data, which\nis designed to minimize the influence of soil brightness\non vegetation reflectance measurements. SAVI serves as an\nindirect indicator of drought impacts on vegetation, as drought\nconditions typically induce vegetation stress, affecting NIR\nand red reflectance. Given vegetation’s high sensitivity to\ndrought, SAVI provides valuable insights into ecosystem\nresponses under drought conditions.\nConsidering temperature variability, the SPEI is a practical\napproach for evaluating drought conditions. Hence, multiple\nDF deep learning models based on SPEI have been developed,\nincluding the long short-term memory network (LSTM) [17],\nthe transformer-based time series prediction model (Informer)\n[18], and the autoregressive integrated moving average model\n(ARIMA) [19]. For example, Dikshit et al. [20] proposed\nan improved SPEI-based DF approach using the LSTM neu-\nral network (NN). The LSTM model predicts SPEI values\nbased on hydrometeorological variables, including precipi-\ntation, maximum temperature, minimum temperature, mean\ntemperature, vapor pressure, cloud cover, and potential evap-\notranspiration. LSTM is an advanced variant of the recurrent\nNN (RNN) [21], which is designed to capture both long-term\nand short-term memory. It addresses the issues of gradient\nexploding/vanishing by using the customized forget gate, input\ngate, and output gate. Similar to LSTM, a variant of RNN\nusing the gated recurrent unit (GRU) [22] is proposed for\npredicting time series data. In GRU, three gates in LSTM are\nreplaced by two gates: the reset gate and the update gate.\nSpecifically, the reset gate controls how much of the previous\nstate should be forgotten, while the update gate regulates\nthe retention of information from the previous hidden state,\nhelping the RNN capture long-term information [23].\nBased on the recently developed transformer model, Shang\net al. [24] proposed the SPEI-based DF method using the In-\nformer framework. The Informer maintains the advantages of\nthe transformer structure, which is adept at capturing long-term\ndependencies and demonstrates strong potential for forecasting\ntime-series data. To reduce computational complexity and\nmemory usage compared to the original transformer model,\nInformer utilizes the ProbSparse self-attention mechanism [25]\nand an attention-distilling strategy. From another perspective,\nHasan et al. [26] proposed another SPEI-based DF model\nbased on the ARIMA. It consists of three main components,\nincluding the autoregressive (AR) part, the integrated (I) part,\nand the moving average (MA) part. The AR part makes\npredictions based on previous p-lag observations. The I part\ntransforms the data into a stationary series through d-order\ndifferencing operations. The MA part adjusts the forecasting\nresults based on the past q-lag forecasting errors [27].\nBeyond traditional forecasting methods, quantum technol-\nogy has created new opportunities for algorithm development.\nAs quantum technology advances rapidly, it has become a\ncutting-edge scientific research area. In 2022, the Nobel Prize\nin Physics was awarded to scientists who made significant\ncontributions to quantum entanglement studies, highlighting\nthe growing recognition of quantum information science. As a\nresult, quantum technology has recently been applied to remote\nsensing areas, particularly in addressing challenging inverse\nproblems such as hyperspectral satellite data restoration [28],\nmangrove mapping [29], change detection [30], multispectral\nunmixing [31], and well-log interpretation [32]. In these tasks,\nthe quantum neural network (QNN) has proven its value and\napplicability, demonstrating the potential of quantum technol-\nogy in handling complicated problems. Beyond solving inverse\nproblems in remote sensing areas, QNN has also achieved\nremarkable success in forecasting tasks, including solar irra-\ndiance forecasting [33], financial prediction [34], and weather\nforecasting [35]. Inspired by these advancements, this study\naims to design a hybrid quantum-classical forecasting network\nto address the DF problem. Specifically, we integrate QNN\nand convolutional NN (CNN) models to enhance prediction\naccuracy in the final decision-making process.\nTo further enhance the efficiency of the classical component\nwithin our hybrid quantum-classical framework, we integrate\nthe Mamba network [36], a newly developed time-series\nmodel recognized for its state-of-the-art performance across\nvarious applications, including time-series forecasting [37],\nnatural language processing [38], and image analysis [39].\nUnlike traditional transformer-based models [40], which rely\nheavily on self-attention mechanisms [41], [42] with quadratic\ncomputational complexity, the Mamba network introduces an\ninnovative approach by employing a linear time complexity\narchitecture, significantly reducing computation when process-\ning long sequences. One key feature of Mamba is its ability\nto dynamically adjust state space model (SSM) parameters\nbased on the input data, enabling the model to retain or discard\ninformation throughout the selective mechanism (cf. Section\nII). This adaptive mechanism effectively addresses challenges\ncommonly encountered with discrete modalities, improving\nlearning efficiency. Furthermore, its efficiency does not come\nat the cost of performance. Mamba has demonstrated superior\nresults in language modeling, outperforming transformers of\nthe same size and matching the performance of models twice\nas large in pretraining and downstream evaluations. As a result,\nMamba achieves nearly an order-of-magnitude improvement\nin inference speed compared to transformer-based models,\nmaking it particularly well-suited for forecasting tasks such\nas the DF problem.\nGiven Mamba’s remarkable efficiency in processing long\n\n\n3\nFig. 1: Graphical illustration of the proposed SPEI-driven quantum spatially-aware Mamba network (SQUARE-Mamba). It first\nincorporates neighboring spatial information through the spatial encoding block (SEB), which accepts the spatially augmented\ntensor T (z) as its input. Next, the temporal encoding block (TEB) models temporal dependencies via a parallel CNN/QNN\nstructure, in order to simultaneously incorporate the powerful Mamba temporal modeling and the quantum temporal entangling\nmechanisms. Finally, the feature fusion block (FFB) integrates the extracted spatiotemporal features to forecast the drought\nprediction results.\nsequences, it enhances our framework’s temporal modeling\ncapabilities, which are essential for complicated forecasting\ntasks such as the DF problem. This capability has become\nincreasingly important due to the growing impact of ex-\ntreme climate changes. Thus, we propose an SPEI-driven\nquantum spatially-aware Mamba network (SQUARE-Mamba)\nto effectively solve the challenging DF problem. The main\ncontributions of this work are summarized as follows:\n• To effectively capture the spatial continuity of meteoro-\nlogical data across adjacent regions, we have developed\na spatial encoding block (SEB) to extract relevant spatial\ninformation from neighboring areas for each forecasting\nlocation. SEB enables SQUARE-Mamba to distill critical\nspatial features, resulting in better spatial coherence and\npromising drought prediction accuracy.\n• In SQUARE-Mamba, a hierarchical structure is leveraged\nwith a temporal encoding block (TEB) and a feature\nfusion block (FFB). Within the TEB, SQUARE-Mamba\nelegantly integrates the novel QNN and Mamba models\nto enhance its temporal modeling capabilities. Specifi-\ncally, the input sequence for the TEB is partitioned into\nlocal groups, enabling the model to capture short-term\ndependencies and temporal variations across neighboring\nmonths. This design improves the model robustness to\nshort-term extreme climate fluctuations. Empowered by\nthe temporal quantum entanglement across different time\ninstances for better capturing the short-term temporal\ndependencies, FFB aggregates the SEB/TEB-extracted\nglobal spatiotemporal features to generate the final fore-\ncasting results.\n• Our proposed novel SQUARE-Mamba leverages deep\nlearning and quantum computing to achieve state-of-the-\nart DF performance, having a remarkable improvement of\nup to about 9.8% in the R2 index. To ensure the effective-\nness of SQUARE-Mamba, we evaluate its performance\nacross diverse spatiotemporal scenarios. From a spatial\nperspective, we test six datasets across three distinct\nclimate regions (i.e., wet, dry, and moderate areas) to as-\nsess SQUARE-Mamba’s generalization ability to different\nenvironmental conditions. From a temporal perspective,\nwe analyze SQUARE-Mamba’s performance under El\nNi˜no, La Ni˜na, and normal years to evaluate its stability\nacross varying climate patterns. Extensive experiments\ndemonstrate that SQUARE-Mamba consistently outper-\nforms existing benchmark DF methods across diverse\nenvironmental regions and climate phases. By integrating\nSEB and TEB, SQUARE-Mamba offers a practical and\nreliable solution to the challenging DF problem.\nThe remainder of this paper is organized as follows. In\nSection II, we provide a detailed description of the proposed\nSQUARE-Mamba model. Section III presents and discusses\nextensive experimental results conducted across El Ni˜no, La\nNi˜na, and normal years over a long time period. Besides,\nwe perform ablation studies to demonstrate the importance of\nincorporating spatial information, and to evaluate the effective-\nness of multi-scale temporal features of quantum-empowered\nMamba. Finally, Section IV summarizes the conclusions and\nkey insights of this study.\nII. THE PROPOSED SQUARE-MAMBA METHOD FOR\nDROUGHT FORECASTING\nTo address the limitations of existing benchmark DF mod-\nels, which tend to overlook the spatial coherence of climatic\npatterns, we propose a radically new SPEI-driven quantum\nspatially-aware Mamba neural network (i.e., SQUARE-Mamba\nnetwork). As shown in Figure 1, SQUARE-Mamba comprises\nthree key modules, including the spatial encoding block (SEB),\ntemporal encoding block (TEB), and feature fusion block\n(FFB), each having customized functions for DF.\nThe three key blocks are briefly illustrated hereinafter,\nand later they will be reported in detail in the following\nsubsections. First, the SEB utilizes the spatial coherence of\nlocal climatic continuity by integrating meteorological infor-\nmation of neighboring regions when forecasting the drought\ncondition of a target region, thereby improving the prediction\naccuracy. Second, the TEB extracts temporal dependencies\n\n\n4\nFig. 2: Detailed architecture of the proposed spatial encoding block (SEB), which is designed to extract spatial features by\nemploying the climatic continuity in the 8 adjacent areas as specified by T (z). The 105 channels correspond to 7 different\nmeteorological variables (i.e., precipitation, maximum/minimum/mean temperatures, vapor pressure, cloud cover, and potential\nevapotranspiration) over continuous 15 months.\nAlgorithm 1 The proposed SQUARE-Mamba algorithm\n1: Given the time-series data Z ∈R15×7 over 15 months\nwith 7 critical meteorological statistics.\n2: Vectorize Z to z ∈R105 for ease of the subsequent spatial\naugmentation.\n3: Obtain the spatially augmented tensor T (z) ∈R105×3×3\nfrom the neighboring 3 × 3 regions.\n4: Compute the spatially encoded feature s ∈R105 using the\nspatial encoding block SEB(·) based on (2).\n5: Reshape s back to S ∈R15×7.\n6: Compute the temporally encoded features F ∈R15×7\nusing the temporal encoding block TEB(·) based on (3).\n7: Obtain the drought condition d ∈R using the feature\nfusion block FFB(·) based on (8).\n8: Standardize the d value to [−3, 3] using the scaled Tanh\nfunction s-Tanh(·).\n9: Output the predicted drought condition d ∈[−3, 3].\nusing a dual CNN-QNN framework, leveraging the state-of-\nthe-art Mamba time sequence modeling while incorporating\nquantum temporal entanglement mechanisms to enhance tem-\nporal feature learning. Specifically, TEB integrates the quan-\ntum deep network (QUEEN) [28] to capture the short-term\nclimatic variations/dependencies, while the Mamba network\nefficiently learns long-range temporal patterns. Unlike the\ntraditional CNN that extract affine-computing features, our\nQUEEN adopts unitary-computing quantum neurons to extract\nfundamentally distinct features [29], [30]; this strategy has\nbeen proven effective for diverse remote sensing applications.\nBy parallelly integrating classical and quantum architectures,\nTEB enhances the model’s expressiveness in learning intricate\nspatiotemporal features, leading to more robust DF. Third, the\nextracted spatiotemporal features from different meteorologi-\ncal variables are then fused by the customized FFB, thereby\ngenerating the final DF results.\nMathematically, according to the above illustration, the\noverall architecture of the SQUARE-Mamba network is de-\nfined as follows:\nd = s-Tanh(FFB(TEB(SEB(z, T (z))))),\n(1)\nwhere d ∈[−3, 3] represents the forecasting result indicat-\ning the predicted drought conditions; s-Tanh(·) denotes the\nscaled hyperbolic tangent function [43] returning a value\nwithin the interval [−3, 3]; FFB(·) denotes the feature fusion\nblock function; TEB(·) denotes the temporal encoding block\nfunction; SEB(·) denotes the spatial encoding block function;\nz ∈R105 is the input time series data (at a target region)\nacross 15 months, each having 7 meteorological variables (i.e.,\nprecipitation, maximum/minimum/mean temperatures, vapor\npressure, cloud cover, and potential evapotranspiration); the\ntensor T (z) ∈R105×3×3 is the spatially augmented version\nof the data z ∈R105 (at the target region) by including the\ndata from its 8 neighboring regions (cf. Figure 2). Following\na similar setting [20], we assume that the drought condition\nd of a given month can be predicted from the historical\nmeteorological data over the past 15 months.\nBased on the elegant and concise quantum/classical deep\nmodel (1), we then construct the effective DF algorithm, i.e.,\nAlgorithm 1, which summarizes the above discussion and\ndesign philosophy for better understanding. Our experiments\nwill show that the spatial augmentation strategy T (z) and the\nQUEEN-based temporal analysis both play essential roles in\nyielding accurate forecasting results. The proposed SEB, TEB,\nand FFB deployed in SQUARE-Mamba (i.e., Algorithm 1) will\nbe detailed in Sections II-A, II-B, and II-C, respectively.\nA. Spatial Encoding Block\nOwing to the strong spatial correlations in meteorological\ndata, neighboring areas tend to exhibit similar climate charac-\nteristics, as can be observed from Figure 5. However, existing\nbenchmark forecasting models frequently treat each location\nindependently, thereby neglecting crucial spatial dependencies\nand limiting their prediction performance. To address this lim-\nitation, we introduce the spatial encoding block (SEB) to em-\nbed climatic spatial dependencies into the forecasting process\nwithin the proposed SQUARE-Mamba model. By modeling\nspatial dependencies, our approach enables the model to more\n\n\n5\nFig. 3: Detailed architecture of the proposed temporal encoding block (TEB), which adopts a parallelized classical/quantum\ndeep structure for temporal feature extraction. Simply speaking, TEB learns temporal dependencies of the spatially encoded\nfeatures, thereby yielding the exquisite “spatiotemporal” features. To establish global temporal relations, we first partition the\nsequence into five local groups to extract short-term variations through the local time encoding module (LTEM) and Quantum\nLTEM (QLTEM), where the Mamba temporal modeling (used in LTEM) and the temporal quantum entanglement (used in\nQLTEM) greatly contribute to the learning of temporal dependencies. These locally correlated features are then combined as\ncomplete temporal representations, allowing the model to learn both short-term fluctuations and long-term trends effectively.\neffectively capture regional correlations, thereby enhancing\nprediction reliability and accuracy. Specifically, we transform\nthe target input vector, which spans 15 months and includes\nthe 7 meteorological variables defined above (i.e., z ∈R105)\ninto the 3-D augmented tensor T (z) ∈R105×w×w using the\noperator “T : R105 →R105×w×w”. The resulting 3-D tensor\nT (z) is constructed from the continuous w × w pixel region\nsurrounding the target input vector z, where the window size\nw is set to 3 in this work, and z is positioned at the window\ncenter. To address potential missing values in T (z), one can\nsimply apply the k-nearest neighbor (KNN) imputation with\nk := 1 [44], [45] during the augmentation procedure.\nAs shown in Figure 2, the overall procedure of the SEB,\ndenoted as SEB(·), is defined as follows:\nSEB(z, T (z)) = z + Maxpooling(σ(fD(T (z)))),\n(2)\nwhere Maxpooling(·) represents the max-pooling operator;\nσ(·) denotes the LeakyReLU activation function with a neg-\native slope of 0.2 [46]; and fD(·) is a 2 × 2 depthwise\nconvolutional layer. The core idea of (2) is to extract spatial\ninformation from four distinct directions (i.e., corners) using\ndepthwise convolution. Notably, the depthwise convolutional\nlayer aggregates spatial dependencies while preserving essen-\ntial temporal information within each channel. Subsequently,\nthe most representative spatial feature is selected via the max-\npooling operator, ensuring that the most salient information\nis retained. Finally, a shortcut connection mechanism is in-\ntroduced to integrate the extracted adjacent spatial features\nwith the target pixel z, thereby obtaining the spatially encoded\nfeature s ∈R105. By following (2), SEB, which can be easily\nimplemented, encodes spatial dependencies effectively while\nmaintaining high computational efficiency.\nB. Temporal Encoding Block\nAs extreme climate events get more frequently occurred,\nshort-term temperature and precipitation fluctuations have\nbeen intensified [47]. Therefore, accurately capturing these\nfluctuations is crucial for improving the predictive perfor-\nmance of DF. To address this challenge, we customize a\ntemporal encoding block (TEB) designed to capture short-term\nfluctuations while effectively preserving long-term trends. As\nshown in Figure 3, TEB models temporal dependencies across\nfive local time groups, thereby enhancing the model’s ability\nto detect rapid climate variations.\nSpecifically, the proposed TEB function, denoted as TEB(·),\nis defined as follows:\nTEBi(·) = LTEMi(·) + QLTEMi(·), i ∈{1, . . . , 5},\n(3)\nwhere i denotes the ith local time group in TEB(·); TEBi(·)\ndenotes the ith local temporal encoding block function;\nLTEMi(·) represents the ith local time encoding module\nfunction; QLTEMi(·) represents the ith quantum local time en-\ncoding module function. Notably, five local groups in (3) have\nnon-shared weights, allowing them to capture distinct features\nfrom different temporal patterns. To preserve long-term trends,\nall locally encoded temporal features are concatenated into a\ncomprehensive long-term representation for feature fusion.\nWithin our model design, the local time encoding module\n(LTEM) serves as the core component of TEB, enabling the\nprecise modeling of short-term temporal dependencies. By\nleveraging Mamba [36], a state-of-the-art sequence modeling\n\n\n6\nmethod, our LTEM effectively captures temporal relationships\nthrough its strong time-series modeling capabilities. Unlike\nthe traditional Transformer model [40], which relies on self-\nattention with quadratic complexity, Mamba adopts a dis-\ncrete selective state-space model (SSSM) with only linear\ncomplexity, significantly improving computational efficiency,\nespecially for long-sequence modeling.\nMathematically, the discrete SSSM function [48] (i.e., y =\nSSSM(x)) can be defined as follows:\nhi = Aihi−1 + Bixi,\n(4)\nyi = Cihi + Dxi,\n(5)\nwhere x and y ∈RL×1 represent the input and output\nsequence vectors, respectively; hi ∈RN×1 is the ith hidden\nstate; xi and yi ∈R denote ith elements of x and y,\nrespectively; Ai ∈RN×N, Bi ∈RN×1, Ci ∈R1×N, and\nD ∈R are learnable weights that regulate the input xi and\nthe hidden state hi in (4) and (5). If the input sequence has a\nlength of L with K channels (i.e., [x1, ..., xK]), SSSM(·) is\napplied independently to each channel [36]. Therefore, (4) and\n(5) enable LTEM to model temporal dependencies effectively,\nand this is the so-called Mamba time-series modeling [36].\nThis design facilitates the climate prediction tasks involving\nlarge-scale temporal data (e.g., drought forecasting).\nTo be mathematically rigorous, building upon the efficiency\nof LTEM, we now define its architectural details as follows:\nSSSSM = SSSM(τ(f1(LP1(S)))) ⊙τ(LP2(S)),\n(6)\nLTEM(S) = σ(f2(BN(LP3(SSSSM)))),\n(7)\nwhere SSSSM is the gated feature modulated by τ(LP2(S));\nτ(·) denotes the sigmoid linear unit (SiLU) activation function\n[49]; fi(·) denotes the ith 3 × 1 1-D convolutional layer\nalong the temporal dimension; LPi(·) represents the ith linear\nprojection operator; S ∈R15×7 is the reshaped matrix of the\nspatially encoded feature vector s ∈R105 returned by SEB(·);\nσ(·) corresponds to the exponential linear unit (ELU) activa-\ntion function [50]; BN(·) represents the batch normalization\nlayer. Overall, LTEM (cf. (6) and (7)) leverages the SSSM\nto enhance temporal feature extraction, ensuring efficient and\nexpressive sequence modeling.\nOn the other hand, as alluded above, capturing/learning the\nshort-term climatic fluctuations is critical. So, we further incor-\nporate the temporal entanglement among the quantum features\nextracted from a short time period (say, three months). This\nfurther enhances the temporal encoding capability, as we plug\nthe Quantum LTEM (QLTEM) into the TEB by using quantum\ndeep network (QUEEN) [28] to learn temporal features. Unlike\nclassical CNN features, QUEEN is proven to be able to pro-\nvide more abstract features (a.k.a., unitary features; cf. Table\nI), as having been successfully demonstrated on numerous\nremote sensing missions in very recent literature, including\nmangrove forest classification [29], hyperspectral change de-\ntection [30], NASA optical data restoration [51], [52], and\nunderdetermined blind source separation [31]. Specifically,\nQNN leverages unitary computing and quantum entanglement\nmechanisms [28] to enhance model’s representation capacity.\nTABLE I: Symbols and mathematical definitions for the quan-\ntum gates (all corresponding to unitary operators, according\nto the Schr¨odinger equation [28]) used in the QLTEM defined\nby Figure 3. With θ representing the learnable parameters,\nwe use δ and γ to denote cos( θ\n2) and sin( θ\n2), respectively,\nfor conciseness. Additionally, DIAG(A, B, C) represents a\nblock-diagonal matrix with diagonal blocks A, B and C, and\nIn denotes the n × n identity matrix.\nQuantum Gate\nSymbol\nUnitary Operator\nRotation X\nRX(θ)\n \nδ\n−iγ\n−iγ\nδ\n!\nRotation Y\nRY (θ)\n \nδ\n−γ\nγ\nδ\n!\nIsing XX\nXX(θ)\n\n\n\n\n\nδ\n0\n0\n−iγ\n0\nδ\n−iγ\n0\n0\n−iγ\nδ\n0\n−iγ\n0\n0\nδ\n\n\n\n\n\nPauli-Z\n \n1\n0\n0\n−1\n!\nNOT\nX\n \n0\n1\n1\n0\n!\nToffoli (CCNOT)\nDIAG(I4, X, I2)\nThis motivates us to adopt QNN to extract entangled tempo-\nral features within the dual-branch network architecture (cf.\nFigure 3), aiming to upgrade the DF performance.\nSimply speaking, QUEEN is to replace the neurons in the\ntraditional deep network (e.g., CNN) by so-called quantum\nneurons. Before presenting the design principles and imple-\nmentation details, we first introduce the notations and mathe-\nmatical definitions of the quantum neurons used in QLTEM,\nas summarized in Table I. Note that quantum neurons are\nimplemented through some Hamiltonian over a specific time\ninterval, ensuring that their corresponding operators remain\nunitary, as dictated by the Schr¨odinger equation [53]. By\nleveraging these quantum operations, QNNs have demon-\nstrated their effectiveness across various applications [28]–\n[31], particularly in hybrid architectures that combine classical\nnetworks and QNNs. This convergence highlights the advan-\ntage of integrating quantum computing to tackle complicated\nproblems. Inspired by these promising results, we adopt a\nparallel structure integrating the classical NN and QNN.\nThe parallel structure is illustrated in Figure 3, where we\nincorporate Rotation X, Rotation Y, Ising XX, Pauli-Z, and\nToffoli quantum gates to develop interpretable QLTEM. Within\nthis framework, QLTEM extracts temporal features from each\n1 × 3 time-wise sequence using the RY -Ising-RX-Ising-RY -\nToffoli3 architecture, which has been empirically validated for\nits effectiveness (cf. Figure 3). Specifically, the QNN learns\nthe quantum unitary transformation with a set of trainable\nparameters {ρk, ωk, θk, ϕk}. Furthermore, by leveraging the\nentanglement mechanism and measurement, QLTEM captures\nfiner temporal dependencies, thereby improving predictive\n\n\n7\nFig. 4: Detailed architecture of the proposed feature fusion\nblock (FFB). The proposed FFB aims to fuse the spatiotem-\nporally encoded features of the seven meteorological variables\n(i.e., precipitation, maximum/minimum/mean temperatures,\nvapor pressure, cloud cover, and potential evapotranspiration)\nto predict the final drought condition of the next month (i.e.,\nthe month next to the input 15 continuous months).\nperformance. Additionally, QLTEM is designed to achieve\nquantum full expressibility (FE), guaranteeing that the network\ncan express all valid quantum functions. This property is\nformally established in Theorem 1 below.\nTheorem 1 The trainable quantum neurons deployed in the\nproposed QLTEM (cf. Figure 3) can express any valid quantum\nunitary operator U, parameterized by a set of real-valued\ntrainable network variables {ρk, ωk, θk, ϕk}.\n□\nThe proof of Theorem 1 can be done by utilizing the\ntransparency of the Ising quantum neurons. The exact proof\nprocedure follows a similar approach to that of [28, Theorem\n2] and is omitted here for conciseness. To conclude, the\nTEB (cf. (3)) can be effectively implemented based on the\naforementioned structure.\nC. Feature Fusion Block\nOnce the LTEM and QLTEM jointly capture temporal\nfeatures of the spatial characteristics returned by SEB, the\nproposed SQUARE-Mamba has extracted the exquisite spa-\ntiotemporal features from different meteorological variables.\nThese spatiotemporal representations are then fused to maxi-\nmize the predictive accuracy for effective DF. To fully lever-\nage the complementary strengths of these two modules, we\nintroduce the feature fusion block (FFB), which integrates\nthe temporal information from classical LTEM and quantum\nQLTEM encoding processes to generate the final prediction\nresult. Specifically, FFB aggregates all encoded spatiotemporal\nfeatures, as illustrated in Figure 4.\nThe mathematical formulation of the module FFB(·) is\ndefined as follows:\nFFB(F ) = FCL(BN(F + F ′)),\n(8)\nF ′ = Drop2(f2(Drop1(σ(f1(F ))))),\n(9)\nwhere FCL(·) denotes a fully connected layer; F ∈R15×7\nis the temporally encoded features obtained through TEB(·);\nF ′ ∈R15×7 represents the embedded features; Dropi(·) refers\nto the ith dropout layer with a dropping probability of 0.2 [54];\nfi(·) is the ith 1 × 1 1-D convolutional layer applied along\nthe temporal dimension; and σ(·) denotes the Gaussian error\nlinear unit (GELU) activation function [55].\nThe core function of FFB (cf. (8) and (9)) is to refine\nand effectively fuse spatiotemporal feature representations,\nensuring the integration of complementary classical-QNN\ninformation. By incorporating the dropout mechanism, FFB\nselectively filters and propagates informative features to deeper\nlayers, mitigating overfitting and improving generalization.\nIn addition, a shortcut connection mechanism is employed\nto preserve the original spatiaotemporally encoded features,\nensuring that critical information is retained throughout the\nfusion process. Finally, the fully connected layer (FCL) pro-\nduces the final prediction, demonstrating the effectiveness of\nthe fusion mechanism in integrating valuable information. By\nfollowing (8) and (9), FFB can be efficiently implemented.\nTo conclude this section, we present SQUARE-Mamba,\nan SPEI-driven quantum spatially-aware Mamba network, as\nsummarized in Figure 1. This framework effectively leverages\nneighboring climatic coherence information through the SEB\nto enhance DF performance. Furthermore, the integration of\nthe computationally efficient Mamba network and the ex-\nplainable QNN with FE (cf. Theorem 1) successfully leads\nto rich temporal feature extraction results, well capturing\nboth classical and quantum characteristics. Additionally, the\nparallel structure of TEB ensures that both Mamba- and QNN-\nbased features are fairly fused in the final prediction outcome.\nFinally, the spatiotemporally encoded features for different\nmeteorological variables are fused by FFB, in order to enhance\npredictive accuracy and also to ensure effective integration of\ncomplementary classical and quantum information. We will\nconduct systematic ablation studies to evaluate the effective-\nness of the spatial augmentation strategy and the temporal\nquantum entanglement mechanism. We will also demonstrate\nthe superior forecasting performance of the overall SQUARE-\nMamba architecture (i.e., Algorithm 1), validating our design\nphilosophy and highlighting its practical applicability.\nIII. EXPERIMENTAL RESULTS\nIn this section, we first introduce the experimental set-\ntings and then present the DF performance of SQUARE-\nMamba across six representative locations in New South Wales\n(NSW), Australia, covering wet, dry, and moderate climatic\nconditions. The testing locations include Woombah, Geehi,\nEnngonia, Jerilderie, Milparinka, and Pooncarie, as illustrated\nin Figure 5. Section III-A provides details on the dataset\ndescription, the calculation of SPEI, the preprocessing steps,\nas well as the hyperparameter configurations. Section III-B\n\n\n8\nFig. 5: Investigated area in the New South Wales (NSW), Australia, and the long-term mean precipitation map using the\n1961–1990 base period.\npresents the forecasting results for six representative locations\nover a comprehensive testing period from December 2007\nto December 2023, covering more than 16 years of diverse\nclimatic conditions. This long-term evaluation encompasses\nvarious climatic phases, including El Ni˜no, La Ni˜na, and\nnormal years, ensuring a thorough assessment of model robust-\nness under varying drought patterns. All results are evaluated\nusing both objective quantitative metrics and visual qualitative\nassessments. In Section III-C, ablation studies are conducted\nto systematically analyze the effectiveness of the spatial-\naware mechanism and the temporal quantum entanglement\nmechanism in facilitating the DF performance.\nA. Experimental Settings\n1) Data Description: This study utilizes the Climatic Re-\nsearch Unit gridded time series dataset (CRU TS Version\n4.08), which is produced by the University of East Anglia\nand is publicly available1. Specifically, this dataset has a\nspatial resolution of 0.5◦latitude by 0.5◦longitude, with\nmonthly temporal resolution over the period from 1901 to\n2023 [56]. Following recent literature [20], seven climatic\nvariables are selected to predict drought severity. These include\nprimary variables (mean temperature and precipitation), sec-\nondary variables (vapor pressure and cloud cover), and derived\nvariables (potential evapotranspiration, maximum temperature,\nand minimum temperature). In this work, we utilize 15 months\nof data along with 7 meteorological variables (i.e., z ∈R15×7)\nto predict drought condition d ∈[−3, 3], as summarized in\nAlgorithm 1. Moreover, the widely used CRU dataset has been\napplied to various research fields, including studies on climate\nvariability, paleoclimatology [57], and agronomy [58].\n2) Standardized Precipitation Evapotranspiration Index: In\nSQUARE-Mamba, we use the SPEI [14] to predict drought\n1https://spei.csic.es/database.html\nTABLE II: Drought categories based on the DF result d [59].\nCategory\nDrought Forecasting Result d\nExtremely Dry\n−3 ≤d ≤−2\nSeverely Dry\n−2 < d ≤−1.5\nModerately Dry\n−1.5 < d ≤−1\nNear Normal\n−1 < d ≤1\nModerately Wet\n1 < d ≤1.5\nSeverely Wet\n1.5 < d ≤2\nExtremely Wet\n2 < d ≤3\nconditions [20], [24]. To enhance understanding, Table II\npresents the drought classifications corresponding to different\nSPEI values. SPEI is derived from the climatic water balance,\nwhich is calculated as the difference between precipitation and\nPET. As a result, SPEI serves as an effective metric for drought\nassessment. Notably, predicting drought conditions helps miti-\ngate significant economic losses, while meteorological drought\noften precedes agricultural and hydrological drought. Thus,\nshorter time scales are more suitable for assessing meteoro-\nlogical drought than medium or longer time scales [20]. Given\nthese considerations, this study focuses on predicting SPEI at\na one-month time scale (i.e., SPEI-1) to facilitate practical\napplications. For a detailed explanation of SPEI calculations,\ninterested readers may refer to the recent literature [14].\n3) Data Splitting and Preprocessing: To ensure a fair com-\nparison and robust evaluation, we partition the CRU dataset\n(1901-2023) into non-overlapping training, validation, and\ntesting datasets [60]. By splitting into three disjoint datasets,\none can ensure that all the methods are evaluated on com-\npletely new data, thus providing a more reliable assessment\nof their generalizability and effectiveness [61]. Accordingly,\n\n\n9\nthis study empirically employs about 65% (1901–1980) of\nthe data for training, 20% (1981–2005) for validation, and\nthe remaining portion (2006–2023) for testing. We adopt this\nsplitting method to ensure fair and reliable model evaluation,\navoiding overly optimistic results in real-world applications.\nOur primary goal is to train a model that remains robust to\nclimate variability rather than one that merely fits historical\ntrends. For the time series regression task, it is crucial to ensure\nthat the input data is stationary, indicating that the mean and\nvariance remain constant over time [62]. Thus, the normalized\ndata Y = [yT\n1 , yT\n2 , . . . , yT\nL]T ∈RL×K is derived from the\noriginal data X = [xT\n1 , xT\n2 , . . . , xT\nL]T ∈RL×K through the\nfollowing procedure [63], i.e.,\nyi = xi −µ\nσ\n,\n∀i = 1, 2, . . . , L,\n(10)\nµ = 1\nL\nL\nX\ni=1\nxi,\nσ =\nv\nu\nu\nt 1\nL\nL\nX\ni=1\n(xi −µ)2,\n(11)\nwhere µ ∈RK and σ ∈RK represent the mean and\nstandard deviation of distinct hydro-meteorological variables;\nthe division, square, and square root operations above are\nelementwise operators. In this work, the number of time\nframes (i.e., L) and the number of variables (i.e., K) are 15\nand 7, respectively. By ensuring statistical stability within each\nsegment, the model can focus on learning meaningful features\nwhile minimizing the impact of data distribution shifts across\ndifferent climate regimes, thereby improving training stability\nand model’s generalization ability [63].\n4) Computer Facility and Hyperparameter for Training:\nFor training the proposed spatial-temporal drought forecasting\nnetwork (i.e., SQUARE-Mamba), we employ the AdamW\noptimizer [64] with a learning rate decay mechanism. The\ninitial learning rate is 1 × 10−3 under the cosine annealing\nscheme. The mean squared error (MSE) loss function is\nutilized for the training stage. The training process ends once\nthe validation loss stabilizes, typically within 250 epochs. To\nevaluate the performance, we choose the checkpoint model\nwith the best R-squared measure (R2) among the validation\ndata for the following testing experiments. In addition, the\ndetails of the computational setup and resources are outlined\nbelow. All experiments are conducted on a desktop computer\nwith an NVIDIA Geforce RTX 4090 GPU and an Intel Core\ni9-13900 CPU (5.6 GHz) with 32 GB of RAM, while the\nnumerical computing environment is Python 3.10.13.\nB. Quantitative and Qualitative Analyses\nIn this section, we evaluate the effectiveness of our\nSQUARE-Mamba by comparing it with benchmark methods,\nincluding the autoregressive integrated moving average model\n(ARIMA) [19], the long short-term memory network (LSTM)\n[17], and the transformer-based time series prediction model\n(Informer) [18]. To ensure the robustness of these methods,\nwe conduct experiments over long-term periods across a wide\nrange of climatic conditions. This comprehensive evaluation\nencompasses normal, El Ni˜no, and La Ni˜na years, allowing\nus to assess the reliability of studied methods under varying\nenvironmental scenarios. Specifically, we conducted experi-\nments over the period from December 2007 to December 2023,\nincluding normal years (i.e., 2012–2014 and 2019–2020), El\nNi˜no periods (i.e., 2009–2010, 2014–2016, and 2018–2019),\nand La Ni˜na phases (i.e., 2007–2009, 2010–2012, 2016–2018,\nand 2020–2023).\nBesides evaluating performance over long-term periods,\nwe also assess the studied methods across six representative\nlocations that exhibit distinct climatic conditions, including\nwet (e.g., Woombah and Geehi), moderate (e.g., Enngonia and\nJerilderie), and dry (e.g., Milparinka and Pooncarie) regions.\nAs demonstrated in Figure 5, these investigated regions are\nlocated in NSW, Australia, which has historically experienced\nmultiple severe droughts, such as the Federation Drought\n(1895–1902) and the Millennium Drought (2001–2010) [65].\nThis makes NSW an ideal testing region, as it provides diverse\nclimatic scenarios and meets the practical need for reliable\nDF. Finally, the experimental results, categorized under wet,\ndry, and moderate climatic conditions over the extended study\nperiod, are presented in Table III and Figures 6 to 11, which\nwill be discussed later.\nFor quantitative assessment, three commonly used objective\nmetrics are adopted to assess the performance of the studied\nmethods, including mean absolute error (MAE) [66], root MSE\n(RMSE) [67], and R2 [68]. The definitions of these metrics\nare detailed below. The MAE index assesses the mean of the\nabsolute error between the predicted values and the observed\nvalues, defined as follows:\nMAE =\nPN\nn=1 |en|\nN\n,\nwhere N = 193 months representing the total prediction time\nlength, and |en| = |byn −yn| represents the n-th absolute error\nwith byn denoting the n-th predicted values and yn denoting\nthe n-th observed values. The RMSE index calculates the\nroot mean squared error between the observed values and the\npredicted ones, defined as follows:\nRMSE =\nv\nu\nu\nt 1\nN\nN\nX\nn=1\n(byn −yn)2.\nSince the squaring operation amplifies the values of greater\ndeviations, RMSE places more emphasis on larger errors.\nHence, the RMSE index is more responsive to extreme error\ncases. The R2 computes the coefficient of determination,\ndefined as follows:\nR2 = 1 −N × MSE\nSST\n,\nSST =\nN\nX\nn=1\n(yn −yn)2,\nwhere yn =\n1\nN\nPN\nn=1 yn. The sum of squares total (SST)\nindicates the sum of squared differences between individual\ndata yn and the mean yn. In summary, R2 measures how well\nthe model fits the data. Hence, the model can better explain the\ntrends in the data if it has a higher R2 score. For instance, as\nthe value approaches to 1, it signifies that the model explains\nthe majority of the variability in the data.\n\n\n10\nTABLE III: Quantitative comparison using six representative\nlocations across NSW, Australia, covering different climatic\nconditions (i.e., wet, moderate, and dry). A boldfaced number\nindicates the best performance for each location and index.\nLocation\nIndex\nARIMA\nLSTM\nInformer\nSQUARE-Mamba\nWoombah\nMAE(↓)\n0.8790\n0.3290\n0.2248\n0.1663\nRMSE(↓)\n1.0306\n0.4932\n0.3086\n0.2250\nR2(↑)\n0.0277\n0.7772\n0.9128\n0.9536\nGeehi\nMAE(↓)\n0.7746\n0.4242\n0.3635\n0.1553\nRMSE(↓)\n0.9214\n0.5562\n0.5327\n0.2108\nR2(↑)\n0.0914\n0.6689\n0.6962\n0.9524\nEnngonia\nMAE(↓)\n0.6402\n0.3332\n0.2441\n0.1948\nRMSE(↓)\n0.7860\n0.4104\n0.3202\n0.2867\nR2(↑)\n0.1524\n0.7689\n0.8593\n0.8872\nJerilderie\nMAE(↓)\n0.6695\n0.2187\n0.2414\n0.2007\nRMSE(↓)\n0.8101\n0.3149\n0.3385\n0.2915\nR2(↑)\n0.1188\n0.8668\n0.8461\n0.8858\nMilparinka\nMAE(↓)\n0.6133\n0.3092\n0.3230\n0.2407\nRMSE(↓)\n0.8033\n0.4090\n0.4224\n0.3234\nR2(↑)\n0.1437\n0.7779\n0.7631\n0.8612\nPooncarie\nMAE(↓)\n0.8002\n0.2515\n0.2990\n0.1891\nRMSE(↓)\n0.9697\n0.3547\n0.3910\n0.2677\nR2(↑)\n0.0624\n0.8745\n0.8475\n0.9285\nThe three objective metrics are utilized to assess the DF\nperformance across six representative locations, as presented\nin Table III. For clarity, the best results are highlighted in\nboldfaced numbers, where lower MAE/RMSE values and\nhigher R2 scores indicate better DF performances. As ex-\npected, the proposed SQUARE-Mamba achieves state-of-the-\nart results, owing to its spatially-aware mechanism that ef-\nfectively captures spatial coherence (i.e., SEB), its Mamba-\nbased time sequence modeling, as well as its integration\nof the quantum deep network (QUEEN). In contrast, other\nbenchmark models exhibit noticeable misalignment between\npredicted and observed trends, resulting in higher DF errors\nacross the evaluation metrics, as will be discussed below.\nFirst, we conduct experiments in wet climatic regions (i.e.,\nWoombah and Geehi), as shown in Figures 6 and 7, where the\nfirst to fourth rows represent the prediction curves of ARIMA,\nLSTM, Informer, and SQUARE-Mamba, respectively. Com-\npared to the prediction curves of SQUARE-Mamba, other\nbenchmark methods exhibit noticeable deviations from the\nobserved curves (i.e., ground-truth curves), particularly at the\ntime points highlighted by red-marked circles. As shown in\nFigure 6, the rightmost circle highlights the superior forecast-\ning capability of SQUARE-Mamba even during the El Ni˜no\nevent in 2023. Most importantly, the year 2023 experienced\nan abrupt and intense climate shift within a short period.\nDuring this period, La Ni˜na conditions persisted in January,\nfollowed by a normal phase in February, March, and April,\nbefore rapidly transitioning into an El Ni˜no event in May 2023,\nwhich lasted until April 2024. Despite these rapid climatic\nchanges, SQUARE-Mamba still obtains satisfactory prediction\nresults, thanks to the quantum/classical-hybrid temporal mod-\neling of TEB (cf. Figure 3), which effectively captures short-\nterm fluctuations. Furthermore, the middle circle in Figure\n7 demonstrates that SQUARE-Mamba delivers more accurate\nDF results among studied methods during the 2014–2016 El\nNi˜no event. Notably, the 2014–2016 El Ni˜no event has been\ndocumented as one of the most significant since records2 began\nin 1950, with the Oceanic Ni˜no Index (ONI) [69] exceeding\n2◦C at its peak during this period. As shown in the first\nand second rows of Table III, the quantitative metrics double\nconfirm the superiority of SQUARE-Mamba over benchmark\nmethods, with R2 remarkably exceeding 0.9 in both Woombah\nand Geehi.\nSecond, we analyze the moderate climatic regions (i.e.,\nEnngonia and Jerilderie), which pose greater challenges for\nDF evaluation compared to the wet areas due to their lower\nprecipitation, as shown in Figures 8 and 9. As expected,\nSQUARE-Mamba consistently outperforms benchmark meth-\nods in DF. As shown in the middle circle of Figures 8, the\nSQUARE-Mamba demonstrates satisfactory DF results even\nduring the La Ni˜na event in 2016. Similar to the short-term\nfluctuation in 2023, the year 2016 also experienced a sudden\nand intense climate transition within a short timeframe. During\nthis period, El Ni˜no persisted through April, shifted to normal\nconditions from May to July, and then rapidly developed into\nthe La Ni˜na event starting in August 2016 and continuing\nuntil December 2016. Despite the rapid variability in cli-\nmatic conditions, SQUARE-Mamba achieves strong predictive\nperformance, primarily due to its TEB architecture, which\nsuccessfully captures short-term variations. Furthermore, in\nthe rightmost red circle of Figure 9, the SQUARE-Mamba\nachieves satisfactory prediction results even during the El Ni˜no\nevent in 2023 with short-term fluctuation, as mentioned before.\nAll in all, under the extreme conditions associated with the\nEl Ni˜no and La Ni˜na events, SQUARE-Mamba consistently\nachieves higher DF accuracy than benchmark methods, further\nhighlighting its reliability in DF, as demonstrated in the third\nand fourth rows of Table III.\nFinally, we evaluate the performance of the methods under\nthe most challenging conditions for DF prediction, specifi-\ncally dry climatic regions (i.e., Milparinka and Pooncarie),\nas presented in Figures 10 and 11. Even in extremely dry re-\ngions, SQUARE-Mamba consistently outperforms benchmark\nmethods. For example, as illustrated by the middle circle in\nFigure 10, SQUARE-Mamba has demonstrated robust and\nstable performance during the La Ni˜na event of 2016 despite\nexperiencing significant short-term fluctuations, as previously\ndiscussed. Furthermore, the middle circle in Figure 11 clearly\nshows that SQUARE-Mamba maintains outstanding prediction\naccuracy, even under severely dry conditions in 2019. Notably,\nthe first half of 2019 experienced the El Ni˜no event, which\nthen transitioned into a normal climatic phase lasting until\nAugust 2020. However, despite this classification as a normal\nperiod (based on an ONI threshold of +/- 0.5◦C), Australia\nexperienced the devastating and exceptionally severe wildfire\nseason known as the Black Summer [70]. This highlights a\ncritical issue: even seemingly climatically “normal” conditions\ncan result in severe economic losses due to unforeseen events.\nThus, providing accurate DF predictions is crucial for early\n2https://origin.cpc.ncep.noaa.gov/products/analysis monitoring/ensostuff/\nONI v5.php\n\n\n11\nFig. 6: Prediction curves from 2007 to 2023 using various DF methods with Woombah data acquired over wet climate region.\nFig. 7: Prediction curves from 2007 to 2023 using various DF methods with Geehi data acquired over wet climate region.\ndetection and response. As summarized in the last two rows\nof Table III, SQUARE-Mamba consistently achieves superior\nquantitative results compared to benchmark models, under-\nscoring its robustness and reliability even under the most\ndemanding scenarios.\nTo sum up, we evaluated various scenarios across different\nclimatic conditions, from wet to dry, over long-term periods\n(i.e., December 2007 to December 2023), including normal, El\nNi˜no, and La Ni˜na years, to assess the robustness of the stud-\nied methods. Table III demonstrates that SQUARE-Mamba\noutperforms benchmark methods across all climatic regions,\nachieving an average improvement of more than 9.8% in R2.\nNotably, SQUARE-Mamba maintains its superior performance\neven in the most challenging testing scenarios for DF (i.e., dry\nclimatic regions), with R2 exceeding 0.85 in both Milparinka\nand Pooncare. Over the long term, Figures 6 to 11 illustrate the\nrobustness and consistency of SQUARE-Mamba in adapting\nto climate variations compared to benchmark methods, which\ncan be attributed to the original design philosophy behind the\nproposed temporal modeling (i.e., TEB in Figure 3).\nC. Ablation Study\nAs\ndemonstrated\nin\nSection\nIII-B,\nSQUARE-Mamba\nachieves state-of-the-art performance in both qualitative and\nquantitative evaluations across various climatic regions. To\ngain deeper insights into the efficacy of the proposed SEB and\nQLTEM, we conducted ablation studies, with the results sum-\nmarized in Tables IV, V, and VI. Before discussing the details,\nwe first briefly recall the design philosophy. The proposed\nSEB integrates meteorological information from neighboring\nregions to capture spatial coherence, thereby enhancing pre-\ndiction accuracy. Meanwhile, QLTEM is adopted to identify\nshort-term climate fluctuations and is implemented using the\nquantum deep network (QUEEN) to capture more abstract\ntemporal features through the quantum entanglement mech-\nanism, providing informative features for the final prediction.\n\n\n12\nFig. 8: Prediction curves from 2007 to 2023 using various DF methods with Enngonia data acquired over moderate climate\nregion.\nFig. 9: Prediction curves from 2007 to 2023 using various DF methods with Jerilderie data acquired over moderate climate\nregion.\nTo sum up, we conducted ablation studies to evaluate the\nefficacy of the spatial analysis strategy (i.e., SEB) and the\ntemporal analysis strategy (i.e., QLTEM) across three distinct\nclimatic regions (i.e., wet, moderate, and dry). In the following\nparagraph, we provide a detailed analysis of our findings,\nhighlighting their impact on model performance in different\nclimatic conditions.\nAs shown in the second and fourth rows of Tables IV, V, and\nVI, the integration of SEB does further improve DF accuracy\nacross all performance metrics. These observations clearly\ndemonstrate the efficacy of SEB in enhancing DF predictions\nacross different climatic conditions. Furthermore, in the pro-\nposed TEB, QLTEM captures short-term climate variations\nby entangling temporal features. As illustrated in the third\nand fourth rows of Tables IV, V, and VI, it is clear that DF\nperformance is noticeably improved by incorporating QLTEM.\nBased on the above findings, we conclude that integrating\nSEB or QLTEM can significantly enhance prediction accuracy.\nConsidering both the existing spatial coherence information\nand short-term fluctuation problem, we incorporate SEB and\nQLTEM simultaneously to capture more sophisticated interac-\ntions between spatial and temporal features, thereby extracting\nrefined spatiotemporal representations. The advantages are\nevident in the first and fourth rows of Tables IV, V, and\nVI, showing that integrating both SEB and QLTEM leads to\nsubstantial improvements in five out of six evaluated metrics.\nBoth QLTEM and SEB significantly enhance DF prediction\naccuracy across various climatic scenarios, ranging from wet\nto dry conditions, demonstrating their generalizability and\neffectiveness for DF prediction. To sum up, SQUARE-Mamba\nachieves state-of-the-art performance and is thus a promising\ntool for forecasting drought conditions, potentially helping\n\n\n13\nFig. 10: Prediction curves from 2007 to 2023 using various DF methods with Milparinka data acquired over dry climate region.\nFig. 11: Prediction curves from 2007 to 2023 using various DF methods with Pooncarie data acquired over dry climate region.\nTABLE IV: Ablation study of the proposed SQUARE-Mamba\nalgorithm in wet regions (i.e., Woombah and Geehi) to eval-\nuate the efficacy of the spatial encoding block (SEB) and the\nquantum local temporal encoding module (QLTEM).\nSEB\nQLTEM\nLocation\nMAE (↓)\nRMSE (↓)\nR2(↑)\n✗\n✗\nWoombah\n0.1608\n0.2300\n0.9515\nGeehi\n0.1805\n0.2414\n0.9376\n✗\n✓\nWoombah\n0.1817\n0.2623\n0.9370\nGeehi\n0.1710\n0.2277\n0.9444\n✓\n✗\nWoombah\n0.2132\n0.2744\n0.9310\nGeehi\n0.1944\n0.2594\n0.9279\n✓\n✓\nWoombah\n0.1663\n0.2250\n0.9536\nGeehi\n0.1553\n0.2108\n0.9524\nmitigate severe economic impacts.\nTABLE V: Ablation study of the proposed SQUARE-Mamba\nalgorithm in moderate regions (i.e., Enngonia and Jerilderie)\nto evaluate the efficacy of the spatial encoding block (SEB)\nand the quantum local temporal encoding module (QLTEM).\nSEB\nQLTEM\nLocation\nMAE (↓)\nRMSE (↓)\nR2(↑)\n✗\n✗\nEnngonia\n0.2254\n0.3726\n0.8095\nJerilderie\n0.2013\n0.3100\n0.8709\n✗\n✓\nEnngonia\n0.2026\n0.3005\n0.8761\nJerilderie\n0.2085\n0.3098\n0.8711\n✓\n✗\nEnngonia\n0.2160\n0.3048\n0.8724\nJerilderie\n0.2153\n0.3183\n0.8639\n✓\n✓\nEnngonia\n0.1948\n0.2867\n0.8872\nJerilderie\n0.2007\n0.2915\n0.8858\n\n\n14\nTABLE VI: Ablation study of the proposed SQUARE-Mamba\nalgorithm in dry regions (i.e., Milparinka and Pooncarie) to\nevaluate the efficacy of the spatial encoding block (SEB) and\nthe quantum local temporal encoding module (QLTEM).\nSEB\nQLTEM\nLocation\nMAE (↓)\nRMSE (↓)\nR2(↑)\n✗\n✗\nMilparinka\n0.2715\n0.3943\n0.7936\nPooncarie\n0.2105\n0.3139\n0.9017\n✗\n✓\nMilparinka\n0.2627\n0.3490\n0.8383\nPooncarie\n0.2188\n0.3107\n0.9037\n✓\n✗\nMilparinka\n0.2831\n0.3766\n0.8117\nPooncarie\n0.2078\n0.2866\n0.9180\n✓\n✓\nMilparinka\n0.2407\n0.3234\n0.8612\nPooncarie\n0.1891\n0.2677\n0.9285\nIV. CONCLUSION\nWe have leveraged the Mamba deep learning (a power-\nful temporal analysis modeling) and quantum deep network\n(QUEEN) to achieve state-of-the-art drought forecasting (DF)\nperformance. The proposed DF method is termed SPEI-driven\nquantum spatially-aware Mamba network (SQUARE-Mamba),\nwhich yields a remarkable DF improvement of more than\n9.8% in the essential index R2. SQUARE-Mamba is gen-\nerally applicable across diverse climate regions (including\nwet, dry, and moderate areas) and varying climate patterns\n(including El Ni˜no, La Ni˜na, and normal years) over a\nlong testing period. As the ablation study demonstrated, the\nsuperiority of SQUARE-Mamba can be attributed to the pro-\nposed spatially-aware mechanism and the temporal quantum\nentanglement, where the former exploits the meteorological\ndata from neighboring regions to assist the DF at a target\nregion, while the latter employs QUEEN to capture the short-\nterm climate variations for the subsequent long-term DF.\nThe proposed SQUARE-Mamba has successfully fused the\nseven extracted/refined spatiotemporal features corresponding\nto seven meteorological variables to accurately predict the\nDF results, well aligning with the observed SPEI drought\nconditions. Therefore, SQUARE-Mamba is expected to serve\nas a reliable algorithm (i.e., Algorithm 1) for the monitoring\nand management of water resources amidst ongoing extreme\nclimate changes.\nREFERENCES\n[1] D. A. Wilhite, Drought as A Natural Hazard: Concepts and Definitions.\nMilton Park, Abingdon, Oxfordshire, UK: Routledge, 2016.\n[2] Y. Mao, B. Nijssen, and D. P. Lettenmaier, “Is climate change impli-\ncated in the 2013–2014 California drought? A hydrologic perspective,”\nGeophysical Research Letters, vol. 42, no. 8, pp. 2805–2813, Mar. 2015.\n[3] A. F. Van Loon, T. Gleeson, J. Clark, A. I. Van Dijk, K. Stahl,\nJ. Hannaford, G. Di Baldassarre, A. J. Teuling, L. M. Tallaksen, and\nR. Uijlenhoet, “Drought in the Anthropocene,” Nature Geoscience,\nvol. 9, no. 2, pp. 89–91, Feb. 2016.\n[4] W. W. Immerzeel, L. P. H. V. Beek, and M. F. P. Bierkens, “Climate\nchange will affect the Asian water towers,” Science, vol. 328, no. 5984,\npp. 1382–1385, Jun. 2010.\n[5] R. G. Taylor, B. Scanlon, P. D¨oll, M. Rodell, R. Van Beek,\nY. Wada, L. Longuevergne, M. Leblanc, J. S. Famiglietti, M. Edmunds,\nL. Konikow, T. R. Green, J. Chen, M. Taniguchi, M. F. P. Bierkens,\nA. MacDonald, Y. Fan, R. M. Maxwell, Y. Yechieli, J. J. Gurdak,\nD. M. Allen, M. Shamsudduha, K. Hiscock, P. J.-F. Yeh, I. Holman,\nand H. Treidel, “Ground water and climate change,” Nature Climate\nChange, vol. 3, no. 4, pp. 322–329, Nov. 2012.\n[6] M. Fl¨orke, C. Schneider, and R. I. McDonald, “Water competition\nbetween cities and agriculture driven by climate change and urban\ngrowth,” Nature Sustainability, vol. 1, no. 1, pp. 51–58, Jan. 2018.\n[7] L. Giovannini, X. Ma, and A. Huete, “Drought resilience of Australian\nrangelands under intense hydroclimatic variability,” in IEEE Interna-\ntional Geoscience and Remote Sensing Symposium (IGARSS), Beijing,\nChina, 10-15 Jul. 2016, pp. 5467–5469.\n[8] K. Xiang, B. Wang, D. L. Liu, C. Chen, C. Waters, A. Huete, and\nQ. Yu, “Probabilistic assessment of drought impacts on wheat yield in\nsouth-eastern Australia,” Agricultural Water Management, vol. 284, pp.\n108 359–108 359, Jun. 2023.\n[9] H. Chang and M. R. Bonnette, “Climate change and water-related\necosystem services: Impacts of drought in California, USA,” Ecosystem\nHealth and Sustainability, vol. 2, no. 12, pp. 1–19, Jun. 2017.\n[10] N. R. Bond, P. S. Lake, and A. H. Arthington, “The impacts of drought\non freshwater ecosystems: An Australian perspective,” Hydrobiologia,\nvol. 600, pp. 3–16, Feb. 2008.\n[11] X. Zhang, N. Chen, H. Sheng, C. Ip, L. Yang, Y. Chen, Z. Sang,\nT. Tadesse, T. P. Y. Lim, A. Rajabifard, C. Bueti, L. Zeng, B. Wardlow,\nS. Wang, S. Tang, Z. Xiong, D. Li, and D. Niyogi, “Urban drought\nchallenge to 2030 sustainable development goals,” Science of the Total\nEnvironment, vol. 693, pp. 1–11, Nov. 2019.\n[12] M. M. Salvia, N. S´anchez, M. Piles, R. C. Ruscica, ´A. Gonz´alez-\nZamora, E. Roitberg, and J. Mart´ınez-Fern´andez, “The added-value of\nremotely-sensed soil moisture data for agricultural drought detection\nin Argentina,” IEEE Journal of Selected Topics in Applied Earth\nObservations and Remote Sensing, vol. 14, pp. 6487–6500, May 2021.\n[13] T. B. McKee, N. J. Doesken, and J. Kleist, “The relationship of drought\nfrequency and duration to time scales,” in Proceedings of the 8th\nConference on Applied Climatology, Anaheim, California, 17-22 Jan.\n1993, pp. 179–183.\n[14] S. M. Vicente-Serrano, S. Beguer´ıa, and J. I. L´opez-Moreno, “A mul-\ntiscalar drought index sensitive to global warming: The standardized\nprecipitation evapotranspiration index,” Journal of Climate, vol. 23,\nno. 7, pp. 1696–1718, Apr. 2010.\n[15] S. M. Vicente-Serrano, S. Beguer´ıa, J. Lorenzo-Lacruz, J. J. Camarero,\nJ. I. L´opez-Moreno, C. Azorin-Molina, J. Revuelto, E. Mor´an-Tejeda,\nand A. Sanchez-Lorenzo, “Performance of drought indices for eco-\nlogical, agricultural, and hydrological applications,” Earth Interactions,\nvol. 16, no. 10, pp. 1–27, Sep. 2012.\n[16] A. R. Huete, “A soil-adjusted vegetation index (SAVI),” Remote Sensing\nof Environment, vol. 25, no. 3, pp. 295–309, Aug. 1988.\n[17] S. Hochreiter and J. Schmidhuber, “Long short-term memory,” Neural\nComputation, vol. 9, no. 8, pp. 1735–1780, Nov. 1997.\n[18] H. Zhou, S. Zhang, J. Peng, S. Zhang, J. Li, H. Xiong, and W. Zhang,\n“Informer: Beyond efficient transformer for long sequence time-series\nforecasting,” in Proc. AAAI Conference on Artificial Intelligent (AAAI),\nvol. 35, no. 12, Virtual Event, 2-9 Feb. 2021, pp. 11 106–11 115.\n[19] G. E. Box, G. M. Jenkins, G. C. Reinsel, and G. M. Ljung, Time Series\nAnalysis: Forecasting and Control.\nHoboken, New Jersey, USA: John\nWiley & Sons, 2015.\n[20] A. Dikshit, B. Pradhan, and A. Huete, “An improved SPEI drought\nforecasting approach using the long short-term memory neural network,”\nJournal of Environmental Management, vol. 283, pp. 1–12, Apr. 2021.\n[21] L. Medsker and L. C. Jain, Recurrent Neural Networks: Design and\nApplications.\nBoca Raton, Florida, USA: CRC Press, 1999.\n[22] J.\nChung,\nC.\nGulcehre,\nK.\nCho,\nand\nY.\nBengio,\n“Empirical\nevaluation of gated recurrent neural networks on sequence modeling,”\narXiv\npreprint\narXiv:1412.3555,\nDec.\n2014.\n[Online].\nAvailable:\nhttps://arxiv.org/abs/1412.3555\n[23] K. Cho, B. Van Merri¨enboer, C. Gulcehre, D. Bahdanau, F. Bougares,\nH.\nSchwenk,\nand\nY.\nBengio,\n“Learning\nphrase\nrepresentations\nusing\nRNN\nencoder-decoder\nfor\nstatistical\nmachine\ntranslation,”\narXiv\npreprint\narXiv:1406.1078,\nJun.\n2014.\n[Online].\nAvailable:\nhttps://arxiv.org/abs/1406.1078\n[24] J. Shang, B. Zhao, H. Hua, J. Wei, G. Qin, and G. Chen, “Application\nof Informer model based on SPEI for drought forecasting,” Atmosphere,\nvol. 14, no. 6, pp. 1–20, May 2023.\n[25] H. Dong, L. Sun, and F. Ouyang, “Prediction of PM2.5 concentration\nbased on Informer,” Environmental Engineering, vol. 40, no. 6, pp. 48–\n54, Mar. 2022.\n[26] N. A. Hasan, Y. Dongkai, and F. Al-Shibli, “SPI and SPEI drought\nassessment and prediction using TBATS and ARIMA models, Jordan,”\nWater, vol. 15, no. 20, pp. 1–32, Oct. 2023.\n\n\n15\n[27] R. Hyndman and G. Athanasopoulos, Forecasting: Principles and\nPractice.\nOTexts, 2018. [Online]. Available: https://books.google.com.\ntw/books?id= bBhDwAAQBAJ\n[28] C.-H. Lin and Y.-Y. Chen, “HyperQUEEN: Hyperspectral quantum deep\nnetwork for image restoration,” IEEE Transactions on Geoscience and\nRemote Sensing, vol. 61, pp. 1–20, May 2023.\n[29] C.-H. Lin, P.-W. Tang, and A. R. Huete, “Quantum feature-empowered\ndeep classification for fast mangrove mapping,” IEEE Transactions on\nGeoscience and Remote Sensing, vol. 63, pp. 1–13, Jan. 2025.\n[30] C.-H. Lin, T.-H. Lin, and J. Chanussot, “Quantum information-\nempowered graph neural network for hyperspectral change detection,”\nIEEE Transactions on Geoscience and Remote Sensing, vol. 62, pp. 1–\n15, Nov. 2024.\n[31] C.-H. Lin and J.-T. Lin, “Prime: Blind multispectral unmixing using\nvirtual quantum prism and convex geometry,” IEEE Transactions on\nGeoscience and Remote Sensing, pp. 1–16, Feb. 2025.\n[32] N. Liu, T. Huang, J. Gao, Z. Xu, D. Wang, and F. Li, “Quantum-\nenhanced deep learning-based lithology interpretation from well logs,”\nIEEE Transactions on Geoscience and Remote Sensing, vol. 60, pp. 1–\n13, Jun. 2021.\n[33] Y.-Y. Hong, D. Josh Domingo Lopez, and Y.-Y. Wang, “Solar irradiance\nforecasting using a hybrid quantum neural network: A comparison on\nGPU-based workflow development platforms,” IEEE Access, vol. 12, pp.\n145 079–145 094, Oct. 2024.\n[34] E. Paquet and F. Soleymani, “Quantumleap: Hybrid quantum neural\nnetwork for financial predictions,” Expert Systems with Applications,\nvol. 195, pp. 1–10, Jun. 2022.\n[35] A. Safari and A. A. Ghavifekr, “Quantum neural networks (QNN)\napplication in weather prediction of smart grids,” in 2021 11th Smart\nGrid Conference (SGC), Tabriz, Iran, 7-9 Dec. 2021, pp. 1–6.\n[36] A. Gu and T. Dao, “Mamba: Linear-time sequence modeling with\nselective state spaces,” arXiv preprint arXiv:2312.00752, Dec. 2023.\n[Online]. Available: https://arxiv.org/abs/2312.00752\n[37] A. Liang, X. Jiang, Y. Sun, and C. Lu, “Bi-Mamba4TS: Bidirectional\nMamba for time series forecasting,” arXiv preprint arXiv:2404.15772,\nApr. 2024. [Online]. Available: https://arxiv.org/abs/2404.15772\n[38] L.\nYue,\nS.\nXing,\nY.\nLu,\nand\nT.\nFu,\n“BioMamba:\nA\npre-\ntrained biomedical language representation model leveraging mamba,”\narXiv preprint arXiv:2408.02600, Aug. 2024. [Online]. Available:\nhttps://arxiv.org/abs/2408.02600\n[39] Y. Li, Y. Luo, L. Zhang, Z. Wang, and B. Du, “MambaHSI: Spa-\ntial–spectral Mamba for hyperspectral image classification,” IEEE Trans-\nactions on Geoscience and Remote Sensing, vol. 62, pp. 1–16, Jul. 2024.\n[40] A. Vaswani, N. Shazeer, N. Parmar, J. Uszkoreit, L. Jones, A. N. Gomez,\nŁ. Kaiser, and I. Polosukhin, “Attention is all you need,” in Proceedings\nof the 31st International Conference on Neural Information Processing\nSystems, Long Beach, California, USA, 4-9 Dec. 2017, pp. 6000–6010.\n[41] P.-W. Tang, C.-H. Lin, and Y. Liu, “Transformer-driven inverse problem\ntransform for fast blind hyperspectral image dehazing,” IEEE Transac-\ntions on Geoscience and Remote Sensing, vol. 62, pp. 1–14, Jan. 2024.\n[42] S.-S. Young, C.-H. Lin, and Z.-C. Leng, “Unsupervised abundance\nmatrix reconstruction transformer-guided fractional attention mechanism\nfor hyperspectral anomaly detection,” IEEE Transactions on Neural\nNetworks and Learning Systems, pp. 1–15, Aug. 2024.\n[43] R. Gnanasambandam, B. Shen, J. Chung, X. Yue, and Z. Kong,\n“Self-scalable tanh (Stan): Multi-scale solutions for physics-informed\nneural networks,” IEEE Transactions on Pattern Analysis and Machine\nIntelligence, vol. 45, no. 12, pp. 15 588–15 603, Dec. 2023.\n[44] U. Pujianto, A. P. Wibawa, M. I. Akbar, and D. M. P. Murti, “K-\nnearest neighbor (K-NN) based missing data imputation,” in 2019\n5th International Conference on Science in Information Technology\n(ICSITech), Yogyakarta, Indonesia, 23–24 Oct. 2019, pp. 83–88.\n[45] J.-T. Lin and C.-H. Lin, “SuperRPCA: A collaborative superpixel\nrepresentation prior-aided RPCA for hyperspectral anomaly detection,”\nIEEE Transactions on Geoscience and Remote Sensing, vol. 62, pp. 1–\n16, Sep. 2024.\n[46] A. L. Maas, A. Y. Hannun, and A. Y. Ng, “Rectifier nonlinearities im-\nprove neural network acoustic models,” in Proc. of the 30th International\nConference on Machine Learning, vol. 30, no. 1.\nAtlanta, GA, 16-21\nJun. 2013, pp. 1–6.\n[47] D. R. Easterling, J. L. Evans, P. Y. Groisman, T. R. Karl, K. E. Kunkel,\nand P. Ambenje, “Observed variability and trends in extreme climate\nevents: A brief review,” Bulletin of the American Meteorological Society,\nvol. 81, no. 3, pp. 417–426, Mar. 2000.\n[48] D. Han, Z. Wang, Z. Xia, Y. Han, Y. Pu, C. Ge, J. Song, S. Song,\nB. Zheng, and G. Huang, “Demystify Mamba in vision: A linear at-\ntention perspective,” in The Thirty-eighth Annual Conference on Neural\nInformation Processing Systems, Vancouver, Canada, 10-15 Dec. 2024.\n[49] B. Singh, S. Patel, A. Vijayvargiya, and R. Kumar, “Analyzing the\nimpact of activation functions on the performance of the data-driven\ngait model,” Results in Engineering, vol. 18, pp. 1–13, Jun. 2023.\n[50] L. Trottier, P. Giguere, and B. Chaib-Draa, “Parametric exponential\nlinear unit for deep convolutional neural networks,” in 2017 16th\nIEEE international conference on machine learning and applications\n(ICMLA), Cancun, Mexico, 18-21 Dec. 2017, pp. 207–214.\n[51] C.-H. Lin, C.-Y. Kuo, and S.-S. Young, “Quantum adversarial learning\nfor hyperspectral remote sensing,” in IGARSS 2024-2024 IEEE Inter-\nnational Geoscience and Remote Sensing Symposium, Athens, Greece,\n7-12 Jul. 2024, pp. 7807–7811.\n[52] C.-H. Lin and Y.-Y. Chen, “Quantum deep hyperspectral satellite remote\nsensing,” in IGARSS 2023-2023 IEEE International Geoscience and\nRemote Sensing Symposium, Pasadena, California, 16-21 Jul. 2023, pp.\n7316–7319.\n[53] M. A. Nielsen and I. L. Chuang, Quantum Computation and Quantum\nInformation.\nShaftesbury Road, Cambridge, CB2 8BS, United King-\ndom: Cambridge University Press, Cambridge, 2010.\n[54] G. E. Hinton, N. Srivastava, A. Krizhevsky, I. Sutskever, and R. R.\nSalakhutdinov, “Improving neural networks by preventing co-adaptation\nof feature detectors,” arXiv preprint arXiv:1207.0580, Jul. 2012.\n[Online]. Available: https://arxiv.org/abs/1207.0580\n[55] D. Hendrycks and K. Gimpel, “Gaussian error linear units (GELUs),”\narXiv preprint arXiv:1606.08415, Jun. 2016. [Online]. Available:\nhttps://arxiv.org/abs/1606.08415\n[56] I. Harris, T. J. Osborn, P. Jones, and D. Lister, “Version 4 of the CRU TS\nmonthly high-resolution gridded multivariate climate dataset,” Scientific\nData, vol. 7, no. 1, pp. 1–18, Mar. 2020.\n[57] V. Nagavciuc, M. Ionita, A. Pers,oiu, I. Popa, N. J. Loader, and\nD. McCarroll, “Stable oxygen isotopes in Romanian oak tree rings\nrecord summer droughts and associated large-scale circulation patterns\nover Europe,” Climate Dynamics, vol. 52, pp. 6557–6568, Nov. 2019.\n[58] D. Renard and D. Tilman, “National food production stabilized by crop\ndiversity,” Nature, vol. 571, no. 7764, pp. 257–260, May 2019.\n[59] J. Rhee and J. Im, “Meteorological drought forecasting for ungauged\nareas based on machine learning: Using long-range climate forecast and\nremote sensing data,” Agricultural and Forest Meteorology, vol. 237, pp.\n105–122, May 2017.\n[60] A. Belayneh, J. Adamowski, B. Khalil, and B. Ozga-Zielinski, “Long-\nterm SPI drought forecasting in the Awash River Basin in Ethiopia using\nwavelet neural network and wavelet support vector regression models,”\nJournal of Hydrology, vol. 508, pp. 418–429, Jan. 2014.\n[61] C.-H. Lin, M.-C. Chu, and P.-W. Tang, “CODE-MM: Convex deep\nmangrove mapping algorithm based on optical satellite images,” IEEE\nTransactions on Geoscience and Remote Sensing, vol. 61, pp. 1–19, Sep.\n2023.\n[62] G. P. Zhang and M. Qi, “Neural network forecasting for seasonal and\ntrend time series,” European Journal of Operational Research, vol. 160,\nno. 2, pp. 501–514, Jan. 2005.\n[63] Y. Wang, H. Wu, J. Dong, Y. Liu, M. Long, and J. Wang,\n“Deep time series models: A comprehensive survey and benchmark,”\narXiv\npreprint\narXiv:2407.13278,\nJul.\n2024.\n[Online].\nAvailable:\nhttps://arxiv.org/abs/2407.13278\n[64] I. Loshchilov and F. Hutter, “Decoupled weight decay regularization,”\nin Proc. International Conference on Learning Representations, New\nOrleans, USA, May 6-9 2019, pp. 1–8.\n[65] A. Dikshit, B. Pradhan, and A. M. Alamri, “Short-term spatio-temporal\ndrought forecasting using random forests model at New South Wales,\nAustralia,” Applied Sciences, vol. 10, no. 12, pp. 1–16, Jun. 2020.\n[66] C. J. Willmott and K. Matsuura, “Advantages of the mean absolute error\n(MAE) over the root mean square error (RMSE) in assessing average\nmodel performance,” Climate Research, vol. 30, no. 1, pp. 79–82, Dec.\n2005.\n[67] T. Chai and R. R. Draxler, “Root mean square error (RMSE) or mean\nabsolute error (MAE),” Geoscientific Model Development Discussions,\nvol. 7, no. 1, pp. 1525–1534, Feb. 2014.\n[68] A. C. Cameron and F. A. Windmeijer, “An R-squared measure of\ngoodness of fit for some common nonlinear regression models,” Journal\nof Econometrics, vol. 77, no. 2, pp. 329–342, Apr. 1997.\n[69] M. H. Glantz and I. J. Ramirez, “Reviewing the Oceanic Ni˜no Index\n(ONI) to enhance societal readiness for El Ni˜no’s impacts,” International\nJournal of Disaster Risk Science, vol. 11, pp. 394–403, May 2020.\n[70] A. I. Filkov, T. Ngo, S. Matthews, S. Telfer, and T. D. Penman, “Impact\nof Australia’s catastrophic 2019/20 bushfire season on communities and\n\n\n16\nenvironment. retrospective analysis and current trends,” Journal of Safety\nScience and Resilience, vol. 1, no. 1, pp. 44–56, Sep. 2020.\nPo-Wei Tang (S’20) received the B.S. degree from\nthe Department of Electronic Engineering, National\nChanghua University of Education, Changhua, Tai-\nwan, in 2018. He is currently pursuing the Ph.D.\ndegree with the Intelligent Hyperspectral Computing\nLaboratory, Institute of Computer and Communi-\ncation Engineering, National Cheng Kung Univer-\nsity (NCKU), Tainan, Taiwan. His research interests\ninclude deep learning, convex optimization, tensor\ncompletion, and hyperspectral imaging.\nMr. Tang has received a highly competitive schol-\narship from NCKU, as well as the Pan Wen Yuan Award from the Industrial\nTechnology Research Institute (ITRI) of Taiwan. He has been selected as a\nrecipient for the Ph.D. Students Study Abroad Program from the National\nScience and Technology Council (NSTC), in 2024.\nChia-Hsiang Lin (S’10-M’18-SM’24) received the\nB.S. degree in electrical engineering and the Ph.D.\ndegree in communications engineering from Na-\ntional Tsing Hua University (NTHU), Taiwan, in\n2010 and 2016, respectively. From 2015 to 2016, he\nwas a Visiting Student of Virginia Tech, Arlington,\nVA, USA.\nHe is currently an Associate Professor with the\nDepartment of Electrical Engineering, and also with\nthe Miin Wu School of Computing, National Cheng\nKung University (NCKU), Taiwan. Before joining\nNCKU, he held research positions with The Chinese University of Hong\nKong, HK (2014 and 2017), NTHU (2016-2017), and the University of Lisbon\n(ULisboa), Lisbon, Portugal (2017-2018). He was an Assistant Professor\nwith the Center for Space and Remote Sensing Research, National Central\nUniversity, Taiwan, in 2018, and a Visiting Professor with ULisboa, in 2019.\nHis research interests include network science, quantum computing, convex\ngeometry and optimization, blind signal processing, and imaging science.\nDr. Lin received the Emerging Young Scholar Award (The 2030 Cross-\nGeneration Program) from National Science and Technology Council (NSTC),\nfrom 2023 to 2027, the Future Technology Award from NSTC, in 2022, the\nOutstanding Youth Electrical Engineer Award from The Chinese Institute of\nElectrical Engineering (CIEE), in 2022, the Best Young Professional Member\nAward from IEEE Tainan Section, in 2021, the Prize Paper Award from IEEE\nGeoscience and Remote Sensing Society (GRS-S), in 2020, the Top Perfor-\nmance Award from Social Media Prediction Challenge at ACM Multimedia,\nin 2020, and The 3rd Place from AIM Real World Super-Resolution Challenge\nat IEEE International Conference on Computer Vision (ICCV), in 2019. He\nreceived the Ministry of Science and Technology (MOST) Young Scholar\nFellowship, together with the EINSTEIN Grant Award, from 2018 to 2023.\nIn 2016, he was a recipient of the Outstanding Doctoral Dissertation Award\nfrom the Chinese Image Processing and Pattern Recognition Society and the\nBest Doctoral Dissertation Award from the IEEE GRS-S.\nJian-Kai Huang (S’25) received the B.S. degree\nfrom the Department of Electrical Engineering, Na-\ntional Chung Cheng University, Chiayi, Taiwan, in\n2023. He is currently pursuing the Graduate de-\ngree with the Intelligent Hyperspectral Computing\nLaboratory, Institute of Computer and Communica-\ntion Engineering, National Cheng Kung University\n(NCKU), Tainan, Taiwan. His research interests in-\nclude deep learning, drought forecasting, and hyper-\nspectral imaging.\nAlfredo R. Huete received the M.Sc. degree in soil\nand plant biology from the University of California\nat Berkeley, Berkeley, CA, USA, in 1982, and the\nPh.D. degree in soil and water science from The\nUniversity of Arizona, Tucson, AZ, USA, in 1984.\nFrom 1984 to 2009, he was an Assistant Professor\nand an Associate Professor with The University of\nArizona. He has over 20 years of experience in\nworking on satellite mission teams, including the\nNASA-EOS MODIS Science Team, the New Millen-\nnium EO-1 Hyperion Team, and JAXA GLI Team,\nthrough which he developed the soil-adjusted vegetation index (SAVI) and the\nenhanced vegetation index (EVI). He is currently a Distinguished Professor\nwith the University of Technology Sydney, Sydney, NSW, Australia, where\nhe leads the Ecosystem Dynamics Health and Resilience Research Program\nin the Faculty of Science and is a Core Member of the Centre for Advanced\nModelling and Geospatial Information Systems, Faculty of Engineering and\nInformation Technology. He also leads the development of vegetation products\nfor the Australian Terrestrial Ecosystem Research Network (TERN).\n\n\n",
  "metadata": {
    "source_file": "dataset/pdfs/arxiv_2502.20703v1.pdf",
    "total_pages": 16,
    "title": "A Quantum-Empowered SPEI Drought Forecasting Algorithm Using Spatially-Aware Mamba Network",
    "authors": [
      "Po-Wei Tang",
      "Chia-Hsiang Lin",
      "Jian-Kai Huang",
      "Alfredo R. Huete"
    ],
    "abstract": "Due to the intensifying impacts of extreme climate changes, drought\nforecasting (DF), which aims to predict droughts from historical meteorological\ndata, has become increasingly critical for monitoring and managing water\nresources. Though drought conditions often exhibit spatial climatic coherence\namong neighboring regions, benchmark deep learning-based DF methods overlook\nthis fact and predict the conditions on a region-by-region basis. Using the\nStandardized Precipitation Evapotranspiration Index (SPEI), we designed and\ntrained a novel and transformative spatially-aware DF neural network, which\neffectively captures local interactions among neighboring regions, resulting in\nenhanced spatial coherence and prediction accuracy. As DF also requires\nsophisticated temporal analysis, the Mamba network, recognized as the most\naccurate and efficient existing time-sequence modeling, was adopted to extract\ntemporal features from short-term time frames. We also adopted quantum neural\nnetworks (QNN) to entangle the spatial features of different time instances,\nleading to refined spatiotemporal features of seven different meteorological\nvariables for effectively identifying short-term climate fluctuations. In the\nlast stage of our proposed SPEI-driven quantum spatially-aware Mamba network\n(SQUARE-Mamba), the extracted spatiotemporal features of seven different\nmeteorological variables were fused to achieve more accurate DF. Validation\nexperiments across El Ni\\~no, La Ni\\~na, and normal years demonstrated the\nsuperiority of the proposed SQUARE-Mamba, remarkably achieving an average\nimprovement of more than 9.8% in the coefficient of determination index (R^2)\ncompared to baseline methods, thereby illustrating the promising roles of the\ntemporal quantum entanglement and Mamba temporal analysis to achieve more\naccurate DF.",
    "published_date": "2025-02-28",
    "source": "arxiv"
  }
}