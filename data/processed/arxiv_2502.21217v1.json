{
  "id": "arxiv_2502.21217v1",
  "text": "DYNAMIC MARKOV BLANKET DETECTION FOR MACROSCOPIC\nPHYSICS DISCOVERY\nA PREPRINT\nJeff Beck\nNoumenal Labs\nDepartment of Neurobiology, Duke University\nMaxwell J. D. Ramstead\nNoumenal Labs\nQueen Square Institute of Neurology, University College London, UK\nMarch 3, 2025\nABSTRACT\nThe free energy principle (FEP), along with the associated constructs of Markov blankets and\nontological potentials, have recently been presented as the core components of a generalized modeling\nmethod capable of mathematically describing arbitrary objects that persist in random dynamical\nsystems; that is, a mathematical theory of “every” “thing.” Here, we leverage the FEP to develop a\nmathematical physics approach to the identification of objects, object types, and the macroscopic,\nobject-type-specific rules that govern their behavior. To do so, we draw out the deep connections\nbetween Markov blankets, reinforcement learning, system identification theory, and macroscopic\nphysics discovery. More specifically, we use the statistics of Markov blankets to operationalize\ntwo conditions for system equivalence in the literature, and to develop an approach to subsystem\ndiscovery, i.e., how to best partition a system into subsystems, and how to best classify (sub)systems.\nUsing the statistics of Markov blankets, we demonstrate that two subsystems of a given system are\nweakly equivalent if their blankets share the same steady state statistics or reward rate; and strongly\nequivalent if the time evolution or paths of their boundaries have the same statistics. This allows us to\nformally define object types in terms of how they interact with their environment. It also allows us to\nreframe the problems of systems identification and macroscopic physics discovery as a problem of\nMarkov blanket detection. We take a generative modeling approach and use variational Bayesian\nexpectation maximization to develop a dynamic Markov blanket detection algorithm that is capable of\nidentifying and classifying macroscopic objects, given partial observation of microscopic dynamics.\nThis unsupervised algorithm uses Bayesian attention to explicitly label observable microscopic\nelements according to their current role in a given system, as either the internal or boundary elements\nof a given macroscopic object; and it identifies macroscopic physical laws that govern how the\nobject interacts with its environment. Because these labels are dynamic or evolve over time, the\nalgorithm is capable of identifying complex objects that travel through fixed media or exchange matter\nwith their environment. This approach leads directly to a flexible class of structured, unsupervised\nalgorithms that sensibly partition complex many-particle or many-component systems into collections\nof interacting macroscopic subsystems, namely, “objects” or “things.” We derive a few examples\nof this kind of macroscopic physics discovery algorithm and demonstrate its utility with simple\nnumerical experiments, in which the algorithm correctly labels the components of Newton’s cradle, a\nburning fuse, the Lorenz attractor, and a simulated cell.\nAcknowledgments\nWe thank Karl Friston for useful feedback.\narXiv:2502.21217v1  [q-bio.NC]  28 Feb 2025\n\n\nA PREPRINT - MARCH 3, 2025\n1\nIntroduction\nIn this paper, we reconsider approaches to system identification and typification used in systems identification theory,\nengineering, and statistical physics using the tools of information theory, in particular, the constructs of Markov blankets\nand ontological potential functions that have been developed in the literature on the free energy principle (FEP). Inspired\nby recent derivations of classical and statistical mechanics from information theoretic principles [31, 10], we present\na novel derivation of the FEP, foregrounding how it can be used to write down “ontological potential functions” that\ndefine object types or phenotypes. This approach is based upon a consideration of the relative entropy formulation of\nJaynes’ principle of maximum caliber [41, 36, 42], with constraints imposed upon the boundary or Markov blanket of a\nmacroscopic object or subsystem of a certain type. We show that these Markov blanket constraints fully characterize\nthe interactions between an object or object type and the other objects in its environment, thereby formalizing the\nbehavioral profile of a subsystem in terms of the effects that it has on other subsystems. This approach subsumes the\nmore standard approaches to identification and typification of physical objects in contemporary reinforcement learning,\nsystem identification theory, and macroscopic physics discovery.\nThe problem of identification and typification of systems and subsystems is deceptively simple. In plain language,\ntraditional systems identification theory asks the question: How can one characterize the complex interactions and\nbehavior of a many-component system using a simple black box function approximator? In the standard approach\nto systems identification, the user identifies a subsystem as a connected subset of a large multi-component complex\nsystem and then characterizes the relationship between the inputs to and outputs from the subsystem. For example,\nin reinforcement learning, the inputs to a system are the observations of the agent and the outputs are its actions.\nThe function that maps inputs to outputs is called the “policy” and in this context, two agents that execute the same\npolicy perform the same actions given the same input conditions and, therefore, are considered to be equivalent. More\ngenerally, two subsystems with the same input-output relationship can then be said to be subsystems of the same type.\nOther than providing a means of typing subsystems, the utility of this approach lies in its ability to provide a compact\ndescription of a complex subsystem, by modeling it as a simple transfer function or as a low-dimensional dynamical\nsystem. This usually involves “black-boxing” the internal components of an overall system: that is, drawing a boundary\naround a many-object or many-component system, and then determining a (hopefully simplified) mathematical\nexpression that summarizes the effect of the complex goings-on inside the boundary, in terms of their effects on the\nboundary of the subsystem, i.e., in terms of its input-output relationship to other subsystems. In this setting, the\nboundary itself is an arbitrary, user-defined boundary that separates the subsystem of interest from other subsystems.\nThe definition of systems equivalence used in reinforcement learning is the one from systems identification theory: Two\nsystems are then said to be of the same type if they have the same input-output relationship or policy, regardless of the\ndetails of their inner workings.\nIn statistical physics, a similar notion of equivalence between macroscopic systems isused. Two systems are said\nto be of the same type if they can be modeled by the same dynamical system or energy function (Hamiltonian or\nLagrangian). The main difference between the systems identification approach and the statistical physics approach is\nthe latter’s use of a coarse-graining procedure to simplify complex microscopic dynamics. This procedure begins by\ndrawing an arbitrary boundary around a connected volume of microscopic particles and identifying macroscopic state\nvariables that summarize the activity of the microscopic components (e.g., temperature, pressure, and density) inside the\nvolume. Rules or laws that relate internal state variables to the net flux of conserved quantities at the boundary are then\nderived from knowledge of microscopic dynamics. Because flux is a conserved quantity, different volumes can then be\nconnected to yield field equations that govern a larger system that is itself made up smaller subsystems that use the same\nflux variables. A macroscopic system of a given type can then be identified as consisting of the connected volumes that\ncan be modeled using the same flux-state relationship, i.e., it is a bucket of water because each fluid element in the\nbucket has the same flux-state relationship. This extends the state space to a field that is dependent on the shape of the\nmacroscopic object and establishes the bucket as providing boundary conditions.\nThe free energy principle (FEP) has been proposed as a general mathematical modeling framework, unifying statistical\nmechanics and information theory, and providing a formal, biologically plausible approach to belief formation and\nupdating as well as information processing. The FEP starts with a mathematical definition of a “thing” or “object”: any\nobject that when can sensibly label as such must be separated from its environment by a boundary. Under the FEP,\nthis boundary is formalized as a Markov blanket that establishes conditional independence between that object and\nits environment. Within this framework, an object is defined not by physical states and fluxes or user labeled inputs\nand outputs, but rather by the flow of information across the Markov blanket. Strictly speaking, a Markov blanket\ndefines the statistical boundary for a set of variables Z ⊂X as the minimal set B ⊂X such that Z is conditionally\nindependent of all variables not in Z or B, given the blanket B. [15, 36]. In the FEP literature, Markov blankets are\nusually described as formalizing the notion of object, because the statistics of the Markov blanket fully characterize the\ninput-output relationship between an object and other objects in its environment.\n2\n\n\nA PREPRINT - MARCH 3, 2025\nThis seemingly abstract definition of a boundary is, in fact, implicit in the definitions of a boundaries used in systems\nidentification and statistical physics. In systems identification, the boundary of a system is directly defined by its inputs\nand outputs. Complete specification of the inputs and outputs of a system allows one to the treat the subsystem as\na driving force on the system as a whole. Similarly, in statistical physics, knowledge of the fluxes into and out of\na subsystem fully characterize both the subsystem and its impact on the rest of system, in the same way that initial\nconditions plus boundary conditions are sufficient to determine the evolution of the state variables. Thus, the notion that\nconditional independence is a property of boundaries between a subsystem and its environment is uncontroversial. In\nthe FEP literature, it is therefore argued that we can define object types or phenotypes in terms of their Markov blankets.\nIn the interest of precision, however, we note that it would be more accurate to say that the presence of a Markov\nblanket in a given system merely indicates a possible partitioning of the system into two interacting subsystems—and\nnothing else. Having identified a blanket, one can then make use of the fact that the blanket summarizes inputs and\noutputs of the associated subsystem to conclude that it is the statistics of the blanket that defines an object type. Recent\nwork has made explicit the mathematical conditions under which the existence of a partition into subsystems with\ntheir Markov blankets can be guaranteed at steady state [44, 20]; and they are guaranteed to exist in the path-based\nformulation of the FEP [43, 44]. Garnering significantly less interest is the question of how to discover these boundaries\nin the first place in a data-driven manner. Indeed, in most of the FEP literature, the focus is on explicating the dynamics\nof information flow in the presence of a blanket, and so the existence of a Markov blanket is usually assumed, i.e., the\nexistence and domain of the blanket are specified a priori. When methods are proposed in the literature to identify\nMarkov blankets, as they are, e.g., in [17], the focus is on an approximate blanket structure in the stationary distribution.\nThis kind of blanket is rarely realized, even in systems that have actual blanket structure. Moreover, Markov blankets\nare always assumed to be static—or are associated with fixed components, giving rise to the false impression that things\nthat display material turnover, such as traveling waves, flames, and living creatures cannot be modeled as having a\nMarkov blanket [35, 30]. Taken together, all this suggests that the critical missing ingredient in the FEP literature is a\nprocedure for identifying dynamic Markov blanketed subsystems, which is thereby capable of describing a wide range\nof stationary and non-stationary phenomena, including flames, lightning bolts, organisms, and other systems that have\ntransient or porous boundaries, and that can pop in and out of existence.\nThis requires the elucidation of a theoretical framework and associated class of inference algorithms that allow us to\nmetaphorically “carve the world at its joints”: that is, to partition complex many-component systems into macroscopic\nobjects and object types, and discover the physical laws or macroscopic rules that govern the interactions between these\nobjects. Ideally, such an unsupervised partitioning would (1) result in a compact, low-dimensional description of objects\nand their interaction, and (2) largely agree with human intuition, in that the partitions of systems into subsystems that it\ngenerates should largely be consistent with human intuitions about the associated perceptual phenomena. For reasons\nthat will become apparent below, the class of algorithms that we are describing are dynamic Markov blanket detection\nalgorithms. The overall approach we take is based upon the formulation of the FEP in the space of paths or trajectories\nof systems over time, which is derived from Jaynes’ principle of maximum caliber, coupled to the Markov blanket based\ndefinition of object and object type. This formulation leads directly to a notion of an “ontological potential function,”\nwhich is specified in terms of constraints on the blanket statistics and constraints on blanket dynamics, and which can be\nused as the basis for a taxonomy of object types. Here, “blanket statistics” refer to the typical summary of the dynamics\nof a subsystem in terms of its input-output relationship with its environment; while “blanket dynamics” refers to how\nthe boundary itself changes over time.\nStarting from this definition of objects and object types, we consider a class of macroscopic generative models utilize\ntwo types of latent variables: (1) macroscopic latent variables that coarse-grain microscopic dynamics in a manner\nconsistent with the imposition of Markov blanket structure, and (2) latent assignment variables that label microscopic\nelements or observations in terms of their role in a macroscopic object, its boundary, or the environment. Critically,\nthese latent assignment variables are also allowed to evolve over time, in a manner consistent with Markov blanket\nstructure. Finally, by taking a Bayesian approach to model discovery, we leverage to automatic Occam’s razor effect of\nBayesian inference to select the partitions of the system into subsystems, such that the global dynamics is as simple or\nlow-dimensional as possible.\nIn summary, we reformulate the problem of system identification as a Markov blanket detection problem. We take a\ngenerative modeling approach and use variational Bayesian expectation maximization to develop a dynamic Markov\nblanket detection algorithm that is capable of identifying and classifying macroscopic objects, given partial observation\nof microscopic dynamics. This unsupervised algorithm uses Bayesian attention to explicitly label microscopic elements\naccording to their current role, as either the internal or boundary elements of a given macroscopic object; and it identifies\nmacroscopic physical laws that govern how the object interacts with its environment. Because these labels are dynamic\nor evolve over time, the algorithm is capable of identifying complex objects that travel through fixed media or exchange\nmatter with their environment. Crucially, this approach eliminates the need to impose arbitrary user-specified boundaries\nupon which systems identification typically relies, allowing for unsupervised segmentation of complex systems into\n3\n\n\nA PREPRINT - MARCH 3, 2025\ncollections of interacting macroscopic objects. Furthermore, by virtue of being based on discovering the statistics of\nMarkov blankets, it automatically inherits the ability to identify object types, allowing us to classify subsystems in\nterms of the macroscopic rules or laws that govern how the object interacts with its environment.\nThe rest of this paper is structured as follows. We first present an overview of Markov blankets and their use in\nthe FEP. We then consider core elements of reinforcement learning, systems identification theory, and macroscopic\nphysics discovery, mapping two notions of systems equivalence onto the statistics of Markov blankets, and discussing\nlimitations. Following this, we return to Markov blankets under the FEP and discuss the mathematics of static and\ndynamic Markov blankets. We then present the Markov blanket detection algorithm and examine numerical work\napplying it to simple systems. We conclude with a discussion of implications of this work for the FEP broadly and\ndirections for future work. We argue that the statistics of Markov blankets as formulated in the FEP literature provide\nus with the mathematical apparatus needed to establish the notion of an “ontological potential function,” i.e., a function\nthat rigorously defines object types via boundary constraints.\n2\nThe free energy principle: Core elements\n2.1\nMarkov blankets in the formulation of the free energy principle\nAt a high level, the standard formulation of the FEP starts from the equations of statistical physics, with Markov blanket\nstructure imposed. The notion of a Markov blanket was originally introduced by Pearl [33] as a means of identifying\nthe complete set of random variables that impact inference regarding the value of a given set of “internal” random\nvariables.1 Pragmatically, knowledge of a Markov blanket for each node in a graphical model can be used to identify\nthe structure of message passing algorithms used for efficient probabilistic inference. The property is inherited directly\nfrom the definition of a Markov blanket of set of “internal” random variables z ⊂X as set b ⊂X such that z ⊥s|b,\nwhere s is the complement of the union of z and b, or equivalently:\np(s, z|b) = p(s|b)p(z|b)\n(1)\nIn a directed graphical model, the Markov blanket of a set of nodes Z consists of all the parents of the nodes in Z,\nall the children of nodes in Z, and all the parents of the children of the nodes in Z. This establishes a conditional\nindependence relationship between nodes in Z and all of the other nodes not in the blanket of B, i.e. S = (Z ∪B)c,\nwhere the superscript c denotes the complement,\np(z|b)\n=\np(z|s, b)\n(2)\np(s|b)\n=\np(s|z, b)\n(3)\nwhere the lowercase refers to the values of the random variables in the corresponding set.\nIn the FEP, this Markov blanket structure is realized by assuming that the dynamics of a microscopic system can be\npartitioned into three subsets of variables: internal variables (z), boundary variables (b), and external or environmental\nvariables (s), such that:\nds\ndt = fs(s, b) + ηs\n(4)\ndb\ndt = fb(s, b, z) + ηb\n(5)\ndz\ndt = fz(b, z) + ηz\n(6)\nwhere the η’s indicate noise that is independent across the s, b, z variables. This results in the desired posterior\nprobability distribution over trajectories or paths (indicated by subscript τ):\np(sτ, zτ|bτ)p(bτ) = p(sτ|bτ)p(zτ|bτ)p(bτ)\n(7)\n1Note that here we are using Markov blanket and Markov boundary interchangeably. In some parts of the literature, a Markov\nblanket refers to any set that establishes the desired conditional independence structure, while the Markov boundary is the minimal\nset. [33]\n4\n\n\nA PREPRINT - MARCH 3, 2025\nConditional independence follows from the absence of any direct causal interaction between s and z, but can be\nintuitively understood as resulting from that fact that, if the path bτ is observed, then it can be treated as a known driving\nforce to two independent subsystems. It is important to note that the Markov blanket associated with this system applies\nto paths (i.e., to the time evolution or trajectory of a system), and not to steady state distributions. Also important to\nnote is that dynamical systems that have blanket structure (i.e., that conform to Eq. 6) do not generally result in steady\nstate distributions that also have blanket structure. See [15] for some exceptions to this general rule.\nThe link between the Markov blanket and subsystem or object type also follows directly from the conditional inde-\npendence relationship. This is because two objects whose boundaries follow the same path must, by definition, have\nthe same effect on the environment, regardless of the details of their internal dynamics. As a result, one can define an\nobject type by the path statistics of a Markov blanket. See also [42]. Crucially, we note that this statistical definition of\nobject type is consistent with the definition of object type used in systems identification theory, which is standard in\nreinforcement learning. This is because the blanket statistics fully characterize the interactions between a subsystem and\nits environment, and thus, include both the inputs and outputs of the subsystem. As such, two objects with very different\ninternal structure and states, but with the same boundary statistics, will also have the same input-output relationship and\nwill interact with their environment in precisely the same way. This is trivially observed in the simple case where one\ncan partition the blanket into active states that directly influence the external variables and sensory states that directly\ninfluence the internal variables, i.e. b = {a, o}. In this case, straightforward application of Bayes rule to the Markov\nblanket based definition of object type, p(bτ) = p(aτ, oτ), allows for the direct computation of p(at|oτ<t), which we\nrecognize as the agent’s policy or the subsystem’s response function.\nIt is worth noting that this Markov-blanket-statistics-based formulation of systems equivalence offers a more complete\ndescription than the one from systems identification, in that it contains more than just the policy of the agent or object\nin question. This is because the equations are symmetric and so the blanket statistics also encode the “policy” of\nthe external system, p(ot|aτ<t). This makes it clear that the Markov-blanket-based definition of an object type is\nenvironment-specific.\n(a) ’Actual’\n(b) Equivalent\nFigure 1: The Markov blanket definition of object equivalence. The relationship between the boundary (green) and\nenvironment (red) are fixed. The objects are equivalent if replacing the internal variables (blue) and their connections to\nthe boundary with some other set of variables and connections without affecting the distribution of boundary paths,\np(bτ).\n2.2\nThe maximum caliber route to an ontological potential function\nThe utility of any definition lies in its predictive power. Here, we show that, when combined with Jaynes’ principle\nof maximum caliber [23, 10, 31], this blanket statistics based definition of an object leads directly to an “ontological\npotential function” that formalizes the notion object type in terms of the macroscopic rules of behavior necessary to\ninstantiate an object of a given type, where type is defined by blanket statistics [41, 36]. That is, given path statistics on\na Markov blanket, p(btau), Jaynes’ principle can be used to identify an energy function and associated Lagrangian\nthat specify the dynamics of the environment, boundary, and object variables that give rise to an object of that type.\nThis is consistent with the notion of system typing used in physics, wherein physical systems are defined by the energy\nfunctions or stationary actions that they minimize. (For a similar argument based on the maximum entropy principle, see\n[27].) Here, we show that boundary statistics lead directly to an object-specific energy function, an ontological potential\nfunction that corresponds to the generalized free energy and associated Lagrangian. This closes the gap between the\nMarkov blanket based definition of an object type and the notion of type used in statistical physics and leads naturally\nto a typology of systems based on statistical constraints imposed on their Markov blankets [37].\n5\n\n\nA PREPRINT - MARCH 3, 2025\nThe objective function that one obtains from combining blanket statistics with Jaynes’ principle of maximum caliber is\nprecisely the free energy, providing the basis for an alternative derivation of the FEP. To this end we take inspiration\nfrom recent derivations of statistics physics from purely information theoretic considerations [31, 10], and impose\nboundary constraints within the maximum caliber framework. We show that this ultimately results in a free energy\nminimization problem, consistent with the core elements of the path based formulation of the FEP [36]. Jaynes’\nprinciple of maximum caliber is an information theoretic formulation that extends the constrained maximum entropy\napproach [24] to the space of paths or trajectories through state space. This information theoretic approach is commonly\nused in statistical inference, to determine the most parsimonious model of some data; where we maximize entropy or\ncaliber under constraint derived from data or known physical laws [23]. More recently, Jaynes’ principle applied to\npaths through state space has been shown to provide an information theoretic foundation upon which one can derive the\nequations upon which physics is based; that is, given an appropriately chosen set of constraints, optimizing Jaynes’\ncaliber objective leads directly to all the core equations of classical, statistical, and quantum physics in such a way\nthat the deep relationships between action, energy, work, and heat (Hamiltonian or Lagrangian functions) are made\nplain [10, 31]. It can also be used to directly derive powerful theorems in non-equilibrium statistical physics, including\nCrook’s theorem, Noether’s theorem, the Jarzynski inequality, and the second law of thermodynamics itself [31, 22, 19].\nThe near uniform applicability of Jaynes’ maximum caliber principle, when combined with the blanket-statistics-based\ndefinition of an object type allows us to incorporate non-stationary and non-ergodic systems into the FEP modeling\nframework, something that had seemed difficult to model using previous formulations (see [6, 35, 11, 30]). As we\nwill see, this flexibility will allow us to define—and ultimately discover, in a data-driven manner—the dynamic or\nwandering Markov blankets that are required to model non-stationary, changing, and mobile things such as flames,\nlightning bolts, and traveling waves, as well as objects that exchange matter with their environments.\n2.2.1\nJaynes’ principle and ontological potential functions\nMathematically, maximum caliber begins with a probabilistic, and often coarse, characterization of the laws of physics,\np( ˙x, x, t). It then supposes that we have additional information about how a particular system works, which is given by\ncertain constraints that take the form of time dependent expectations\nF(t) = ⟨f( ˙x, x, t)⟩\n(8)\nThese expectations provide “instantaneous” constraints and, when combined with prior knowledge of dynamics,\neffectively define a system type. For example, stationary geometric constraints < f(x) >= C, ∀t lead to the traditional\npotential function of classical mechanics, while the kinetic term arises from Newton’s laws, as expressed via p( ˙x, x, t).\nA probability law q( ˙x, x, t) associated with that system type is then obtained by maximizing the relative path entropy,\nwith the constraints enforced by Lagrange multipliers, λ(t), i.e.\nS[q(·), λ] = −KL(q( ˙x, x, t), p( ˙x, x, t)) −\n\u001cZ\nλ(t) · f( ˙x, x, t)dt\n\u001d\nq(·)\n(9)\nalong with the unstated additional constraint that q(·) is a well-defined probability distribution, i.e. the integral over all\npaths is 1. Written in terms of the Lagrange multipliers, optimization of S[·] results in\nq( ˙x, x, t) =\n1\nZ[λ(t)]p( ˙x, x, t) exp\n\u0012\n−\nZ\nλ(t) · f( ˙x, x, t)\n\u0013\n(10)\nwhere the path entropy at the maxima is given by\nSmax\n=\nlog Z[λ(t)] +\nZ\nλ(t) · F(t)dt\n(11)\nEntropy\n=\n−Free energy + Energy\n(12)\nwith associated dimensionless Lagrangian and action:\nL( ˙x, x, t) = log p( ˙x, x, t) + λ(t)f( ˙x, x, t)\n(13)\nA [xτ] =\nZ\ndtL(x, ˙x; t)\n(14)\n6\n\n\nA PREPRINT - MARCH 3, 2025\nThis relationship between expected energy, entropy, and free energy allows us to cast the maximization of caliber as a\nfree energy minimization, consistent with recent formulations of the FEP [16]. Moreover, armed with the Lagrangian,\none directly obtains the associated Hamiltonian with the interpretation that Hamiltonian dynamics yield the most\nprobable path [10]. Constraints that are also independent of time coupled with the assumption of time translation\nsymmetry leads directly to constant λ and the identification of a conserved energy (λ · F).\nCritically, we can interpret this log partition function form of free energy as a potential function, the partial derivatives\nof which result in generalized notions of heat and work [31]. In this maximum caliber framework, it is the constraints\nthat ultimately lead to this potential function, as well as that Langevin and Hamiltonian dynamics that define physical\nsystems. This implies that the constraints themselves can be thought of as defining system type. For this reason, we\nconclude that this free energy functional is an ontological potential function for noisy dynamical systems, and a central\ncomponent of a generic definition of “every” “thing.”\n2.2.2\nThe Markov blankets of “every” “thing”\nWhat the FEP approach adds to Jaynes’ principle of maximum caliber is a physical definition of the boundary of “every”\n“thing.” That is, the FEP adds to maximum caliber a way of representing the notion that boundaries are not fictive (e.g.,\nmere flux relations between volumes), but rather, that they correspond to distinct, seperable objects. This is inherited\nfrom the notion that subsystems are defined by boundary or blanket constraints.\nCombining the notion of an ontological potential function, as defined above, with the Markov blanket definition of a\nsubsystem type leads directly to a simple definition of a subsystem or “object” or “thing” in a given environment:\nMaximum caliber definition of an object\n1. A time dependent set or manifold B ⊂X ⊗T, parameterized by ΩB(t) ⊂X that maintains Markov\nblanket structure with respect to the prior on unconstrained dynamics p(x, ˙x)\n2. A set of instantaneous constraints applied to both the set ΩB(t) and the elements of x ∈ΩB(t)\nIt is easy to show that imposing blanket constraints does not disrupt the conditional independence structure inherited\nfrom the prior dynamics. While it is possible to enforce the constraint that a particular p(bτ) be realized directly[10],\nwe find it more intuitive to re-represent the blanket distribution by a (possibly infinite) set of instantaneous constraints\non expectations. Of course, the constraints needed to represent an arbitrary p(bτ) are not necessarily the kind of\n“instantaneous” constraints that are typically used with the maximum caliber objective. Instantaneous constraints,\nhowever, are preferred because they lead to causal dynamics and are therefore considered “physically realizable.” We\nrestrict ourselves to this class of instantaneous constraints by defining a time-dependent blanket, ΩB(t) ⊂X, and\nimposing constraints of the form\nFB(t) =\n\nfB( ˙x, x, t, ΩB(t)|x∈ΩB(t)\n\u000b\n(15)\nNote that when applied to a blanket that is a manifold, geometric constraints simply add an additional flux term to\nthe associated Langevin equations, but do not otherwise change their structure. This arises from the time derivative\nof the indicator function that restricts boundary constraints to elements in the boundary. This is true regardless of\nwhether or not the blanket is connected or persists for any length of time. Note also that judicious choice of constraint\nfunctions, fB(·), can be used to place constraints on the shape and evolution of the manifold ΩB(t). The flexibility of\nthis approach follows from the fact that the boundary ΩB(t) can be either specified or treated as a random variable with\nsupport on the set of Markov blankets specified by the prior p(·).\nBefore moving on, we note some connections to systems identification and reinforcement learning. As previously shown,\nequivalence of Markov blanket statistics implies policy equivalence. In reinforcement learning, this is often referred to\nas strong equivalence between two agents. Since policies can be derived from the blanket statistics, equivalence of\nMarkov blanket statistics implies policy equivalence; and therefore, agents that share Markov blanket statistics are\nagents of the same type. Reinforcement learning also has a notion of weak equivalence that is associated with agents\nthat achieve the same reward rate. In an infinite horizon setting, with a reward function that only depends on actions\nand outcomes, agents that are defined by stationary boundary statistics necessarily achieve the same reward rate. The\nconverse is also true: namely, agents with the same stationary boundary statistics have the same reward function, under\nthe assumptions imposed by the maximum entropy inverse reinforcement learning paradigm [49, 45]. This means that\nweakly equivalent agents are associated with constraints on the stationary distribution of the boundary, ˜p(b). A more\ndirect link to reinforcement learning can also be seen by noting the link between Jaynes’ maximum caliber objective\nand that of KL control theory [26, 12]. This makes it plain that the Markov blanket statistics based notion of object\n7\n\n\nA PREPRINT - MARCH 3, 2025\ntype and associated ontological potential function subsumes the relevant notions of systems equivalence used in both\nsystems identification and contemporary reinforcement learning.\nIn short, this maximum caliber, blanket-statistics-based definition of object type has the desired property that it is widely\napplicable, consistent with systems identification theory, and associated with a consistent objective function, namely,\nthe free energy. While the specific details of the constraints imposed by FB indicate an object’s particular type, gross\nproperties of the constraint functions themselves can be used to classify different kinds of objects. It also suggests the\npossibility of developing a taxonomy of different object types based on the domain of the blanket and the kinds of\n“ontological” or object-type-specific constraints imposed. For example, it is standard in the statistical physics literature\nto refer to constraints that only depend upon x as geometric constraints. The approach outlined here elucidates at least\nthree degrees of freedom along which constraints can be defined: the shape or topology of the boundary ΩB(t), the\ndynamics of the boundary, and the statistics of the boundary. For example, the boundary of a cell is, topologically\nspeaking, a spherical surface that is dynamic because it exchanges matter with its environment, and that has stationary\nboundary statistics to the extent that achieves homeostasis in its environment. A rigid body, on the other hand, has no\ninternal states per se, and thus has a spherical “boundary” that is static in the sense that it does not change shape, but\ndynamic in the sense that it can move.\n2.3\nA simple example: the flame\nA common criticism of the Markov blanket definition of a “thing” has been that this definition does not apply to flames\n[30, 35]. This misconception results from the false assumption that Markov blankets must be static or tied to matter.\nHowever, the formalism presented here neatly captures flames and other traveling waves, due to the flexibility endowed\nvia a consideration of dynamic boundaries.\nFor example, consider a simple flame burning down a one dimensional fuse as an unsteady traveling wave (we provide\na numerical example in the following sections). Here, we will define the boundary to be the point that separates burned\nfrom unburned regions, yb(t). The constraint we will impose is that the temperature at this point should correspond to\nthe ignition temperature of the exothermic chemical reaction that drives the flame\nθig =\n\u001cZ\ndy′δ(y′ −yb(t))T(y′, t)\n\u001d\n(16)\nImplementing this constraint results in a Lagrangian and maximum a posteriori (MAP) estimate of temperature given\nby:\nL(T, ˙T, ∇2T, yb(t), t) = log p(·) + λ(t)\nZ\ndy′δ(y′ −yb(t))T(y′, t)\n(17)\n\u0012 ∂\n∂t −∂2\n∂y2 + h\n\u0013\nTmap = σ2\npλ(t)δ(y −yb(t))\n(18)\nThus, the imposition of the constraint results in a point heat source at the boundary, with magnitude proportional to the\nLagrange multiplier that implements the constraint. Here, σ2\np represents the variance of the deviation from a prior that\nfavors the heat equation for a 1 dimensional solid subject to Newton’s law of cooling. Recall that energy is given by the\nconstraint:\nR\ndtλ(t)θig allowing for the interpretation of λ(t) as the energy that must be injected into the system in\norder to keep the flame moving at a specified velocity ˙yf(t).\nWhile this example illustrates how constraints and boundaries can work together to lead to consistent and sensible\ndynamics, it is not quite what we would like. Ideally, we would like a probability distribution over paths that includes a\ndistribution over the boundary location and state. This requires a prior that operates on the location of the boundary, and\nthat in general can include additional constraints. This allows us to treat yb(t) in the same way as T(y, t), resulting in\nan expansion of the set of equations that must be simultaneously solved in order to determine MAP dynamics for both\ntemperature and flame speed. For example, if we assume a priori that the flame speed is normally distributed, then we\nacquire an additional Euler-Lagrange equation that relates flame speed fluctuations to heat release and temperature flux\nat the boundary:\nd2\ndt2 yb(t) = σ2\nybλ(t) ∂\n∂y Tmap(yb(t), t).\n(19)\n8\n\n\nA PREPRINT - MARCH 3, 2025\n2.4\nSummary so far\nIn practice, how do you use an ontological potential function? We begin by specifying a physics via a prior on dynamics\np( ˙x, x, t), and we then specify the statistical properties of a boundary via constraints. The dynamical system that results\nfrom this specification is guaranteed to give rise to the kind of object specified by the boundary statistics. This can be\ninterpreted as answering the questions: (1) how must microscopic elements (both internal and external to the subsystem)\norganize themselves, or (2) how must energy be injected into and dissipated by the system, in order to instantiate a\nboundary of the specified type.2\nHowever, this method of instantiating the desired object still does not allow us to determine which particular subsets of\na given dynamical system system should qualify as an object. It only tells us something about systems that support\nparticular kinds of objects that we have already identified. Indeed, despite their utility, all the methods just reviewed do\nnot adequately address the problem of subsystem identification and typification, precisely because the boundaries are\neffectively user defined.\nHaving established that sensible boundaries correspond to Markov blankets, it is tempting to conclude that any collection\nof elements that has a Markov blanket corresponds to an object. Unfortunately, the definition of a Markov blanket is too\nexpansive to be of practical use, since every snapshot of every microscopic element has a blanket (Fig 2a); see [6] for\ncritical discussion. For this reason, much of the FEP literature has adopted the additional principle for “thing-ness”:\nnamely, stationarity [9]. That is, the blanket and object must be a proper subset of the system as a whole, and the\nelements that make up the blanket and object must not change with time [15]. This assumption eliminates an arbitrary\nfluid element from consideration, since matter can freely pass into and out of the element. As it does, the matter\ntransitions from being inside to outside the object by passing through the blanket, and thus, the blanket is not stationary\nwith respect to the elements that make up the fluid. But this rules out the possibility of modeling all sorts of interesting\nsystems, indeed perhaps the most interesting ones, which have dynamic boundaries and which experience material\nturnover.\nHere, we argue that this stationary formulation of boundaries is both too restrictive and not restrictive enough for our\npurposes. On the one hand, it is too restrictive, because blanket stationarity prohibits one from concluding that a flame,\nor any traveling wave, for that matter, is an object. This is because the elements of the medium that make up a traveling\nwave change as the wave moves through matter. On the other hand, it is not restrictive enough, because it implies that\nany arbitrary connected subset of elements correspond to an object. In the flame example above, this means that any\nsegment of the original fuse, down which the flame burns, must count as a thing, independent of the temperature profile,\nreaction rate, and their dynamics.\nWhat this example makes clear is that a more general definition of an object or thing should be able to accommodate\nthe notion of a blanket that can move or change, and should incorporate some aspects of the dynamics of the system\nas a whole. Moreover, the inclusion of dynamic blankets results in a massive expansion of the number of blankets\npresent in any given system. It is clear that what is needed is an additional principle that allows us to select those\nblankets that correspond to the things that we would like to call things. Since the goal is to sensibly carve the world at\nits joints, an obvious choice for such a principle is Occam’s razor, applied to the global dynamics. We implement this\nnew principle by seeking low-dimensional dynamical systems with dynamic Markov blanket structure and employ a\nBayesian modeling approach to instantiate Occam’s razor.\n3\nA dynamic Markov blanket detection algorithm\nWe now present, in general form, a probabilistic generative model with dynamic Markov blanket structure that can be\ninverted to identify Markov blankets and well as classify objects into types according to their blanket statistics and\ndynamics. Markov blanket detection is, in general, a difficult problem. Even in static settings, it is NP-hard [18, 48].\nThis is because, even in a situation where the blankets are stationary, the number of Markov blankets in a given system\ngrows combinatorially with the number of system components. Allowing for blankets to be dynamic only makes things\nworse.\nWe sidestep this issue by taking inspiration from macroscopic physical discovery, which focuses on discovering low-\ndimensional dynamics that summarize high-dimensional systems. Specifically, we propose a class of dimensionality\nreduction algorithms that partition high-dimensional dynamical systems into subsystems that have Markov blanket\nstructure. This is accomplished via the presumption that low-dimensional latent dynamics have Markov blanket structure\nand that each element in the original high-dimensional observation space is driven by just one of the low-dimensional\n2Of course, the dynamics obtained thereby are not unique: There might indeed be lower entropy solutions. However, the one\nobtained via this maximum caliber approach can be guaranteed to be the most general.\n9\n\n\nA PREPRINT - MARCH 3, 2025\n(a) Fundamental blanket\nSpace\nTime\n(b) Static blanket\nSpace\nTime\n(c) Disconnected blanket\nSpace\nTime\n(d) Moving blanket\nSpace\nTime\nFigure 2: In a spatially connected domain with nearest neighbor connectivity, the blanket of a single node at time t\n(a) consists of its parents (the three adjacent nodes at the previous time step), its children (the three adjacent nodes at\nthe next time step), and its co-parents (which consist of the two nodes immediately to the left and right). This implies\nthat gradients can always be computed on the boundary. A static or stationary blanket (b) is defined as having a spatial\nlocation that does not change. The intersection of any two blankets makes up blanket allowing for blankets to be\ndisconnected (c). Traveling waves are associated with moving blankets (d). All of these blankets (and many, many\nmore) are present solely by virtue of the topology of the network independent of its dynamics.\n10\n\n\nA PREPRINT - MARCH 3, 2025\nlatents. For example, in the case where a single object is assumed to be present, we seek a set of state variables that\nrepresents the environment (s) and two sets of state variables for each object: one that summarizes the collective\nbehavior of the elements that belong to the boundary (b) and another that describes the collective behavior of the\nelements that are inside the boundary (z). We leave open the possibility that the set of internal elements may be empty.\nWe design enough flexibility into the model to discover objects that have non-stationary blankets by directly modeling\nthe boundary, ΣB(t), as a latent assignment variable. This is accomplished by instantiating a dynamic attention\nmechanism that probabilistically assigns a label to each microscopic element or measurement. These labels indicate\nwhether that element is an internal, external, or blanket element. Transitions between these labels obey the usual rules\nfor Markov blankets, i.e., label transitions from internal to external are prohibited and label transition probabilities\ndepend only on the macroscopic blanket variables. When multiple objects are present, we allow for the possibility that\nthere are a set of macroscopic variable for the boundary of each object (bn) as well as its internal state (zn), n = 1 · · · N\nand a single environment variable s. Observed data, denoted yi(t) ∈RD, are assumed to be a relatively fine-grained\nmeasurement of the activity. Associated with each observation index i is one of the discrete time dependent labels\nωi(t) ∈{S, Bn, Zn}. These labels identify the boundary of each object and determine which of the macroscopic\nvariables influences the associated microscopic observation. Specifically, the label associated with each measurement\ndetermines the conditional independence relationship:\np (yi(t)|ωi(t) = Zn, s(t), {b(nt), zn(t)}) = p (yi(t)|ωi(t) = Zn, zn(t))\n(20)\nwith similar equations holding for the cases where ωi(t) is S or Bn. Though written in generative form, this observation\nmodel corresponds to a noisy non-linear projection from observations to target macroscopic variables, modulated by the\nassignment variables. The dynamics of both the macroscopic variables and the transition probabilities of the assignment\nvariables are constrained to obey Markov blanket structure, with the added restriction that the transition probabilities for\nthe labels depend only on the boundary variables.\ndpi\ndt = T({bn})pi\n(21)\nwhere T(·) is a 1+2n x 1+2n matrix, constrained such that TSZn({bn} = TZnS({bn}) = 0 prohibiting element labels\nfrom transitioning directly from object to environment. Similarly, the dynamics of the latent variables are constrained\nsuch that the Jacobian of the global dynamics only allows zn-bn and bn-s interactions. See Fig. 3a.\nThis constitutes the general form of this kind class of blanket discovery algorithms. In order to convert this general\ndynamic Markov blanket model into a more tractable form, a few additional simplifying assumptions are required. For\nexample, non-linear dynamics could be implemented via recurrent switching dynamics system and discovered through\nvariational inference[29] or specified by a neural network and learned via gradient descent[34]. Here, we will assume\nsimple linear dynamics and instantiate the non-linear observational model using a switching linear transform. We will\nalso assume that transition probabilities for the assignment variables are a priori independent of the macroscopic latents.\nThis leads to a factorial Hidden Markov Model (HMM) that mixes discrete and continuous latent variables, with the\nunique feature that the labels associated with every observational node i has its own discrete HMM. See Fig. 4.\nFor a single object this linear model is given by\ns′, b′, z′|s, b, z\n∼\nNormal (A[s, b, z] + B, Σsbz)\n(22)\nω′\ni\n∼\nCategorical (Tωi)\n(23)\nyi\n∼\nNormal (Cωi[s, b, z] + Dωi, Σωi)\n(24)\nwhere the matrix A is constrained to have Markov blanket structure by placing blocks of zeros in the upper right and\nlower left corners. Similarly, the means of CS, CB, and CZ are constrained to have blocks of zeros so that observations\nonly depend upon one of the three continuous latents. These constraints are imposed on the mean via the action of\nLagrange multipliers. We reduce the degeneracy of the model by assuming that Σsbz is diagonal, with unit trace\nimposed on the posterior mean, also via the action of Lagrange multipliers. This further encourages the discovery of\nlow-dimensional macroscopic dynamics via the action of the automatic Occam‘s razor effect of Bayesian inference.\nIn order to model the non-linear observation model, we expand the domain of the discrete latent assignment variables to\ninclude “roles” associated with each of the labels, S, B, Z. This effectively instantiates a hierarchical hidden Markov\nmodel (HHMM) for the label assignment variables, where the blanket structure is enforced at the highest level of the\nhierarchy, and the lowest level represents a mixture of linear experts model to describe the relationship between the\n11\n\n\nA PREPRINT - MARCH 3, 2025\n(a) Transition matrix (A or T)\n(b) Observation tensor B[:, roles, latents]\nFigure 3: (a) Constraints on transition matrices and observation tensors for N = 3 objects. (b) The observation model,\nunder the assumption that there are 4 roles per latent and a 4 dimensions in each observation vector yi(t).\ntargeted macroscopic variable and the observation. This is depicted in Fig. 3b. Note that we could have used the\nsame trick for the dynamics, effectively implementing a recurrent switching dynamical system, but rationalized linear\ndynamics with a non-linear observation model, as an instantiation of the Koopman embedding trick [28]\n3.1\nInference and learning\nWe approximate Bayesian inference using variational Bayesian expectation maximization (VBEM), with a posterior\nthat factorizes over parameters and the two classes of latents, i.e.\nq(s, b, z, ω, Θ) = qsbz(s, b, z)qω(ω)qΘ(Θ)\n(25)\nwhere Θ = {A, B, Cω, Dω, Σ−1\nsbz, Σ−1\nS,B,Z, T}. This leads to an inference algorithm that iteratively updates qsbz(s, b, z)\nand qω(ω) until convergence, i.e.,\nlog qω(ω)\n=\n⟨log p(s, b, z, ω|Θ)⟩p(s,b,z)p(Θ)\n(26)\nlog qsbz(s, b, z)\n=\n⟨log p(s, b, z, ω|Θ)⟩p(ω)p(Θ)\n(27)\nThis follows the attend, infer, repeat (AIR) paradigm [14], where the posterior updates over the assignment variable\ntrajectories, ωi(t), corresponds to the attentional update, which is then followed by jointly inferring s, b, and z, and\nthen repeating prior to updating the posterior distributions over the parameters. Note that unrolling these two steps into\na neural network implementation leads to a variation on the powerful transformer architecture [46], but with added\nstructure that ties attention variables across layers of the network implementation.\nNote that we do not factorize qsbz(·) or qω(·) over time, but instead implement a forward-backward scheme that\nperforms exact computation of the posterior distribution over the latent variables[3]. Conditional conjugacy allows us\nto use a matrix normal gamma distribution for q(A, B, Σ−1), a matrix normal inverse Wishart for q(Cω, Dω, Σ−1\nω ),\nDirichlet for rows of T, and normal inverse Wishart distributions and Dirichlet distributions for the relevant initial\nconditions. Coordinate update rules for the natural parameters of the posteriors over Θ were augmented by a learning\nrate parameter, typically set to 0.5, in order to enable parameter learning on minibatches of trajectories and reap the\nbenefits of stochastic natural gradient descent [25].\n12\n\n\nA PREPRINT - MARCH 3, 2025\nst\nbt\nzt\nyt\ni\nωt\ni\nst−1\nbt−1\nzt−1\nyt−1\ni\nωt−1\ni\nst+1\nbt+1\nzt+1\nyt+1\ni\nωt+1\ni\ni = 1, 2, . . . , N\nFigure 4: Generative model for factorial hidden Markov model with Markov blanket structure. The dashed lines\ndetermine how the macroscopic blanket variables affects the evolution of the blanket labels. This breaks the factorial\nstructure, increasing the complexity of inference. However, when simulating data for algorithm testing purposes, these\nconnections help maintain the stability or permanence of objects.\n4\nResults\nWe present simple numerical experiments that demonstrate how a dynamic Markov blanket detection algorithm sensibly\nlabels the components of Newton’s cradle, a burning fuse, the Lorenz attractor, and an artificial life simulation. Inference\nand learning for this model are implemented using a custom message passing framework, specifically designed to\nexploit conditional conjugacy and stochastic coordinate ascent [21]. The code for the dynamic Markov blanket\ndetection algorithm and the VBEM inference modules upon which it is built can be found at https://github.com/\nbayesianempirimancer/pyDMBD. All simulations are trained on the complete data set, with a learning rate set to\n0.5 for 50 training epochs. This is done a minimum of 10 times. Results shown are from the computational run that\nachieves the largest expected lower bound (ELBO) on the log likelihood.\n4.1\nNewton’s cradle\nThe simulation of Newton’s cradle consists of 5 balls of equal size and shape that are suspended from strings, which are\nseparated by a distance equal to the diameter of any ball. At rest, the balls hang together, just barely touching. When the\nleftmost ball is given an initial position away from the other 4, it swings down, halts its motion at its resting position,\nand transfers its momentum through to the other balls. These move in sequence and similarly transfer their momentum\nup to the rightmost ball, which this swings up and away; before returning, and repeating the process. If two balls are\ninitially perturbed, then two balls will pop out the other side, and so on. We simulate a Newton’s cradle with either zero,\none, two, or three balls initially perturbed by the same randomly selected angle between 0 and 3π/2. All the balls are\nthen randomly perturbed by a small angle difference, with standard deviation 0.1 radians.\n13\n\n\nA PREPRINT - MARCH 3, 2025\nApplied to this data set, a static Markov blanket detection algorithm based upon exerted forces [15] discovers a single\nobject, centered on the middle ball, regardless of the dynamics of the system, and without regard for the number of\ninitially displaced balls. In contrast, the dynamic Markov blanket detection algorithm labels the balls in a manner that is\nconsistent with human intuition: that is, we tend to perceive Newton’s cradle dynamics as either as a pendulum or as a\nset pair of interacting sets of balls, one on the left and one on the right. These two common precepts map precisely onto\nthe two most commonly discovered partition discovered by this simple DMBD algorithm. Specifically, Fig. 5 depicts\nthese two solutions, where color indicates label, with green for boundary, and red and blue for object and environment.\nIf two balls or more balls are initially perturbed, then the balls that move together are always given the same assignment.\nThe most commonly discovered solution (Fig. 5(a-c)) labels the object as the moving balls, regardless of which side of\nthe cradle they are on. In this case, the environment label is assigned to the more or less stationary balls. The boundary\nconsists of the balls that very briefly obtain high velocity due to collision. As a result, the boundary is not physically\nrealised most of the time. The second most commonly identified partition locates the boundary as the stationary balls,\nand labels the object and environment as the moving balls. The ball on one side is always labeled environment and the\nball on the other side is labeled object. See Fig 5(d-f). Once again, when the leftmost or rightmost balls are more or less\nstationary, they become part of the boundary.\n(a) The object (blue) starts on the right\n(b) A collision creates a blanket\n(c) The object emerges on the left\n(d) The object (blue) starts on the right\n(e) The ball is absorbed into the blanket\n(f) The environment emerges on the left\nFigure 5: Newton’s Cradle. In (a-c), the ball that makes up the object (blue) collides with the environment (red). Since\nthe force transmitted must pass through the boundary, the dynamic Markov blanket discovery algorithm labels the\nballs on the periphery as temporarily becoming part of the blanket. The momentum is then passed through to the balls\nthat make up the environment, and is transferred to the ball on the left, which also temporarily becomes part of the\nblanket, before emerging as the object on the other side. In (d-f), we see another common solution to this problem\nthat is discovered by the dynamic Markov blanket discovery algorithm. In that solution, the blanket consists of the\nstationary balls. When energy is transferred to the ball on the right, it is part of the object. When energy is transferred\nto the ball on the left, it is part of the environment.\n4.2\nA burning fuse\nTo demonstrate how this approach can handle flames and traveling waves, we model a combustion front traveling down\na one dimensional medium, i.e., a burning fuse. The fuse is modeled as an in-homogeneous medium composed of\ndiscrete fuel particles separated by a random distance, with unit mean and variance of 0.02. An oxidizer is modeled\nas a diffusive process with an inexhaustible source, orthogonal to the fuse. Its effect on combustion is to determine\nthe rate of heat release. Ignition occurs when the particle reaches a critical temperature. The fuse is assumed have\nconstant thermal diffusivity of 1. We select this toy model because it is known to support traveling waves that propagate\nsmoothly, periodically, or chaotically, even in the absence of random perturbations to fuel particle size, location, and\noxidizer availability [4]. Here, the observable variables, yt\ni consist of the fuel and oxidizer concentrations, as well as\nthe temperature at each location on the fuse, i. Broadly speaking, ahead of the combustion front, fuel and oxidizer are\nplentiful; and behind the combustion front, fuel is absent but oxidizer is plentiful. Inside the combustion front, fuel\nrapidly drops to zero, oxidizer dips and then returns to a level that corresponds to its current availability, and heat is\nreleased (See Fig. 8a). We simulate a variety of combustion waves by systematically varying the fuel availability as\na function of location and the oxidizer availability as a function of time. The conjunction of these parameters drives\n14\n\n\nA PREPRINT - MARCH 3, 2025\n(a) Case 1: Middle balls correspond to the environment and\nmoving balls is the environment. During transition of the\nobject from the left to the right side, there is a brief period\nwhen the boundary appears associated with impacts.\n(b) Case 2: The stationary balls are assigned to the boundary.\nWhen the moving ball is on the left, it is labeled as the\nenvironment; and when the moving ball is on the right, it is\nlabeled as the object.\nFigure 6: The principal component is computed independently for the most likely path taken for each of the 4\ndimensional latents: s, b, z. The dynamics of the latent assignments for each ball are summarized by the total number of\nballs assigned to the environment, blanket, and object. Note that the macroscopic latent variables are highly correlated\nand persist even when they lack physical realization via assignment to a ball. This is consistent with the notion that\ninternal (and blanket) variables maintain a representation of the environment, consistent with Bayesian mechanics.\nvariability in rate of heat released as the fuel particles burned. We also manipulate the ignition temperature across a\nsmall range of values (0.4, 0.5). This leads to combustion waves that travel at different average speeds, with a range of\nperiodic or random fluctuations. Some combustion waves also go extinct. Fig. 8(b) shows an example of a wave that\nhas periodic fluctuations in wave speed. Curiously, the internal variable shows little correlation with object position and\nseems to only represent heat release 9. In contrast, it is the environmental variable that is most strongly correlated with\nflame position. For completeness, we note that while the results shown here are the most common result, the algorithm\nsometimes converges on less sensible solutions. For example, the object sometimes corresponds to the burned portion\nbehind the combustion wave and the boundary sometimes corresponds to the region in which heat is released. The\nsolutions previously described, however, are associated with the greatest ELBOs and so are strongly preferred by a\nBayesian model comparison.\n4.3\nLorenz attractor\nThe Lornez attractor also provides a unique test bed for this approach. In this case, there is a single 3 dimensional\nobservation, the x, y, z position of the object. The chaotic dynamics of the system supports two low (∼2) dimensional\nattractors and global dynamics that switch between the attracting manifolds. Here, the algorithm discovers what could\nbe called a phase transition, by labeling the observation as part of the “object” when it is near to the attractor on the left\nand part of the ”environment” when it is near to attractor on the right. The boundary label is sensibly associated with\nthe part of the trajectory that describes the transition between the two attractors. Because of the symmetry associated\nwith object and environment, we could interpret this as modeling a phase transition in which an single object changes\nidentity after passing through a phase transition boundary.\n4.4\nSynthetic biology simulation\nFor a final example, we use Particle Lenia to simulate a self-organizing system that exhibit cell-like structure and\nbehavior. We use the “rotator” example [7] for the simulation. Individual particles are characterized by different\ndistance-dependent attraction and repulsion functions. This leads to interesting self-organizing behavior depicted in Fig.\n11, which shows an initially random soup of particles quickly that forms into a cell-like object, with a “nucleus” and\nsimple “cell membrane.” After some time, the membrane develops rotating flagella-like structures, and the nucleus\ntightens into a smaller shape. We use this simulation as a test bed for this multiple-object discovery scheme, in the\nhopes that it is able to discover that the different “parts” of the cell are different objects in a common environment. We\nassume the presence of 11 different objects, each characterized by 2 dimensional dynamics for the blanket and object\nvariables. Each object is linked to observations via a single role for each of the blanket and object latents, to encourage\n15\n\n\nA PREPRINT - MARCH 3, 2025\n(a) Idealized combustion wave\n(b) Fuse in the wind\nFigure 7\nFigure 8: The algorithm is trained on 200 flame trajectories with 4 dimensions per latent and a total of 12 roles.\nObservables are sampled at 200 even-spaced locations and 800 points in time. Discovered dynamics are roughly 6\ndimensional. Typical role usage is about 7 in total. Fig. 9 shows the maximum a posteriori label assignments that\nthe algorithm makes to each node at each point in time, when presented with a flame that goes extinct at approximate\nt = 120. Blue represents the flame, red the environment, and green the boundary. The use of roles is critical in this case,\nbecause the environment behaves very differently depending upon whether it corresponds to burned versus unburned\nfuse. Indeed, the blanket only uses two roles: one for each of the front and back of the reaction zone. The object\nrequires only a single role.\n(a) Node Assignments: environment in red, blanket in green,\nobject in blue. Around time t=120 the flame goes extinct\nand disappears.\n(b) The internal variable (blue) tracks the negative of heat\nreleased. The environment variable tracks flame location.\nNote that at approximately t = 125, the flame goes extinct.\nFigure 9\nthe discovery of spatially localized objects. In the example shown, the simulation discovers 5 objects, corresponding to\n(1) a disordered state (green), (2) simple cell membrane (yellow), (3) complex cell membrane (orange), (4) disordered\nnucleus (purple), and (5) tight nucleus (blue). This illustrates the potential utility of this approach for segmenting\ncomplex systems into multiple interacting dynamic subsystems.\n5\nDiscussion\nIn this paper, we situated the FEP, Bayesian mechanics, Markov blankets, and ontological potential functions within\nthe broader set of ideas in Bayesian statistics and information theory, at the intersection of Jaynesian and Bayesian\napproaches to mathematical physics, and to mathematical modeling more generally. In particular, the work that we\npresented here shows that, in order to apply the logic and constructs of the FEP to model interesting things, we must\n16\n\n\nA PREPRINT - MARCH 3, 2025\n(a) Lorenz Attractor.\n(b) Two dimensional projection\n(c) Principal components and assign-\nments\nFigure 10: Red represents the environment, green represents the blanket, blue represents the object. When in the ∼2\ndimensional oscillating state, the object is present. Note that, at about t = 50, the attractor on the left nearly completely\ncaptures the dynamics for an extended period of time.\nstep outside of the logic of the FEP itself and call upon an additional principle, by which to pick the best Markov\nblanket partition, out of the exponentially many different possible ones. Satisfyingly, this turned out to be the same core\nideas from which we started in developing the FEP in the first place: Jaynes’ principle and surprise minimization. This\nis unsurprising to us, because the dynamic Markov blanket detection algorithm that we developed is itself based on the\nsame underlying ideas that led to the development of the FEP.\nWe proposed a class of models and associated inference algorithms that treat the problem of dynamic Markov blanket\ndetection as a macroscopic physics discovery problem, which are fundamentally based upon the identification of\ndynamic boundary elements that result in the simplest macroscopic description of the system as a whole. The output\nof this process is a set of macroscopic object-type-specific rules that govern the interactions between the boundary\nof an object and the environment in which it is embedded (mediated by some possibly fictive internal variables). We\nmotivated this approach by arguing that it is the statistics of Markov blankets that define object type, in a manner\nconsistent with systems identification theory and reinforcement learning; and by arguing that, when combined with\nJaynes’ principle of maximum caliber, this definition leads to familiar descriptions of the associated physical systems in\nterms of energy functions, Hamiltonians, and Lagrangians. Moreover, the combination of these mathematical tools\nleads directly to a characterization of objects in terms of an ontological potential function that precisely corresponds to\nthe free energy functional, and therefore, corresponds to an alternative derivation of the FEP that starts from information\ntheory (maximum caliber modeling), as opposed to the traditional approach to deriving the FEP, which begins with the\nequations of statistical physics.\nOn its own, this information theoretic approach to typing objects is incapable of determining which of the many dynamic\nblankets in a system should be labeled as proper subsystem. To resolve this ambiguity, we appealed to an additional\nprinciple: parsimony. That is, good labels should lead to a compact, low-dimensional description of the system as a\nwhole. This is not meant to imply that labeled objects have some kind of metaphysical significance, only that good\nlabels are useful for prediction, generalization, and data compression.\nTo see how all this might apply in general, consider the humble proton. Despite being composed of a veritable zoo\nof more fundamental particles, correctly applying the label “proton“ to the zoo results in a lower entropy of our\nobservations, if for no other reason than the fact that protons have positive charge, a particular mass, etc., and behave\naccordingly; while a randomly selected particle might have a different mass, charge, etc., and accordingly, behave\ndifferently. Indeed, that is why the zoo was given a label: The label has predictive power, in the sense that, given the\nlabel and knowledge of the observable properties of a proton (position, momentum, spin, etc.), we can predict how the\nparticle will interact with other things in its environment without having to think about what’s going on inside.\nThat is, good labels globally minimize the conditional entropy of future observations (or surprise). In that sense, in\nmathematical physics modeling, labels play the explanatory role of testable hypotheses: a good hypothesis makes sense\nof data, in the sense that the data becomes unsurprising under the hypothesis that the process generating the data can be\nlabeled as being of this or that type. So, labels are useful because they allow us to compactly describe the dynamics\nor observable behaviors of things, generating less surprise upon observing new data or upon considering past data\nthan if the label had not been used. The dynamics of things depend on their properties, and labels are a useful way of\ndenoting things with similar properties and behavior. Indeed, if the entropy of our observations does not, in fact, go\ndown conditioned on that label, then the mutual information between label and observations is zero by definition, and\ntherefore, the label is meaningless, both pragmatically and in an information theoretic sense.\n17\n\n\nA PREPRINT - MARCH 3, 2025\n(a) Initial disordered state.\n(b) ’Cell membrane’ forms.\n(c) ’Flagella’ begin to form.\n(d) ’Flagella’ fully formed\n(e) ’Organelles’ form.\n(f) ’Organelles’ interact.\nFigure 11: DMBD fit to initial evolution of particle Lenia ’rotator’. Time increases left to right. In the initial disordered\nstate nearly all particles are assigned to a single object. As time progresses a cell membrane forms which is assigned to\na new object type. The cell membrane then undergoes a phase change as ’flagella’. This alters the object label of the\nmembrane. Meanwhile a tightly bound nucleus forms which is also given a unique label. An additional 8 repulsive\nparticles move about the region between the nucleus and membrane. This configuration is semi stable with the inner 8\nparticles transiting around the nucleus. The membrane pulses and rotates slightly perturbing the 8 inner particles which\ncauses the nucleus to pulsate as well. This causes the inner 8 particles to regularly shift in their object assignments\ntransitioning from nucleus to organelle to membrane and back.\nInterestingly, conditional entropy is precisely the surprise objective most strongly associated with the FEP. However,\nin that literature, the role of surprise minimization is treated tautologically, not empirically: the idea is that “things\nminimize surprise,” as opposed to “labeling something as an object of a specific type minimizes my surprise.” As a\nconcrete example, consider the humble proton. Correctly applying the label “proton“ to a particle results in a lower\nentropy of our observations, if for no other reason than the fact that protons have positive charge, a particular mass, etc.,\nand behave accordingly; while a randomly selected particle might have a different mass, charge, etc., and accordingly,\nbehave differently. Indeed, that is why it was given a label: the label has predictive power, in the sense that, given the\nlabel and knowledge of the observable properties of a proton (position, momentum, spin, etc.), we can predict how the\nparticle will interact with other things in its environment. To this end, consider why we bothered to label a proton a\n“thing.” Correctly applied, the label reduces uncertainty/entropy and enhances our ability to predict the behavior of both\nthe proton and the system as a whole. That is, good labels globally minimize surprise. This suggests that the surprise\nminimization objective plays a critical empirical role.\nThis is distinct from the manner in which the FEP is traditionally discussed. A good tautology provides a good starting\npoint for a definition. The FEP starts with the definition of an object as a blanketed collection of states, whose internal\nand active states or paths minimizes surprise (as characterized by the free energy of blanket states or paths)—and\nderives a principle of least action and ensuing Bayesian mechanics. That is, the principle focus of the FEP literature has\nbeen on necessary properties of things, and not on empirically discovering which collections we can sensibly label\nas objects. Conversely and in a complementary fashion, the approach described here starts from a Markov blanket\n18\n\n\nA PREPRINT - MARCH 3, 2025\nbased definition of system types, but takes an empirical point of view of an observer or modeler and seeks to provide a\njustification for the decisions that an observer makes when modeling the dynamics of a system.\n5.1\nResponse to technical critiques of the FEP\nThis work addresses some core technical criticism and limitations of modeling based on the FEP, which up until now\nwere arguably still open.3 The Markov blanket based approach to system identification has proven controversial (see,\ne.g., [6, 35, 11, 5]). Some have argued that the Markov blanket based definition of object and object type is not as\nobvious or trivial as its proponents say it is [35].4 Another line of criticism argues that actually identifying Markov\nblankets (both mathematically and empirically, in real world data) rests upon nontrivial modeling decisions, and that, as\na result, the Markov blanket formalism is less easily or generally applicable than claimed [6]. Still others have noted\nthat demonstrations of the near universal applicability of the FEP seems at odds with the assumed form of the Markov\nblanket and nonequilibrium steady state condition that together guarantee a partition between organism and environment\nor between internal and external states [1, 5, 11, 30]. Indeed, the Markov blanket based definition of a macroscopic\nobject has been criticized as being ill posed (since many interesting types of systems will appear to have many Markov\nblankets [6]) or inapplicable to systems that are strongly coupled to their environment, highly variable, or exchange\nmatter with their environment [35, 11, 30]. Plainly, the systems that are of most interest to us are open systems that\nexchange matter and energy with their environments, exist far from thermodynamic equilibrium, and usually have\nmobile and dynamic—and possibly non contiguous—boundaries. Candidate counterexamples to the applicability of the\nMarkov blanket based approach turned out to be things with mobile or wandering boundaries, like flames and organisms.\nIt was especially problematic because the FEP was developed originally to model the dynamics of the brain and the\nbehavior of living things, and is probably best known in this application.\nAs one would hope, these criticisms have led to substantial debate and an explicit acknowledgment that the FEP, as\nformulated for systems at steady state, applies only to a rather “particular” class of macroscopic objects that only\nsparsely or weakly interact with their environment [15, 1]. Here, we argue that many of these criticism ultimately stem\nfrom the FEP literature’s prior focus on “static” Markov blanket construct. From a mathematical point of view, several\nof these objections were resolved by moving from a state-wise formulation to a path-based or path integral formulation\nof the FEP [43, 16], allowing us to avoid having to make assumptions about the steady state statistics of a system (see\n[36] for a detailed discussion) or rely on approximate Markov blanket structure in the stationary statistics of the system\nas a whole. In the path-based formulations of the FEP, quantities of interest and the equations that relate them now\nare defined for paths of a system, i.e., they are defined in objects that make up a structured space or set of trajectories\nthat each represent a specific way the system might evolve over time. Moreover, a consideration of dynamic blankets\nand maximum caliber modeling [36, 42] allows us to identify sensible objects and boundaries in complex systems that\ninclude phase transitions, and to models of objects with transient and moving boundaries. Our contribution here is to\nprovide a mathematical framework and numerical demonstrations that show definitively that such dynamic objects can\nbe modeled within this framework, thereby resolving this debate in the literature empirically.\n5.2\nNiche construction and the role of the environment in active inference\nIn our simulation of a burning fuse, the environment played an unexpected role: we note that the position of the flame is\nbest tracked by the state of the environment, rather than by internal states of the combustion network. We also noted\nabove that, because the equations that govern the dynamics of Markov blankets are symmetric with respect to internal\nand external states, the blanket encodes the policies of both the internal and the external subsystems, concluding that the\nMarkov blanket based definition of an object type is always environment-specific. This result sits well with recent work\nreconsidering the role of the environment in active inference and with work on active inference in sociocultural systems\n[47]. This work considers the multi scale recursively nested structure of the dynamics that coupled individual agents,\nthe sociocultural systems they form, and the ecological niche that these shape through action [8, 39, 47, 32]. There is\nno a priori reason to always center our model on agents for every kind of task and situation. Instead, we can model\nagents as special parts of the wider environment—that are highly salient to other agents; see e.g., [13]. This also speaks\nto previous work in this tradition on niche construction work, emphasizing that the property of the synchronization\nbetween objects that the FEP describes—i.e., that it is symmetric—can be exploited by agents. This work models the\n3Albeit, see section 3.4. “Some remarks about the state of the art” in [36] for a discussion of the current state of affairs regarding\ntechnical critiques of the FEP, and responses to them).\n4Interestingly to us, when considering what possible alternative there could be to the FEP from an information theoretic\nperspective, the authors [35] land upon maximum entropy as a possible alternative. This choice of candidate alternative approach is\ntelling, especially in light of recent developments on the duality of the FEP and maximum entropy/caliber. Indeed, there seems to be\nno other game in town.\n19\n\n\nA PREPRINT - MARCH 3, 2025\npassive (habitual, unintentional) and active construction (e.f., deliberate design) of an ecological niche by its denizens,\nsuch that certain kinds of patterned behavior are solicited, as opposed to others that are discouraged [8, 38].\n5.3\nFuture directions\nOur specific realization of a member of this class of Markov blanket detection algorithms relied on linear approximations\nand a decoupling of blanket (label) dynamics and macroscopic dynamics. This choice resulted in an algorithm that\nsensibly partition systems, but that cannot be relied upon for prediction. This is for two reasons: (1) the assumption of\nlinear dynamics causes the effects of any non-linearities in the system to be attributed to noise, causing an effective\nenhancement of diffusive strength; and (2) the assumption that the boundary dynamics are decoupled from the\nmacroscopic dynamics means that latent assignment variables quickly diffuse to a uniform stationary distribution in\nthe absence of observed data. We plan to address these issues in future work by imposing Markov blanket structure\non Bayesian instantiations of switching linear dynamical systems models. This work is also related to work on\nmathematically modeling downward causality and emergent phenomena via dimensionality reduction [2, 40], in ways\nthat we plan to explore.\nReferences\n[1]\nMiguel Aguilera et al. “How particular is the physics of the free energy principle?” In: Physics of Life Reviews\n40 (2022), pp. 24–50.\n[2]\nLionel Barnett and Anil K Seth. “Dynamical independence: discovering emergent macroscopic processes in\ncomplex dynamical systems”. In: Physical Review E 108.1 (2023), p. 014304.\n[3]\nMatthew James Beal. Variational algorithms for approximate Bayesian inference. University of London, Univer-\nsity College London (United Kingdom), 2003.\n[4]\nJ.M. Beck and V.A. Volpert. “Nonlinear dynamics in a simple model of solid flame microstructure”. In: Physica\nD: Nonlinear Phenomena 182.1–2 (2003), pp. 86–102. DOI: 10.1016/S0167-2789(03)00189-5.\n[5]\nMartin Biehl, Felix A. Pollock, and Ryota Kanai. “A Technical Critique of Some Parts of the Free Energy\nPrinciple”. In: Entropy 23.3 (2021). Ed. by Kevin H. Knuth, p. 293. DOI: 10.3390/e23030293.\n[6]\nJohan Bruineberg et al. “The Emperor’s New Markov Blankets”. In: Behavioral and Brain Sciences 45 (2022),\nE183. DOI: 10.1017/S0140525X21002351.\n[7]\nBert Wang-Chak Chan. “Lenia: Biology of Artificial Life”. In: Complex Systems 28.3 (2019), pp. 251–286. DOI:\n10.25088/ComplexSystems.28.3.251. URL: https://doi.org/10.25088/ComplexSystems.28.3.\n251.\n[8]\nAxel Constant et al. “A variational approach to niche construction”. In: Journal of the Royal Society Interface\n15.141 (2018), p. 20170685.\n[9]\nLancelot Da Costa et al. “Bayesian mechanics for stationary processes”. In: Proceedings of the Royal Society A\n477.2256 (2021), p. 20210518.\n[10]\nSergio Davis and Diego González. “Hamiltonian formalism and path entropy maximization”. In: Journal of\nPhysics A: Mathematical and Theoretical 48.42 (2015), p. 42500. DOI: 10.1088/1751-8113/48/42/42500.\n[11]\nEzequiel Di Paolo, Evan Thompson, and Randall Beer. “Laying down a forking path: Tensions between enaction\nand the free energy principle”. In: Philosophy and the Mind Sciences 3 (2022).\n[12]\nKrishnamurthy Dvijotham and Emanuel Todorov. “Inverse Optimal Control with Linearly-Solvable MDPs”. In:\nInternational Conference on Machine Learning. 2010.\n[13]\nKanako Esaki et al. “Environment-Centric Active Inference”. In: arXiv preprint arXiv:2408.12777 (2024).\n[14]\nS. M. Ali Eslami et al. “Attend, Infer, Repeat: Fast Scene Understanding with Generative Models”. In: arXiv\npreprint arXiv:1603.08575 (2016). arXiv: 1603.08575 [cs.CV]. URL: https://doi.org/10.48550/\narXiv.1603.08575.\n[15]\nKarl Friston. “A free energy principle for a particular physics”. In: arXiv preprint arXiv:1906.10184 (2019).\narXiv: 1906.10184.\n[16]\nKarl Friston et al. “Path integrals, particular kinds, and strange things”. In: Physics of Life Reviews (2023).\n[17]\nKarl J Friston et al. “Parcels and particles: Markov blankets in the brain”. In: Network Neuroscience 5.1 (2021),\npp. 211–251.\n[18]\nClark Glymour, Kun Zhang, and Peter Spirtes. “Review of Causal Discovery Methods Based on Graphical\nModels”. In: Frontiers in Genetics 10.June (2019). This article is part of the Research Topic Shift the Current\nParadigm of Genetic Studies of Complex Diseases from Association to Causation, p. 524. ISSN: 1664-8021.\nDOI: 10.3389/fgene.2019.00524. URL: https://doi.org/10.3389/fgene.2019.00524.\n20\n\n\nA PREPRINT - MARCH 3, 2025\n[19]\nDiego González and Sergio Davis. “Jarzynski equality in the context of maximum path entropy”. In: arXiv\npreprint arXiv:1607.07287 (2016). URL: https://arxiv.org/abs/1607.07287.\n[20]\nConor Heins and Lancelot Da Costa. “Sparse coupling and Markov blankets: A comment on\" How particular is\nthe physics of the Free Energy Principle?\" by Aguilera, Millidge, Tschantz and Buckley”. In: arXiv preprint\narXiv:2205.10190 (2022).\n[21]\nMatthew D. Hoffman et al. “Stochastic Variational Inference”. In: Journal of Machine Learning Research 14\n(2013), pp. 1303–1347. URL: http://www.jmlr.org/papers/volume14/hoffman13a/hoffman13a.pdf.\n[22]\nChristopher Jarzynski. “Equalities and inequalities: Irreversibility and the second law of thermodynamics at the\nnanoscale”. In: Time: Poincaré Seminar 2010. Springer. 2012, pp. 145–172.\n[23]\nEdwin T Jaynes. “The minimum entropy production principle”. In: Annual Review of Physical Chemistry 31.1\n(1980), pp. 579–601.\n[24]\nEdwin T. Jaynes. “Information theory and statistical mechanics”. In: Physical Review 106.4 (1957), p. 620. DOI:\n10.1103/PhysRev.106.620.\n[25]\nMatt Jones, Peter Chang, and Kevin Murphy. “Bayesian Online Natural Gradient BONG”. In: arXiv preprint\narXiv:2405.19681 (2024). URL: https://arxiv.org/abs/2405.19681.\n[26]\nB. Kappen, V. Gomez, and M. Opper. “Optimal control as a graphical model inference problem”. In: Machine\nLearning Journal (2012). arXiv: arXiv:0901.0633[math.OC] [math.OC].\n[27]\nAlex B Kiefer. “Psychophysical identity and free energy”. In: Journal of the Royal Society Interface 17.169\n(2020), p. 20200370.\n[28]\nBernard O Koopman. “Hamiltonian systems and transformation in Hilbert space”. In: Proceedings of the\nNational Academy of Sciences 17.5 (1931), pp. 315–318.\n[29]\nScott Linderman et al. “Bayesian Learning and Inference in Recurrent Switching Linear Dynamical Systems”.\nIn: Proceedings of the 20th International Conference on Artificial Intelligence and Statistics. Ed. by Aarti Singh\nand Jerry Zhu. Vol. 54. Proceedings of Machine Learning Research. PMLR, Apr. 2017, pp. 914–922. URL:\nhttps://proceedings.mlr.press/v54/linderman17a.html.\n[30]\nKathryn Nave. A drive to survive: The free energy principle and the meaning of life. MIT Press, 2025.\n[31]\nRobert K. Niven. “Minimization of a free-energy-like potential for non-equilibrium flow systems at steady state”.\nIn: Philosophical Transactions of the Royal Society B: Biological Sciences 365.1545 (2010), pp. 1323–1331.\nDOI: 10.1098/rstb.2009.0296.\n[32]\nThomas Parr. “Choosing a Markov blanket.” In: Behavioral & Brain Sciences 43 (2020).\n[33]\nJudea Pearl. Quantified Representation of Uncertainty and Imprecision. Graphical models for probabilistic and\ncausal reasoning. Springer, 1998, pp. 367–389.\n[34]\nMaziar Raissi, Paris Perdikaris, and George E Karniadakis. “Physics-informed neural networks: A deep learning\nframework for solving forward and inverse problems involving nonlinear partial differential equations”. In:\nJournal of Computational Physics 378 (2019), pp. 686–707.\n[35]\nVicente Raja et al. “The Markov blanket trick: On the scope of the free energy principle and active inference”.\nIn: Physics of Life Reviews 39 (2021), pp. 49–72.\n[36]\nMaxwell J. D. Ramstead et al. “On Bayesian mechanics: a physics of and by beliefs”. In: Interface Focus 13.3\n(2023), p. 20220029. DOI: 10.1098/rsfs.2022.0029. URL: https://doi.org/10.1098/rsfs.2022.\n0029.\n[37]\nMaxwell JD Ramstead, Dalton AR Sakthivadivel, and Karl J Friston. “An approach to non-equilibrium statistical\nphysics using variational Bayesian inference”. In: arXiv preprint arXiv:2406.11630 (2024).\n[38]\nMaxwell JD Ramstead, Samuel PL Veissière, and Laurence J Kirmayer. “Cultural affordances: Scaffolding local\nworlds through shared intentionality and regimes of attention”. In: Frontiers in psychology 7 (2016), p. 1090.\n[39]\nMaxwell JD Ramstead et al. “Variational ecology and the physics of sentient systems”. In: Physics of life Reviews\n31 (2019), pp. 188–205.\n[40]\nFernando E Rosas et al. “Reconciling emergences: An information-theoretic approach to identify causal\nemergence in multivariate data”. In: PLoS computational biology 16.12 (2020), e1008289.\n[41]\nDalton A R Sakthivadivel. “Towards a Geometry and Analysis for Bayesian Mechanics”. In: arXiv preprint\narXiv:2204.11900 (2022). DOI: 10.48550/arXiv.2204.11900. arXiv: 2204.11900 [math-ph]. URL:\nhttps://arxiv.org/abs/2204.11900.\n[42]\nDalton AR Sakthivadivel. “A worked example of the Bayesian mechanics of classical objects”. In: International\nWorkshop on Active Inference. Springer. 2022, pp. 298–318.\n[43]\nDalton AR Sakthivadivel. “Regarding Flows Under the Free Energy Principle: A Comment on\" How Particular\nis the Physics of the Free Energy Principle?\" by Aguilera, Millidge, Tschantz, and Buckley”. In: arXiv preprint\narXiv:2205.07793 (2022).\n21\n\n\nA PREPRINT - MARCH 3, 2025\n[44]\nDalton AR Sakthivadivel. “Weak Markov blankets in high-dimensional, sparsely-coupled random dynamical\nsystems”. In: arXiv preprint arXiv:2207.07620 (2022).\n[45]\nAaron J. Snoswell, Surya P. N. Singh, and Nan Ye. “Revisiting Maximum Entropy Inverse Reinforcement\nLearning: New Perspectives and Algorithms”. In: arXiv preprint arXiv:2108.10056 (2021).\n[46]\nA Vaswani. “Attention is all you need”. In: Advances in Neural Information Processing Systems (2017).\n[47]\nSamuel PL Veissière et al. “Thinking through other minds: A variational approach to cognition and culture”. In:\nBehavioral and brain sciences 43 (2020), e90.\n[48]\nHao Wang et al. “Towards efficient and effective discovery of Markov blankets for feature selection”. In:\nInformation Sciences 509 (2020), pp. 227–242. DOI: 10.1016/j.ins.2019.09.053. URL: https://doi.\norg/10.1016/j.ins.2019.09.053.\n[49]\nBrian D Ziebart et al. “Maximum entropy inverse reinforcement learning”. In: Proceedings of the 23rd AAAI\nConference. 2008.\n22\n\n\n",
  "metadata": {
    "source_file": "dataset/pdfs/arxiv_2502.21217v1.pdf",
    "total_pages": 22,
    "title": "Dynamic Markov Blanket Detection for Macroscopic Physics Discovery",
    "authors": [
      "Jeff Beck",
      "Maxwell J. D. Ramstead"
    ],
    "abstract": "The free energy principle (FEP), along with the associated constructs of\nMarkov blankets and ontological potentials, have recently been presented as the\ncore components of a generalized modeling method capable of mathematically\ndescribing arbitrary objects that persist in random dynamical systems; that is,\na mathematical theory of ``every'' ``thing''. Here, we leverage the FEP to\ndevelop a mathematical physics approach to the identification of objects,\nobject types, and the macroscopic, object-type-specific rules that govern their\nbehavior. We take a generative modeling approach and use variational Bayesian\nexpectation maximization to develop a dynamic Markov blanket detection\nalgorithm that is capable of identifying and classifying macroscopic objects,\ngiven partial observation of microscopic dynamics. This unsupervised algorithm\nuses Bayesian attention to explicitly label observable microscopic elements\naccording to their current role in a given system, as either the internal or\nboundary elements of a given macroscopic object; and it identifies macroscopic\nphysical laws that govern how the object interacts with its environment.\nBecause these labels are dynamic or evolve over time, the algorithm is capable\nof identifying complex objects that travel through fixed media or exchange\nmatter with their environment. This approach leads directly to a flexible class\nof structured, unsupervised algorithms that sensibly partition complex\nmany-particle or many-component systems into collections of interacting\nmacroscopic subsystems, namely, ``objects'' or ``things''. We derive a few\nexamples of this kind of macroscopic physics discovery algorithm and\ndemonstrate its utility with simple numerical experiments, in which the\nalgorithm correctly labels the components of Newton's cradle, a burning fuse,\nthe Lorenz attractor, and a simulated cell.",
    "published_date": "2025-02-28",
    "source": "arxiv"
  }
}