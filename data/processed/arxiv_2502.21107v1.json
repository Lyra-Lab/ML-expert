{
  "id": "arxiv_2502.21107v1",
  "text": "Generating patient cohorts from electronic health records using two-step\nretrieval-augmented text-to-SQL generation\nAngelo Ziletti*\nBayer AG\nangelo.ziletti@bayer.com\nLeonardo D’Ambrosi\nBayer AG\nAbstract\nClinical cohort definition is crucial for patient\nrecruitment and observational studies, yet trans-\nlating inclusion/exclusion criteria into SQL\nqueries remains challenging and manual. We\npresent an automated system utilizing large lan-\nguage models that combines criteria parsing,\ntwo-level retrieval augmented generation with\nspecialized knowledge bases, medical concept\nstandardization, and SQL generation to retrieve\npatient cohorts with patient funnels. The sys-\ntem achieves 0.75 F1-score in cohort identifi-\ncation on EHR data, effectively capturing com-\nplex temporal and logical relationships. These\nresults demonstrate the feasibility of automated\ncohort generation for epidemiological research.\n1\nIntroduction\nElectronic Health Records (EHR) have become es-\nsential resources for clinical research, serving as a\nfoundational component across multiple healthcare\napplications. In clinical trials, accurate cohort iden-\ntification directly impacts patient recruitment suc-\ncess, study validity, timeline adherence, and cost\nmanagement (Sherman et al., 2016). For observa-\ntional studies and epidemiological research, well-\ndefined cohorts enable researchers to investigate\ndisease patterns, treatment effectiveness, and health\noutcomes across specific patient populations, in-\nforming critical healthcare decisions from drug de-\nvelopment to regulatory submissions (Casey et al.,\n2016; U.S. FDA, 2024)\nProblem Statement.\nConverting clinical in-\nclusion/exclusion criteria into accurate database\nqueries requires addressing multiple technical chal-\nlenges simultaneously: (1) mapping natural lan-\nguage criteria to precise computational logic while\nleveraging medical domain knowledge, (2) pre-\nserving complex temporal and logical relationships\nacross multiple criteria, (3) mapping diverse med-\nical concepts to standardized codes, and (4) gen-\nerating queries that conform to established data\nmodels.\nContributions. This paper presents an approach\nfor automatically generating patient cohorts from\nEHRs. Our main contributions are:\n• A\nmanually\ncurated\ndataset\nof\ninclu-\nsion/exclusion criteria paired with SQL\nqueries that conform to the Observational\nMedical Outcomes Partnership Common\nData Model (OMOP-CDM) (OMOP-CDM,\n2023).\n• A two-level retrieval-augmented generation\n(RAG) framework that substantially outper-\nforms simple prompting across all tested\nmodels, demonstrating robust performance in\ntranslating complex clinical criteria into exe-\ncutable SQL queries.\n• Open-source release of dataset, source code,\nand prompt configurations1.\nThe system has been deployed and is currently\nbeing evaluated at Bayer by epidemiologists and\ndata analysts.\n2\nKnowledge base generation\nWe create two complementary knowledge bases\n(KBs) for our retrieval-augmented approach: Epi-\nAskKB and EpiCohoKB.\nEpiAskKB consists of 111 question-SQL pairs\nthat capture typical analytical questions in obser-\nvational studies, extending and refining the dataset\nfrom Ziletti and DAmbrosi (2024) to better reflect\ncommon epidemiological research questions.\nEpiCohoKB contains inclusion/exclusion cri-\nteria for observational studies, which we create\nthrough structured language model prompting. The\ngeneration integrates three key elements: (1) a\n1Upon acceptance of the paper\narXiv:2502.21107v1  [cs.CL]  28 Feb 2025\n\n\nFigure 1: (a-g) From inclusion/exclusion criteria in natural language to patient cohorts using electronic health\nrecord databases: end-to-end workflow. (h) Query decomposition and patient funnel generation through LLM-based\nprocessing.\nprompt specifying OMOP CDM vocabulary us-\nage and structural constraints for cohort criteria,\n(2) standard guidelines for study criteria (including\ntemporal relationships, assessment windows, and\nobservable time definitions) Wang et al. (2021), and\n(3) real observational study protocols from the Eu-\nropean Medicines Agency (EMA) catalog (EMA,\n2024) (89 samples) as exemplars for in-context\nlearning. This ensures both structural rigor and\nclinical authenticity. EpiCohoKB covers diverse\ntherapeutic areas and study types, including drug\nsafety analyses, comparative effectiveness research,\nand healthcare utilization studies, creating a com-\nprehensive benchmark for clinical criteria transla-\ntion. We generate an initial set of SQL queries\nthrough large language model (LLM) prompting,\nmanually review and validate them for Snowflake\nSQL compatibility, resulting in 104 samples.\n3\nMethods\nOur approach translates clinical cohort definitions\ninto executable SQL queries through a multi-stage\npipeline (Fig. 1). First, we use an LLM to parse\ninput criteria into a semi-structured format, explic-\nitly identifying inclusion criteria, exclusion criteria,\nand index date definition. We then compile an in-\nstruction prompt incorporating domain knowledge\nabout OMOP CDM and SQL query construction,\nforming our baseline zero-shot (ZS) approach.\nWe implement three retrieval augmentation\nstrategies: (1) Criteria-level RAG (RAG+A) re-\ntrieves top-5 similar question-SQL pairs from\n\n\nEpiAskKB per criterion; (2) Cohort-level RAG\n(RAG+C) retrieves top-5 similar cohort defini-\ntions from EpiCohoKB; (3) Combined RAG\n(RAG+A+C) performs both criteria-level and\ncohort-level retrieval. This modular design enables\nquery pattern reuse at different granularities - in-\ndividual criteria can be composed into complex\ncohort definitions while preserving temporal re-\nlationships. The augmented prompt is passed to\nthe LLM to generate SQL with placeholder enti-\nties (e.g., condition@hypertension). This approach\ndisentangles the query logic generation from the\nsubsequent medical coding step where placehold-\ners are mapped to specific concept IDs (Ziletti\nand DAmbrosi, 2024). The system implements\na self-healing mechanism with up to three itera-\ntions (Pourreza and Rafiei, 2023). The output is a\ncohort table with patient IDs and index dates.\nTo provide interpretability and enable criteria\nrefinement, we also implement a patient funnel cal-\nculation pipeline (Fig. 1h). The LLM generates\nseparate SQL queries per criterion, which are ex-\necuted independently and combined through set\noperations (intersections for inclusions, differences\nfor exclusions), tracking cohort attrition at each\nstep.\n4\nEvaluation\n4.1\nExperimental setup\nWe evaluate several state-of-the-art LLMs: Claude\n3.5 Sonnet (hereafter Claude) (Anthropic AI,\n2024), Gemini 2.0 Flash (Gemini) (Gemini Team,\n2023), LLAMA 3.1 70B (Grattafiori et al., 2024),\nand GPT-4o (OpenAI, 2023). We also include rea-\nsoning models: o1 (OpenAI, 2024) and DeepSeek\nR1 (deepseek) (DeepSeek-AI et al., 2025). We\ntest these models in ZS settings and with RAG\nusing different configurations: question-based re-\ntrieval (RAG+A), cohort-based retrieval (RAG+C),\nand their combination (RAG+A+C). For RAG, we\nemploy entity masking and the BGE-LARGE-EN-\nV1.5 embedding model (Zhang et al., 2023b). The\nsame model is used for medical entity normal-\nization (Limsopatham and Collier, 2016; Portelli\net al., 2022; Ziletti et al., 2022; Zhang et al., 2022),\nwith GPT-4o verification (Ziletti and DAmbrosi,\n2024). The evaluation uses Optum’s de-identified\nClinformatics® Data Mart Database (a major US\nclaims database) converted to OMOP CDM. Our\nmethodology is compatible with the OMOP net-\nwork (over 2.1 billion patient records world-\nwide (Reich et al., 2024)), including the freely\navailable DE-SynPUF synthetic dataset (SynPUF,\n2010). For successful queries, we compute patient-\nlevel metrics (F1, precision, recall) and normalized\ncohort size differences based on matching patients,\nwith temporal alignment assessed through exact\nmatches and within a ± 30-day window. Failed\nqueries (invalid SQL or empty results) contribute\nzero scores to the final cross-sample averages.\n4.2\nExperimental results\nResults are shown in Table 1, and outlined below.\nGenerated queries have high syntactic validity.\nMost models show high SQL compilation rates\nwith RAG augmentation, while also improving data\nretrieval success. The retrieved data rate increases\nsubstantially with RAG.\nRAG strongly improves zero-shot performance.\nThe combined RAG strategy (RAG+A+C) sub-\nstantially outperforms ZS across all models.\nRAG+A+C significantly improves patient cohort\nidentification across all metrics.\nPrecision in-\ncreases (Claude: ↑14.6pp, Gemini ↑33.3pp, GPT-\n4o ↑29.6pp), while maintaining high recall (>70%).\nSimilar patterns emerge in temporal alignment.\nThe balanced improvement in precision and recall\nsuggests that RAG helps models better understand\nboth inclusion and exclusion criteria.\nComplementary RAG strategies enhance per-\nformance. Cohort-level examples (RAG+C) are\nparticularly effective. When compared to criteria-\nlevel RAG (RAG+A), cohort-level examples lead\nto substantially higher F1 scores. The combina-\ntion of both strategies (RAG+A+C) further im-\nproves performance for most models, suggesting\ncomplementary benefits from both example types.\nInterestingly, GPT-4o shows slightly decreased per-\nformance with RAG+A+C compared to RAG+C\n(↓6.4pp), indicating that longer input contexts may\nimpact its generation capabilities.\nClaude and Gemini emerge as top performers.\nClaude and Gemini achieve comparable perfor-\nmance when augmented with RAG+A+C. Claude\nexhibits the strongest ZS performance, while Gem-\nini shows excellent in-context learning capabili-\nties (↑33.3pp from ZS to RAG+A+C). Reasoning-\nfocused models (o1, DeepSeek R1) struggle with\nSQL formatting despite their analytical capabili-\nties.\nTo evaluate the patient funnel creation, for the\nbest performing model (Claude RAG+A+C), we\nmeasure a 90% normalized cohort size similarity\n\n\nModel name\nSettings\nGeneral metrics\nPatient-level metrics\nDate-level metrics\nValid SQL\nRetrieved\nF1\nPrec.\nRecall\nSize sim.\nDate overlap\nWithin 30d\nClaude 3.5 Sonnet\nZS\n100.0\n78.1\n57.8\n61.0\n63.1\n62.8\n75.9\n74.9\nClaude 3.5 Sonnet\nRAG+A\n99.0\n82.6\n58.4\n59.5\n68.6\n62.6\n80.8\n77.5\nClaude 3.5 Sonnet\nRAG+C\n99.0\n91.4\n69.5\n72.0\n74.7\n74.5\n88.2\n87.4\nClaude 3.5 Sonnet\nRAG+A+C\n99.0\n93.3\n72.8\n75.6\n79.0\n77.6\n91.7\n90.5\nGemini 2.0 Flash\nZS\n96.2\n55.2\n42.4\n43.3\n44.5\n46.6\n51.7\n50.9\nGemini 2.0 Flash\nRAG+A\n99.0\n62.9\n41.6\n42.1\n48.6\n46.0\n58.7\n58.4\nGemini 2.0 Flash\nRAG+C\n99.0\n89.5\n68.0\n68.9\n75.2\n73.5\n85.4\n84.6\nGemini 2.0 Flash\nRAG+A+C\n99.0\n91.3\n75.4\n76.6\n79.7\n79.8\n89.1\n89.1\nGPT-4o\nZS\n84.8\n61.0\n35.4\n38.1\n39.7\n42.1\n52.9\n52.5\nGPT-4o\nRAG+A\n86.7\n50.5\n31.7\n32.8\n34.7\n37.4\n44.9\n44.6\nGPT-4o\nRAG+C\n97.1\n91.4\n72.1\n73.1\n76.8\n77.7\n87.0\n87.9\nGPT-4o\nRAG+A+C\n98.1\n84.8\n65.7\n67.7\n71.1\n70.5\n80.9\n82.3\no1\nZS\n9.5\n5.7\n4.3\n5.2\n4.2\n4.5\n5.4\n5.0\no1\nRAG+A+C\n78.1\n73.3\n60.0\n62.0\n62.2\n63.0\n71.5\n70.0\nDeepSeek R1\nZS\n35.2\n28.6\n22.2\n22.6\n23.1\n23.6\n25.9\n24.8\nDeepSeek R1\nRAG+A+C\n36.2\n31.4\n23.6\n25.0\n25.4\n25.4\n29.6\n30.2\nLLAMA 3.1 70B\nZS\n37.1\n17.1\n8.5\n9.6\n9.0\n11.0\n16.2\n14.5\nLLAMA 3.1 70B\nRAG+A+C\n79.1\n69.5\n47.0\n51.2\n52.0\n52.7\n66.6\n65.3\nTable 1: Performance evaluation of text-to-SQL generation for patient cohort identification. Valid SQL indicates\nsyntactically correct queries, Retrieved indicates queries that successfully retrieved patient data. Patient-level\nmetrics evaluate cohort membership accuracy, while date-level metrics assess the temporal alignment of cohort\nindex dates. Higher values are better, all values in percentage. Bold indicates best results, underlined shows second\nbest.\ncompared to the single-query approach, validating\nthe funnel decomposition strategy.\n5\nRelated Work\nCohort Generation from EHR Data. Rule-based\nsystems achieve high precision but require sub-\nstantial expert curation (Banda et al., 2017; Hripc-\nsak et al., 2019; OHDSI Collaborative, 2021; Priv-\nitera and Hartenstein, 2024). While early work\ncombined rules and machine learning (Yuan et al.,\n2019), recent approaches leverage LLMs: Park\net al. (2024) for OMOP-CDM clinical trial queries,\nMelnichenko (2023) for structured criteria extrac-\ntion, Dobbins et al. (2023) for cross-schema tem-\nplated queries, Yan et al. (2024) for phenotyping,\nand Wong et al. (2023) for eligibility criteria struc-\nturing. Ziletti and DAmbrosi (2024) introduced\nRAG-enhanced epidemiological text-to-SQL. Sev-\neral EHR text-to-SQL datasets exist (Wang et al.,\n2020; Raghavan et al., 2021; Lee et al., 2022;\nTarbell et al., 2023; Ziletti and DAmbrosi, 2024),\nthough none maps observational study criteria to\nOMOP-SQL.\nText-to-SQL with In-Context Learning.\nRe-\ncent work shows LLMs excel at text-to-SQL tasks\nwhen enhanced with in-context learning (Rajku-\nmar et al., 2022), particularly through optimized\nexample selection (Nan et al., 2023; Gao et al.,\n2023), query decomposition (Pourreza and Rafiei,\n2023), diverse demonstrations (Chang and Fosler-\nLussier, 2023a,b), ensemble approaches (Gao et al.,\n2025), and chain-of-thought prompting (Zhang\net al., 2023a).\n6\nConclusions\nThis work shows that LLMs with RAG can ef-\nfectively identify patient cohorts from EHR data.\nThe pipeline combines medical concept standard-\nization, criteria parsing, and two-level retrieval to\nhandle complex temporal relationships, while the\npatient funnel provides interpretable intermediate\nmetrics. Future applications to clinical trial recruit-\nment could help bridge the gap between observa-\ntional and interventional research.\n7\nLimitations\nOur work has several limitations. The modest size\nof our dataset may not capture the full complex-\n\n\nity and variety of real-world observational studies.\nThe current system lacks formal uncertainty es-\ntimates for its predictions, making it difficult to\nidentify cases where human review is particularly\nimportant. While the patient funnel provides some\ntransparency, the model remains largely a black box\nfor users unfamiliar with SQL, potentially limiting\nadoption among clinical researchers. The current\nmethodology relies on OMOP-CDM, and although\nit could be in principle adapted to other data models\nthrough in-context learning, this was not tested.\nReferences\nAnthropic AI. 2024.\nModel card for claude 3\nmodels.\nhttps://docs.anthropic.com/en/docs/\nresources/model-card.\nAccessed:\nFebruary 15,\n2024.\nJuan M Banda, Yoni Halpern, David Sontag, and\nNigam H Shah. 2017. Electronic phenotyping with\nAPHRODITE and the Observational Health Sciences\nand Informatics (OHDSI) data network.\nAMIA\nJoint Summits on Translational Science proceedings,\n2017:48–57.\nJoan A. Casey, Brian S. Schwartz, Walter F. Stewart,\nand Nancy E. Adler. 2016. Using electronic health\nrecords for population health research: A review of\nmethods and applications. Annual Review of Public\nHealth, 37(Volume 37, 2016):61–81.\nShuaichen Chang and Eric Fosler-Lussier. 2023a. How\nto prompt llms for text-to-sql: A study in zero-shot,\nsingle-domain, and cross-domain settings. Preprint,\narXiv:2305.11853.\nShuaichen Chang and Eric Fosler-Lussier. 2023b. Se-\nlective demonstrations for cross-domain text-to-SQL.\nIn Findings of the Association for Computational\nLinguistics: EMNLP 2023, pages 14174–14189, Sin-\ngapore. Association for Computational Linguistics.\nDeepSeek-AI, Daya Guo, Dejian Yang, Haowei Zhang,\nJunxiao Song, Ruoyu Zhang, Runxin Xu, Qihao Zhu,\nShirong Ma, Peiyi Wang, Xiao Bi, Xiaokang Zhang,\nXingkai Yu, Yu Wu, Z. F. Wu, Zhibin Gou, Zhi-\nhong Shao, Zhuoshu Li, Ziyi Gao, and 181 others.\n2025. Deepseek-r1: Incentivizing reasoning capa-\nbility in llms via reinforcement learning. Preprint,\narXiv:2501.12948.\nNicholas J Dobbins, Bin Han, Weipeng Zhou, Kris-\ntine F Lan, H Nina Kim, Robert Harrington, Özlem\nUzuner, and Meliha Yetisgen. 2023. Leafai: query\ngenerator for clinical cohort discovery rivaling a hu-\nman programmer. Journal of the American Medical\nInformatics Association, 30(12):1954–1964.\nEMA. 2024. Hma-ema catalogues of real-world data\nsources and studies. Accessed: March 3, 2025.\nDawei Gao, Haibin Wang, Yaliang Li, Xiuyu Sun,\nYichen Qian, Bolin Ding, and Jingren Zhou. 2023.\nText-to-sql empowered by large language models: A\nbenchmark evaluation. Preprint, arXiv:2308.15363.\nYingqi Gao, Yifu Liu, Xiaoxia Li, Xiaorong Shi,\nYin Zhu, Yiming Wang, Shiqi Li, Wei Li, Yun-\ntao Hong, Zhiling Luo, Jinyang Gao, Liyu Mou,\nand Yu Li. 2025.\nA preview of xiyan-sql:\nA\nmulti-generator ensemble framework for text-to-sql.\nPreprint, arXiv:2411.08599.\nGemini Team. 2023. Gemini: A family of highly ca-\npable multimodal models. Technical report, Google.\nAccessed: February 15, 2024.\nAaron Grattafiori, Abhimanyu Dubey, Abhinav Jauhri,\nAbhinav Pandey, Abhishek Kadian, Ahmad Al-\nDahle, Aiesha Letman, Akhil Mathur, Alan Schel-\nten, Alex Vaughan, Amy Yang, Angela Fan, Anirudh\nGoyal, Anthony Hartshorn, Aobo Yang, Archi Mi-\ntra, Archie Sravankumar, Artem Korenev, Arthur\nHinsvark, and 542 others. 2024. The llama 3 herd of\nmodels. Preprint, arXiv:2407.21783.\nGeorge Hripcsak, Ning Shang, Peggy L. Peissig, Luke V.\nRasmussen, Cong Liu, Barbara Benoit, Robert J.\nCarroll, David S. Carrell, Joshua C. Denny, Ozan\nDikilitas, Vivian S. Gainer, Kayla Marie Howell,\nJeffrey G. Klann, Iftikhar J. Kullo, Todd Lingren,\nFrank D. Mentch, Shawn N. Murphy, Karthik Natara-\njan, Jennifer A. Pacheco, and 3 others. 2019. Facili-\ntating phenotype transfer using a common data model.\nJournal of Biomedical Informatics, 96:103253.\nGyubok Lee, Hyeonji Hwang, Seongsu Bae, Yeonsu\nKwon, Woncheol Shin, Seongjun Yang, Minjoon Seo,\nJong-Yeup Kim, and Edward Choi. 2022. Ehrsql: A\npractical text-to-sql benchmark for electronic health\nrecords. In Advances in Neural Information Process-\ning Systems, volume 35, pages 15589–15601. Curran\nAssociates, Inc.\nNut Limsopatham and Nigel Collier. 2016. Normalis-\ning medical concepts in social media texts by learn-\ning semantic representation. In Proceedings of the\n54th Annual Meeting of the Association for Compu-\ntational Linguistics (Volume 1: Long Papers), pages\n1014–1023, Berlin, Germany. Association for Com-\nputational Linguistics.\nOlesya Melnichenko. 2023. Designing multi-step co-\nhort creation flow for biomedical datasets. Microsoft\nTechnical Community Blog.\nLinyong Nan, Yilun Zhao, Weijin Zou, Narutatsu\nRi, Jaesung Tae, Ellen Zhang, Arman Cohan, and\nDragomir Radev. 2023. Enhancing text-to-SQL capa-\nbilities of large language models: A study on prompt\ndesign strategies.\nIn Findings of the Association\nfor Computational Linguistics: EMNLP 2023, pages\n14935–14956, Singapore. Association for Computa-\ntional Linguistics.\nOHDSI Collaborative. 2021.\nThe book of OHDSI.\nIn The Book of OHDSI, chapter 10. Observational\nHealth Data Sciences and Informatics.\n\n\nOMOP-CDM. 2023. Omop cdm common data model.\nhttps://ohdsi.github.io/CommonDataModel/.\nAc-\ncessed: January 23, 2024.\nOpenAI. 2023.\nGpt-4 technical report.\nPreprint,\narXiv:2303.08774.\nOpenAI. 2024. Learning to reason with llms. Accessed:\nSeptember 2024.\nJimyung Park, Yilu Fang, Casey Ta, Gongbo Zhang,\nBetina Idnay, Fangyi Chen, David Feng, Rebecca\nShyu, Emily R. Gordon, Matthew Spotnitz, and\nChunhua Weng. 2024. Criteria2query 3.0: Lever-\naging generative large language models for clinical\ntrial eligibility query generation. Journal of Biomedi-\ncal Informatics, 154:104649.\nBeatrice Portelli, Simone Scaboro, Enrico Santus,\nHooman Sedghamiz, Emmanuele Chersoni, and\nGiuseppe Serra. 2022. Generalizing over long tail\nconcepts for medical term normalization. In Proceed-\nings of the 2022 Conference on Empirical Methods\nin Natural Language Processing, pages 8580–8591,\nAbu Dhabi, United Arab Emirates. Association for\nComputational Linguistics.\nMohammadreza Pourreza and Davood Rafiei. 2023.\nDIN-SQL: Decomposed in-context learning of text-\nto-SQL with self-correction. In Thirty-seventh Con-\nference on Neural Information Processing Systems.\nS. Privitera and A. Hartenstein. 2024. Phenex: Au-\ntomatic phenotype extractor. https://github.com/\nBayer-Group/PhenEx. Accessed: March 3, 2025.\nPreethi Raghavan, Jennifer J Liang, Diwakar Mahajan,\nRachita Chandra, and Peter Szolovits. 2021. emrK-\nBQA: A clinical knowledge-base question answering\ndataset. In Proceedings of the 20th Workshop on\nBiomedical Language Processing, pages 64–73, On-\nline. Association for Computational Linguistics.\nNitarshan Rajkumar, Raymond Li, and Dzmitry Bah-\ndanau. 2022. Evaluating the text-to-sql capabilities\nof large language models. ArXiv, abs/2204.00498.\nChristian Reich, Anna Ostropolets, Patrick Ryan, Pe-\nter Rijnbeek, Martijn Schuemie, Alexander Davy-\ndov, Dmitry Dymshyts, and George Hripcsak. 2024.\nOHDSI Standardized Vocabularies—a large-scale\ncentralized reference ontology for international data\nharmonization. Journal of the American Medical\nInformatics Association, page ocad247.\nRachel E. Sherman, Steven A. Anderson, Gerald J. Dal\nPan, Gerry W. Gray, Thomas Gross, Nina L. Hunter,\nLisa LaVange, Danica Marinac-Dabic, Peter W.\nMarks, Melissa A. Robb, Jeffrey Shuren, Robert Tem-\nple, Janet Woodcock, Lilly Q. Yue, and Robert M.\nCaliff. 2016.\nReal-world evidence — what is it\nand what can it tell us?\nNew England Journal of\nMedicine, 375(23):2293–2297.\nSynPUF. 2010.\nMedicare claims synthetic pub-\nlic use files (synpufs).\nhttps://www.cms.gov/\ndata-research/statistics-trends-and-reports/\nmedicare-claims-synthetic-public-use-files.\nAccessed: January 23, 2024.\nRichard Tarbell, Kim-Kwang Raymond Choo, Glenn Di-\netrich, and Anthony Rios. 2023. Towards understand-\ning the generalization of medical text-to-sql models\nand datasets. AMIA ... Annual Symposium proceed-\nings. AMIA Symposium, 2023:669–678.\nU.S. FDA. 2024. Real-world data: Assessing electronic\nhealth records and medical claims data to support\nregulatory decision-making for drug and biological\nproducts. Guidance for Industry FDA-2020-D-2307,\nU.S. Food and Drug Administration. Final Level 1\nGuidance.\nPing Wang, Tian Shi, and Chandan K. Reddy. 2020.\nText-to-sql generation for question answering on elec-\ntronic medical records. In Proceedings of The Web\nConference 2020, WWW ’20, page 350–361, New\nYork, NY, USA. Association for Computing Machin-\nery.\nShirley V Wang, Simone Pinheiro, Wei Hua, Peter Ar-\nlett, Yoshiaki Uyama, Jesse A Berlin, Dorothee B\nBartels, Kristijan H Kahler, Lily G Bessette, and Se-\nbastian Schneeweiss. 2021. Start-rwe: structured\ntemplate for planning and reporting on the implemen-\ntation of real world evidence studies. BMJ, 372.\nCliff Wong, Sheng Zhang, Yu Gu, Christine Moung, Ja-\ncob Abel, Naoto Usuyama, Roshanthi Weerasinghe,\nBrian Piening, Tristan Naumann, Carlo Bifulco, and\nHoifung Poon. 2023. Scaling clinical trial matching\nusing large language models: A case study in oncol-\nogy. In Proceedings of the 8th Machine Learning\nfor Healthcare Conference, volume 219 of Proceed-\nings of Machine Learning Research, pages 846–862.\nPMLR.\nChao Yan, Henry H Ong, Monika E Grabowska,\nMatthew S Krantz, Wu-Chen Su, Alyson L Dick-\nson, Josh F Peterson, QiPing Feng, Dan M Roden,\nC Michael Stein, V Eric Kerchberger, Bradley A Ma-\nlin, and Wei-Qi Wei. 2024. Large language models\nfacilitate the generation of electronic health record\nphenotyping algorithms. Journal of the American\nMedical Informatics Association, 31(9):1994–2001.\nChi Yuan, Patrick B Ryan, Casey Ta, Yixuan Guo, Zi-\nran Li, Jill Hardin, Rupa Makadia, Peng Jin, Ning\nShang, Tian Kang, and Chunhua Weng. 2019. Cri-\nteria2Query: a natural language interface to clinical\ndatabases for cohort definition. Journal of the Ameri-\ncan Medical Informatics Association, 26(4):294–305.\nHanchong Zhang, Ruisheng Cao, Lu Chen, Hongshen\nXu, and Kai Yu. 2023a. ACT-SQL: In-context learn-\ning for text-to-SQL with automatically-generated\nchain-of-thought.\nIn Findings of the Association\nfor Computational Linguistics: EMNLP 2023, pages\n3501–3532, Singapore. Association for Computa-\ntional Linguistics.\n\n\nPeitian Zhang, Shitao Xiao, Zheng Liu, Zhicheng\nDou, and Jian-Yun Nie. 2023b.\nRetrieve any-\nthing to augment large language models. Preprint,\narXiv:2310.07554.\nSheng Zhang, Hao Cheng, Shikhar Vashishth, Cliff\nWong, Jinfeng Xiao, Xiaodong Liu, Tristan Nau-\nmann, Jianfeng Gao, and Hoifung Poon. 2022.\nKnowledge-rich self-supervision for biomedical en-\ntity linking. In Findings of the Association for Com-\nputational Linguistics: EMNLP 2022, pages 868–\n880, Abu Dhabi, United Arab Emirates. Association\nfor Computational Linguistics.\nAngelo Ziletti, Alan Akbik, Christoph Berns, Thomas\nHerold, Marion Legler, and Martina Viell. 2022.\nMedical coding with biomedical transformer ensem-\nbles and zero/few-shot learning. In Proceedings of\nthe 2022 Conference of the North American Chapter\nof the Association for Computational Linguistics: Hu-\nman Language Technologies: Industry Track, pages\n176–187, Hybrid: Seattle, Washington + Online. As-\nsociation for Computational Linguistics.\nAngelo Ziletti and Leonardo DAmbrosi. 2024.\nRe-\ntrieval augmented text-to-SQL generation for epi-\ndemiological question answering using electronic\nhealth records. In Proceedings of the 6th Clinical\nNatural Language Processing Workshop, pages 47–\n53, Mexico City, Mexico. Association for Computa-\ntional Linguistics.\n\n\n",
  "metadata": {
    "source_file": "dataset/pdfs/arxiv_2502.21107v1.pdf",
    "total_pages": 7,
    "title": "Generating patient cohorts from electronic health records using two-step retrieval-augmented text-to-SQL generation",
    "authors": [
      "Angelo Ziletti",
      "Leonardo D'Ambrosi"
    ],
    "abstract": "Clinical cohort definition is crucial for patient recruitment and\nobservational studies, yet translating inclusion/exclusion criteria into SQL\nqueries remains challenging and manual. We present an automated system\nutilizing large language models that combines criteria parsing, two-level\nretrieval augmented generation with specialized knowledge bases, medical\nconcept standardization, and SQL generation to retrieve patient cohorts with\npatient funnels. The system achieves 0.75 F1-score in cohort identification on\nEHR data, effectively capturing complex temporal and logical relationships.\nThese results demonstrate the feasibility of automated cohort generation for\nepidemiological research.",
    "published_date": "2025-02-28",
    "source": "arxiv"
  }
}