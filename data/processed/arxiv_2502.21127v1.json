{
  "id": "arxiv_2502.21127v1",
  "text": "CuPID: Leveraging Masked Single-Lead ECG Modelling\nfor Enhancing the Representations\nAdrian Atienza 1 Gouthamaan Manimaran 1 Jakob E. Bardram 1 Sadasivan Puthusserypady 1\nAbstract\nWearable\nsensing\ndevices,\nsuch\nas\nElectrocardiogram\n(ECG)\nheart-rate\nmoni-\ntors, will play a crucial role in the future of\ndigital health. This continuous monitoring leads\nto massive unlabeled data, incentivizing the\ndevelopment of unsupervised learning frame-\nworks. While Masked Data Modelling (MDM)\ntechniques have enjoyed wide use, their direct\napplication to single-lead ECG data is suboptimal\ndue to the decoder’s difficulty handling irregular\nheartbeat intervals when no contextual informa-\ntion is provided. In this paper, we present Cueing\nthe Predictor Increments the Detailing (CuPID), a\nnovel MDM method tailored to single-lead ECGs.\nCuPID enhances existing MDM techniques\nby cueing spectrogram-derived context to the\ndecoder,\nthus incentivizing the encoder to\nproduce more detailed representations. This has a\nsignificant impact on the encoder’s performance\nacross a wide range of different configurations,\nleading CuPID to outperform state-of-the-art\nmethods in a variety of downstream tasks.\n1. Introduction\nThe wearable sensing field has seen remarkable advance-\nments in recent years, and is expected to play a crucial role\nin the future of digital health. One widely used type of\nwearable health sensor is the heart monitor that captures\ncardiac activity as single-lead Electrocardiogram (ECG) sig-\nnals during free-living conditions, such as in the patient’s\nhome. Mapping these signals with significant clinical out-\ncomes has the potential to provide outstanding benefits such\nas simplifying the diagnostic process (Himmelreich et al.,\n2019) or enabling users to engage proactively in tracking\ntheir cardiac health (Abdou & Krishnan, 2022). In this\ncontext, models that extract information from single-lead\nECG into generalizable representations are mandated to\naddress distinct downstream tasks. In addition, this contin-\nuous monitoring leads to massive unlabeled datasets. This\nmakes Self-Supervised Learning (SSL) framework particu-\nlarly well-suited for addressing this clinical challenge.\nFigure 1. Example of the commonly used masking strategy pro-\nposed in (Na et al., 2024) for 12-Lead ECG processing. Unmasked\nportions are displayed in blue. Most of the ECG waves remain\nunmasked in at least one of the leads.\nRecently, Masked Data Modelling (MDM) methods have\nbeen gaining attention in the SSL field (He et al., 2021;\nGupta et al., 2023; Assran et al., 2023). They rely on mask-\ning a portion of the input and driving a transformer-based\nencoder, typically a Vision Transformer (ViT) (Dosovitskiy\net al., 2021) to compute detailed representations that en-\nable a decoder to infer the unseen patches. In the realm of\n12-lead ECG processing, MDM methods have been applied\nrecently with promising results (Na et al., 2024). They prove\nthat independently masking the different leads outperforms\nthe strategy of consistently masking across time proposed\nin Masked Time Autoencoder (MTAE) (Zhang et al., 2023).\nThis lead-independent masking strategy, represented in Fig-\nure 1, allows the encoder to model the temporal positions\nof the distinct ECG waves by integrating the unmasked por-\ntions of the various leads. This contextual information is\ncrucial, as it enables the decoder to deal with fluctuations in\nthe time intervals between heartbeats. However, this mask-\ning strategy can not be applied to single-lead ECG data, our\ndata of interest, which just accommodates one signal. The\ndecoder encounters challenges in handling irregular heart-\nbeat intervals, as it lacks contextual information from other\nleads. Since not inferring exactly this position has a big im-\npact on the loss, the decoder is cautious when reconstructing\nthe masked patches. Figure 2a displays how it estimates a\nvalue near the average rather than matching precisely the\nsignal’s morphology.\n1\narXiv:2502.21127v1  [cs.LG]  28 Feb 2025\n\n\nCuPID: Leveraging Masked Single-Lead ECG Modelling for Enhancing the Representations\n(a)\n(b)\n(c)\n(d)\nFigure 2. Reconstruction comparison between CuPID and MTAE. Figures 2a and 2c display a reconstruction from MTAE and CuPID,\nwhere the unmasked part, the ground truth, and the inference computed by both methods are represented in gray, blue, and orange,\nrespectively. Figure 2b illustrates loss function evolution across pre-training. Figure 2d compares the performance of CuPID and MTAE,\nacross different heartbeat irregularity levels, measured in SDNN (Standard Deviation of Normal Intervals).\nThis paper presents Cueing the Predictor Increments the\nDetailing (CuPID), which is a novel SSL method that\naddresses the issue mentioned above by cueing the decoder\nwith contextual information provided by the spectrogram\nof the input signal. The spectrogram is expected to mirror\nthe contextual information provided by other leads in\nthe 12-Lead ECG framework. It is fed into the attention\nmechanism of the decoder as the Key (K) to ensure that its\nrole is merely informative and its value can not be used\ndirectly to reconstruct the representations. It leads to a\nsignificant decrease in the loss function values, as shown\nin Figure 2b, and reconstructions are adjusted more to the\nmorphology of the original signal, as captured in Figure\n2c. Figure 2d shows how this behavior is consistent across\ndifferent levels of irregularity in heartbeat intervals.\nAlthough these results are insignificant on their own since\nCuPID’s decoder is provided with additional information,\nwe hypothesize: (I) The decoder’s inability to reconstruct\nthe original signal due to the irregularity in the heartbeat\nintervals limits the encoder’s learning potential. (ii) Cueing\nthe decoder with the spectrogram endows it with the\npotential to solve the task. It drives the encoder to compute\ndetailed patch representations which can be used to\naccurately reconstruct the input. (iii) The more informative\nthe patch representations are, the more performant the\nencode will be at the time of addressing downstream tasks.\nTo assess our hypothesis, we have conducted an extensive\nevaluation where CuPID is compared against the existing\nstate-of-the-art SSL methods tailored for single-lead ECG\nanalysis. Up to three distinct databases; MIT-BIH Atrial\nFibrillation (MIT-AFIB) (Moody & Mark, 1983), Physionet\nChallenge 2017 (Clifford et al., 2017), and Long Term\nAF (LT-AF) (Petrutiu et al., 2007), are considered. Remark-\nably, CuPID achieves significantly superior performance\nwhen compared with single-lead ECG methods. Finally, the\nbenefit of incorporating the spectrogram compared with the\nMTAE baseline is assessed for different configurations.\nIn summary, the contributions of this paper are:\n• We have discussed the limitations of applying MDM\ntechniques directly to single-lead ECG signals due to\nthe idiosyncrasy of this kind of data.\n• We introduce CuPID, a novel SSL method that ad-\ndresses these limitations by helping the decoder dur-\ning the pre-training. This is made by incorporating\nthe spectrogram of the input signal to the attention\nmechanism as the Key, limiting its role to be merely\ninformative.\n• We provide a model that achieves markedly enhanced\nresults in a variety of downstream tasks that are relevant\nfor cardiovascular remote monitoring.\n2\n\n\nCuPID: Leveraging Masked Single-Lead ECG Modelling for Enhancing the Representations\n2. Related Work\n2.1. Masked Data Modelling (MDM)\nMasked Data Modelling (MDM) has been a commonly used\ntechnique in the Natural Language Processing (NLP) field.\nMethods such as Bidirectional Encoder Representations\nfrom Transformers (BERT) (Devlin et al., 2019) that rely on\nhiding a series of words within a sentence and optimizing\na decoder to infer these words have proven to be the most\neffective pre-training method in the field.\nIn recent times, this pre-training mechanism has been\nadapted in the field of computer vision. Existing methods,\nsuch as, Masked Autoencoders (MAE) (He et al., 2021) or\nSiamese Masked Autoencoders (SiamMAE) (Gupta et al.,\n2023) incorporate a decoder trained to reconstruct masked\npatches from the original input. This approach has shown\npromising results in the field of computer vision, outper-\nforming gold-standard Energy-Based Modelling (EBM)\nmethods such as Variance-Invariance-Covariance Regular-\nization (VIC-REG) (Bardes et al., 2022), Self-Distillation\nwith no Labels (DINO) (Caron et al., 2021), or Bootstrap\nYour Own Latent (BYOL) (Grill et al., 2020).\n2.2. SSL in 12-Lead ECG Signal Processing\nIn the realm of 12-lead ECG signals, research has effec-\ntively utilized the MDM framework. The availability of\nvarious leads broadens the scope for the strategy of input\nmasking. Techniques like MTAE, MLAE, and MLTAE, all\nintroduced by MAE family of ECG (MaeFE) (Zhang et al.,\n2023), suggest three masking strategies: temporal masking,\nspatial masking across different leads, or a combination of\nboth. Spatio-Temporal Masked Electrocardiogram Model-\ning (ST-MEM) (Na et al., 2024) reaches the state-of-the-art\nperformance by employing a joint decoder that reconstructs\nthe original input attending to each lead independently. It\nproves that adopting this combined strategy by indepen-\ndently masking the different leads achieves the best results.\nAmong the four listed methods, only MTAE is suitable for\nsingle-lead ECG signals, as the other three require multiple\nleads. MTAE is not only included in the evaluation, but\nalso in the ablation studies since this method is CuPID’s\nanalogous version without the use of the spectrogram.\n2.3. SSL in Single-Lead ECG Signal Processing\nMost-widely used single-lead ECG SSL methods follows\na EBM approach; (i) Contrastive Learning of Cardiac Sig-\nnals Across Space (CLOCS) (Kiyasseh et al., 2021) uti-\nlizes two consecutive ECG time strips as positive pairs, (ii)\nMixing-Up (Wickstrøm et al., 2022) introduces a more tai-\nlored data augmentation product of two time series from the\nsame recording, (iii) Patient Contrastive Learning (PCLR)\n(Diamant et al., 2022) which considers two time strips\nfrom the same subject but different recordings.\nWhile\nall these methods utilize the Contrastive Learning (Chen\net al., 2020) as a common framework for learning the in-\nvariant attributes considering non-overlapping inputs as\npositive pairs, Distilled Embedding for Almost-Periodic\nTime Series (DEAPS) (Atienza et al., 2024) follows a non-\ncontrastive learning approach. (iv) It drives the model to\ncapture the also dynamic patterns of the single-lead ECGs.\nAll of these SSL methods will compose the set of base-\nlines for the CuPID’s evaluation, where the representations\ncomputed by each pre-trained model will be employed for\naddressing several downstream tasks.\n2.4. Use of Spectogram for ECG Processing\nSpectrograms have enjoyed wide use in ECG signal process-\ning due to their ability to provide a time-varying spectral\ndensity description of the data. Consequently, it is often\nused as a substitute for the ECG signal as input for deep\nlearning models designed to address various arrhythmia\nclassification tasks (Eleyan et al., 2024; Bing et al., 2022).\nAdditionally, the spectrogram can be treated as an image,\nenabling the application of SSL techniques developed for\ncomputer vision to this type of data (Thinh et al., 2022).\nAll the previously mentioned methods actively utilize the\nspectrogram to map input to clinical outcomes. CuPID\nstands out since the spectrogram is only employed during\npre-training to provide the decoder with the temporal con-\ntext of the ECG waves. The encoder does not receive the\nspectrogram, and thus, it is not used during inference.\n3. Cueing the Predictor Increments the\nDetailing (CuPID)\nThe core idea behind CuPID is cueing the decoder with the\ncontextual information provided by the spectrogram. Its\nworkflow is illustrated in Figure 3. From left to right the\noriginal signal input is patched and embedded using a linear\nlayer. A portion of these tokens (Represented as gray blocks\nin the figure) is randomly masked with a fixed ratio. Only\nthe unmasked tokens are passed through the encoder. Learn-\nable mask tokens with their respective positional encoding\nare placed in the original position of the masked segments.\nWhat sets CuPID apart is that it uses the spectrogram as the\nKey for the attention mechanism, as represented in Figure 3.\nThis decoder reconstructs the original input. The L1 metric\nis computed between this reconstruction and the original\ninput. This loss function is only calculated on the masked\npatches. It is important to note that the decoder is discarded\nafter training, with the encoder being used for downstream\ntasks. Therefore, the spectrogram is only utilized during\npre-training and not during inference.\n3\n\n\nCuPID: Leveraging Masked Single-Lead ECG Modelling for Enhancing the Representations\nFigure 3. CuPID architecture. The left side of the Figure shows how the spectrogram is incorporated into the decoder’s attention\nmechanism. This incorporation sets CuPID apart from the standard framework for MDM. The encoder is the model used to address the\ndownstream tasks, while the decoder is discarded after the pre-training. Therefore, this spectrogram is not provided during the evaluation.\nThe right side of the diagram provides a closer look at CuPID’s decoder. Due to the challenges of using the spectrogram as a Key, the\nspectrogram is incorporated from the second block of the decoder. Its first block mirrors the standard decoder block for MDM framework.\n3.1. Role of Spectrogram for the decoder\nDue to the lack of contextual information, the baseline de-\ncoder faces challenges when handling irregular heartbeat\nintervals. The core idea behind CuPID is to provide the\ndecoder with the needed contextual information from an\nalternative source. The spectrogram is identified as an effec-\ntive tool for this purpose. This section delves deeper into\nthe rationale behind this decision and its implementation.\nSpectrogram as Choice:\nA spectrogram is a visual rep-\nresentation of the spectrum of frequencies in a signal as\nthey vary over time. They are commonly generated using\nthe Fast Fourier Transform (FFT), which converts a time-\ndomain signal into its frequency components.\nWe identify the spectrogram as a tool that has the potential to\nprovide the decoder with the needed contextual information\nsince: (i) The spectrogram retains the temporal aspect of the\nsignal, allowing us to isolate the frequency component of\neach patch by dividing it into consistent patches aligned with\nthe original input ones. (ii) The distinct waves accommo-\ndated in the ECG signal operate in distinct frequencies. This\nfeature is leveraged by traditional signal processing methods\nto perform ECG signal delineation (Martinez et al., 2004).\nTherefore, by providing the frequency component of each\nmask token, the decoder can determine if a wave is present\nthere and identify the kind of wave it should reconstruct.\nLimiting the Information Provided by the Spectrogram:\nJust as the time domain input is transformed into the fre-\nquency domain when computing the spectrogram, it can\nalso be converted back to the time domain. It means that the\ndecoder could potentially reconstruct the original input with-\nout using the encoder’s representations. To prevent this, the\nspectrogram is used just as the K in the attention mechanism\nwhen fed into the decoder. This transformer-based decoder\nrelies on the standard attention mechanism formulated on\n(Vaswani et al., 2017). It is composed of three components,\ni.e., query (Q), key (K), and value (V ) and it is expressed\nas the following:\nAttention(Q, K, V ) = softmax\n\u0012QKT\n√dk\n\u0013\nV,\n(1)\nwhere the query (Q) refers to the token that is attending\nthe others for information, the key (K) represents what\ninformation can be found in the specific token, and the value\n(V ) accommodates the information. It is worth highlighting\nthat the K only has the potential of informing what kind\nof information it could be found in the respective token,\nbut not providing information by itself. This information\nis provided by the corresponding V . In other words, even\nthough the spectrogram gathers all the information needed\nfor reconstructing the input, this information can not be\napplied directly.\n4\n\n\nCuPID: Leveraging Masked Single-Lead ECG Modelling for Enhancing the Representations\nChallenges of Using the Spectrogram as the Key:\nCu-\nPID does not mask the spectrogram when fed into the de-\ncoder. The purpose of incorporating the spectrogram is to\nenhance mask tokens with contextual information about the\ntemporal location and the kind of ECG waves each accom-\nmodates for an accurate reconstruction. Therefore, masking\nthe spectrogram would be counterproductive.\nHowever, a primary issue arises when using the spectro-\ngram without masking it. Since this spectrogram is fed\nas the K into the attention mechanism of the decoder, it\ncannot distinguish between informative tokens and mask\ntokens, as this distinction is not present in the spectrogram.\nTherefore, a token might be retrieving information from a\nmask token even when it is merely a mask and contains no\nactual information. To overcome this issue, CuPID delays\nincorporating the spectrogram into the decoder’s second\nblock. Consequently, the regular concatenation of encoder\nrepresentations and mask tokens is used as the K in the\nfirst encoder block. By doing this, CuPID ensures that each\nmask token retains some information after the initial block,\nwhich can then be distilled in subsequent blocks with the\ncontext information provided by the spectrogram.\nDecoder Workflow and Loss Function:\nConsidering\nthese two crucial aspects, Figure 3 depicts the CuPID de-\ncoder. In the initial block, the inference follows a conven-\ntional approach, while the spectrogram is integrated into\nsubsequent blocks as the K in the attention mechanism.\nThis decoder computes the single-lead ECG reconstruction,\nwhich is compared to its corresponding original input using\nthe L1 metric. This metric serves as the sole loss function\nof the model and is represented by the following formula:\nL1(X, ˆY , M) =\n1\nsum(M) ·\nn\nX\ni=1\n\f\f\fYi −ˆYi\n\f\f\f · Mi,\n(2)\nwhere X, ˆY , M, and n represent the original input, the de-\ncoder reconstruction, the mask, and the number of patches.\n3.2. Implementation Details\nTo ensure the replication of the method, we meticulously\noutline the hyperparameter configuration.\nModel Architecture: As is standard practice when eval-\nuating MDM approaches, the standard ViT (Dosovitskiy\net al., 2021) architecture is used as the encoder module.\nTo align the encoder size with the data complexity and\nmeet the efficiency requirements for constant monitoring,\nCuPID introduces a very lightweight model. In detail, the\nViT architecture proposed by CuPID for processing the\nsingle-lead ECG signals count with four regular transformer\nblocks with four heads each and a model dimension of 128.\nThe input consists of a one-dimensional 10-second signal\nsampled at 100 Hz. This signal is split into patches with\na length of 20 samples. The influence of the patch size is\nstudied in Section 5.\nCuPID Implementation and Optimization: The decoder\nconsists of a ViT model with two blocks and a dimension\nof 128. The training procedure consists of 45,000 iterations.\nWe use a batch size of 256, AdamW (Loshchilov & Hutter,\n2019) optimizer with a learning rate of 1e −3. To compute\nthe spectrogram consistent with both the decoder dimen-\nsions and the patch length, the number of coefficient bins is\nset to 255 and the window length to 40. The masking ratio\nis set to 0.4. The masking ratio and the length of the training\nprocess have been determined by a sensitivity study (See\nSection 5). The training procedure and the evaluations are\nperformed on a desktop computer, with a Nvidia GeForce\nRTX 3070 GPU.\n4. Evaluation\nTo assess our hypotheses, we have conducted an extensive\nevaluation. This included five different baselines from key\nstudies in single-lead ECG processing, three commonly\nused benchmarking datasets, and both linear probing and\nfine-tuning experiments. This section presents the details of\nthe evaluation, along with the results and their discussion.\n4.1. Baselines.\nCuPID has been evaluated against the following meth-\nods that compel the set of baselines for the evaluation;\nCLOCS (Kiyasseh et al., 2021), PCLR (Diamant et al.,\n2022), MTAE, from (Zhang et al., 2023); DEAPS (Atienza\net al., 2024); and Mix-up (Wickstrøm et al., 2022). To en-\nsure fairness in the evaluation, all the methods have been\ntrained using the same optimizer for the same number of\nepochs. The hyperparameter configuration for each baseline\nhas been set up according to the specifics of each paper.\n4.2. Pre-Training Dataset\nThe different methods necessitate specific properties in the\npre-training dataset. For instance, PCLR requires ECG\nrecordings from the same patient across different years,\nwhile DEAPS needs recordings longer than 2 minutes.\nSince all methods should be pre-trained using the same\ndataset to ensure a fair evaluation, the SHHS dataset Sleep\nHeart Health Study (SHHS) (Zhang et al., 2018; Quan\net al., 1998) is used as the only pre-training data source.\nIt has been identified as the only large publicly available\ndataset that meets the conditions for all methods used in\nthe evaluation. The details of SHHS are provided in the\n5\n\n\nCuPID: Leveraging Masked Single-Lead ECG Modelling for Enhancing the Representations\nAppendix B.\n4.3. Downstream Datasets.\nThis section describes the datasets used for the various\ndownstream tasks. These datasets, commonly employed for\nbenchmarking ECG methods, have been carefully selected\nto offer different perspectives on the different method’s per-\nformance, as detailed below. All these databases are publicly\navailable on Physionet (Goldberger et al., 2000).\nMIT-BIH Atrial Fibrillation (MIT-AFIB) (Moody &\nMark, 1983):\nThis dataset accommodates long-term\nrecordings of 23 subjects transitioning between Normal Si-\nnus Rhythm (NSR) to paroxysmal Atrial Fibrillation (AFib)\nepisodes and vice versa. To achieve strong performance\non this downstream task, the encoder is expected to learn\ndetailed representations during the pre-training step to dis-\ncretize between the different states the subject experiences\nthroughout the recording. This is necessary because the lim-\nited number of subjects seems insufficient for the encoder\nto learn these distinctions during the fine-tuning procedure.\nLong Term AF (LT-AF) (Petrutiu et al., 2007):\nThis\ndataset compels long-term recordings of 84 subjects. It is\ncomposed of subjects suffering spontaneous bradycardia\nepisodes and subjects with sustained AFib in addition to\nsubjects suffering paroxysmal AFib episodes that are also\ncontained in the previous dataset. This dataset includes\nmore subjects than the previous one, although the number\nof subjects remains limited. It provides a different view of\nthe method’s performance since it introduces a new class\nof arrhythmia and is unbalanced. All this underscores the\nimportance of pre-training. The encoder, similar to the\nprevious dataset, cannot be expected to learn new features\nduring fine-tuning that distinguish between the three classes.\nPhysionet Challenge 2017 (Clifford et al., 2017): This\ndataset comprises over 8,000 recordings aimed at distin-\nguishing between Sinus Rhythm, AF, and other arrhythmias.\nDespite having the fewest instances, it can be assumed that\neach instance corresponds to a different subject. Existing lit-\nerature (Guldenring et al., 2022) indicates that ECG datasets\nscale more with the number of subjects rather than the num-\nber of instances per subject. Therefore, this downstream\ntask will provide additional insights into how the perfor-\nmance of different methods scales when fine-tuning with a\nsufficiently large dataset.\n4.4. Experiments\nWe carried out a 5-fold cross-validation for MIT-AFIB and\nLT-AF datasets. The training, validation, and test datasets\nwere split with a ratio of 60-20-20, ensuring no patient\noverlap between the different partitions. It will artificially\nboost the performance. For the Physionet Challenge 2017\ndataset, we adhered to the recommended train-test split.\nIn practical applications, just a single encoder should be\nused to derive useful representations that can be utilized\nacross multiple downstream tasks to meet the real time\nmonitoring efficiency needs. Consequently, we argue that\nlinear probing evaluation holds greater importance, as fine-\ntuning the model creates task-specific encoders, requiring a\ndistinct model for each task.\nHowever, to scientifically assess CuPID, we have conducted\nboth linear probing and fine-tuning experiments for all the\npreviously mentioned datasets. For linear probing evalua-\ntion, a Logistic Regression model has been fitted on top of\nthe representations. For the fine-tuning evaluation, the en-\ncoder weights were updated using an Adam (Kingma & Ba,\n2017) optimizer with a learning rate of 1e-4. The fine-tuning\ntraining finishes with an early-stopping patience of 5 based\non the loss function values on the validation split, ensuring\nno decisions were influenced by the test split performance.\nTable 1. Performance comparison of various methods under linear probing and fine-tuning on three ECG datasets. Best values in bold and\nsecond best underlined.\nMIT-AFIB\nLT-AF\nPhysionet 2017\nMethods\nAccuracy\nF1\nAUC\nAccuracy\nF1\nAUC\nAccuracy\nF1\nAUC\nLinear Probing\nPCLR\n0.691 ± 0.113\n0.636 ± 0.095\n0.731 ± 0.113\n0.808 ± 0.058\n0.568 ± 0.048\n0.869 ± 0.034\n0.6454 ± 0.0104\n0.5597 ± 0.0094\n0.7621 ± 0.0129\nMix-Up\n0.691 ± 0.056\n0.579 ± 0.232\n0.746 ± 0.103\n0.813 ± 0.045\n0.593 ± 0.060\n0.889 ± 0.031\n0.6546 ± 0.0186\n0.5817 ± 0.0188\n0.7906 ± 0.0109\nDEAPS\n0.790 ± 0.079\n0.687 ± 0.189\n0.851 ± 0.100\n0.829 ± 0.045\n0.592 ± 0.051\n0.893 ± 0.033\n0.6791 ± 0.0126\n0.6228 ± 0.0081\n0.7897 ± 0.0082\nCLOCS\n0.680 ± 0.088\n0.567 ± 0.218\n0.709 ± 0.108\n0.748 ± 0.023\n0.534 ± 0.032\n0.843 ± 0.032\n0.6117 ± 0.0112\n0.4650 ± 0.0186\n0.7473 ± 0.0135\nMTAE\n0.808 ± 0.937\n0.758 ± 0.071\n0.878 ± 0.080\n0.875 ± 0.035\n0.636 ± 0.043\n0.919 ± 0.024\n0.6064 ± 0.0117\n0.4820 ± 0.0056\n0.7623 ± 0.0106\nCuPID (Ours)\n0.860 ± 0.041\n0.782 ± 0.107\n0.933 ± 0.010\n0.880 ± 0.030\n0.671 ± 0.042\n0.934 ± 0.021\n0.7119 ± 0.0102\n0.6611 ± 0.0150\n0.8108 ± 0.0064\nFine-Tuning\nPCLR\n0.779 ± 0.097\n0.728 ± 0.098\n0.897 ± 0.031\n0.867 ± 0.035\n0.581 ± 0.025\n0.840 ± 0.036\n0.760 ± 0.012\n0.714 ± 0.012\n0.839 ± 0.012\nMix-Up\n0.726 ± 0.067\n0.656 ± 0.052\n0.848 ± 0.071\n0.849 ± 0.042\n0.567 ± 0.031\n0.801 ± 0.034\n0.809 ± 0.011\n0.777 ± 0.013\n0.872 ± 0.002\nDEAPS\n0.778 ± 0.079\n0.717 ± 0.074\n0.873 ± 0.041\n0.887 ± 0.031\n0.626 ± 0.058\n0.898 ± 0.039\n0.822 ± 0.011\n0.800 ± 0.019\n0.871 ± 0.011\nCLOCS\n0.721 ± 0.072\n0.657 ± 0.092\n0.708 ± 0.126\n0.850 ± 0.039\n0.612 ± 0.067\n0.858 ± 0.043\n0.735 ± 0.013\n0.676 ± 0.021\n0.826 ± 0.013\nMTAE\n0.757 ± 0.077\n0.714 ± 0.035\n0.816 ± 0.047\n0.879 ± 0.031\n0.611 ± 0.023\n0.852 ± 0.037\n0.674 ± 0.018\n0.585 ± 0.034\n0.789 ± 0.011\nCuPID (Ours)\n0.888 ± 0.074\n0.860 ± 0.081\n0.955 ± 0.017\n0.889 ± 0.024\n0.616 ± 0.040\n0.887 ± 0.044\n0.805 ± 0.017\n0.773 ± 0.023\n0.876 ± 0.012\n6\n\n\nCuPID: Leveraging Masked Single-Lead ECG Modelling for Enhancing the Representations\n4.5. Discussion of the Results\nTable 1 illustrates that CuPID excels in all metrics across ev-\nery downstream task in the linear proving evaluation. These\nresults are noteworthy because, as previously mentioned, ef-\nfective remote monitoring requires a single encoder capable\nof handling a diverse range of downstream tasks.\nRegarding CuPID fine-tuning results, Table 1 indicates that\nthe performance improvement for datasets MIT-AFIB and\nLT-AF is minimal compared to linear probing. These find-\nings align with recent studies (Bergamaschi et al., 2024),\nwhich suggest that in highly limited cohort conditions, fine-\ntuning can yield worse results than linear probing. As previ-\nously mentioned, these outcomes are supported by research\n(Guldenring et al., 2022), which demonstrates that an ECG\ndataset scales with the number of patients rather than the\nnumber of instances. Notably, these datasets consist of 23\nand 84 patients, respectively. Conversely, CuPID’s perfor-\nmance improves when the dataset is composed of a larger\nnumber of subjects, such as Physionet Challenge 2017. Cu-\nPID outperforms the baseline set on most metrics, and de-\nlivers competitive results for the rest of them.\nLastly, we would like to highlight that CuPID consistently\noutperforms its analogue version, MTAE, which does not\nleverage the decoder with the contextual information pro-\nvided by the spectrogram. A more detailed comparison\nbetween these two methods will be provided in the next sec-\ntion. These findings provide robust evidence in favor of the\nhypotheses posited by this study: (I) The decoder’s inability\nto reconstruct the original signal due to the irregularity in\nthe heartbeat intervals limits the encoder’s learning poten-\ntial. (ii) Cueing the decoder with the spectrogram endows it\nwith the potential to solve the task. It drives the encoder to\ncompute detailed patch representations which can be used\nto accurately reconstruct the input. (iii) The more informa-\ntive the patch representations are, the more performant the\nencode will be at the time of addressing downstream tasks.\n5. Ablation and Sensitivity Studies\nThis section aims to evaluate the impact of various hyperpa-\nrameters on model performance and to determine whether\nincorporating the spectrogram in the decoder offers benefits\nacross different hyperparameter configurations. Specifically,\nwe will assess the influence of patch size, masking ratio,\ntraining duration, and encoder size. For all evaluated hy-\nperparameter combinations, CuPID’s performance will be\ncompared to its analogue version without the incorpora-\ntion of the spectrogram, MTAE. This evaluation will be\nconducted across the three downstream tasks. Due to the\nimpracticality of fine-tuning numerous configurations, this\nevaluation will be conducted using linear probing. How-\never recent literature (Balestriero et al., 2023) suggests is a\nvaluable indicator of the quality of the representations.\nInfluence of the Masking Ratio and Patch Size:\nTable\n2 presents the performance of CuPID and MTAE across\nvarious configurations for the downstream datasets. These\nresults validate the selection of a patch size of 20 and a\nmasking ratio of 0.4 for both methods, as this combination\nconsistently yields the best overall metrics. Notably, CuPID\noutperforms MTAE in 34 out of 45 possible combinations\n(over 75%). This results in overall improvements ranging\nfrom 2.1% to 4.2% for each dataset. Additionally, CuPID\nachieves the best metrics for each dataset.\nTable 2. Ablation study results for different parameter settings on three ECG datasets. The final row represents the mean MAE and CuPID\nacross all experiments. Accuracy is the metric chosen for displaying the results.\nHyperparameters\nMIT-AFIB\nLF-AF\nPhysionet 2017\nPS\nMR\nMTAE\nCuPID\nMTAE\nCuPID\nMTAE\nCuPID\n10\n0.3\n0.733 ± 0.050\n0.776 ± 0.093\n0.830 ± 0.040\n0.875 ± 0.034\n0.648 ± 0.017\n0.684 ± 0.017\n10\n0.4\n0.777 ± 0.068\n0.793 ± 0.094\n0.819 ± 0.035\n0.876 ± 0.030\n0.694 ± 0.014\n0.681 ± 0.014\n10\n0.5\n0.656 ± 0.064\n0.821 ± 0.075\n0.817 ± 0.041\n0.856 ± 0.034\n0.658 ± 0.025\n0.676 ± 0.025\n10\n0.6\n0.788 ± 0.070\n0.751 ± 0.101\n0.848 ± 0.028\n0.855 ± 0.049\n0.615 ± 0.018\n0.686 ± 0.018\n10\n0.7\n0.803 ± 0.076\n0.737 ± 0.102\n0.835 ± 0.043\n0.808 ± 0.064\n0.653 ± 0.012\n0.636 ± 0.012\n20\n0.3\n0.703 ± 0.054\n0.780 ± 0.078\n0.852 ± 0.039\n0.889 ± 0.029\n0.685 ± 0.013\n0.683 ± 0.013\n20\n0.4\n0.808 ± 0.093\n0.860 ± 0.041\n0.875 ± 0.035\n0.880 ± 0.030\n0.703 ± 0.012\n0.715 ± 0.012\n20\n0.5\n0.815 ± 0.070\n0.836 ± 0.090\n0.870 ± 0.040\n0.882 ± 0.026\n0.701 ± 0.012\n0.727 ± 0.012\n20\n0.6\n0.819 ± 0.087\n0.812 ± 0.086\n0.860 ± 0.324\n0.876 ± 0.038\n0.678 ± 0.011\n0.709 ± 0.011\n20\n0.7\n0.723 ± 0.093\n0.752 ± 0.072\n0.857 ± 0.025\n0.849 ± 0.024\n0.683 ± 0.024\n0.695 ± 0.024\n25\n0.3\n0.768 ± 0.068\n0.833 ± 0.080\n0.835 ± 0.043\n0.868 ± 0.051\n0.670 ± 0.015\n0.697 ± 0.015\n25\n0.4\n0.793 ± 0.091\n0.821 ± 0.057\n0.846 ± 0.041\n0.852 ± 0.043\n0.673 ± 0.013\n0.693 ± 0.013\n25\n0.5\n0.818 ± 0.050\n0.815 ± 0.076\n0.854 ± 0.040\n0.869 ± 0.045\n0.732 ± 0.013\n0.727 ± 0.013\n25\n0.6\n0.799 ± 0.066\n0.860 ± 0.050\n0.861 ± 0.044\n0.870 ± 0.036\n0.714 ± 0.024\n0.709 ± 0.024\n25\n0.7\n0.773 ± 0.088\n0.810 ± 0.102\n0.847 ± 0.010\n0.863 ± 0.040\n0.667 ± 0.014\n0.695 ± 0.014\nMean (∆)\n0.772 ± 0.073\n0.804 ± 0.080 (↑4.2%)\n0.847 ± 0.055\n0.865 ± 0.038 (↑2.1%)\n0.679 ± 0.016\n0.694 ± 0.016 (↑2.3%)\n7\n\n\nCuPID: Leveraging Masked Single-Lead ECG Modelling for Enhancing the Representations\nInfluence of the Training Procedure Duration:\nWe have\nevaluated the impact of pre-training duration. Figure 5\nillustrates that performance in various downstream tasks\nimproves up to the 45K iteration, after which a general de-\ncline is observed across different datasets for both methods.\nThese findings support the selection of this iteration count\nand align with relevant studies (He et al., 2021) indicating\nthat model performance deteriorates beyond a certain point.\nNotably, as shown in Figure 5, CuPID outperforms in most\ncheckpoints evaluated during the pre-training process across\ndifferent datasets.\nFigure 4. Evolution of the performance over training procedure\nInfluence of the Model Size:\nWe evaluated the perfor-\nmance of both models with various encoder sizes. Table\n5 indicates that models larger than the proposed one do\nnot show significant improvement. This suggests that an\nencoder with 4 transformer blocks is adequate to capture\nthe complexity of single-lead ECG signals. Notably, CuPID\nconsistently achieves better results across different datasets\nand model sizes.\nFigure 5. Impact of the model size on the model.\n6. Conclusion\nThis research provides strong evidence that directly applying\nthe Masked Data Modelling (MDM) framework to single-\nlead ECG signals is suboptimal. Due to the lack of con-\ntextual information provided by the unmasked patches of\nthe other leads, the baseline decoder faces challenges when\nhandling irregular heartbeat intervals. This leads the predic-\ntor to be cautious when reconstructing the masked patches\nand to not drive the encoder to compute detailed patch rep-\nresentations that can be used for addressing downstream\ntasks. To overcome this issue, we introduce CuPID, a novel\nSSL technique for ECG analysis. By cueing the predictor\nwith the contextual information given by the spectrogram\nof the input signal, CuPID enforces the encoder to compute\nmore informative representations. It results in a significant\nperformance improvement when addressing downstream\ntasks.\nLimitations:\nWe have evaluated CuPID solely using one\npre-training dataset. As discussed in the manuscript, this is\ndue to SHHS is the only dataset that fits the requirements of\nall the SSL methods that compose set of baselines.\n7. Reproducibility Statement\nThe attached code as a part of the supplementary material en-\ncompasses the implementation of CuPID and several other\nbaselines. Moreover, comprehensive details on training hy-\nperparameters, schemes, and hardware specifications are\nprovided. In addition the pseudocode for the method is pro-\nvided in the Appendix. Finally, we furnish the pre-trained\nmodel’s parameters to facilitate others in achieving repro-\nducible results, together with the code used for processing\neach database.\n8\n\n\nCuPID: Leveraging Masked Single-Lead ECG Modelling for Enhancing the Representations\nReferences\nAbdou, A. and Krishnan, S. Horizons in single-lead ecg\nanalysis from devices to data. Frontiers in Signal Process-\ning, 2, 2022. ISSN 2673-8198. doi: 10.3389/frsip.2022.\n866047. URL https://www.frontiersin.org/\narticles/10.3389/frsip.2022.866047.\nAssran, M., Duval, Q., Misra, I., Bojanowski, P., Vincent,\nP., Rabbat, M., LeCun, Y., and Ballas, N. Self-supervised\nlearning from images with a joint-embedding predic-\ntive architecture, 2023. URL https://arxiv.org/\nabs/2301.08243.\nAtienza, A., Bardram, J., and Puthusserypady, S. Con-\ntrastive learning is not optimal for quasiperiodic time\nseries. In Larson, K. (ed.), Proceedings of the Thirty-\nThird International Joint Conference on Artificial Intel-\nligence, IJCAI-24, pp. 3661–3668. International Joint\nConferences on Artificial Intelligence Organization, 8\n2024.\ndoi: 10.24963/ijcai.2024/405.\nURL https:\n//doi.org/10.24963/ijcai.2024/405. Main\nTrack.\nBalestriero, R., Ibrahim, M., Sobal, V., Morcos, A., Shekhar,\nS., Goldstein, T., Bordes, F., Bardes, A., Mialon, G., Tian,\nY., Schwarzschild, A., Wilson, A. G., Geiping, J., Garrido,\nQ., Fernandez, P., Bar, A., Pirsiavash, H., LeCun, Y., and\nGoldblum, M. A cookbook of self-supervised learning,\n2023.\nBardes, A., Ponce, J., and LeCun, Y. Vicreg: Variance-\ninvariance-covariance regularization for self-supervised\nlearning, 2022.\nBergamaschi, T. S., Stultz, C. M., and Alam, R. Heart block\nidentification from 12-lead ecg: Exploring the generaliz-\nability of self-supervised ai. In 2024 IEEE 20th Interna-\ntional Conference on Body Sensor Networks (BSN), pp.\n1–4, 2024. doi: 10.1109/BSN63547.2024.10780740.\nBing, P., Liu, Y., Liu, W., Zhou, J., and Zhu, L. Electrocar-\ndiogram classification using tsst-based spectrogram and\nconvit. Frontiers in Cardiovascular Medicine, 9, 2022.\nISSN 2297-055X. doi: 10.3389/fcvm.2022.983543. URL\nhttps://www.frontiersin.org/journals/\ncardiovascular-medicine/articles/10.\n3389/fcvm.2022.983543.\nCaron, M., Touvron, H., Misra, I., J´egou, H., Mairal, J.,\nBojanowski, P., and Joulin, A. Emerging properties in\nself-supervised vision transformers, 2021.\nChen, T., Kornblith, S., Norouzi, M., and Hinton, G. A\nsimple framework for contrastive learning of visual rep-\nresentations, 2020.\nClifford, G. D., Liu, C., Moody, B., Li-wei, H. L., Silva,\nI., Li, Q., Johnson, A. E., and Mark, R. G. Af clas-\nsification from a short single lead ecg recording: The\nphysionet/computing in cardiology challenge 2017. In\n2017 Computing in Cardiology (CinC), pp. 1–4. IEEE,\nSep 2017. doi: 10.22489/CinC.2017.065-469.\nDevlin, J., Chang, M.-W., Lee, K., and Toutanova, K. Bert:\nPre-training of deep bidirectional transformers for lan-\nguage understanding, 2019. URL https://arxiv.\norg/abs/1810.04805.\nDiamant, N., Reinertsen, E., Song, S., Aguirre, A. D.,\nStultz, C. M., and Batra, P. Patient contrastive learn-\ning: A performant, expressive, and practical approach\nto electrocardiogram modeling. PLOS Computational\nBiology, 18(2):1–16, 02 2022.\ndoi: 10.1371/journal.\npcbi.1009862. URL https://doi.org/10.1371/\njournal.pcbi.1009862.\nDosovitskiy, A., Beyer, L., Kolesnikov, A., Weissenborn,\nD., Zhai, X., Unterthiner, T., Dehghani, M., Minderer,\nM., Heigold, G., Gelly, S., Uszkoreit, J., and Houlsby, N.\nAn image is worth 16x16 words: Transformers for image\nrecognition at scale, 2021.\nEleyan, A., Bayram, F., and Eleyan, G. Spectrogram-based\narrhythmia classification using three-channel deep learn-\ning model with feature fusion. Applied Sciences, 14(21):\n9936, 2024. doi: 10.3390/app14219936.\nGoldberger, A., Amaral, L., Glass, L., Havlin, S., Hausdorg,\nJ., Ivanov, P., Mark, R., Mietus, J., Moody, G., Peng,\nC.-K., Stanley, H., and Physiobank, P. Components of a\nnew research resource for complex physiologic signals.\nPhysioNet, 101, 01 2000.\nGrill, J.-B., Strub, F., Altch´e, F., Tallec, C., Richemond,\nP. H., Buchatskaya, E., Doersch, C., Pires, B. A., Guo,\nZ. D., Azar, M. G., Piot, B., Kavukcuoglu, K., Munos,\nR., and Valko, M. Bootstrap your own latent: A new\napproach to self-supervised learning, 2020.\nGuldenring, D., Rababah, A. S., Finlay, D. D., Bond,\nR. R., Kennedy, A., Doggart, P., and McLaugh-\nlin, J. A. D.\nInfluence of the training set size\non the subject-to-subject variability of the estima-\ntion performance of linear ecg-lead transformations.\n2022 Computing in Cardiology (CinC), 498:1–4,\n2022.\nURL https://api.semanticscholar.\norg/CorpusID:257316995.\nGupta, A., Wu, J., Deng, J., and Fei-Fei, L. Siamese masked\nautoencoders, 2023.\nHe, K., Chen, X., Xie, S., Li, Y., Doll´ar, P., and Girshick, R.\nMasked autoencoders are scalable vision learners, 2021.\n9\n\n\nCuPID: Leveraging Masked Single-Lead ECG Modelling for Enhancing the Representations\nHimmelreich, J. C., Karregat, E. P., Lucassen, W. A., van\nWeert, H. C., de Groot, J. R., Handoko, M. L., Nijveldt,\nR., and Harskamp, R. E.\nDiagnostic accuracy of a\nsmartphone-operated, single-lead electrocardiography de-\nvice for detection of rhythm and conduction abnormalities\nin primary care. The Annals of Family Medicine, 17(5):\n403–411, 2019. ISSN 1544-1709. doi: 10.1370/afm.2438.\nURL https://www.annfammed.org/content/\n17/5/403.\nKingma, D. P. and Ba, J. Adam: A method for stochastic\noptimization, 2017.\nKiyasseh, D., Zhu, T., and Clifton, D. A. Clocs: Contrastive\nlearning of cardiac signals across space, time, and pa-\ntients, 2021.\nLoshchilov, I. and Hutter, F. Decoupled weight decay regu-\nlarization, 2019. URL https://arxiv.org/abs/\n1711.05101.\nMartinez, J., Almeida, R., Olmos, S., Rocha, A., and\nLaguna, P.\nA wavelet-based ecg delineator: evalu-\nation on standard databases.\nIEEE Transactions on\nBiomedical Engineering, 51(4):570–581, 2004.\ndoi:\n10.1109/TBME.2003.821031.\nMoody, G. and Mark, R. A new method for detecting atrial\nfibrillation using r-r intervals. Computers in Cardiology,\npp. 227–230, 1983.\nNa, Y., Park, M., Tae, Y., and Joo, S. Guiding masked\nrepresentation learning to capture spatio-temporal rela-\ntionship of electrocardiogram. In International Confer-\nence on Learning Representations, 2024. URL https:\n//openreview.net/forum?id=WcOohbsF4H.\nPetrutiu, S., Sahakian, A., and Swiryn, S. Abrupt changes\nin fibrillatory wave charactedstics at the termination of\nparoxysmal atrial fibrillation in humans. Europace : Euro-\npean pacing, arrhythmias, and cardiac electrophysiology\n: journal of the working groups on cardiac pacing, ar-\nrhythmias, and cardiac cellular electrophysiology of the\nEuropean Society of Cardiology, 9:466–70, 08 2007. doi:\n10.1093/europace/eum096.\nQuan, S., Howard, B., Iber, C., Kiley, J., Nieto, F.,\nO’Connor, G., Rapoport, D., Redline, S., Robbins, J.,\nSamet, J., and Wahl, P. The sleep heart health study:\nDesign, rationale, and methods. Sleep, 20:1077–85, 01\n1998. doi: 10.1093/sleep/20.12.1077.\nThinh, P., Le, D., Brijesh, P., Adjeroh, D., Wu, J., and\nJensen, M. Multimodality multi-lead ecg arrhythmia\nclassification using self-supervised learning, 09 2022.\nVaswani, A., Shazeer, N., Parmar, N., Uszkoreit, J., Jones,\nL., Gomez, A. N., Kaiser, L. u., and Polosukhin, I.\nAttention is all you need. In Guyon, I., Luxburg, U. V.,\nBengio, S., Wallach, H., Fergus, R., Vishwanathan, S.,\nand Garnett, R. (eds.), Advances in Neural Information\nProcessing Systems, volume 30. Curran Associates, Inc.,\n2017.\nURL https://proceedings.neurips.\ncc/paper_files/paper/2017/file/\n3f5ee243547dee91fbd053c1c4a845aa-Paper.\npdf.\nWickstrøm, K., Kampffmeyer, M., Mikalsen, K. Ø., and\nJenssen, R.\nMixing up contrastive learning:\nSelf-\nsupervised representation learning for time series. Pat-\ntern Recognition Letters, 155:54–61, mar 2022.\ndoi:\n10.1016/j.patrec.2022.02.007.\nURL https://doi.\norg/10.1016%2Fj.patrec.2022.02.007.\nZhang, G.-Q., Cui, L., Mueller, R., Tao, S., Kim, M.,\nRueschman, M., Mariani, S., Mobley, D., and Redline,\nS.\nThe national sleep research resource: Towards a\nsleep data commons. Journal of the American Medi-\ncal Informatics Association, pp. 572–572, 08 2018. doi:\n10.1145/3233547.3233725.\nZhang, H., Liu, W., Shi, J., Chang, S., Wang, H., He, J.,\nand Huang, Q. Maefe: Masked autoencoders family\nof electrocardiogram for self-supervised pretraining and\ntransfer learning. IEEE Transactions on Instrumentation\nand Measurement, 72:1–15, 2023. doi: 10.1109/TIM.\n2022.3228267.\nZhao, Z. and Zhang, Y. Sqi quality evaluation mechanism\nof single-lead ecg signal based on simple heuristic fu-\nsion and fuzzy comprehensive evaluation. Frontiers in\nPhysiology, 9, 06 2018. doi: 10.3389/fphys.2018.00727.\n10\n\n\nCuPID: Leveraging Masked Single-Lead ECG Modelling for Enhancing the Representations\nA. Data Preprocessing\nTo ensure the complete reproducibility of this work, this section presents a detailed description of the preprocessing steps\nemployed for the training and evaluation databases utilized in the proposed method.\nA.1. SHHS Data Selection\nOnly the subjects that appear in both recording cycles are used during the training procedure. This leads to 2643 subjects.\nECG signals are extracted from the Polysomnography (PSG) recordings. The quality of every 10 seconds-data strips has\nbeen evaluated with the algorithm proposed by Zhao and Zhang (Zhao & Zhang, 2018). We use SHHS since it contains two\nrecords belonging to the same subject. This makes this specific database special, and this is the reason that it has been the\nonly database used during the optimization.\nA.2. Data cleaning\nIn addition, all signals from the utilized datasets were resampled to a frequency of 100Hz. Then, a 5th order Butterworth\nhigh-pass filter with a cutoff frequency of 0.5Hz was applied to eliminate any DC-offset and baseline wander. Finally, each\ndataset underwent normalization to achieve unit variance, ensuring that the signal samples belong to a N(0, 1) distribution.\nThis normalization process aimed to mitigate variations in device amplifications.\nB. Details of SHHS Dataset\nTable 3. Demographic and Clinical Distribution in the SHHS Dataset\nCategory\nPercentage (%)\nPrevalent Atrial Fibrillation (AFib)\nNo\n49.8\nYes\n0.8\nUnknown\n49.4\nRace Distribution\nWhite\n84.5\nBlack\n8.9\nOther\n6.6\nAge (at Visit 1)\n63.1 ± 11.2 years\nSex Distribution\nMale\n47.6\nFemale\n52.4\nC. Details of Datasets used for Main Evaluation of Single-Lead ECG Baselines\nTable 4. Statistics of the PhysioNet 2017 Training Set\nLabel\nTotal Recordings\nMean Time (s)\nSD Time (s)\nNormal\n5,154\n31.9\n10.0\nAF\n771\n31.6\n12.5\nOther rhythm\n2,557\n34.1\n11.8\nNoisy\n46\n27.1\n9.0\nTotal\n8,528\n32.5\n10.9\n11\n\n\nCuPID: Leveraging Masked Single-Lead ECG Modelling for Enhancing the Representations\nTable 5. Statistics of the MIT-BIH Atrial Fibrillation (MIT-AFIB) Database\nLabel\nTotal ECGs\nRecord Count (%)\nAvg. ECGs per Record\nNormal Sinus Rhythm (NSR)\n50,115\n21 (91.3%)\n0.401 ± 0.357\nAtrial Fibrillation (AFib)\n33,694\n23 (100%)\n0.656 ± 0.320\nTable 6. Statistics of the Long Term AF (LT-AF) Database\nLabel\nTotal ECGs\nRecord Count (%)\nAvg. ECGs per Record\nNormal Sinus Rhythm (NSR)\n270,702\n53 (63.1%)\n0.672 ± 0.315\nAtrial Fibrillation (AFib)\n368,272\n84 (100%)\n0.546 ± 0.422\nBradycardia\n19,197\n35 (41.7%)\n0.072 ± 0.100\nC.1. Pseudocode\nAlgorithm CuPID Training Algorithm\nInput: Number of iterations K, Batch size B\nInput: Encoder F(x), Predictor P(h, s)\nInput: Parameters θ, Optimizer opt(θ, ∇θ)\nInput: Spectrogram Transform S(x), Mask Function RM(X)\nInput: Mask Tokens Mt, Loss Function L1(X, Y, M)\nfor k = 0 to K do\nSample mini-batch: X ←{X1, . . . , XN}B\nb=0\nApply random masking: (Hm, M) ←RM(X)\nCompute encoder representations: Hm ←F(Hm)\nAttach mask tokens: H ←Rec(Hm, Mt)\nCompute spectrogram: S ←S(X)\nCompute predictor output: Y ←P(H, S)\nCompute loss: l ←L1(X, Y, M)\nCompute gradients: ∇θ ←∂l\n∂θ\nUpdate parameters: θ ←opt(θ, ∇θ)\nend for\nAlgorithm CuPID Predictor Algorithm\nInput: Predictor Layers P, Final Layer O(H)\nInput: Predictor Input H, Spectrogram S\nfor each (idx, Pt) in P do\nif idx = 0 then\nH ←Pt(H, H, H)\nelse\nH ←Pt(H, S, H) {Feed Spectrogram as Key}\nend if\nend for\nY ←O(H)\nreturn Y\n12\n\n\n",
  "metadata": {
    "source_file": "dataset/pdfs/arxiv_2502.21127v1.pdf",
    "total_pages": 12,
    "title": "CuPID: Leveraging Masked Single-Lead ECG Modelling for Enhancing the Representations",
    "authors": [
      "Adtian Atienza",
      "Gouthamaan Manimaran",
      "Jakob E. Bardram",
      "Sadasivan Puthusserypady"
    ],
    "abstract": "Wearable sensing devices, such as Electrocardiogram (ECG) heart-rate\nmonitors, will play a crucial role in the future of digital health. This\ncontinuous monitoring leads to massive unlabeled data, incentivizing the\ndevelopment of unsupervised learning frameworks. While Masked Data Modelling\n(MDM) techniques have enjoyed wide use, their direct application to single-lead\nECG data is suboptimal due to the decoder's difficulty handling irregular\nheartbeat intervals when no contextual information is provided. In this paper,\nwe present Cueing the Predictor Increments the Detailing (CuPID), a novel MDM\nmethod tailored to single-lead ECGs. CuPID enhances existing MDM techniques by\ncueing spectrogram-derived context to the decoder, thus incentivizing the\nencoder to produce more detailed representations. This has a significant impact\non the encoder's performance across a wide range of different configurations,\nleading CuPID to outperform state-of-the-art methods in a variety of downstream\ntasks.",
    "published_date": "2025-02-28",
    "source": "arxiv"
  }
}