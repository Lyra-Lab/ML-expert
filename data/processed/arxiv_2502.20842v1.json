{
  "id": "arxiv_2502.20842v1",
  "text": "arXiv:2502.20842v1  [math.OC]  28 Feb 2025\nA LAPLACE DUALITY FOR INTEGRATION\nJEAN B. LASSERRE\nAbstract. We consider the integral v(y) =\nR\nKy f(x)dx on a domain Ky =\n{x ∈Rd : g(x) ≤y}, where g is nonnegative and Ky is compact for all\ny ∈[0, +∞). Under some assumptions, we show that for every y ∈(0, ∞)\nthere exists a distinguished scalar λy ∈(0, +∞) such that\nv(y) =\nZ\nRd f(x) exp(−λy g(x)) dx\nwhich is the counterpart analogue for integration of Lagrangian duality for\noptimization. A crucial ingredient is the Laplace transform, the analogue for\nintegration of Legendre-Fenchel transform in optimization.\nIn particular, if\nboth f and g are positively homogeneous then λy is a simple explicitly ra-\ntional function of y. In addition if g is quadratic form then computing v(y)\nreduces to computing the integral of f with respect to a speciﬁc Gaussian\nmeasure for which exact and approximate numerical methods (e.g. cubatures)\nare available.\nKeywords:Integration, Laplace transform, optimization, positively homoge-\nneous functions,\n1. Introduction\nLet g : Rd →R be continuous, nonnegative and such that\n(1.1)\nKy := { x ∈Rd : g(x) ≤y } ,\ny ∈[0, +∞) .\nis compact for all y ∈[0, +∞), and let f : Rd →R be continuous. Consider the\nfunction\n(1.2)\ny 7→v(y) :=\nZ\nKy\nf(x) dx ,\ny ∈[0, +∞) ,\nwhich is well-deﬁned for every y ∈[0, +∞). This problem appears in several a rea\nof science and engineering. For instance, if f the density of a Gaussian measure µ\nthen v(y) = µ(Ky) provides the probability that a Gaussian random vector (with\ndistribution µ) lies in Ky, a basic problem encountered in probability, analysis of\ndynamical systems, and space engineering (e.g., for collision probability of satellites\n[10]).\nContribution. (i) Assuming that the Laplace transform of v exists (see e.g. [4,\n§6.26.1] and satisﬁes the Final Value Theorem (see e.g. [4, Theorem 3.8.2]), our\nﬁrst contribution is to show that for every y ∈(0, +∞) there exists λy ∈(0, +∞)\nsuch that:\n(1.3)\nv(y) =\nZ\nRd f(x) exp(−λy g(x)) dx .\nThat is, integrating f on Ky reduces to integrating f on the whole space Rd but\nnow against the measure with density x 7→exp(−λy g(x)) with respect to Lebesgue\n1\n\n\n2\nJEAN B. LASSERRE\nmeasure. Such integrals can be approximated, e.g. by cubatures [2, 3] whereas\nintegration on the domain Ky can be quite complicated. In particular, if g is a\nquadratic polynomial then (1.3) is a Gaussian integral for which even more speciﬁc\nnumerical approximations (e.g. cubatures) are available [9].\n(ii) Next, if g (resp. f) is positively homogeneous of degree dg (resp. df), then\ny and λy are related by\n(1.4)\ny · λy = (Γ(1 + (d + df)/dg))dg/(d+df) ,\nfor every y ∈(0, +∞). In particular, let f be a polynomial (x 7→P\nα fαxα) of\ndegree df, and write f = Pdf\nk=0 fk where for each k, fk homogeneous of degree k.\nThen for every y ∈(0, +∞),\nv(y) =\ndf\nX\nk=0\nZ\nRd fk(x) exp(−λy,k g(x)) dx ,\nwhere for every k = 0, 1, . . ., df,\nλy,k = 1\ny (Γ(1 + (d + k)/dg))dg/(d+k) ,\ny ∈(0, +∞) .\n(iii) Finally, we interpret (1.3) as a duality result, namely a duality analogue\nfor integration (hence in the usual (+, ×)-algebra) of Lagrangian duality for opti-\nmization (hence in the (max, +)-algebra). Indeed, associated with the optimization\nproblem\n(1.5)\nP :\nˆv(y) = inf { f(x) : g(x) ≥y } ,\ny ∈R ,\nis the Lagrangian x 7→L(x, λ) := f(x) −λ g(x). If f and −g are convex then so is\nˆv and its Legendre-Fenchel transform ˆv∗reads:\n(1.6)\nˆv∗(λ) = sup\ny λ y −ˆv(y) =\n(\n−inf\nx f(x) −λ g(x) if λ ≥0,\n+∞otherwise.\nThen applying Legendre-Fenchel to ˆv∗yields\nˆv(y)\n=\nsup\nλ\nλ y −ˆv∗(λ) = sup\nλ≥0\nλ y + G(λ)\n(1.7)\nwith G(λ)\n:=\ninf\nx L(x, λ) ,\nλ ≥0 .\n(1.8)\nUnder some convexity assumptions on f and g, there exists a maximizer xy ∈Ky =\n{x : g(x) ≥y} and KKT-multiplier λ∗\ny ≥0 such that\n∇f(xy) −λ∗\ny∇g(xy) = 0 ;\nλ∗\ny (g(xy) −y) = 0 ,\nand so\n(1.9)\nv(y) = λy y + inf\nx f(x) −λ∗\ny g(x) ,\ny ∈(0, +∞) .\nSo the original minimization of f on Ky reduces to the minimization of the La-\ngrangian L(x, λ∗\ny) now over the whole Rd, for a distinguished value λ∗\ny of the KKT-\nmultiplier λ ≥0 associated with the constraint g(x) ≥y.\nIn particular, notice that if g (resp. f) is diﬀerentiable and positively homoge-\nneous of degree dg (resp. df) then using Euler’s identity ⟨xy, ∇f(xy)⟩= df f(y)\n(resp. ⟨xy, ∇g(xy)⟩= dg g(y)) one obtains λy · y = ˆv(y) df/dg, to compare with\n(1.4).\n\n\nA LAPLACE DUALITY FOR INTEGRATION\n3\n– The analogue for integration of the Lagrangian L(x, λ) in (1.8) for optimization,\nis the “Lagrangian” integrand x 7→f(x) exp(−λ g(x)), x ∈Rd, and\n– the analogue of the dual function G(λ) in (1.8) is just the integral\nR\nRd f(x) exp(−λ g(x)) dx\n(where the “maxx∈Rd” has been replaced with “\nR\nx∈Rd”).\n– Finally, the analogue for integration of the Legendre-Fenchel transform (1.6)\nin optimization, is the Laplace transform\nLv(λ) =\nZ ∞\n0\nexp(−λ y) v(y) dy ,\n∀λ ∈C , ℜ(λ) > 0 ,\nof v in (1.2), and the analogue of (1.7) is via the inverse Laplace transform\nv(y) =\n1\n2πi\nZ c+i∞\nc−i∞\nexp(λy) Lv(λ) dλ ,\n∀y ∈(0, +∞) ,\n(with c > ℜa for some a ∈C).\nFormal analogies between concepts in optimization and their counterparts in\nintegration is not new and has been observed in a number of domains. For in-\nstance, convolution of Gaussian distributions in probability is the analogue of inf-\nconvolution of quadratic forms in optimization. Similarly, concepts in probability\nhave their counterparts in Dynamic Programming as outlined and described in [1,\n§9.4]. Finally for convex polytopes Ky ⊂Rd, in [6] one has shown explicit links\nbetween integration and counting on the one hand, and linear (LP) and integer\nprogramming (IP) on the other hand. In particular, classical LP ingredients (basis,\nreduced gradient, and dual vector) also appear explicitly in Brion & Vergne formula\nfor integration and counting over convex polytopes; see [6].\nThe present contribution is also in the same spirit as in [6] and [7] but now for\nintegration of a larger class of functions (continuous rather than linear in [6]) on\na larger class of domains (Ky instead of convex polytopes in [6], or very speciﬁc\ndomains in [7]). Indeed, an integration domain of the form { x ∈Rd : gj(x) ≤\nbj, j = 1, . . . , m } reduces to { x ∈Rd : maxj ˜gj(x) ≤1, j = 1, . . . , m } with\n˜gj(x) := gj(x)/bj). Then one considers the set Ky := { x ∈Rd : maxj ˜gj(x) ≤y }.\n(In particular notice that if the gj’s are all positively homogeneous of degree dg,\nthen so is the function x 7→maxj gj(x).) Crucial in all the references [7, 6, 5] is to\nembed a speciﬁc integral on K1 in a larger parametrized family of integrals on Ky,\nwith values v(y), y ∈(0, +∞), and then apply the Laplace transform to v. This is\nexactly what is done in optimization on Ky where one applies the Legendre-Fenchel\ntransform to the value function ˆv(y) in (1.5). When the Laplace transform has a\nclosed form expression then its inverse (e.g. for y = 1 to obtain v(1)) can sometimes\nbe computed eﬃciently; see e.g. [7].\n2. Main result\n2.1. Notation and deﬁnitions. Let R[x] = R[x1, . . . , xd]n be the ring of polyno-\nmials in the real variables x1, . . . , xd, of degree at most n. Denote by R+ ⊂R\nthe positive half-line.\nA function f is positively homogeneous of degree df if\nf(λ x) = λdf f(x) for all x ∈Rd and all λ > 0. When f is continuously diﬀer-\nentiable, Euler’s identity states that ⟨∇f(x), x⟩= df f(x), ∀x ∈Rd.\n\n\n4\nJEAN B. LASSERRE\nLaplace transform. For a function h : R+ →R, its Laplace transform Lh : C →\nC, is deﬁned by:\n(2.1)\nLh(λ) =\nZ ∞\n0\nh(y) exp(−λ y) dy ,\nλ ∈C ,\nprovided that the integral is well-deﬁned. For instance a suﬃcient condition is that\nh is of exponential order exp(at) (a > 0) as t →∞, i.e. there exists T, M > 0\nsuch that for all t > T , |h(t)| ≤M exp(at); see e.g. [4, §3.3]. If h is continuous\nor piecewise continuous in every ﬁnite interval (0, T ), then Lh exists for all λ ∈C\nwith ℜs > a. When it is the case then we can recover h via the inverse Laplace\ntransform:\nh(y) =\nZ c+i∞\nc−i∞\nexp(λ y) Lh(λ) dλ ,\ny ∈(0, +∞) ,\nwhere c > a. We also have the well-known Initial Value Theorem ([4, Theorem\n3.8.1])\n(2.2)\nlim\nλ→∞λ Lh(λ) = lim\ny→0 h(y) ,\nand Final Value Theorem\n(2.3)\nlim\nλ→0 λ Lh(λ) = lim\ny→∞h(y) .\nThe latter holds under additional assumptions; see [4, Theorem 3.8.2, pp. 110–112].\n2.2. Main result.\nAssumption 2.1. (i) The function g : Rd →R is continuous, nonnegative and the\nset Ky in (1.1) is compact for every y ∈[0, ∞).\n(ii) The function f : Rd →R is continuous and nonnegative.\nLet v : [0, ∞) →R be as in (1.2). Observe that if one knows how to evaluate v(y)\nfor continuous nonnegative functions, then we may also evaluate v(y) for continuous\nfunctions bounded from below. Indeed if f is bounded below, say f ≥τ for some\nτ > −∞, then\nv(y) =\nZ\nKy\nf dx = τ\nZ\nKy\n1 dx +\nZ\nKy\n(f −τ) dx\ni.e. v is a weighted sum of two integrals of nonnegative functions (1 and f −τ)).\nTherefore it suﬃces to restrict to the family of nonnegative functions f.\nTheorem 2.2. Let Assumption 2.1 hold.\n(i) With v as in (1.2), assume that v is of exponential order exp(at) for some\na > 0. Then for every real λ > 0,\n(2.4)\nLv(λ) = 1\nλ\nZ\nRd f(x) exp(−λ g(x)) dx ,\n(ii) In addition, assume that the set K0 = { x ∈Rd : g(x) = 0 } has Lebesgue\nmeasure zero, and that the Final Value Theorem (2.3) holds. Then for every y ∈\n(0, +∞), there exists λy ∈(0, +∞) such that\n(2.5)\nv(y) = λy Lv(λy) =\nZ\nRd f(x) exp(−λy g(x)) dx .\n\n\nA LAPLACE DUALITY FOR INTEGRATION\n5\nSimilarly, for every λ ∈(0, +∞) there exists yλ ∈(0, +∞) such that\n(2.6)\nv(yλ) = λ Lv(λ) =\nZ\nRd f(x) exp(−λ g(x)) dx .\nProof. (i) By [4, Theorem 3.31], Lv exists for all λ provided that ℜ(λ) > a. Next,\nlet λ ∈R. Then\nLv(λ) =\nZ ∞\n0\nv(y) exp(−λ y) dy\n=\nZ ∞\n0\n Z\nKy\nf(x) dx\n!\nexp(−λ y) dy\n=\nZ\nRd f(x)\n Z ∞\ng(x)\nexp(−λ y) dy\n!\ndx\n=\n1\nλ\nZ\nRd f(x) exp(−λ g(x)) dx ,\n∀λ > 0 ,\nwhich yields (2.4). (The third equality is obtained by a standard Fubini-Tonelli\ninterchange.)\n(ii) In view of the assumptions on f and g, the function v is continuous and non\ndecreasing, and the Initial Value Theorem (2.2) holds. Hence limλ→∞λ Lv(λ) =\nv(0) = 0. Next, as the Final value Theorem holds we also have limλ→0 λ Lvλ =\nlimy→∞v(y) =: v(∞) with possibly v(∞) = +∞. Moreover, the function\nλ 7→λ Lv(λ) =\nZ\nRd f(x) exp(−λ g(x)) dx ,\nλ ∈(0, +∞) ,\nis continuous and therefore,\nλ Lv(λ)(0, +∞) = (0, +∞) = v((0, ∞)) ,\nwhich yields the desired result (2.5) and (2.6).\n□\nHence Theorem 2.2 states that for every y ∈(0, +∞), integrating f on Ky w.r.t.\nLebesgue measure is the same as integrating f on the whole space Rd but now\nagainst the measure with density exp(−λy g(x)) w.r.t. Lebesgue measure, for some\ndistinguished real scalar λy ∈(0, +∞).\nFor a ﬁxed λ, evaluating the integral\nR\nf exp(−λ g)dx is challenging but numeri-\ncal approximations are available, e.g. via cubature formula for the weight function\nx 7→exp(−λy g(x)); see e.g. [2, 3]. A prototypal and important case is when g is a\n(nonnegative) quadratic polynomial. Then the measure exp(−λy g(x)) dx is (up to\nscaling) a Gaussian measure for which numerical integration techniques are is well\ndocumented; see e.g. [9].\nEquation (2.5) is also the analogue for integration of the Lagrangian relaxation\n(1.9) in optimization, where under some convexity assumptions, the minimization\nof f on Ky = {x : g(x) ≥y} is replaced with the minimization of the Lagrangian\nx 7→L(x, λ∗\ny) = λ∗\ny g −f on the whole Rd for some distinguished multiplier λ∗\ny ≥0.\nIndeed with y ﬁxed, the KKT-optimality conditions at a local minimizer x∗∈Ky\nof P state that there exists λ∗\ny ≥0 such that x∗\ny is a critical point of the Lagrangian\nL(x, λ∗\ny); in addition, if f and −g are convex then x∗\ny is a global minimizer of\nL(x, λ∗\ny).\nNext, with λ ﬁxed and Lv the Laplace transform of v,\n(2.7)\nλ Lv(λ) =\nZ ∞\n0\nexp(−λ y) v(y) dy =\nZ\nRd f(x) exp(−λ g(x)) dx ,\n\n\n6\nJEAN B. LASSERRE\nis the counterpart for integration of the Legendre-Fenchel transform\nˆv∗(λ)\n=\nsup\ny λ y −ˆv(y) = −inf\nx∈Rd f(x) −λ g(x)\n=\nsup\nx∈Rd λ g(x) −f(x) ,\nλ ≥0 ,\n(2.8)\nfor ˆv in (1.5).\nIn (2.7) “\nR\nRd” (inﬁnitesimal sum) is the analogue of “supx∈Rd” in (2.8). So it\nis fair to consider the density x 7→f(x) exp(−λ g(x)) w.r.t. Lebesgue measure on\nRd as the counterpart of the Lagrangian x 7→L(x, λ) in optimization. Moreover,\nwe call the distinguished scalar λy in Theorem 2.2 a “Laplace dual variable”, the\nexact analogue for integration of the Karush-Kuhn-Tucker Lagrange multiplier λ∗\ny\nin (1.9) for optimization, associated with the constraint g(x) ≥y.\nThese correspondences provide with an additional instance of formal analogies\nbetween duality in optimization and in integration via Fenchel and Laplace trans-\nforms respectively, in the spirit of those investigated in [6] for LP and Integer\nProgramming on the one hand and linear integration and counting on the other\nhand.\nHowever, so far Theorem 2.2 is only a qualitative result as it does not provide\na clue on what is the scalar λy associated with y ∈(0, +∞). We next address this\nissue under additional assumptions on f and g.\nCorollary 2.3. Let Assumption 2.1(i) holds. In addition let g (resp. f) be posi-\ntively homogeneous of degree dg (resp. df). Then with v as in (1.2):\n(2.9)\nLv(λ) =\n1\nλ1+(d+df)/dg\nZ\nRd f(x) exp(−g(x)) dx ,\nfor all λ ∈(0, +∞), and\n(2.10)\nv(y) = y(d+df)/dg R\nRd f(x) exp(−g(x)) dx\nΓ(1 + (d + df)/dg)\nfor all y ∈[0, +∞). In addition, for every y ∈(0, +∞),\n(2.11)\nv(y) = λy · Lv(λy) =\nZ\nRd f(x) exp(−λy g(x)) dx ,\nwith y · λy = Γ(1 + (d + df)/dg)dg/(d+df).\nProof. By (2.4) in Theorem 2.2(i), for every real scalar λ > 0 (and using that f, g\nare positively homogeneous),\nLv(λ)\n=\nZ\nRd f(x) exp(−λ g(x)) dx ,\nℜ(λ) > 0\n=\n1\nλ1+(d+df)/dg\nZ\nRd f(x) exp(−g(x)) dx ,\nwhich yields (2.9). On the other hand, as f and g are positively homogeneous, v is\nalso positively homogeneous of degree (d + df)/dg), and v being univariate,\nv(y)\n=\ny(d+df)/dg v(1)\n⇒\nLv(λ)\n=\nΓ(1 + (d + df)/dg)\nλ1+(d+df)/dg)\nv(1) ,\nℜ(λ) > 0 ,\n\n\nA LAPLACE DUALITY FOR INTEGRATION\n7\nfrom which we deduce that v(1)Γ(1 + (d + df)/dg) =\nR\nRd f(x) exp(−g(x)) dx, and\nfrom which (2.10) follows. So with y ∈(0, +∞),\nλy Lv(λy) = v(y)\n⇐⇒\nλy · y = Γ(1 + (d + df)/dg)dg/(d+df) ,\nwhich yields (2.11).\n□\nSo Corollary 2.3 identiﬁes the Laplace (or “dual”) variable λy associated with\neach y ∈(0, +∞), and such that integrating f on Ky reduced to integrating f\non Rd, but now against the measure with density exp(−λy g(x)) w.r.t. Lebesgue\nmeasure. Notice that if g is a nonnegative quadratic polynomial then this measure\nis a Gaussian measure (up to scaling by a constant).\nOf course, in view of (2.10), to evaluate v(y) is suﬃces to evaluate v(1), or\nequivalently, to compute the single integral\nR\nRd f(x) exp(−g(x)) dx, which is quite\na diﬃcult task in general. However to approximate the integral, one may invoke\nnumerical tools like cubatures for the weight function exp(−g(x)); see e.g. [2, 3].\nAn even more speciﬁc case is when g is a nonnegative quadratic form in which case\none has to integrate f against a Gaussian measure for which several specialized\nprocedures exist; see for instance some speciﬁc cubatures rules described in [9].\nNotice also that in the particular case where d + df = dg then λy · y = 1 and so\nv(y) = R\nRd f(x) exp(−g(x)/y) dx for all y ∈(0, +∞).\nAnother interesting case is when f is a polynomial. Then write f as f(x) =\nPdf\nk=0 fk(x), where for each k, fk is a homogeneous polynomial of degree k. Then\nin view of Corollary 2.3:\nv(y) =\ndf\nX\nk=0\nZ\nRd fk(x) exp(−λy,k g(x)) dx\nwith λy,k = Γ(1 + (d + k)/dg)dg/(d+k)/y, for every y ∈(0, +∞).\nThe case of the simplex. Let e := (1, . . . , 1) ∈Rd and Ky := { x ≥0 : eT x ≤y}\n(a dilation of the canonical simplex). As one integrates over a subset of Rd\n+ one\nmay and will assume that f(x) = 0 on Rd \\ Rd\n+. Then\nLv(λ) = 1\nλ\nZ\nRd\n+\nf(x) exp(−⟨λe, x⟩) dx = Lf(λ e) ,\nwhere Lf is the multivariate Laplace transform of f.\nThen Theorem 2.2 states that under Assumption 2.1, for every y ∈(0, +∞),\nthere exists λy ∈(0, +∞) such that v(y) = λy Lf(λy y), i.e., v is directly related to\nthe Laplace transform Lf of f, evaluated on the diagonal.\nMean Value Theorem. For the optimization problem P in (1.5), in addition to\nthe optimal value ˆv(y), one is also interested in extracting a minimizer ˆxy ∈Ky.\nThe counterpart for integration of “extraction” of minimizer in optimization, is\nprovided by the Mean Value Theorem. Indeed if f is continuous and Ky is compact\nthen by the Mean Value Theorem (MVT), for every y ∈(0, +∞), there exists\nx∗\ny ∈Ky such that\n(2.12)\nv(y) =\nZ\nKy\nf(x) dx = f(x∗\ny) vol(Ky)\n\n\n8\nJEAN B. LASSERRE\nto compare with ˆv(y) = f(ˆxy) for some ˆxy ∈Ky for the optimization problem (1.5).\nClearly, as for the extraction of the minimizer ˆxy in optimization, MVT “extracts”\na distinguished point x∗\ny ∈Ky that “explains” v(y). In the positively homogeneous\ncase one may say more on x∗\ny.\nLemma 2.4. Let g : Rd →R be nonnegative homogeneous of degree dg and with\nKy ⊂Rd compact for every y ∈[0, ∞). Let f : Rd →R be continuous and positively\nhomogeneous of degree df. Then in (2.12) one may choose x∗\ny := y1/dg x∗\n1 for any\nx∗\n1 ∈K1 (which satisﬁes (2.12) with y = 1).\nProof. On the one hand, by Corollary 2.3\nv(y) =\nZ\nKy\nf(x) dx = y(d+df)/dg R\nRd f(x) exp(−g(x)) dx\nΓ(1 + (d + df)/dg)\n,\nwhile on the other hand, by the MVT, there exists x∗\ny ∈Ky, such that\nv(y)\n=\nf(x∗\ny) vol(Ky) = f(x∗\ny) yd/dgvol(K1)\n=\nf(x∗\ny)\nyd/dg\nΓ(1 + d/dg)\nZ\nRd exp(−g(x)) dx .\nTherefore\nf(x∗\ny)\nR\nRd exp(−g(x)) dx\nΓ(1 + d/dg)\n= ydf/dg R\nRd f(x) exp(−g(x)) dx\nΓ(1 + (d + df)/dg)\n,\nthat is,\nf(x∗\ny) = ydf/dg\nv(1)\nvol(K1) = ydf/dgf(x∗\n1) = f(y1/dgx∗\n1)\nwhere we have used (2.12) with y = 1, and the fact that f is df-positively homoge-\nneous. Hence one may indeed choose x∗\ny := y1/dgx∗\n1 because g(x∗\ny) = g(y1/dgx∗\n1) =\ny g(x∗\n1) ≤y (as g(x∗\n1) ≤1), and so x∗\ny ∈Ky.\n□\nOne has a similar result in homogeneous optimization. Indeed under the same\nassumptions of Lemma 2.4 (and also assuming continuously diﬀerentiability of f\nand g), consider any point x∗\n1 ∈K1 of P with y = 1, which satisﬁes the KKT-\noptimality conditions\n∇f(x∗\n1) = λ1 ∇g(x∗\n1) ;\nλ∗\n1(1 −g(x∗\n1)) = 0 ,\nfor some λ∗\n1 ≥0. Deﬁne x∗\ny := y1/dg x∗\n1 so that g(x∗\ny) = y g(x∗\n1) ≤y, which shows\nthat x∗\ny ∈Ky. Next, ∇f and ∇g are positively homogeneous of degree df −1 and\ndg −1 respectively. Hence\n∇f(x∗\ny) = ∇f(y1/dg x∗\n1)\n=\ny(df−1)/dg ∇f(x∗\n1)\n=\ny(df−1)/dg λ∗\n1 ∇g(x∗\n1)\n=\ny(df−1)/dg λ∗\n1 ∇g(y−1/dg x∗\ny)\n=\ny((df−1)−(dg−1))/dg λ∗\n1 ∇g(x∗\ny)\n=\ny(df−dg)/dgλ∗\n1\n|\n{z\n}\nλ∗y\n∇g(x∗\ny) .\nHence with λ∗\ny := y(df−dg)/dgλ∗\n1 ≥0, x∗\ny ∈Ky satisﬁes the KKT-optimality condi-\ntions of P with y ∈(0, +∞) because the complementary condition λ∗\ny(g(x∗\ny)−y) = 0\n\n\nA LAPLACE DUALITY FOR INTEGRATION\n9\nis also satisﬁed (as g(x∗\n1) = 1 implies g(x∗\ny) = y). This also shows that the KKT-\nmultiplier λ∗\ny is a positively homogeneous function of degree (df −dg)/dg.\n3. Conclusion\nWe have provided a Laplace duality framework for integrals on domains Ky ⊂Rd\nparametrized by y ∈(0, +∞). It mimics Legendre-Fenchel duality in optimization,\nand we have exhibited existence of a distinguished Laplace dual variable λy that\npermits to replace the initial integral on the compact domain Ky with an associated\nintegral on the whole Rd, with same value. In the homogeneous case one obtains\nan explicit expression of λy and it would be interesting to identify other cases\nwhere such an identiﬁcation is possible because then, the original integral can be\napproximated, e.g., by cubatures for the integral on the whole Rd with the identiﬁed\nspeciﬁc exponential weight.\nReferences\n[1] F. Bacelli, G. Cohen, G.J. Olsder, and J.P. Quadrat, Synchronization and Linearity: An\nAlgebra for Discrete Event Systems, John Wiley & Sons Ltd., 1992\n[2] R. Cools, ”An encyclopaedia of cubature formulas”, J. Complexity, vol 19, no. 3, pp. 445–453,\n2003\n[3] R. Cools, and A. Haegemans, ”Algorithm 824: CUBPACK: A package for automatic cuba-\nture; framework description”, Trans. Math. Software, vol 29, no. 3, pp. 287–296, 2003.\n[4] L. Debnath, Integral Transforms and Their Applications, CRC Press Inc., Boca Raton,\nFlorida, 1995.\n[5] J.B. Lasserre, ”A quick proof for the volume of n-balls”, Amer. Math. Monthly, vol 108, pp.\n768–769, 2001.\n[6] J.B. Lasserre, Linear and Integer Programming versus Linear Integration and Counting,\nSpringer Series in Operations Research and Financial Engineering, Springer, New York, 2009.\n[7] J.B. Lasserre, and E.S. Zeron, ”Solving a class of multivariable integration problems via\nLaplace Lechniques”, Appl. Math. (Warsaw), vol 28, pp. 391–405, 2001\n[8] J.B. Lasserre, and E.S. Zeron, ”A Laplace transform algorithm for the volume of a convex\npolytope”, JACM, vol 48, pp. 1126–1140, 2001.\n[9] R. Orive, J.C. Santos-Leon, and M.G. Spalevic, ” Cubature formulae for Gaussian weight:\nSome old and new rules”, Elec. Trans. Num. Anal., vol 53, pp. 426–438, 2020\n[10] R. Serra, D. Arzelier, M. Joldes, J.B. Lasserre, A. Rondepierre, and B. Salvy, ”Fast and Accu-\nrate Computation of Orbital Collision Probability for Short-Term Encounters”, J. Guidance,\nControl & Dynamics, vol 39, pp. 1–13, 2016.\nLAAS-CNRS and Toulouse School of Economics (TSE), LAAS, 7 avenue du Colonel\nRoche, 31077 Toulouse C´edex 4, France, Tel: +33561336415\nEmail address: lasserre@laas.fr\n\n\n",
  "metadata": {
    "source_file": "dataset/pdfs/arxiv_2502.20842v1.pdf",
    "total_pages": 9,
    "title": "A Laplace duality for integration",
    "authors": [
      "Jean B Lasserre"
    ],
    "abstract": "We consider the integral v(y) = Ky f (x)dx on a domain Ky = {x $\\in$ R d :\ng(x) $\\le$ y}, where g is nonnegative and Ky is compact for all y $\\in$ [0,\n+$\\infty$). Under some assumptions, we show that for every y $\\in$ (0,\n$\\infty$) there exists a distinguished scalar $\\lambda$y $\\in$ (0, +$\\infty$)\nsuch that which is the counterpart analogue for integration of Lagrangian\nduality for optimization. A crucial ingredient is the Laplace transform, the\nanalogue for integration of Legendre-Fenchel transform in optimization. In\nparticular, if both f and g are positively homogeneous then $\\lambda$y is a\nsimple explicitly rational function of y. In addition if g is quadratic form\nthen computing v(y) reduces to computing the integral of f with respect to a\nspecific Gaussian measure for which exact and approximate numerical methods\n(e.g. cubatures) are available.",
    "published_date": "2025-02-28",
    "source": "arxiv"
  }
}