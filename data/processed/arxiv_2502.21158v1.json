{
  "id": "arxiv_2502.21158v1",
  "text": "CONSeg: Voxelwise Glioma Conformal Segmentation \n______________________________________________________________________________ \nDanial Elyassirad1, Benyamin Gheiji1, Mahsa Vatanparast1, Amir Mahmoud Ahmadzadeh, \nMD2, Shahriar Faghani, MD3* \n(1) Student Research Committee, Mashhad University of Medical Sciences, Mashhad, Iran \n(2) Department of Radiology, Mashhad University of Medical Sciences, Mashhad, Iran \n(3) Radiology Informatics Lab, Department of Radiology, Mayo Clinic, Rochester, Minnesota \n(*) Correspondence: Shahriar Faghani, Email: Faghani.Shahriar@mayo.edu \n______________________________________________________________________________ \nAbstract \nBackground and Purpose: Glioma segmentation is crucial for clinical decisions and treatment \nplanning. Uncertainty quantification methods, including conformal prediction (CP), can enhance \nsegmentation models reliability. This study aims to use CP in glioma segmentation. \nMethods: We used the UCSF and UPenn glioma datasets, with the UCSF dataset split into training \n(70%), validation (10%), calibration (10%), and test (10%) sets, and the UPenn dataset divided \ninto external calibration (30%) and external test (70%) sets. A UNet model was trained, and its \noptimal threshold was set to 0.5 using prediction normalization. To apply CP, the conformal \nthreshold was selected based on the internal/external calibration nonconformity score, and CP was \nsubsequently applied to the internal/external test sets, with coverage reported for all. We defined \nthe uncertainty ratio (UR) and assessed its correlation with the Dice score coefficient (DSC). \nAdditionally, we categorized cases into certain and uncertain groups based on UR and compared \ntheir DSC. We also evaluate the correlation between UR and DSC of the BraTS fusion model \nsegmentation (BFMS), and compare DSC in the certain and uncertain subgroups. \nResults: The base model achieved a DSC of 0.8628 and 0.8257 on the internal and external test \nsets, respectively. The CP coverage was 0.9982 for the internal test set and 0.9977 for the external \ntest set. Statistical analysis showed a significant negative correlation between UR and DSC for test \nsets (p<0.001). UR was also linked to significantly lower DSCs in the BFMS (p<0.001). \nAdditionally, certain cases had significantly higher DSCs than uncertain cases in test sets and the \nBFMS (p<0.001). \nConclusion: CP effectively quantifies uncertainty in glioma segmentation. Using CONSeg \nimproves the reliability of segmentation models and enhances human-computer interaction.  \nKeywords: Radiology, Deep Learning, Machine Learning, Glioma Segmentation, Conformal \nPrediction, Uncertainty Quantification \n \n \n\n\nINTRODUCTION \nGliomas are the most prevalent primary brain tumors (1). Accurate segmentation of glioma from \nMR images is critical for clinical decision-making, including surgical and radiotherapy planning, \ntreatment monitoring, and prognosis assessment (2). Additionally, segmentation masks were used \nas input for deep learning (DL) models in various tasks, including radiogenomics, grading, and \nsurvival prediction (3-5). \nDL has advanced glioma segmentation from MRI scans, with the annual BraTS challenge \nunderscoring its growing importance in the field (6,7). Despite these advancements, the robustness \nof these models remains a concern, and challenges persist regarding their clinical acceptability and \nreliability across diverse patient populations (8). \nOne potential approach to address the reliability issue of DL models is uncertainty quantification \n(UQ) which provides a probabilistic measure of model confidence, enabling the identification of \nuncertain predictions and improving decision-making in clinical applications (9,10). Several \nstudies have explored uncertainty estimation in image segmentation, aiming to provide more \ntrustworthy predictions (11-13). Among the various techniques, conformal prediction (CP) has \nemerged as a promising method for UQ (14). \nCP quantifies uncertainty in model predictions by generating a set of possible classes for each \nprediction with a statistical guarantee. This set is constructed to ensure that the label is contained \nwithin it with a specified confidence level, thereby providing a rigorous measure of uncertainty in \nthe model's outputs (15). There have been works on the application of CP in image segmentation, \nhighlighting its potential to improve model reliability by providing rigorous uncertainty estimates \n(16-18). However, to the best of our knowledge, no research has yet applied CP to glioma \nsegmentation. \nThis study aims to integrate CP with DL-based glioma segmentation to quantify uncertainty in \nsegmentation outputs. By applying CP, we aim to enhance the reliability of the model by \nidentifying uncertain regions in the segmentation, thus improving the modelâ€™s robustness and \nclinical applicability. This approach provides a more reliable framework for decision-making in \nneuro-oncology, especially when dealing with challenging cases. \nMETHOD \nDataset \nThe UCSF glioma dataset was used for training, validation, calibration, and test set (19). This \ndataset consists of MRI scans acquired using a 3-T scanner and includes preoperative scans of \nglioma patients. The inclusion criteria required the presence of the FLAIR sequence and manual \nsegmentation masks for the tumoral area. For model evaluation, we used the UPenn glioma dataset, \nwhich followed the same inclusion criteria as the UCSF dataset with the additional criterion that \ncases also had automated segmentation masks generated using a fusion of top-ranked BraTS \nChallenge models (20). The detailed acquisition parameters for each dataset have been reported in \n\n\nthe original publications (19,20). All images underwent skull stripping and were resampled to 1 \nmmÂ³ isotropic voxels as part of the original dataset preprocessing. \nData Preprocessing and splitting \nThe UCSF dataset was divided into training (70%), validation (10%), calibration (10%), and test \n(10%) sets, while the UPenn dataset was split into external calibration (30%) and external test \n(70%) sets at the patient level. Preprocessing involved background cropping, followed by \nsymmetric zero-padding. Each image was independently normalized, using all nonzero voxels to \ncompute the minimum and maximum voxel values. \nDL Models Development \nWe trained a UNet model with FLAIR sequences as input (21). The loss function combined a \nsummation of Dice loss and weighted binary cross-entropy (BCE), where the BCE weight was \ndetermined based on the training label distribution. \nThe best model was selected based on the validation set Dice score coefficient (DSC). To \ndetermine the base model optimal threshold (BMOT) for voxel classification, DSCs were \nevaluated across thresholds from 0 to 1 (in 1% increments), selecting the threshold that maximized \nthe validation DSC. The final model performance was assessed using the DSC across validation, \ninternal, and external test sets, applying the BMOT. \nConformal Prediction \nTo apply CP, we normalized base model voxelsâ€™ prediction using the following equations \n(equations 1): \nğ‘ğ‘œğ‘Ÿğ‘šğ‘ğ‘™ğ‘–ğ‘§ğ‘’ğ‘‘ ğ‘ğ‘Ÿğ‘’ğ‘‘ğ‘–ğ‘ğ‘¡ğ‘–ğ‘œğ‘› (ğ¼ğ‘“ ğ‘£ğ‘œğ‘¥ğ‘’ğ‘™> ğ‘œğ‘ğ‘¡ğ‘–ğ‘šğ‘¢ğ‘š ğ‘¡â„ğ‘Ÿğ‘’ğ‘ â„ğ‘œğ‘™ğ‘‘) =\nğ‘Œ ğ‘ğ‘Ÿğ‘’ğ‘‘âˆ’(ğ‘‚ğ‘ğ‘¡ğ‘–ğ‘šğ‘¢ğ‘š ğ‘¡â„ğ‘Ÿğ‘’ğ‘ â„ğ‘œğ‘™ğ‘‘Â± ğœ€)\n2 Ã— (ğ‘Œmax âˆ’ ( (ğ‘‚ğ‘ğ‘¡ğ‘–ğ‘šğ‘¢ğ‘š ğ‘¡â„ğ‘Ÿğ‘’ğ‘ â„ğ‘œğ‘™ğ‘‘Â± ğœ€)) + 0.5 \nğ‘ğ‘œğ‘Ÿğ‘šğ‘ğ‘™ğ‘–ğ‘§ğ‘’ğ‘‘ ğ‘ğ‘Ÿğ‘’ğ‘‘ğ‘–ğ‘ğ‘¡ğ‘–ğ‘œğ‘› (ğ¼ğ‘“ ğ‘£ğ‘œğ‘¥ğ‘’ğ‘™< ğ‘œğ‘ğ‘¡ğ‘–ğ‘šğ‘¢ğ‘š ğ‘¡â„ğ‘Ÿğ‘’ğ‘ â„ğ‘œğ‘™ğ‘‘) =\nğ‘Œ ğ‘ğ‘Ÿğ‘’ğ‘‘âˆ’(ğ‘‚ğ‘ğ‘¡ğ‘–ğ‘šğ‘¢ğ‘š ğ‘¡â„ğ‘Ÿğ‘’ğ‘ â„ğ‘œğ‘™ğ‘‘Â± ğœ€)\n2 Ã— ((ğ‘‚ğ‘ğ‘¡ğ‘–ğ‘šğ‘¢ğ‘š ğ‘¡â„ğ‘Ÿğ‘’ğ‘ â„ğ‘œğ‘™ğ‘‘Â± ğœ€) âˆ’ğ‘Œğ‘šğ‘–ğ‘›) + 0.5 \nğ‘–ğ‘“ ğ‘œğ‘ğ‘¡ğ‘–ğ‘šğ‘¢ğ‘š ğ‘¡â„ğ‘Ÿğ‘’ğ‘ â„ğ‘œğ‘™ğ‘‘ ğ‘–ğ‘  1, ğ‘ğ‘¢ğ‘¡âˆ’ğœ€; ğ‘–ğ‘“ ğ‘œğ‘ğ‘¡ğ‘–ğ‘šğ‘¢ğ‘š ğ‘¡â„ğ‘Ÿğ‘’ğ‘ â„ğ‘œğ‘™ğ‘‘ ğ‘–ğ‘  0, ğ‘¢ğ‘ ğ‘’+ ğœ€ \nThis procedure yielded normalized predictions with an optimal threshold of 0.5.  \nCP aims to satisfy this equation (equation 2): \n1 âˆ’ğ›¼â‰¤ğ‘ƒ(ğ‘Œ ğ‘¡ğ‘Ÿğ‘¢ğ‘’ ğœ– ğ’(ğ‘¥ğ‘–)) â‰¤1 âˆ’ğ›¼+ \n1\nğ‘›+ 1 \nWhere Î± is the error (was set to 0.002 in our study), ğ‘Œ ğ‘¡ğ‘Ÿğ‘¢ğ‘’ is the label of y, ğ’(ğ‘¥ğ‘–) indicates the \nprediction set, and ğ‘› represents the number of cases (in our study, voxels) in the calibration set. \nUsing the calibration set(s), we computed nonconformity scores based on hinge loss (equation 3):  \nğ¸ğ‘ğ‘â„ ğ‘£ğ‘œğ‘¥ğ‘’ğ‘™â€²ğ‘  ğ‘›ğ‘œğ‘›ğ‘ğ‘œğ‘›ğ‘“ğ‘œğ‘Ÿğ‘šğ‘–ğ‘¡ğ‘¦ ğ‘ ğ‘ğ‘œğ‘Ÿğ‘’= 1 âˆ’ğ‘ƒ(ğ‘Œ ğ‘¡ğ‘Ÿğ‘¢ğ‘’) \nWhere the model prediction for the label is shown as ğ‘ƒ(ğ‘Œ ğ‘¡ğ‘Ÿğ‘¢ğ‘’). Subsequently, the nonconformity \nscore threshold (NCST) is determined using the selected Î± value. To apply CP, for each test voxel, \nthe nonconformity score is computed for both potential classes. A class is included in the prediction \nset if its corresponding nonconformity score is below the NCST. If neither or both classes are \n\n\nincluded in the prediction set, the voxel is classified as uncertain. If only one class is included in \nthe prediction set, the voxel is considered certain. Additionally, we report the coverage, defined as \nthe proportion of voxels for which the label is included in the prediction set (ğ‘ƒ(ğ‘Œ ğ‘¡ğ‘Ÿğ‘¢ğ‘’ ğœ– ğ’(ğ‘¥ğ‘–))). \nConformal Model Validation \nTo validate the output of the CP model, the following steps were conducted \n1. \nUncertainty ratio (UR) analysis for internal test set: The UR for each internal test case was \ncomputed, defined as (equation 4): \nğ‘ˆğ‘›ğ‘ğ‘’ğ‘Ÿğ‘¡ğ‘ğ‘–ğ‘›ğ‘–ğ‘¡ğ‘¦ ğ‘Ÿğ‘ğ‘¡ğ‘–ğ‘œ=\nğ‘ğ‘¢ğ‘šğ‘ğ‘’ğ‘Ÿ ğ‘œğ‘“ ğ‘¢ğ‘›ğ‘ğ‘’ğ‘Ÿğ‘¡ğ‘ğ‘–ğ‘› ğ‘£ğ‘œğ‘¥ğ‘’ğ‘™ğ‘ \nğ‘ğ‘¢ğ‘šğ‘ğ‘’ğ‘Ÿ ğ‘œğ‘“ ğ‘ğ‘’ğ‘Ÿğ‘¡ğ‘ğ‘–ğ‘› ğ‘ğ‘™ğ‘ğ‘ ğ‘  1 ğ‘£ğ‘œğ‘¥ğ‘’ğ‘™ğ‘  \nWhere certain class 1, is the CP model prediction. Next, the correlation coefficient (and \ncorresponding p-value) between the UR of each case in the internal test set and the corresponding \nmodel's DSC was assessed. \n2. \nUR analysis for external test set: The UR for external test cases was calculated, and its \ncorrelation coefficient (and corresponding p-value) with the DSCs was statistically analyzed. \n3. \nUR clustering for internal model validation: The CP model was applied to the internal \ncalibration set, and the UR was calculated. A K-means clustering algorithm was used to categorize \ncases based on their UR into two certain and uncertain subgroups. The internal test set was then \ncategorized using the clustering model threshold, and the DSC of these groups were statistically \ncompared. \n4. \nUR clustering for external model validation: To assess generalizability, the same approach \nused for the internal calibration and test sets was repeated for the external calibration and test sets, \nincluding UR calculation, K-means clustering, and statistical comparison of DSC across \ncategorized groups. \n5. \nComparative analysis with BraTS fusion model segmentation (BFMS) masks: To validate \nthe modelâ€™s ability to identify uncertain cases, the UR of each external test case was compared \nwith the DSC of automated segmentation masks derived from a fusion of top-ranked BraTS \nmodels, and statistical significance was assessed. \n6. \nThreshold-based categorization of external test set, using BFMS masks: Finally, the \nselected threshold from the external calibration set (using the K-means clustering algorithm) was \nused to categorize the external test cases, and their DSC were statistically compared against the \nBFMS masks to further validate the reliability of the CP model. \nStatistical Analysis \nCategorical data were compared using the chi-square test or Fisherâ€™s exact test and were reported \nas frequency (percentage). Normality was assessed using the Kolmogorov-Smirnov test. \nQuantitative variables were expressed as mean Â± standard deviation or median (interquartile \nrange), depending on data distribution. Based on normality, comparisons were conducted using \nthe t-test or Mann-Whitney U test. Correlations between variables were analyzed using the Pearson \n\n\nor Spearman rank correlation test, depending on the data distribution. All statistical analyses were \nperformed using SPSS 20 software, with p < 0.05 considered statistically significant. \nRESULTS \nThe UCSF dataset comprised 495 cases and the UPenn dataset included 147 cases. The data \ncharacteristics summarized in Table 1. \nTable 1: Data characteristics \n \nUCSF \nUPenn \nP value \nNumber of patients \n495 \n147 \n \nWHO CNS Grade \n \n \n<0.001 \n2 \n56(11.31%) \n0 \n \n3 \n43(8.69%) \n0 \n \n4 \n396(80%) \n(100%) \n \nSex \n \n \n0.989 \nMale \n296(59.8%) \n88(59.86%) \n \nFemale \n199 (40.2%) \n59 (40.14%) \n \nAge \n59 (47-68) \n62.22(53.5-70.14) \n<0.001 \nSegmentation Model Performance \nThe best model achieved a validation DSC of 0.8745, and a test DCS of 0.8628 on UCSF dataset \nand DSC of 0.8257 on UPenn dataset. The BMOT was found to be almost 1 (Figure S1). \nConformal Model Performance \nUCSF dataset \nThe CP model achieved a NCST of 0.8874 with coverage of 0.9982 in the UCSF test set. A \nsignificant correlation was observed between the UR and the DSC for the UCSF test set (p <0.001, \ncorrelation coefficient = -0.827) (Figure S2-3). \nThe test cases were categorized into uncertain and certain subgroups using a UR threshold of \n0.0314 (Figure S4-5). Uncertain cases (20.4%) achieved a DSC of 0.7090, whereas certain cases \nattained a DSC of 0.9023 (p value < 0.001). The detailed results of this analysis are presented in \nTable 2. \nTable 2: DSC for categorized test cases in the UCSF test set \nUR Threshold \nNumber of Cases \nMean DSC  \np-value \nUR > 0.0314 \n10 (20.4%) \n0.7090 (median= 0.77, 0.6747-0.8286) \n< 0.001 \nUR â‰¤ 0.0314 \n39 (79.6%) \n0.9023 (median= 0.9176, 0.8903-0.9357) \n  \n\n\nUPenn dataset: \nThe CP model reached a NCST of 0.9947 with coverage of 0.9977 in the UPenn test set. A \nsignificant correlation was observed between the UR and DSC for the UPenn test set (p <0.001, \ncorrelation coefficient = -0.833) (Figure S6). \nNext, the cases were categorized based on the UR threshold of 0.12281 (Figure S7-8). A \nsignificant difference in DSC between the uncertain (18.4% of cases with DSC of 0.6558) and \ncertain (81.6% of cases, DSC = 0.8642) subgroups was found (p < 0.001). The detailed results of \nthis analysis are presented in Table 3. \nTable 3: DSC for categorized test cases in the UPenn test set \nUR Threshold \nNumber of Cases \nMean DSC \np-value \nUR > 0.12281 \n19 (18.45%) \n0.6558 (median= 0.6990, 0.5217-0.7812) \n< 0.001 \nUR â‰¤ 0.12281 \n84 (81.55%) \n0.8642 (median= 0.8849, 0.8903-0.9357) \n  \nComparative Analysis with BraTS Fusion Model Outputs: \nA significant correlation was found between the UR and DSC of the BFMS (p <0.001, correlation \ncoefficient = -0.562) (Figure S9). \nAlso, Upenn cases were divided based on the UR threshold of 0.12281. A significant difference \nin DSC between the uncertain (18.4% cases, DSC = 0.8789) and certain (81.6% cases, DSC = \n0.9286) subgroups was observed (p < 0.001). The detailed results of this analysis are presented in \nTable 4. \nTable 4: DSC for categorized test cases in the UPenn test set, using BFMS outputs \nUR Threshold \nNumber of Cases \nMean DSC \np-value \nUR > 0.12281 \n19 (18.45%) \n0.8789 (median= 0.8758, 0.8465-0.9101) \n< 0.001 \nUR â‰¤ 0.12281 \n84 (81.55%) \n0.9286 (median= 0.9406, 0.9216-0.9517) \n  \nDISCUSSION \nIn this study, we demonstrate that conformal segmentation (CONSeg) enhances model reliability \nby identifying uncertain voxels and cases. We define the UR and find out that it has a significant \nnegative correlation with the DSC in both the internal and external test sets. Additionally, the UR \nfor each case (based on our U-Net model) also exhibits a significant correlation with the DSC of \nBFMS masks in the external test set. Using the internal and external calibration sets, we determined \na threshold for the UR to categorize cases to certain and uncertain cases. Applying this threshold \nto the internal and external test sets revealed a significant difference in DSC between uncertain \n\n\nand certain cases. Finally, applying the selected threshold to the BFMS masks resulted in a \nsignificant difference in the DSC. \nIn this study, before applying CP, we use a base model prediction normalization (BMPN) \nprocess that adjusts the BMOT to 50% and guarantees that uncertain predictions cover both sides \nof the BMOT (Figure 1). The imbalanced BMOT arises due to factors such as weighted loss and \nimbalanced datasets.  \nFigure 1. A-C represent different possible scenarios when applying CP to a model with an \nimbalanced BMOT, while D and E show the possible scenarios after applying BMPN. \nFigure 1 shows various scenarios of CP with an imbalanced BMOT (e.g., 0.99) and the changes \nafter applying BMPN. Figure 1A shows that when the NCST (or 1- NCST if NCST is below 0.5) \nis lower than the BMOT, CP classifies some predictions as certain with CP class 1, while those \npredictions were class 0 based on the BMOT (yellow box in Figure 1A). Figure 2 shows without \nBMPN, the CP model misclassifies some voxels as CP class 1 when they should be uncertain or \ncertain with CP class 0 (indicated by yellow circles).  \nFigure 2. From left to right; manual segmentation, base model segmentation with BMOT, \nconformal segmentation without BMPN (gray voxels are uncertain voxels), conformal \n\n\nsegmentation with BMPN. This figure shows scenario (A) which happened before BMPN in our \nCP model. \nFigure 1B, shows what happens when the NCST is close to the BMOT. In this situation, all \npredictions more than BMOT remain certain with CP class 1, however some predictions below the \nBMOT are considered uncertain. Also all CP certain classes align with BMOT predictions.  Figure \n1C represents the ideal scenario, where the NCST is higher than the BMOT, leading to uncertainty \nin both class 0 and class 1 voxels based on the BMOT. In this case, the CP model's certain classes \nmatch with the BMOT classes.  \nAfter applying BMPN, Figures 1D and 1E are possible scenarios (both are similar, just in figure \n1D no voxel with class 1 based on BMOT categorized as uncertain voxels, like 1B). Overall, \nBMPN eliminates the misclassification issue observed before normalization (as shown in Figure \n1A and 2) and aligns the CP classes more accurately with the BMOT classes. \nFew studies have previously applied CP for segmentation. Davenport applied CP for polyp \ntumor segmentation (17), while Gade et al. used CP for prostate segmentation (18). Based on these \nstudies and our own findings, we have gained a clearer understanding of the advantages that \nuncertainty quantification in segmentation provides. It serves as a guide for manual correction of \nmodel-generated segmentations and helps identify regions more susceptible to misclassification \n(17,18). Additionally, when the UR is high, it indicates that automated segmentation may not be \nsuitable for the case, necessitating a manual approach. Furthermore, our findings show that \nuncertain cases, as identified by our model, exhibit significantly lower DSC compared to certain \ncases, even when utilizing a combination of the best valid segmentation models (BraTS models). \nThis highlights a crucial insight: they are inherently challenging to segment with confidence. \nTherefore, for such uncertain cases, manual segmentation remains the preferred approach. By \nincorporating CONSeg, we can enhance human-computer interaction and achieve more reliable \nsegmentation results. CONSeg can be useful in various clinical contexts, including tumor follow-\nup, assessment of tumor response to therapy, and prognosis. It is also valuable in metastasis \ndetection, as new metastases may not exhibit the typical tumoral features on MRI, making them \nharder to predict accurately with DL models. CP can help identify these suspicious regions and \nflag them as uncertain.  \nAdditionally, CONSeg can be used more generally, for tasks like anomaly detection, though \nthis was not the focus of our study. On the other hand, CONSeg can be applied across a wide range \nof tasks due to the flexibility of CP. It is post-hoc process, model-agnostic, requires minimal \ncomputational resources, and does not depend on large datasets, making it a versatile tool for \nvarious tasks. \nThis study is the first to apply CP for segmentation in neuroimaging. Our work introduces \nseveral novel contributions, including defining the UR and categorizing segmentation cases into \ncertain and uncertain. Additionally, we implemented prediction normalization, which has not been \npreviously used in CP. However, our study has some limitations. We trained our model just on a \nsingle MRI sequence (FLAIR), and all datasets used were publicly available, with model training \nconducted at a single center. Moreover, k-means clustering may not define the optimal threshold \n\n\nfor categorizing UR. Future studies should focus on further evaluating conformal segmentation \nand incorporating local datasets to enhance the modelâ€™s generalizability. Additionally, utilizing \nmore MRI sequence(s) may further improve the modelâ€™s performance. \nCONCLUSIONS \nCP effectively quantifies uncertainty in glioma segmentation, flagging uncertain voxels and cases. \nBy employing conformal segmentation, we enhance model reliability and human-computer \ninteraction. It also identifies less reliable segmentation cases, recommending them for manual \nsegmentation. \nCONFLICT OF INTERESTS \nThe authors declare no conflicts of interest related to the content of this article. \nREFERENCES \n1. Ostrom QT, Gittleman H, Liao P, et al. CBTRUS Statistical Report: Primary brain and \nother central nervous system tumors diagnosed in the United States in 2010-2014. Neuro \nOncol. 2017;19(suppl_5):v1-v88. https://doi.org/10.1093/neuonc/nox158 \n2. Rasool N, Bhat JI. A Critical Review on Segmentation of Glioma Brain Tumor and \nPrediction of Overall Survival. Arch Computat Methods Eng. 2024;17:1-45. \nhttps://doi.org/10.1007/s11831-024-10188-2 \n3. Elyassirad D, Gheiji B, Vatanparast M, et al. Comparative Analysis of 2D and 3D ResNet \nArchitectures for IDH and MGMT Mutation Detection in Glioma Patients. arXiv \npreprint. https://doi.org/10.48550/arXiv.2412.21091 \n4. Poursaeed R, Mohammadzadeh M, Safaei AA. Survival prediction of glioblastoma \npatients using machine learning and deep learning: a systematic review. BMC Cancer. \n2024;24(1):1581. https://doi.org/10.1186/s12885-024-13320-4 \n5. Gutta S, Acharya J, Shiroishi MS, et al. Improved Glioma Grading Using Deep \nConvolutional Neural Networks. AJNR Am J Neuroradiol. 2021;42(2):233-239. \nhttps://doi.org/10.3174/ajnr.A6882 \n6. Herr J, Stoyanova R, Mellon EA. Convolutional Neural Networks for Glioma \nSegmentation and Prognosis: A Systematic Review. Crit Rev Oncog. 2024;29(3):33-65. \nhttps://doi.org/10.1615/CritRevOncog.2023050852 \n7. LaBella D, Schumacher K, Mix M, et al. Brain tumor segmentation (brats) challenge \n2024: Meningioma radiotherapy planning automated segmentation. arXiv preprint. \nhttps://doi.org/10.48550/arXiv.2405.18383 \n8. MÃ¼ller S, Weickert J, Graf N. Robustness of brain tumor segmentation. J Med Imaging \n(Bellingham). 2020;7(6):064006. https://doi.org/10.1117/1.JMI.7.6.064006 \n\n\n9. Huang L, Ruan S, Xing Y, et al. A review of uncertainty quantification in medical image \nanalysis: Probabilistic and non-probabilistic methods. Med Image Anal. 2024;97:103223. \nhttps://doi.org/10.1016/j.media.2024.103223 \n10. Faghani S, Moassefi M, Rouzrokh P, et al. Quantifying Uncertainty in Deep Learning of \nRadiologic Images. Radiology. 2023;308(2):e222217. \nhttps://doi.org/10.1148/radiol.222217 \n11. Sagar A. Uncertainty quantification using variational inference for biomedical image \nsegmentation. arXiv preprint. https://doi.org/10.48550/arXiv.2008.07588 \n12. Zhou T, Zhu S. Uncertainty quantification and attention-aware fusion guided multi-modal \nMR brain tumor segmentation. Comput Biol Med. 2023;163:107142. \nhttps://doi.org/10.1016/j.compbiomed.2023.107142 \n13. Li H, Nan Y, Del Ser J, et al. Region-based evidential deep learning to quantify \nuncertainty and improve robustness of brain tumor segmentation. Neural Comput Appl. \n2023;35(30):22071-22085. https://doi.org/10.1007/s00521-022-08016-4 \n14. Faghani S, Gamble C, Erickson BJ. Uncover This Tech Term: Uncertainty Quantification \nfor Deep Learning. Korean J Radiol. 2024;25(4):395-398. \nhttps://doi.org/10.3348/kjr.2024.0108 \n15. Angelopoulos AN, Bates S. A gentle introduction to conformal prediction and \ndistribution-free uncertainty quantification. arXiv preprint. \nhttps://doi.org/10.48550/arXiv.2107.07511 \n16. Mossina L, Dalmau J, AndÃ©ol L. Conformal semantic image segmentation: Post-hoc \nquantification of predictive uncertainty. arXiv preprint. \nhttps://doi.org/10.48550/arXiv.2405.05145 \n17. Davenport, S. (2024). Conformal confidence sets for biomedical image \nsegmentation. arXiv preprint. https://doi.org/10.48550/arXiv.2410.03406 \n18. Gade M, Nguyen KM, Gedde S, et al. Impact of uncertainty quantification through \nconformal prediction on volume assessment from deep learning-based MRI prostate \nsegmentation. Insights Imaging. 2024;15(1):286. https://doi.org/10.1186/s13244-024-\n01863-w \n19. Calabrese E, Villanueva-Meyer JE, Rudie JD, et al. The University of California San \nFrancisco Preoperative Diffuse Glioma MRI Dataset. Radiol Artif Intell. \n2022;4(6):e220058. https://doi.org/10.1148/ryai.220058 \n20. Bakas S, Sako C, Akbari H, et al. The University of Pennsylvania glioblastoma (UPenn-\nGBM) cohort: advanced MRI, clinical, genomics, & radiomics. Sci Data. 2022;9(1):453. \nhttps://doi.org/10.1038/s41597-022-01560-7 \n21. Cardoso MJ, Li W, Brown R, et al. Monai: An open-source framework for deep learning \nin healthcare. arXiv preprint. https://doi.org/10.48550/arXiv.2211.02701 \n\n\nSUPPLEMENTAL FILES \nFigure S1. DSC of the segmentation model on the validation set at different thresholds \n \n \nFigure S2. Scatter plot showing the correlation between UR and the DSC on the internal test set \n(UCSF test set). \n \n \n \n \n\n\nFigure S3. Scatter plot showing the correlation between UR and the DSC on the internal test set \n(UCSF test set), with outlier(s) removed to better highlight the correlation in cases with lower \nUR. \n \nFigure S4. Scatter plot showing the correlation between UR and the DSC on the internal \ncalibration set (UCSF calibration set). \n \n \n \n \n\n\nFigure S5. K-means clustering used to determine the threshold on the internal calibration set UR \n \n \nFigure S6. Scatter plot showing the correlation between UR and the DSC on the external test set \n(UPenn test set). \n \n \n\n\nFigure S7. Scatter plot showing the correlation between UR and the DSC  on the external \ncalibration set (UPenn calibration set). \n \n \nFigure S8. K-means clustering used to determine the threshold on the external calibration set UR \n \n \n \n\n\nFigure S9. Scatter plot showing the correlation between UR and the BraTS fusion model DSC on \nthe external test set (UPenn test set). \n \n \n \n \n \n \n \n \n \n \n \n \n\n\n",
  "metadata": {
    "source_file": "dataset/pdfs/arxiv_2502.21158v1.pdf",
    "total_pages": 15,
    "title": "CONSeg: Voxelwise Glioma Conformal Segmentation",
    "authors": [
      "Danial Elyassirad",
      "Benyamin Gheiji",
      "Mahsa Vatanparast",
      "Amir Mahmoud Ahmadzadeh",
      "Shahriar Faghani"
    ],
    "abstract": "Background and Purpose: Glioma segmentation is crucial for clinical decisions\nand treatment planning. Uncertainty quantification methods, including conformal\nprediction (CP), can enhance segmentation models reliability. This study aims\nto use CP in glioma segmentation. Methods: We used the UCSF and UPenn glioma\ndatasets, with the UCSF dataset split into training (70%), validation (10%),\ncalibration (10%), and test (10%) sets, and the UPenn dataset divided into\nexternal calibration (30%) and external test (70%) sets. A UNet model was\ntrained, and its optimal threshold was set to 0.5 using prediction\nnormalization. To apply CP, the conformal threshold was selected based on the\ninternal/external calibration nonconformity score, and CP was subsequently\napplied to the internal/external test sets, with coverage reported for all. We\ndefined the uncertainty ratio (UR) and assessed its correlation with the Dice\nscore coefficient (DSC). Additionally, we categorized cases into certain and\nuncertain groups based on UR and compared their DSC. We also evaluate the\ncorrelation between UR and DSC of the BraTS fusion model segmentation (BFMS),\nand compare DSC in the certain and uncertain subgroups. Results: The base model\nachieved a DSC of 0.8628 and 0.8257 on the internal and external test sets,\nrespectively. The CP coverage was 0.9982 for the internal test set and 0.9977\nfor the external test set. Statistical analysis showed a significant negative\ncorrelation between UR and DSC for test sets (p<0.001). UR was also linked to\nsignificantly lower DSCs in the BFMS (p<0.001). Additionally, certain cases had\nsignificantly higher DSCs than uncertain cases in test sets and the BFMS\n(p<0.001). Conclusion: CP effectively quantifies uncertainty in glioma\nsegmentation. Using CONSeg improves the reliability of segmentation models and\nenhances human-computer interaction.",
    "published_date": "2025-02-28",
    "source": "arxiv"
  }
}