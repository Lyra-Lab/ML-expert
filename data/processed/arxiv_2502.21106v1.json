{
  "id": "arxiv_2502.21106v1",
  "text": "A Non-contrast Head CT Foundation Model for\nComprehensive Neuro-Trauma Triage\nYoungjin Yoo1, Bogdan Georgescu1, Yanbo Zhang1, Sasa Grbic1, Han Liu1,\nGabriela D. Aldea1,8,9, Thomas J. Re1, Jyotipriya Das1, Poikavila\nUllaskrishnan1, Eva Eibenberger2, Andrei Chekkoury2, Uttam K.\nBodanapally4, Savvas Nicolaou5, Pina C. Sanelli6, Thomas J. Schroeppel7,\nYvonne W. Lui3, and Eli Gibson1\n1 Digital Technology and Innovation, Siemens Healthineers, Princeton, NJ USA\n2 Department of Computed Tomography, Siemens Healthineers, Forchheim, Germany\n3 Department of Radiology, New York University, New York, NY USA\n4 Department of Radiology, University of Maryland Medical Center, Baltimore, MD\nUSA\n5 Department of Radiology, Vancouver General Hospital, Vancouver, BC Canada\n6 Department of Radiology, Northwell Health, New York, NY USA\n7 Department of Surgery, UCHealth Memorial Hospital, Colorado Springs, CO USA\n8 Foundational Technologies, Siemens SRL, Braşov, Romania\n9 Automation and Information Technology Department, Transilvania University of\nBraşov, Braşov, Romania\nAbstract. Recent advancements in AI and medical imaging offer trans-\nformative potential in emergency head CT interpretation for reducing\nassessment times and improving accuracy in the face of an increasing re-\nquest of such scans and a global shortage in radiologists. This study intro-\nduces a 3D foundation model for detecting diverse neuro-trauma findings\nwith high accuracy and efficiency. Using large language models (LLMs)\nfor automatic labeling, we generated comprehensive multi-label annota-\ntions for critical conditions. Our approach involved pretraining neural\nnetworks for hemorrhage subtype segmentation and brain anatomy par-\ncellation, which were integrated into a pretrained comprehensive neuro-\ntrauma detection network through multimodal fine-tuning. Performance\nevaluation against expert annotations and comparison with CT-CLIP\ndemonstrated strong triage accuracy across major neuro-trauma find-\nings, such as hemorrhage and midline shift, as well as less frequent crit-\nical conditions such as cerebral edema and arterial hyperdensity. The\nintegration of neuro-specific features significantly enhanced diagnostic\ncapabilities, achieving an average AUC of 0.861 for 16 neuro-trauma\nconditions. This work advances foundation models in medical imaging,\nserving as a benchmark for future AI-assisted neuro-trauma diagnostics\nin emergency radiology.\nKeywords: Foundation Model · Neuro-Trauma Detection · Head CT.\narXiv:2502.21106v1  [eess.IV]  28 Feb 2025\n\n\n2\nYoo et al.\n1\nIntroduction\nHead computed tomography (CT) is an essential diagnostic tool of emergency\nmedicine, particularly for assessing acute neurological symptoms and head trauma [13,\n20]. Its utilization is on the rise [26] while the availability of trained radiol-\nogists qualified to interpret its results is facing a worldwide shortage [16, 24].\nAI-assisted interpretation of emergent head CT could help address this situa-\ntion by increasing the efficiency and accuracy of available qualified radiologists\nand of less specialized clinicians in interpreting such imaging [19,22]. AI-driven\napproaches have evolved from supervised methods [12,21] to self-supervised and\nsemi-supervised approaches [7, 18], reducing dependence on extensive annota-\ntions. Recently foundation models trained on large datasets have shown remark-\nable success across domains [2] such as MedViT [14] and MIMIC-CXR [10].\nNotably, CT-CLIP [6] has enabled supervised-level zero-shot detection of chest\nabnormalities and FM-CT [27], a newly introduced head CT foundation model\nfor detecting various neuro conditions such as hemorrhages, tumors and other\nabnormalities, illustrating the transformative potential in medical imaging.\nDespite this progress, applying foundation models to head CT remains chal-\nlenging due to anatomical complexity and the broad spectrum of neuro-trauma\nconditions. Rapid and accurate diagnosis is critical in emergency settings [17],\nyet traditional interpretation is time-consuming and prone to variability [4,15].\nExisting foundation models may underperform in neuro-trauma detection due\nto domain-specific limitations. To address this, we developed a 3D foundation\nmodel specialized for head CT, trained on a large multi-site dataset. This model\nenables accurate, efficient few-shot detection of neuro-trauma conditions, poten-\ntially enhancing trauma triage and improving patient outcomes.\nOur contributions include setting benchmark performance for neuro-trauma\ndetection, demonstrating robust generalization across common and rare critical\nfindings, and emphasizing the importance of domain-specific pretraining [25,27].\nBy integrating neuro-specific pathological and anatomical features, we highlight\nthe advantages of specialized foundation models over CT-CLIP and the broader\ncoverage of neuro-trauma findings compared to FM-CT.\n2\nThe comprehensive neuro-trauma detection foundation\nmodel\nTo develop a head CT foundation model, a neuro-radiologist curated a compre-\nhensive list of neuro-trauma findings requiring urgent clinical attention [23,28],\nincluding Hemorrhage, Infarct, Mass Lesion, Mass Effect, Hydrocephalus, Mid-\nline Shift, Skull Fracture, Cerebral hemorrhagic Contusion, Diffuse Cerebral\nEdema, Microhemorrhage, Diffuse Axonal Injury, Generalized Cerebral Edema,\nPneumocephalus, Brain Herniation, Arterial Hyper-density and Venous Sinus\nHyper-density. Using this list, we automatically generated labels for a large-scale\ndataset through an Large Language Models (LLMs) pipeline. We independently\n\n\nComprehensive Neuro-Trauma Triage\n3\npretrained two task-specific vision networks and integrated these pretrained net-\nworks into a foundation model via multimodal finetuning with LLM-generated\nlabels. Instead of training directly on image-report pairs [6], we utilized image-\nLLM multi-label pairs to streamline task-specific pretraining and directly inte-\ngrate anatomical and pathological features.\n2.1\nAutomatic comprehensive labeling\nLeveraging recent advancements of LLMs in generating medical content [1], we\nautomatically generated multi-labels for neuro-trauma findings for each radio-\nlogical report in our dataset. The labels were generated using a private GPT4-o\nmodel on our private network. To efficiently label a large-scale dataset, we in-\nvestigated prompts that requested 16 multiple labels, minimizing the need for\nrepetitive label processing. The optimized prompt was “Given this radiology\nreport, extract POS or NEG value for these concepts {0}. POS means the con-\ncept is present in patient as per report. NEG means not. Return as json format\nwith keys being the name of the concepts and value being either POS or NEG.\nReport:{report content}”, and for {0} we provided the entire 16 neuro-trauma\nfindings as a list. Presenting labeling examples to the LLM before labeling the\nentire dataset improved labeling accuracy.\n2.2\nTask-specific pretraining\nWe pretrained two networks independently, each performing a specific task: brain\nbleeding (hemorrhage) subtype segmentation and brain anatomy parcellation.\nThe hemorrhage subtype segmentation network is based on a 3D Dense U-\nNet architecture [8], specifically designed for classifying five hemorrhage sub-\ntypes: intraparenchymal, subarachnoid, intraventricular, subdural, and epidu-\nral hemorrhages [5]. We adapted the specialized network architecture described\nin [5] for this task. In this work, the network additionally incorporates Squeeze-\nand-Excitation (SE) blocks [9] to enhance feature recalibration throughout the\narchitecture. SE blocks are strategically placed before and after each DenseBlock\nto adaptively recalibrate feature responses.\nThe brain parcellation network is designed for segmenting 15 brain struc-\ntures: left/right hemispheres, supratentorial/infratentorial regions, frontal lobe,\nparietal lobe, occipital lobe, temporal lobe, cerebellum, basal ganglia, medulla\noblongata, pons, midbrain, falx and ventricles. The network employs a U-Net ar-\nchitecture with 15 stages, using ReLU activations, batch normalization, strided\nconvolutions for downsampling and transposed convolutions for upsampling. The\nmodel employs a multi-head architecture with three output layers: one dedicated\nto segmenting left-side hemispheres, another for supratentorial-infratentorial re-\ngions, and a third handling the remaining brain structures.\n2.3\nBuilding a foundation model with multimodal finetuning\nOur foundation model is based on the 3D densely connected network specifically\ndesigned for brain hemorrhage classification [5], which we trained to perform\n\n\n4\nYoo et al.\ncomprehensive neuro-trauma detection tasks. We refer to it as the Comprehen-\nsive Neuro Trauma Detection Network (CNTD-Net). To learn a wider variety\nof imaging features for handling heterogeneous pathologies beyond brain hemor-\nrhage, we expanded the network capacity of the brain hemorrhage classification\nnetwork by increasing the number of layers and feature channels, resulting in the\nDeepCNTD-Net. Specifically, we increased the convolutional channel growth rate\nof the 3D DenseBlock from 5 to 8, the initial number of feature maps from 16 to\n64, the total number of 3D dense layers from 15 to 20, and the final feature vector\ndimension from 1638 to 4032. We pretrained both CNTD-Net and DeepCNTD-\nNet by performing the comprehensive neuro-trauma detection task using the\nLLM-generated multi-labels. To integrate the task-specific pretrained networks,\nwe employed an encoder that extracts features with dimensions similar to those\nof DeepCNTD-Net by collapsing the segmentation features. The features from\nDeepCNTD-Net, the hemorrhage subtype segmentation network, and the brain\nparcellation network were then fused using linear layers, which were subsequently\nused for multi-label classification. The feature fusion process was performed after\nfreezing the pretrained networks. Pre-training and fine-tuning were performed\nusing the Adam optimizer [11] to adapt the learning rates for each parameter.\nAdditionally, binary cross-entropy with logits loss was employed, incorporating\nadjusted class weights to effectively address the class imbalances in the dataset.\nThe overall procedure is illustrated in Fig. 1.\nFig. 1. Overview of the head CT foundation model for neuro-trauma triage.\n3\nResults and Discussion\n3.1\nDataset and Preprocessing\nAnonymized non-contrast CT (NCCT) head volumes were retrospectively col-\nlected from nine centers across the U.S., Canada, China, and India, with ethics\ncommittee approvals waiving informed consent. Data were sourced from pre-\nestablished cohorts or retrospective selections. NCCT volumes were acquired\nusing Siemens, GE, and Toshiba scanners. Exclusion criteria included age un-\nder 18 or absence of axial reconstruction. A total of 29,395 NCCT studies met\n\n\nComprehensive Neuro-Trauma Triage\n5\ninclusion criteria: (a) 26,514 studies were used for model development—23,592\nfor training and 2,922 for system optimization (architecture selection, parame-\nter tuning, and classifier calibration); (b) 2,881 studies were reserved for inde-\npendent performance evaluation. Patient-level random splitting was performed\nbefore development to prevent data contamination. The prevalence of trauma\nfindings, based on LLM labels, is shown in Fig. 2. Preprocessing involved auto-\nmatic alignment of axial NCCT volumes to a standard reference frame, resam-\npling to a 1-mm in-plane and 4-mm out-of-plane resolution, and normalization\nusing Hounsfield Unit (HU) windows: 0–80 HU (bleeding), -20–180 HU (brain),\nand -800–2000 HU (bone), scaled to 0–1. To enhance robustness against transla-\ntion and scanner noise, data augmentation included random in-plane translation\n(±10 mm), in-plane flipping (50% probability), random CT windowing noise\n(±10 HU), and random image noise (0.01 STD).\nFig. 2. A comprehensive list of neuro-trauma findings that encompass the critical con-\nditions requiring immediate clinical attention in trauma emergency centers curated by\na neuro-radiologist and their prevalence in our dataset.\n3.2\nLLM labeling accuracy against manual expert label\nWe evaluated the accuracy of our LLM pipeline labeling against expert-generated\nmanual labels for six major neuro-trauma findings in head CT scans (Table 1).\nThese six major labels were previously generated by expert users. LLMs achieved\n92–99% accuracy, except for ischemia / infarction at 79%, probably due to the\nlower sensitivity of NCCT causing ambiguities in the report. This highlights\nthe LLMs’ robustness in detecting diverse pathologies. Table 1 compares LLM\n\n\n6\nYoo et al.\nlabels with neuro-radiologist annotations for 200 randomly selected cases for\nall 16 findings. The LLMs excelled in identifying microhemorrhages, diffuse ax-\nonal injuries, and venous sinus hyperdensity (accuracy: 1.0) and performed well\non diffuse/generalized cerebral edema and skull fractures (0.99). These results\ndemonstrate the LLMs’ effectiveness in accurately labeling complex head CT\nfindings, supporting automated trauma triage.\nTable 1. LLM labeling accuracy compared to expert labels. Accuracy is reported for six\nmajor findings across the entire dataset (values in parentheses) and for all 16 findings\nin 200 randomly selected cases.\nFinding\nAccuracy\nFinding\nAccuracy\nHemorrhage\n0.95 (0.920) Diffuse cerebral edema\n0.99\nIschemia/Infarct\n0.80 (0.786) Microhemorrhage\n1.0\nMass Lesion\n0.95 (0.921) Diffuse axonal injury\n1.0\nMass Effect\n0.94 (0.958) Generalized cerebral edema\n1.0\nHydrocephalus\n0.95 (0.950) Pneumocephalus\n0.96\nMidline Shift\n0.99 (0.987) Brain herniation\n0.98\nSkull fracture\n0.99\nArterial Hyper-density\n0.99\nCerebral hemorrhagic contusion\n0.98\nVenous Sinus Hyper-density\n1.0\n3.3\nComprehensive neuro-trauma detection performance\nTable 2 presents ablation study results, assessing the impact of different model\ncomponents. The baseline CNTD-Net, designed for six major findings, achieved\nan AUC of 0.768. Expanding it to DeepCNTD-Net significantly improved per-\nformance (AUC: 0.858). Adding brain hemorrhage segmentation features (hem-\nSegFeat) further increased AUC to 0.873, underscoring their importance. In-\ncorporating brain anatomy features (brainAnatFeat) provided a slight boost to\n0.875. For detecting all 16 findings, DeepCNTD-Net reached an AUC of 0.849,\nimproving to 0.859 with hemSegFeat and peaking at 0.861 with brainAnat-\nFeat. Table 3 compares DeepCNTD-Net with CT-CLIP, which, despite being\ntrained on the same LLM-generated labels and fine-tuned with CT-LiPro [6],\nachieved lower AUCs (0.822 for six major findings, 0.835 for all 16). In contrast,\nDeepCNTD-Net, leveraging hemSegFeat and brainAnatFeat, achieved superior\nscores of 0.875 and 0.861, highlighting its advantage in neuro-trauma detection\nthrough specialized feature integration.\nWe analyzed individual AUC performance to identify key factors driving de-\ntection improvements (Fig. 3). Models incorporating segmentation and anatomi-\ncal features consistently outperformed baselines across both major and rare find-\nings, reinforcing the value of multimodal integration. DeepCNTD-Net, particu-\nlarly with hemSegFeat and brainAnatFeat, delivered superior results, achieving\nan AUC of 0.92 for hemorrhage detection versus CT-CLIP’s 0.83 and FM-CT’s\nrange of 0.835-0.929 (reported in [27]). For midline shift, DeepCNTD-Net vari-\nants reached up to 0.95, surpassing CT-CLIP’s 0.92. The enhanced models also\n\n\nComprehensive Neuro-Trauma Triage\n7\nTable 2. Average detection performance (AUC) results of ablation study for the six\nmajor neuro-trauma findings and all 16 findings. hemSegFeat: brain hemorrahge seg-\nmentation features; brainAnatFeat: brain anatomy segmentation features.\nModel\nAverage AUC\nCNTD-Net (6 major findings)\n0.768 ± 0.064\nDeepCNTD-Net (6 major findings)\n0.858 ± 0.066\nDeepCNTD-Net + hemSegFeat (6 major findings)\n0.873 ± 0.068\nDeepCNTD-Net + hemSegFeat + brainAnatFeat (6 major findings) 0.875 ± 0.065\nDeepCNTD-Net (all 16 findings)\n0.849 ± 0.090\nDeepCNTD-Net + hemSegFeat (all 16 findings)\n0.859 ± 0.085\nDeepCNTD-Net + hemSegFeat + brainAnatFeat (all 16 findings)\n0.861 ± 0.081\nTable 3. Average detection performance of CT-CLIP and DeepCNTD-Net with hem-\nSegFeat and brainAnatFeat.\nModel\nAverage AUC\nCT-CLIP (6 major findings)\n0.822 ± 0.081\nDeepCNTD-Net (6 major findings) 0.875 ± 0.065\nCT-CLIP (all 16 findings)\n0.835 ± 0.083\nDeepCNTD-Net (all 16 findings)\n0.861 ± 0.081\nimproved mass effect detection (AUC: 0.89), while CT-CLIP excelled in general-\nized cerebral edema, suggesting complementary strengths that could be leveraged\nthrough model fusion. To assess generalizability, we evaluated DeepCNTD-Net\non the CQ500 dataset [3], where it maintained strong performance in hemor-\nrhage (AUC: 0.920) and midline shift (AUC: 0.965), outperforming FM-CT [27]\n(hemorrhage AUC: 0.776-0.850, midline shift AUC: 0.780), but exhibited lower\naccuracy for mass effect (AUC: 0.840) against FM-CT (AUC: 0.90). Additionally,\nFM-CT outperformed in detecting edema (AUC: 0.827-0.923) and hydrocepahlus\n(AUC: 0.910-0.944), whereas DeepCNTD-Net achieved an AUC of 0.80-0.90 for\nedema and 0.90 for hydrocepahlus. These findings highlight the model’s relia-\nbility while pointing to areas for further refinement in neuro-trauma detection.\nFig. 4 showcases multi-finding detection, illustrating precise trauma identifica-\ntion alongside occasional false positives due to confounding pathologies.\nTable 4. Individual detection performance of DeepCNTD-Net with hemSegFeat and\nbrainAnatFeat on the CQ500 dataset for hemorrhage, mass effect and midline shift.\nFinding\nAUC (95% CI)\nHemorrhage 0.920 (0.876-0.956)\nMass Effect\n0.840 (0.755-0.910)\nMidline Shift 0.965 (0.922-0.996)\n\n\n8\nYoo et al.\nFig. 3. Individual detection performance (AUC) for six major critical findings and all\n16 neuro-trauma conditions. CNTD-Net was evaluated exclusively for the six major\nfindings.\nFig. 4. Examples of comprehensive neuro-trauma triage. \"POS\" indicates a positive\ncase, while \"NEG\" denotes a negative case, both based on the LLM-gerated multi-\nlabels, and AI triage score is between 0.0 and 1.0.\n\n\nComprehensive Neuro-Trauma Triage\n9\n4\nConclusion\nThis study highlights the potential of a specialized 3D foundation model for head\ntrauma triage, addressing the need for rapid, accurate diagnostics in emergency\nmedicine. By integrating LLM-driven automated labeling with task-specific neu-\nral networks for hemorrhage segmentation and brain anatomy parcellation, we\ndeveloped a robust framework for detecting a broad spectrum of neuro-trauma\nfindings in CT scans. Our DeepCNTD-Net variant achieved high accuracy across\nboth common and less frequent critical conditions, with multimodal feature inte-\ngration enhancing performance. It reached an average AUC of 0.861 for 16 neuro-\ntrauma findings, reinforcing the importance of domain-specific pretraining. This\nwork contributes to the growing evidence supporting AI-driven foundation mod-\nels in clinical practice, helping bridge the gap between increasing emergency head\nCT scans and the radiologist shortage. It also serves as a research reference point\nfor future foundation AI applications in neuro-trauma triage. To maximize clini-\ncal impact, future efforts will focus on real-world validation and seamless clinical\nintegration to improve patient care.\nDisclaimer The concepts and information presented in this paper are based on re-\nsearch results that are not commercially available. Future availability cannot be guar-\nanteed.\nReferences\n1. Bicknell, B.T., Butler, D., Whalen, S., Ricks, J., Dixon, C.J., Clark, A.B., Spaedy,\nO., Skelton, A., Edupuganti, N., Dzubinski, L., et al.: ChatGPT-4 omni perfor-\nmance in usmle disciplines and clinical skills: Comparative analysis. JMIR Medical\nEducation 10(1), e63430 (2024)\n2. Bommasani, R., Hudson, D.A., Adeli, E., Altman, R., Arora, S., von Arx, S.,\nBernstein, M.S., Bohg, J., Bosselut, A., Brunskill, E., et al.: On the opportunities\nand risks of foundation models. arXiv preprint arXiv:2108.07258 (2021)\n3. Chilamkurthy, S., Ghosh, R., Tanamala, S., Biviji, M., Campeau, N.G., Venugopal,\nV.K., Mahajan, V., Rao, P., Warier, P.: Deep learning algorithms for detection of\ncritical findings in head CT scans: a retrospective study. The Lancet 392(10162),\n2388–2396 (2018)\n4. Erly, W.K., Berger, W.G., Krupinski, E., Seeger, J.F., Guisto, J.A.: Radiology\nresident evaluation of head CT scan orders in the emergency department. American\njournal of neuroradiology 23(1), 103–107 (2002)\n5. Gibson, E., Georgescu, B., Ceccaldi, P., Trigan, P.H., Yoo, Y., Das, J., Re, T.J., Rs,\nV., Balachandran, A., Eibenberger, E., et al.: Artificial intelligence with statistical\nconfidence scores for detection of acute or subacute hemorrhage on noncontrast\nCT head scans. Radiology: Artificial Intelligence 4(3), e210115 (2022)\n6. Hamamci, I.E., Er, S., Almas, F., Simsek, A.G., Esirgun, S.N., Dogan, I., Dasdelen,\nM.F., Wittmann, B., Simsar, E., Simsar, M., et al.: A foundation model utilizing\nchest CT volumes and radiology reports for supervised-level zero-shot detection of\nabnormalities. CoRR (2024)\n\n\n10\nYoo et al.\n7. He, K., Zhang, X., Ren, S., Sun, J.: Deep residual learning for image recognition. In:\nProceedings of the IEEE conference on computer vision and pattern recognition.\npp. 770–778 (2016)\n8. Huang, G., Liu, Z., Van Der Maaten, L., Weinberger, K.Q.: Densely connected\nconvolutional networks. In: Proceedings of the IEEE conference on computer vision\nand pattern recognition. pp. 4700–4708 (2017)\n9. Jie, H., Li, S., Gang, S., Albanie, S.: Squeeze-and-excitation networks. In: Proceed-\nings of the IEEE conference on computer vision and pattern recognition. vol. 5\n(2018)\n10. Johnson, A.E., Pollard, T.J., Berkowitz, S.J., Greenbaum, N.R., Lungren, M.P.,\nDeng, C.y., Mark, R.G., Horng, S.: MIMIC-CXR, a de-identified publicly available\ndatabase of chest radiographs with free-text reports. Scientific data 6(1),\n317\n(2019)\n11. Kingma, D.P., Ba, J.: Adam: A method for stochastic optimization. CoRR\nabs/1412.6980 (2014), https://arxiv.org/abs/1412.6980\n12. Krizhevsky, A., Sutskever, I., Hinton, G.E.: Imagenet classification with deep con-\nvolutional neural networks. Advances in neural information processing systems 25\n(2012)\n13. Lolli, V., Pezzullo, M., Delpierre, I., Sadeghi, N.: MDCT imaging of traumatic\nbrain injury. The British journal of radiology 89(1061), 20150849 (2016)\n14. Manzari, O.N., Ahmadabadi, H., Kashiani, H., Shokouhi, S.B., Ayatollahi, A.:\nMedViT: a robust vision transformer for generalized medical image classification.\nComputers in Biology and Medicine 157, 106791 (2023)\n15. Parag, P., Hardcastle, T.C.: Interpretation of emergency ct scans of the head in\ntrauma: neurosurgeon vs radiologist. World Journal of Surgery 46(6), 1389–1395\n(2022)\n16. Parag, P., Hardcastle, T.C.: Shortage of radiologists in low to middle income coun-\ntries in the interpretation of CT scans in trauma. Bangladesh Journal of Medical\nScience 21(3), 489–491 (2022)\n17. Rincon, S., Gupta, R., Ptak, T.: Imaging of head trauma. Handbook of clinical\nneurology 135, 447–477 (2016)\n18. Ronneberger, O., Fischer, P., Brox, T.: U-net: Convolutional networks for biomed-\nical image segmentation. In: Medical image computing and computer-assisted\nintervention–MICCAI 2015: 18th international conference, Munich, Germany, Oc-\ntober 5-9, 2015, proceedings, part III 18. pp. 234–241. Springer (2015)\n19. Savage, C.H., Tanwar, M., Elkassem, A.A., Sturdivant, A., Hamki, O., Sotoudeh,\nH., Sirineni, G., Singhal, A., Milner, D., Jones, J., et al.: Prospective evaluation\nof artificial intelligence triage of intracranial hemorrhage on noncontrast head CT\nexaminations. American Journal of Roentgenology 223(5), e2431639 (2024)\n20. Sharp, A.L., Nagaraj, G., Rippberger, E.J., Shen, E., Swap, C.J., Silver, M.A.,\nMcCormick, T., Vinson, D.R., Hoffman, J.R.: Computed tomography use for adults\nwith head injury: describing likely avoidable emergency department imaging based\non the canadian CT head rule. Academic Emergency Medicine 24(1), 22–30 (2017)\n21. Simonyan, K.: Very deep convolutional networks for large-scale image recognition.\narXiv preprint arXiv:1409.1556 (2014)\n22. Vimalesvaran, K., Robert, D., Kumar, S., Kumar, A., Narbone, M., Dharmad-\nhikari, R., Harrison, M., Ather, S., Novak, A., Grzeda, M., et al.: Assessing the\neffectiveness of artificial intelligence (AI) in prioritising ct head interpretation:\nstudy protocol for a stepped-wedge cluster randomised trial (ACCEPT-AI). BMJ\nopen 14(6), e078227 (2024)\n\n\nComprehensive Neuro-Trauma Triage\n11\n23. Wintermark, M., Sanelli, P.C., Anzai, Y., Tsiouris, A.J., Whitlow, C.T., Druzgal,\nT.J., Gean, A.D., Lui, Y.W., Norbash, A.M., Raji, C., et al.: Imaging evidence\nand recommendations for traumatic brain injury: conventional neuroimaging tech-\nniques. Journal of the American College of Radiology 12(2), e1–e14 (2015)\n24. Yaghmai, V.: Editorial comment: Bridging the gap—international medical grad-\nuates and the radiologist shortage in the united states. American Journal of\nRoentgenology 222(1), e2330540 (2024)\n25. Yoo, Y., Zhao, G., Sandu, A.E., Re, T.J., Das, J., Wang, H., Kim, M., Shen, C.,\nLee, Y., Kondziolka, D., et al.: The importance of data domain on self-supervised\nlearning for brain metastasis detection and segmentation. In: Medical Imaging\n2023: Computer-Aided Diagnosis. vol. 12465, pp. 556–562. SPIE (2023)\n26. Yun, B.J., Borczuk, P., Zachrison, K.S., Goldstein, J.N., Berlyand, Y., Raja, A.S.:\nUtilization of head CT during injury visits to united states emergency departments:\n2012–2015. The American journal of emergency medicine 36(8), 1463–1466 (2018)\n27. Zhu, W., Huang, H., Tang, H., Musthyala, R., Yu, B., Chen, L., Vega, E.,\nO’Donnell, T., Dehkharghani, S., Frontera, J.A., et al.: 3D foundation AI model\nfor generalizable disease detection in head computed tomography. arXiv preprint\narXiv:2502.02779 (2025)\n28. Zimmermann, L.L., Tran, D., Lovett, M., Mangat, H.: Emergency neurological life\nsupport, traumatic brain injury protocol (version 4.0). Neurocritical Care Society\npp. 1–33 (2019)\n\n\n",
  "metadata": {
    "source_file": "dataset/pdfs/arxiv_2502.21106v1.pdf",
    "total_pages": 11,
    "title": "A Non-contrast Head CT Foundation Model for Comprehensive Neuro-Trauma Triage",
    "authors": [
      "Youngjin Yoo",
      "Bogdan Georgescu",
      "Yanbo Zhang",
      "Sasa Grbic",
      "Han Liu",
      "Gabriela D. Aldea",
      "Thomas J. Re",
      "Jyotipriya Das",
      "Poikavila Ullaskrishnan",
      "Eva Eibenberger",
      "Andrei Chekkoury",
      "Uttam K. Bodanapally",
      "Savvas Nicolaou",
      "Pina C. Sanelli",
      "Thomas J. Schroeppel",
      "Yvonne W. Lui",
      "Eli Gibson"
    ],
    "abstract": "Recent advancements in AI and medical imaging offer transformative potential\nin emergency head CT interpretation for reducing assessment times and improving\naccuracy in the face of an increasing request of such scans and a global\nshortage in radiologists. This study introduces a 3D foundation model for\ndetecting diverse neuro-trauma findings with high accuracy and efficiency.\nUsing large language models (LLMs) for automatic labeling, we generated\ncomprehensive multi-label annotations for critical conditions. Our approach\ninvolved pretraining neural networks for hemorrhage subtype segmentation and\nbrain anatomy parcellation, which were integrated into a pretrained\ncomprehensive neuro-trauma detection network through multimodal fine-tuning.\nPerformance evaluation against expert annotations and comparison with CT-CLIP\ndemonstrated strong triage accuracy across major neuro-trauma findings, such as\nhemorrhage and midline shift, as well as less frequent critical conditions such\nas cerebral edema and arterial hyperdensity. The integration of neuro-specific\nfeatures significantly enhanced diagnostic capabilities, achieving an average\nAUC of 0.861 for 16 neuro-trauma conditions. This work advances foundation\nmodels in medical imaging, serving as a benchmark for future AI-assisted\nneuro-trauma diagnostics in emergency radiology.",
    "published_date": "2025-02-28",
    "source": "arxiv"
  }
}