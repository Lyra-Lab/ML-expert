{
  "id": "arxiv_2502.21224v1",
  "text": "Detecting Linguistic Diversity on Social Media\nSidney Wong, Benjamin Adams, and Jonathan Dunn\nAbstract This chapter explores the efficacy of using social media data to examine\nchanging linguistic behaviour of a place. We focus our investigation on Aotearoa\nNew Zealand where official statistics from the census is the only source of language\nuse data. We use published census data as the ground truth and the social media sub-\ncorpus from the Corpus of Global Language Use as our alternative data source. We\nuse place as the common denominator between the two data sources. We identify\nthe language conditions of each tweet in the social media data set and validated\nour results with two language identification models. We then compare levels of\nlinguistic diversity at national, regional, and local geographies. The results suggest\nthat social media language data has the possibility to provide a rich source of spatial\nand temporal insights on the linguistic profile of a place. We show that social media\nis sensitive to demographic and sociopolitical changes within a language and at\nlow-level regional and local geographies.\n1 Introduction\nNational censuses across the globe have been criticised for their “high cost, low\nfrequency, publication lag, limited geographic detail and limited breakdown of pop-\nulations classifications into sub-categories” [10]. Policy makers, non-government\norganisations, and researchers all use census data to determine the demographic\nprofile of places and communities. In Aotearoa New Zealand (New Zealand), census\ninformation is the only source of data on languages for social scientists, linguists, and\nSidney Wong\nGeospatial Research Institute, e-mail: sidney.wong@pg.canterbury.ac.nz\nBenjamin Adams\nUniversity of Canterbury, e-mail: benjamin.adams@canterbury.ac.nz\nJonathan Dunn\nUniversity of Illinois Urbana-Champaign, e-mail: jedunn@illinois.edu\n1\narXiv:2502.21224v1  [cs.CL]  28 Feb 2025\n\n\n2\nSidney Wong, Benjamin Adams, and Jonathan Dunn\nthose working in language revitalisation, retention, and maintenance programmes\n[1]. This reliance on a single data source is a risk leading us to consider alternative\ndata sources and methodologies to collect this information.\nIn this chapter, we investigate the feasibility of using social media data as an\nalternative data source within the context of New Zealand. Based on current research,\nit is possible to observe linguistic behaviour of an underlying population using social\nmedia [6]. Therefore, we use social media language data to examine the linguistic\nsituation of New Zealand. We investigate the following research questions in our\nanalysis:\n•\nHow do census data and social media data compare in terms of their basic\ncharacteristics and what they might tell us about language use variation over\nspace and time?\n•\nAnd more importantly, how might we use social media data in place of official\nstatistics when performing analyses based on language use information?\nWe analyse data from two sources: the New Zealand Census of Population and\nDwellings (the census) and the web-based Corpus of Global Language Use (CGLU)\n[2]. We consider census as the ground truth on the linguistic situation of New Zealand\nand the social media language data from the CGLU is our alternative data source. We\ncan compare the two data sets as they are both organised spatially. We use language\nidentification models to identify the languages present in our social media language.\nWe compare the efficacy of the two language identification models in our analysis.\nFollowing this data analysis step, we compute measures of linguistic diversity from\nour ground truth data and our alternative data source at national, regional, and\nlocal geographic levels. This allows us to understand the similarities and differences\nbetween census and social media language data.\n2 Background\n2.1 Linguistic Situation of New Zealand\nAoteaora is an island country located in the South Pacific Ocean. New Zealand has\ntwo official languages: te reo M¯aori and New Zealand Sign Language (NZSL). These\nlanguages accounts for 4.0% and 0.5% of languages used in New Zealand as of the\n2018 Census. However, the most commonly spoken language in New Zealand is\nEnglish which is the de facto official language and accounts for 95.4% of languages\nspoken in the population [26]. The dominance of English across New Zealand society\nis a result of British colonisation and settlement beginning in the 19th Century and\nsubsequent impacts of globalisation [13].\nGovernment preference for migrants from the United Kingdom and Australia and\ndiscriminatory legislation limiting migration from Asia has meant New Zealand\nsociety remained largely linguistically homogenous throughout the 19th and 20th\n\n\nDetecting Linguistic Diversity on Social Media\n3\nTable 1 Most common languages spoken in New Zealand in 2001 and 2018\nRank 2001 Census\n2018 Census\n1\nEnglish\nEnglish\n2\nte reo M¯aori\nte reo M¯aori\n3\nSamoan\nSamoan\n4\nFrench\nNorthern Chinese\n5\nYue\nHindi\n6\nGerman\nFrench\n7\nNZSL\nYue\n8\nNorthern Chinese Sinitic not further defined\n9\nDutch\nTagalog\n10\nTongan\nGerman\nCenturies. The demographic make-up of New Zealand significantly changed as a\nresult of the Immigration Policy Review in 1986, which has allowed an increased\nnumber of migrants from non-Anglophone countries to immigrate to New Zealand\n[11].\nThis demographic change is evident in the most common languages used across\nNew Zealand. The top ten most spoken languages as of the 2001 Census [29] and\nthe 2018 Census [26] are presented in Table 1. While the top three most common\nlanguages (English, te reo M¯aori, and Samoan) remained the same, over half of the\nmost common languages spoken in New Zealand originate from Asian countries\nsuch as Northern Chinese (including Mandarin), Hindi, Yue (Cantonese), Sinitic not\nfurther defined (which is used to signify an unspecified Sinitic (Chinese) language),\nand Tagalog. Respondents who did not provide a valid response or were too young\nto talk at the time of the census were excluded from Table 1.\nWe can see that in a period of less than twenty years, both the demographic\nand linguistic make-up of New Zealand have significantly changed. An increase in\nlinguistic diversity coupled with the legislative recognition of te reo M¯aori in 1987\nand NZSL in 2006 have increased the public consciousness to language rights and\nlinguistic inclusion.\n2.2 Surveying Language\nThere are practical reasons in understanding the changing linguistic profile of New\nZealand and allow communities to provide linguistically appropriate services across\ndifferent populations. As of present, the most reliable source of language data for\nNew Zealand comes from the census. The census provides the official count of all\npeople and dwellings in New Zealand every five years [22]. This information is used\nto determine electoral boundaries and informs the distribution of public funding.\n\n\n4\nSidney Wong, Benjamin Adams, and Jonathan Dunn\nThe questions in the census are not static and have frequently changed over time.\nThe changes depend on the needs of New Zealand’s official statistics system. For\nexample, questions relating to iwi and ethnic affiliation have only been included\nas part of the individual form since the 1991 Census. Other variables which were\ndeemed no longer relevant such as race, ethnic origin, or nationality have since been\nremoved. The language census topic was only included as part of the 1996 Census.\nThe languages spoken variable is derived from the language census topic question\nin the individual form. More specifically, the questions asks “In which language(s)\ncould you have a conversation about a lot of everyday things?”. This question is a\nmultiple response variable which means participants can include up to six languages\nwhich are coded according to the Language Standard Classification 1999 [27]. In\na multiple response variable, each response is counted towards each applicable\nlanguage classification. Other modalities of language such as signed languages (e.g.,\nNZSL, American Sign Language) are also included as part of the question.\nThe languages spoken variable is a priority three variable which means the vari-\nable does not directly fit with the main purpose of the census, but this information\nis still important to certain populations and communities [27]. The language census\ntopic and the languages spoken variable serves the following functions:\n1. To formulate, target and monitor policies and programmes to revitalise the M¯aori\nlanguage as an official language of New Zealand.\n2. As an indicator of iwi vitality and cultural resources.\n3. To assess the need to provide multi-lingual pamphlets and other translation ser-\nvices in a variety of areas such as education, health and welfare.\n4. To evaluate and monitor existing language education programmes and services.\n5. To provide information for television and radio programmes and services.\n6. To understand the diversity and diversification of the New Zealand population\nover time, as well as language maintenance, retention and distribution.\nOne limitation of the language census topic is that it does not collect written\nlinguistic ability or fluency. It is not possible to determine linguistic competence\nacross different modalities from the language census topic alone. Only Te Kupenga,\na sample survey of 8,500 M¯aori aged 15 years and over living across New Zealand,\nincludes questions regarding written ability and fluency in te reo M¯aori [23]. This\nmeans the census may not meet the needs of heritage language revitalisation efforts\nfor other culturally and linguistically diverse communities.\nDespite the benefits of the census, the national survey is a costly endeavour. The\n2023 Census was estimated to cost NZ$250 million - almost double the cost of\nthe 2018 Census [32]. The success of a census, measured by its response rate, is\nsusceptible to social, environment, and political factors. The proposed 2011 Census\nwas postponed to 2013 due to the 2010-2011 Canterbury Earthquakes. There is also\na trend in declining response rates to surveys [8]. This downward trend was reflected\nin the results of the 2018 Census which was known for its low response rate of 83.3%\n[24]. This is significant 8.9% decline from the 2013 Census.\nIn the case of the language census topic, only 83.8% of responses came from\nthe 2018 Census, 8.2% of responses were derived from 2013 Census data, and\n\n\nDetecting Linguistic Diversity on Social Media\n5\nthe remaining 8.0% of responses were derived through statistical imputation [27].\nDespite the low response, the data quality of the languages spoken variable was rated\nhigh quality. This is particularly concerning for policy makers and researchers who\nuse this information to determine the success of language revitalisation programmes.\n2.3 Alternative Data Sources\nThe five-year (and in some cases ten-year for some countries) census cycles which\nhave traditionally met the requirements to simply count a population. This does not\nmeet the needs of data hungry public and private sector organisations who require\nmore contemporaneous demographic insights on populations. If the purpose of a\ncensus is to understand the changing demographic profile of a population, then\nperhaps there are other data sources and methods to meet this need.\nOne suggested method is the use administrative data as an alternative to a con-\nventional census survey [19]. Administrative data includes all the transactional data\nheld by central government ministries and departments. This information is currently\nmanaged by Stats NZ as part of the Integrated Data Infrastructure (IDI) [16]. For ex-\nample, information about individuals in New Zealand such as location and ethnicity\ndata are held by the Ministry of Health, education and training data are held by the\nMinistry of Education, work and income data are held by Inland Revenue to list a\nfew. This method will only be suitable for some topics and not others.\nThere are currently no administrative sources identified which is suitable to\nreplace the languages spoken variable [1]. The only alternative sources for language\ninformation from other official sources are the biennial General Social Survey (GSS),\na sample survey of 8,000 individuals in households across New Zealand aged 15\nyears and over [30], and enrolment data from the Ministry of Education [17]. This\nmeans we are unlikely to get good quality data about language equivalent to a census\nfrom administrative sources [19].\nThese data gaps coupled with technical issues surrounding sensitive demographic\nattributes such as ethnicity, the lack of consent sought from individuals, and barriers\nin access to the data in the IDI raise legislative and ethical issues as a source of\nofficial statistics. These issues have serious consequences for the government and its\ncommitment to Te Tiriti o Waitangi in upholding M¯aori Data Sovereignty (MDS)\n[9]. In essence, MDS ensures M¯aori communities have the ability to exercise power\nover usage and outputs of data produced by M¯aori and about M¯aori [31].\nBeyond administrative data, social media has been offered as an alternative data\nsource for national censuses and surveys outside of New Zealand [10]. Early work in\nthe United Kingdom investigating the feasibility of using social media data to derive\ndemographic information found that gender and language information from Twitter,\nalso known as X, is proportional to results observed in the 2011 Census [21].\nThere were an estimated 4.99 million internet users in New Zealand in January\n2023. This is equivalent to an internet penetration rate of 95.9% out of New Zealand’s\nestimated population of 5.21 million [14]. More specifically, there was an estimated\n\n\n6\nSidney Wong, Benjamin Adams, and Jonathan Dunn\nTable 2 Social media platform users in New Zealand\nPlatform\nUsers (in millions)\nFacebook\n2.95\nYoutube\n4.24\nInstagram\n2.15\nTikTok\n1.65\nLinkedIn\n2.50\nSnapchat\n1.45\nX (Twitter)\n0.79\nPinterst\n0.67\n4.24 million social media users in New Zealand. This means over 80.0% of New\nZealand’s population have subscribed to a social media platform. Based on this level\nof coverage, social media may be a feasible alternative data source. The user base\nfor different social media platforms have been included in Table 2.\n2.4 Digital Language and Place\nOf the different social media platforms, X (Twitter) is by far the greatest contributor\nof digital language data despite representing 15.2% of New Zealand. A benefit of\nX (Twitter) is the massive volume of publicly available data. X (Twitter) provides\nresearchers access to their data including tweet and user information through their\nApplication Programming Interface (API). Researchers with ‘Essential’ access can\nretrieve up to 500 thousand tweets per month while those who qualify for ‘Academic\nResearch’ access can retrieve up to 10 million tweets per month.\nResearchers can also access temporal and spatial information for each tweet\nthrough the API based on X (Twitter)’s user-enabled geotagging feature [15]. The\nsearch polygon shape is determined by the type of data request: rectangular for\nreal-time tweets and circular for historical tweets. There are no limits to the search\npolygon size, but there is no guarantee all tweets within a geographic area will be\nretrieved.\nThere are some limitations to this data. The number of geotagged tweets only\naccount for a small proportion of tweets as the geotagging feature is disabled by\ndefault. Sloan et al. [21] found that only 0.85% of tweets were geotagged in a sample\nof 113 million tweets. There are also significant demographic differences between\nthe type of users who enable geotagging based on the user’s perceived age, social\nclass, language background, and user interface language [20].\nX (Twitter)’s user base may not be a balanced sample of an underlying population.\nIn the US context, X (Twitter) users tend to skew towards younger urban users who\ncome from an ethnic minority background [18]. We must consider the types of biases\ninherent to digital language and place data when making claims about linguistic\nbehaviour on social media.\n\n\nDetecting Linguistic Diversity on Social Media\n7\nRecent work has shown progress in addressing these limitations. Dunn et al. [5]\nfound that digital language behaviour was sensitive to real-world events. The study\ntracked changes in national measures of linguistic diversity over the course of the\nCOVID-19 pandemic. They were able to account for non-local bias as nationwide\nlockdowns limited travel and migration internationally and domestically.\n3 Data and Methods\n3.1 Corpus of Global Language Use\nThe Corpus of Global Language Use (CGLU) is a web-based corpus which consists\nof the web sub-corpus retrieved through Common Crawl and the social media sub-\ncorpus retrieved through the X (Twitter) API [2]. Data collection has been on-going\nsince 2017. Our focus is the social media sub-corpus.\nThe sub-corpus is coded with both temporal and spatial information. Each tweet\nhas been coded for broad geographic region, country of origin, nearest city, date,\na corresponding fifteen-character geohash , and the content of the tweet itself. The\ngeohash is derived from the latitude and longitude information linked to geotagged\nenabled tweets. The data collection points come from the global Geonames data set\n[7]. We filtered the social media sub-corpus for tweets originating from within New\nZealand. There are one hundred data collection points across New Zealand. The\nsocial media sub-corpus contains geotagged enabled tweets within a 50-kilometre\nradius for each data collection point. The data set does not contain duplicates.\nWe linked each of the data collection points to one of the sixteen regional council\nareas. We visualised the data collection points in Figure 1. A majority of the data\ncollection points are in Te Ika a M¯aui (the North Island). This is expected as more than\na third of the population resides in Te Ika a M¯aui. Te Waipounamu (the South Island)\nis sparsely populated despite being the larger of the two islands. The data catchment\narea accounts for 97.6% of the estimated resident population as of December 2022.\nInversely, Figure 2 visualises all small urban areas (light green) situated outside the\ndata catchment area. This area amounts for a estimated population of 56,904 as of\nDecember 2022 [30]. Small urban areas and rural settlements with an estimated\npopulation greater than 1,000 people as of 2022 includes: Taumarunui (est. 4,830),\nKaik¯oura (est. 2,330), Twizel (est. 1,780), and Alexandra (est. 6,010). Overall, the\ncglu has good coverage of New Zealand despite missing data from these small urban\nsettlements\nMore detailed information on the individual data collection points are presented\nin Table 5 the Appendix. We do not have data linked to the Nelson region. With\nreference to Figure 1, tweets originating from the Nelson region are captured by data\ncollection points located in the neighbouring Tasman and Marlborough regions.\n\n\n8\nSidney Wong, Benjamin Adams, and Jonathan Dunn\nFig. 1 Settlements within CGLU catchment area.\n\n\nDetecting Linguistic Diversity on Social Media\n9\nFig. 2 Settlements outside CGLU catchment area.\n3.2 New Zealand Census of Population and Dwellings\nWe use published census data as the ground truth data set. It is a suitable source to\ndetermine the ground truth linguistic situation of New Zealand as the census is a\n\n\n10\nSidney Wong, Benjamin Adams, and Jonathan Dunn\nFig. 3 Differences between language identification models idNet (left) and pacificID (right).\nnational count of all individuals in New Zealand. Published census data is publicly\naccessible online. This data is aggregated and confidentialised. We retrieved the\nnational-level and regional-level data from NZ.Stat [26]. The data set includes data\nfrom the 2006, 2013, and 2018 census cycles. As we only have access to social media\ndata from 2017 on wards, the focus of our study is on the 2018 Census.\nWe removed additional metadata information as part of the data cleaning process.\nSigned languages such as NZSL were removed from the analytical data set. These\nwere excluded from the current analysis as they do not have a corresponding written\northography identifiable through the language identification models. Furthermore,\nunspecified languages from the statistical classification in ’Other’ and ‘None (e.g.\ntoo young to talk)’ were also removed from the analytical data set.\nWe retrieved additional population information for New Zealand from NZ.Stat\n[25] and geographic information from Datafinder [28]. A demographic summary of\nNew Zealand and the regional council areas are available in Table 6 of the Appendix.\n3.3 Language Identification\nThe first data processing step in our study is to identify the predominate language\nfor each tweet. Unlike the census language topic which is based on self-rated ability,\nthe language condition for each tweet is not implicitly available from the CGLU.\nAlthough X (Twitter) provides support for 34 written languages on sign-up, 33.0%\n\n\nDetecting Linguistic Diversity on Social Media\n11\nTable 3 Most common languages in 2018\nRank 2018 Census\nidNet\npacificLID\n1\nEnglish\nEnglish\nEnglish\n2\nte reo M¯aori\nPortuguese Portuguese\n3\nSamoan\nJapanese\nThai\n4\nNorthern Chinese\nTagalog\nJapanese\n5\nHindi\nSpanish\nSpanish\n6\nFrench\nIndonesian Tagalog\n7\nYue\nArabic\nMalaysian\n8\nSinitic not further defined French\nFrench\n9\nTagalog\nKorean\nArabic\n10\nGerman\nThai\nKorean\nof tweets were in a language that was different from the user interface in a sample\nof 113 million tweets [21].\nWe use the idNet language identification classification model to automatically\ncode the primary language of a tweet [3]. The package has a high accuracy with\na reported F1-score above 0.95 for 464 languages based on 50-character language\nsamples. The second language classifier we have used for this study is the pacificLID\npackage [4]. This language classifier was especially adapted to identify Austronesian\nlanguages (e.g., te reo M¯aori). This is particularly useful in an New Zealand context.\nWe visualised the classification differences between the language identification mod-\nels in Figure 3. Both classifiers were included as part of our analysis for comparability\nas there may be classification errors (i.e., as a result of code switching).\n3.4 Linguistic Diversity\n3.5 Language Identification\nThe last data processing step is to calculate measure of linguistic diversity for the\nvarious levels of geography (national, regional, and local). A simple implementation\nof this measure is the concentration ratio (CR) which we can use as a proxy for\nlinguistic diversity [12]. A CR is used to determine the market structure and com-\npetitiveness of the market and provides a range between 0% to 100%. Common CR\nmeasures include 4-firm (CR4) and 8-firm (CR8). We used a 10-firm CR (𝐶𝑅10).\nThis means for each geographic location, we selected the top ten most common\nlanguages in use. The CR is calculated as in Equation 1.\n𝐶𝑅𝑛= 𝐶1 + 𝐶2 + ... + 𝐶𝑛\n(1)\nWhere: Cn defines the share of the 𝑛th largest languages as a % of a population\nand n defines the number of languages included in the CR calculation.\n\n\n12\nSidney Wong, Benjamin Adams, and Jonathan Dunn\nA𝐶𝑅10 measure under 0.40 suggests low concentration (i.e., perfect competition).\nA 𝐶𝑅10 measure between 0.40 to 0.70 suggests medium concentration (i.e., an\noligopoly). A𝐶𝑅10 measure over 0.70 suggests high concentration (i.e., a monopoly).\nThis means the the lower the measure, the higher the levels of linguistic diversity.\n4 Results\nWe observed a high level of agreement between the idNet and the pacificLID models.\nThere were 76,007 mismatches between the two language identification models. The\nrate of mismatch between the two packages was equivalent to 0.76%. A closer\ninspection of mismatched tweets in English and te reo M¯aori found that a majority of\ntweets were reclassified from English to te reo M¯aori between idNet and pacificLID.\nIn the case of te reo M¯aori tweets identified with idNet, most tweets were re-\nclassified to Tongan and the remaining tweets were equally reclassified to English,\nChamorro, Japanese, Niuean, Albanian, and Wallisian. The reclassification of tweets\nin te reo M¯aori to Chamorro, Niuean, Tongan, and Wallisian was expected as the\npacificLID package was trained to be more sensitive to Austronesian languages.\nThe reclassified tweets could be corrections, or indeed classification errors as\nsome tweets which were predominately in English were reclassified as te reo M¯aori.\nOther reasons for the mismatches between the idNet and the pacificLID could be the\nresult of code-switching or other translanguaging practices that were not captured\nby a classification type language identification model.\nWe identified 403 distinct languages within the sub-corpus. This number is signif-\nicantly higher than the 196 languages listed in the Language Standard Classification\n1999. The nature of written language differs significantly from spoken language.\nThere is not always a one-to-one relationship between the two modes of language.\nIn some cases there could be a zero-to-one, one-to-many, or many-to-many relation-\nships between modes. This means language varieties represented in the census data\nmay not appear in the social media sub-corpus and vice versa.\nTable 3 compares the top ten most common languages from the latest census and\nthe social media language data. English was the most common language across the\ntwo models. This was expected. However, there were a few unexpected results. For\nexample, te reo M¯aori, Samoan, Hindi, German, or any of the Sinitic languages were\nrarely observed on X (Twitter). While census data only provides spatial granularity\nto neighbourhood level geographies, social media data provides both spatial and\ntemporal granularity. This is because census cycles occur once every five (or ten\nyears), while social media platforms can capture data contemporaneously. Figure 4\nand Figure 5 demonstrate this by visualising the monthly frequency count of tweets\nin some language conditions.\nFigure 4 includes languages with high (where y-limit is 500,000) and medium\n(where y-limit is 10,000) frequency counts while Figure 5 includes languages with\nlow (where y-limit is 10,000). The dashed lines on the figure compares the results\nfrom idNet (in grey) and pacificLID (in black). We can see a high level of consistency\n\n\nDetecting Linguistic Diversity on Social Media\n13\nFig. 4 High and Medium Frequency Languages on X (Twitter)\n\n\n14\nSidney Wong, Benjamin Adams, and Jonathan Dunn\nFig. 5 Low Frequency Languages on X (Twitter)\nbetween the two language identification models for English, Spanish, Portuguese,\nand French in Figure 4 and Korean and German in Figure 5.\nIt is clear that the level of consistency is not the result of data availability (as shown\nby the monthly frequency count on the y-axis), but the efficacy of the language\nidentification model itself. There are some severe irregularities between the two\nmodels particularly in Japanese, Tagalog, and written vernacular Chinese, Tagalog\nin Figure 4 and te reo M¯aori and Hindi in Figure 5. The discrepancies between\nBahasa Indonesia and Malay is a result of how these languages are coded in the two\nmodels. These differences require a deeper analysis beyond the scope of this chapter.\nDespite these irregularities, there is value in this information as we can conduct\ntime series analyses on different language conditions. For te reo M¯aori in particular\nas shown in Figure 5, we can observe a seasonal peak of tweets during the second\nhalf of the year. This increase in frequency coincides with Mahuru M¯aori where\nparticipants are encouraged to use te reo M¯aori in all facets of everyday life. This\nsuggests we can observe real-time changes to the linguistic profile of New Zealand\nbased on significant cultural movements.\n\n\nDetecting Linguistic Diversity on Social Media\n15\nFig. 6 Monthly frequency counts of tweets and corresponding 𝐶𝑅10 measures\n4.1 Linguistic Diversity\nNow that we have confirmed that the language identification models can suitably\nidentify languages in social media sub-corpus, we can calculate measures of linguis-\ntic diversity based on the 10-fold concentration ratio (𝐶𝑅10) measure. The initial\nmeasure of the national 𝐶𝑅10 measure for 2006 was 0.76, 0.81 in 2013, and 0.79 in\n2018. These measures from the census suggest that New Zealand is typically linguis-\ntically homogeneous. The 𝐶𝑅10 measures from the social media sub-corpus for 2018\nwas 0.79 (idNet) and 0.72 (pacificLID). We can see from this national measure, idNet\nwas more consistent with the 2018 Census. Once again, these results suggest that\neven the digital presence of New Zealand is typically linguistically homogeneous.\nThese national-level measures provide little detail on how the linguistic profile\nof New Zealand has changed over time. We are again interested in the temporal\ngranularity of the social media language data and how the frequency counts of\ntweets over time (i.e., the sampling) may have an effect on linguistic diversity. We\ncan analyse the stability of the time series visually. Figure 6 is a multiple line graph\nwith two y-axes. The primary y-axis represents the daily counts of tweets (in grey)\nand the secondary y-axis represents the linguistic diversity (in black). We have only\nincluded tweets where idNet and pacificLID matched. We inverted the secondary\ny-axis to improve interpretability.\nThe most striking result is the missing data between 2017-2018 and the spikes of\nfrequency counts. These are clearly outliers in the data collection. When we discount\nthese outliers, we can observe a stable relationship between the frequency of tweets\nand the 𝐶𝑅10 which suggests the time series is stationary. A stationary time series\nis particularly important if we were to model trends from the social media language\ndata.\n\n\n16\nSidney Wong, Benjamin Adams, and Jonathan Dunn\nTable 4 𝐶𝑅10 measures for 2018 by regional council areas\nRegion Name\nCensus idNet pacificLID\nNorthland\n0.76\n0.56\n0.52\nAuckland\n0.60\n0.79\n0.73\nWaikato\n0.76\n0.81\n0.75\nBay of Plenty\n0.75\n0.80\n0.73\nGisborne\n0.70\n0.88\n0.48\nHawkes Bay\n0.78\n0.95\n0.86\nTaranaki\n0.85\n0.49\n0.44\nManawat¯u-Wanganui\n0.80\n0.71\n0.66\nWellington\n0.72\n0.89\n0.82\nWest Coast\n0.89\n0.66\n0.60\nCanterbury\n0.80\n0.79\n0.72\nOtago\n0.82\n0.90\n0.83\nSouthland\n0.87\n0.89\n0.81\nTasman\n0.86\n0.58\n0.54\nMarlborough\n0.85\n0.88\n0.78\n4.2 Regional Insights\nOf interest to policy makers and researchers is the potential to use alternative data\nsources to provide insights at regional and local geographies. Table 4 provides the\n𝐶𝑅10 measures for the census and social media sub-corpus for 2018 year by regional\ncouncil areas. Once again, we compare the results from idNet and pacificLID.\nFirstly, the 𝐶𝑅10 measures from the census differ between regional council ar-\neas. Auckland is the most linguistically diverse, while the West Coast is the least\nlinguistically diverse. Regions in Te Ika a M¯aui (with the exception of Taranaki)\nare more linguistically diverse than regions in Te Waipounamu. As we compare\nthe 𝐶𝑅10 measures from the different data sources we see greater variability. Sur-\nprisingly, Taranaki region is the most linguistically diverse according to the social\nmedia sub-corpus which significantly contrasts its corresponding measure from the\ncensus. There is little consistency between the census measures and the social media\nlanguage measures with the exception of Canterbury, Southland, and Marlborough\nregions which have similar levels of linguistic diversity.\nAnother striking observation is that the 𝐶𝑅10 measures derived from the paci-\nficLID exhibited greater levels of linguistic diversity than census or idNet derived\nmeasures (with the exception of Auckland). The fact that we can only observe these\ndifferences at the regional level suggest a downstream effect of the 76,007 mis-\nmatches from the two language identification models. A regional breakdown of the\nnumber of tweets and proportion of tweets is in Table 5 in the Appendix.\nWe carried out a simple non-parametric test between the 𝐶𝑅10 observed in Table 4\nand demographic information derived from census and X (Twitter) as presented in\nTable 5 and Table 6 of the Appendix. We did not observe a relationship between the\ncensus derived𝐶𝑅10 measures and X (Twitter) derived𝐶𝑅10 measures at the regional\nlevel. The correlation coefficient (Spearman’s Rho) between the census and idNet\n\n\nDetecting Linguistic Diversity on Social Media\n17\nFig. 7 Monthly 𝐶𝑅10 Measures for Te Ika a M¯aui by regional council area\n\n\n18\nSidney Wong, Benjamin Adams, and Jonathan Dunn\nFig. 8 Monthly 𝐶𝑅10 Measures for Te Waipounamu by regional council area\nwas -0.27 and pacificLID was -0.08. We observed a moderate negative relationship\nbetween the census derived 𝐶𝑅10 measure with population density (-0.73**) and a\nweak positive relationship with median age (0.56*).\nWe did observe a statistically significant strong positive correlation coefficient\nbetween the 𝐶𝑅10 measures derived from idNet and pacificLID which was 0.80***.\nThis suggests a high level of consistency between the language identification mod-\nels. There was no relationship between X (Twitter) derived 𝐶𝑅10 measures and the\ndemographic information in Table 6. However, we observed a weak negative rela-\ntionship between census derived 𝐶𝑅10 with the proportion of tweets per region in\nrelation to corpus size (-0.51*).\nThe results from the Spearman’s Rho suggest there is a weak association between\ndemographic measures derived from census and social media sub-corpus at regional\ngeographies. It is possible the small sample of regional geographies is not sufficient\nto identify a consistent relationship between the two sources of data.\nFigure 7 and Figure 8 provide a monthly breakdown of the 𝐶𝑅10 by regional\ncouncil area over time on the primary y-axis (solid in black). The regions are grouped\nby islands and urban-rural in order to standardise the y-axis limit. We inverted the\n\n\nDetecting Linguistic Diversity on Social Media\n19\ny-axis to improve interpretability. We have only included the 𝐶𝑅10 measures derived\nfrom the pacificLID. The monthly mean frequency count of tweets are shown on the\nsecondary y-axis (dotted in black). Furthermore, We included 2018 Census 𝐶𝑅10\nmeasures as our baseline to see how linguistic diversity on social media compares\nwith the ground truth measures of linguistic diversity for each regional council area\n(dotted in grey).\nWe can see from Figure 7 and Figure 8 that a higher monthly mean frequency\ncount corresponds to a more stable𝐶𝑅10 measure. This is shown in the urban regional\ncouncils such as Auckland, Waikato, and Wellington regions in Te Ika a M¯aui as\nshown in Figure 7 and Canterbury and Otago regions in Te Waipounamu as shown\nin Figure 7. Furthermore, linguistic diversity from the social media sub-corpus is\nconsistently lower for all urban regions than the census, while the opposite is true\nfor rural regions (with the exception of Bay of Plenty, Gisborne, and Hawke’s Bay\nregion.\n4.3 Case Study: Wellington\nIn contrast to the other regions with significant urban areas within New Zealand\nwhere linguistic diversity remained stable over times, we observed a significant\nincrease of linguistic diversity in the Wellington region with a peak mid-2020.\nWhile other regions also experienced significant fluctuations over time, we could\nattribute this sampling method where data collection points from rural areas were\nunderrepresented in the social media sub-corpus.\nWellington is the capital region of New Zealand. The Wellington urban area\nconsists of Wellington City, Lower Hutt City, Upper Hutt City, and P¯orirua. The hin-\nterland of the capital region includes the K¯apiti Coast (i.e., ¯Otaki) and the Wairarapa\n(i.e., Masterton, Waipawa). We can see a significant level of overlap in the data\ncatchment area due to the short proximity between the cities within the Wellington\nurban area. Therefore, we would expect a higher level of internal consistency within\nthe Wellington urban area.\nAs shown in Figure 6, we observed an increase of linguistic diversity in the period\nbetween April 2020 and September 2020. A further deep dive of the individual data\ncollection points within the Wellington region revealed a consistent increase of\nlinguistic diversity between the data collection points within the Wellington urban\narea not observed in the hinterland. We validated this pattern to see if this was a result\nof data sampling. Figure 9 provides the monthly 𝐶𝑅10 measures and mean frequency\ncount of tweets for each data collection point within the Wellington region. We can\nsee the consistent increase of linguistic diversity for Lower Hutt, P¯orirua, Upper\nHutt, and Wellington. However, we can see a consistent volume of tweets sampled\nfrom each data collection point when we refer to the mean frequency count of tweets.\nWe therefore conclude that this effect is not the result of sampling, but a change in\nlinguistic behaviour within the Wellington urban area.\n\n\n20\nSidney Wong, Benjamin Adams, and Jonathan Dunn\nFig. 9 Monthly 𝐶𝑅10 measures and mean counts for data collection points in the Wellington region\nIn Figure 10, we provide a stacked bar graph of the most common languages\nidentified by idNet and pacificLID broken down by month for the Wellington region.\nWe removed English from the stacked bar graph to improve interpretability. It is\nevident that the significant increase of linguistic diversity was due to actual changes\nin linguistic behaviour. We can observe a first wave increase of tweets in Spanish\nwhich was followed by a second wave increase of tweets in Portuguese. This period\ncoincided with the beginning of the national lockdown and border closures as a\nresult of the Covid-19 pandemic. This strongly suggests the Spanish and Portuguese\ntweets produced by the users were based in New Zealand at the time. This increase\nis unexpected for the Wellington region as the majority of Spanish and Portuguese\nspeakers in Aoteaora are located in the Auckland region [26].\nThe coronavirus disease was known colloquially as ‘corona’ before it was officially\nnamed ‘Covid-19’ by the World Health Organisation. We considered the possibility\nthat the language identification models erroneously classified tweets with this specific\n\n\nDetecting Linguistic Diversity on Social Media\n21\nFig. 10 Proportion of languages for the Wellington region by language identification model\nstring as Spanish or Portuguese. When we removed these two strings, it did not have\nan impact on the 𝐶𝑅10 or proportion of languages for the Wellington region. We\nalso considered the increase of tweets in Spanish and Portuguese was the result of\nprotests and civil unrest across Latin America during this period. Intuitively, this is a\nreasonable assumption as Wellington is the capital region. The increase of tweets in\nSpanish and Portuguese during this period remains unresolved and requires further\nanalysis on the content of the tweets themselves which is beyond the scope of the\ncurrent chapter.\n\n\n22\nSidney Wong, Benjamin Adams, and Jonathan Dunn\n5 Discussion\nHow do census data and social media data compare in terms of their basic\ncharacteristics and what they might tell us about language use variation over space\nand time?\nWe acknowledge there are significant conceptual differences between the census data\nand the social media language data. For example, the purpose of the census data is\nto collect information on articulated languages (such as spoken and signed) based\non self-report, whereas social media data does not include this information. This\nis evident in the differences in the most common languages used between different\nspaces as shown in Table 3 and the differences in measures of linguistic diversity as\nshown in Table 4.\nOne unexpected difference in the social media sub-corpus is that none of the\nSinitic languages appeared in the top ten list from either models. This is consistent\nwith previous research where user’s with written vernacular Chinese as their language\nbackground or user interface language were significantly underrepresented in a\nsurvey of geotagging enabled users [20]. This indicates that the choice of social media\nplatform may lead to differences in how well certain languages are represented.\nAlthough there are differences in the basic characteristics of the two data sources,\nthis does not mean social media language is without its benefits. We can see from\nour results that linguistic behaviour on social media is sensitive to real-world events\nin the case of te reo M¯aori as shown in Figure 5 and an increase in linguistic diversity\nin the Wellington region as discussed in Section 4.3. This otherwise would not be\npossible with census data.\nFrequency counts and linguistic diversity were only two measures we compared\nbetween the two data sources; however, social media language data allows us to\nobserve other forms of linguistic behaviour. We can measure the level of code-\nswitching or translanguaging behaviour as we have access to the linguistic signal. It\nis also possible to see how different language conditions vary over space and time\nby breaking down the signal into different levels of analysis (e.g., at the word or\nsentence level).\nHow might we use social media data in place of official statistics when performing\nanalyses based on language use information?\nWith reference to the functions of language census topic as discussed in Section 2.2,\nsocial media language data can only indirectly support the needs of culturally and\nlinguistically diverse communities. For example, we could potentially use social\nmedia language data to formulate, target and monitor policies and programmes\nto revitalise te reo M¯aori or understand the diversity and diversification of New\nZealand over time; however, the insights taken from social media may not be a\nbalanced sample of New Zealand’s population.\n\n\nDetecting Linguistic Diversity on Social Media\n23\nThis is because the sample frame and purpose between the census and the social\nmedia data are not equivalent. The census provides better coverage of the entire\npopulation and spatial granularity, however, it lacks in temporal granularity. This is\nan advantage of social media data as demonstrated in Figure 6 and Figure 7 where\nwe can observe changes in linguistic diversity at a regional geographies. However,\nwe may need to up sample rural regions to ensure our sample is representative of the\npopulation.\nAnother advantage to the social media data is the direct access to linguistic\nbehaviour and how people are using language in New Zealand. Some components of\nlinguistic behaviour we can observe include linguistic content, style, sentiment, and\nstructure. These aspects of linguistic behaviour cannot be observed from a national\ncensus or survey. It will be useful to revisit the Wellington case study as discussed\nin Section 4.3 with additional methods from natural language processing such as\ntopic or sentiment analysis to determine why there was an increase in Spanish and\nPortuguese during that period.\nIn a similar vein to administrative data where participant consent is not explicitly\ngiven, there are also ethical concerns with social media data [33]. We need to\nconsider how the use of social media language data for official statistical purposes\nuphold MDS and the potential risks this may impose on M¯aori communities across\nNew Zealand [31]. We can suggest using alternative data sources alongside official\nstatistics to enrich our understanding of the changing linguistic profile and linguistic\nbehaviour of New Zealand.\n6 Conclusion\nThe results from the current study suggest that we can use online social media\nlanguage data to observe spatial and temporal changes in linguistic diversity for\nlow-level regional and local geographies. We should be cautious in how we interpret\ntrends and how they can be applied to policy and research as there are conceptual\ndifferences between ground truth official statistics and alternative data sources like\nsocial media. This does limit the conclusions we can draw from our current analysis\nas further data validation is required. Despite these limitations, the current chapter\nprovides promising results for alternative data sources to be used alongside census\ninformation. Census provides a snapshot of a location at a specific time point, while\nsocial media data provides more contemporaneous information about a place. The\ninformation available to policy makers and researchers from social media, provides a\nrich source of language data us to observe real-time changes in linguistic behaviour.\n\n\n24\nSidney Wong, Benjamin Adams, and Jonathan Dunn\nReferences\n[1] Bycroft C, Reid G, McNally J, Gleisner F (2016) Identifying M¯aori populations\nusing administrative data: A comparison with the census. Tech. rep., Statistics\nNew Zealand, URL https://www.stats.govt.nz/\n[2] Dunn J (2019) Global Syntactic Variation in Seven Languages: Toward a\nComputational Dialectology. Frontiers in Artificial Intelligence 2:15, DOI 10.\n3389/frai.2019.00015, URL https://www.frontiersin.org/article/\n10.3389/frai.2019.00015\n[3] Dunn\nJ\n(2020)\nMapping\nlanguages:\nthe\nCorpus\nof\nGlobal\nLan-\nguage\nUse.\nLanguage\nResources\nand\nEvaluation\n54(4):999–1018,\nDOI\n10.1007/s10579-020-09489-2,\nURL\nhttps://doi.org/10.1007/\ns10579-020-09489-2\n[4] Dunn\nJ,\nNijhof\nW\n(2022)\nLanguage\nIdentification\nfor\nAustrone-\nsian\nLanguages.\nIn:\n13th\nInternational\nConference\non\nLanguage\nResources\nand\nEvaluation,\nURL\nhttps://jdunn.name/2022/04/29/\nlanguage-identification-for-austronesian-languages/\n[5] Dunn J, Coupe T, Adams B (2020) Measuring Linguistic Diversity During\nCOVID-19. In: Proceedings of The Fourth Workshop on the Fourth Workshop\non Natural Language Processing and Computational Social Science, DOI\n10.18653/v1/P17, URL https://arxiv.org/abs/2104.01290\n[6] Eisenstein J, O’Connor B, Smith NA, Xing EP (2014) Diffusion of lexical\nchange in social media. PLOS ONE 9(11):e113114, DOI 10.1371/journal.\npone.0113114, URL https://journals.plos.org/plosone/article?\nid=10.1371/journal.pone.0113114, publisher: Public Library of Science\n[7] GeoNames (2018) GeoNames. URL https://www.geonames.org/\n[8] Greaves LM, Oldfield LD, Von Randow M, Sibley CG, Milne BJ (2020)\nHow low can we go? Declining survey response rates to new zealand elec-\ntoral roll mail surveys over three decades. Political Science 72(3):228–244,\nDOI 10.1080/00323187.2021.1898995, URL https://doi.org/10.1080/\n00323187.2021.1898995\n[9] Greaves LM, Lindsay Latimer C, Muriwai E, Moore C, Li E, Sporle A, Clark\nTC, Milne BJ (2023) M¯aori and the integrated data infrastructure: an assess-\nment of the data system and suggestions to realise m¯aori data aspirations [Te\nM¯aori me te Integrated Data Infrastructure: he aromatawai i te p¯unaha ra-\nraunga me ng¯a marohitanga e poipoia ai ng¯a wawata raraunga M¯aori]. Journal\nof the Royal Society of New Zealand 0(0):1–17, DOI 10.1080/03036758.2022.\n2154368, URL https://doi.org/10.1080/03036758.2022.2154368\n[10] Gromm´e F (2018) Is Facebook the future of the national census? The Conver-\nsation URL http://theconversation.com/\n[11] Henderson A (2003) Untapped talents: The employment and settlement experi-\nences of skilled Chinese in New Zealand. Unfolding history, evolving identity:\nthe Chinese in New Zealand pp 141–164\n[12] Hirschman A (1945) National Power and the Structure of Foreign Trade. Uni-\nversity of California Press\n\n\nDetecting Linguistic Diversity on Social Media\n25\n[13] Kachru BB (1982) The Other tongue: English across cultures. University of\nIllinois Press, Urbana-Champaign\n[14] Kemp S (2023) Digital 2023: New zealand. URL https://datareportal.\ncom/\n[15] Mart´ı P, Serrano-Estrada L, Nolasco-Cirugeda A (2019) Social media\ndata: Challenges, opportunities and limitations in urban studies. Com-\nputers,\nEnvironment\nand\nUrban\nSystems\n74:161–174,\nDOI\n10.1016/\nj.compenvurbsys.2018.11.001, URL https://www.sciencedirect.com/\nscience/article/pii/S0198971518302333\n[16] Milne BJ, Atkinson J, Blakely T, Day H, Douwes J, Gibb S, Nicolson M, Shack-\nleton N, Sporle A, Teng A (2019) Data Resource Profile: The New Zealand\nIntegrated Data Infrastructure (IDI). International Journal of Epidemiology\n48(3):677–677e, DOI 10.1093/ije/dyz014\n[17] Ministry\nof\nEducation\n(2023)\nStatistics.\nURL\nhttps://www.\neducationcounts.govt.nz\n[18] Mislove A, Lehmann S, Ahn YY, Onnela JP, Rosenquist J (2011) Understanding\nthe Demographics of Twitter Users. Proceedings of the International AAAI\nConference on Web and Social Media 5(1):554–557, URL https://ojs.\naaai.org/index.php/ICWSM/article/view/14168, number: 1\n[19] O’Byrne E, Bycroft C, Gibb S (2014) An initial investigation into the\npotential for administrative data to provide census long-form information:\nCensus Transformation. Tech. rep., Statistics New Zealand, URL https:\n//www.stats.govt.nz/\n[20] Sloan L, Morgan J (2015) Who tweets with their location? understanding\nthe relationship between demographic characteristics and the use of geoser-\nvices and geotagging on twitter. PLoS ONE 10(11):e0142209, DOI 10.\n1371/journal.pone.0142209, URL https://www.ncbi.nlm.nih.gov/pmc/\narticles/PMC4636345/\n[21] Sloan L, Morgan J, Housley W, Williams M, Edwards A, Burnap P, Rana\nO (2013) Knowing the Tweeters: Deriving Sociologically Relevant Demo-\ngraphics from Twitter. Sociological Research Online 18(3):74–84, DOI\n10.5153/sro.3001, URL https://doi.org/10.5153/sro.3001, publisher:\nSAGE Publications Ltd\n[22] Statistics New Zealand (2001) Introduction to the Census. Statistics New\nZealand, Wellington\n[23] Stats NZ (2018) Differences between Te Kupenga 2013 and 2018 surveys. Tech.\nrep., Stats NZ, URL https://www.stats.govt.nz/\n[24] Stats NZ (2019) 2018 Census collection response rates unacceptably low. URL\nhttps://www.stats.govt.nz/\n[25] Stats NZ (2020) Age and sex by ethnic group (grouped total responses), for\ncensus usually resident population counts, 2006, 2013, and 2018 Censuses (RC,\nTA, SA2, DHB). URL https://nzdotstat.stats.govt.nz/\n[26] Stats NZ (2020) Languages spoken (total responses) and birthplace (broad\ngeographic areas) by age group and sex, for the census usually resident\n\n\n26\nSidney Wong, Benjamin Adams, and Jonathan Dunn\npopulation count, 2006, 2013, and 2018 Censuses (RC, TA, DHB). URL\nhttps://nzdotstat.stats.govt.nz/\n[27] Stats NZ (2021) Languages spoken (information about this variable and its\nquality). URL https://datainfoplus.stats.govt.nz/\n[28] Stats NZ (2021) Regional Council 2018 Clipped (generalised). URL https:\n//datafinder.stats.govt.nz/\n[29] Stats NZ (2023) 2001 Census Language Spoken. URL https://statsnz.\ncontentdm.oclc.org/\n[30] Stats NZ (2023) General social survey (GSS). URL https://datainfoplus.\nstats.govt.nz/\n[31] Te Mana Raraunga: M¯aori Data Sovereignty Network (2018) Principles of\nM¯aori data sovereignty. URL https://www.temanararaunga.maori.nz/\n[32] Williams D (2022) Stats NZ braces for $250m census. Newsroom URL https:\n//www.newsroom.co.nz/\n[33] Williams ML, Burnap P, Sloan L (2017) Towards an Ethical Framework\nfor Publishing Twitter Data in Social Research: Taking into Account Users’\nViews, Online Context and Algorithmic Estimation. Sociology 51(6):1149–\n1168, DOI 10.1177/0038038517708140, URL https://doi.org/10.1177/\n0038038517708140\n\n\nDetecting Linguistic Diversity on Social Media\n27\nAppendix\nTable 5 Data collection points and regional council areas\nRegion\nData Collection Points\nNo. Tweets % of Corpus\nNorthland\nDargaville, Kawakawa, Kerikeri, Moerewa, Ngun-\nguru, Paihia, Taipa, Waimate North, Whang¯arei\n372,366\n3.7%\nAuckland\nAuckland, North Shore, Parakai, Waitakere, Wark-\nworth, Wellsford\n1,850,642\n18.5%\nWaikato\nCoromandel, Hamilton, Muriwai Beach, Ng¯atea,\nOtorohanga,\nPaeroa,\nPukekohe\nEast,\nRaglan,\nTairua, Taup¯o, Te Kauwhata, Thames, Tokoroa,\nT¯urangi, Waihi, Waiuku, Whangamata, Whitianga\n2,133,361\n21.3%\nBay of Plenty\nEdgecumbe,\nKatikati,\nKawerau,\nMurupara,\n¯Op¯otiki,\nRotorua,\nTauranga,\nWaihi\nBeach,\nWhakat¯ane\n383,597\n3.8%\nGisborne\nGisborne\n49,535\n0.5%\nHawkes Bay\nHastings, Napier, Wairoa\n218,106\n2.2%\nTaranaki\nEltham, H¯awera, New Plymouth, ¯Opunake, Patea,\nWaitara\n262,045\n2.6%\nManawat¯u-Wanganui Bulls, Foxton, Levin, Manakau, Palmerston North,\nWaiouru, Wanganui\n658,375\n6.6%\nWellington\nLower Hutt, Masterton, ¯Otaki, Porirua, Upper Hutt,\nWaipawa, Wellington\n1,244,145\n12.4%\nWest Coast\nGreymouth, Hokitika, Westport\n136,344\n1.4%\nCanterbury\nAmberley, Burnham, Christchurch, Darfield, Lee-\nston, Lincoln, Methven, Oxford, Pleasant Point,\nRolleston, Timaru, Woodend\n1,379,036\n13.8%\nOtago\nDunedin, ¯Oamaru, Queenstown, W¯anaka\n446,041\n4.5%\nSouthland\nBalclutha, Bluff, Gore, Invercargill, Milton, River-\nton, Te Anau, Winton\n237,929\n2.4%\nTasman\nBrightwater, M¯apua, Motueka, T¯akaka, Wakefield\n405,008\n4.0%\nMarlborough\nBlenheim, Picton\n235,719\n2.4%\n\n\n28\nSidney Wong, Benjamin Adams, and Jonathan Dunn\nTable 6 Demographic summary of regional council areas\nRegion\nPop. Density Median Age\nNorthland\n14.3\n42.6\nAuckland\n318.1\n34.7\nWaikato\n19.2\n37.4\nBay of Plenty\n25.6\n40.2\nGisborne\n5.7\n37.0\nHawkes Bay\n11.8\n40.6\nTaranaki\n16.2\n40.0\nManawat¯u-Wanganui\n10.7\n39.4\nWellington\n63.0\n37.2\nWest Coast\n5.4\n46.0\nCanterbury\n4.5\n45.5\nOtago\n1.4\n45.7\nSouthland\n13.5\n38.7\nTasman\n7.2\n38.2\nMarlborough\n3.1\n39.8\n\n\n",
  "metadata": {
    "source_file": "dataset/pdfs/arxiv_2502.21224v1.pdf",
    "total_pages": 28,
    "title": "Detecting Linguistic Diversity on Social Media",
    "authors": [
      "Sidney Wong",
      "Benjamin Adams",
      "Jonathan Dunn"
    ],
    "abstract": "This chapter explores the efficacy of using social media data to examine\nchanging linguistic behaviour of a place. We focus our investigation on\nAotearoa New Zealand where official statistics from the census is the only\nsource of language use data. We use published census data as the ground truth\nand the social media sub-corpus from the Corpus of Global Language Use as our\nalternative data source. We use place as the common denominator between the two\ndata sources. We identify the language conditions of each tweet in the social\nmedia data set and validated our results with two language identification\nmodels. We then compare levels of linguistic diversity at national, regional,\nand local geographies. The results suggest that social media language data has\nthe possibility to provide a rich source of spatial and temporal insights on\nthe linguistic profile of a place. We show that social media is sensitive to\ndemographic and sociopolitical changes within a language and at low-level\nregional and local geographies.",
    "published_date": "2025-02-28",
    "source": "arxiv"
  }
}