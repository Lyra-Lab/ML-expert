{
  "id": "arxiv_2502.21034v1",
  "text": "Synthesizing Tabular Data Using\nSelectivity Enhanced Generative\nAdversarial Networks\n[25pt Research Project]\nby\nYouran Zhou\nSupervised by\nDr. Jianzhong Qi\nTHE UNIVERSITY OF MELBOURNE\nFaculty of Science\nSchool of Mathematics and Statistics\nThis thesis submitted to the University of Melbourne for partial fulfillment of the\ndegree of\nMaster of Data Science\nMarch 2025\narXiv:2502.21034v1  [cs.LG]  28 Feb 2025\n\n\nTHE UNIVERSITY OF MELBOURNE\nAbstract\nWhile the fast pace of economic development, E-commerce platforms face significant\nchallenges in handling excessive customer transactions during major online shopping\nevents like Black Friday. To be prepared for large volumes of transactions, those plat-\nforms need to utilize synthesized data to run stress tests and derive the computational\nresources needed to cope with such transactions. The synthesized data for such patterns\nare usually in the form of tables.\nGenerating Adversarial Networks (GAN) are used in most recent tabular data synthe-\nsizing studies and have shown impressive performance in generating tabular data while\nfulfilling privacy constraints and downstream machine learning model training needs.\nHowever, existing studies do not apply to the E-commerce stress testing scenarios di-\nrectly because the computational resources required to process the data generated by\nGAN have not been considered. A core concept in computational resource estimation\nfor database transaction processing is query selectivity. To the best of our knowledge,\nno study has been conducted on supporting selectivity constraints in the tabular data\nsynthesizing field.\nThis thesis considers query selectivity constraints in tabular data generation and offers\nsolutions by designing a novel method for tabular generation GAN models. We add\na pre-trained deep neural network component for an additional supervision signal to\nmodel the query selectivity constraint that maintains the selectivity consistency between\nground truth data and synthetic data. We implement our method on top of two GAN\nmodels and evaluate them with extensive experiments against the three state-of-the-art\nGAN models and a VAE model on five real-world datasets. The results show that the\nsynthetic data generated by our model resembles the real data, increasing the selectivity\nestimation accuracy by up to 20% and machine learning utilities by up to 6%.\nKeywords: GAN, data synthesis, tabular data, selectivity estimation\n\n\nDeclaration of Authorship\nI certify that this report does not incorporate without acknowledgement any material\npreviously submitted for a degree or diploma in any university; and that to the best\nof my knowledge and belief it does not contain any material previously published or\nwritten by another person where due reference is not made in the text. The report is\n11460 words in length (excluding text in images, tables, bibliographies and appendices).\nSigned: Youran Zhou\nDate: 05/06/2022\nii\n\n\nAcknowledgements\nI would like to thank our supervisors, Dr Jianzhong Qi as well as Dr Wei Wang from\nthe Hong Kong University of Science and Technology, for your guidance and constant\npatience and encouragement throughout the year. As I look back, this precious experi-\nence with you has been the highlight of my Master’s program. When I struggled, you\nalways pointed me in the right direction and supported me during our weekly meetings.\nThank you to Dr Qi for leading me to this research topic and showing me a different\nworld I’ve never seen before. Preparing papers for me, scheduling our meetings, and\nhelping me understand our project. Thank you for guiding my codes and experiments.\nThank you for bearing my writing skills, providing detailed feedback and helping me\nwith my thesis. It is my pleasure to have a great supervisor like you for my research\nproject. I did grow and learned a lot from the past year. I am truly grateful for your\nkind words and encouragement.\nThank you to all kind staff from Spartan and IT support from the University of Mel-\nbourne for fixing my slurms and teaching me how to use the Spartan properly. Without\nyou, I could not finish all of my experiments.\nLastly, I would like to thank my parents, my twin sister and our family mascot Jinzhi\nfor sending me videos and voice calls to cheer me up, supporting and believing in me\nunconditionally.\niii\n\n\nContents\nAbstract\ni\nDeclaration of Authorship\nii\nAcknowledgements\niii\nList of Figures\nvi\nList of Tables\nvii\n1\nIntroduction\n1\n1.1\nProblem . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n3\n1.2\nContributions and Thesis Outline . . . . . . . . . . . . . . . . . . . . . . .\n4\n2\nRelated Work\n6\n2.1\nTabular Data Generative models . . . . . . . . . . . . . . . . . . . . . . .\n6\n2.1.1\nBayesian network . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n7\n2.1.2\nAutoencoder\n. . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n9\n2.1.3\nGenerative Adversarial Network\n. . . . . . . . . . . . . . . . . . .\n11\n2.1.4\nGAN Variants for Tabular Data Generation . . . . . . . . . . . . .\n15\n2.2\nSelectivity Estimation . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n20\n2.2.1\nRegression-based Models . . . . . . . . . . . . . . . . . . . . . . . .\n20\n3\nMethodology\n22\n3.1\nProposed Method . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n22\n3.1.1\nData Transforming . . . . . . . . . . . . . . . . . . . . . . . . . . .\n22\n3.1.2\nPre-trained Selectivity Model . . . . . . . . . . . . . . . . . . . . .\n25\n3.1.3\nBase Model Training . . . . . . . . . . . . . . . . . . . . . . . . . .\n27\n3.1.4\nBase Model . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n29\n4\nExperiments\n31\n4.1\nDataset\n. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n31\n4.2\nBaseline Models . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n32\n4.3\nEvaluation Metrics . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n33\n4.3.1\nMode Collapse\n. . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n33\n4.3.2\nVisualization . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n33\niv\n\n\nContents\nv\n4.3.3\nSelectivity Estimation . . . . . . . . . . . . . . . . . . . . . . . . .\n33\n4.3.4\nMachine Learning Utility\n. . . . . . . . . . . . . . . . . . . . . . .\n34\n4.4\nParameter Setting\n. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n34\n4.5\nResults analysis . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n35\n4.5.1\nMode Collapse\n. . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n35\n4.5.2\nVisualization . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n35\n4.5.3\nSelectivity Estimation . . . . . . . . . . . . . . . . . . . . . . . . .\n38\n4.5.4\nMachine Learning Utility\n. . . . . . . . . . . . . . . . . . . . . . .\n38\n4.6\nAblation Study . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n40\n5\nConclusions and Future Work\n42\n5.1\nConclusions . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n42\n5.2\nFuture Direction\n. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n44\nA Notations\n46\nB Figures\n47\nBibliography\n52\n\n\nList of Figures\n1.1\nExample of using GAN to solve the tabular data shortage problem . . . .\n3\n2.1\nBayesian network over five attributes from PrivBayes [1]\n. . . . . . . . .\n7\n2.2\nAutoencoder scheme from [2] . . . . . . . . . . . . . . . . . . . . . . . . .\n9\n2.3\nTraining evolution of DCGAN [3] . . . . . . . . . . . . . . . . . . . . . . . .\n11\n2.4\nGAN Training Process . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n13\n2.5\nArchitecture of MedGAN . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n16\n2.6\nArchitecture of table-GAN . . . . . . . . . . . . . . . . . . . . . . . . . . .\n17\n2.7\nArchitecture of CTGAN\n. . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n19\n3.1\nMethodology Overview . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n23\n3.2\nExample of multi-modal distribution . . . . . . . . . . . . . . . . . . . . .\n24\n3.3\nExample of mode-specific normalization . . . . . . . . . . . . . . . . . . .\n25\n3.4\nArchitecture of Pre-trained Selectivity Model . . . . . . . . . . . . . . . .\n26\n3.5\nBase Model Training Process\n. . . . . . . . . . . . . . . . . . . . . . . . .\n28\n4.1\nage in Adult . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n36\n4.2\naspect in Covertype\n. . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n36\n4.3\nglobal subjectivity in News\n. . . . . . . . . . . . . . . . . . . . . . . . . .\n36\n4.4\nCorrelation Heap Map for Adult\n. . . . . . . . . . . . . . . . . . . . . . .\n37\n4.5\nCorrelation Heap Map for News . . . . . . . . . . . . . . . . . . . . . . . .\n38\n4.6\nACC and F1 Score for Classification Task over five datasets . . . . . . . .\n39\nB.1\neducation-num in Adult . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n47\nB.2\nfnlwgt in Adult . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n47\nB.3\ncapital-loss in Adult . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n47\nB.4\nelevation in Covertype . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n48\nB.5\nslope in Covertype . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n48\nB.6\nhillshade noon in Covertype . . . . . . . . . . . . . . . . . . . . . . . . . .\n48\nB.7\nAmount in Credit . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n48\nB.8\nMktDistance in Ticket . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n48\nB.9\nPassengers in Ticket . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n49\nB.10 title subjectivity in News\n. . . . . . . . . . . . . . . . . . . . . . . . . . .\n49\nB.11 shares in News\n. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n49\nB.12 average token length in News . . . . . . . . . . . . . . . . . . . . . . . . .\n49\nB.13 LDA00 in News . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n49\nB.14 Correlation Heap Map for Covertype . . . . . . . . . . . . . . . . . . . . .\n50\nB.15 Correlation Heap Map for Ticket . . . . . . . . . . . . . . . . . . . . . . .\n50\nB.16 Correlation Heap Map for Credit . . . . . . . . . . . . . . . . . . . . . . .\n51\nvi\n\n\nList of Tables\n2.1\nSummary for commonly used Tabular data generation GAN models\n. . .\n15\n4.1\nSummary of datasets . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n32\n4.2\nModel Compatible table . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n32\n4.3\nRate of Repeated Data (%) . . . . . . . . . . . . . . . . . . . . . . . . . .\n35\n4.4\nDifference in pair-wise correlation . . . . . . . . . . . . . . . . . . . . . . .\n37\n4.5\nSelectivity Estimation MSE in 102\n. . . . . . . . . . . . . . . . . . . . . .\n38\n4.6\nClassification Accuracy (F1) . . . . . . . . . . . . . . . . . . . . . . . . . .\n40\n4.7\nRegression Accuracy (MSE)\n. . . . . . . . . . . . . . . . . . . . . . . . .\n40\n4.8\nAblation Selectivity Estimation MSE in 102 . . . . . . . . . . . . . . . . .\n41\n4.9\nAblation Study: Regression Accuracy (MSE)\n. . . . . . . . . . . . . . . .\n41\n4.10 Ablation Study: Classification Accuracy (F1) . . . . . . . . . . . . . . . .\n41\nA.1 Notations . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n46\nvii\n\n\nChapter 1\nIntroduction\nBack in 2017, The Economist published a story titled, ‘The world’s most valuable re-\nsource is no longer oil, but data.’\nCompanies from a variety of industry fields gain\nvaluable insights from using internal and external data sources.\nThe desire of data\nraises the issue of data shortage. For instance, in the medical field, new technologies\nare utilizing patient health histories to create predictive models that can be used to\nimprove diagnosis and understanding of illness. Rare diseases are challenging to study\nsince we can only find a limited number of real-life datasets. In the E-commerce field,\nthe online shopping platforms face the challenge from gigantic amount of transaction\ndata during the major shopping events such as Black Friday, where a lack of computa-\ntion resources may result in a blockage of user transactions, thus negatively impacting\nthe revenue. They need a sufficient amount of data to do the stress testing to avoid\nsuch loss. As another example, scientists who work in the data science area are often\nfaced with the problem of insufficient data when they are trying to train new and robust\nmachine models.\nOn the other hand, big data often compromises privacy and results in unjustified anal-\nyses because of its immense knowledge. Some European governments implemented the\nEuropean General Data Protection Regulation in order to prevent misuse of data and\nviolations of privacy rights and to implement strict rules with respect to data protection\nin order to prevent privacy leaks. This poses a new challenge for the industries that are\ndriven by big data to find solutions that will allow them to make big discoveries while\nrespecting the privacy rights of individuals as well as mandatory government regulations.\nOne emerging solution is to rely on synthetic data rather than real data, which is statis-\ntically very close to real data and can satisfy privacy requirements due to its synthetic\nnature. However, there are some challenges for tabular data synthesizing tasks.\n1\n\n\nChapter 1 Introduction\n2\nThe major issues can be summarized as follows:\n1. Data Shortage Issue: Generative models aim to produce sufficient outputs with\na wide variety. Due to the limited number of input data, it is hard to consider\nboth quantity and variety for synthetic data. Some models may suffer from mode\ncollapse problems, which means the model can not generate various data. Thus it\nkeeps generating the same output.\n2. Data Privacy Issue: Tabular data usually contains users’ sensitive information,\nwhich could be used to identify individuals and harm their privacy. The more\nsimilarity between synthetic data and real data indicates the better quality of\nsynthetic data. However, synthetic data with high similarity could reveal users’\ninformation. Therefore, the tabular data synthesizer should try to protect users’\ninformation and maintain the high generating quality.\n3. Data Quality Issue (Machine Learning Utility): Synthetic data are used for down-\nstream machine learning model training needs in specific applications. That re-\nquires high-quality synthetic data.\nThese high-quality data should satisfy the\nmachine learning utility to complete the downstream tasks.\nThat means if we\ntrain the machine learning model using the synthetic data, that should have a\nsimilar performance to the machine learning model trained by real data.\n4. Data Quality Issue (Database Constraint): Databases are commonly used to store\nand manage tabular data. Some database constraints define specific properties that\ndata in a database must comply with. The origin data define those properties. The\nsynthetic data with high quality should fulfil these constraints as well.\nGenerative Adversarial Network (GAN) [4] is one of the most promising approaches to\nsynthesize data. Initially, GAN was designed in the past to generate images. Now, it\nhas been migrated to produce tabular datasets as well [5] [6] [7] [8]. Normally, a GAN\nmodel is trained on a real dataset. Once it is constructed, it can be used to efficiently\ngenerate tabular data.\nFigure 1.1 shows the example of using GAN model to solves the issue 1 successfully.\nMost of the recent works pay considerable attention to the issue 2 and issue 3. TGAN [5]\nuses a reversible data transformer and Gaussian Mixture Model (GMM) to pre-process\nthe categorical data, and numerical data further improves the ability to generate categor-\nical data and the distribution of numerical data. The state-of-the-art CTGAN [6] augments\nthe training procedure with mode-specific normalization and treats categorical variables\nas condition vectors and addresses data imbalance by employing a conditional generator.\nTableGAN-MCA [9] proposes a novel Membership Collision Attack against GANs, which\n\n\nChapter 1 Introduction\n3\nFigure 1.1: Example of using GAN to solve the tabular data shortage problem\nallows an adversary given only synthetic entries randomly sampled from a black-box\ngenerator to recover partial GAN training data to immune Membership Inference at-\ntack. ITS-GAN [10] studies an incomplete table synthesis problem (using a very small\nproportion of real data to train GAN models) for tabular data augmentation. It used\npre-trained functional dependencies models to enhance the GAN model in order to en-\nsure the generated data satisfied the machine learning utility.\nAlthough current works yielding success on the first three issues, issue 4 has not been\nwell developed and solved.\n1.1\nProblem\nRecall the E-commerce problem: the online platforms need to conduct the stress test\nand use sufficient data to estimate the computational resources required during major\nshopping events.\nRequired computational resources can be formulated as the query\nexecution cost. The query cost occurs when we take any actions on a table from our\ndatabase.\nThe query execution cost is computed by combining the cost of each of\nthe operators appearing in the query plan. The standard operators include selection,\nprojection, joint and so on. However, calculating the actual cost of query plans is usually\n\n\nChapter 1 Introduction\n4\nimpossible without actually executing the plan. The only method we could calculate the\nexecution cost is to estimate the cost of each operator separately and combine them.\nEquation 1.1 shows the idea of how to estimate the query execution cost.\nˆCQuery execution = ˆCSelection + ˆCProjection + ˆCJoint + · · ·\n(1.1)\nwhere ˆC indicates the estimated cost.\nDespite the current GAN models having made great successes, the existing methods\ncould not ensure their synthetic data fit the requirement for E-commerce platforms as\nthere is a research gap between the Issue 4 and current methods. Motivated by this\nproblem, we start from the selection cost and take a further step to selectivity.\nTo\nmaximize the accuracy of selectivity cost, we should let the generated data satisfy the\nselectivity constraints from the original data.\nThe problem can be stated as:\n‘How to develop a tabular data generation GAN to model selectivity constraints in\ntabular data synthesizing’\nMotivated by this question, this thesis conducts a series of studies on query selectivity\nconstraint modeling for GAN-based tabular data generation.\n1.2\nContributions and Thesis Outline\nIn this thesis, we design a GAN based tabular data synthesizer that fulfills query selec-\ntivity constraints. We propose a novel method to combine with state-of-the-art GAN\nmodels by introducing a pre-trained selectivity estimation deep neural network to pro-\nvide additional control of the selectivity of generated data. By modifying the loss term\nof the GAN model to ensure the generated data could fit the selectivity constraint. We\ncombined the method with two GAN models and tested on five widely used machine\nlearning datasets against three GAN-based tabular data generation methods and one\nVAE-based method.\nThe main contributions of our work can be summarized as following:\n• Improves the current data reversible transforming method to ensure the GAN\nmodel is suitable with any mixed-type data.\n• Pre-trains a selectivity estimation model.\nIncorporates the selectivity score in\ntraining the generator, thus the synthesizing data can fulfill the selectivity con-\nstraints.\n\n\nChapter 1 Introduction\n5\n• The proposed augmentation method is flexible that could compatible any GAN\nbased tabular data synthesizer.\nThe rest of the chapters are organized below:\nIn Chapter 2, we will discuss common approaches of tabular data synthesizing methods\nand the selectivity estimation methods.\nIn Chapter 3, we will introduce pre-trained selectivity model, GAN model architecture\nand how to combine them together.\nIn Chapter 4, we will talk about the implementation, parameter setting and present\nsufficient experimental results.\nIn Chapter 5, we will gave a summary of the experiments, proposes the limitation of our\nmethod, and provides the future improvement direction.\n\n\nChapter 2\nRelated Work\nIn this chapter, we will introduce some background information regarding traditional\ngenerative models for tabular data generation, Bayesian networks in statistics, varia-\ntional autoencoders (VAEs) and generative adversarial networks (GANs) in computer\nscience.\nFurthermore, we will discuss the different approaches to selectivity estima-\ntion, which include traditional estimation models and novel regression-based estimation\nmodels.\n2.1\nTabular Data Generative models\nGenerative models are unsupervised machine learning models that attempt to discover\nthe regularities, patterns and distributions from the input origin data, then use the\nlearned knowledge to generate plausible data. The purpose of synthetic data generation\nis to resolve four issues, which are discussed in Chapter 1: data shortage issues, data\nprivacy issues, data quality issues, including Machine Learning and Data Base issues.\nThe models learn from the existing real data and generate their distributions from the\nacquired data, fulfilling requirements from the different industries and addressing the\nfour issues.\nStatistical generative models such as Bayesian networks and Gaussian mixture models\nare suitable for fitting certain probability distributions.\nHowever, in the real world,\nthe datasets are often more complex and come in different formats. As a result, the\nstatistical models are not usually compatible with image or text datasets.\n6\n\n\nChapter 2 Related Work\n7\n2.1.1\nBayesian network\nThe Bayesian network [11] model is widely studied in the field of statistical and machine\nlearning.\nAssume A is the set of attributes on the dataset D. D has a joint probability distri-\nbution over the cross-product of A’s attribute domains. A Bayesian network can be\nused to describe the distribution through the particular conditional independence be-\ntween the attributes of A. To be specific, a Bayesian network is a directed acyclic graph\n(DAG) that represents each attribute in A as a node and conditional independence be-\ntween attributes using directed edges. A simple Bayesian network schematic is shown\nin Figure 2.1. Bayesian networks are simple but powerful graphical models. They can\napproximate the complete-dimensional data distribution by combining low-dimensional\ndata distributions.\nFigure 2.1: Bayesian network over five attributes from PrivBayes [1]\nThe standard Bayesian network generating synthetic data can be summarized as follow-\ning steps:\n1. Train a standard Bayesian network\n2. Compute the differential privacy distributions of the data and then inject the\nLaplace noise to each parameter of the learned Bayesian network\n3. Generate synthetic data from the noisy Bayesian network\nHowever, the inappropriate amount or content of noise would lead the Bayesian network\nto a very poor generation performance. The other limitation of the traditional Bayesian\nnetworks is that they cannot handle continuous data, but they can represent a joint\ndistribution of discrete variables.\n\n\nChapter 2 Related Work\n8\nPrivBayes\nPrivBayes [1] was developed by ZHANG et al. in 2017. A novel Bayesian Network-\nbased model provides a solution to protect differential privacy. The formal definition of\nε-differential privacy is as follows:\nPr[G(D1) = O] ≤eε · Pr[G(D2) = O]\nwhere Pr[ · ] is the probability of an event.\nPrivBayes uses traditional Bayesian network architecture but a differential privacy\nlearning algorithm to reduce the amount of noise that needs to be inserted.\nThey\ncompute a differential private Bayesian network that approximates the full-dimensional\ndistribution using the Laplace mechanism and the exponential mechanism. Before the\nmodel, it discretized all continuous variables into 16 equal-sized bins to make the model\nmore flexible for mixed-type datasets.\nThe PrivBayes can be constructed in to three stages:\n1. Using ε1-differential privacy method to build a k-degree Bayesian network N\nthrough the attributes in dataset D.\n2. Using ε2-differential privacy method to generate d, a set of conditional distributions\nfor D. For example, each pair of conditional distribution Pr[Xi|Πi] got a noisy\ndistribution Pr⋆[Xi|Πi].\n3. Use the Bayesian network N and the d noisy conditional distributions to derive an\nestimated distribution of the tuples in D, then sample tuples from the estimated\ndistribution to generate a synthetic dataset D⋆.\nIn phase 1, the choice of k is non-trivial. It involves a trade-off between the Bayesian\nnetwork’s original quality. A Bayesian network with a larger k keeps more information\nfrom the full-dimensional distribution Pr[A]. For instance, a (d −1) - degree Bayesian\nnetwork can fit the distribution. In contrast, if a 1 - degree Bayesian network is present,\nthere is much information loss when fitting the distribution. To resolve this problem,\nthey use a measure called θ - usefulness to provide a more choose k automatically to\nbalance the accuracy of the Bayesian network. Through the constraint of θ - usefulness,\nPrivBayes uses a greedy algorithm to maximize the mutual information and to optimally\nstructure the tree-based Bayesian network.\n\n\nChapter 2 Related Work\n9\n2.1.2\nAutoencoder\nBack in 1987, Autoencoder [12] was first developed by Ballard. An autoencoder is a type\nof deep neural network used to solve an unsupervised learning task — representation\nlearning. That means the autoencoder could efficiently learn the coding of datasets.\nThus, it can usually be used to remove the redundancy and extract the important\ndata features. More specifically, a deep neural network contains a bottleneck inside the\nnetwork and then forces a compressed knowledge representation from the input data.\nFigure 2.2 shows the sample scheme for autoencoder.\nFigure 2.2: Autoencoder scheme from [2]\nA standard autoencoder contains two components: an encoder E( · ) and a decoder D( · ).\nThe encoder compresses the input and produces the code, the decoder then reconstructs\nthe input only using this code.\nTo be more specific, provide a dataset X, the encoder E( · ) compresses the input data x\nfrom X into a hidden distributed representation z (Compressed data from Figure 2.2).\nThe encoding step can be shown as:\nz = E(x), where x ∼X.\nThen the decoder D( · ) takes the hidden representation z and reconstructs it. Lastly, it\nwill produce ˆx:\nˆx = D(z), where ˆx ≈x.\nThe generated data ˆx is approximate to the original data x because a successful au-\ntoencoder aims to extract all the essential features of x. The x and ˆx should share\nthe same properties. Therefore, the autoencoder network is trained by minimizing the\nreconstruction error:\nL = (x, ˆx) = Ex∼X[∥D(E(x)) −x∥2\n2]\n\n\nChapter 2 Related Work\n10\nTypically, the reconstruction error is the mean squared error, which measures the dif-\nferences between the original input data and the later reconstruction ˆx.\nVariational Autoencoder\nThe Variational Autoencoder (VAE) [13] is a variant of standard autoencoder. The ‘vari-\national’ means that the encodings distribution is regularised during the training process\nto keep the approximate features and generate new data.\nThe architecture of a VAE is the same as a standard autoencoder. It contains an en-\ncoder E[ · ] and a decoder D[ · ]. The VAE is trained using the similar reconstruction\nerror L = (x, ˆx), which aims to minimize the difference between origin data and the\ngenerated data as well.\nAs mentioned before, some regularisation term is introduced to VAE. A small mod-\nification is applied to the encoding-decoding step to achieve the regularisation. In a\ntraditional autoencoder, the input data is a single point x from the original data X, and\nthe output is the hidden representation z. In VAE, the hidden representation is seen as\na Gaussian distribution N[ · ]. Therefore the hidden representation from a VAE encoder\nforms a normal distribution N(µ, σ2).\nµ, σ = E(x), where x ∼X.\nThe decoder takes one sample z from the N(µ, σ2) and reconstructs the data.\nˆx = Ez∼N(µ,σ)[D(z)], where ˆx ≈x.\nAdditionally, VAE made a constraints to force all the aggregated distribution of z over\nall the data X to be N(0, I). Under this constraint, we can input any vector sampled\nfrom N(0, I) into the trained decoder to generate new data.\nThe encoder-decoder pair is multi-input and multi-output deep neural networks and\ntrained by stochastic gradient descent (SGD). The Equation 2.1 shows the reconstruction\nerror is further modified as a evidence lower-bound (ELBO) loss.\nL = [ Ex∼N(µ,σI)[∥D(E(x)) −x∥2\n2] + KL(N(µ, σI)∥N(0, I)) ].\n(2.1)\nThe first term is precisely the same as the traditional autoencoder. The second term\nKL(p||q) is the Kullback–Leibler (KL) divergence. The KL divergence is used to measure\nthe distance between two distributions p and q using the following formula:\nKL(p||q) = −\nZ\nx\np(x) log q(x)\np(x)\n\n\nChapter 2 Related Work\n11\nIn the VAE case, we have the p as the standard normal distribution N(0, I), the q as\nthe distribution of z ∼N(µ, σI). Thus, this term makes a constraint to ensure the z to\nbe the standard normal distribution. The outer expectation is computed by taking the\naverage over minibatch. The training process will end when the model converges. The\nlearned D is an approximated mapping from a multivariate Gaussian distribution to the\ndata distribution.\n2.1.3\nGenerative Adversarial Network\nGenerative Adversarial Networks (GANs) were firstly proposed by Goodfellow [4] in\n2014. GAN is a generative model using deep learning techniques to generate different\ntypes of data to fit the requirements of variant industry needs.\nGenerative modelling is an unsupervised learning task. GAN models convert the problem\nfrom an unsupervised learning task to a supervised learning task masterly using two sub-\nmodels: A generator G and a discriminator D.\nFigure 2.3: Training evolution of DCGAN [3]\nThe generator G is trained to generate new samples, and the discriminator D is required\nto recognize if the generated samples are real or fake. The training process is like an\nadversarial zero-sum competition as the G have to foolish the D and the D tries its\nbest to classify the provided data. During the training, the G and D grow together,\n\n\nChapter 2 Related Work\n12\nthe quality of generated data is higher and higher, as well as the ability to recognize D.\nFigure 2.3 shows the training evolution of a deep convolutional generative adversarial\nnetwork [3] which is commonly used to generate images. It is an example of generating\nsunset images from the first epoch to the 500th epoch. The growth of G and D shows\nthe adversarial process during training.\nVanilla GAN\nAs mentioned in the last section, the GAN model contains two deep neural networks\nthat make the training process quite complete; it has to solve those complications:\n• Handle two different training tasks (Generating and Classification)\n• Identify training convergence\nFigure 2.4 shows the flow chart for Vanilla GAN training. Vanilla GAN is the origin\nGAN training method proposed by Goodfellow [4]. The main training process can be\nbroken down into two alternating steps:\n1. Update Discriminator D.\n2. Update Generator G.\nThe two steps run repeatedly to continuous training the G and D.\nStep 1:\nThe Discriminator D is a classifier which needs to distinguish if the data is generated by\nthe Generator G. To train the classifier more accurately, we should use the data from\nboth data sources. The real data from the original data as the positive samples. The\nfake data generated by G as the negative samples. During the training, the D classifies\nboth real data and fake data and produces a D loss. The discriminator loss will penalize\nthe D for all misclassified samples. The D updates its weights through backpropagation\nfrom the D loss function Equation 2.2:\nLD = −Ex∼X[log(D(x))] + Ez∼N(0,I)[log(1 −D(G(z)))]\n(2.2)\nLD is the cross-entropy loss for binary classification.\nStep 2:\n\n\nChapter 2 Related Work\n13\nFigure 2.4: GAN Training Process\nThe Generator G is used to create fake data incorporating feedback from the Discrim-\ninator. It aims to fool the D and let D can not complete the classification task well.\nThe training process for G is more complicated. The whole training process involves\nthree components: Random Input which makes sure the GAN produce a wide variety\nof data; Generator G which generates the data using the random feed input and the\nD loss, which enhances the generating ability by penalizes the G for correctly classified\nsamples. The Generator G is optimized using the equation:\nLG = Ez∼N(0,I)[log(D(G(z)))]\n(2.3)\nMinimax Loss Function:\nThe MiniMax loss function(Equation 2.4) is commonly uses in standard GAN which is\ncombined from the LG(Equation 2.3) and LD(Equation 2.2). In this function the gener-\nator tries to minimize the following function while the discriminator tries to maximize\nit.\nEx∼X[log(D(x))] + Ez∼N(0,I)[log(1 −D(G(z)))]\n(2.4)\nIn the first term, D(x) is the probability estimation to indicate if the real instance x is\nreal. The Ex is the expected value among all real data instances. In the second term,\nG(z) is the generated data using the input noise z. D(G(z)) is the probability estimation\nto indicate if fake instance G(z) is real. The Ez is the expected value among all fake\n\n\nChapter 2 Related Work\n14\ndata instances. The formula derives from the cross-entropy between the real and fake\ndistributions. However, the Vanilla GAN always suffers from the mode collapse problem.\nMode collapse means the Generator keeps producing the same output data.\nWassersttein GAN\nWassersttein GAN [14] is a improved training method to solve the mode collapse prob-\nlem. WGAN uses a critic network C[ · ]. The output of the critic network C[ · ] is dynamic.\nWhen the input is more realistic, the output value is larger or vice versa.\nTo achieve this, the critic network is trained using:\nLC = −Ex∼X[log(C(x))] + Ez∼N(0,I)[log(1 −C(G(z)))]\n(2.5)\nThat means, the critic network is trying to maximize the output on real data and\nminimized the output of the generated data.\nConversely, the generator is trying to\nmaximize the output of the critic network using the following function:\nLG = −Ez∼N(0,I)[log(1 −C(G(z)))]\nWGAN aims to minimize the Wasserstein distance between the generated and real data\ndistribution. The Wasserstein distance will provide the between probability distributions\non a given metric space. The Wasserstein distance W( · )can be shown as:\nW(x, PG) =\nsup\n∥f∥L≤1\nEx∼X[f(x)] −Eˆx∼PG[f(ˆx]\nwhere ∥f∥L ≤1 indicates f is a 1-Lipschitz function.\nEquation 2.5 can be seen as approaching the Wasserstein distance equation. Therefore,\nthe training process for the Generator can be seen as minimizing the Wasserstein dis-\ntance. Note that parameters in the C are controlled to fit the 1-Lipschitz constraint.\nThe WGAN is also trained by stochastic gradient descent (SGD) with the similar steps\nto Vanilla GAN: In the first step, WGAN updates Critic C, the next step is to update\nGenerator G. The two steps repeatedly run to continuous training the C and D.\nMostly, the training processes are the same as the Vanilla GAN training processes. Be-\nsides, we use Critic C instead of Discriminator G. Additionally, the parameter in C has\nto be modified to satisfy the 1-Lipschitz condition in step 1.\n\n\nChapter 2 Related Work\n15\n2.1.4\nGAN Variants for Tabular Data Generation\nThe initial GAN model was used to synthesize the image [4]. The development of GAN\nhas led to more and more varieties being proposed in different fields. Now, GAN models\nhave migrated from image data to tabular data.\nThis session summarizes the most\ncommonly used GAN-based tabular data generation models.\nModel\nDiscrete\nNumerical\nEnhanced\nMedGAN (2017)\n✓\nHigh-Dimensional\ntablgeGAN (2017)\n✓\nData Semantic\nCTGAN (2019)\n✓\n✓\nImbalanced Data\nOCTGAN (2021)\n✓\n✓\nImbalanced Data\nTable 2.1: Summary for commonly used Tabular data generation GAN models\nMedGAN\nMedGAN [15] was proposed by Choi et al. in 2017 to produce high-dimensional electronic\nhealth record (EHR) data in discrete variables. High-dimensional data suffers from the\ncurse of dimensionality. To overcome this, MedGAN develop an autoencoder to learn the\ndata representation. The original data can be represented as a low-dimensional data\nrepresentation without any information loss by using the autoencoder.\nMedGAN is limited applied to binary responses and continuous features.\nThe binary\nfeatures are represented as 1 or 0. The continuous features should apply a min-max\nnormalization method to normalized to the range [0,1] using the MinMax normalization\nformula:\nci,j −min(Ci)\nmax(Ci) −min(Ci))\n(2.6)\nwhere Ci means the ith continuous column and cij means the jth value in the ith con-\ntinuous column.\nFigure 2.5 shows the Architecture of MedGAN. The discrete x comes from the source\nEHR data, z is the random prior for the generator G; G is a feedforward network with\nshortcut connections (right-hand side figure); An autoencoder (i.e, the encoder Enc and\ndecoder Dec) is learned from x; The same decoder Dec is used after the generator G\nto construct the discrete output. The discriminator D tries to differentiate real input\nx and discrete synthetic output Dec(G(z)).\nThe pre-trained autoencoder is used to\nlearn discrete features, and then it can be applied to decode the continuous output of\nG. The autoencoder uses to mean a squared loss for the loss function to check if only\ncontinuous features exist in the generated data and cross-entropy loss to check if the\n\n\nChapter 2 Related Work\n16\ndiscrete columns are in binary. The loss function for the GAN model is the standard\nMinimax loss function (see Equation 2.6) from Vanilla GAN [4]. The loss function for\nthe autoencoder is the mean squared error if the table contains only continuous columns\nand cross-entropy loss if the columns are all binary. The generator and discriminator\nare trained using the same loss function as a vanilla GAN.\nHowever, the MedGAN does not support tabular data with mixed data types. Only contin-\nuous and binary discrete data is acceptable. The real-world data is usually complicated\nwith the mixed data type, and this is not very suitable in most real-world scenarios.\nFigure 2.5: Architecture of MedGAN\nTable-GAN\nTable-GAN [8] is a variation on the GAN Architecture published by Park et al.\nin\n2017. It applies the idea of DCGAN [3] which is a typically used image generation GAN\nmodel to generate tabular data to protect people‘s privacy. In this paper, Table-GAN\nis developed against three attacks: re-identification attack, attribute disclosure and\nmembership attack.\nThe Table-GAN is developed from Deep Convolutional Generative Adversarial Network.\nUnlike the GAN model mentioned in the previous section, the Generator G and the Dis-\ncriminator D are a pair of Convolutional neural networks and De-convolutional neural\nwork. Additionally, Table-GAN add another neural network Classifier C to supervise the\nsemantic. Since DCGAN [3] was used for image generation. Thus the input data is not a\nvector but a matrix with a number. Thus, all the data should be prepossessed before\ntraining. For continuous variables, the MinMax normalization Equation 2.4 is applied;\nthe discrete variables are converted to floating-point numbers or one-hot vectors. After\n\n\nChapter 2 Related Work\n17\nthat, the preprocessed data should be re-arranged into a squared matrix. If the number\nof columns can not fill in a squared matrix, zeros are padded behind to increase the vec-\ntor length to form a squared matrix. For example, if the vector length for preprocessed\nfeatures is 12, then four zeros are padding behind, then the vector after padding can\nform a 4 × 4 matrix.\nFigure 2.6 shows the architecture of the Generator G and the Discriminator D from\nTable-GAN. The Generator G performs a series of deconvolution operations to generate\ndata, while the Discriminator D has the corresponding convolution layers to classify the\nreal and fake data. The final loss after the sigmoid activation can be back-propagated\nto the Generator. The dimensions of the latent vector input z and intermediate tensors\nshould be configured considering the number of attributes (e.g., 16 × 16 = 196 attributes\nin this figure). The Classifier C increases the semantic integrity of synthetic records that\nhave the same structure of the Discriminator D. For example, (cholesterol=50, dia-\nbetes=1) is not a correct record because cholesterol=50 is too low to be diagnosed as\ndiabetes. The C is trained by the ground-truth label from the original table, therefore\nit can recognize if the generated data is semantic correct.\nFigure 2.6: Architecture of table-GAN\nThe Table-GAN is trained using standard GAN loss function (Equation 2.4) with two\nadditional term.\nInformation Loss\nThe information loss is defined as the discrepancy between two statistics of synthetic\nand real records. The information loss compares the first-order statistics(mean) and\nsecond-order statistics(sd) using the Equation 2.7:\nLmean = ∥E[fx]x∼pdata(x) −E[fG(z)]z∼p(z)∥2\nLsd = ∥SD[fx]x∼pdata(x) −SD[fG(z)]z∼p(z)∥2\n(2.7)\n\n\nChapter 2 Related Work\n18\nThe less value of Lmean and Lsd indicates that real and synthetic records have the\nstatistically same features from the perspective of the discriminator. To make the privacy\ndegree more controllable, the two loss terms are combined with two thresholds using\nEquation 2.8.\nLG\ninfo = max(0, Lmean −δmean) + max(0, Lsd −δsd)\n(2.8)\nClassification Loss\nClassification loss maintains the semantic integrity using the Equation 2.9. It measures\nthe between the label of a generated record and the label predicted by the classifier for\nthat record.\nLC\nclass = E[|l(x) −C(remove(x))|]x∼pdata(x),\nLG\nclass = E[|l(G(x)) −C(remove(C(x)))|]z∼p(x)\n(2.9)\nwhere l( · ) is a function that returns the ground truth label, remove( · ) is to remove the\nlabel attribute and C( · ) is a label predicted by the classifier neural network.\nTable-GAN is a novel approach for tabular data generation with convolutional neural\nnetwork, but the CNN and classifier architecture restrict it only compatible with limited\ndata type.\nCT-GAN\nCTGAN [6] was proposed by Xu et al. from MIT in 2019. This paper uses Mode-specific\nnormalization to solve mixed data type and Non-Gaussian distribution assumption prob-\nlems and uses Conditional vectors to solve imbalanced categorical column problems.\nData Preprocessing\nThe discrete columns are represented in a one-hot vector, the ith discrete column is\ndonated as di. A special method called Mode-specific normalization is used to process\ncontinuous values. This method is used since the continuous columns in the real-world\nare usually not following a normal distribution but a Multi-modal distribution. In this\npaper, for each continuous column Ci, variational Gaussian mixture model is used to\nfind the number of Modes. Then fit a Gaussian mixture and find the parameters Mean,\nWeight and Standard Deviation of a mode respectively. For each value ci,j in Ci com-\npute the probability of ci,j coming from each mode. Using the most possible mode to\nnormalize ci,j, the normalized value donates as αi,j and the chosen mode is represent in\none-hot vector βi,j.\nAfter that, the representation of a row becomes the concatenation of continuous and\n\n\nChapter 2 Related Work\n19\ndiscrete columns can be written as follows:\nrj = α1,j ⊕βi,j ⊕...αNc,j ⊕βNc,j ⊕d1,j... ⊕dNd,j\nConditional Generator\nUsually, when a GAN model is trained using an unbalanced dataset, the data in the\nminor category will not be sufficiently represented. CTGAN uses a conditional generator\nto enforce that the Generator matches a given category.\nThe cond vector is introduced to indicate the condition. Recall that after the data\npreprocessing, all the discrete columns D1....DN end up as one-hot vector d1...dNd, such\nthat the ith one hot vector is di. The one-hot representation vector is the mask vector\nmi for each discrete column Di. All mask vectors are concated to form a cond vector.\nFor instance, for two discrete columns, D1 = {1, 2, 3} and D2 = {1, 2}, the condition for\nD2 assigned to 1. Thus, the D1 mask vectors m1 = [0, 0, 0] since no condition is assign\nto D1, and the D2 mask vectors m2 = [1, 0]; The final cond vector = [0, 0, 0, 1, 0].\nCTGAN use fully connected hidden layers in both generator and critics (discriminator).\nFor the generator, the input is a random variable z and output is our synthetic data. For\nthe Critics, the PACGAN [16] framework is used to prevent mode collapse. The model\nis trained using WGAN loss(Equation 2.5) with gradient penalty and Adam optimizer.\nFigure 2.7 shows the architecture of CTGAN, the cond vector feed into the conditional\ngenerator, that generates synthetic conditioned rows. With training-by-sampling, the\ncond and training data are sampled according to the log-frequency of each category,\nthus CTGAN can evenly explore all possible discrete values.\nFigure 2.7: Architecture of CTGAN\nNow, CTGAN has become a commonly used GAN-based tabular data generation method,\n\n\nChapter 2 Related Work\n20\nand it can generate data effectively with high-quality synthetic. Thus, CTGAN is one of\nthe models we used as the base model to further develop our method.\n2.2\nSelectivity Estimation\nQuery execution cost estimates the number of computational resources (e.g. CPU and\nI/O resources) for running queries in the current query plan.\nThe total query plan\ncost is computed by combining the cost of each of the operators appearing in the plan.\nSelection, Projection and Joint are three commonly used standard operators. In this\nthesis, we focus on the selection operation. Therefore, this session will introduce some\nregular approaches to the selectivity estimation method. In database systems, selectivity\nestimation has been extensively studied. Common approaches are sampling [17] and\nhistograms [18]. However, most of them suffer from the curse of dimensionality, which\nmeans they could not be compatible with the high-dimensional data. Mattig et al. [19]\nuse the Kernel-based cardinality to highlight the distribution of metric space. However,\nthe kernel function usually needs to be supported by strong assumptions, and a single\nkernel function sometimes is insufficient to solve the complicated inner correlation of\nhigh-dimensional data.\n2.2.1\nRegression-based Models\nAnother method is to see the Selectivity estimation as a regression problem with query\nobject and threshold as input features. Wang et al. [20] developed a Regression based\nmodel called Selnet to estimate the selectivity as well as maintain the consistency for\nhigh-dimensional data. Definition 2.1 shows how to form the selectivity to a regression\nproblem.\nDefinition 2.1 (Selectivity). Given a database with d dimensional vector D = {oi}n\ni=1,\noi ∈Rd. Provide a distance function dist( · ), a scaler threshold t and a query object\nx ∈Rd. The estimate the selectivity in the database can be written as:\n|{ o | dist(x, o) ≤t, o ∈D}|\nThe selectivity (i.e., the ground truth label) y of a query object x and a threshold t as\ngenerated by a value function:\ny = f(x, t, D)\nThus, the selective estimation can be seen as estimate f(x, t, D) using ˆf(x, t, D). How-\never, f is complex, thus f is broke into small sub-functions to rather than using one\n\n\nChapter 2 Related Work\n21\nfunction to estimate f directly. For example, let y = y1 + y2 and t = t1 + t2. Then we\ncan use two linear model to estimate corresponding y1 and y2 with t1 and t2 in the range\nof [0, t1] and (t1, t2]. Following this idea, the Threshold Partitioning method (Definition\n2.2) is adopt.\nDefinition 2.2 (Threshold Partitioning). Assume the maximum threshold is tmax, the\ntmax is divided it with an increasing sequence of (L + 2) value: [τ0, τ1, · · ·, τL+1]. We\nhave τ0 = 0 and τL+1 = tmax + ϵ where ϵ is a small positive quantity to cover corner\ncases. Let gi(x, t) be an interpolant function for interval [τi−1, τi) and we have:\nˆf(x, t, D) =\nL+1\nX\ni=1\n1[t ∈[τi−1, τi)] · gi(x, t)\n(2.10)\nWhere 1[ ] is the indicator function.\nSelnet uses L + 1 continuous piece-wise linear functions to implement gi(x, t) for the\nrange of [τi−1, τi) from Equation 2.10. The τi values are called control points. Let\npi be the estimated Selectivities at Control Points τi. The gi function can written\nusing τi and pi through:\ngi(x, t) = pi−1 + t −τi−1\nτi −τi−1\n· (pi −pi−1)\n(2.11)\nHence, τi and pi are the two parameters for each sub-regression model. The final estima-\ntion function can be re-parameterized as ˆf(x, t, D; Θ) where Θ represents {(τi, pi)}L+1\ni=0 .\nRegression-based estimation methods need to find the best control points and estimate\nthe corresponding pi, then combine the τi and pi to estimate the total selectivity y.\n\n\nChapter 3\nMethodology\nThis chapter will discuss the metrics we used and the methods used in our experiments.\nIn section 3.1, we will discuss the proposed methodology we use to enhance the GAN\nmodel to fulfil query selectivity constraints. Section 4.3 will introduce the metrics used\nto measure the quality of the synthesizing data.\n3.1\nProposed Method\nWe use the proposed methodology to enhance the Base Model to fulfil query selectivity\nconstraints through the Pre-Trained Selectivity Model. The Base Model could be any\nexisting GAN-based tabular data generation model. Figure 3.1 shows the overview of\nthe method process. The whole process can break into three steps:\n1. Data Transforming: Make the GAN model compatible with the mixed data type.\n2. Pre-trained Selectivity Model: Provide supervision for generated data.\n3. Base model Training: Incorporates the selective score during the Base Model train-\ning.\n3.1.1\nData Transforming\nTabular data usually contains multiple columns with continuous mixed type and cate-\ngorical type. From Chapter 2 we know that generating tabular data with mixed data\ntypes could be challenging for some of the existing GAN-based methods. CTGAN uses a\nReversible Data Transforms(RDT) for data pre-processing to handle mixed data types.\n22\n\n\nChapter 3 Methodology\n23\nFigure 3.1: Methodology Overview\nThe RDT converts the categorical features to one-hot vectors and uses the ”Mode-\nSpecific Normalization” method to convert a continuous feature to the corresponding\nMode and normalized value.\nCategorical Data\nThere are two types of categorical data in tabular data, ordinal and nominal. Nomi-\nnal data is classified without a natural order or rank (for example: Male and Female),\nwhereas ordinal data has a predetermined or natural order (for example: Small, Medium\nand Large). CTGAN uses One-hot Encoding to convert both nominal and ordinal data.\nOne-hot Encoding is a simple encoding method to creates additional features based\non the number of unique values in the categorical feature. This encoding method usu-\nally used to convert nominal type categorical data, but it may not suitable for ordinal\ndata. One-hot Encoding may not catch the natural ordered relationship between each\nresponse for ordinal data. For example, if we have a nominal categorical variable Dgender\nand an ordinal categorical variable Dsize.\nOne-hot Encoding represents Dgender =\n{F, M} are [1, 0] and [0, 1], represents Dsize = {small, medium, large} are [1, 0, 0], [0, 1, 0] and [0, 0, 1].\nOnt-hot Encoding provides an equal distance between outcomes. However, for ordinal\nvariable Dsize the distance between small and large should be larger than the distance\nbetween small and medium since the order matters in ordinal variables. The One-hot\nEncoding loses natural order information when converts ordinal variables.\nAs a result, we decide to use Ordinal Encoding for ordinal variables to maintain\nthe inner ordered relations to make sure the GAN model can understand and harness\n\n\nChapter 3 Methodology\n24\nthis relationship during the generation step. By using the Ordinal Encoding, the rep-\nresentation of Dsize = {small, medium, large} is [1, 2, 3]. We use di,j to represent the\nconverted value from the ith categorical column and jth row.\nContinuous Data\nWe continuous data we used the Mode-specific normalization method, which has been in-\ntroduced in CTGAN from session 2.1.4. The Mode-specific normalization method normal-\nizes a continuous column with multi-modal distributions. Figure 3.2 shows the histogram\nof daily temperature records through one year. It is a typical two-modal distribution\nexample where the two distribution indicates the temperature in winter and summer.\nFigure 3.2: Example of multi-modal distribution\nTo be specific,the Mode-specific normalization uses variational Gaussian mixture(VGM)\nmodel to find the number of Modes for each continuous column Ci and the parameters\nmean ηk and standard deviation ϕk of each mode. Then, for each value ci,j in Ci compute\nthe probability ρk of ci,j coming from each mode. Using the ρk to choose which mode\nthe value belong to and using the parameters from the selected mode to normalized the\nci,j. Finally, record the normalized value αi,j and the chosen mode represent in one-hot\nvector βi,j.\nFor example, in Figure 3.3 there are three mode are found by VGM with the mean value\nof η1, η2 and η3. Each mode is a Gaussian distribution with the parameter mean ηk and\nstandard deviation ϕk. Then a continuous value ci,j from column Ci appears. ci,j has\nthe ρ1, ρ2 and ρ3 of coming from each mode. It is more likely to come from the third\nmode η3. Thus, ci,j is normalized by the parameters from the third mode, using the\nformulae:\nci,j −ηk\nϕk\n.\n\n\nChapter 3 Methodology\n25\nWe use αi,j to represent the normalized value, βi,j(Mode indicator) is a one-hot vector\nwhich represents it allocated into the third mode [0, 0, 1]. Finally, a continuous value\nci,j can be converted into the concatenate of αi,j and βi,j\nFigure 3.3: Example of mode-specific normalization\nAfter the above transformation, the representation of the jth row becomes the concate-\nnation of continuous and discrete columns can be written as follows:\nrj = α1,j ⊕βi,j ⊕...αNc,j ⊕βNc,j ⊕d1,j... ⊕dNd,j\nA modified Reversible Data Transformer(mRDT) is built to transform the origin data\ninto the processed data and convert the processed back to the original form.\n3.1.2\nPre-trained Selectivity Model\nIn the second step, we need to train a model to estimate the selectivity for the original\ntabular data. After step one, the dimension of transformed data increases a lot. There-\nfore, we need a selectivity estimation model that can handle high-dimensional data.\nFinally, We decided to employ the simple version of Selnet [20] as our Pre-trained Se-\nlective Model. Selnet is designed to estimate the selectivity for high-dimensional data,\nwhich is quite suitable for our case. It is a regression-based deep learning model that\nlearns a query-dependent piecewise linear function as a selectivity estimator. The origi-\nnal implementation of Selnet contains a Data Partitioning part to improve the accuracy\nof estimation on large-scale datasets. We drop this part for the current implementation.\nRecall the Definition 2.1 Selectivity from Section 2.2.1:\nGiven a database with d dimensional vector D = {oi}n\ni=1, oi ∈Rd. Provide a distance\nfunction dist( · ), a scaler threshold t and a query object x ∈Rd. The estimate the\nselectivity in the database can be written as:\n|{ o | dist(x, o) ≤t, o ∈D}|\n\n\nChapter 3 Methodology\n26\nThe selectivity (i.e., the ground truth label) y of a query object x and a threshold t as\ngenerated by a value function:\ny = f(x, t, D)\nThrough the Definition 2.2 Threshold Partitioning, the estimation of selectivity\ncan be written as Equation (2.10). We use this Threshold Partitioning method, which\nmeans L + 1 piece-wise linear function is used to implement the interpolant function\ngi(x, t). Each g(x, t) contains corresponding τi and pi. The final estimation function\ncan be re-parameterized as ˆf(x, t, D; Θ) where Θ represents {(τi, pi)}L+1\ni=0 . Therefore, we\nneed to find the best control pointsτ and estimate the selectivity p, then combine all the\nτ and p to calculate the total selectivity ˆy.\nFigure 3.4: Architecture of Pre-trained Selectivity Model\nFigure 3.4 shows the architecture of the Pre-trained Selectivity Model. It is a com-\nplicated model which combines three deep neural network components. We firstly input\nthe query objects x to an Autoencoder(AE) to learn a latent representation. The AE\nencourages the model to use latent representation and query distributions for the piece-\nwise linear function. The AE makes the model more generalized and better for handling\nquery objects beyond the training data. Then the query objects x is feed in to the\nAE to learn the representation z. The origin x and representation z is concatenated\ntogether to form [x; z]. After that the [x; z] is fed into two independent deep neural\nnetworks: a feed-forward network (FFN) and M. The M is a encoder-decoder model.\nIn the encoder, an FFN is used to generate (L + 2) embeddings:\n[h0; h1; ...; hL+1] = FFN([x; z]),\nwhere his are high-dimensional representations to represent the latent information of p.\nThen, we adopt adopt (L + 2) linear transformations with the ReLU activation function:\nki = ReLu(wT\ni hi + bi)\n\n\nChapter 3 Methodology\n27\nThen, we have p = [k0, k0+k1, ... PL+1\ni=0 ki]. The output of FFN and M can be converted\nto the τ and p vector. Finally they can combine with the threshold t and fed into the\noperator Σ∗to compute the estimated selectivity ˆy. The Estimation Loss is used to\nestimate the loss between the true selectivity y and the estimated value ˆy of a query\n(x, t).\nJest(ˆj) =\nX\n((x,t),y)∈Ttrain\nl(f(x, t, D), ˆf(x, t, D)) = l(y, ˆy)\nDue to the use of AE, the final loss function(3.1) is a linear combination of the Estima-\ntion loss and the loss of the AE(JAE) during the training.\nJ( ˆf) = Jest(ˆj) + λ · JAE\n(3.1)\nIn our setting, the Selnet is trained to make sure the GAN model satisfies the selec-\ntivity constraint. We denote the transformed Torigin through mRDT as Dorigin. Using\nthe entire data set as the training query objects Qtrain to ensure the Selnet can be\ntrained properly. Then, the labels ytrain and thresholds ttrain are generated based on\nDorigin. Then, we use the training query objects Qtrain and ytrain to train the selectivity\nmodel. After the training is done, the model is ready to evaluate the performance of any\narbitrary synthesizing data through Mean Squared Error (MSE). The evaluation result\ncan be written as follows:\nLSel = MSE(y, ˆy)\n(3.2)\n3.1.3\nBase Model Training\nAfter the Selectivity Model is trained, we use the trained selectivity model to enhance\nthe Base Model.\nThe Base Model could be modified from any existing GAN-based\ntabular data generation model. Figure 3.5 shows the flowchart of the training process\nof Base Model.\nIn a standard GAN model, the Generator G will generate Fake data each iteration after\nreceiving a random noise. Then the Real data from the original input and Fake data\nwill both send into the Discriminator D. The D recognizes the Fake and Real, and then\nthe feedback is produced to Generator Loss and Discriminator Loss, respectively. After\nthat, the loss will be back-propagated to the G and D and start the next iteration. In our\nmethod, we can pick any arbitrary standard GAN model as the Base Model and then\nmake two changes during the Base Model training so that the produced data from Base\nModel can satisfy our requirements. One is the Selectivity Evaluation for the Fake data,\nand the other is the Generator Loss Function Modification before back-propagation.\n\n\nChapter 3 Methodology\n28\nFigure 3.5: Base Model Training Process\nSelectivity Evaluation\nDuring the GAN training process, the generator synthesis a fake tabular data in each\niteration. The synthesised data has the same format and dimension with the transformed\ndata, therefore there is no need to further per-processed the synthesised data. Then for\neach Fake data, we generate the test query Qtest, labels ytest and thresholds ttest. Note\nthat the labels ytest are computed on Dorigin, not Qtest, thus the estimated selectivity\nperformance will not be overestimated. Then the Qtest and labels ytest will send to the\nPre-trained Selectivity Model to predict the ˆytest. The evaluation metric is MSE which\nis calculated through equation (3.2). The evaluation result is donated as LSel. The LSel\nindicates that if the Qtest fulfill the selectivity constraints, the less MSE score means\nthe better performance.\nGenerator Loss Function Modification\nThe selectivity estimation score LSel could not only indicate the performance of the Fake\ndata but also shows the ability of the Generator G in the current status. To improve the\ncapability of G, we add the LSel to the Generator Loss LG. Thus the G will modify itself\nto minimize the loss function then the selectivity constraints will be satisfied. Thus, the\nloss function for the Generator G is adapted as:\nL∗\nG = LG + α · LSel\n(3.3)\n\n\nChapter 3 Methodology\n29\nwhere the LSel is the Selectivity Loss (3.2) and α is the hyper-parameter indicates\nthe weight of the Selectivity Loss term to avoid the large selectivity Loss dominating\nthe whole loss value. For the Discriminator D we remain the same loss function. In\ngeneral, the loss functions should be globally continuous and differentiable. Fortunately,\nthe added term to Generator loss is MSE, one of the simplest and most typical loss\nfunctions. Thus the modified loss function should work well theoretically.\nOverall, Algorithm 1 shows the Generator training algorithm.\nAlgorithm 1 Generator Training Algorithm\nInput: Torigin\nOutput: Trained Generator G\n1: Selnet ←Pre-Trained Selectivity model\n2: G ←Generator\n3: D ←Discriminator\n4: Dorigin ←mRDT(Torigin)\n5: for number of epoch do\n6:\nfor k steps do\n7:\nCreate a mini-batch of random noise Z = {z1, ..., zn}\n8:\nSample a mini-batch of real data X = {X1, ..., Xn} from Dorigin\n9:\nTrain D by maximizing equation (2.2)\n10:\nend for\n11:\nCreate a mini-batch of random noise Z = {z1, ..., zn}\n12:\nGenerate Qtest and Labels ytest using G(Z)\n▷Labels are computed on Dorigin\n13:\nLSel ←Selnet([Qtest : ytest])\n14:\nL∗\nG = LG + α · LSel\n15:\nTrain G by minimizing L∗\nG\n16: end for\n17: return G\n3.1.4\nBase Model\nThis thesis employs two existing models as our Base Model to test our proposed method’s\ncompatibility.\nCTGAN\nCTGAN is a commonly used baseline tabular data synthesizing GAN model. It could\nsynthesize data in high quality and solve imbalanced data problems by introducing\nadditional conditions. It uses RDT to prepossess data and then send the prepossessed\ndata to the CTGAN model. CTGAN uses PACGAN framework to prevent mode collapse\nand WGAN loss (2.5) with gradient penalty and Adam optimizer. Figure 2.7 shows\n\n\nChapter 3 Methodology\n30\nthe architecture of CTGAN. We use CTGAN as our Base Model and combine it with our\nmethod. The completed model we name it SelGAN.\nDaisy\nDaisy [21] is a survey paper which compares the different GAN-based frameworks in the\ntabular data synthesizing field. We want to use a standard GAN-based tabular data gen-\neration method to conduct further ablation studies to test whether our proposed method\nworks well. In Daisy work, we find that utilizing a sequence generation mechanism (such\nas recurrent neural networks(RNN) and long short-term memory (LSTM)) as Generator\ncould generate attributes separately in sequential timesteps and provide robust results.\nAs a result, we decide to employ an LSTM as the Generator and a standard MLP as\nthe Discriminator as the Base Model. Again, we use RDT to prepossess data and then\nsend the prepossessed data to the Base Model and add our proposed method. The final\nresulted model we call it Daisy-sel.\n\n\nChapter 4\nExperiments\nIn this chapter, we will discuss the implementation of experiments.\nWe will briefly\nintroduce the five real-world datasets in section 4.1. Section 4.2 and Section 4.4 will\ntalk about the four baseline models and parameter setting for each models and dataset.\nSection 4.5 shows the evaluation results using the metrics mentioned in section 4.3. An\nablation study is also conducted to demonstrate the efficacy of our method.\n4.1\nDataset\nIn our experiments, we choose five commonly used real-world from UCI Machine Learn-\ning Repository and Kaggle.\n• Adult1: Contains the work-hour attribute has the information of work hours per\nweek for each individual.\n• Covertype2: Contains cartographic variables for four wilderness areas located in\nthe Roosevelt National Forest of northern Colorado.\n• Ticket3: Contains the data for the plane tickets.\n• News4: Contains a heterogeneous set of features about articles published.\n• CreditCard5: Contains PCA data with 28 dimensions of fraudulent credit card\ntransactions information.\nThose data sets contains both high and low dimension data with mixed type which\nmeans all dataset contain both numerical and categorical data. Table 4.1 shows the\nsummary of chosen datasets. As a result, all data can be sent to both regression and\n31\n\n\nChapter 4 Experiments\n32\nclassification task in the later machine learning utility tests. For regression task we use\neducutation num from Adult, soil type from Covertype, amount from CreditCard,\nshares from News, and passengers from Ticket as our response.\nFor classification\ntask we use sex’ from Adult, cover type from Covertype, class from CreditCard,\nis lifestyle from News, and mktcoupons from Ticket as our response.\nName\n#Instance\n#Columns\n#Continuous\n#Ordinal\n#Nominal\nAdult\n30148\n15\n6\n1\n8\nCovertype\n77469\n13\n10\n0\n3\nTicket\n5000\n38\n4\n0\n34\nNews\n39644\n60\n46\n0\n14\nCreditCard\n14241\n30\n28\n0\n1\nTable 4.1: Summary of datasets\n4.2\nBaseline Models\nFor baseline models, we mentioned existing works VAE, MedGAN, tablgeGAN, CTGAN,\nand OCTGAN in Chapter 2. MedGAN is limited to generated binary response which is not\nsuitable for our data set. Therefore, we abandon the MedGAN. OCTGAN failed in Ticket\ndue to mode collapse.\ntablgeGAN has a classifier component inside to maintain the\nsemantic, which needs a binary response column as the label input for the classifier.\nOnly Adult and CreditCard datasets contain a binary response. Therefore tablgeGAN\nonly successfully works for those two datasets. Also, generated data could not produce\nthe label input, and we do not adopt tablgeGAN to the Selectivity Estimation Test.\nSelGAN is one of our resulting model mentioned in 3.1.4.\nTable 4.2 shows the compatibility for each model.\nModel\nAdult\nCovertype\nTicket\nNews\nCreditCard\nSelGan\n✓\n✓\n✓\n✓\n✓\nCT-GAN\n✓\n✓\n✓\n✓\n✓\nOCT-GAN\n✓\n✓\n✓\n✓\ntablGAN\n✓\n✓\nVAE\n✓\n✓\n✓\n✓\n✓\nTable 4.2: Model Compatible table\n1Adult: http://archive.ics.uci.edu/ml/datasets/adult\n2Covertype: http://archive.ics.uci.edu/ml/datasets/covertype\n3Ticket: https://www.transtats.bts.gov/DataIndex.asp.\n4News: https://archive.ics.uci.edu/ml/datasets/online+news+popularity\n5CreditCard: https://www.kaggle.com/mlg-ulb/creditcardfraud\n\n\nChapter 4 Experiments\n33\n4.3\nEvaluation Metrics\nQuality assessment of generated data is not a simple task. Through different propose\nand setting, different evaluation metric is designed.\nWe will introduce the designed\nmetric and how to evaluate the synthesizing data in the three aspects.\n4.3.1\nMode Collapse\nMode Collapse is a common problem for the GAN-based model. The synthesizing data\nis supposed to be diverse. Since the generator is always trying to find the one output\nthat seems most plausible to the discriminator, thus if a generator produces a plausible\noutput, it might learn only to produce that output. Therefore generators keep producing\na small set of output over and over again. We will input the same amount of origin data\nfor each model by testing this problem and letting them generate the same amount of\ndata. Check if there are duplicated records exist in the generated data.\n4.3.2\nVisualization\nWe expect the synthesized data to be close to the original data. For numerical columns,\none simplest way is to visualize the data distribution. Visualizations could provide us\nwith a clear view of the comparison results. We could recognize if the model gener-\nates the correct number of modes or if the model can handle outliers. We compared\nthe cumulative distribution functions (CDFs) of each column’s origin data and synthe-\nsized data to evaluate whether a generated synthesized data is close to the origin data\nstatistically. Also, we plot Pearson correlation heat maps. A correlation heat map is\na graphical representation of a correlation matrix representing the correlation between\ndifferent variables. These Pearson Correlation Heat Maps can test if the synthetic data\ncontains the inner linear correlation between features.\n4.3.3\nSelectivity Estimation\nAs one of the major contributions of our works, we will evaluate the selectivity estimation\nscore for Torigin and TSynth. This test is conducted to compare the ability to handle\nselectivity for models. Similar to before, we used a pre-trained selectivity estimation\nmodel metric. Each TSynth will generate the 1000 queries QSynth based on Dorigin. The\nqueries are sent into the pre-trained model and result in MSE score to indicate if the\nTSynth satisfy the selectivity constraints. Each experiment is repeated ten times. The\naverage lower MSE score shows better performance on fulfilling selectivity constraints.\n\n\nChapter 4 Experiments\n34\n4.3.4\nMachine Learning Utility\nData utility is highly dependent on the specific needs of the synthetic data for down-\nstreaming tasks. We use the Machine learning score to evaluate the effectiveness of using\nsynthetic data as training data for machine learning tasks. We conduct both supervised\nlearning tasks and unsupervised learning to evaluate the data quality thoroughly. For\nthe supervised learning task, we first need to choose our task and separate the features\nX and labels y from the original data table Torigin. Then split the origin data feature\nX into the training set Xtrain and test set Xtest. Then, we extract the features from\nsynthesizing data table TSynth denote as XSynth. We use Xtrain and XSynth to train\nthe machine learning models. Then, we could use Xtest to test the performance of each\nmodel. XGBoost, RandomForest and SVM are employed as regressors and classifiers to\nmake the results more accurate. For the classification task, the accuracy or F1 score\nwill be used. In the regression task, R2 and MSE will be used.\n4.4\nParameter Setting\nAll experiments are conducted on the ‘Spartan’ [22] server, which is the general purpose\nHigh-Performance Computing (HPC) system operated by Research Computing Services\nat The University of Melbourne. The partition deeplearn we used contains 13 nodes,\neach with four NVIDIA V100 graphics cards and six nodes each with four NVIDIA A100\ngraphics cards. The implementation for the Python version is 3.7.4 (compatible with\nTensorFlow 1.15, which is required for tableGAN) and 3.8.6.\nWe use source code for baseline models CT-GAN6, OCT-GAN7, tableGAN8, VAE and Daisy9\nwith their default parameters.\nAs our method is orthogonal to any existing GAN model, the performance of our method\nis largely dependent on the capability of the Base Model, and we do not need to do the\nparameter truing for the Base Model. SelGAN and Daisy-Sel uses the same parameters\nwith CTGAN and Daisy. To ensure the fairness of experiments, we use batch size 500 for\nVAE and all GAN-based models with 300 training epochs using an Adam optimizer.\nSelnet10 is used as the pre-trained selectivity component. We use complete origin data\nTorigin to train Selnet models with batch size 512. The training epoch for AE is 100\n6CT-GAN: https://github.com/sdv-dev/CTGAN\n7OCT-GAN: https://github.com/bigdyl-yonsei/OCTGAN\n8table-GAN https://github.com/mahmoodm2/tableGAN\n9VAE and Daisy https://github.com/ruclty/Daisy\n10Selnet:https://github.com/yyssl88/SelNet-Estimation\n\n\nChapter 4 Experiments\n35\nand 120 for other models. The parameter α from equation (3.3) is set as 0.01 to avoid\nlarge selectivity loss dominate the whole loss value.\n4.5\nResults analysis\nIn this session, we conduct a complete evaluation of our method to understand the\nquality of synthetic data in the metrics mentioned before.\n4.5.1\nMode Collapse\nTable 4.3 show the rate of repeated data. We use this method to check if the model suffers\nfrom mode collapse. The higher value indicates that the mode collapse phenomenon is\nserious. From the table, we can see that the VAE model suffers from the mode collapse\nproblem the most. SelGAN is not suffering from this problem as well as its Base Model\nCTGAN. The standard capability of SelGAN depends on the Base Model. We can only\ncomment that our method will not cause any mode collapse, but we could not make any\ncomment on if our method could ease mode collapse.\nModel\nAdult\nCovertype\nTicket\nNews\nCreditCard\nCT-GAN\n0\n0\n0\n0\n0\nOCT-GAN\n0\n0\n1\n0\n0\ntableGAN\n3.2\n−\n−\n−\n0\nVAE\n0.779\n0\n9.78\n0\n84.83\nSelGAN\n0\n0\n0\n0\n0\nTable 4.3: Rate of Repeated Data (%)\n4.5.2\nVisualization\nDue to the space limit, we do not reveal the complete visualization plots in this chapter,\nand more plots are shown in Appendix B.\nCDF Comparison\nThree interpret-able continuous columns are chosen for the CDF comparison.\nFig-\nure 4.1, Figure 4.2 and Figure 4.3 shows age in Adult, aspect in Covertype and\nglobal subjectivity in news.\nThe left-hand side shows an overall CDFs compari-\nson among all baseline model and our resulting model SelGAN. The comparison of CDFs\n\n\nChapter 4 Experiments\n36\nfor SelGAN and SelGAN-w/o Sel are showns in the right hand side. The SelGAN-w/o\nSel model removes the selectivity estimation component for ablation studies.\nFrom\nthses plots, CDFs of SelGAN in orange are close to CDFs of Torigin in blue, suggesting\nthat SelGAN performs quite well. However, SelGAN could not fit well at the beginning\nand end in Figure 4.2, that means our SelGAN does not always successfully capture the\nstatistics of the Torigin. But, SelGAN still outperform among other base line models\nvisually.\nFigure 4.1: age in Adult\nFigure 4.2: aspect in Covertype\nFigure 4.3: global subjectivity in News\nCorrelation Heat Map\nFigure 4.4 and Figure 4.5 shows the Correlation Heap Map for Adult and CreditCard.\nFrom Figure 4.4, we can see SelGAN generates a similar pattern and color with the\nTorigin. CTGAN and VAE also generate similar patterns and colours, but there are some\nmassive patterns inside. OCTGAN and tableGAN fail to produce the inner correlations.\n\n\nChapter 4 Experiments\n37\nFrom Figure 4.5, we find OCTGAN and VAE simulate the correlation pretty good, but CTGAN\nfailed. SelGAN produce a similar colour but fails to generate the pattern. We realise that\nit is hard to evaluate the performance just by visuals. Thus, we conduct a difference\nin pair-wise correlation comparison test to assess the correlation performance at the\nquantity level. Table 4.4 summarize the difference in pair-wise correlation between the\ncorrelation matrix of origin data Torigin and correlation matrix of synthetic data TSynth.\nThe smaller value indicates that the synthetic data can mimic the correlation well.\nFrom this table, we find that SelGAN outperforms the other GAN-based models in two\ndatasets. We also investigate an interesting phenomenon, VAE models have the lowest\ndistance in Adult and Covertype, but it does not show ideal results in the other three\ndatasets. However, SelGAN has the second-best results in Adult and Covertype. Thus\nwe can conclude that overall, SelGAN can handle the inner correlation between dataset\nfeatures well.\nFigure 4.4: Correlation Heap Map for Adult\nModel\nAdult\nCovertype\nTicket\nNews\nCreditCard\nCT-GAN\n2.79\n21.94\n59.59\n79.00\n100.48\nOCT-GAN\n2.04\n26.96\n−\n46.24\n85.82\ntableGAN\n10.09\n−\n−\n−\n467.84\nVAE\n0.76\n15.99\n91.41\n54.9\n554.05\nSelGAN\n0.93\n19.79\n45.54\n75.07\n66.13\nTable 4.4: Difference in pair-wise correlation\n\n\nChapter 4 Experiments\n38\nFigure 4.5: Correlation Heap Map for News\n4.5.3\nSelectivity Estimation\nTable 4.5 shows the average summary results for the Selectivity estimation accuracy.\nFrom the table, we could see that there are clear reductions for SelGAN among all\nbaseline models. The average decrease rate in MSE score is around 20%. Since the\nability of our model is also dependent on the ability of the Base Model, we find that\nthe scores are various between baseline models. Thus, further ablation studies are still\nrequired to understand better if our method can successfully enhance the existing model\nto fulfil the selectivity constraints.\nModel\nAdult\nCovertype\nTicket\nNews\nCreditCard\nCT-GAN\n40.93\n98.82\n66.12\n111.38\n230.75\nOCT-GAN\n55.53\n128.04\n−\n163.73\n247.22\nVAE\n63.49\n97.27\n68.07\n132.29\n238.40\nSelGAN\n23.86\n82.50\n54.83\n104.36\n200.01\nTable 4.5: Selectivity Estimation MSE in 102\n4.5.4\nMachine Learning Utility\nWe conducted both classification and regression for all datasets. The predicted labels\nwere mentioned in section 4.1. For classification tasks, We plot the Accuracy vs F1-\nscore for all three machine learning models for five datasets (Figure 4.6).\nThis plot\nshows that for the dataset Ticket and CreditCard, SelGAN largely outperforms all others\n\n\nChapter 4 Experiments\n39\nFigure 4.6: ACC and F1 Score for Classification Task over five datasets\nacross all used machine learning models.\nFor dataset Adult and Covertype, SelGAN\noutperforms all GAN-based models. For datasets News, the best result and worst both\ncome from OCTGAN, which means the performance of OCTGAN is quite volatile. SelGAN\nshows relatively stable results with high compatibility.\nWe also use Table 4.6 and Table 4.7 table to summarize the averaged machine learning\nutility score between Torigin and synthetic data in terms of accuracy, F1 score and MSE.\nA better synthetic data is expected to have a similar performance to the Torigin. The\nbest evaluation scores have been labelled in boldface.\nFrom the two tables, we can\nsee, that mostly SelGAN outperforms all other GAN-based state-of-the-art methods in\n\n\nChapter 4 Experiments\n40\nterms of F1-score and MSE. The averaged F1 across the three machine learning models\nincreases up to 6%, and the averaged MSE decreases up to 20%.\nModel\nAdult\nCovertype\nTicket\nNews\nCreditCard\nOrigin\n0.66\n0.69\n0.98\n0.96\n0.99\nCT-GAN\n0.65\n0.42\n0.80\n0.91\n0.91\nOCT-GAN\n0.47\n0.32\n−\n0.81\n0.93\ntableGAN\n0.59\n−\n−\n−\n0.75\nVAE\n0.57\n0.51\n0.84\n0.90\n0.93\nSelGAN\n0.63\n0.42\n0.85\n0.92\n0.95\nTable 4.6: Classification Accuracy (F1)\n]\nModel\nAdult\nCovertype\nTicket\nNews\nCreditCard\nOrigin\n4.17\n49.03\n51.67\n12.03\n4562\nCT-GAN\n7.66\n247.05\n53.62\n12.62\n49226\nOCT-GAN\n9.38\n116.50\n−\n74.23\n68724\ntableGAN\n23.98\n−\n−\n−\n58099\nVAE\n16.43\n159.35\n53.69\n12.77\n52410\nSelGAN\n5.18\n103.27\n53.26\n12.28\n39484\nTable 4.7: Regression Accuracy (MSE)\n4.6\nAblation Study\nTo illustrate the efficiency of our method, we implement an ablation study.\nDue to\nthe limitation of data resources, from Table 4.1 we realized there are not many ordinal\ncolumns in the experimental datasets. In our proposed method, we use an m-RDT pre-\nprocessing method for the proposed data to send to the downstream model more easily.\nThrough m-RDT, we should use Ordinal encoding for ordinal attributes rather than\none-hot vectors. That means we will not have enough experimental data to support\nthe impact of using Ordinal encoding or One-Hot encoding. Therefore, we abandon the\nablation study of the m-RDT component.\nAs mentioned in Section 3.1.4. We combined our method with two existing GAN base\nmodels. These two resulting models are used to test our method’s flexibility and com-\npatibility and check if our method can successfully enhance the synthetic data quality.\nWe remove the pre-trained selectivity component from the model and then redo the test\nto see the performance differences.\nThe following are the two pairs of models we used for the ablation study:\n• SelGAN and SelGAN-w/o Sel\n• Daisy-Sel and Daisy\n\n\nChapter 4 Experiments\n41\nOn the right-handed side of each figure from Figure 4.1, Figure 4.2 and Figure 4.3, the\nCDS distributions of between Torigin and TSynth are revealed. Table 4.8, Table 4.9 and\nTable 4.10 shows the quantity comparison of selectivity estimation and machine learn-\ning performance. In Table 4.8, we find that the average decrease rate for adding the\nselectivity component is 27%, which is a significant drop in the selectivity score. That\nis strong evidence to say that our method does help the current GAN model meet the\nselectivity constraints. As well as the machine learning utility, we can observe trivial\ndifferences among them in most cases. In Table 4.10, Daisy-sel pair in CreditCard\ndataset and SelGAN pair in Covertype dataset share the same results. Therefore, both\nDaisy-sel and SelGAN show better results than the Daisy and SelGAN-w/o Sel re-\nspectively. Considering the high data utility in several datasets, it is crucial to use the\nselectivity component.\nModel\nAdult\nCovertype\nTicket\nNews\nCreditCard\nDaisy\n39.77\n73.86\n88.83\n139.99\n225.22\nDaisy-sel\n11.21\n67.47\n48.77\n82.35\n184.46\nSelGAN-w/o Sel\n40.93\n98.82\n66.12\n111.38\n230.75\nSelGAN\n23.86\n82.50\n54.83\n104.36\n200.01\nTable 4.8: Ablation Selectivity Estimation MSE in 102\nModel\nAdult\nCovertype\nTicket\nNews\nCreditCard\nDaisy\n8.89\n261.19\n152.66\n15.20\n55135\nDaisy-sel\n7.83\n143.36\n104.87\n12.07\n50798\nSelGAN-w/o Sel\n7.66\n247.05\n53.62\n12.62\n49226\nSelGAN\n5.18\n103.27\n53.26\n12.28\n39484\nTable 4.9: Ablation Study: Regression Accuracy (MSE)\nModel\nAdult\nCovertype\nTicket\nNews\nCreditCard\nDaisy\n0.54\n0.47\n0.77\n0.72\n0.97\nDaisy-sel\n0.63\n0.52\n0.83\n0.75\n0.97\nSelGAN-w/o Sel\n0.65\n0.42\n0.80\n0.91\n0.91\nSelGAN\n0.63\n0.42\n0.85\n0.92\n0.95\nTable 4.10: Ablation Study: Classification Accuracy (F1)\n\n\nChapter 5\nConclusions and Future Work\n5.1\nConclusions\nThis thesis proposed a flexible method that could enhance any existing GAN-based\ntabular data generation model to fulfil the selectivity constraints. Through this method,\nwe can synthesize data with a similar selectivity to the origin data Torigin. Then the\nsynthetic data can be used to estimate query execution cost more accurately and further\nestimate the computational resources required if we create queries to the Torigin.\nIn Chapter 1, we introduce the background and aim of our project.\nWe listed four\nchallenges for current tabular data synthesizers, including Data Shortage Issue, Data\nPrivacy Issue, and Data Quality Issues in both the Machine Learning utility and Data\nConstraints aspects. Then we talked about how the promising tabular data generation\nmethod GAN handles these four challenges. We found that current state-of-the-art GAN\nmodels have made successes in the first three challenges, but there is a research gap\nbetween the current method and the fourth challenge. Motivated by the E-commerce\nplatforms problem, we decided to develop a tabular data generation GAN to model\nselectivity constraints in tabular data synthesizing and contribute to solving the last\nIssue.\nIn Chapter 2, we reviewed some common approaches of tabular data synthesizing meth-\nods from statistical and machine learning aspects. Bayesian network [11] is a statistical\ndata generation method. It can describe a dataset as a directed acyclic graph. The\ndependency or relations can be represented through edges and nodes. In the machine\nlearning aspect, we introduce the Variational Auto-encoder. It is a variant of a standard\nauto-encoder whose encoding distribution is regularised during the training process to\nkeep the approximate features and generate new data. Then, we introduced some GAN\n42\n\n\nChapter 5 Conclusion and Future Work\n43\nvariants for tabular data generation including MedGAN, tableGAN, CTGAN and OCTGAN.\nThey developed different methods to make the GAN model solve the first three chal-\nlenges mentioned before. MedGAN is designed for high-dimensional medical record data,\nbut it can only generate numerical and binary data. tableGAN uses a convolutional\nneural network as the generator G and adds a classifier to maintain the semantics of\nsynthetic data. CTGAN and OCTGAN are all aim to solve the in-balanced data distribu-\ntion problem through a conditional vector and neural ordinary differential equations\n(NODEs). We also studied different approaches for selectivity estimation, such as the\nhistogram-based and regression-based methods.\nIn Chapter 3, we talked about the proposed method after consulting many relevant\nmaterials and learning from GAN-based tabular data generation methods. Finally, we\ndecided to develop a flexible method to combine any existing GAN-based tabular data\ngeneration method to model the selectivity constraints. We first need to send the origin\ndata Torigin to train the selectivity estimation model. The pre-trained selectivity estima-\ntion model will supervise the Generator’s performance during the GAN model training\nprocess. The supervision feedback term is added to the Generator loss function, and the\nGenerator can use this feedback to adjust itself in each iteration. We also modified the\ncurrent data pre-processing step to make the method more suitable for the various data\ntypes.\nIn Chapter 4, we introduce the detail of the experiments. Overall, our proposed method\nis an enhanced method to the current GAN based model; thus, the major capability\nin large depends on the Base Model we used to combine.\nTo satisfy the selectivity\nconstraints as well as the quality of the synthetic data, we implement our method to the-\nstate-of-art tabular data generation model CTGAN and resulting SelGAN. The selectivity\nestimation results show that SelGAN can model tabular data with selectivity constraints\nsuccessfully, and it is also robust over different datasets to compare with three GAN-\nbased models and one VAE model.\nUsing the results from machine learning utility\ntests and statistical tests in visual, we can conclude SelGAN can also effectively model\ntabular data and generate high-quality synthetic data. We also combine a GAN model\nwithout outstanding performance, resulting Daisy-Sel to test the compatibility of our\nmethod. Finally, we conduct an ablation study for SelGAN and Daisy-Sel to analyze the\nimportance of the pre-trained selectivity estimation term. We remove the pre-trained\nterm and rerun the tests. The results show that our method is efficient.\n\n\nChapter 5 Conclusion and Future Work\n44\n5.2\nFuture Direction\nThere are still some limitations of our method. Therefore, in the future work, we plan\nto explore the following aspects:\n1. More query operators could be considered\nThere are many query operators in a query execution plan. Now, we only focus\non the selection. More commonly used query operators like projection and joint\ncould be considered in the future.\nThe selection and projection involve only one single data table. Therefore, the\nmodelling cost for selection and projection should be similar. We use projection\nqueries to train the current model or to replace the current model with a projection\nestimation model.\nHowever, modelling joint constraints should be more complicated since the joint\noperation involves two or more data tables. To model the joint constraints, we\nconsider that we should use multiple parallel GAN models for each data table.\nEach GAN model will produce a single data table in each iteration, and then we\nshould calculate the joint cost for the current generated table and provide them\nfeedback. Then the feedback is sent to each GAN model to update the G. The\nmultiple GAN training method should be parallel to ensure all sub-GAN models\ncan grow and interact together. One limitation for that the multiple GAN model\ncould be too complicated.\nSince the number of GAN components depends on\nthe joint constraints, we have to run the same number of sub-GAN components\nsimultaneously if a joint constraint involves a large number of the data table. That\ncould be a huge cost of computational resources.\n2. Improvement on Selectivity component\nCurrently, we use Selnet as our pre-trained selectivity estimation model.\nWe\npicked this Selnet because it can handle the high-dimensional data. We failed\nto use the sampling and histograms based or Gradient boosting trees regression-\nbased estimation method due to the curse of dimensionality. In the future, more\nselectivity estimation models are worth trying to improve estimation accuracy\nfurther. To solve the high-dimensional data, we could try to train an Auto-Encoder\nto learn the representation of synthetic data.\nWe sent the synthetic data into\nthe Encoder to get the representation. Then we sent the representation into the\nestimation model to receive feedback and use the feedback to update G. Even\nthough the model could not handle the high-dimensional data, it can still handle\nthe representation with lower dimensions. Nevertheless, we need to consider that\n\n\nChapter 5 Conclusion and Future Work\n45\ncould the representation have any statistically meaning to fit the logic of estimation\nmodels.\nIn addition, we employed an existing selectivity estimation model previously. Nev-\nertheless, we should have a novel, own-designed selectivity model for our scenario.\n3. Satisfy industrial needs\nThis project is motivated by the E-commence platform cases. However, our current\nmethod is not yet satisfied industrial needs. We have to solve the previous two\nfuture directions and then consider them for industry application. There is one\nbig challenge for the E-commence platform in a real-world scenario: we have to\ndynamically update the users’ data. In the E-commence platform cases, users’\ndata or transactions should be updated frequently. Our method can only handle\nthe static data table. If the data table changes, we must redo the GAN model\ntraining. However, that should be a common issue for GAN-based models or even\nall static machine learning models. To solve this problem, we should consider a\nDynamic Training method.\n4. More experiments in other GAN variants\nIn this thesis, we only test two existing models. These two existing models have\ndifferent architectures but still can not be representative enough. There are lots\nof varieties in GAN-based tabular generation methods. We can implement our\nmethod to more GAN models and further analyze whether the selectivity im-\nprovement would be changed due to the other GAN architectures.\n5. Hyper-parameter setting\nDuring the GAN training process, we add the LSel into the LG. We define the\nparameter α = 0.01 to control the weight of LSel. This weight is to ensure the\nLSel will not dominate the whole loss function. However, the scale of LSel for the\ndifferent datasets is various, and a single value of α may not work well. Thus,\nmore precision experiments are required. We may need to test new α for different\ndatasets or use some normalization function to normalize the LSel in a certain\nrange.\n\n\nAppendix A\nNotations\nNotation\nDescription\nGeneral:\nTorigin\nOriginal Data\nTSynth\nSynthetic data produced by model\nPre-processing:\nCi\nith continuous column\nDi\nith discrete column\nci,j\nValue in the i-th continuous column of j-th row\ndi,j\nValue in the i-th discrete column of j-th row\nm-RDT\nModified Reversible Data Transforms\nαi,j\nnormalized value for ci,j\nβi,j\nMode representation for ci,j\nm-RDT\nModified Reversible Data Transforms\nGAN model:\nD\nDiscriminator\nG\nGenerator\nQuery Generation:\nDorigin\nTransformed Original Data\nQtrain\ntesting query objects\nQtest\ntraining query objects\nGAN training:\nLG\nGenerator Loss\nLSel\nSelectivity Loss\nLD\nDiscriminator Loss\nX ∼{X1, X2, X2}\nReal data sampled from Dorigin\nZ ∼{Z1, Z2, Z2}\nNoisy data sampled from N ∼(0, 1)\nTable A.1: Notations\n46\n\n\nAppendix B\nFigures\nComplete CDFs and correlation heat maps visualization plots from Chapter 4\nFigure B.1: education-num in Adult\nFigure B.2: fnlwgt in Adult\nFigure B.3: capital-loss in Adult\n47\n\n\nAppendix\n48\nFigure B.4: elevation in Covertype\nFigure B.5: slope in Covertype\nFigure B.6: hillshade noon in Covertype\nFigure B.7: Amount in Credit\nFigure B.8: MktDistance in Ticket\n\n\nAppendix\n49\nFigure B.9: Passengers in Ticket\nFigure B.10: title subjectivity in News\nFigure B.11: shares in News\nFigure B.12: average token length in News\nFigure B.13: LDA00 in News\n\n\nAppendix\n50\nFigure B.14: Correlation Heap Map for Covertype\nFigure B.15: Correlation Heap Map for Ticket\n\n\nAppendix\n51\nFigure B.16: Correlation Heap Map for Credit\n\n\nBibliography\n[1] Jun Zhang, Graham Cormode, Cecilia M Procopiuc, Divesh Srivastava, and Xiaokui\nXiao. Privbayes: Private data release via bayesian networks. ACM Transactions\non Database Systems (TODS), 42(4):1–41, 2017.\n[2] J´er´emie Sublime and Ekaterina Kalinicheva. Automatic post-disaster damage map-\nping using deep-learning techniques for change detection: Case study of the tohoku\ntsunami. Remote Sensing, 11(9), 2019. ISSN 2072-4292. doi: 10.3390/rs11091123.\nURL https://www.mdpi.com/2072-4292/11/9/1123.\n[3] Alec Radford, Luke Metz, and Soumith Chintala.\nUnsupervised representation\nlearning with deep convolutional generative adversarial networks. arXiv preprint\narXiv:1511.06434, 2015. URL https://cpang4.github.io/gan/.\n[4] Ian Goodfellow, Jean Pouget-Abadie, Mehdi Mirza, Bing Xu, David Warde-Farley,\nSherjil Ozair, Aaron Courville, and Yoshua Bengio. Generative adversarial nets.\nAdvances in neural information processing systems, 27, 2014.\n[5] Lei Xu and Kalyan Veeramachaneni. Synthesizing tabular data using generative\nadversarial networks. arXiv preprint arXiv:1811.11264, 2018.\n[6] Lei Xu, Maria Skoularidou, Alfredo Cuesta-Infante, and Kalyan Veeramachaneni.\nModeling tabular data using conditional gan.\nAdvances in Neural Information\nProcessing Systems, 32, 2019.\n[7] Jayoung Kim, Jinsung Jeon, Jaehoon Lee, Jihyeon Hyeong, and Noseong Park.\nOCT-GAN: neural ode-based conditional tabular gans.\nCoRR, abs/2105.14969,\n2021. URL https://arxiv.org/abs/2105.14969.\n[8] Noseong Park, Mahmoud Mohammadi, Kshitij Gorde, Sushil Jajodia, Hongkyu\nPark, and Youngmin Kim. Data synthesis based on generative adversarial networks.\nCoRR, abs/1806.03384, 2018. URL http://arxiv.org/abs/1806.03384.\n[9] Aoting Hu, Renjie Xie, Zhigang Lu, Aiqun Hu, and Minhui Xue. Tablegan-mca:\nEvaluating membership collisions of gan-synthesized tabular data releasing. In Pro-\nceedings of the 2021 ACM SIGSAC Conference on Computer and Communications\n52\n\n\nBibliography\n53\nSecurity, CCS ’21, page 2096–2112, New York, NY, USA, 2021. Association for\nComputing Machinery. ISBN 9781450384544. doi: 10.1145/3460120.3485251. URL\nhttps://doi.org/10.1145/3460120.3485251.\n[10] Haipeng Chen, Sushil Jajodia, Jing Liu, Noseong Park, Vadim Sokolov, and V. S.\nSubrahmanian.\nFaketables: Using gans to generate functional dependency pre-\nserving tables with bounded real data. In Proceedings of the Twenty-Eighth Inter-\nnational Joint Conference on Artificial Intelligence, IJCAI-19, pages 2074–2080.\nInternational Joint Conferences on Artificial Intelligence Organization, 7 2019. doi:\n10.24963/ijcai.2019/287. URL https://doi.org/10.24963/ijcai.2019/287.\n[11] Daphne Koller and Nir Friedman. Probabilistic graphical models: principles and\ntechniques. MIT press, 2009.\n[12] Dana H Ballard. Modular learning in neural networks. In Aaai, volume 647, pages\n279–284, 1987.\n[13] Diederik P Kingma and Max Welling.\nAuto-encoding variational bayes.\narXiv\npreprint arXiv:1312.6114, 2013.\n[14] Martin Arjovsky, Soumith Chintala, and L´eon Bottou. Wasserstein generative ad-\nversarial networks. In Doina Precup and Yee Whye Teh, editors, Proceedings of\nthe 34th International Conference on Machine Learning, volume 70 of Proceed-\nings of Machine Learning Research, pages 214–223. PMLR, 06–11 Aug 2017. URL\nhttps://proceedings.mlr.press/v70/arjovsky17a.html.\n[15] Karim Armanious, Chenming Jiang, Marc Fischer, Thomas K¨ustner, Tobias Hepp,\nKonstantin Nikolaou, Sergios Gatidis, and Bin Yang.\nMedgan: Medical image\ntranslation using gans.\nComputerized medical imaging and graphics, 79:101684,\n2020.\n[16] Adriel Cheng. Pac-gan: Packet generation of network traffic using generative ad-\nversarial networks. In 2019 IEEE 10th Annual Information Technology, Electronics\nand Mobile Communication Conference (IEMCON), pages 0728–0734. IEEE, 2019.\n[17] Wentao Wu, Jeffrey F Naughton, and Harneet Singh. Sampling-based query re-\noptimization. In Proceedings of the 2016 International Conference on Management\nof Data, pages 1721–1736, 2016.\n[18] Yannis E. Ioannidis and Viswanath Poosala. Histogram-based solutions to diverse\ndatabase estimation problems. IEEE Data Eng. Bull., 18(3):10–18, 1995.\n[19] Zhenjie Zhang, Yin Yang, Ruichu Cai, Dimitris Papadias, and Anthony Tung.\nKernel-based skyline cardinality estimation. In Proceedings of the 2009 ACM SIG-\nMOD International Conference on Management of data, pages 509–522, 2009.\n\n\nBibliography\n54\n[20] Yaoshu Wang, Chuan Xiao, Jianbin Qin, Rui Mao, Makoto Onizuka, Wei Wang,\nRui Zhang, and Yoshiharu Ishikawa. Consistent and flexible selectivity estimation\nfor high-dimensional data.\nIn Proceedings of the 2021 International Conference\non Management of Data. ACM, jun 2021. doi: 10.1145/3448016.3452772. URL\nhttps://doi.org/10.1145%2F3448016.3452772.\n[21] Ju Fan, Junyou Chen, Tongyu Liu, Yuwei Shen, Guoliang Li, and Xiaoyong Du.\nRelational data synthesis using generative adversarial networks: A design space\nexploration. Proc. VLDB Endow., 13(12):1962–1975, jul 2020. ISSN 2150-8097. doi:\n10.14778/3407790.3407802. URL https://doi.org/10.14778/3407790.3407802.\n[22] Spartan documentation. https://dashboard.hpc.unimelb.edu.au/. Accessed:\n2022-05-20.\n\n\n",
  "metadata": {
    "source_file": "dataset/pdfs/arxiv_2502.21034v1.pdf",
    "total_pages": 62,
    "title": "Synthesizing Tabular Data Using Selectivity Enhanced Generative Adversarial Networks",
    "authors": [
      "Youran Zhou",
      "Jianzhong Qi"
    ],
    "abstract": "As E-commerce platforms face surging transactions during major shopping\nevents like Black Friday, stress testing with synthesized data is crucial for\nresource planning. Most recent studies use Generative Adversarial Networks\n(GANs) to generate tabular data while ensuring privacy and machine learning\nutility. However, these methods overlook the computational demands of\nprocessing GAN-generated data, making them unsuitable for E-commerce stress\ntesting.\n  This thesis introduces a novel GAN-based approach incorporating query\nselectivity constraints, a key factor in database transaction processing. We\nintegrate a pre-trained deep neural network to maintain selectivity consistency\nbetween real and synthetic data. Our method, tested on five real-world\ndatasets, outperforms three state-of-the-art GANs and a VAE model, improving\nselectivity estimation accuracy by up to 20pct and machine learning utility by\nup to 6 pct.",
    "published_date": "2025-02-28",
    "source": "arxiv"
  }
}