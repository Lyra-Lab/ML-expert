{
  "id": "arxiv_2502.21226v2",
  "text": "arXiv:2502.21226v2  [cs.AR]  3 Mar 2025\nRecurrent CircuitSAT Sampling for Sequential Circuits\nArash Ardakani\nUniversity of California, Berkeley\narash.ardakani@berkeley.edu\nKevin He\nUniversity of California, Berkeley\nkevinjhe@berkeley.edu\nJohn Wawrzynek\nUniversity of California, Berkeley\njohnw@berkeley.edu\nAbstract—In this work, we introduce a novel GPU-accelerated circuit\nsatisﬁability (CircuitSAT) sampling technique for sequential circuits. This\nwork is motivated by the requirement in constrained random veriﬁcation\n(CRV) to generate input stimuli to validate the functionality of digital\nhardware circuits. A major challenge in CRV is generating inputs for\nsequential circuits, along with the appropriate number of clock cycles\nrequired to meet design constraints. Traditional approaches often use\nBoolean satisﬁability (SAT) samplers to generate inputs by unrolling state\ntransitions over a ﬁxed number of clock cycles. However, these methods\ndo not guarantee that a solution exists for the given number of cycles.\nConsequently, producing input stimuli together with the required clock\ncycles is essential for thorough testing and veriﬁcation. Our approach\nconverts the logical constraints and temporal behavior of sequential\ncircuits into a recurrent CircuitSAT problem, optimized via gradient\ndescent to efﬁciently explore a diverse set of valid solutions, including\ntheir associated number of clock cycles. By operating directly on the\ncircuit structure, our method reinterprets the sampling process as a\nsupervised multi-output regression task. This differentiable framework\nenables independent element-wise operations on each tensor element,\nfacilitating parallel execution during learning. As a result, we achieve\nGPU-accelerated sampling with substantial runtime improvements (up\nto 105.1×) over state-of-the-art heuristic samplers. We demonstrate the\neffectiveness of our method through extensive evaluations on circuit\nproblems from the ISCAS-89 and ITC’99 benchmark suites.\nIndex Terms—Circuit Satisﬁability, Gradient Descent, Sequential Cir-\ncuits, Veriﬁcation, and Testing.\nI. INTRODUCTION\nSimulation-based functional veriﬁcation plays a crucial role in\ncontemporary digital design automation processes, though it is often\nquite time-intensive [1]. In this stage, the design undergoes thorough\ntesting by running numerous simulations with a wide range of input\nsignals to ensure that it complies with its intended functional require-\nments. For complex systems, each input typically spans numerous\nclock cycles, making exhaustive simulation impractical for real-world\ndesigns [2]. Therefore, generating high-quality stimuli that effectively\nexplore key functional scenarios, especially in corner cases, is essen-\ntial for achieving sufﬁcient coverage. Constrained random veriﬁcation\n(CRV) [3]–[6] addresses this challenge by allowing the user to deﬁne\nconstraints that guide the generation of valid input stimuli, ensuring\nthe design is tested in critical, bug-prone areas. CRV introduces\nrandomness in the input selection process while still satisfying the\ngiven constraints, improving the efﬁciency of the veriﬁcation process\nby increasing the likelihood of discovering hard-to-detect bugs [7]–\n[9].\nThe task of generating input stimuli in CRV for a given Boolean\ncircuit is known as circuit satisﬁability (CircuitSAT) sampling [10],\n[11]. CircuitSAT sampling involves transforming circuit problems\ninto Boolean satisﬁability (SAT) problems and using SAT samplers\nto generate random solutions that meet the speciﬁed constraints.\nCircuitSAT is essentially a specialized form of the SAT problem\n[12]–[16], where the circuit’s structure is represented explicitly as a\nnetwork of logic gates rather than in conjunctive normal form (CNF).\nCircuitSAT sampling for combinational circuits focuses on generating\ndiverse input patterns that satisfy the logic of the circuit, without\ninvolving any state or temporal dependencies. Since combinational\ncircuits are acyclic and consist purely of logic gates (e.g., AND, OR,\nNOT), the sampling process is relatively straightforward and well-\nestablished in the literature [10], [11], [17]. This process typically\nbegins by converting the circuit’s structure into CNF using methods\nsuch as the Tseitin transformation [18]. Any design constraints on\nthe circuit’s outputs can also be encoded in the CNF, after which\nSAT samplers can be applied to generate valid input stimuli for the\nCircuitSAT problem.\nUnlike combinational circuits, sequential circuits depend on mem-\nory elements and clock-driven state transitions, making test genera-\ntion signiﬁcantly more complex. To apply SAT sampling to sequential\ncircuits, the circuit must be “unrolled” over multiple time steps,\neffectively transforming it into a series of combinational steps that\ncapture the circuit’s state transitions [19]. However, this approach\nassumes that the required number of clock cycles for the given\ndesign constraints is known in advance, which is often unrealistic.\nConsequently, the CircuitSAT sampling process for sequential circuits\ninvolves not only generating input stimuli that satisfy the design\nconstraints but also determining the necessary number of clock cycles\nfor each input. This requirement makes CircuitSAT sampling for\nsequential circuits extremely challenging, yet invaluable if success-\nfully implemented, as it provides a powerful means of testing and\nveriﬁcation for complex, state-dependent systems.\nIn this work, we introduce a machine-learning-driven method to\ngenerate input stimuli for sequential circuits along with the necessary\nnumber of clock cycles for each sample. To this end, We formulate\nthe CircuitSAT sampling process for sequential circuits as a recurrent\nmulti-output regression task, where each logic gate is represented\nprobabilistically and each memory element (e.g., ﬂip-ﬂops) is treated\nas hidden state, enabling the use of gradient descent (GD) to learn\ndiverse solutions. This approach enables the parallel generation of\nindependent input stimuli including their associated required clock\ncycles while accelerating the sampling computations with GPUs. We\ndemonstrate the superior performance of our sampling method across\nall instances from the ISCAS-89 and ITC’99 benchmark suites.\nII. PRELIMINARIES\nA. CircuitSAT Sampling\nA digital circuit is an electronic system that processes binary\ninformation according to the rule of Boolean logic. Digital circuits are\nbuilt using interconnected digital components including logic gates\n(e.g., AND, OR, and NOT gates) and memory elements (e.g., ﬂip-\nﬂops). In digital circuits, variables are restricted to discrete binary\nvalues of either 0 or 1. The output of such circuits is produced based\non how these digital components operate on binary variables. There\nare two types of digital circuits: combinational and sequential circuits.\nIn combinational circuits, the output solely depends on current inputs,\nwhereas in sequential circuits, the output depends not only on the\ncurrent inputs but also on the history of inputs represented as the\ncurrent state.\nCircuitSAT sampling is the task of generating a sequence of a set of\nbinary-valued assignments to the inputs of a given digital circuit that\nmakes its output evaluate to desired value. The desired outputs are\nreferred to as output constraints to the CircuitSAT problem. Sampling\n\n\nsolutions from CircuitSAT instances in CRV is valuable as it enables\nefﬁcient, targeted generation of test cases that satisfy speciﬁc logical\nconstraints, ensuring that only valid and meaningful scenarios are\nexplored. This approach increases coverage and detects edge cases\nmore effectively than random sampling, focusing on diverse, rele-\nvant conﬁgurations that might reveal hidden bugs. CircuitSAT-based\nsampling also reduces the need for exhaustive testing, especially in\ncomplex circuits, by selectively exploring the solution space. Ulti-\nmately, this method improves veriﬁcation efﬁciency and reliability,\nmaking it valuable for high-quality digital design testing.\nA common method for CircuitSAT sampling is to use SAT\nsolvers equipped with sampling features. These solvers not only\ncheck whether a Boolean formula is satisﬁable but also sample\nspeciﬁc solutions from the set of all possible solutions. Efﬁcient\nSAT solving techniques include backtracking methods like the Davis-\nPutnam-Logemann-Loveland (DPLL) algorithm [20], stochastic local\nsearch approaches like WalkSAT [21], and conﬂict-driven clause\nlearning (CDCL) algorithms [22], [23]. In recent years, various\nalgorithms for SAT and CircuitSAT sampling have been introduced,\nincluding randomized methods, Markov chain Monte Carlo (MCMC)\napproaches, and heuristic-based sampling techniques [10], [24]–[27].\nThese techniques generally work by iteratively exploring possible\nsolutions, selecting candidates based on certain rules, and using\nprobabilistic criteria to accept or reject them.\nThe ﬁrst step in CircuitSAT sampling using SAT solvers is to model\nthe relationships among digital components and translate them into\na CNF representation. CNF is structured as a conjunction (AND)\nof multiple clauses, where each clause is a disjunction (OR) of\nliterals. Here, literals refer to Boolean variables or their negations.\nThe number of variables in the CNF is determined by the primary\ninputs, intermediate signals, and primary outputs of the digital circuit.\nConversely, the number of clauses corresponds to the logic operations\nin the circuit. The transformation into CNF offers SAT solvers\na standardized representation of the problem, preserving the core\nconstraints of the original circuit. The conversion to CNF is typically\nachieved using the Tseitin transformation [18].\nConverting combinational circuits to CNF is straightforward, as\neach logic gate can be mapped to corresponding CNF sub-clauses\nusing the Tseitin transformation. The size and intricacy of the\nresulting CNF formula can vary widely, inﬂuenced by factors like\nthe number of gates, circuit depth, and counts of inputs, outputs,\nand intermediate signals. Generally, the CNF representation requires\nsubstantially more bit-wise operations than the original circuit. This\nadded complexity increases the time SAT solvers need to ﬁnd\nsolutions due to the NP-complete nature of SAT problems. The\nchallenge is even greater for sequential circuits, which involve time-\ndependent behavior. Representing these temporal dependencies in\nCNF necessitates additional variables and constraints to maintain con-\nsistency across time steps, further complicating the transformation.\nAlthough theoretically possible, converting sequential circuits to CNF\ninvolves unique difﬁculties such as state encoding, temporal logic,\nand clock handling, making it particularly challenging for large or\ncomplex designs. The main challenge in converting sequential circuits\nto CNF is determining the speciﬁc number of clock cycles to unroll\nthe sequential circuit so that it can be treated as a combinational\ncircuit for conversion using the Tseitin transformation. However, it\nis generally impossible to know the number of clock cycles that will\nguarantee satisfying solutions for given output constraints, creating a\nunique challenge for sequential CircuitSAT sampling.\nCombinational\nCircuit (Fh)\nFlip-Flops\nCombinational\nCircuit (Fo)\nPt\nHt+1\nHt\nˆYt\nFigure 1: The general form of a sequential circuit.\nB. Multi-Output Regression Task\nA multi-output regression task involves predicting several target\nvariables simultaneously based on a set of input features [28]. The\ngoal is to build a model that effectively captures the connections\nbetween the inputs and each output variable. This model can be\ndeveloped through various approaches, such as linear regression or\nneural networks, and is trained on a dataset with known input-output\npairs. During training, the model’s parameters are optimized to reduce\nthe difference between its predictions and the actual targets, often\nusing mean squared error (MSE) or ℓ2 loss as a measure of accuracy.\nIII. METHODOLOGY\nIn contrast to combinational circuits, where outputs are determined\nsolely by their present inputs, the output in sequential circuits depends\non both the past behavior of the circuit and the present values of\ninputs. The temporal operations of sequential circuits are controlled\nby a clock signal. The contents of memory elements (i.e., ﬂip-ﬂops)\nrepresent the past behavior of such a circuit, which is commonly\nreferred to as the state of the circuit.\nA. Recurrent CircuitSAT Sampler for Sequential Circuits\nSolving CircuitSAT problems for sequential circuits presents a\nunique challenge as it requires ﬁnding a sequence of inputs that\nsatisﬁes the target output constraint over a series of clock cycles. To\ntackle such problems, we can leverage a novel technique inspired\nby recurrent neural networks (RNNs). In RNNs, backpropagation\nthrough time is utilized during the learning process, allowing for\nupdates to the network’s hidden state at each time step. Similarly,\nin the context of solving CircuitSAT problems, we perform forward\ncomputations to iteratively update the state values at each clock\ncycle. During backward computations, gradients are backpropagated\nthrough time, extending back to the initial time step (i.e., the ﬁrst\nclock cycle), to adjust the input sequence accordingly. While this\napproach draws parallels to RNN training, it is tailored to the unique\nchallenges posed by solving CircuitSAT problems for sequential\ncircuits.\nFig. 1 shows the general structure of a sequential circuit. We use\nthis structure to formulate the CircuitSAT problem for sequential\ncircuits to ﬁnd satisfying solutions. In this structure, there are two\ncombination circuits: one to update the state of the circuit (i.e., the\ncontent values of ﬂip-ﬂops) and the other one to generate the output.\nIt is worth mentioning that both of these combinational circuits take\nthe present values of ﬂip-ﬂops and primary inputs at the current time\nstep as their inputs. Given that these combinational circuits (i.e., Fh\nand Fo) are fundamentally discrete and non-differentiable, we need\nto relax the CircuitSAT problem into a continuous version that still\nmaintains the circuit’s core structure and behavior. To do this, we\nutilize the probability model of digital gates, as outlined in Table\nI. This probabilistic model is widely applied across various ﬁelds,\nincluding stochastic computing [29] and the estimation of dynamic\npower in digital circuits [30]. By applying these probabilities to model\neach gate, we produce a differentiable formulation of the circuit that\n\n\nRecurrent Cell\nFo\nFh\nHt\nHt+1\nˆYt\nPt\nRecurrent Cell\nPt\nˆYt\nHt+1\nFigure 2: Left: The proposed recurrent sequential model. Right: The\nproposed recurrent cell for sequential circuits.\npreserves its functionality. Importantly, for any binary input, this\nmodel remains equivalent to the original circuit in its discrete form.\nLet us represent the primary input variables at time step t as Vt ∈\nRb×n. We encode the primary input variables at each time step as\nlearnable parameters to an embedding layer followed by the sigmoid\nfunction to provide input probabilities at time t as Pt ∈[0, 1]p×n to\nthe combinational circuits, i.e.,\nPt = σ(Vt).\n(1)\nThe present output of the circuit (i.e., ˆYt ∈[0, 1]b×m) is computed\nas:\nˆYt = Fo(Pt, Ht),\n(2)\nwhere Fo and Ht\n∈[0, 1]b×r denote the functionality of the\ncombinational circuit generating outputs and the present values of\nﬂip-ﬂops at each time step, respectively. The number of ﬂip-ﬂops in\nthe circuit is represented by r. The state of the circuit for the next\ntime step is obtained as:\nHt+1 = Fh(Pt, Ht),\n(3)\nwhere the functionality of the combinational circuit updating the\nvalues of ﬂip-ﬂops is denoted by Fh. The ℓ2-loss function L can then\nbe constructed by measuring the distance between ˆYt at the desired\ntime step T and the target output valuation matrix Y ∈{0, 1}b×m\nas follows:\nL =\nX\nb,m\n\f\f\f\n\f\f\fY −ˆYT\n\f\f\f\n\f\f\f\n2\n2 .\n(4)\nWith such a formulation for sequential circuits, we can solve the\nCircuitSAT problem and provide b solutions. The general form of\nthe recurrent cell for sequential circuits is shown in Fig. 2, which is\nanalogous to the RNN cell.\nWith our formulation, backpropagation through time is used to\ncompute the gradients of the loss with respect to the primary input\nvariables (i.e., Vt). The objective is to ﬁnd the gradient of L with\nrespect to Vt. To derive this gradient, we apply the chain rule across\ntime steps. The gradient with respect to Vt requires accounting for\nhow the circuit’s states inﬂuence each other over time, computed as\nfollows:\n∂L\n∂Ht = ∂L\n∂ˆYt\n· ∂ˆYt\n∂Ht +\n∂L\n∂Ht+1 · ∂Ht+1\n∂Ht ,\n(5)\ngiven Eq. (2) and Eq. (3). The recursive formula above captures the\ninﬂuence of the circuit state at each time step on both the output and\nthe subsequent state. Backpropagation through time, as shown in Eq.\n(5), can now be used to calculate the gradients of L with respect to\nVt:\n∂L\n∂Vt = ∂L\n∂ˆYt\n· ∂ˆYt\n∂Pt · ∂Pt\n∂Vt +\n∂L\n∂Ht+1 · ∂Ht+1\n∂Pt\n· ∂Pt\n∂Vt .\n(6)\nThis formula enables updating the primary input variables by prop-\nagating the gradients back through time.\nTable I: Probability model and input derivatives of primary logic gates\nOperator\nOutput Variable\nDerivative w.r.t Input\nNOT(P1)\nPy = P1 = 1 −P1\n∂Py\n∂P1\n= −1\nAND(P1, P2)\nPy = P1 P2\n∂Py\n∂P1\n= P2, ∂Py\n∂P2\n= P1\nOR(P1, P2)\nPy = 1 −P1 P2\n∂Py\n∂P1\n= P2, ∂Py\n∂P2\n= P1\nXOR(P1, P2)\nPy = P1 P2 + P1 P2\n∂Py\n∂P1\n= 1 −2P2, ∂Py\n∂P2\n= 1 −2P1\nXNOR(P1, P2)\nPy = P1 P2 + P1 P2\n∂Py\n∂P1\n= 2P2 −1, ∂Py\n∂P2\n= 2P1 −1\nB. Theoretical Analysis\nProof of convergence is a crucial concept across various ﬁelds,\nincluding machine learning, economics, engineering, and operations\nresearch. Convergence in optimization is important because it en-\nsures stable solutions, enhances robustness to noise, and enables the\napplication of efﬁcient algorithms that leverage gradient information\nand duality principles. In our formulation for the CircuitSAT problem,\nconvergence plays a key role by simplifying the optimization process,\nthereby allowing our method to reliably ﬁnd the satisfying solutions.\nBefore presenting a proof of convergence, let us ﬁrst demonstrate\nthat the optimization problem in our formulation is non-convex. The\ncombinational parts of our formulation for the CircuitSAT problem\ncan be viewed as an AND-inverter graph (AIG), where the AND\noperation is deﬁned as\nAND(p1, p2) = p1 · p2,\n(7)\nwith p1, p2 ∈[0, 1] as the inputs. To test the convexity of the AND\nfunction, we analyze its Hessian matrix H of second derivatives,\nwhich is given by\nH =\n\n\n∂2AND(p1, p2)\n∂p2\n1\n∂2AND(p1, p2)\n∂p1∂p2\n∂2AND(p1, p2)\n∂p2∂p1\n∂2AND(p1, p2)\n∂p2\n2\n\n=\n\u00140\n1\n1\n0\n\u0015\n.\n(8)\nThe eigenvalues of H are ±1. Since one eigenvalue is negative, H\nis not positive semi-deﬁnite, and therefore, the AND function is non-\nconvex. As a result, the AIG containing multiple AND gates is also\nnon-convex.\nWhile our CircuitSAT problem formulation is a non-convex opti-\nmization, we prove the convergence of gradient descent to global\nminima for such a non-convex formulation using the Lipschitz\ncontinuity of the gradient [31]. Let us represent the sequence of\ninputs over T clock cycles as the matrix X ∈[0, 1]n×T and let\nF(X) →[0, 1]m be the non-convex function of the sequential circuit.\nSince X and F(X) are bounded within [0, 1], the ℓ2-loss (L(X)) of\nF(X) is also bounded by the number of constrained outputs (i.e.,\nL(X) ∈[0, m]) and, therefore, there exists a constant L > 0 such\nthat\n||∇L(X) −∇L(Z)|| ≤L||X −Z||\n∀X, Z ∈[0, 1]n×T ,\n(9)\nimplying that the Hessian of the function L(X) is bounded, i.e.,\nH(X) ≤L. The gradient descent update for a matrix X ∈[0, 1]n×T\nat the kth training iteration is as follows:\nXk+1 = Xk −α∇L(Xk),\n(10)\nwhere α > 0 denotes the learning rate.\n\n\nUsing the second-order Taylor expansion of L(Xk+1) around Xk,\nwe have:\nL(Xk+1) ≈L(Xk) + ∇L(Xk)T (Xk+1 −Xk)\n+ 1\n2(Xk+1 −Xk)T H(Xk)(Xk+1 −Xk).\n(11)\nUsing the Lipschitz bound on the Hessian, we can replace H(Xk)\nwith L to get the following inequality:\nL(Xk+1) ≤L(Xk) + ∇L(Xk)T (Xk+1 −Xk)\n+ L\n2 ||Xk+1 −Xk||2.\n(12)\nGiven Eq. (10), we can substitute Xk+1 −Xk with −α∇L(Xk) and,\ntherefore, rewrite the inequality as\nL(Xk+1) ≤L(Xk) −α||∇L(Xk)||2 + Lα2\n2 ||∇L(Xk)||2.\n(13)\nBy deﬁning µ = α −Lα2\n2\nfor 0 < α < 2\nL and µ > 0, we have\nL(Xk+1) ≤L(Xk) −µ||∇L(Xk)||2.\n(14)\nSince F(X) is bounded, we can sum this inequality over K ∈\n{0, 1, . . . , K −1} and accordingly get:\nL(XK) ≤L(X0) −µ\nK−1\nX\nk=0\n||∇L(Xk)||2.\n(15)\nBy rearranging the above inequality, we have\nµ\nK−1\nX\nk=0\n||∇L(Xk)||2 ≤L(X0) −L(XK) ≤L(X0).\n(16)\nSince L(X0) is bounded within [0, 1], we can conclude\nK−1\nX\nk=0\n||∇L(Xk)||2 < ∞.\n(17)\nThe above inequality implies that ||∇L(Xk)||2 →0 as k →∞,\nshowing the gradient descent algorithm converges to a stationary\npoint where ∇L(X) = 0. Since L(X) is bounded and non-convex,\ngradient descent guarantees convergence to a stationary point within\n[0, 1] for inputs, though this may be a global minimum, local\nminimum or saddle point.\nGiven our probabilistic formulation, ∇L(X) can only be zero in\ntwo cases. The ﬁrst occurs when the ℓ2-loss (i.e., L(X)) is zero. This\nimplies that the output constraints are satisﬁed for the given inputs,\nand the inputs to the circuit must have converged to either 0 or 1, as\nthe outputs can only take discrete binary values when the inputs are\nalso discrete binary values in our formulation. This guarantees that\nthe inputs associated with a loss value of zero are satisfying solutions\nand, as such, represent global minima.\nThe second case in which ∇L(X) = 0 occurs when the logic gates\ncause the gradients to be zero through their derivative functions with\nrespect to their inputs (see Table I). For example, a single AND gate\ncannot reach an output of 1 through gradient descent if both of its\ninputs are initialized to zero. This results in a non-zero loss while\n∇L(X) remains zero, which is referred to as a saddle point. However,\nthis scenario is unlikely (though possible) to occur since the inputs are\nrandomly initialized within [0, 1]. Moreover, even if it does happen,\nit can be mitigated by regularization techniques such as input decay\nand noise injection.\nAlgorithm 1 Pseudo Code of our Backtracking Algorithm\n1: Input: The upper bound for clock cycles η, the number of\ntraining iterations itr, the target output valuation matrix Y\n2: Output: List of satisfying primary inputs PI\n3: for cc = 1 to η do\n4:\nfor j = 1 to itr do\n5:\nfor t = 1 to cc do\n6:\nPt = σ(Vt)\n7:\nYt = Fo(Pt, Ht−1)\n8:\nHt = Fh(Pt, Ht−1)\n9:\nend for\n10:\nL = P\nb,m\n\f\f\f\n\f\f\fY −ˆYcc\n\f\f\f\n\f\f\f\n2\n2\n11:\nL.backward()\n12:\noptimizer.step()\n13:\nif P is satisﬁable then\n14:\nAppend P to PI\n15:\nend if\n16:\nend for\n17: end for\n18: Return PI\nC. Backtracking Algorithm\nGiven our differentiable recurrent sampling method described in\nSection III-A, we now introduce a backtracking algorithm that can\ngenerate satisfying input solutions of varying lengths based on\nspeciﬁc design constraints. All generated solutions are constrained\nto have their initial state values set to zero. We begin the sampling\nprocess by deﬁning the upper bound for the number of clock cycles,\ndenoted as η. The goal is to generate solutions where the required\nnumber of clock cycles for each sample is less than or equal to\nthis upper bound. Starting with the design constraint on the output\nof a sequential circuit, we run the differentiable recurrent sampling\nmethod for one clock cycle and generate potential solutions. If the\ngenerated solutions meet the design constraint, they are stored; other-\nwise, they are discarded. This process is repeated for 2 clock cycles,\ncontinuing the same procedure. The cycle-by-cycle sampling process\ncontinues incrementally until reaching the speciﬁed upper limit on\nclock cycles. By then, we will have solutions that require varying\nnumbers of clock cycles. It is possible, however, that for certain\nnumbers of clock cycles, no solutions are found, as the constraints\nmay not be satisﬁable for those speciﬁc cycle lengths. Without loss\nof generality, a lower bound can also be deﬁned for the number of\nclock cycles, ensuring that the generated solutions fall within a user-\nspeciﬁed range. Algorithm 1 summarizes the backtracking algorithm.\nIV. EXPERIMENTAL RESULTS\nIn this section, we showcase the effectiveness of our sampling\napproach. To this end, we implemented a prototype of our method\nusing PyTorch, an open-source library that merges Torch’s GPU-\noptimized backend with a Python-compatible interface. For a com-\nprehensive evaluation, we utilize the complete ISCAS-89 and ITC’99\nbenchmark suites, incorporating all components. Our experiments\nwere conducted on a system with an Intel Xeon E5-2698 processor\nrunning at 2.2 GHz and 8 NVIDIA V100 GPUs, each equipped\nwith 32 GB of memory. We assess the runtime performance of our\nmethod based on throughput, deﬁned as the number of unique and\nvalid solutions produced per second. GD was used as the optimizer\nduring training, with a learning rate of 50 and a total of 5 iterations.\nDepending on the size of each CircuitSAT instance, we adjust the\n\n\nTable II: The runtime performance of sampler is evaluated in terms of unique solution throughput for sequential circuits.\nCircuitSAT\n# Primary\n# Primary\n# Logic\n# DFF\n# Variables\n# Clauses\nThroughput (# Unique Solutions per Second)\nInstance\nInputs\nOutputs\nGates\n(CNF)\n(CNF)\nThis work\nCMSGEN\ns208.1\n10\n1\n104\n8\n7696\n7371\n114,242.4 (105.1×)\n1087.2\ns386\n7\n7\n159\n6\n12, 790\n12, 609\n35,849.5 (65.6×)\n546.6\ns526\n3\n6\n193\n21\n16, 772\n16, 692\n15,978.6 (32.6×)\n490.8\ns832\n18\n19\n287\n5\n25, 386\n24, 919\n5,700.4 (30.5×)\n186.9\ns1196\n14\n14\n529\n18\n38, 592\n38, 230\n5,651.1 (51.7×)\n109.4\ns4863\n49\n16\n2342\n104\n166, 035\n164, 796\n157.6 (75.0×)\n2.1\ns15850.1\n77\n150\n9772\n534\n606, 514\n604, 444\n14.5 (3.7×)\n3.9\ns38584\n12\n278\n19, 253\n1, 452\n1, 357, 767\n1, 357, 194\n1.7 (2.1×)\n0.8\nb01\n2\n2\n45\n5\n3, 205\n3, 154\n54,774.3 (18.2×)\n3, 012.6\nb06\n2\n6\n56\n9\n3, 271\n3, 216\n173,909.9 (66.5×)\n2, 614.3\nb10\n11\n6\n206\n17\n13, 963\n13, 683\n5,463.6 (13.8×)\n396.8\nb12\n5\n6\n1, 076\n121\n78, 559\n78, 429\n402.5 (4.1×)\n98.2\nb15\n36\n70\n8, 922\n449\n660, 026\n659, 059\n3.1 (15.5×)\n0.2\nb17\n37\n97\n32, 326\n1, 415\n2, 379, 165\n2, 378, 145\n0.2\nTO\nb19\n24\n30\n231, 320\n6, 642\n16, 819, 969\n16, 819, 339\n0.01\nTO\nb22\n32\n22\n29, 951\n735\n2, 183, 304\n2, 182, 485\n0.5 (5×)\n0.1\nbatch size between 100 and 1, 000, 000. It is also noteworthy that the\nmaximum sample count generated by our sampler is limited by the\nproduct of the batch size and the maximum number of clock cycles\n(i.e., η). For our experiments, we set the maximum clock cycle limit\nto η = 50.\nA. Runtime Performance\nIn sequential circuit sampling, the goal is to identify input se-\nquences of varying lengths (i.e., requiring different numbers of clock\ncycles) that satisfy given output constraints. To transform these\ncircuits into CircuitSAT sampling problems, we randomly assign\nspeciﬁc binary values to certain output nodes. Table II presents the\nsampling performance of our recurrent CircuitSAT sampler in terms\nof throughput, deﬁned as the number of unique input sequences\ngenerated per second, for a representative set of 16 sequential\nCircuitSAT instances from the ISCAS-89 and ITC’99 benchmark\nsuites. The generated samples are input sequences with clock cycles\nranging from 1 to 50. Producing valid input sequences of different\nlengths is essential for sequential CircuitSAT sampling, as speciﬁc\noutput constraints may preclude solutions at certain clock cycle\nlengths. Furthermore, samples with varying sequence lengths (i.e.,\nclock cycles) enable the detection of both static logic faults and\ndynamic issues related to timing and state transitions.\nTo compare runtime performance with previous works, we unrolled\nthe sequential circuits in the ISCAS-89 and ITC’99 benchmark suites\nover 25 clock cycles, converting the resulting combinational circuit to\nCNF using the Tseitin transformation. For this CircuitSAT sampling\nprocess, we applied the same output constraints used in our recurrent\nsampler experiments. These output constraints were initially set to\nensure the existence of solutions at 25 clock cycles. We selected 25\nclock cycles as it represents the average of all clock cycles (ranging\nfrom 1 to 50) used in our sampling experiments.\nWe compare the runtime performance of our recurrent CircuitSAT\nsampler with state-of-the-art SAT sampling methods, speciﬁcally\nUNIGEN3 [26], CMSGEN [27], and DIFFSAMPLER [17], each tasked\nwith generating at least 1, 000 solutions within a 4-hour timeframe.\nWhile these samplers work directly on the CNF representations of\nCircuitSAT instances, our sampler operates on the sequential circuits\nthemselves, preserving their original structure and temporal behavior.\nBoth UNIGEN3 and CMSGEN are optimized C++ implementations,\nwhile DIFFSAMPLER is a Python-based SAT sampler that leverages\nJAX for GPU acceleration. UNIGEN3 and CMSGEN were tested on a\nserver-grade AMD EPYC 9274F CPU with the maximum frequency\nof 4.3 GHz and 1 TB of RAM, whereas DIFFSAMPLER was evaluated\n0\n10\n20\n30\n40\n50\n10−2\n100\n102\n104\n106\nNumber of Clock Cycles\n[log scale] Throughput\n(# Unique Solutions per Second)\nISCAS-89\nITC’99\nFigure 3: A log plot showing the runtime performance of our recurrent\nsampler in terms of throughput, measured as the number of unique\nsatisfying solutions per second, versus the number of clock cycles\nacross all instances from the ISCAS-89 and ITC’99 benchmark suites.\nThe throughput values are rounded to two decimal places in this plot.\non a system with an Intel Xeon E5-2698 processor at 2.2 GHz and\n8 NVIDIA V100 GPUs, each with 32 GB of memory.\nOur experiments show that UNIGEN3 and DIFFSAMPLER can only\ngenerate solutions for the CircuitSAT instance “s27” with throughputs\nof 58, 180.0 and 64, 458.4, respectively. For this speciﬁc CircuitSAT\ninstance, our recurrent sampler outperforms both UNIGEN3 and\nDIFFSAMPLER by factors of 4.3× and 3.9×, respectively. On the\nother hand, CMSGEN generates solutions across the majority of\nCircuitSAT instances, as shown in Table II. According to Table II,\nour recurrent CircuitSAT sampler achieves up to a 105.1× increase\nin throughput compared to CMSGEN. Furthermore, our recurrent\nsampler consistently outperforms CMSGEN, achieving an average\nspeedup of 24.3× across all instances for which CMSGEN generated\nsolutions. Figure 3 illustrates the throughput of our sampler across\nvarious clock cycle counts for all instances from the ISCAS-89\nand ITC’99 benchmark suites, with throughput values rounded to\ntwo decimal places in the plot. This ﬁgure demonstrates that our\nsampler can produce input sequences of different lengths for a given\nCircuitSAT problem. Notably, some instances lack solutions that meet\nthe speciﬁed output constraints at certain clock cycles.\n\n\n0\n10\n20\n30\n40\n50\n0\n20\n40\n60\n80\n100\nNumber of Clock Cycles\nPercentage of Unique\nSolutions (%)\ns3271\nb02\nb08\nFigure 4: A plot illustrating the percentage of unique solutions\ngenerated by our recurrent sampler over 50 clock cycles for three\nrepresentative CircuitSAT instances. The batch size for this experi-\nment is set to 100, 000.\nFor conventional samplers, including CMSGEN, UNIGEN3, and\nDIFFSAMPLER, we ﬁxed the number of clock cycles at 25 to ensure\na fair runtime performance comparison. However, these samplers can\nalso be used to generate input sequences over varying clock cycles.\nThis approach, however, requires transforming the sequential circuit\ninto a separate CNF for each clock cycle, which leads to an increase\nin CNF size with the number of clock cycles. In contrast, our method\nrecursively computes forward computations for any desired number of\nclock cycles (see Algorithm 1) and calculates gradients with respect\nto inputs as described in Section III-A.\nB. Learning Dynamics\nHere, we present the learning dynamics of our recurrent sampler\nfor a few representative sequential CircuitSAT instances. We begin\nby analyzing the distribution of the generated input sequences across\n50 clock cycles. The randomly speciﬁed output constraints ensure the\nexistence of satisfying solutions at the 25th clock cycle for runtime\ncomparisons with prior works. However, there is no guarantee of so-\nlutions existing for other clock cycles. For example, Fig. 4 highlights\nthree representative sequential CircuitSAT instances, showcasing the\npercentage of valid and unique solutions generated by our sampler\n(calculated as the number of unique solutions divided by the batch\nsize) for speciﬁc clock cycles.\nFig. 5 shows the learning progress of our recurrent sampler,\nshowing the total number of unique solutions generated over ﬁve\niterations. The learning curves indicate that as the number of it-\nerations increases, the total number of unique solutions identiﬁed\nby our sampler over 50 clock cycles also grows. This aligns with\nour theoretical convergence proof, which shows that gradient descent\ncan reach a global minimum, achieving zero-valued loss in the\nnon-convex landscapes of our continuous formulation for sequential\nCircuitSAT problems. Of course, the convergence rate varies across\nCircuitSAT instances, inﬂuenced by the complexity and structure of\nthe sequential circuit, as well as the hyper-parameters selected for\nthe learning process.\nV. RELATED WORK\nOver the years, researchers have developed various Circuit-\nSAT/SAT sampling strategies. Among these, tools like UNIGEN3\naim to maintain approximate uniformity in sampling [32], while\nCMSGEN and QUICKSAMPLER [10] prioritize speed and efﬁciency.\nEfforts to exploit data-parallel hardware for SAT solving have largely\nrevolved around accelerating CDCL and heuristic-based methods\n[33], [34]. More recently, approaches such as MATSAT [35] and\nNEUROSAT [36] have reimagined SAT problems as constrained\noptimization tasks over continuous domains. However, these inno-\nvations have primarily targeted small, random benchmarks, leaving\n1\n2\n3\n4\n5\n104\n105\n106\n# Training Iterations\n# Unique\nSolutions\ns3271\nb02\nb08\nFigure 5: A log plot illustrating the number of unique solutions\ngenerated by our recurrent sampler over 5 training iterations for three\nrepresentative CircuitSAT instances.\ntheir potential for large-scale and standard benchmarks unrealized,\nparticularly with GPU-accelerated sampling. The introduction of\nDIFFSAMPLER [17] marks a turning point by demonstrating com-\npetitive performance in GPU-accelerated SAT sampling on widely\nused benchmarks, rivaling methods like UNIGEN3 and CMSGEN.\nComplementing this, DEMOTIC [11] offers a GPU-powered, sampling\nsolution tailored for combinational CircuitSAT in CRV, operating\ndirectly on hardware description language representations such as\nVerilog.\nDespite the high runtime performance of the aforementioned\nCircuitSAT samplers, they are primarily designed for combinational\ncircuits. Recently, a symbolic algorithm based on Algebraic Decision\nDiagrams, called TRACESAMPLER, has been introduced to sample\nbounded traces (i.e., sequences of states) in sequential circuits with\nguaranteed uniformity [19]. However, TRACESAMPLER focuses on\nuniform sampling of ﬁxed-length traces, typically starting from a\ndeﬁned initial state, without applying constraints on the circuit’s\nprimary outputs.\nUnlike the previous sampling approaches, our sampler takes a\nfundamentally different approach. Our formulation reframes the sam-\npling procedure as an optimization task that can be minimized using\ngradient descent under speciﬁed output constraints, with a theoretical\nproof of convergence to a stationary point. During optimization,\nforward and backward computations are performed recurrently over\nany number of clock cycles without unrolling the circuit (i.e.,\nconverting it to a combinational circuit). This allows sampling from\nthe solution space across varying clock cycles, which is crucial for\ndetecting timing-related and state-transition faults. Additionally, due\nto the parallel nature of this optimization process across different data\nbatches, our method can be accelerated using GPUs. Consequently,\nour sampler outperforms the state-of-the-art (i.e., CMSGEN) in terms\nof runtime performance across all CircuitSAT instances from the\nISCAS-89 and ITC’99 benchmark suites.\nVI. CONCLUSION\nIn this work, we introduced a novel GPU-accelerated CircuitSAT\nsampling approach tailored for sequential circuits, addressing key\nchallenges in CRV. By reframing the sampling process as a recurrent\noptimization problem and utilizing gradient descent, our method\nefﬁciently generates input stimuli along with the required clock\ncycles, ensuring compliance with design constraints. We provided\ntheoretical guarantees showing that minimizing this recurrent opti-\nmization process via gradient descent converges to a stationary point,\nwith a high likelihood of reaching a global minimum by incorporating\nregularization techniques to avoid saddle points. Operating directly on\nthe circuit structure without unrolling state transitions, our approach\nredeﬁnes sampling as a differentiable multi-output regression task, en-\nabling highly parallel computations and delivering substantial runtime\nimprovements. Extensive evaluations on benchmark suites such as\n\n\nISCAS-89 and ITC’99 demonstrate the effectiveness and scalability\nof our method, achieving up to 105.1× higher throughput compared\nto state-of-the-art samplers. This work lays the foundation for more\nefﬁcient veriﬁcation methods for sequential systems and paves the\nway for integrating differentiable sampling techniques into broader\nhardware design and validation processes.\nREFERENCES\n[1] H. D. Foster, “Trends in functional veriﬁcation: a 2014 industry study,”\nin Proceedings of the 52nd Annual Design Automation Conference, ser.\nDAC ’15. New York, NY, USA: Association for Computing Machinery,\n2015. [Online]. Available: https://doi.org/10.1145/2744769.2744921\n[2] L. Bening et al., Principles of Veriﬁable RTL Design, 2nd ed.\nUSA:\nKluwer Academic Publishers, 2001.\n[3] J. Bhadra et al., “A survey of hybrid techniques for functional\nveriﬁcation,” IEEE Des. Test, vol. 24, no. 2, p. 112–122, Mar. 2007.\n[Online]. Available: https://doi.org/10.1109/MDT.2007.30\n[4] N. Kitchen et al., “Stimulus generation for constrained random simula-\ntion,” in Proceedings of the 2007 IEEE/ACM International Conference\non Computer-Aided Design, ser. ICCAD ’07.\nIEEE Press, 2007, p.\n258–265.\n[5] Y. Naveh et al., “Constraint-based random stimuli generation for hard-\nware veriﬁcation,” in Proceedings of the 18th Conference on Innovative\nApplications of Artiﬁcial Intelligence - Volume 2, ser. IAAI’06.\nAAAI\nPress, 2006, p. 1720–1727.\n[6] J. Yuan et al., Constraint-Based Veriﬁcation, 1st ed. Springer Publishing\nCompany, Incorporated, 2010.\n[7] N. Kitchen et al., “Stimulus generation for constrained random simula-\ntion,” in 2007 IEEE/ACM International Conference on Computer-Aided\nDesign, 2007, pp. 258–265.\n[8] Y. Zhao et al., “Random stimulus generation with self-tuning,” in 2009\n13th International Conference on Computer Supported Cooperative\nWork in Design, 2009, pp. 62–65.\n[9] R. Naveh et al., “Beyond feasibility: Cp usage in constrained-random\nfunctional hardware veriﬁcation,” in Principles and Practice of Con-\nstraint Programming, C. Schulte, Ed.\nBerlin, Heidelberg: Springer\nBerlin Heidelberg, 2013, pp. 823–831.\n[10] R. Dutra et al., “Efﬁcient sampling of sat solutions for testing,” in Proc.\nof the International Conference on Software Engineering, 2018.\n[11] A. Ardakani et al., “DEMOTIC: A differentiable sampler for multi-level\ndigital circuits,” in Proceedings of the 30th Asia and South Paciﬁc Design\nAutomation Conference (ASP-DAC 2025), 2025.\n[12] A. Mishchenko et al., “Sat-based complete don’t-care computation for\nnetwork optimization,” in Proceedings of the Conference on Design,\nAutomation and Test in Europe - Volume 1, ser. DATE ’05.\nUSA:\nIEEE Computer Society, 2005, p. 412–417.\n[13] S. Tsai et al., “A false-path aware formal static timing analyzer consid-\nering simultaneous input transitions,” in Proceedings of the 46th Annual\nDesign Automation Conference, ser. DAC ’09.\nNew York, NY, USA:\nAssociation for Computing Machinery, 2009, p. 25–30.\n[14] A. R. Bradley, “Sat-based model checking without unrolling,” in Pro-\nceedings of the 12th International Conference on Veriﬁcation, Model\nChecking, and Abstract Interpretation, ser. VMCAI’11.\nBerlin, Hei-\ndelberg: Springer-Verlag, 2011, p. 70–87.\n[15] A. Mishchenko et al., “Improvements to combinational equivalence\nchecking,” in Proceedings of the 2006 IEEE/ACM International Con-\nference on Computer-Aided Design, ser. ICCAD ’06.\nNew York, NY,\nUSA: Association for Computing Machinery, 2006, p. 836–843.\n[16] H.-T. Zhang et al., “A circuit-based sat solver for logic synthesis,” in\n2021 IEEE/ACM International Conference On Computer Aided Design\n(ICCAD).\nIEEE Press, 2021, p. 1–6.\n[17] A. Ardakani et al., “Late breaking results: Differential and massively\nparallel sampling of sat formulas,” in Proceedings of the 61st ACM/IEEE\nDesign Automation Conference (DAC), 2024.\n[18] G. S. Tseitin, “On the complexity of derivation in propositional calcu-\nlus,” Automation of reasoning: 2: Classical papers on computational\nlogic 1967–1970, pp. 466–483, 1983.\n[19] S. Chakraborty et al., “On uniformly sampling traces of a transition\nsystem,” in Proceedings of the 39th International Conference on\nComputer-Aided Design, ser. ICCAD ’20.\nNew York, NY, USA:\nAssociation for Computing Machinery, 2020. [Online]. Available:\nhttps://doi.org/10.1145/3400302.3415707\n[20] M. Davis et al., “A machine program for theorem-proving,” Commun.\nACM, vol. 5, no. 7, p. 394–397, jul 1962.\n[21] B. Selman et al., “Local search strategies for satisﬁability testing.”\nCliques, coloring, and satisﬁability, vol. 26, pp. 521–532, 1993.\n[22] J. Marques Silva et al., “Grasp-a new search algorithm for satisﬁability,”\nin Proceedings of International Conference on Computer Aided Design,\n1996, pp. 220–227.\n[23] J. Marques-Silva et al., Chapter 4: Conﬂict-driven clause learning SAT\nsolvers, ser. Frontiers in Artiﬁcial Intelligence and Applications.\nIOS\nPress BV, 2021, pp. 133–182, publisher Copyright: © 2021 The authors\nand IOS Press. All rights reserved.\n[24] R. Impagliazzo et al., “Does Looking Inside a Circuit Help?” in 42nd\nInternational Symposium on Mathematical Foundations of Computer\nScience (MFCS 2017), ser. Leibniz International Proceedings in Infor-\nmatics (LIPIcs), vol. 83, 2017, pp. 1:1–1:13.\n[25] N. Kitchen et al., “A markov chain monte carlo sampler for mixed\nboolean/integer constraints,” in Computer Aided Veriﬁcation: 21st In-\nternational Conference, CAV 2009, Grenoble, France, June 26-July 2,\n2009. Proceedings 21.\nSpringer, 2009, pp. 446–461.\n[26] M. Soos et al., “Tinted, detached, and lazy cnf-xor solving and its\napplications to counting and sampling,” in Proceedings of International\nConference on Computer-Aided Veriﬁcation (CAV), 2020.\n[27] P. Golia et al., “Designing samplers is easy: The boon of testers,” in\nProc. of Formal Methods in Computer-Aided Design (FMCAD), 2021.\n[28] H. Borchani et al., “A survey on multi-output regression,” Wiley Inter-\ndisciplinary Reviews: Data Mining and Knowledge Discovery, vol. 5,\nno. 5, pp. 216–233, 2015.\n[29] A. Ardakani et al., “Vlsi implementation of deep neural network using\nintegral stochastic computing,” IEEE Transactions on Very Large Scale\nIntegration (VLSI) Systems, vol. 25, no. 10, pp. 2688–2699, 2017.\n[30] D. Harris et al., “Cmos vlsi design,” ed: Pearson Education, Inc, 2010.\n[31] A. A. Goldstein, “Optimization of lipschitz continuous functions,” Math-\nematical Programming, vol. 13, pp. 14–22, 1977.\n[32] Y. Pote et al., “On scalable testing of samplers,” in Advances in Neural\nInformation Processing Systems (NeurIPS), 2022.\n[33] C. Costa, “Parallelization of sat algorithms on gpus,” Technical report,\nINESC-ID, Technical University of Lisbon, Tech. Rep., 2013.\n[34] M. Osama et al., “Sat solving with gpu accelerated inprocessing,” in\nInternational Conference on Tools and Algorithms for the Construction\nand Analysis of Systems.\nSpringer, 2021, pp. 133–151.\n[35] T. Sato et al., “Matsat: a matrix-based differentiable sat solver,” arXiv\npreprint arXiv:2108.06481, 2021.\n[36] S. Amizadeh et al., “Learning to solve circuit-sat: An unsupervised\ndifferentiable approach,” in International Conference on Learning Rep-\nresentations, 2018.\n\n\n",
  "metadata": {
    "source_file": "dataset/pdfs/arxiv_2502.21226v2.pdf",
    "total_pages": 7,
    "title": "Recurrent CircuitSAT Sampling for Sequential Circuits",
    "authors": [
      "Arash Ardakani",
      "Kevin He",
      "John Wawrzynek"
    ],
    "abstract": "In this work, we introduce a novel GPU-accelerated circuit satisfiability\n(CircuitSAT) sampling technique for sequential circuits. This work is motivated\nby the requirement in constrained random verification (CRV) to generate input\nstimuli to validate the functionality of digital hardware circuits. A major\nchallenge in CRV is generating inputs for sequential circuits, along with the\nappropriate number of clock cycles required to meet design constraints.\nTraditional approaches often use Boolean satisfiability (SAT) samplers to\ngenerate inputs by unrolling state transitions over a fixed number of clock\ncycles. However, these methods do not guarantee that a solution exists for the\ngiven number of cycles. Consequently, producing input stimuli together with the\nrequired clock cycles is essential for thorough testing and verification. Our\napproach converts the logical constraints and temporal behavior of sequential\ncircuits into a recurrent CircuitSAT problem, optimized via gradient descent to\nefficiently explore a diverse set of valid solutions, including their\nassociated number of clock cycles. By operating directly on the circuit\nstructure, our method reinterprets the sampling process as a supervised\nmulti-output regression task. This differentiable framework enables independent\nelement-wise operations on each tensor element, facilitating parallel execution\nduring learning. As a result, we achieve GPU-accelerated sampling with\nsubstantial runtime improvements (up to 105.1x) over state-of-the-art heuristic\nsamplers. We demonstrate the effectiveness of our method through extensive\nevaluations on circuit problems from the ISCAS-89 and ITC'99 benchmark suites.",
    "published_date": "2025-02-28",
    "source": "arxiv"
  }
}