{
  "id": "arxiv_2502.21156v1",
  "text": "arXiv:2502.21156v1  [cs.CR]  28 Feb 2025\nCryptis: Cryptographic Reasoning in Separation Logic\nARTHUR AZEVEDO DE AMORIM, Rochester Institute of Technology, USA\nAMAL AHMED, Northeastern University, USA\nMARCO GABOARDI, Boston University, USA\nWe introduce Cryptis, an extension of the Iris separation logic that can be used to verify cryptographic com-\nponents using the symbolic model of cryptography. The combination of separation logic and cryptographic\nreasoning allows us to prove the correctness of a protocol and later reuse this result to verify larger systems\nthat rely on the protocol.To make this integration possible, we propose novel speciﬁcations for authentication\nprotocols that allow agents in a network to agree on the use of system resources. We evaluate our approach\nby verifying various authentication protocols and a key-value store server that uses these authentication\nprotocols to connect to clients. Our results are formalized in Coq.\n1\nINTRODUCTION\nComputer systems rely on various resources, such as IO devices, shared memory, cryptographic\nkeys, random number generators or network connections. The proper management of these re-\nsources is essential to ensure that each system behaves correctly, in particular in regards to secu-\nrity and privacy. However, enforcing this discipline is nontrivial, especially when resources are\nshared by multiple components that might interfere with each other. For example, a networked\nsystem might rely on cryptographic protocols to secure its connections, and if cryptographic keys\nor sources of randomness are not shared between diﬀerent components with care, the security of\nthe overall system may get compromised. Good tool support can rule out potential conﬂicts in the\nuse of shared resources, making the system more reliable and secure.\nA great tool for reasoning about resources is separation logic [46, 15, 43, 16]. Assertions in sepa-\nration logic denote the ownership of resources, and if a program meets a speciﬁcation, it is guaran-\nteed not to aﬀect any resources that are disjoint from those mentioned in its pre- or postconditions.\nThe notion of disjointness is embodied by a special connective, the separating conjunction, that\nasserts that multiple resources can be used independently, without conﬂict. What constitutes a\nresource and a conﬂict depends on the application at hand. Originally [46], the resources were\ndata structures in memory, and the separating conjunction guaranteed the absence of aliasing. In\nmodern versions of the logic, this has been generalized to cover other types of resources, such as\nthe state of a concurrent protocol [29] or sources of randomness [9, 7, 37].\nBy describing precisely what resources each component can use, and how they are used, separa-\ntion logic brought a key advancement to program veriﬁcation: compositionality. We can verify each\ncomponent in isolation, without knowing exactly what other resources might be used elsewhere.\nLater, we can argue that the entire system is correct, provided that the resources used by each\ncomponent are separate at the beginning of the execution. This allows the logic to scale to large\nsystems, including many that were challenging to handle with prior techniques, such as concur-\nrent or distributed ones. And thanks to its rich, expressive speciﬁcation language, the logic can be\nused to reason about a wide range of components with diverse purposes. Individual proofs of cor-\nrectness can be composed in a uniﬁed formalism, thus ruling out bugs due to possible mismatches\nbetween the guarantees of one component and the requirements of another.\nDue to the relative novelty of separation logic, however, the power of such compositional rea-\nsoning remains unexplored in many applications. Among many examples, we can cite applications\ninvolving cryptographic protocols. Cryptographic protocols are a crucial component of distributed\nPL’18, January 01–03, 2018, New York, NY, USA\n2018.\n1\n\n\nPL’18, January 01–03, 2018, New York, NY, USA\nArthur Azevedo de Amorim, Amal Ahmed, and Marco Gaboardi\nsystems, which can only function correctly if the communication between the nodes satisﬁes basic\nintegrity and conﬁdentiality guarantees. Unfortunately, the design and implementation of proto-\ncols are diﬃcult to get right, leaving the systems that rely on these protocols open to attack. This\nhas led to the development of many techniques for verifying protocols. Some target the imple-\nmentation of the protocol and underlying cryptographic primitives, with the goal of ruling out\nmemory safety violations or other low-level bugs [24, 45]. Such properties are crucial for security,\nbut do not suﬃce to establish all the secrecy and integrity guarantees that we might expect out of\na protocol. Such higher-level properties are usually analyzed with specialized libraries or check-\ners [12, 14, 41]. Unfortunately, none of these tools can be readily integrated with separation logic\nor other general-purpose veriﬁcation formalisms. For example, consider DY* [12], a state-of-the-\nart system for protocol veriﬁcation that is implemented as a library in the language F*. Although\nF* is an expressive veriﬁcation tool and supports some separation logic [51, 25], DY* is built on\na custom eﬀect, an execution environment that oﬀers useful features for verifying a range of pro-\ntocols, but that does not currently support reasoning about general-purpose state or concurrency.\nWith current technology, if we are verifying a system that relies on the security guarantees of a\nprotocol, the best we can do is to remove the protocol from the model of the system, hardwire\nthe expected guarantees, and relate them informally the results of separate analyses using such\nspecialized tools.\nWhile convenient, this compromise is not innocuous. The most immediate (and dangerous) issue\nis that the model might mischaracterize the guarantees of the underlying cryptographic protocol,\neven if the protocol is formally veriﬁed. Such gaps might cause the system to behave incorrectly,\nopening the door to attacks. More insidiously, removing cryptography from the model prevents\nus from even stating, let alone verifying, what happens to a system when attackers gain control\nof some private keys—a common concern in modern protocols [22].\nOur contribution in this paper is a new separation logic, Cryptis, that extends Iris [32] with\nthe ability to reason about cryptographic components in the symbolic (or Dolev-Yao) model of\ncryptography. Cryptis allows us to produce integrated proofs of system speciﬁcations, where the\ncorrectness proof for the system can leverage not only the full power of Iris, but also the correct-\nness of the cryptographic protocols on which it is built. Protocol speciﬁcations are combined with\nthe proofs for the rest of the system in a uniﬁed formalism, thus avoiding potential mismatches.\nWe illustrate this workﬂow by implementing a key-value store, where a client communicates with\na storage server over an authenticated channel built on top of encryption. We prove that the client\nwrappers that communicate with the server can be given separation-logic speciﬁcations reminis-\ncent of how local state is modeled: a points-to resource describes which value the server stores\nunder a certain key, giving the client exclusive access to read it and modify it.\nA second contribution of this paper is to adapt the speciﬁcation of authentication protocols so\nthat they can be reused eﬀectively in separation logic. In the protocol veriﬁcation literature, au-\nthentication is seen as a means for agents to agree on a shared secret key, their identities, the order\nof events in the system, or protocol parameters [39]. Traditionally, such properties are expressed\nas predicates over traces of belief events. Since such events are ghost code that does not have any\nobservable eﬀect on execution, it is not immediately clear how these guarantees can be related to\nthe behavior of the rest of the system. Our authentication speciﬁcations establish a set of shared\nresources that the agents can use to coordinate their actions even after the handshake is completed.\nFor example, our key-value store leverages these resources to allow the client and the server to\nagree on the state of the database.\nA ﬁnal contribution of this paper is to demonstrate how our speciﬁcations allow us to assess\nthe security of a protocol through security games. This idea, which goes back to the wider crypto\n2\n\n\nCryptis: Cryptographic Reasoning in Separation Logic\nPL’18, January 01–03, 2018, New York, NY, USA\nliterature, consists of deﬁning code snippets where honest agents run a program along with an\nattacker. The code contains an assertion that embodies the security guarantee of the protocol. The\ngoal of the attacker is to cause the assertion to fail. The Cryptis speciﬁcations of authentication\nprotocols allows us to argue that attackers can never succeed against the agents, demonstrating\nhow Cryptis speciﬁcations allow us to illustrate rich guarantees such as forward secrecy [22]. A key\ningredient to make this possible is to treat the secrecy of a term as a separation-logic resource. This\nresource allows us to keep the long-term keys of honest agents secret while they are authenticating\nand compromise the keys only after the handshake completes. Moreover, since protocols can be\nintegrated within larger systems, we can use games to analyze the eﬀect of such compromise\nscenarios in the entire system—e.g. “this database operation returns the correct value even if the\nserver’s private key is compromised.” To the best of our knowledge, the analysis of high-level,\nwhole-system properties in the presence of key compromise is new.\nStructure of the paper. In Section 2, we introduce Cryptis by verifying a key-value storage service\nwhere clients and servers communicate using symmetric encryption and pre-shared keys. Then,\nwe discuss how to verify authentication protocols, which allow agents to exchange such symmetric\nencryption keys for establishing sessions. We present correctness proofs for the classic Needham-\nSchroeder-Lowe protocol [42, 39] (Section 3), which uses asymmetric encryption, and the ISO\nprotocol [33] (Section 4), which uses Diﬃe-Hellman key exchange and digital signatures. For the\nlatter, we show that the protocol guarantees forward secrecy: session keys remain secret even after\nlong-term keys are compromised. The authentication protocols can be reused to prove the cor-\nrectness of an authenticated, reliable channel abstraction (Section 5) which, in turn, can be used to\nincorporate an authentication step in our key-value store (Section 6). We implemented Cryptis in\nCoq using Iris [32], an extensible higher-order concurrent separation logic, and mechanized all our\ncase studies using the Iris proof mode [35] (Section 7). The implementation and the case studies\nare included in the supplementary material. We discuss related work in Section 8 and conclude in\nSection 9.\n2\nA TOUR OF CRYPTIS: IMPLEMENTING A KEY-VALUE STORE\nSuppose that Bob owns a company that oﬀers a key-value store service on the cloud. Alice is\nconsidering hiring this service for her own company, but would like guarantees about the integrity\nof her data. In particular, she might want to know that, if she does not change the value of a\nkey, she will read back the last value she stored. For this property to hold, the storage server\nmust authenticate every operation performed in the system; otherwise, an attacker might trick\nthe server into modifying Alice’s data without her consent.\nPrior veriﬁcation techniques made it diﬃcult to verify this system in an end-to-end fashion, sub-\nstantiating the high-level claims of correctness laid out above by appealing to basic properties of\ncryptographic primitives in the symbolic model of cryptography. The Cryptis logic was designed\nprecisely to make such arguments possible. As an introduction to the logic, we present a correct-\nness proof for such a storage service. The structure of the application is shown in Figure 1. Client\nwrappers are responsible for taking the data associated with a request, sending it to the server, and\nwaiting for the corresponding response. The server stores the client data in internal data structures.\nThe two agents communicate over a secure connection established by some authentication proto-\ncol. For the moment, we consider a simpliﬁed design that omits authentication, where clients and\nservers communicate using a pre-shared key and keep their connection alive permanently. (We\nwill lift this restriction later, in Section 6.)\nFigure 2 shows some of the key-value store functions implemented in a typical higher-order\nlanguage with networking primitives. The load function sends to the server the key that the client\n3\n\n\nPL’18, January 01–03, 2018, New York, NY, USA\nArthur Azevedo de Amorim, Amal Ahmed, and Marco Gaboardi\nMessaging\nlayer\nData structures\nWrappers\nServer\nClient\nAuthentication\nprotocol\nFig. 1. Structure of key-value store\n(* Client wrappers *)\nlet store db k v =\nlet c = db_connection db in\nwrite c [\"store\"; k; v]\nlet [=\"ack_store\"] = read c in\n()\nlet load db k =\nlet c = db_connection db in\nwrite c \"load\" k;\nlet [=\"ack_load\"; v] = read c in\nv\n(* Server handlers *)\nlet handle_store c db request =\nlet [k; v] = request in\ndb_store db k v;\nwrite c [\"ack_store\"]\nlet handle_load c db request =\nlet k = request in\nlet v = db_load db k in\nwrite c [\"ack_load\"; v]\nlet handler c db =\nhandle c\n[(\"store\", handle_store c db);\n(\"load\" , handle_load\nc db);\n(* ... *)];\nFig. 2. Key-value store functions\nwants to load from. The server sits in a loop waiting for the next message from the client (handler),\nand invokes a handler based on the type of message it received. When it receives the “load” mes-\nsage, it fetches the corresponding value from its local database and sends it back to the client.\nWhen the client wrapper gets the response back, it returns this value to the caller. To keep exam-\nples short, we’ll use a syntax inspired by the ProVerif protocol analyzer [14]: let declarations can\nmention patterns of the form =p, which are only matched by p itself. Any errors that arise during\nexecution, such as failed pattern matching, cause the code to return None. (Formally, these errors\nare managed using the option monad, and let in our code snippets should be read as monadic\nbind.)\nThe code uses two functions, write and read, that send and receive data through a bidirectional\nconnection 푐. These functions are not baked into Cryptis, but deﬁned in terms of more basic primi-\ntives. In the remainder of this section, we will introduce several core features of Cryptis and show\nhow they can be used to implement and verify the higher-level functionality needed for the key-\nvalue store. Rather than presenting all of Cryptis at once, we will proceed in a step-by-step manner,\nintroducing these features as needed to encode the application functionality. Here and through-\nout, ﬁgures with assertions and proof rules marked as “Core Cryptis” refer to these core features,\n4\n\n\nCryptis: Cryptographic Reasoning in Separation Logic\nPL’18, January 01–03, 2018, New York, NY, USA\n푃,푄:= · · · | senc_pred 푠휑| senc_key 푘| public 푡| · · ·\n푃∈{senc_pred 푠휑, senc_key 푡, public 푡}\npersistent(푃)\nSend\n{⊲public 푡} send푡{True}\nRecv\n{True} recv() {푡, public 푡}\nPublicInt\npublic 푛\nPublicPair\npublic (푡1,푡2) ⇐⇒public 푡1 ∗public 푡2\nPublicSEncPublic\npublic 푘\npublic 푡\npublic (senc 푘푡)\nPublicSEnc\nsenc_pred 푠휑\n⊲\u001f휑푘[푡1; . . . ;푡푛]\n\u001f(public 푘⇒∗\n푖\npublic 푡푖)\npublic (senc 푘[푠;푡1; . . . ;푡푛])\nSDec\nsenc_pred 푠휑\n{senc_key 푘∗public 푡} sdec 푘푡\n\n\n푟,\n푟= None ∨∃푡′,푟= Some 푡′ ∗∀®푡,푡′ = (푠:: ®푡)\n⇛⊤public 푘∗public ®푡\n∨\u001f휑푘®푡∗\u001f(public 푘⇒public ®푡)\n\n\nFig. 3. Core Cryptis: Rules for symmetric encryption.\nwhereas other ﬁgures refer to application-speciﬁc deﬁnitions that leverage these features as well\nas the rest of Iris.\n2.1\nNetworking and Symmetric Encryption\nFor the key-value store to work, communication must be reliable: the messages must be delivered\nin the same order they were sent, without duplicates, and they must not be tampered with. If that\nweren’t the case, the client’s load function might return an outdated value, a value that corresponds\nto the wrong key, or even a value that was chosen arbitrarily by an attacker.\nOne way of obtaining this guarantee is to use symmetric encryption to protect the integrity of\nmessages sent through an unreliable network. Figure 3 presents the Cryptis rules for reasoning\nabout these functionalities. We use the metavariables 푘and 푡to range over cryptographic terms,\nwhich are values that exclude anything that cannot be meaningfully sent over the network, such\nas pointers or closures. The metavariable 푘will be used speciﬁcally for terms that serve as sym-\nmetric encryption keys. The assertion senc_pred 푠휑allows us to associate a message invariant 휑\nwith messages tagged with the tag 푠(a string). The assertion senc_key 푘means that 푘is a valid\nsymmetric encryption key. The assertion public 푡means that 푡can be seen in clear text by anyone,\nincluding malicious agents.\nSome of the connectives in the ﬁgure refer to features inherited from Iris. For space reasons, we\nwill focus on the Cryptis extensions, and refer readers to Jung et al. [32] for more background on\nthe other features. The ⊲symbol refers to the later modality of Iris, which is used to state recursive\ndeﬁnitions while avoiding paradoxes. The assertion \u001f 푃means that 푃holds persistently, without\nholding any resources. The assertion 푃⇛E 푄means that we can make 푄hold by consuming the\nresource 푃, modifying ghost state and accessing invariants under any namespace N ∈E.\nThe functions send and recv allow programs to communicate with the network. Cryptis assumes\na Dolev-Yao, or symbolic, model, where the network is controlled by an attacker has the power to\ndrop, duplicate, or manipulate network messages arbitrarily by applying cryptographic operations,\n5\n\n\nPL’18, January 01–03, 2018, New York, NY, USA\nArthur Azevedo de Amorim, Amal Ahmed, and Marco Gaboardi\nand where cryptographic operations behave as perfect black boxes. It is impossible to manipulate\nmessages directly as bit strings, or to guess nonces or keys out of thin air, by sampling.\nTo guarantee that information is manipulated securely, Cryptis only allows public terms through\nthe network. The rule for send requires us to show that the term we send is public; conversely, the\nrule for recv guarantees that the term we receive from the network is public. Since the network\nis controlled by the attacker, public terms are preserved by the Cryptis operations, to guarantee\nthat the attacker can only derive public terms from what is sent through the network. For example,\npairing two public terms results in a public term, encrypting a public term with a public symmetric\nkey yields another public term, and any integer 푛is public. (Note that this last point does not mean\nthat all terms are public: because Cryptis works in the Dolev-Yao model, there are many terms that\ndo not correspond to integers, such as nonces and secret keys.) We deﬁne public as a persistent\npredicate so that messages can be duplicated arbitrarily.\nOther rules allow honest agents to derive public terms from other terms that are not necessarily\npublic. The PublicSEnc rule says that we can prove that an encrypted term senc 푘[푠;푡1; . . . ;푡푛]\nis public provided that (1) the payload terms 푡1, ..., 푡푛can be considered public if the key 푘is ever\nleaked to an attacker, and (2) 휑푘[푡1; . . . ;푡푛] holds, where 휑is the predicate associated with the tag\n푠. The rationale for (1) is that, if 푘is ever leaked to an attacker, the attacker will be able to open\nthe message, so we need to prove that the payload is public in that case. As for (2), the Cryptis\nlogic is parameterized by a mapping that associates each tag 푠with a message invariant 휑, which\nis captured by the predicate senc_pred 푠휑. Any set of message invariants can be chosen, provided\nthat at most one invariant is used for each tag, and provided that the same invariants are used\nthroughout the entire proof.\nThe speciﬁcation for sdec says that decryption either fails, returning None, or succeeds, return-\ning the payload of the encrypted message. In the case of success, if the message is tagged with 푠,\nthen either the payload is public (for example, because the message was encrypted by the attacker),\nor the message invariant that corresponds to 푠holds. This type of case analysis is common in the\nliterature on protocol veriﬁcation [5, 6].\n2.2\nImplementing Reliable Communication\nFigure 4 shows the implementation and speciﬁcation of the client primitives for reliable connec-\ntions. The implementation simply wraps a message with a corresponding sequence number before\nencrypting it and sending it over the network. For simplicity, we assume two restrictions: only al-\nlow public terms to be sent and received, and the agents take turns sending messages (the client\nsends a request, and the server replies). We use 푐to refer to the address of a connection object, a\nrecord containing a symmetric key 푘and a counter 푛of how many messages the client has sent.\nThe predicate conn 푐푘푛means that 푐is a well-formed connection object. These counters are up-\ndated when sending and receiving messages to check if the received message is the next one to be\nsent, and the message number is tracked separately in the corresponding message predicate. Apart\nfrom that, the speciﬁcations are similar to those for symmetric encryption. To send a message, we\nneed to prove that the corresponding invariant holds; when we receive a message, we learn that\neither the corresponding encryption key was compromised, or that the message invariant holds.\nThe speciﬁcations are not the strongest possible; in particular, nothing guarantees that a message\nis uniquely determined by its sequence number. This is not needed, since we can use message\ninvariants themselves to impose an order on messages, as we will see next.\n2.3\nVerifying the Store\nNow that we have reliable communication, let us see how we can implement the key-value store.\nWe use some application-level resources described in Figure 5. We parameterize these resources\n6\n\n\nCryptis: Cryptographic Reasoning in Separation Logic\nPL’18, January 01–03, 2018, New York, NY, USA\nlet write c m =\nlet sent = c.sent in\nlet ciphertext =\nsenc c.key [\"conn\"; sent; m] in\nsend ciphertext\nlet rec read c =\nlet m = recv () in\nlet [=\"conn\"; n; payload] = sdec c.key m in\nlet sent = c.sent in\nif n == sent then c.sent++; payload\nelse read c\nconn 푐푘푛≜senc_key 푘∗푐↦→{key = 푘; sent = 푛}\nsenc_pred ”conn” (휆푘푡, ∃푛푠®푡휑,푡= [푛; (푠:: ®푡)] ∗public ®푡∗conn_pred 푠휑∗휑푘푛®푡)\nWrite\nconn_pred 푠휑\n\b\nconn 푐푘푛∗public ®푡∗(public 푘∨\u001f ⊲휑푘푛®푡)\n\t\nwrite 푐(푠:: ®푡) {conn 푐푘푛}\nRead\nconn_pred 푠휑\n{conn 푐푘푛} read 푐\n\u001a 푡,\nconn 푐푘(푛+ 1) ∗∀®푡,푡= (푠:: ®푡)\n⇛⊤public ®푡∗(public 푘∨\u001f휑푘푛®푡)\n\u001b\nMkConn\n{senc_key 푘} mkconn 푘{푐, conn 푐푘0}\nFig. 4. Key-value store: Implementation and specification of client functions for reliable communication\nusing symmetric encryption.\nby the connection key 푘, which allows us to operate on multiple databases, one per connection.\n(When we incorporate authentication, we will see that the database can be bound to the identity\nof its owner and the server where it is stored.) We distinguish between two types of databases:\nthe logical database, which the client believes ought to be stored in the server, and the physical\ndatabase, which is what is actually stored in the server. The logical database is ghost state that is\nowned by the client, and the physical database is tracked by the resource is_map 푙휎, which says\nthat the location 푙points to an object that represents the map 휎. The exact deﬁnition of is_map is\nnot too important, as long as it allow us to implement the database operations in the server. (Our\nimplementation uses an association list.)\nThe logical database consists of a series of resources deﬁned with term metadata, a Cryptis\nfeature we will discuss soon. For now, we focus on the high-level operations on these resources\nthat we use to verify the store.\nThe resource db_state푘휎means that the current logical state is exactly휎. This resource behaves\nsimilarly to how the heap is modeled in Iris: as shown in Figure 5, it can be combined with the\npoints-to assertion 푡1 ↦→푘\ndb 푡2 to update the logical state (DbStateUpdate) or ﬁnd out which values\nare stored under it (DbStateAgree).\nThe other resource is a trace that tracks all the operations (loads and stores) that have been per-\nformed on the database. The assertion #푘푛means that exactly푛operations have been performed on\nthe database so far. This resource allows the client to apply new operations to the logical database\n(OpAdd, OpApply). The assertion op_at 푘푛표means that the operation 표was the 푛-th operation\nthat was applied to the database. The assertion db_at 푘푛휎means that, after applying the 푛ﬁrst\n7\n\n\nPL’18, January 01–03, 2018, New York, NY, USA\nArthur Azevedo de Amorim, Amal Ahmed, and Marco Gaboardi\nOpAdd\n#푘푛⇛#푘(푛+ 1) ∗op_at 푘푛표\nOpApply\ndb_at 푘푛휎∗op_at 푘푛표−∗db_at 푘(푛+ 1) (표휎)\nDbAtAgree\ndb_at 푘푛휎1 ∗db_at 푘푛휎2 −∗휎1 = 휎2\nOpAtAgree\nop_at 푘푛표1 ∗op_at 푘푛표2 −∗표1 = 표2\nDbStateAgree\ndb_state 푘휎∗푡1 ↦→푘\ndb 푡2 −∗휎푡1 = Some 푡2\nDbStateUpdate\ndb_state 푘휎∗푡1 ↦→푘\ndb 푡2 ⇛db_state 푘(휎[푡1 ↦→푡′\n2]) ∗푡1 ↦→푘\ndb 푡′\n2\nFig. 5. Key-value store: Auxiliary assertions and rules. The predicates db_at and op_at are persistent.\nn\nclient db 푘∗푡1 ↦→푘\ndb 푡2\no\nload db 푡1\nn\n푡′\n2, (public 푘∨푡′\n2 = 푡2) ∗client db 푘∗푡1 ↦→푘\ndb 푡2\no\nn\nclient db 푘∗푡1 ↦→푘\ndb ⊥\no\ncreate db 푡1 푡2\nn\nclient db 푘∗푡1 ↦→푘\ndb 푡2\no\nn\nclient db 푘∗푡1 ↦→푘\ndb 푡′\n2\no\nstore db 푡1 푡2\nn\nclient db 푘∗푡1 ↦→푘\ndb 푡2\no\nclient 푐푘≜∃휎푛, conn 푐푘푛∗db_at 푘푛휎∗#푘푛∗db_state 푘휎\nserver 푐푘푙≜∃휎푛, conn 푐푘푛∗(public 푘∨db_at 푘푛휎) ∗is_map 푙휎\nFig. 6. Key-value store: Specifications for the client API. A load must return the last value that was stored\nunder the key, regardless of how much time has elapsed or what other operations have been performed. The\nterms 푡1, 푡2 and 푡′\n2 are assumed public.\noperations, the resulting database is 휎. At each time stamp 푛, the last operation applied and the\ncurrent database are uniquely determined (DbAtAgree, OpAtAgree).\nWith these resources, we are ready to prove the correctness of the key-value store. The speciﬁ-\ncations for the client functions are shown in Figure 6. The speciﬁcations are reminiscent of how\nwe reason about state in separation logic. To store or load a value, we require a corresponding\npoints-to assertion in the precondition. The assertion is kept in the postcondition, but, in the case\nof store, it is updated to reﬂect the new value. The main diﬀerence lies in the speciﬁcation of load:\nthe value loaded from the server might diﬀer from the one tracked in the logical state if the key 푘\nis controlled by the attacker.\nThe resource client 푐푘gives the client thread exclusive access to manipulate the database. It\nsays that the client has a well-formed connection 푐. This connection is associated with a key 푘\nthat is used to identify the database. Moreover, the resource relates the trace of operations to the\nlogical state db_state 푘휎. Another resource, server 푐푘푙, describes the state of the server. It is\nsimilar to the previous resource, but it ties the logical state at time 푛with the server’s physical\nstate. Note that the resource also allows the physical and logical states to diverge, in case the key\n푘is controlled by an attacker.\nTo prove the store speciﬁcations, we use message invariants for the client to communicate to\nthe server which operations where performed in the logical state. When the server receives these\nmessages, it applies the corresponding operations to maintain its invariant server푐푘푙. For example,\nthe invariants for loading a value from the key-value store are shown in Figure 7. To load a value,\nthe client adds a load operation to its history of operations, and 퐼load informs the server that that\noperation was the last one. When the server replies, the invariant 퐼ack_load ensure that the contents\n8\n\n\nCryptis: Cryptographic Reasoning in Separation Logic\nPL’18, January 01–03, 2018, New York, NY, USA\n퐼load 푘푛푡≜∃푡1,푡= [푡1] ∗op_at 푘푛(Load 푡1)\n퐼ack_load 푘푛푡≜∃푡1 푡2,푡= [푡2] ∗op_at 푘푛(Load 푡1) ∗stored_at 푘(푛+ 1) 푡1 푡2\nstored_at 푘푛푡1 푡2 ≜∃db, db_at 푘푛db ∗db 푡1 = Some 푡2\nFig. 7. Key-value store: Message invariants for loading a value.\nlet game () =\nlet k\n= mkskey () in\nfork (fun () -> start_server k);\nlet db = mkconn k in\nlet key = recv () in\nlet val = recv () in\ncreate db key val;\nlet val' = load db key in\nassert (val = val')\nFig. 8. Key-value store: Security game.\nof the reply are the value associated with the queried key. Note that the message number 푛in the\nserver’s response refers to the number of messages sent by the client, since we the communication\nbetween the two is assumed to follow a request/response pattern.\n2.4\nA Game Formulation\nIt might not be clear that the key-value store speciﬁcations guarantee anything useful—for exam-\nple, if public 푘were always true, it is possible that load never returns the correct value. Fortunately,\nCryptis allows us to assess the security guarantees of a protocol in more concrete terms, via a se-\ncurity game. The game in Figure 8 generates a fresh encryption key 푘, spawns a database server in\na separate thread, and asks a client to contact the server. (For simplicity, we assume that all agents\nrun on the same machine.) The client tries to store a new value in the server and then retrieve it.\nThe goal of the attacker is to try to make the client retrieve a diﬀerent value from the original one\nby manipulating the network messages. Though the deﬁnition is simple, the operational seman-\ntics of the game is subtly complex: the agents run concurrently and their interaction is mediated\nby a Dolev-Yao attacker. Thus, checking the security of the game forces us to reason about con-\ncurrency, making it challenging to provide similar formulations in systems that do not cover this\nfeature, such as DY* [12].\nTo show that the attacker cannot win, we prove a speciﬁcation for the game with trivial pre- and\npostconditions. As usual, speciﬁcations in Cryptis guarantee safety, implying that no assertions\nfail during execution. To prove the speciﬁcation, we need two core features of Cryptis that we\nhave not discussed yet: secrecy resources and metadata. These features are summarized in Figure 9.\nThe rule MkSKeysays that, after allocating a symmetric key 푘, we obtain two resources, secret 푘\nand token푘⊤. The ﬁrst resource means that 푘has not been made public yet. At any point, we can\nconsume this resource to make 푘public, or to make 푘permanently secret. The second resource\nallows us to attach metadata with the 푘. The MetaSet rule says that, if we give up a token resource\nwhose mask E covers the namespace N, we obtain the assertion meta푡N 푥, which says that the\nmetadata item 푥has been permanently associated with the term 푡under the namespace N. The\nvalue 푥is arbitrary and can be drawn from any countable set. After we give up the token, it\nbecomes unavailable, as seen in the MetaToken rule. Moreover, the metadata associated with\n9\n\n\nPL’18, January 01–03, 2018, New York, NY, USA\nArthur Azevedo de Amorim, Amal Ahmed, and Marco Gaboardi\n푃,푄:= · · · | secret 푡| meta푡N 푥| token푡E | 푎푡\nN | · · ·\n푎푡\nN ≜∃훾, meta푡N 훾∗푎훾\nSecretNotPublic\nsecret 푡∗public 푡⊢⊲False\nSecretPublic\nsecret 푡⇛public 푡\nFreezeSecret\nsecret 푡⇛\u001f(public 푡⇐⇒⊲False)\nMkSKey\n{True} mkskey() {푘, senc_key 푘∗secret 푘∗token푘⊤}\npersistent(meta푡N 푥)\nMetaSet\n↑N ⊆E\ntoken푡E ⇛meta푡N 푥\nMetaToken\nN ∈E\nmeta푡N 푥∗token푡E −∗False\nMetaAgree\nmeta푡N 푥∗meta푡N 푦−∗푥= 푦\nTokenDiff\nE1 ⊆E2\ntoken푡E2 ⊣⊢token푡E1 ∗token푡(E2 \\ E1)\nTermOwnAlloc\nN ∈E\n✓푎\ntoken푡E ⇛푎푡\nN\nFig. 9. Core Cryptis: Rules for reasoning about secret terms and metadata.\n푡and N is unique (MetaAgree). The derived assertion 푎\n푡\nN allows us to associate an element\n푎of any resource algebra under 푡and N. In addition to TermOwnAlloc, the ghost ownership\nassertion 푎\n푡\nN inherits most laws from the Iris ghost ownership assertion 푎\n훾. Metadata serves\nvarious purposes in Cryptis. For example, we term ghost ownership to deﬁne the resources of the\nprevious section, using a heap-like resource algebra and another resource algebra of monotonic\ntraces. We can initialize the client-level database resources by consuming the key token:\ntoken푘⊤⇛#푘0 ∗db_state 푘∅∗db_at 푘0 ∅∗∗\n푡\n푡↦→푘\ndb ⊥.\nTo prove security, we keep the resource secret 푘after we generate the key 푘, and consume the\ntoken to initialize the client’s resources. After the load function returns, either val = val′, or the\nkey 푘is public. However, we can rule out this possibility, because 푘was kept secret during the\ngame. Therefore, the assertion must succeed.\n3\nAUTHENTICATION: THE NSL PROTOCOL\nSo far, our store assumes that clients and servers communicate using a pre-shared key. To lift\nthis assumption, we need to incorporate an authentication step in the key-value store that allows\nclients and servers to exchange a session key. In the next few sections, we will prove self-contained\nspeciﬁcations of popular authentication protocols; later (Section 5), we will see how we can use\nthese speciﬁcations to incorporate an authentication step in our reliable connection abstraction.\nThe novelty of these results is not in the protocols that we verify, which have been extensively\nstudied in the literature, but in their speciﬁcations, which assign separation-logic resources to the\nresult of authentication, thus enabling its reuse within larger programs.\nThe ﬁrst protocol we will analyze is Needham-Schroeder-Lowe [42, 39] (NSL), a classic protocol\nbased on public-key encryption. It is the hello world of protocol veriﬁcation and thus provides\n10\n\n\nCryptis: Cryptographic Reasoning in Separation Logic\nPL’18, January 01–03, 2018, New York, NY, USA\nlet initiator skI pkR =\nlet pkI = pkey skI in\nlet a = mknonce () in\nlet m1 = aenc pkR [\"m1\"; a; pkI] in\nsend m1;\nlet m2 = recv () in\nlet [=\"m2\"; =a; b; =pkR] = adec skI m2 in\nlet m3 = aenc pkR [\"m3\"; b] in\nsend m3;\nlet k = derive_key [pkI; pkR; a; b] in\nk\nlet responder skR =\nlet pkR = pkey skR in\nlet m1 = recv () in\nlet [=\"m1\"; a; pkI] = adec skR m1 in\nlet b = mknonce () in\nlet m2 = aenc pkR [\"m2\"; a; b; pkR] in\nsend m2;\nlet m3 = recv () in\nlet [=\"m3\"; =b] = adec skR m3 in\nlet k = derive_key [pkI; pkR; a; b] in\n(pkI, k)\nFig. 10. Implementation of the NSL protocol. Variables beginning with sk and pk refer to secret and public\nkeys.\na good benchmark for comparing Cryptis with other tools. Later, we will see other designs that\nprovide stronger security. There are two versions of the protocol: one that relies on a trusted server\nto distribute public keys, and one where the participants know each other’s public keys from the\nstart. For simplicity, we model the second one. A typical run can be summarized as follows:\n퐼→푅: aenc pk푅[m1;푎; pk퐼]\n푅→퐼: aenc pk퐼[m2;푎;푏; pk푅]\n퐼→푅: aenc pk푅[m3;푏].\nFirst, the initiator 퐼generates a fresh nonce푎and sends it to the responder 푅, encrypted under their\npublic key pk푅. (The tags m1, m2 and m3 serve to prevent confusion attacks that exploit messages\nwith similar formats used in other protocols.) The responder replies by generating another nonce\n푏and sending it back with 푎. The initiator conﬁrms the end of the handshake by returning 푏. If the\nprotocol terminates successfully, and both agents are honest, they can conclude that their identities\nare correct—that is, they match the public keys sent in the messages—and that the nonces 푎and\n푏are secret. In particular, they can use 푎and 푏to derive a secret session key to encrypt further\ncommunication.\nFigure 10 shows an implementation of the protocol. The code uses some functions we have\nalready seen, plus others that we haven’t discussed yet. The function mknonce generates a fresh\nnonce. The functions aenc and adec performasymmetric encryption, and pkey computes the public\nkey associated with a secret key. Finally, the function derive_key is used to derive a symmetric key\nfrom the protocol parameters (public keys and nonces).\n3.1\nProving security\nThe NSL handshake produces a session key 푘that is guaranteed to be secret, as long as both\nparticipants are honest. We formalize this claim with the following theorem, which, moreover,\nproduces metadata tokens for the agents to coordinate their actions, similarly to Section 2.\nTheorem 3.1. Deﬁne\nsessionNSL sk퐼sk푅푎푏푘≜\u001f(public 푘⇐⇒⊲(public sk퐼∨public sk푅))\n∗푘= derive_key [pkey sk퐼; pkey sk푅;푎;푏].\n11\n\n\nPL’18, January 01–03, 2018, New York, NY, USA\nArthur Azevedo de Amorim, Amal Ahmed, and Marco Gaboardi\nThe following triples are valid:\n\baenc_key sk퐼∗public pk푅\n\t\ninitiatorsk퐼pk푅\n\n\n푟,\n푟≠None −∗∃sk푅푎푏푘,\n푟= Some 푘∗pk푅= pkey sk푅\n∗sessionNSL sk퐼sk푅푎푏푘\n∗token푎(↑sess)\n\n\n{aenc_key sk푅}\nresponder sk푅\n\n\n푟,\n푟≠None −∗∃sk퐼푎푏푘,\n푟= Some (pkey sk퐼,푘)\n∗sessionNSL sk퐼sk푅푎푏푘\n∗token푏(↑sess)\n\n\nLet us dissect this result. We focus on the initiator, since both speciﬁcations are similar. Like in\nsymmetric encryption, the assertion aenc_pred 푠휑means that 휑is the asymmetric encryption\npredicate associated with the tag 푠, whereas aenc_key sk means that sk is a valid secret key for\nasymmetric encryption. (We use sk and pk to range over secret or public key terms.) We assume\nthat initiator has a secret key sk퐼and that the responder’s public key is indeed public. If the pro-\ntocol successfully terminates, the initiator function returns the session key exchanged by the two\nagents. The predicate sessionNSL sk퐼sk푅푎푏푘says that푘is public if and only if one of the long-term\nsecret keys is known by the attacker, and that 푘is a symmetric encryption key that was correctly\ngenerated from all the handshake material (public long-term keys and the participants’ nonces 푎\nand 푏).\nTo prove the speciﬁcations, we employ the rules of Figure 11. The rules for asymmetric en-\ncryption are similar to those for symmetric encryption. The speciﬁcation of mknonce allows us\nto deﬁne what it means for the new nonce 푡to be public as any property 휑푡, provided that the\nproperty holds persistently—“persistently” because public 푡should be persistent. We can take 휑푡\nto be True, if we want 푡to be sent out in the clear, or we can set it to False, if we want to ensure\nthat it is never seen by an attacker. Another option is to set 휑to some other predicate that does\nnot hold when the nonce was generated, but that can become true afterwards. This will allow us\nto model situations in which cryptographic material starts out as secret and is later leaked to the\nattacker.\nThe proof uses the message invariants of Figure 12. Each invariant conveys to the recipient of a\nmessage what they need to know to conclude that the postcondition holds. To see how this works,\nconsider how we prove the correctness of the initiator. We use the MkNonce rule to generate a\nfresh nonce 푎such that, if pk푅= pkey sk푅, then public 푎⇐⇒⊲(public sk퐼∨public sk푅) holds.\nThis nonce comes with a token resource, which we will eventually use in the postcondition. To\nsend 푚1 to the responder, we need to show that it is public (cf. Figure 11), which boils down to (1)\nproving 퐼m1 and (2) proving public sk푅⇒public 푎∗public (pkey sk퐼). Both points follow from\nhow 푎was generated.\nNow, consider what happens when the initiator receives 푚2. Since the message is public, after\ndecrypting and checking it, we need to consider two cases (Figure 11). One possibility is that the\nbody of the encrypted message (that is, the nonces 푎and푏) is public, which could happen if푚2 was\nsent by a malicious party. In this case, because 푏is public, we can send the third message 푚3 to the\nresponder without proving its invariant. Moreover, because 푎turned out to be public, it must be\nthe case that either sk퐼or sk푅is compromised. Since public 푎, public 푏and public sk퐼∨public sk푅\nhold, we can trivially prove the logical equivalence in sessionNSL is valid.\nThe other possibility is that the invariant of 푚2 holds. The metadata assertion in 퐼m2 is exactly\nthe one we need to prove 퐼m3, so we can safely send 푚3. To conclude, we just need to prove that\n12\n\n\nCryptis: Cryptographic Reasoning in Separation Logic\nPL’18, January 01–03, 2018, New York, NY, USA\n푃∈{aenc_pred 푐휑, aenc_key sk}\npersistent(푃)\nPublicDeriveKey\npublic (derive_key푡) ⇐⇒⋄public 푡\nPublicPKey\naenc_key 푡\npublic (pkey 푡)\nPublicAEncPublic\npublic 푡1\npublic 푡2\npublic (aenc 푡1 푡2)\nPublicAEnc\naenc_pred 푐휑\n∀sk, pk = pkey sk −∗⊲\u001f휑sk [푡1; . . . ;푡푛] ∗\u001f(public sk ⇒∗\n푖\npublic 푡푖)\npublic (aenc pk [푐;푡1; . . . ;푡푛])\nADec\naenc_pred 푠휑\n{aenc_key sk} adec sk 푡\n\u001a 푟,\n푟= None ∨∃푡′,푟= Some 푡′ ∗∀®푡,푡′ = (푠:: ®푡)\n⇛⊤public ®푡∨\u001f휑푘®푡∗\u001f(public 푘⇒public ®푡)\n\u001b\nMkNonce\n{True} mknonce() {푡, \u001f(public 푡⇐⇒⊲\u001f휑푡) ∗token푡⊤}\nMkAKey\n{True} mkakey() {sk, public (pkey sk) ∗secret sk ∗token sk ⊤}\nFig. 11. Core Cryptis: Rules for reasoning about asymmetric encryption and nonces. The ⋄symbol refers to\nthe “except zero” modality of Iris [32].\n퐼m1(sk푅,푚1) ≜∃푎sk퐼,푚1 = [푎; pkey sk퐼] ∗public (pkey sk퐼) ∗(public 푎⇐⇒⊲(public sk퐼∨public sk푅))\n퐼m2(sk퐼,푚2) ≜∃푎푏sk푅푘,푘= derive_key [pkey sk퐼; pkey sk푅;푎;푏] ∗푚2 = [푎;푏; pkey sk푅]\n∗(public 푏⇐⇒⊲(public sk퐼∨public sk푅)) ∗meta푏data (pkey sk퐼)\n퐼m3(sk푅,푚3) ≜∃푏sk퐼,푚3 = [푏] ∗meta푏data (pkey sk퐼)\nFig. 12. Invariants used in NSL proof\nthe session key 푘has the desired secrecy. This follows because the invariant on푚2 guarantees that\npublic 푏⇐⇒⊲(public sk퐼∨public sk푅) holds, and because of how 푎was generated.\n3.2\nGame Security for NSL\nIn addition to Theorem 3.1, we can assess the security of NSL via a game (Figure 13). We generate\nfresh keys for two honest participants, an initiator and a responder, and let them run an arbitrary\nnumber of NSL sessions in parallel (do_init and do_resp). In each iteration of do_init, the initia-\ntor attempts to contact an agent chosen by the attacker. If the handshake successfully terminates,\nthe initiator adds the exchanged session key to a set of keys keysI, while ensuring that the key is\nfresh. Moreover, if the initiator contacted the honest responder, the attacker tries to guess the ses-\nsion key. The session is successful if its key had not been previously used and cannot be guessed by\nthe attacker. The logic in do_resp is similar. This implies that the assertion in check_key_secrecy\n13\n\n\nPL’18, January 01–03, 2018, New York, NY, USA\nArthur Azevedo de Amorim, Amal Ahmed, and Marco Gaboardi\nlet check_key_secrecy session_key =\nlet guess = recv () in\nassert (session_key != guess)\n(* keysI: Set of agreed session keys\n*)\n(* skI: Honest initiator's secret key *)\n(* pkR: Honest responder's public key *)\nlet rec do_init keysI skI pkR =\nfork (fun () -> do_init keysI skI pkR);\n(* Attacker chooses responder *)\nlet pkR' = recv () in\n(* Run handshake *)\nlet k = init skI pkR' in\n(* The session key should be fresh and *)\nassert (not (Set.mem keysI k));\nSet.add keysI k;\n(* if attacker chose honest responder,\nthe key cannot be guessed. *)\nif pkR' == pkR then check_key_secrecy k\nelse ()\nlet rec do_resp keysR skR pkI =\n(* Similar to initiator *)\n(* ... *)\nlet game () =\n(* Generate keys and leak public keys *)\nlet skI, skR = mkakey (), mkakey () in\nlet pkI, pkR = pkey skI, pkey skR in\nsend pkI; send pkR;\n(* Generate sets of session keys *)\nlet keysI = Set.new () in\nlet keysR = Set.new () in\n(* Run agents *)\nfork (fun () -> do_init keysI skI pkR);\nfork (fun () -> do_resp keysR skR pkI)\nFig. 13. A security game where the atacker tries to learn the session keys of honest agents or trick them\ninto reusing keys.\n퐼→푀: aenc pk푀[m1;푎; pk퐼]\n푀→푅: aenc pk푅[m1;푎; pk퐼]\n푅→푀: aenc pk퐼[m2;푎;푏]\n푀→퐼: aenc pk퐼[m2; 푎;푏]\n퐼→푀: aenc pk푀[m3;푏]\n푀→푅: aenc pk푅[m3;푏].\nFig. 14. Atack on the original Needham-Schroeder protocol [39].\ncannot fail, because terms that come from the network are public, and because the attacker does\nnot know sk퐼or sk푅.\nProviding this kind of guarantee can be elusive. Indeed, the original version of the NSL pro-\ntocol [42] was vulnerable to a man-in-the-middle attack [39], even though it was thought to be\nsecure for several years (and even veriﬁed [19]). The issue was that the original version omitted\nthe identity of the responder in the second message—that is, the second message would have been\naenc pk퐼[m2;푎;푏] instead of aenc pk퐼[m2;푎;푏; pk푅]. This omission meant that the initiator had\nno way of telling if the responder was actually supposed to see the nonce 푏. As seen in Figure 14,\na malicious responder 푀can exploit this to lead an honest responder 푅to generating a nonce 푏\nfor authenticating with 퐼, and then tricking 퐼into leaking this nonce to 푀. In the end, 푀is able to\nconstruct the same session key that 푅believes is being used to communicate with 퐼—despite the\nfact that 푅believes that the handshake was performed between two agents that are, in fact, honest.\nThe game shows that the attack cannot succeed—otherwise, check_key_secrecy would fail.\nTo show that the attacker cannot win the game, we proceed as follows. First, we prove speciﬁ-\ncations for the functions do_init and do_resp that guarantee that they are safe to run. We use\nFreezeSecret (Figure 9) to guarantee that the agent’s secret keys cannot become public. In the\nproof of do_init, we invoke the speciﬁcation of init in Theorem 3.1. We maintain an invariant\non keysI guaranteeing that every key 푘′ stored in the set satisﬁes meta푘′ sess (). This means\n14\n\n\nCryptis: Cryptographic Reasoning in Separation Logic\nPL’18, January 01–03, 2018, New York, NY, USA\n(* skI: initiator's signing key\n*)\n(* vkR: responder's verification key *)\nlet initiator skI vkR =\nlet vkI = vkey skI in\nlet a = mknonce () in\nlet m1 = [\"m1\"; g^a; vkR] in\nsend m1;\nlet m2 = recv () in\nlet [=\"m2\"; =g^a; gb; =vkI] =\nverify vkR m2 in\nlet m3 = sign skI [\"m3\"; g^a; gb; vkR] in\nsend m3;\nlet k =\nderive_key [vkI; vkR; g^a; gb; gb^a] in\nk\n(* skR: responder's signing key\n*)\nlet responder skR =\nlet vkR = vkey skR in\nlet m1 = recv () in\nlet [=\"m1\"; ga; vkI] = m1 in\nlet b = mknonce () in\nlet m2 = sign skR [\"m2\"; ga; g^b; vkI] in\nsend m2;\nlet m3 = recv () in\nlet [=\"m3\"; =ga; =g^b; =vkR] =\nverify vkI m3 in\nlet k =\nderive_key [vkI; vkR; ga; g^b; ga^b] in\n(vkI, k)\nFig. 15. ISO authentication protocol based on Diﬀie-Hellman key exchange. Note that the signature verifi-\ncation function verify outputs the contents of the signed message, instead of a success bit.\nthat the new session key 푘cannot be in the set, because its token has not been used yet. Thus,\nthe ﬁrst assertion cannot fail. We consume this token so that the key can be added to keysI. We\nthen argue that the second assertion cannot fail because the attacker’s guess is public, whereas\nthe session key cannot be session is authentic. A symmetric reasoning shows that do_resp is safe\nas well.\nFinally, we prove that game is safe. We generate the key pairs of the honest participants by\ninvoking the speciﬁcations in Figure 11. Then, we allocate two empty sets of keys, which trivially\nsatisfy the invariant that all keys have their metadata token set. We conclude by invoking the\nspeciﬁcations of do_init and do_resp to show that the last line is safe.\n4\nDIFFIE-HELLMAN KEY EXCHANGE AND FORWARD SECRECY\nOne limitation of a protocol such as NSL is that it is vulnerable to key compromise. If a private key is\nleaked, an attacker can decrypt the messages of a handshake and learn its session key. By contrast,\nmany modern protocols guarantee forward secrecy: if a handshake is successful, its session keys\nwill remain secret even if long-term keys are leaked [22].\nOur goal in this section is to demonstrate that Cryptis can scale up to more complex proto-\ncols with richer guarantees. Speciﬁcally, we will prove the correctness of the ISO protocol [33],\nwhich provides forward secrecy through Diﬃe-Hellman exponentiation. A typical run proceeds\nas follows:\n퐼→푅: [m1;푔푎; vk퐼]\n푅→퐼: sign sk푅[m2;푔푎;푔푏; vk퐼]\n퐼→푅: sign sk퐼[m3;푔푎;푔푏; vk푅].\nThe ﬂow is similar to the NSL protocol, except that (1) it uses digital signatures instead of asym-\nmetric encryption; (2) the ﬁrst message does not need to be signed or encrypted; (3) the keys used\nin the signed messages 2 and 3 are swapped; (4) the agents exchange the key shares 푔푎and 푔푏\nrather than the nonces 푎and 푏. At the end of the handshake, the participants can compute the\nshared secret 푔푎푏= (푔푎)푏= (푔푏)푎and use it to derive a session key.\n15\n\n\nPL’18, January 01–03, 2018, New York, NY, USA\nArthur Azevedo de Amorim, Amal Ahmed, and Marco Gaboardi\nWe’ll use the notation 푡ˆ(Î푛\n푖=1 푡푖) to denote the term 푡, seen as the element of a Diﬃe-Hellman\ngroup, raised to the powers 푡푖. We quotient terms to validate some of the expected equations asso-\nciated with exponentiation. In particular, we can freely permute the exponents 푡푖, and\n(푡ˆ(푡1 · · ·푡푛)) ˆ(푡푛+1 · · ·푡푚) = 푡ˆ\n 푚\nÖ\n푖=1\n푡푖\n!\n.\nFigure 15 shows an implementation of ISO.\nWe state the security of the ISO protocol following the same idea as in Section 3. We formulate a\nspeciﬁcation for the initiator and the responder, and use these speciﬁcations to prove the security\nof a game between the attacker and the agents. The main diﬀerence lies in the secrecy guarantees\nfor the session key 푘: when the handshake terminates, if we can prove that the participants’ long-\nterm keys are not compromised yet, then 푘will remain secret forever, even if some long-term keys\nare leaked later.\nThe proof uses the rules and assertions of Figure 16. The public predicate on Diﬃe-Hellman\nterms is deﬁned as follows: a key share 푡ˆ푡′ is always public, whereas a key of the form 푡ˆ(푡1푡2)\ncan only be public if one of the secret keys is. The deﬁnition could be made more general, but this\nsuﬃces for protocols involving two parties where the key shares 푡ˆ푡′ need not be kept secret.\n푃,푄:= · · · | sign_pred 푠휑| sign_key 푡| · · ·\nMkSigKey\n{True} mksigkey () {sk, sign_key sk ∗secret sk ∗token sk ⊤}\n푡does not begin with ˆ\npublic (푡ˆ(푡1푡2)) ⊣⊢⋄(public 푡1 ∨public 푡2)\n푡does not begin with ˆ\npublic (푡ˆ푡′)\nPublicSignPublic\npublic sk\npublic 푡\npublic (sign sk 푡)\nPublicSign\nsign_pred 푠휑\nsign_key sk\n⊲\u001f휑sk [푡1; . . . ;푡푛] ∗\n푖\npublic 푡푖\npublic (sign sk [푐;푡1; . . . ;푡푛])\nVerify\nsign_pred 푠휑\n{True} verify vk 푡\n\u001a 푟,\n푟= None ∨∃vk 푡,푟= Some 푡∗vk = vkey sk ∗\n∀®푡,푡= Some (푠:: ®푡) ⇛⊤public ®푡∗(public sk ∨\u001f휑sk ®푡)\n\u001b\nFig. 16. Core Cryptis: Diﬀie-Hellman exponentiation and digital signatures.\nTheorem 4.1. Deﬁne\nsessionISO sk퐼sk푅푡1 푡2 푘≜(public sk퐼∨public sk푅∨\u001f(public 푘⇐⇒⊲False))\n∗∃푡,푘= derive_key [vkey sk퐼; vkey sk푅;푡1;푡2;푡].\n16\n\n\nCryptis: Cryptographic Reasoning in Separation Logic\nPL’18, January 01–03, 2018, New York, NY, USA\n퐼m2(sk푅,푚2) ≜∃푠푎푏vk퐼,푚2 = [푠푎;푔푏; vk퐼] ∗(public 푏⇐⇒⊲False)\n퐼m3(sk퐼,푚3) ≜∃푎푠푏sk푅,푚3 = [푔푎;푠푏; vkey sk푅]\n∗(public sk퐼∨public sk푅∨\n(public (derive_key [vkey sk퐼; vkey sk푅;푔푎;푠푏;푠푎\n푏]) −∗⊲False))\nFig. 17. Invariants for ISO protocol.\nThe following triples are valid:\n{sign_key sk퐼∗public vk푅}\ninitiator sk퐼vk푅\n\n\n푟,\n푟= None∨∃sk푅푡1 푡2 푘,\n푟= Some 푘∗vk푅= vkey sk푅\n∗sessionISO sk퐼sk푅푡1 푡2 푘\n∗token푡1 (↑sess)\n\n\n{sign_key sk푅}\nresponder sk푅\n\n\n푟,\n푟= None∨∃sk퐼푡1 푡2 푘,\n푟= Some (vkey sk퐼,푘)\n∗sessionISO sk퐼sk푅푡1 푡2 푘\n∗token푡2 (↑sess)\n\n\nWe use the message invariants of Figure 17. The idea is that each agent allocates their short-term\nprivate keys 푛so that public 푛⇐⇒⊲False.1 When the initiator checks the signature, either the\nresponder’s secret key is compromised, or they learn that the responder’s key share is of the form\n푔푏, with public 푏⇐⇒⊲False. Since public 푎⇐⇒⊲False, the rules of Figure 16 imply that 푔푎푏\nis equivalent to ⋄⊲False, which is itself equivalent to ⊲False.\nWe modify the game of Figure 13 so that both long-term secret keys are eventually leaked, and\nwe only check the secrecy of a session key if its handshake was concluded before the compromise\n(Figure 18). To prove that the game is secure, we proceed similarly to what we did for the NSL game.\nThe main diﬀerence lies in the management of long-term keys. After generating the signature keys\nsk퐼and sk푅, we allocate an invariant 퐼that says that either the compromise bit 푐is set to false, in\nwhich case secret sk퐼∗secret sk푅holds, or it is set to true, in which case both sk퐼and sk푅are\npublic. Then, we prove that the check_key_secrecy function is safe provided that it is called on\na session key 푘of the ISO protocol. If we run the “then” branch of that function, the invariant\n퐼, combined with the post-condition of the handshake, implies that \u001f(public 푘\n⇐⇒\n⊲False)\nholds. By a reasoning analogous to the NSL game, this guarantees that the attacker cannot guess\nthe session key.\nSession compromise. The speciﬁcation of ISO has a limitation: if the handshake completes suc-\ncessfully, it becomes impossible for us to model the compromise of the session key 푘. We can relax\nthis limitation by modifying the secrecy predicates of the private DH keys 푎and 푏so that\npublic 푎⇐⇒public 푏⇐⇒⊲(released푔푎∗released푔푏),\nwhere the released predicate is just a wrapper around meta that obeys the following rules:\nrelease_token푡∗released푡−∗False\nrelease_token푡⇛released푡\nWe strengthen the ISO invariants and Theorem 4.1 so that the postconditions of the speciﬁcations\ninclude a release token resource for the DH public key of the corresponding agent. Then, we can\n1We also use a more general rule for mknonce (omitted) that allows us to allocate metadata tokens for terms derived from\nnonces, such as the public key shares 푔푛.\n17\n\n\nPL’18, January 01–03, 2018, New York, NY, USA\nArthur Azevedo de Amorim, Amal Ahmed, and Marco Gaboardi\n(* c: Have keys been compromised? *)\nlet rec wait_for_compromise c =\nif !c then () else wait_for_compromise c\nlet check_key_secrecy c k =\nif not !c then\nwait_for_compromise c;\nlet guess = recv () in\nassert (k != guess)\nelse ()\nlet compromise_keys c skI skR =\nc := true; send skI; send skR\nlet game () =\n(* ... *)\nlet skI = mksigkey #() in\nlet skR = mksigkey #() in\nlet vkI = vkey skI in\nlet vkR = vkey skR in\nlet c = ref false in\n(* ... *)\nfork (fun () -> do_init keysI c skI vkR);\nfork (fun () -> do_resp keysR c skR vkI);\nfork (fun () -> compromise_keys c skI skR)\nFig. 18. Security game for the ISO protocol (excerpt). The agents’ secret signing keys are leaked eventually,\nand we only check the secrecy of session keys if they have been exchanged before the compromise.\nmodel a compromise of the session key by simply releasing the tokens of the initiator and the\nresponder. While the agents still hold their release tokens, we can prove that the session key is not\nyet compromised.\n5\nAUTHENTICATED CONNECTIONS\nThe reliable connection abstraction of Section 2 was too restrictive, in that it forced clients to\ncommunicate using a single pre-shared key. In this section, we will lift this restriction by allow-\ning agents to authenticate each other and exchange session keys. The agents can only exchange\nmessages after they authenticate. They can also disconnect from each other, which allows them\nto free the connection state. We could use many diﬀerent authentication protocols to implement\nthis, but for concreteness we will employ the ISO protocol of Section 4, since it provides forward\nsecrecy. We will use the stronger speciﬁcation of ISO that enables the compromise of session keys,\nwhich will allow us to leak the session key after disconnection without harming security—or, bet-\nter, without harming the integrity of messages, since their secrecy cannot be preserved after the\nleak. While similar examples have been analyzed in the literature [13], our proofs illustrate how\nagents running higher-level protocols can leverage separation-logic resources to coordinate their\nactions (in this case, the total number of messages exchanged between two agents throughout\ntheir entire execution).\nFigure 19 presents the client functions of API of authenticated connections. The API is mostly\nsimilar to the one of Section 2. The resource connected sk퐶sk푆푛푐푘means that 푐is a well-formed\nconnection object between the client 퐶and the server 푆with an associated session key 푘. Once\nagain, we assume that client and server take turns exchanging messages. The number 푛counts\nhow many messages have been sent through the connection. The disconnected resource is similar,\nbut is not associated with any connection object 푐. It is also parameterized by a compromise bit 푏,\nwhich we’ll explain shortly.\nWe use a resource compromised 푘to model whether one of the agents had their keys compro-\nmised when the handshake completed. As seen in the Write rule, when sending a message, we\nhave to show that either the attacker compromised the handshake, or that the message’s invariant\nholds. Conversely, the Read rule says that either the handshake was compromised, or that the\ncorresponding message invariant holds. We can rule out the possibility of a compromised hand-\nshake by showing that the long-term keys of the two agents are secret. Note that this rule proves\n18\n\n\nCryptis: Cryptographic Reasoning in Separation Logic\nPL’18, January 01–03, 2018, New York, NY, USA\nWrite\nconn_pred 푠휑∗public ®푡∗(compromised 푘∨\u001f ⊲휑sk퐶sk푆푛®푡)\n{connected sk퐶sk푆푛푐푘} write 푐(푠:: ®푡) {connected sk퐶sk푆푛푐푘}\nRead\n{connected sk퐶sk푆푛푐푘} read 푐\n\n\n푡,\nconnected sk퐶sk푆(푛+ 1) 푐푘∗\n∀푠®푡휑,푡= (푠:: ®푡) ∗conn_pred 푠휑⇛⊤public ®푡∗\n(compromised 푘∨\u001f ⊲휑sk퐶sk푆푛®푡)\n\n\nConnect\n{disconnected sk퐶sk푆푛푏} connect sk퐶(vkey sk푆)\n\u001a 푐,\n∃푘, \u001f(푏= 1 ⇒compromised 푘) ∗\nconnected sk퐶sk푆푛푐푘\n\u001b\nClose\n{connected sk퐶sk푆푛푐푘} close 푐\n\n\n∃푏,\ndisconnected푆sk퐶sk푆푛푏∗\n\u001f(푏= 1 ⇐⇒compromised 푘) ∗\n(compromised 푘∨public 푘)\n\n\nConnectedOk\nconnected sk퐶sk푆푛푐푘∗secret sk퐶∗secret sk푆−∗⊲\u001f ¬compromised 푘\ntoken sk퐶(↑client.sk푆) ⇛disconnected sk퐶sk푆0 0\nFig. 19. Authenticated connections.\nthat compromised 푘is persistently false, which relies on the forward secrecy properties of the\nunderlying protocol.\nThe client switches back and forth between the connected and disconnected states by calling\nthe connect and close functions. Like in our ﬁrst connection implementation, a connection object\nstores a counter keeping track of how many messages the client has sent during that particular\nsession. However, it would also be useful to track the total number of messages that have been sent\nbetween the agents across all sessions, so that the agents can agree on the state of some system\ncomponent that should persist across connections. The issue, however, is that the client frees the\nmemory used to store the session state when it disconnects. Therefore, we need to track the total\nnumber of messages using some other mechanism.\nTo this end, we use a piece of ghost state attached to the client’s key. The resource clocksk퐶sk푆푛0\nmeans that 푛0 messages had been sent by the client the last time they connected. This resource\ncomes in two pairs, which are forced to be kept in sync (cf. Figure 20). When the client initializes\nthe database, it creates two copies of the clock. One copy is kept by the client, whereas the other is\nmeant for the server. Then, whenever the client wants to connect to the server, it sends its copy of\nthe clock to the server.2 When the server receives the client’s clock, it uses the ClockAgree rule\nto agree on what 푛0 is. When the client attempts to disconnect, the server updates both clocks to\n2To make this possible, the connection function requires the client and the server to exchange an additional pair of messages.\nIt would be possible to avoid this additional communication by enriching the ISO invariants so that the third message can\ncarry the client’s clock, but we keep the speciﬁcations of Section 4 for simplicity.\n19\n\n\nPL’18, January 01–03, 2018, New York, NY, USA\nArthur Azevedo de Amorim, Amal Ahmed, and Marco Gaboardi\nclock sk퐶sk푆푛≜(Ag1/2푛) sk퐶\nclient.sk푆\nconnected sk퐶sk푆푛푐푘≜∃푛′ 푛0 푡퐶푡푆,\n푛= 푛′ + 푛0 ∗푐↦→{key = 푘, sent = 푛′} ∗\nsessionISO sk퐶sk푆푡퐶푡푆푘∗\nescrow sk푆server.sk퐶(clock sk퐶sk푆0) ∗\nmeta푡퐶beginning 푛0 ∗token푡푆(↑end) ∗\n(compromised 푘∨\u001f ¬compromised 푘) ∗\nrelease_token푡퐶\ndisconnected sk퐶sk푆푛푏≜(푏= 1 ∗(public sk퐶∨public sk푆) ∨푏= 0 ∗clock sk퐶sk푆푛) ∗\nescrow sk푆db.sk퐶(clock sk퐶sk푆0).\nEscrowIntro\n⊲푃⇛⊤escrow 푡N 푃\nEscrowElim\n↑N ⊆E\nescrow 푡N 푃∗token푡E ⇛⊤⊲푃\nClockAgree\nclock sk퐶sk푆푛∗clock sk퐶sk푆푚−∗푛= 푚\nClockUpdate\nclock sk퐶sk푆푛∗clock sk퐶sk푆푚−∗clock sk퐶sk푆푝∗clock sk퐶sk푆푝\npersistent(escrow 푡N 푃)\nFig. 20. Definition of client resources for authenticated communication. The assertion meta푡퐶beginning 푛0\ntracks how many operations had been performed at the beginning of the session. The resource\ntoken푡퐶(↑end) is used by the client to retrieve its clock upon disconnection.\nreﬂect the moment of the disconnection, and then sends the client’s clock back. The server also\nconsumes its release token, so that the client can leak the session key after the connection closes.\nFor this to work, however, we need to circumvent one technical problem: because message\ninvariants are persistent, they cannot be used directly to send non-persistent resources such as a\nclock. Our solution is to wrap the clock in a persistent escrow assertion. This assertion, deﬁned\nusing Iris invariants, allows us to save a resource so that it be retrieved by consuming a speciﬁc\ntoken resource. We use this pattern in two diﬀerent ways: when the client initializes the database,\nit sends the server’s initial clock using an escrow keyed by the server and the client’s long-term\nkey. Later, when the nodes send the client’s clock back and forth, they use an escrow keyed by the\nsession key itself.\nAnother issue is that, when attempting to connect, the agents might fail to exchange the clock\nif their keys have been compromised, since nothing would guarantee that the message invariants\nrequired to transfer the clock are enforced. If this happens, the client will not be able to synchronize\nwith the server at the beginning of the connection. Thus, the disconnected resource allows for the\nclient’s clock to be absent in the case of a key compromise. This is controlled by the compromise\nbit 푏, which tracks whether any of the prior handshakes have been compromised by the attacker.\n20\n\n\nCryptis: Cryptographic Reasoning in Separation Logic\nPL’18, January 01–03, 2018, New York, NY, USA\ndb_connected sk퐶sk푆푐푘≜∃휎푛, connected sk퐶sk푆푛푐푘∗\n#sk퐶,sk푆푛∗db_at sk퐶sk푆푛휎∗db_state sk퐶sk푆휎\ndb_disconnected sk퐶sk푆푏≜∃휎푛, disconnected sk퐶sk푆푛푏∗\n#sk퐶,sk푆푛∗db_at sk퐶sk푆푛휎∗db_state sk퐶sk푆휎\nFig. 21. Definition of client resources for the authenticated key-value store.\n6\nAN AUTHENTICATED STORE\nNow that we have developed an authenticated connection abstraction, we can use it to incorporate\nan authentication step in the key-value store of Section 2, leading to the ﬁrst veriﬁed, authenticated\nkey-value store whose correctness can be formally justiﬁed by appealing to the laws of symbolic\ncryptography.\nThe API is mostly similar to what we saw earlier, in Figure 6, with a few diﬀerences. Earlier,\nthe client used the resource client to interact with the database; now, the client can only invoke\ndatabase operations when it is in the connected state. The connected state is deﬁned in terms of\nthe connected resource that we saw earlier. It tracks how many database operations have been per-\nformed so far, using the message count of the previous section, and ties this number to analogues\nof the database resources of Section 2.\nAt the implementation level, we modify the server so that it maintains several databases, each\none belonging to a diﬀerent client. The server keeps a thread in a loop listening for new connec-\ntions. When a client successfully authenticates, the server spawns oﬀa new thread to handle the\nclient’s requests. If the client does not have anything stored in the server yet, the server initializes\na new database for them. For simplicity, we consider that each client can have at most one active\nconnection with the server: the client’s database is protected by a lock, and the server attempts to\nacquire this lock before handling the client’s operations. When the client disconnects, the handler\nreleases the lock and its thread terminates.\nTo conclude, we can revisit the security guarantees of the key-value store with a game (Fig-\nure 22). The game is similar to the one of Figure 8, but it includes some connection and disconnec-\ntion calls. It shows that the client is capable of reading the expected value back from the server\neven after reconnecting to the server, and even if old session keys are leaked and even if long-term\nkeys are leaked before disconnection. Similarly to the ISO game (Figure 18), we prove this by using\nthe secrecy resources of the long-term keys, together with the ConnectedOk rule, to prove that\nthe session key is secret after the two agents connect. Then, we consume these secrecy resources\nto allow us to leak the private keys through the network.\n7\nIMPLEMENTATION\nWe implemented Cryptis as a Coq library [52] using the Iris framework [32] and used it to verify\nthe main examples of the paper. (We have not veriﬁed the simpler key-value store of Section 2,\nsince it is subsumed by the version with authentication.) Iris allows deﬁning expressive concurrent\nseparation logics, with support for higher-order ghost state, invariants, resource algebras and more.\nCryptis inherits those features from Iris, and since they are orthogonal to the reasoning patterns\nsupported by Cryptis, it is possible to compose protocols with other concurrent programs and\nreason about their behavior without compromising the soundness of the logic. Though the model\nof Iris is quite complex, most of this complexity is shielded from the user; moreover, thanks to its\ngeneric adequacy theorem, it is possible to relate Iris proofs to the plain operational semantics of\n21\n\n\nPL’18, January 01–03, 2018, New York, NY, USA\nArthur Azevedo de Amorim, Amal Ahmed, and Marco Gaboardi\nlet game () =\nlet skI, skR = mksigkey (), mksigkey () in\nlet vkI, vkR = vkey skI, vkey skR in\nsend vkI; send vkR;\nfork (fun () -> start_server skR);\nlet c = db_connect skI vkR in\nlet key = recv () in\nlet val = recv () in\ndb_create c key val;\ndb_close c;\nsend (session_key c);\nlet c = db_connect skI vkR in\nsend skI; send skR;\nlet val' = load c key in\nassert (val = val')\nFig. 22. Security game for the key-value storage service. The client reads back the value they stored even if\nlong-term keys are leaked afer the connection.\nthe language. Moreover, Iris comes with an interactive proof mode [34], which greatly simpliﬁes\nthe veriﬁcation of programs using the logic.\nRather than formalizing the Cryptis programming language from scratch, we implemented it\nas a library in HeapLang, the default programming language used in Iris developments. We devel-\noped a small library of HeapLang programs to help manipulating lists and other data structures.\nThe resulting language diﬀers in a few respects compared to our paper presentation. First, we\nformalized cryptographic terms as a separate type from HeapLang values, and rely on an explicit\nfunction to encode terms as values. Thanks to this encoding, we can ensure that Diﬃe-Hellman\nterms are normalized so that their intended notion of equality coincides with equality in the Coq\nlogic, similar to some encodings of quotient types in type theory [21]. Instead of deﬁning symmet-\nric encryption, asymmetric encryption, and digital signatures as separate primitives, all of these\nare encoded in terms of a single sealing primitive that behaves essentially like asymmetric encryp-\ntion. We implemented nonces as heap locations, which allowed us to reuse much of the location\ninfrastructure, such as the metadata predicates. This encoding is well-suited for reasoning about\nprotocols in the symbolic model, but it is not meant to be taken too literally—in particular, real\ncryptographic protocols need to send messages over the wire as bit strings, and it is not reasonable\nto expect that attackers that have access to the network at that level comply with the represen-\ntation constraints that we impose. We have pretended that we can only quantify over terms that\nhave been previously generated. In our implementation, we cannot impose this restriction easily,\nso instead we have a separate minted predicate that ensures that every nonce that appears in a\nterm has been previously allocated.\nOn paper, Cryptis proofs are parameterized by a set of axioms mapping tags to invariants. To\nensure soundness, we need to ensure that each tag is mapped to exactly one invariant. In our\nimplementation, we guarantee this property by expressing this mapping in ghost state. Proofs that\nuse the Iris program logic can simply assume that a certain tag is associated with some invariant as\nanother hypothesis. To use these proofs in a self-contained result, the user needs to declare a ghost\nlocation that contains this mapping, and initialize the invariants one by one before invoking the\n22\n\n\nCryptis: Cryptographic Reasoning in Separation Logic\nPL’18, January 01–03, 2018, New York, NY, USA\nComponent\nDeﬁnitions (loc)\nProofs (loc)\nWall-clock time (s)\nCryptis Core\n3971\n3500\n108.78\nNSL (Section 3)\n447\n139\n44.61\nISO (Section 4)\n627\n311\n56.50\nConnections (Section 5)\n932\n494\n66.36\nStore (Section 6)\n1139\n612\n84.13\nFig. 23. Code statistics.\nIris proof. To make this process more modular, we represent tags as Iris namespaces: if a protocol\nuses several tags, we can group them in a single namespace N, so that they can be initialized\ntogether and independently of invariants attached to other tags.\nFinally, when we proved results about programs and games, we assumed that the attacker is\nimplicitly running in the background. In our implementation, instead, the attacker is explicitly\ninitialized. It allocates a list for storing all the messages that are sent through the network, and\nlaunches a separate thread that nondeterministically generates fresh nonces and keys or applies\ncryptographic operations to other terms available to the attacker. We maintain an invariant that\nonly public messages appear on this list. When someone tries to receive a message, the attacker\nnondeterministically chooses one of the messages that it has seen or produced and returns that\nmessage to the user.\nTo give an idea of the eﬀort involved in Cryptis, Figure 23 shows the size of our development\nand case studies, split into lines of code in deﬁnitions and proofs. We also include the time spent to\ncompile the code with parallel compilation on Coq 8.18 running on an Ubuntu 24.04 laptop with\nan Intel i7-1185G7 3.00GHz with eight cores and 15GiB of RAM. These statistics show that the\nproof eﬀort required to use Cryptis is comparable to other advanced tools for modular protocol\nveriﬁcation, such as DY* [12].\n8\nRELATED WORK\nTools for protocol veriﬁcation. There is a vast literature on techniques for verifying cryptographic\nprotocols; see Barbosa et al. [8] for a recent survey. The work that is the most closely related to\nDY* [12], a state-of-the-art F* library for protocol veriﬁcation that has been used to verify various\nprotocols, such as the Signal messaging protocol [12] or the ACME protocol [11]. Like Cryptis,\nDY* is based on the symbolic model of cryptography and emphasizes expressiveness, allowing\nusers to state and verify complex properties. The veriﬁcation is carried out manually, with partial\nautomation support—in the case of DY*, by leveraging the F* type system. By contrast, other tools,\nsuch as ProVerif [14] or Tamarin [41], focus on automation and ease of use, but can face scalabity\nissues when reasoning about large protocols or more complex properties.\nOne important ingredient for achieving scalability in Cryptis and DY*, compared to automated\ntools, is compositionality. DY* enables compositionality through a layered approach [13]: a protocol\ncan be deﬁned as a composition of several layers, where each layer speciﬁes disjointness conditions\nthat should be respected by other components, as well as predicates that need to be proved by its\nclients when using a cryptographic primitive. For example, if a component 퐶uses an encryption\nkey is shared with other components, we must specify all encrypted messages that 퐶is allowed to\nmanipulate, and the other components cannot manipulate such messages in ways that conﬂict with\nwhat퐶expects. The message invariants of Cryptis play a similar role, but sacriﬁce some generality\nin return for ease of use: protocols can be composed automatically if they rely on disjoint message\ntags, a phenomenon that has been observed several times in the literature [20, 4, 3, 40, 17, 18,\n2]. Tag disjointness only needs to be checked once, when declaring tag invariants; by contrast,\n23\n\n\nPL’18, January 01–03, 2018, New York, NY, USA\nArthur Azevedo de Amorim, Amal Ahmed, and Marco Gaboardi\ndisjointness conditions in DY* need to be checked on every call to a cryptographic primitive. This\nmeans that protocol composition in Cryptis can be obtained as a simple consequence of the general\ncomposition rules of separation logic, which are easier to apply than earlier protocols in this space\n(e.g., Protocol Composition Logic [23], which is inspired by the Owicki-Gries method [44] and leads\nto a quadratic blowup in the number of veriﬁcation conditions required by parallel composition).\nApart from the approach to compositionality, the main diﬀerence between Cryptis and DY* is\nthat Cryptis is built upon separation logic, thus simplifying the integration of proofs of crypto-\ngraphic protocols with other components, which might be veriﬁed using other features of sepa-\nration logic. By contrast, components written in DY* must make use of the API exposed by the\nlibrary, which might not be a natural ﬁt for general-purpose programming. For example, if we\nwant to use DY* to implement a stateful system (such as our key-value store), we need to store\nits state within the session of a particular protocol. Such state sessions are manipulated with a\nbespoke interface that makes it convenient to write protocols, at the expense of making it more\nawkward to encode arrays or other user-deﬁned data structures.\nNaturally, there are many tools in this space, some of which aim for slightly diﬀerent goals than\nCryptis or DY*. For example, tools such as SSProve [1], EasyCrypt [10], EasyUC [48] or Owl [27]\nallow us to reason about protocols in the computational model of cryptography. The computational\nmodel is more realistic than the symbolic model on which Cryptis is based, since it assumes that\nattackers have the power to manipulate messages as raw bitstrings, without being conﬁned to a\nlimited API of cryptographic operations. On the other hand, dealing with such attackers requires\nmore detailed reasoning, which means that such tools have diﬃculty scaling beyond individual\ncryptographic primitives or simple protocols.\nSpeciﬁcation of authentication protocols. Most works on the veriﬁcation of authentication proto-\ncols view a protocol as a means for agents to agree on their identities, protocol parameters, session\nkeys, or the order of events during the execution [38, 12, 23, 28]. For example, if an initiator 퐼au-\nthenticates with a responder 푅, we might want to guarantee that 푅was indeed running at some\npoint in the past, that it was running and accepted to connect with 퐼speciﬁcally, or that it accepted\nto start a unique session with 퐼that corresponds to the session key that they exchanged [38].\nSome of these requirements are reﬂected in the Cryptis speciﬁcations of NSL and ISO (Sections 3\nand 4). For example, a session key is unequivocally associated with a particular initiator and re-\nsponder, since the agents’ public keys are used to derive the session key. However, other aspects\nof authentication are missing: the speciﬁcations do not guarantee that a successful handshake\ncompleted by the initiator must match a successful handshake by its responder.\nIt would be possible to adapt the speciﬁcations to enforce these properties as well. For example,\nwe could allocate a separation-logic resource for each agent where they could record all the ses-\nsions that they have been involved in. Then, we could modify the invariants of Figure 12 so that\nthe messages guarantee to the receiving agent that the session has been recorded in the sending\nagent’s trace. This resource could be deﬁned so that we could tie this trace of events to a physical\ndata structure manipulated by the agents, making it possible to provide a game-based formulation\nof these guarantees. Nevertheless, we chose not to emphasize this aspect of authentication in our\nspeciﬁcations, because it would complicate the presentation, but, more importantly, because we\nhave not found a use for such properties when composing the authentication protocol with other\nparts of the system. The possibility of attaching metadata and ghost state to terms allows agents\nto use the protocol to agree on how to use system resources even after the handshake completed,\nwhich suﬃces for reusing protocol speciﬁcations.\nVeriﬁcation of General-Purpose Protocols. Recent years have seen the introduction of several\ntools for reasoning about distributed systems and protocols, such as Disel [47], Actris [29, 30],\n24\n\n\nCryptis: Cryptographic Reasoning in Separation Logic\nPL’18, January 01–03, 2018, New York, NY, USA\nor Aneris [36]. One common limitation of these tools is that they assume a fairly reliable network-\ning model. For example, Actris assumes that messages cannot be dropped, duplicated or tampered\nwith, whereas Aneris assumes that messages cannot be tampered with. By contrast, Cryptis allows\nus to reason about programs running over an adversarial network, but provides few tools for rea-\nsoning about distributed protocols at a high-level. In future work, we would like to bring together\nthese two lines of research, by developing an extension of Cryptis that integrates the reasoning\nprinciples identiﬁed by these and other tools for reasoning about distributed systems.\n9\nCONCLUSION AND FUTURE WORK\nWe presented Cryptis, an Iris extension for symbolic cryptographic reasoning. As we demonstrated\nthroughout the paper, Cryptis makes it possible to reduce the correctness of distributed systems\nveriﬁed in Iris (or, more generally, in separation logic) to elementary assumptions embodied by the\nsymbolic model of cryptography, without the need for stronger (and less realistic) assumptions\nabout the integrity of network communication. The integration of cryptographic reasoning in\nseparation logic allows us to evaluate how the correctness of a system is aﬀected by compromising\ncryptographic material such as a long-term private key, going beyond what standard speciﬁcations\nin separation logic provide. Thanks to the adequacy of the Iris logic, which Cryptis inherits, these\ncorrectness results can be understood in rather concrete terms, via security games that rely only\non the operational semantics of the underlying programming language.\nLike related tools [12], Cryptis’ guarantees are currently limited to single executions. This can\nbe restrictive for security, since many secrecy properties talk about pairs of executions (e.g. indis-\ntinguishability). We plan to lift this restriction in the future, drawing inspiration from Sumii and\nPierce’s work on reasoning through sealing via logical relations [49, 50], as well as recent work\nthat extends Iris with relational reasoning [26]. Another avenue for strengthening the logic would\nbe to extend it for reasoning about probabilistic properties and the computational model of cryp-\ntography. Recent work shows that probabilistic reasoning can beneﬁt from separation logic [9],\nand we believe that these developments could be naturally incorporated to our setting. Finally, we\nplan to strengthen our set of cryptographic primitives to encompass more protocols. For example,\nthe recent OPAQUE protocol [31] relies on group inverses, something that Cryptis currently lacks.\nREFERENCES\n[1]\nCarmine Abate et al. “SSProve: A Foundational Framework for Modular Cryptographic\nProofs in Coq”. In: 34th IEEE Computer Security Foundations Symposium, CSF 2021, Dubrovnik,\nCroatia, June 21-25, 2021. IEEE, 2021,pp. 1–15. doi: 10.1109/CSF51468.2021.00048. url: https://doi.org/10\n[2]\nSuzana Andova et al. “A framework for compositional veriﬁcation of security protocols”. In:\nInf. Comput. 206.2-4(2008),pp. 425–459.doi: 10.1016/j.ic.2007.07.002. url: https://doi.org/10.1016/j.ic.200\n[3]\nMyrto Arapinis, Vincent Cheval, and Stéphanie Delaune. “Composing Security Protocols:\nFrom Conﬁdentiality to Privacy”. In: Principles of Security and Trust - 4th International Con-\nference, POST 2015, Held as Part of the European Joint Conferences on Theory and Practice of\nSoftware, ETAPS 2015, London, UK, April 11-18, 2015, Proceedings. Ed. by Riccardo Focardi and\nAndrew C. Myers. Vol. 9036. Lecture Notes in Computer Science. Springer, 2015, pp. 324–343.\ndoi: 10.1007/978-3-662-46666-7\\_17. url: https://doi.org/10.1007/978-3-662-46666-7%5C_17.\n[4]\nMyrto Arapinis, Vincent Cheval, and Stéphanie Delaune. “Verifying Privacy-Type Proper-\nties in a Modular Way”. In: 25th IEEE Computer Security Foundations Symposium, CSF 2012,\nCambridge, MA, USA, June 25-27, 2012. Ed. by Stephen Chong. IEEE Computer Society, 2012,\npp. 95–109. doi: 10.1109/CSF.2012.16. url: https://doi.org/10.1109/CSF.2012.16.\n[5]\nMichael Backes, Catalin Hritcu, and Matteo Maﬀei. “Union and Intersection Types for Secure\nProtocol Implementations”. In: Theory of Security and Applications - Joint Workshop, TOSCA\n25\n\n\nPL’18, January 01–03, 2018, New York, NY, USA\nArthur Azevedo de Amorim, Amal Ahmed, and Marco Gaboardi\n2011, Saarbrücken, Germany, March 31 - April 1, 2011, Revised Selected Papers. Ed. by Sebas-\ntian Mödersheim and Catuscia Palamidessi. Vol. 6993. Lecture Notes in Computer Science.\nSpringer, 2011,pp. 1–28. doi: 10.1007/978-3-642-27375-9\\_1. url: https://doi.org/10.1007/978-3-642-273\n[6]\nMichael Backes, Catalin Hritcu, and Matteo Maﬀei. “Union, intersection and reﬁnement\ntypes and reasoning about type disjointness for secure protocol implementations”. In: J.\nComput. Secur. 22.2 (2014),pp. 301–353.doi: 10.3233/JCS-130493. url: https://doi.org/10.3233/JCS-13049\n[7]\nJialu Bao et al. “A separation logic for negative dependence”. In: Proc. ACM Program. Lang.\n6.POPL (2022), pp. 1–29. doi: 10.1145/3498719. url: https://doi.org/10.1145/3498719.\n[8]\nManuel Barbosa et al. “SoK: Computer-Aided Cryptography”. In: IACR Cryptol. ePrint Arch.\n2019 (2019), p. 1393. url: https://eprint.iacr.org/2019/1393.\n[9]\nGilles Barthe, Justin Hsu, and Kevin Liao. “A probabilistic separation logic”. In: Proc. ACM\nProgram. Lang. 4.POPL (2020),55:1–55:30.doi: 10.1145/3371123. url: https://doi.org/10.1145/3371123.\n[10]\nGilles Barthe et al. “EasyCrypt: A Tutorial”. In: Foundations of Security Analysis and Design\nVII - FOSAD 2012/2013 Tutorial Lectures. Ed. by Alessandro Aldini, Javier López, and Fabio\nMartinelli. Vol. 8604. Lecture Notes in Computer Science. Springer, 2013, pp. 146–166. doi:\n10.1007/978-3-319-10082-1\\_6. url: https://doi.org/10.1007/978-3-319-10082-1%5C_6.\n[11]\nKarthikeyan Bhargavan et al. “An In-Depth Symbolic Security Analysis of the ACME Stan-\ndard”. In: CCS ’21: 2021 ACM SIGSAC Conference on Computer and Communications Security,\nVirtual Event, Republic of Korea, November 15 - 19, 2021. Ed. by Yongdae Kim et al. ACM, 2021,\npp. 2601–2617. doi: 10.1145/3460120.3484588. url: https://doi.org/10.1145/3460120.3484588.\n[12]\nKarthikeyan Bhargavan et al. “DY* : A Modular Symbolic Veriﬁcation Framework for Exe-\ncutable Cryptographic Protocol Code”. In: EuroS&P 2021 - 6th IEEE European Symposium on\nSecurity and Privacy. Virtual, Austria, Sept. 2021. url: https://hal.inria.fr/hal-03178425.\n[13]\nKarthikeyan Bhargavan et al. “Layered Symbolic Security Analysis in DY★”. In: Computer\nSecurity - ESORICS 2023 - 28th European Symposium on Research in Computer Security, The\nHague, The Netherlands, September 25-29, 2023, Proceedings, Part III. Ed. by Gene Tsudik et al.\nVol. 14346.Lecture Notes in Computer Science. Springer, 2023, pp. 3–21. doi: 10.1007/978-3-031-51479-1\nurl: https://doi.org/10.1007/978-3-031-51479-1%5C_1.\n[14]\nBruno Blanchet. “An Eﬃcient Cryptographic Protocol Veriﬁer Based on Prolog Rules”. In:\n14th IEEE Computer Security Foundations Workshop (CSFW-14 2001), 11-13 June 2001, Cape\nBreton, Nova Scotia, Canada. IEEE Computer Society, 2001, pp. 82–96. doi: 10.1109/CSFW.2001.930138.\nurl: https://doi.org/10.1109/CSFW.2001.930138.\n[15]\nStephen Brookes. “A semantics for concurrent separation logic”. In: Theor. Comput. Sci. 375.1-\n3 (2007),pp. 227–270.doi: 10.1016/j.tcs.2006.12.034. url: https://doi.org/10.1016/j.tcs.2006.12.034.\n[16]\nStephen Brookes and Peter W. O’Hearn. “Concurrent separation logic”. In: ACM SIGLOG\nNews 3.3 (2016), pp. 47–65. url: https://dl.acm.org/citation.cfm?id=2984457.\n[17]\nMichele Bugliesi, Riccardo Focardi, and Matteo Maﬀei. “Authenticity by tagging and typing”.\nIn: Proceedings of the 2004 ACM Workshop on Formal Methods in Security Engineering, FMSE\n2004, Washington, DC, USA, October 29, 2004. Ed. by Vijayalakshmi Atluri et al. ACM, 2004,\npp. 1–12. doi: 10.1145/1029133.1029135. url: https://doi.org/10.1145/1029133.1029135.\n[18]\nMichele Bugliesi, Riccardo Focardi, and Matteo Maﬀei. “Compositional Analysis of Authen-\ntication Protocols”. In: Programming Languages and Systems, 13th European Symposium on\nProgramming, ESOP 2004, Held as Part of the Joint European Conferences on Theory and Prac-\ntice of Software, ETAPS 2004, Barcelona, Spain, March 29 - April 2, 2004, Proceedings. Ed. by\nDavid A. Schmidt. Vol. 2986. Lecture Notes in Computer Science. Springer, 2004, pp. 140–154.\ndoi: 10.1007/978-3-540-24725-8\\_11. url: https://doi.org/10.1007/978-3-540-24725-8%5C_11.\n[19]\nMichael Burrows, Martín Abadi, and Roger M. Needham. “A Logic of Authentication”. In:\nACM Trans. Comput. Syst. 8.1 (1990),pp. 18–36. doi: 10.1145/77648.77649. url: https://doi.org/10.1145/77\n26\n\n\nCryptis: Cryptographic Reasoning in Separation Logic\nPL’18, January 01–03, 2018, New York, NY, USA\n[20]\nŞtefan Ciobâcă and Véronique Cortier. “Protocol Composition for Arbitrary Primitives”.\nIn: Proceedings of the 23rd IEEE Computer Security Foundations Symposium, CSF 2010, Ed-\ninburgh, United Kingdom, July 17-19, 2010. IEEE Computer Society, 2010, pp. 322–336. doi:\n10.1109/CSF.2010.29. url: https://doi.org/10.1109/CSF.2010.29.\n[21]\nCyril Cohen. “Pragmatic Quotient Types in Coq”. In: Interactive Theorem Proving - 4th In-\nternational Conference, ITP 2013, Rennes, France, July 22-26, 2013. Proceedings. Ed. by San-\ndrine Blazy, Christine Paulin-Mohring, and David Pichardie. Vol. 7998. Lecture Notes in\nComputer Science. Springer, 2013, pp. 213–228. doi: 10.1007/978-3-642-39634-2\\_17. url:\nhttps://doi.org/10.1007/978-3-642-39634-2%5C_17.\n[22]\nKatriel Cohn-Gordon, Cas J. F. Cremers, and Luke Garratt. “On Post-compromise Security”.\nIn: IEEE 29th Computer Security Foundations Symposium, CSF 2016, Lisbon, Portugal, June\n27 - July 1, 2016. IEEE Computer Society, 2016, pp. 164–178. doi: 10.1109/CSF.2016.19. url:\nhttps://doi.org/10.1109/CSF.2016.19.\n[23]\nAnupam Datta et al. “Protocol Composition Logic”. In: Formal Models and Techniques for An-\nalyzing Security Protocols. Ed. by Véronique Cortier and Steve Kremer. Vol. 5. Cryptology and\nInformation Security Series. IOS Press, 2011,pp. 182–221.doi: 10.3233/978-1-60750-714-7-182.\nurl: https://doi.org/10.3233/978-1-60750-714-7-182.\n[24]\nAndres Erbsen et al. “Simple High-Level Code for Cryptographic Arithmetic - With Proofs,\nWithout Compromises”. In: 2019 IEEE Symposium on Security and Privacy, SP 2019, San Fran-\ncisco, CA, USA, May 19-23, 2019. IEEE, 2019, pp. 1202–1219. doi: 10.1109/SP.2019.00005. url:\nhttps://doi.org/10.1109/SP.2019.00005.\n[25]\nAymeric Fromherz et al. “Steel: proof-oriented programming in a dependently typed concur-\nrent separation logic”. In: Proc. ACM Program. Lang. 5.ICFP (2021),pp. 1–30. doi: 10.1145/3473590.\nurl: https://doi.org/10.1145/3473590.\n[26]\nDan Frumin, Robbert Krebbers, and Lars Birkedal. “ReLoC: A Mechanised Relational Logic\nfor Fine-Grained Concurrency”. In: Proceedings of the 33rd Annual ACM/IEEE Symposium on\nLogic in Computer Science, LICS 2018, Oxford, UK, July 09-12, 2018. Ed. by Anuj Dawar and\nErich Grädel. ACM, 2018, pp. 442–451.doi: 10.1145/3209108.3209174. url: https://doi.org/10.1145/320910\n[27]\nJoshua Gancher et al. “Owl: Compositional Veriﬁcation of Security Protocols via an Information-\nFlow Type System”. In: 44th IEEE Symposium on Security and Privacy, SP 2023, San Francisco,\nCA, USA, May 21-25, 2023. IEEE, 2023, pp. 1130–1147. doi: 10.1109/SP46215.2023.10179477.\nurl: https://doi.org/10.1109/SP46215.2023.10179477.\n[28]\nAndrew D. Gordon and Alan Jeﬀrey. “Authenticity by Typing for Security Protocols”. In:\nJournal of Computer Security 11.4 (2003),pp. 451–520. url: http://content.iospress.com/articles/journal-o\n[29]\nJonas Kastberg Hinrichsen, Jesper Bengtson, and Robbert Krebbers. “Actris: session-type\nbased reasoning in separation logic”. In: Proc. ACM Program. Lang. 4.POPL (2020), 6:1–6:30.\ndoi: 10.1145/3371074. url: https://doi.org/10.1145/3371074.\n[30]\nJonas Kastberg Hinrichsen et al. “Machine-checked semantic session typing”. In: CPP ’21:\n10th ACM SIGPLAN International Conference on Certiﬁed Programs and Proofs, Virtual Event,\nDenmark, January 17-19, 2021. Ed. by Catalin Hritcu and Andrei Popescu. ACM, 2021,pp. 178–\n198. doi: 10.1145/3437992.3439914. url: https://doi.org/10.1145/3437992.3439914.\n[31]\nStanislaw Jarecki, Hugo Krawczyk, and Jiayu Xu. “OPAQUE: An Asymmetric PAKE Protocol\nSecure Against Pre-Computation Attacks”. In: IACR Cryptol. ePrint Arch. (2018), p. 163. url:\nhttp://eprint.iacr.org/2018/163.\n[32]\nRalf Jung et al. “Iris from the ground up: A modular foundation for higher-order concurrent\nseparation logic”. In: J. Funct. Program. 28 (2018), e20. doi: 10.1017/S0956796818000151. url:\nhttps://doi.org/10.1017/S0956796818000151.\n27\n\n\nPL’18, January 01–03, 2018, New York, NY, USA\nArthur Azevedo de Amorim, Amal Ahmed, and Marco Gaboardi\n[33]\nHugo Krawczyk. “SIGMA: The ’SIGn-and-MAc’ Approach to Authenticated Diﬃe-Hellman\nand Its Use in the IKE-Protocols”. In: Advances in Cryptology - CRYPTO 2003, 23rd Annual\nInternational Cryptology Conference, Santa Barbara, California, USA, August 17-21, 2003, Pro-\nceedings. Ed. by Dan Boneh. Vol. 2729. Lecture Notes in Computer Science. Springer, 2003,\npp. 400–425.doi: 10.1007/978-3-540-45146-4\\_24. url: https://doi.org/10.1007/978-3-540-45146-4%5C_2\n[34]\nRobbert Krebbers, Amin Timany, and Lars Birkedal. “Interactive proofs in higher-order con-\ncurrent separation logic”. In: Proceedings of the 44th ACM SIGPLAN Symposium on Principles\nof Programming Languages, POPL 2017, Paris, France, January 18-20, 2017. Ed. by Giuseppe\nCastagna and Andrew D. Gordon. ACM, 2017, pp. 205–217. doi: 10.1145/3009837.3009855.\nurl: https://doi.org/10.1145/3009837.3009855.\n[35]\nRobbert Krebbers et al. “The Essence of Higher-Order Concurrent Separation Logic”. In: Pro-\ngramming Languages and Systems - 26th European Symposium on Programming, ESOP 2017,\nHeld as Part of the European Joint Conferences on Theory and Practice of Software, ETAPS 2017,\nUppsala, Sweden, April 22-29, 2017, Proceedings. Ed. by Hongseok Yang. Vol. 10201. Lecture\nNotes in Computer Science. Springer, 2017, pp. 696–723.doi: 10.1007/978-3-662-54434-1\\_26.\nurl: https://doi.org/10.1007/978-3-662-54434-1%5C_26.\n[36]\nMorten Krogh-Jespersen et al. “Aneris: A Mechanised Logic for Modular Reasoning about\nDistributed Systems”. In: Programming Languages and Systems - 29th European Symposium\non Programming, ESOP 2020, Held as Part of the European Joint Conferences on Theory and\nPractice of Software, ETAPS 2020, Dublin, Ireland, April 25-30, 2020, Proceedings. Ed. by Peter\nMüller. Vol. 12075. Lecture Notes in Computer Science. Springer, 2020, pp. 336–365. doi:\n10.1007/978-3-030-44914-8\\_13. url: https://doi.org/10.1007/978-3-030-44914-8%5C_13.\n[37]\nJohn M. Li, Amal Ahmed, and Steven Holtzen. “Lilac: A Modal Separation Logic for Condi-\ntional Probability”. In: Proc. ACM Program. Lang. 7.PLDI (2023),pp. 148–171. doi: 10.1145/3591226.\nurl: https://doi.org/10.1145/3591226.\n[38]\nGavin Lowe. “A Hierarchy of Authentication Speciﬁcation”. In: 10th Computer Security Foun-\ndations Workshop (CSFW ’97), June 10-12, 1997, Rockport, Massachusetts, USA. IEEE Computer\nSociety, 1997, pp. 31–44. doi: 10.1109/CSFW.1997.596782. url: https://doi.org/10.1109/CSFW.1997.59678\n[39]\nGavin Lowe. “Breaking and Fixing the Needham-Schroeder Public-Key Protocol Using FDR”.\nIn: Tools and Algorithms for Construction and Analysis of Systems, Second International Work-\nshop, TACAS ’96, Passau, Germany, March 27-29, 1996, Proceedings. Ed. by Tiziana Margaria\nand Bernhard Steﬀen. Vol. 1055. Lecture Notes in Computer Science. Springer, 1996, pp. 147–\n166. doi: 10.1007/3-540-61042-1\\_43. url: https://doi.org/10.1007/3-540-61042-1%5C_43.\n[40]\nMatteo Maﬀei. “Tags for Multi-Protocol Authentication”. In: Electron. Notes Theor. Comput.\nSci. 128.5 (2005),pp. 55–63. doi: 10.1016/j.entcs.2004.11.042. url: https://doi.org/10.1016/j.entcs.2004.11.0\n[41]\nSimon Meier et al. “The TAMARIN Prover for the Symbolic Analysis of Security Protocols”.\nIn: Computer Aided Veriﬁcation - 25th International Conference, CAV 2013, Saint Petersburg,\nRussia, July 13-19, 2013. Proceedings. Ed. by Natasha Sharygina and Helmut Veith. Vol. 8044.\nLecture Notes in Computer Science. Springer, 2013,pp. 696–701.doi: 10.1007/978-3-642-39799-8\\_48.\nurl: https://doi.org/10.1007/978-3-642-39799-8%5C_48.\n[42]\nRoger M. Needham and Michael D. Schroeder. “Using Encryption for Authentication in\nLarge Networks of Computers”. In: Commun. ACM 21.12(1978),pp. 993–999.doi: 10.1145/359657.359659\nurl: https://doi.org/10.1145/359657.359659.\n[43]\nPeter W. O’Hearn. “Resources, concurrency, and local reasoning”. In: Theor. Comput. Sci.\n375.1-3(2007),pp. 271–307.doi: 10.1016/j.tcs.2006.12.035. url: https://doi.org/10.1016/j.tcs.2006.12.035.\n[44]\nSusan S. Owicki and David Gries. “An Axiomatic Proof Technique for Parallel Programs I”.\nIn: Acta Informatica 6 (1976),pp. 319–340. doi: 10.1007/BF00268134. url: https://doi.org/10.1007/BF00268\n28\n\n\nCryptis: Cryptographic Reasoning in Separation Logic\nPL’18, January 01–03, 2018, New York, NY, USA\n[45]\nMarina Polubelova et al. “HACLxN: Veriﬁed Generic SIMD Crypto (for all your favourite\nplatforms)”. In: CCS ’20: 2020 ACM SIGSAC Conference on Computer and Communications\nSecurity, Virtual Event, USA, November 9-13, 2020. Ed. by Jay Ligatti et al. ACM, 2020, pp. 899–\n918. doi: 10.1145/3372297.3423352. url: https://doi.org/10.1145/3372297.3423352.\n[46]\nJohn C. Reynolds. “Separation Logic: A Logic for Shared Mutable Data Structures”. In: 17th\nIEEE Symposium on Logic in Computer Science (LICS 2002), 22-25 July 2002, Copenhagen, Den-\nmark, Proceedings. IEEE Computer Society, 2002, pp. 55–74. doi: 10.1109/LICS.2002.1029817.\nurl: https://doi.org/10.1109/LICS.2002.1029817.\n[47]\nIlya Sergey, James R. Wilcox, and Zachary Tatlock. “Programming and proving with dis-\ntributed protocols”. In: Proc. ACM Program. Lang. 2.POPL (2018),28:1–28:30.doi: 10.1145/3158116.\nurl: https://doi.org/10.1145/3158116.\n[48]\nAlley Stoughton et al. “Formalizing Algorithmic Bounds in the Query Model in EasyCrypt”.\nIn: 13th International Conference on Interactive Theorem Proving, ITP 2022, August 7-10, 2022,\nHaifa, Israel. Ed. by June Andronick and Leonardo de Moura. Vol. 237. LIPIcs. Schloss Dagstuhl\n- Leibniz-Zentrum für Informatik, 2022, 30:1–30:21. doi: 10.4230/LIPIcs.ITP.2022.30. url:\nhttps://doi.org/10.4230/LIPIcs.ITP.2022.30.\n[49]\nEijiro Sumii and Benjamin C. Pierce. “A bisimulation for dynamic sealing”. In: Theor. Comput.\nSci. 375.1-3(2007),pp. 169–192.doi: 10.1016/j.tcs.2006.12.032. url: https://doi.org/10.1016/j.tcs.2006.12.0\n[50]\nEijiro Sumii and Benjamin C. Pierce. “Logical Relations for Encryption”. In: J. Comput. Secur.\n11.4 (2003),pp. 521–554.url: http://content.iospress.com/articles/journal-of-computer-security/jcs180.\n[51]\nNikhil Swamy et al. “SteelCore: an extensible concurrent separation logic for eﬀectful de-\npendently typed programs”. In: Proc. ACM Program. Lang. 4.ICFP (2020), 121:1–121:30. doi:\n10.1145/3409003. url: https://doi.org/10.1145/3409003.\n[52]\nThe Coq Development Team. The Coq Proof Assistant, version 8.12.0. Version 8.12.0. July 2020.\ndoi: 10.5281/zenodo.4021912. url: https://doi.org/10.5281/zenodo.4021912.\n29\n\n\n",
  "metadata": {
    "source_file": "dataset/pdfs/arxiv_2502.21156v1.pdf",
    "total_pages": 29,
    "title": "Cryptis: Cryptographic Reasoning in Separation Logic",
    "authors": [
      "Arthur Azevedo de Amorim",
      "Amal Ahmed",
      "Marco Gaboardi"
    ],
    "abstract": "We introduce Cryptis, an extension of the Iris separation logic that can be\nused to verify cryptographic components using the symbolic model of\ncryptography. The combination of separation logic and cryptographic reasoning\nallows us to prove the correctness of a protocol and later reuse this result to\nverify larger systems that rely on the protocol. To make this integration\npossible, we propose novel specifications for authentication protocols that\nallow agents in a network to agree on the use of system resources. We evaluate\nour approach by verifying various authentication protocols and a key-value\nstore server that uses these authentication protocols to connect to clients.\nOur results are formalized in Coq.",
    "published_date": "2025-02-28",
    "source": "arxiv"
  }
}