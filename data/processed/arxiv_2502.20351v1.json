{
  "id": "arxiv_2502.20351v1",
  "text": "1 \n \nKNOWM Memristors in a Bridge Synapse delay-based Reservoir Computing system for \ndetection of epileptic seizures \nDawid Przyczyna,*1,2 Grzegorz Hess3 and Konrad Szaciłowski*1 \n \n1. \nAGH University of Science and Technology, Academic Centre for Materials and \nNanotechnology, \nal. Mickiewicza 30, 30-059 Kraków, Poland \n2. \nAGH University of Science and Technology, Faculty of Physics and Applied Computer \nScience, \nal. Mickiewicza 30, 30-059 Kraków, Poland \n3 Jagiellonian University, Department of Neurophysiology and Chronobiology, Institute of \nZoology and Biomedical Research,  \nul. Gronostajowa 9, 30-387 Kraków, Poland \n \n \n1. \nAbstract \n \nNanodevices that show the potential for non-linear transformation of electrical signals \nand various forms of memory can be successfully used in new computational paradigms, such \nas neuromorphic or reservoir computing (RC). Dedicated hardware implementations based on \nfunctional neuromorphic structures significantly reduce energy consumption and/or increase \ncomputational capabilities of a given artificial neural network system. Concepts of RC, which \nas a flexible computational paradigm can be highly inclusive, are often used as a model to \ndescribe computations performed in materia. With mostly fixed internal structure, solid-state \ndevices, especially memristors, are studied as computational substrates in various RC systems. \nIn this work, we present single-node Echo State Machine (SNESM) RC system based on bridge \nsynapse as a computational substrate (consisting of 4 memristors and a differential amplifier) \nused for epileptic seizure detection. KNOWM memristors were posed as ideal candidates \nbecause of their easy prototyping and reliability of operation. In this account, we present an \napplication of commercially available KNOWM memristors in various neuromorphic \napplications, from simple analysis of switching and internal dynamics (elucidated form noise \nspectroscopy and total harmonic distortion analysis) to the classification and recognition of \ncomplex time series: epilepsy seizure recognition using a wrist-worn triaxial accelerometer. \nThe results show that the evolution of the signal in a feedback loop helps improve the \n\n\n2 \n \nclassification accuracy of the system for that task. The transformation in SNESM changes the \ncorrelation and distribution of the complexity parameters of the input signal. In general, there \nare more differences in the correlation of complexity parameters between the transformed signal \nand the input signal, which may explain the improvement in the classification scores.  SNESM \ncould prove to be a useful time series signal processing system designed to improve accuracy \nin classification tasks. \n \n2. \nIntroduction \n \nNowadays, one can observe a drastic technological development and a real \"explosion\" \nof data created and accumulated through various activities. Scientists are beginning to pay \nattention to an effect that we are already slowly beginning to observe in the world, the so-called \ninformational black hole. This concept is based on the fact that such a large amount of \ninformation is generated that we are physically unable to process it [1-4]. For this reason, vital \ninformation can get lost in a \"black hole\" overwhelmed by the commonly generated data noise. \nThis should not come as a surprise at a time when we can have, among many others, a smart \nrefrigerator, smart light bulbs, TV, telephone, washing machine, vacuum cleaner, curtains, \nheating, and assistant (e.g., Apple Siri, Google Assistant, Samsung Bixby) in our homes. These \ncomplex information collection and processing systems are known as the “Internet of Things” \n(IoT) [5-7]. Additionally, a huge portion of data is generated every second in cyberspace. We \nuse social media, messengers, online stores, video players, etc. The data collected on each of \nthese platforms is analyzed and profiled in order to be able to provide us with more personalized \nadvertisements and to make a bigger profit for the service provider. Furthermore, it provides us \nwith information published by our friends or groups to which we belong or subscribe, topics \nwhich attract our attention because of our aesthetic, intellectual, or political preferences [8]. \nThe collection and analysis of those data translates into real-world effects in the form of \nmonetary gains/losses [9,10], our choices as customers, and finally as voters (the case of \nCambridge Analytica affecting the US presidential election and Brexit) [11]. \n \nTo address the computational problems of the modern age, scientists are working to \nimprove existing hardware and software technologies, as well as develop unconventional and/or \nhybrid approaches known as heteroic computing [12]. The growth of the first approach is \ncommonly known to be subjected to Moore’s law, whereas the second approach attempts to \novercome its limitations through embedded multifunctionality and interaction with the \n\n\n3 \n \nenvironment [13]. Moore’s law states that computational capabilities of conventional transistor \ntechnologies will double every few years. However, there is a lower limit to miniaturization \ndue to (i) the granularity of matter and (ii) the effects of quantum tunneling of electrons through \nthe gate of the transistor and (iii) heat management problems, which are the main reasons for \nlooking for other computational technologies [14-19]. Second major issue is the so-called Von \nNeuman Bottleneck. It is a problem that limits the computing abilities of classic computers \nresulting from the separation of memory functions and processing that require communication \nbetween these components, which in turn limits the speed of the computing process. One of the \nnovel technologies that aims to resolve some of modern computing problems is the application \nof memristors (and other memristive elements) and memristive circuits [20-24]. \n \nIn a classic configuration, capacitive material (e.g. dielectric or semiconductor) is placed \nbetween metal electrode contacts in a sandwich-type system. Basically, memristive materials \nhave two resistance states, called HRS (high-resistive state) and LRS (low-resistive state). By \napplying electrical pulses (or scans) of proper voltage, materials can be SET or RESET to LRS \nor HRS depending on the memristor type and its initial state. Due to some preservation of states \nafter the turning off of the power source, resistive switching effect is hoped to be used as \nbuilding block for novel non-volatile memory. In this configuration, it would be a new genre \nof information storage elements, called ReRAM (resistive, random access memory) [25], which \nwould compete with currently available flash memory and some other continuously developed \ntechnologies (magnetoresistive random access memory, etc.). Nevertheless, the high demands \non the energy efficiency of the switching, its statistical repeatability, and speed of operation \nmake the new materials are still being sought to meet them. The application of novel elements, \nsuch as memristors, allows delegatement of some of the computational steps of artificial neural \nnetworks to be realized in materia [26]. \n \nMany scientists conduct intensive research that draws inspiration from biological neural \nstructures in order to achieve more efficient computational structures, potentially of a universal \nnature. The high popularity is evident by an increasing number of publications appearing each \nyear, scientific journals, and numerous conference meetings related to this subject. Interested \nreaders are referred to recent reviews on the subject [27-30]. As can be seen, neuromorphic \ncomputing appears to be moving towards \"conventional\" computing, or at least towards special \npurpose computing modules [31]. Recurrent neural networks, which are especially good at \nrepresenting dynamics of given input due to feedback loops present in the system, exhibit \nproblems with costly learning process. To solve this problem, Jäger and Maas independently \n\n\n4 \n \nproposed the Echo State Network (ESN) [32]⁠ and the Liquid State Machine (LSM) approaches \n[33].⁠ In their constructs, in contract with artificial neural networks, the information processing \nlayer is not to be trained, only the readout layer is subjected to training procedures. Thus, they \nsuggested the importance of the multidimensional, rich, and dynamic state space of the \ninformation processing layer [26,34]. Over time, both of these approaches to efficient training \nof recurrent neural networks were incorporated into a common conceptual framework named \nReservoir Computing (RC) and the information processing layer was named the \"reservoir\" \n[35,36]. The reservoir in the RC paradigm describes a computational substrate capable of \nrepresenting various inputs in a multidimensional configuration space of states, where \ncomputation is represented as a trajectory between successive states of the system in this space. \nHence, as a proof of concept, RC has been implemented in simple systems as a bucket of⁠ water, \nwhere the data set with human speech was encoded as a series of water splashes [37]. Pictures \nof the perturbed water surface and used as basis for classification tasks. In our previous work \nwe have shown that RC computing systems can be implemented even in such primitive setups \nas a doped cement and successfully used to classify simple signal according to its shape [38]. \n \nThese unconventional computing systems must have several features in order to \nfunction properly, namely they must show appropriate internal dynamics, volatile memory, and \nthe echo property of previous states. The RC circuits are based on: (i) a nonlinear element (e.g. \na memristor) that also provides memory functions, (ii) an input layer that provides \ninformation/signal for processing, (iii) readout layer, and optionally (iv) a delayed feedback \nloop that provides internal system dynamics [39,40]. The readout layer is the only part of the \nsystem that needs to be „trained” and that is capable of sampling and representing the internal \nstate of the reservoir. In other words, only simple model training is performed on the given \nfeatures of signal transformed by the reservoir. In this case, no sophisticated ANN network is \nneeded as readout, simple models such as linear regression, decision tree, etc.  suffice. There is \nan obvious trade-off between the complexity of reservoir layer and the complexity of the \nreadout process needed for a given classification/prediction task [41]. \n \nSingle-node echo-state machine (SNESM) are novel RC systems that has only one \nphysical node operating in the delayed feedback loop [26,42-45]. Basically, both the signal and \nthe physical node state change each time the signal passes through the device in each cycle. The \nevolution of the loop signal can potentially improve clustering and classification capabilities of \nthe RC system. Wlaźlak et. al. showed implementation of SNESM system based on a single \nhardware memristor for the signal classification task based on its amplitude [43,46]. In our \n\n\n5 \n \nprevious work we have shown clustering of musical consonant/dissonant intervals through \nsignal evolution in the software RC system based on the bridge synapse operating in the \nfeedback loop [47]. Bridge synapse consists of four memristors and a differential amplifier. It \nwas shown that bridge synapse is good at supporting lots of analog states, which can be \nbeneficial from the perspective of rich state space needed for a good reservoir computing \nsubstrate. \nEpilepsy is a disease that affects approximately 50 million people worldwide [48]. \nEpilepsy is diagnosed based on the appearance of seizures, which are defined as transient signs \nand/or symptoms resulting from abnormal activity of a population of brain nerve cells [49]. \nTherefore, epilepsy is considered a chronic brain disease characterized by an enduring \ndisposition towards recurrent unprovoked seizures and by the neurobiological, cognitive, \npsychological, and social consequences of this condition [50]. Causes of epilepsy are different \nand include structural, genetic, infectious, metabolic, immune, and finally unknown factors \n[49]. There are several types of epilepsy that are classified on the basis of the type of seizure \nand pattern of brain activity [51] recorded with the use of non-invasive electroencephalography \n(EEG) through electrodes affixed to the scalp [52]. Currently seizures can be controlled and it \nis estimated that 70% of patients could live without seizures with appropriate medication [48]. \nHowever, the occurrence of seizures is unpredictable and, therefore, the development of \nmethods of seizure detection is of great importance for a significant improvement in the quality \nof the patient, especially with a risk of sudden unexpected death in epilepsy (SUDEP) [53]. It \nshould be noted that while in many cases seizures are associated with muscle activity, usually \nstiffening and then jerking of an arm or leg (tonic-clonic seizures), there are also types that are \nnot associated with motor manifestations, for example, symptoms like hot and cold feelings, \nabnormal visual, olfactory, auditory, gustatory and somatic sensations, or seizures characterized \nby interruption of activities that occur suddenly with impairment of consciousness (absence \nseizures) [50]. Currently, EEG combined with video recordings are the most reliable methods \nfor detecting epileptic seizures; however, they are only available in ambulatory monitoring. \nThus, portable seizure detection devices have been proposed as an alternative solution [54]. \nAs of today, deep learning methods allow classification of epilepsy using EEG signals \nwith a precision of 99%, but those models require large datasets for training and classification \ntasks, and are cost ineffective [55]. Artificial data augmentation methods often must be used as \na large amount of epilepsy seizure data is generally hard to obtain. One of the advantages of \nRC systems is their capability of operating with scarce, incomplete data employing only the \n\n\n6 \n \nsimplest classificators (at the read-out layer) like linear regression, gradient descent, or decision \ntrees. There is no need for multilayer artificial neural networks to train the SNESM read-out \nlayer, as the reservoir performs data transformation that aims at simplifying classification task. \nThe SNESM system gives additional benefit in the form of dataset extension. Each consecutive \nsignal epoch is slightly different version of the base signal due to non-linear transformation and \ndamping in a delay-based RC system. Echo of the primary signal may be easier to classify due \nto changes in its complexity and correlations between the parameters that describe it. \n \nIn this work, we present characteristics (noise characteristics and total harmonic \ndistortion) of KNOWM memristors and bridge synapse based on them. Furthermore, we present \nanalysis of reservoir layer and results of evolution of classification accuracy score of analyzed \nsignal in the SNESM system based on hardware bridge synapse. For the classification task, we \nused a dataset containing cases of epilepsy, walking, running and sawing (overall 408 instances) \ncollected from three different patients using a triaxial accelerometer attached to the dominating \nhands, which is a common technique of a non-invasive and non-disturbing way of monitoring \nmotor activity [56-58]. On the contrary, other techniques, such as electroencephalography, \nelectrocardiography, and electromyography, are impractical in daily life. The data for each \npatient were then analyzed separately. A scarce dataset is used on purpose, as with the RC \napproach, and the system could be calibrated individually for each patient in a cost-effective \nmanner. Evolution of the signal in the system, especially damping, noise, and distortion \naccumulation, as well as nonlinear filtering influences improvement of a f1-score of \nclassification of used signals. F1 score is a statistical analysis used to test the classification \naccuracy of the system [59]. For this data set we have found that echo of the base signal \npresented a better classification accuracy of epilepsy in relation to unprocessed waveforms. \nFurthermore, when epochs were analyzed collectively, further improvements of classification \naccuracy were obtained. In addition, changes in distribution and correlation between \ncomplexity parameters are shown for the input signal and transformed signal, which could \nexplain changes in classification scores. This work poses as proof-of-concept that evolution of \nthe signal in SNESM systems can highlight features of given signal or transform it in such a \nway that the overall classification of it can be improved in the case of scarce dataset and simple \nclassification model. \n \n2.1. \n KNOWM memristors \n\n\n7 \n \nKNOWM Inc. memristors are semi-commercial memristive devices designed for scientific \nresearch [60]. It is very convenient at prototyping various memristive circuits. Several scientific \nworks use KNOWM memristors in their research [61,62]. The researchers presented the \npossibility of constructing a hardware chaotic Chua oscillator without the need to use equivalent \ncircuits [63]. The other group showed the characteristics of the impulse response and the \npossibility of coupling the operation of KNOWM memristors with an ultrasonic transducer \n[64]. These memristors are good candidates for the construction of hardware neural networks \nbased on thin-film nanomaterials because of their good and mostly repeatable performance and \nsimplicity in the prototyping of networks with various structures. The schematic layer diagram \nof the device is shown in Fig. 1. \n \nFigure 1. Layer diagram of the thin-film stack of nanomaterials in KNOWM memristive devices \nand depiction of the switching mechanism. Reprinted from Ref. [65].  \n \n \nThe mechanism of operation of KNOWM memristors proposed by the manufacturers is \nas follows. After manufacture, the devices are in the HRS state (MΩ – GΩ range). When the \ndevice is put into operation for the first time, a so-called self-directed channel is formed when \na positive potential to the upper electrode. In this case, the required potential is the same as that \nused during normal operation of the device. Applying a positive potential to the memristor \ngenerates Sn ions from the SnSe layer and forces them into the active Ge2Se3 layer (here W-\ndoped). The Sn ions are intended to facilitate the transport of Ag to the active layer at the Ge-\nGe binding sites. This occurs due to the energetically beneficial process in which the electrons \nentering the active layer (Ge2Se3) from the negatively polarized bottom electrode (with the \nsimultaneous formation of Sn ions from the SnSe layer) are strongly localized around Ge-Ge \n\n\n8 \n \ndimers. During this reaction, the glassy network of Ge2Se3 is distorted, creating an \"opening\" \nnear the Ge-Ge sites. That opening allows the Ag+ ions to access possible Ag-Ge binding site \nmore easily and become preferred conductive channels in the active layer for Ag+ movement \nduring device operation. As a result, the Sn ions facilitate the energetically favorable Ag/Ge \nsubstitution reaction at the Ge-Ge bond. This self-directed conductive channel is a result of the \nnatural structure of the glass and follows the position of the initial Ge-Ge dimers in the glass. \nSince Ag tends to agglomerate with other Ag atoms, the Ag-Ge substitution sites may favor Ag \nagglomeration in the glass. Accordingly, the resistance of the device is altered by adding or \nremoving Ag from agglomeration sites within this in situ generated path. It is anticipated that \nconduction may occur between clusters of Ag agglomerations in the glass. Therefore, the path \nneed not be composed of conductive metallic filaments that include two opposing electrodes, \nas in CBRAM devices. In the case of KNOWM memristors, the device resistance is dictated by \nthe Ag concentration in a given place of the agglomeration and the distance between successive \nplaces of the Ag agglomeration. Resistance regulation is carried out by the movement of Ag+ \nions between the device layers, forced by the application of a positive or negative electric \npotential [60]. \n \n3. \nResults \n3.1. \nLarge-amplitude sinusoidal voltammetry \n \nLASV (large amplitude sinusoidal voltage) is a classic electrochemical measurement \ntechnique, used here used to characterize memristive devices, to determine threshold of their \nswitching potential, speed of operation, and its repeatability. The probing signal is a simple \nsinusoidal wave of given frequency and amplitude. The scans were performed in the potential \nwindow for which switching from ON/OFF (or Low Resistive State/High Resistive State) states \nis repeatable, in order to determine the optimal \"SET\" and \"RESET\". \n \nTo prevent memristors from being burnt, measurements were made with a series 5 kΩ \nresistor in the circuit to limit the current. Too high currents (above 1mA) irreversibly damage \nKNOWM memristors, irreversibly switching them to LRS. On the other hand, too low currents \nprevent the system from switching to the LRS state. This was observed during memristor tests \nin which a 20 kΩ resistor was used. For a single chip (16 memristors), for a 20 kΩ resistor, 4 \nout of 16 memristors did not switch to the LRS state. In the case of the 5 kΩ resistor, all \nmemristors were switching and had good cycling repeatability. \n\n\n9 \n \n \nIn this study, LASV measurements were performed at 19 different scan speeds ranging \nfrom 1 to 100 Hz (example in Fig. 2a). The results are shown in Figs. S1 and S2. In this \nfrequency range, KNOWM memristors operate reliably, as producers show in the data sheet, \nthat they can operate even at 1000 Hz. LASV measurements were performed for three \nscenarios: for a single memristor and for a bridge synapse without and with a differential \namplifier.  \n \n3.2. \nTotal Harmonic Distortion \n \nOn the basis of the results from LASV measurements, an analysis of the frequency \ndistortion was performed. This was done by determining the total harmonic distortion (THD) \nparameter. It tells us about the contribution of higher harmonics of the total signal to the \nfundamental frequency of the signal and can thus be considered as a simple experimental index \nof device linearity [66]. It is especially useful in the characterization of memristive devices, \nbecause it gives a clear distinction between unipolar and bipolar memristors [67]. To determine \nTHD, Fourier spectra of the analyzed signals are needed (an example spectrum is shown in Fig. \n2b). Additionally, Fig. S3 shows a Fourier transform of an exemplary driving signal. Based on \nthe calculated Fourier transform for all frequencies analyzed, the fundamental THDF was \ndetermined on the basis of the following formula (1): \n𝑇𝑇𝑇𝑇𝐷𝐷𝐹𝐹=\nට𝑉𝑉22+𝑉𝑉32+𝑉𝑉42+⋯\n𝑉𝑉1\n, \n \n \n \n \n \n \n \n \n(1) \nwhere Vn is the nth amplitude of the frequency of successive higher-harmonic peaks observed \nin the Fourier spectra. The THD parameter in its fundamental form can take values greater than \n100%, hence the following correction can be applied as normalization (2): \n𝑇𝑇𝑇𝑇𝐷𝐷𝑅𝑅=\n𝑇𝑇𝑇𝑇𝐷𝐷𝐹𝐹\nට1+𝑇𝑇𝑇𝑇𝑇𝑇𝐹𝐹\n2, \n \n \n \n \n \n \n \n \n \n(2) \nwhere R in THDR stands for \"root mean square\". \n\n\n10 \n \n \nFigure 2. Exemplary LASV signal measured at 10 Hz (a) and Fourier spectra (with rectangular \napodizing function window) based on it (b). Total harmonic distortion determined on the basis \nof Fourier transform, for frequencies ranging from 1 to 100 Hz (c). Results presented for single \nmemristor (I), bridge synapse without differential amplifier (II), and with differential amplifier \n(III). \n \n \nFourier spectra clearly indicate bipolar character of the studied memristors, as all even \nand odd harmonics are equally well represented in the spectra (Fig. 2b) [67]. The results in \nFigure 2c show that higher THDR occurs at frequencies above 10 Hz for a single KNOWM \nmemristor, while for bridge synapse circuits, THDR is generally constant (apart from several \ncases in lower frequency range shown in Figure 2c). This is a marked difference between \nKNOWM memristors and reported theoretical models, where the introduction of a differential \namplifier into the Wien-like bridge resulted in a much increased THD [47]. \n \n3.3. \nNoise Analysis \n \nChronoamperometric methods were used to characterize the noise present in KNOWM \ndevices in the ±1 V range. A set of potentials was applied step manner (step size 100 mV) to \nthe device, and the response was measured for 100 s. The average values of the measured \ncurrent at each step during the measurement are shown in Fig. 3a. These values resemble the \nclassic hysteresis loop observed during LASV measurements. Presented in the time domain, \nthe alternating switching of the four memristors in the bridge synapse (without differential \namplifier) can be observed in Fig. 3b. If plotted in I-V (or V-V) domain, the result from Fig. 3b \nwould resemble the one on the Fig. 3a. In the next step, a Fourier transform was performed to \neach voltage step to calculate the noise spectra (Fig. 3c). \n\n\n11 \n \n \nFigure 3. Average current values for the noise measured in the potential window ± 1V for 100 \ns for each step of 100mV. The arrows indicate the direction of the measurement. Measurement \nperformed for a single memristor (a). Voltage difference recorded between individual elements \nof the bridge synapse during noise recording measurement (b). Noise measured for KNOWM \nmemristors presented in frequency domain, for potentials from 0V to 1V. The black line \nindicates the thermal base floor measured at 0V (c). An example of fitting a line to the several \nfiltered noise spectra (d). \n \n \nThe slope of the noise spectra was determined in order to compare the noise character \nat different potentials (Fig. 3d). Due to the fact that the results are presented on a logarithmic \nscale, in order to reliably fit the lines, it is necessary to interpolate recorded traces, and reduce \npoint density to achieve uniform data point distribution in all frequency ranges.  \n\n\n12 \n \n \nFigure 4. Collected slope values of noise spectra at different DC potentials. Arrows indicate \ndirection of the experiment. Results for single KNOWM memristor (a), synaptic bridge (b), and \na circuit comprising a bridge synapse and a differential amplifier (c). \n \n \nGenerally, the noise spectra observed in the case of KNOWM devices are of red/brown \ncharacter [68], described by the power law of the form (3): \n𝑆𝑆𝑉𝑉(𝑓𝑓) ∝\n1\n𝑓𝑓𝛾𝛾 \n \n \n \n \n \n \n \n \n \n \n(3) \nwhere 𝑆𝑆𝑉𝑉𝑆𝑆(𝑓𝑓) is the spectral power density of the signal and γ is a parameter that reflects the \nnoise type (0 for white noise, -1 for pink one, and -2 for the brown noise. In the studies cases, \nwe can see that the thermal noise of the KNOWM memristor evolved from white through pink \nto brown noise, depending on the applied potential and its history, as the noise exponent for all \nstudied circuits follows the hysteresis loop, however the point s are a bit more scattered. During \nthe stepwise voltage scans, the γ parameter changed from close to zero at very low voltages \ndown to -2 for voltages higher than ca. 0.5 V. At ca. 1 V (the point of transition from HRS to \nLRS), the noise parameter gradually increased to zero with decreasing voltage (Fig. 4a). This \nbehavior indicates that the charge carrier dynamics in multilayer KNOWM memristors is \ncomplex and voltage-dependent. Voltage dependence may suggest electron-hopping-type \nconductivity [69]. \nSanta et al. suggest internal fluctuations between metastable atomic positions as one of the \npossible mechanisms of observing 1/f type noise in Ag filament-based memristive materials. \nFurthermore, redox exchange is another possible mechanism, which in our studies would \noriginate from the binding of Ag+ ions to the Ge-Ge sites during the switching. Diffusion of Ag \n+ ions inside Ag clusters may also have an influence on registered noise [70,71]. This \nsuggestion is consistent with the observed characteristics. In the HRS conductivity is dominated \nby the hopping impurity mechanism, and results in low γ values (γ ≤ −1), which depend on \n\n\n13 \n \napplied potential only weakly. In LRS state, the γ values are significantly higher (γ ≥ −1), and \nincrease with decreasing voltage across the device. It is associated with mixed conductivity \ntype/; Ohmic via filaments (or silver agglomerates) and impurity hopping in the bulk of the \nmaterial. \nThe observable noise signature demonstrates the presence of multiple conductivity channels \nthat form a complex network within a single device. The source of the noise can thus be \ndescribed as an internal switching dynamics of an atomic switch network with a small world \narchitecture [36]. \nIt is in accordance with the literature studying 1/f noise present in memristive devices. For a \nbridge synapse (Figs. 4b and 4c), white noise is observed at potential close to 0V. The most \nsymmetric response is observed for the bridge synapse without a differential amplifier (Fig. \n4b), as this configuration is symmetrical in design. Symmetric switching of the KNOWM \nmemristors in the bridge synapse is shown in Fig. 3b. \n \n3.4. \nAnalysis of simple signal transformation in SNESM \n \nAs part of the initial characterization of signal transformation in the SNESM system, \nsimple signals of various shapes and frequencies were applied to the reservoir. Frequency \nranged from 1 to 10Hz in 1Hz steps and from 10Hz to 100Hz in 10Hz steps were used. The \ndelay time of the returned signal was determined as 20% of the signal packet duration, which \nprovided an equal relative distance of repeated packets between different frequencies (an \nexample shown in Fig. S4). \n \nTo analyze differences in signal damping, we fitted an exponential decay function to the \nmaximal potential values of all signal packages. The time constant of the fitted exponent was \ncollected for the frequencies and signal shapes (results shown in Fig. 5). \n\n\n14 \n \n \nFigure 5. Collection of the values of exponential decay time constant for three signal shapes. \nSignal measured in SNESM with bridge synapse as computational substrate.  \n \n \nResults show that for nearly all studied frequencies, clear separation of time constant \ncan be noticed, however a substantial overlap is also present in some frequency ranges (ca. 5-\n10 and 50-100 Hz). That result further suggests that signals of various shapes and frequencies \ncan be represented in the SNESM system differently, possibly enabling their classification. \nFurthermore, signals of different shapes are filtered in a different way by a reservoir. Generally, \ntriangular-shaped waves were damped the most, whereas square waves were passing with less \nattenuation. This result supports the presence of two fundamental reservoir requirements: \nseparation and generalization properties – signals of different shapes are separated by the \nsystem, and this separation is generalized across different frequencies (with slight deviations at \n1, 5 and 6Hz). Finally, the memory of KNOWM memristor (in addition to its resistive switching \nproperties) can be represented as changes in the noise characteristics, which is sensitive to the \nsystem history, which is another important feature sought in the RC paradigm.  \n \n3.5. \nEpilepsy detection \n \nThe classification possibilities and the influence of the RC system on signal evolution \nwere tested in the recognition of signals representing an epilepsy attack in patients. The dataset \ncontains results for three patients, with 136 instances per patient. The classes included in the \ndataset are \"walking\", \"running\", „sawing”, and \"epileptic seizure\". The data set contains time \nseries of equal length. \n\n\n15 \n \n \nFigure 6. Examples of four classes of signals from the dataset (after standardization) (a). \nEvolution of the signal in the SNESM system (b). First, the driving signal passes through the \nsystem, then is delayed and feed back again (arrows indicate direction of data flow). \n \n \nDue to the nonlinear nature of the operation of memristors, which translates into non-\nlinearity in the transformation of signals through the entire bridge synapse, strong filtering of \nnegative part of signals can be observed (Fig. 6b). Individual signal epochs exhibit stationary \ncharacter which was confirmed with the augmented Dickey-Fuller as well as the Kwiatkowski-\nPhillips-Schmidt-Shin test. Subsequently, 11 parameters characterizing the complexity of the \nsignal were calculated, which served as features for the ML model training. An example of the \ncorrelation analysis (Pearson's correlation parameter) of the calculated features can be seen on \nFig. 7. The presence of positive and negative correlations in the dataset is desirable, potentially \ncontributing to a good classification accuracy. The calculated parameters were then used in \ntraining/testing a decision tree classification algorithm.  \n\n\n16 \n \n \nFigure 7. Exemplary result of Pearson's correlation for the \"features\" of the signal used by the \nreservoir system (a). The numbers correspond to the following parameters: 1- 'Permutation \nentropy', 2- 'Spectral entropy', 3- 'Singular value decomposition entropy', 4-'Approximate \nentropy', 5-'Sample entropy', 6-'Hjorth mobility ', 7 -'Hjorth complexity ', 8-'Number of zero \ncrossings’, 9-'Petrosian Fractal Dimension ', 10-Katz Fractal Dimension', 11-'Higuchi Fractal \ndimension ', 12-'Detrendend Fluctuational Analysis. Results for unprocessed input data (patient \nno. 1) (a) data transformed with SNESM: all 5 epochs (b), only second epoch (c), only 5th epoch \n(d). \n \n \nThe analysis was performed for a maximum of 7 epochs of the signal (an increasing part \nof the signal was filtered in further epochs). Analysis was performed for each individual epoch \n(Fig. 8a) as well as for several epochs at the same time (Fig. 8b). The classic statistical \nparameter was used to determine the accuracy of the classification performed by the SNESM. \nIt is the harmonic mean of the ‘precision’ (known as a positive predictive value) and “recall” \n\n\n17 \n \n(also known as sensitivity) classification parameters. Precision is the fraction of relevant \ninstances (target class, \"Epilepsy\" in this study) among the other instances, whereas recall is the \nfraction of the relevant instances that have been classified correctly among other instances from \nthe same class that have been omitted. F1 scores are biased to the lowest value of each precision \nand recall, so when the F1 score increases, both precision and recall parameters will be \nincreased and balanced. In Fig. 8 are presented results of the classification accuracy for \nincreasing number of consecutive signal epochs. \n \nFigure 8. Result of classification precision scores for consecutive signal epochs (a) and for \nseveral epochs at once (b). The number ‘0’ symbolizes unprocessed input data that serve as a \nreference. \n \n \nThe results obtained show that after several cycles, system exhibits an improvement of \nclassification accuracy in comparison to unprocessed data. When the data were analyzed \ncollectively, several epochs at once, further improvements in accuracy were obtained. To \nillustrate and compare the operation of the SNESM system for different patients, results were \nnormalized in relation to the accuracy of unprocessed data, representing ‘1’. This method of \ndata presentation allows for a simpler comparison of data sets from different patients for which \nthe initial classification accuracy serving as a reference may differ. Apart from the case of \npatient no. 2, the first signal epoch actually worsens the classification accuracy. However, \ntaking into account first and second signal epoch, accuracy is improved for all patients even \nthough for individual epochs the accuracy was worse than reference. This effect may arise due \nto SNESM capabilities of data expansion and data transformation. \n\n\n18 \n \nFigure 9. Comparison of histograms for the complexity parameters of the unprocessed signal \n(“Pure”, colored red) and the transformed signal in the reservoir computing system (“RC”, \ncolored blue) for the patient no. 1 (Epoch no. 5 for RC). \n \n \nTo inspect changes in complexity of the transformed signal histograms of two cases \nwere compared – unprocessed signal and epoch no. 5 of this signal transformed by the SNESM \nfor patient no. 1. Those signals were chosen as in this case, the highest improvement of \nclassification accuracy was observed for a single signal epoch. Almost all of the calculated \ncomplexity parameters show distinct changes in their distribution, which can be one of the main \nreasons for improvement in the classification task in question. Not only those distributions \nchanged, but also correlations between individual parameters have changed, where for \ntransformed signal, more positive correlations are present for parameters which previously \nexhibited weak correlation (Figs. 7a, b). At the same time, for the 2nd epoch case, the highest \nnumber of extreme correlation values can be observed, where for this case the classification \naccuracy result was the worst. The correlation results for the fifth epoch (Fig. 7d) are more \nsimilar to the correlation results for the cumulative five epochs (Fig. 7b), which may suggest \nthat there are some optimal parameter correlation values that maximize the final ability of the \nsystem to accurately classify data.  \n \n4. \nSummary \n\n\n19 \n \n \nIn this work we have presented measurements and analysis of THDR and noise in \nKNOWM memristors and bridge synapse based on them. Furthermore, the bridge synapse was \nincorporated into SNESM as a computational node. Analysis was performed on damping of \nsignal of three standard different shapes (sin, square, and triangle) based on time constants of \nfitted exponential decay curves. After establishing rich internal dynamics, memory, \nseparability, and generalization properties, the SNESM system was tested as a tool to improve \nthe classification of epilepsy. The system was tested under the constraints of scarce datasets \n(data from three patients classified in parallel) and using a simple classification model (decide \ntree). The results show an improvement in classification accuracy for several transformed signal \nepochs. Further improvements were achieved when signal epochs were analyzed collectively. \nThis result shows that by transforming and filtering data in the SNESM system, certain \nproperties of a given signal are amplified and others weakened, which is represented by \ndifferent values of its non-linear dynamics parameters and changes of their correlation. \n \nNonlinear transformation, filtering of the signal, and its evolution in the feedback loop \nhave a positive effect on the overall classification accuracy score. Results of similar nature were \nshown in one of our previous works, where signal filtering through an artificial neuron helped \nto improve overall data separability [72]. As was shown before, bridge synapse exhibits rich \ndynamics represented in several ways: in its noise characteristics, THDR and time constant of \nexponential decay. As various RC systems aim to be more general in their computation \ncapabilities, those facts may serve as an indication that this SNESM based RC can be a good \ncomputational system for other classification tasks. Results of characterization of KNOWM \nmemristors and bridge synapse-based SNESM system suggests the possibility of employing \nsuch systems for other computational and/or classification/prediction tasks, with scarce datasets \nand simple classification models. \n \n5. \nExperimental \nThree different circuits used in this study are shown in Fig. 10. BioLogic Sp-150 was \nused to measure LASV and chronoamperometric noise measurements. ADA-24 PicoLog was \nused to probe individual KNOWM memristors in the bridge synapse. An analog channel of \nBioLogic was used to record signals of simple shapes (sin, triangle, and square). Fitting of \nexponential decay curves and collection of their time constants were performed using Python \n\n\n20 \n \n(Pandas and SciPy packages). OriginPro was used in calculations of the fast Fourier Transform \nfor THD and noise analysis.  \n \nFigure 10. Schematics of the systems studied. Bridge synapse without (a), with differential \namplifier (b), and incorporated into SNESM system (c). \n \n \nThe dataset for the classification task was downloaded from the \"UEA & UCR Time \nSeries \nClassification \nRepository\" \n(https://www.timeseriesclassification.com/description.php?Dataset=Epilepsy). Firstly, the data \nset was standardized using Python. The arbitrary function generator TTI TG5012A was used to \napply the signals to the RC system. Data were uploaded from a flash drive in bits of four \n(maximum TTI TG5012A memory). Each waveform required additional scaling to be in the \n1Vpp range due to the observed lack of consistency in the amplitudes of the signals generated \nby the TTI TG5012A. Before each measurement, an Agilent oscilloscope was used to fine-scale \nthe signal. The Rigol DG4062 generator was used as the arbitrary trigger for the TTI TG5012A \nsignal source. Furthermore, the TTI WA301 amplifier was used as a current buffer. The bridge \nsynapse includes the TL082 operational amplifier (powered by a 9 V battery) in differential \nmode - the negative input of the operational amplifier has an additional feedback from the \namplifier output connected through a 10 kΩ resistor. The analog channel of the Biologic SP-\n150 potentiostat was used to record the data. Custom-made delay line (Chip, Poland) was used \nin the setup. The generator signal was first sent to delay, then to the Kacper-01 analog \npotentiostat (Instytut Fotonowy, Poland), which transmitted the signal to the synaptic bridge. \nThe differential amplifier passed the signal back to the delay (via the TTI amplifier). The delay \nsignal was recorded, delayed, attenuated (~ 10%) and finally circulated back to the system until \nfully suppressed.  \n\n\n21 \n \n \nThe recorded signal was then analyzed using Python. To analyze reservoir properties, \nan exponential decay function was fitted to maximal amplitudes of given repeated signal \ninstances. Time constants of exponential decay were collected and presented in Fig. 5. The \nextraction of signal complexity features was performed using the AntroPy Python package. A \nshort description of the calculated complexity parameters can be found in the SI. The \nparameters with appropriate labels were passed through a simple machine learning pipeline \n(using Python Scikit learn package). Initially, general descriptions of the data (histograms and \ncorrelation matrix) were generated. A 10-fold cross-validation was used to divide the data set \ninto training and testing sets. It involves dividing the data set into 10 parts, using 9 parts as a \ntraining set and 1 part as a testing set. This procedure is then repeated 10 times so that each \npiece of data is used as both a training and a testing set. As a classification model, the Decision \nTree Classifier implemented in scikit-learn Python package was used. The complexity \nparameters of the unprocessed signal were used as a reference. Model training was performed \non an unprocessed signal and for each consecutive delay signal epoch. In the next step, an \nincreasing number of signal epochs were collectively used in training/testing the model. \n \n6. Acknowledgements \nThe authors acknowledge the financial support from the Polish National Science Center within \nthe OPUS (grant agreement No. UMO-2020/37/B/ST5/00663) and PRELUDIUM (grant \nagreement No. UMO-2018/31/N/ST5/03112) projects. DP has been partly supported by the EU \nproject POWR.03.02.00-00-I004/16. \n \n7. Literature \n1. Schuster, A.J. Understanding information. Springer: 2017. \n2. Zgurovsky, M.Z.; Zaychenko, Y.P. Big data: Conceptual analysis and applications. \nSpringer: 2020; Vol. 58. \n3. Schuster, A.J. Understanding information: From the big bang to big data. Springer: Cham, \n2017. \n4. Sangaiah, A.K.; Thangavelu, A.; Sundaram, V.M. Cognitive computing for big data \nsystems over iot. Springer: Cham, 2018. \n\n\n22 \n \n5. Reis, R. In Challenges in the design of integrated systems for iot, Cham, 2020; Springer \nInternational Publishing: Cham, pp 179-196. \n6. Yassine, A.; Singh, S.; Hossain, M.S.; Muhammad, G. Iot big data analytics for smart \nhomes with fog and cloud computing. Future Generation Computer Systems 2019, 91, 563-\n573. \n7. Reis, R. In Strategies for reducing power consumption and increasing reliability in iot, \nCham, 2019; Springer International Publishing: Cham, pp 76-88. \n8. Zafarani, R.; Abbasi, M.A.; Liu, H. Social media mining: An introduction. Cambridge \nUniversity Press: 2014. \n9. Lee, T.K.; Cho, J.H.; Kwon, D.S.; Sohn, S.Y. Global stock market investment strategies \nbased on financial network indicators using machine learning techniques. Expert Systems \nwith Applications 2019, 117, 228-242. \n10. Tkáč, M.; Verner, R. Artificial neural networks in business: Two decades of research. App. \nSoft Comput. 2016, 38, 788-804. \n11. Rathi, R. Effect of cambridge analytica’s facebook ads on the 2016 us presidential election. \nhttps://towardsdatascience.com/effect-of-cambridge-analyticas-facebook-ads-on-the-\n2016-us-presidential-election-dacb5462155d (15.05.22),  \n12. Kendon, V.; Sebald, A.; Stepney, S. Heterotic computing: Past, present and future. \nPhilosophical Transactions of the Royal Society A: Mathematical, Physical and \nEngineering Sciences 2015, 373, 20140225. \n13. Arden, W.; Brillouët, M.; Cogez, P.; Graef, M.; Huizing, B.; Mahnkopf, R. More-than-\nmoore white paper. Version 2010, 2, 14. \n14. Szaciłowski, K. Infochemistry. Information processing at the nanoscale. John Wiley & \nSons: Chichester, 2012. \n15. Adamatzky, A.; Akl, S.G.; Sirakoulis, G.C. From parallel to emergent computing. CRC \nPress: Boca Raton, 2019. \n16. Stepney, S.; Adamatzky, A. Inspired by nature. Springer International Publishing: Cham, \n2018. \n17. Adamatzky, A. Advances in unconventional computing. Prototypes, models and \nalgorithms. Springer International Publishing: 2017. \n18. Adamatzky, A. Advances in unconventional computing. Theory. Springer International \nPublishing: 2017. \n19. Adamatzky, A. Handbook of unconventional computing. World Scientific: 2020; p 1208. \n\n\n23 \n \n20. Pilarczyk, K.; Wlaźlak, E.; Przyczyna, D.; Blachecki, A.; Podborska, A.; Anathasiou, V.; \nKonkoli, Z.; Szaciłowski, K. Molecules, semiconductors, light and information: Towards \nfuture sensing and computing paradigms. Coord. Chem. Rev. 2018, 365, 23-40. \n21. Li, Y.; Wang, Z.; Midya, R.; Xia, Q.; Yang, J.J. Review of memristor devices in \nneuromorphic computing: Materials sciences and device challenges. Journal of Physics D: \nApplied Physics 2018, 51, 503002. \n22. Liao, K.; Lei, P.; Tu, M.; Luo, S.; Jiang, T.; Jie, W.; Hao, J. Memristor based on inorganic \nand organic two-dimensional materials: Mechanisms, performance, and synaptic \napplications. ACS Applied Materials & Interfaces 2021, 13, 32606-32623. \n23. Chua, L.; Sirakoulis, G.C.; Adamatzky, A. Handbook of memritsor networks. Springer \nNature: Switzerland, 2019. \n24. Adamatzky, A.; Chua, L. Memristor networks. Springer: New York, 2014. \n25. Ito, S.; Hayakawa, Y.; Wei, Z.; Muraoka, S.; Kawashima, K.; Kotani, H.; Kouno, K.; \nNakamura, M.; Du, G.A.; Chen, J.F. In Reram technologies for embedded memory and \nfurther applications, 2018 IEEE International Memory Workshop (IMW), 2018; IEEE: pp \n1-4. \n26. Przyczyna, D.; Zawal, P.; Mazur, T.; Strzelecki, M.; Gentili, P.L.; Szaciłowski, K. In-\nmaterio neuromimetic devices: Dynamics, information processing and pattern recognition. \nJpn. J. Appl. Phys. 2020, 59, 050504. \n27. Kumar, S.; Wang, X.; Strachan, J.P.; Yang, Y.; Lu, W.D. Dynamical memristors for \nhigher-complexity neuromorphic computing. Nature Reviews Materials 2022. \n28. Park, H.-L.; Lee, T.-W. Organic and perovskite memristors for neuromorphic computing. \nOrganic Electronics 2021, 98, 106301. \n29. Zhou, G.; Wang, Z.; Sun, B.; Zhou, F.; Sun, L.; Zhao, H.; Hu, X.; Peng, X.; Yan, J.; Wang, \nH. Volatile and nonvolatile memristive devices for neuromorphic computing. Advanced \nElectronic Materials 2022, 2101127. \n30. Wlaźlak, E.; Przyczyna, D.; Gutierrez, R.; Cuniberti, G.; Szaciłowski, K. Towards \nsynthetic neural networks: Can artificial electrochemical neurons be coupled with artificial \nmemristive synapses? Jpn. J. Appl. Phys. 2020, 59, SI0801. \n31. Akopyan, F.; Sawada, J.; Cassidy, A.; Alvarez-Icaza, R.; Arthur, J.; Merolla, P.; Imam, N.; \nNakamura, Y.; Datta, P.; Nam, G.-J. Truenorth: Design and tool flow of a 65 mw 1 million \nneuron programmable neurosynaptic chip. IEEE Trans. Comp.-Aided Des. Integr. Circ. \nSyst. 2015, 34, 1537-1557. \n\n\n24 \n \n32. Jaeger, H. The “echo state” approach to analysing and training recurrent neural networks-\nwith an erratum note. Bonn, Germany: German National Research Center for Information \nTechnology GMD Technical Report 2001, 148, 13. \n33. Maass, W.; Natschläger, T.; Markram, H. Real-time computing without stable states: A \nnew framework for neural computation based on perturbations. Neural Comput. 2002, 14, \n2531-2560. \n34. Otto, A.; Just, W.; Radons, G. Nonlinear dynamics of delay systems: An overview. \nPhilosophical Transactions of the Royal Society A: Mathematical, Physical and \nEngineering Sciences 2019, 377, 20180389. \n35. Konkoli, Z.; Nichele, S.; Dale, M.; Stepney, S. Reservoir computing with computational \nmatter. In Computational matter, Springer: 2018; pp 269-293. \n36. Nakajima, K.; Fischer, I. Reservoir computing. Theory, physical implementations, and \napplications. Springer Nature Singapore: Singapore, 2021. \n37. Fernando, C.; Sojakka, S. In Pattern recognition in a bucket, European conference on \nartificial life, 2003; Springer: pp 588-597. \n38. Przyczyna, D.; Suchecki, M.; Adamatzky, A.; Szaciłowski, K. Towards embedded \ncomputation with building materials. Materials 2021, 14, 1724. \n39. Hart, J.D.; Larger, L.; Murphy, T.E.; Roy, R. Delayed dynamical systems: Networks, \nchimeras and reservoir computing. Phil Trans. A 2019, 377, 20180123. \n40. Biswas, D.; Banerjee, T. Time-delayerd chaotic dynamical systems. Springer Nature: \nCham, 2018. \n41. Konkoli, Z. On reservoir computing: From mathematical foundations to unconventional \napplications. In Advances in unconventional computing. Vol. 1: Theory, Adamatzky, A., \nEd. Springer International Publishing: Cham, Switzerland, 2017. \n42. Lis, M.; Omuna, S.; Przyczyna, D.; Zawal, P.; Mazur, T.; Pilarczyk, K.; Gentili, P.L.; \nKasai, S.; Szaciłowski, K. From oscillatory reactions to robotics: A serendipitous journey \nthrough chemistry, physics and computation. In Handbook of unconventional computing, \nWorld Scientific: Singapore, 2022; pp 1-80. \n43. Wlaźlak, E.; Marzec, M.; Zawal, P.; Szaciłowski, K. Memristor in a reservoir system—\nexperimental evidence for high-level computing and neuromorphic behavior of pbi2. ACS \napplied materials & interfaces 2019, 11, 17009-17018. \n44. Wlaźlak, E.; Zawal, P.; Szaciłowski, K. Neuromorphic applications of a multivalued [sni4 \n{(c6h5) 2so} 2] memristor incorporated in the echo state machine. ACS Applied Electronic \nMaterials 2020, 2, 329-338. \n\n\n25 \n \n45. Przyczyna, D.; Pecqueur, S.; Vuillaume, D.; Szaciłowski, K. Reservoir computing for \nsensing—an experimental approach. Int. J. Unconv. Comput. 2019, 14, 267-284. \n46. Wlaźlak, E.; Zawal, P.; Szaciłowski, K. Neuromorphic applications of a multivalued \n[sni4{(c6h5)2so}2] memristor incorporated in the echo state machine. ACS Appl. Electron. \nMater. 2020, 2, 329-338. \n47. Przyczyna, D.; Szaciłowska, M.; Przybylski, M.; Strzelecki, M.; Szaciłowski, K. \nRecognition of musical dissonance and consonance in a simple neuromorphic computing \nsystem. Int. J. Unconv. Comput. 2022, 17, 81-104. \n48. Epilepsy. https://www.who.int/news-room/fact-sheets/detail/epilepsy]. (03.06.2022),  \n49. Falco-Walter, J.J.; Scheffer, I.E.; Fisher, R.S. The new definition and classification of \nseizures and epilepsy. Epilepsy research 2018, 139, 73-79. \n50. Sarmast, S.T.; Abdullahi, A.M.; Jahan, N. Current classification of seizures and epilepsies: \nScope, limitations and recommendations for future action. Cureus 2020, 12. \n51. Scheffer, I.E.; Berkovic, S.; Capovilla, G.; Connolly, M.B.; French, J.; Guilhoto, L.; \nHirsch, E.; Jain, S.; Mathern, G.W.; Moshé, S.L. Ilae classification of the epilepsies: \nPosition paper of the ilae commission for classification and terminology. Epilepsia 2017, \n58, 512-521. \n52. Noachtar, S.; Rémi, J. The role of eeg in epilepsy: A critical review. Epilepsy & Behavior \n2009, 15, 22-33. \n53. Frei, M.G. Seizure detection. Scholarpedia 2013, 8, 5780. \n54. Regalia, G.; Onorati, F.; Lai, M.; Caborni, C.; Picard, R.W. Multimodal wrist-worn devices \nfor seizure detection and advancing research: Focus on the empatica wristbands. Epilepsy \nresearch 2019, 153, 79-82. \n55. Ullah, I.; Hussain, M.; Aboalsamh, H. An automated system for epilepsy detection using \neeg brain signals based on deep learning approach. Expert Systems with Applications 2018, \n107, 61-71. \n56. Velez, M.; Fisher, R.S.; Bartlett, V.; Le, S. Tracking generalized tonic-clonic seizures with \na wrist accelerometer linked to an online database. Seizure 2016, 39, 13-18. \n57. Onorati, F.; Regalia, G.; Caborni, C.; LaFrance, W.C., Jr.; Blum, A.S.; Bidwell, J.; De Liso, \nP.; El Atrache, R.; Loddenkemper, T.; Mohammadpour-Touserkani, F., et al. Prospective \nstudy of a multimodal convulsive seizure detection wearable system on pediatric and adult \npatients in the epilepsy monitoring unit. Front. Neurol. 2021, 12, 724904-724904. \n\n\n26 \n \n58. Van de Vel, A.; Cuppens, K.; Bonroy, B.; Milosevic, M.; Van Huffel, S.; Vanrumste, B.; \nLagae, L.; Ceulemans, B. Long-term home monitoring of hypermotor seizures by patient-\nworn accelerometers. Epilepsy Behav. 2013, 26, 118-125. \n59. Williams, C.K.I. The effect of class imbalance on precision-recall curves. Neural Comput. \n2021, 33, 853-857. \n60. Knowm \nsdc \nmemristors. \nhttps://knowm.org/downloads/Knowm_Memristors.pdf \n(15.05.22),  \n61. Gomez, J.; Vourkas, I.; Abusleme, A. Exploring memristor multi-level tuning \ndependencies on the applied pulse properties via a low cost instrumentation setup. IEEE \nAccess 2019, 7, 59413-59421. \n62. Marković, I.; Potrebić, M.; Tošić, D. Memristors as candidates for replacing digital \npotentiometers in electric circuits. Electronics 2021, 10, 181. \n63. Volos, C.K.; Pham, V.-T.; Nistazakis, H.E.; Stouboulos, I.N. A dream that has come true: \nChaos from a nonlinear circuit with a real memristor. International Journal of Bifurcation \nand Chaos 2020, 30, 2030036. \n64. Dos Santos, S.; Furui, S. In A memristor based ultrasonic transducer: The memosducer, \n2016 IEEE International Ultrasonics Symposium (IUS), 2016; IEEE: pp 1-4. \n65. Ostrovskii, V.; Fedoseev, P.; Bobrova, Y.; Butusov, D. Structural and parametric \nidentification of knowm memristors. Nanomaterials 2021, 12, 63. \n66. Giner-Sanz, J.J.; Ortega, E.M.; Pérez-Herranz, V. Total harmonic distortion based method \nfor linearity assessment in electrochemical systems in the context of eis. Electrochim. Acta \n2015, 186, 598-612. \n67. Pershin, Y.V.; Chien, C.-C.; Di Ventra, M. The fourier signatures of memristive hysteresis. \nJ. Phys. D: Appl. Phys. 2021, 54, 245302. \n68. Vasseur, D.A.; Yodzis, P. The color of environmental noise. Ecology 2004, 85, 1146-1152. \n69. Chen, T.; Bobbert, P.A.; van der Wiel, W.G. 1/f noise and machine intelligence in a \nnonlinear dopant atom network. Small Science 2021, 1, 2000014. \n70. Sánta, B.; Balogh, Z.; Gubicza, A.; Pósa, L.; Krisztián, D.; Mihály, G.; Csontos, M.; \nHalbritter, A. Universal 1/f type current noise of ag filaments in redox-based memristive \nnanojunctions. Nanoscale 2019, 11, 4719-4725. \n71. Sánta, B.; Balogh, Z.; Pósa, L.; Krisztián, D.; Török, T.N.; Molnár, D.; Sinkó, C.; Hauert, \nR.; Csontos, M.; Halbritter, A. Noise tailoring in memristive filaments. ACS Appl. Mater. \nInterfaces 2021, 13, 7453-7460. \n\n\n27 \n \n72. Przyczyna, D.; Lis, M.; Pilarczyk, K.; Szaciłowski, K. Hardware realization of the pattern \nrecognition with an artificial neuromorphic device exhibiting a short-term memory. \nMolecules 2019, 24, 2738. \n \n\n\n",
  "metadata": {
    "source_file": "dataset/pdfs/arxiv_2502.20351v1.pdf",
    "total_pages": 27,
    "title": "KNOWM Memristors in a Bridge Synapse delay-based Reservoir Computing system for detection of epileptic seizures",
    "authors": [
      "Dawid Przyczyna",
      "Grzegorz Hess",
      "Konrad Szaciłowski"
    ],
    "abstract": "Nanodevices that show the potential for non-linear transformation of\nelectrical signals and various forms of memory can be successfully used in new\ncomputational paradigms, such as neuromorphic or reservoir computing (RC).\nDedicated hardware implementations based on functional neuromorphic structures\nsignificantly reduce energy consumption and/or increase computational\ncapabilities of a given artificial neural network system. Concepts of RC, which\nas a flexible computational paradigm can be highly inclusive, are often used as\na model to describe computations performed in materia. With mostly fixed\ninternal structure, solid-state devices, especially memristors, are studied as\ncomputational substrates in various RC systems. In this work, we present\nsingle-node Echo State Machine (SNESM) RC system based on bridge synapse as a\ncomputational substrate (consisting of 4 memristors and a differential\namplifier) used for epileptic seizure detection. KNOWM memristors were posed as\nideal candidates because of their easy prototyping and reliability of\noperation. In this account, we present an application of commercially available\nKNOWM memristors in various neuromorphic applications, from simple analysis of\nswitching and internal dynamics (elucidated form noise spectroscopy and total\nharmonic distortion analysis) to the classification and recognition of complex\ntime series: epilepsy seizure recognition using a wrist-worn triaxial\naccelerometer.",
    "published_date": "2025-02-27",
    "source": "arxiv"
  }
}