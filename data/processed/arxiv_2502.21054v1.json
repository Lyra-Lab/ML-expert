{
  "id": "arxiv_2502.21054v1",
  "text": "IEEE JOURNAL OF SELECTED TOPICS IN APPLIED EARTH OBSERVATIONS AND REMOTE SENSING, VOL. XX, NO. X, MONTH YEAR\n1\nHoloMine: A Synthetic Dataset for Buried\nLandmines Recognition using Microwave\nHolographic Imaging\nEmanuele Vivoli , Member, IEEE, Lorenzo Capineri , Senior Member, IEEE, and Marco Bertini , Member, IEEE\nAbstract—The detection and removal of landmines is a complex\nand risky task that requires advanced remote sensing techniques\nto reduce the risk for the professionals involved in this task.\nIn this paper, we propose a novel synthetic dataset for buried\nlandmine detection to provide researchers with a valuable re-\nsource to observe, measure, locate, and address issues in landmine\ndetection. The dataset consists of 41,800 microwave holographic\nimages (2D) and their holographic inverted scans (3D) of different\ntypes of buried objects, including landmines, clutter, and pottery\nobjects, and is collected by means of a microwave holography\nsensor.\nWe evaluate the performance of several state-of-the-art deep\nlearning models trained on our synthetic dataset for various\nclassification tasks. While the results do not yield yet high\nperformances, showing the difficulty of the proposed task, we\nbelieve that our dataset has significant potential to drive progress\nin the field of landmine detection thanks to the accuracy and\nresolution obtainable using holographic radars.\nTo the best of our knowledge, our dataset is the first of its kind\nand will help drive further research on computer vision methods\nto automatize mine detection, with the overall goal of reducing\nthe risks and the costs of the demining process.\nIndex\nTerms—Holographic\nimaging,\nLandmine\ndetection,\nRobotic platform, Holographic dataset\nI. INTRODUCTION\nLandmines are a significant threat to human life and the\nenvironment in many regions of the world [1], with sev-\neral thousand persons killed or maimed every year. Their\ndetection and removal is a complex and risky task that\ndemands advanced remote sensing methods and technologies\nto reduce the risk of death or injuries for the professionals\ninvolved in this task; it is estimated that one deminer is\nkilled and two injured for every 5,000 successfully removed\nmines [2]. Traditional detection methods involve detection\nwith hand held instruments by human experts, the use of\ntrained animals [3], [4], and the use of specialized equipment\nsuch as impulse ground-penetrating radar (GPR) [5], [6], [7],\n[8], metal detectors [9], and thermal imaging cameras [10].\nDespite the considerable progress made in landmine detection\nmethods, these approaches exhibit inherent limitations [11],\n[12]. For instance, plastic mines contain very small amounts\nof metal and are constructed using plastic materials to evade\nE. Vivoli and M. Bertini are with the Media Integration and Communication\nCenter, Viale Giovanni Battista Morgagni, 65, 50134 Firenze FI, Italy\nL. Capineri is with Ultrasound and Non-Destructive Testing Laboratory,\nUniversity of Florence, Italy.\ne-mail: emanuele.vivoli@unifi.it.\nManuscript received July 9, 2024; revised ??, 2024.\nFig. 1: Detail of a PMN-4 scan represented in 2D complex\nholographic image H0 and 3D reconstruction H. On the right,\nis presented amplitude and phase of Hz = f(H0, z).\ndetection. As a result, the identification and clearance of\nburied landmines remain arduous and time-consuming tasks,\nincurring significant monetary costs. The United Nations has\nestimated that the removal of a single mine can cost between\nUS $300 and US $1,000 [13].\nOn the other hand, microwave holographic radars have the\nability to penetrate the soil up to 10-20 cm and be used to\ndetect buried objects. Compared to GPR, holography is known\nfor its precision and ability to generate high-resolution images\nof the shape and position of buried objects. Moreover, the\nvisual outputs produced by holographic radars are simpler\nfor operators to interpret compared to GPR images, which\nrequire specialized analysis skills. This advantage has led to\nthe proposal of using holographic radars for mine detection.\nThese holographic images are generated through the use\nof inversion algorithms [14] including methods such as the\nangular spectrum and Fresnel inversion [15]. Such methods\nallow for the reconstruction of the shape and distance of buried\nobjects by analyzing the electromagnetic reflectivity of objects\nin a plane parallel to the scanning plane. This enables the\nreflective scene picked up by the radar to be reconstructed in\nreverse along with the radar image.\nHowever, creating a dataset for buried landmine detection\nis a time-consuming task, requiring scanning the ground some\ndays after burying the landmines. Moreover, knowing the exact\nposition of the buried object can be challenging [16] since the\nsoil is subject to change with time and weather conditions,\npotentially altering the objects’ position w.r.t. where they were\narXiv:2502.21054v1  [cs.CV]  28 Feb 2025\n\n\nIEEE JOURNAL OF SELECTED TOPICS IN APPLIED EARTH OBSERVATIONS AND REMOTE SENSING, VOL. XX, NO. X, MONTH YEAR\n2\noriginally buried. As a result, there is currently no common\ndataset available for either GPR data or holographic data.\nTo overcome the challenges posed by creating a dataset,\nwe propose a synthetic dataset consisting of microwave holo-\ngraphic images of buried objects for classification and local-\nization. Creating a synthetic hologram is a faster and more ef-\nficient process than physically burying an object and scanning\nit in the ground. Moreover, synthetic holograms can be easily\nmanipulated and customized to simulate different scenarios\nand conditions, which is not possible with physical objects in\nthe ground. Despite the possible differences in environmental\nconditions (i.e. temperature and humidity) and variations in\nobject-ground interactions, our proposed dataset “HoloMine”\naims to address these concerns by utilizing a rigorous process\nto create realistic holograms, obtained combining holograms of\nreal objects and real ground scenes, that accurately simulate\nburied objects. The dataset includes 2D and 3D images (as\nshown in Fig. 1), of different types of objects in multiple\nscenarios; we used a set of 6 military-grade replicas of mines\nused to train deminers, that replicate all the physical features\nof real mines, along with several types of clutter and objects.\nOur approach consists of collecting 200 real-ground scans and\n208 in-air scans of objects to create the 41,800 size dataset\nwhich, to the best of our knowledge, is the largest (and first)\nsynthetic dataset publicly available.\nTo evaluate our synthetic dataset, we tested state-of-the-art\nbaseline models for 2D and 3D data. Our results indicate\nthat there is significant room for improvement for these\nmodels in performing the classification tasks. However, the\nproblem is difficult even for trained experts. Therefore, while\nthe limitations of synthetic holography should be considered,\nwe believe that our dataset is a valuable contribution to the\nfield of buried landmine detection research for the computer\nvision community and can provide an accurate and realistic\nrepresentation of buried objects in various scenarios.\nTo summarize, the key contributions of our work are:\n• to recognize the difficulties in creating a real dataset due\nto the uncertainty of the object’s position and the time\nrequired for the object-ground stabilization;\n• to pinpoint a new approach for this task thanks to the\nproperties of holograms and holography inversions which\nallowed us to fuse scans and obtain the biggest synthetic\ndataset for buried landmines and clutters;\n• to carry out extensive experimentation and providing\nbaseline results on the provided dataset.\nData, baselines and pre-trained models are available at the\nlink https://github.com/emanuelevivoli/asmara1.\nII. RELATED WORKS\nGPR and landmine detection\nGround-penetrating radar (GPR) [17] is one of the most\ncommonly used techniques for detecting large buried objects\nsuch as pipes and walls [18], and small objects such as stones,\nother material objects, and landmine [6], [8], [7]. Among\nthe works that tackle the task of landmine recognition [19],\n1available upon acceptance.\nthe vast majority uses a simulator [20] to generate GPR\nBscans with different soil composition and buried objects\nshape and material. In [21] the authors propose a neural\nnetwork that combines a complex-valued layer, to deal with the\nscattering parameters measured by GPR, with Self Organizing\nMap. Only few works use deep learning for classification\nor localization [6], [8], [7], [22], [21]. In particular, the\nauthors of [23] presented a two-step classification process\nwhich first isolate landmines from false alarms, and then\nrecognize the type of each landmine; the authors trained their\nmodel using simulated 2D Bscans images. In [6] the authors\nemployed a CNN with pre-defined convolutional filters which\nallowed them to obtain high accuracy over a perfectly balanced\ngenerated dataset of 100k 2D patches in total. Despite the\nmajority of the works being on the detection step of landmine\nclearance, two recent works [7], [22] approached the task of\nlocalization employing modern neural network architectures,\nsuch as Faster R-CNN on simulated and real data. However,\nthese works have addressed the problem of distinguishing anti-\ntank (AT) landmine versus all other possible objects such as\nstones, woods and anti-personnel (AP) landmine. Moreover,\nwhen building the experimental setting, the authors considered\nonly metallic AT and AP. In fact, GPR has some limitations\nsuch as the inability to detect very shallow buried objects,\nwhich may require post-processing to generate high-resolution\nplane images. Additionally, the technology may have difficulty\ndetecting small non-metallic objects.\nHolography and Inversion algorithms\nAs an alternative to GPR, [24] developed an HSR system\n(Holographic Subsurface Radar), which uses a circular waveg-\nuide antenna with a single feed. The antenna operates at 1.9\nGHz. The choice of this frequency for the holographic radar\nis based on an in-depth study of the electromagnetic char-\nacteristics of the soil of Ukraine, which today represents an\nimportant application scenario for humanitarian demining [25].\nAdditionally, holographic radars are low-cost with the possi-\nbility of using 3D printing for their production [24]. With this\nsetting, the holographic radar has a theoretical resolution equal\nto a quarter of the wavelength, i.e., about 15cm in the air and\nabout 3cm in the target ground [26], and makes it possible\nto use holographic radars in the detection of landmines [27].\nThis value is a compromise between penetration depth and\nresolution as reported in the paper. In this way, the images\nof the data set contain information on the size and shape\n(circular or elongated artifacts can be thus discriminated). A\nseries of published works show how the designed holographic\nradar provides such information [28], [29]. Finally, the design\nof the holographic radar has been addressed to obtain the\nmaximum sensitivity to the dielectric contrast that allows to\nreconstruct images of weakly reflecting anti-personnel mines\n(Low Metal Content AP landmines), and the design of the\nantenna and electronics is reported in [30]. One convenient\nproperty of holography is the holographic image reconstruc-\ntion, arguably the most effective processing algorithm for mi-\ncrowave landmine detection. With the same principle of optical\nholography [31], through image reconstruction algorithms it is\n\n\nIEEE JOURNAL OF SELECTED TOPICS IN APPLIED EARTH OBSERVATIONS AND REMOTE SENSING, VOL. XX, NO. X, MONTH YEAR\n3\npossible to obtain 3D images from 2D holograms, revealing\nobjects’ size and location. Despite being the Fresnel transform\nalgorithm the most commonly used method for holographic\ninversion, its limitations, such as sensitivity to phase errors\nand inability to deal with high frequencies, make it unusable\nin this context. However, Sheen et al. [32], inspired by a\nreconstruction algorithm originally derived from microwave\nholography techniques [33], designed a modification able to\ndeal with high-frequency data and being less sensitive to phase\nerrors. Our approach considers both 2D holograms and angular\nspectrum inverted holograms (3D) to provide a comprehensive\ndataset for landmine detection.\nLandmine datasets\nBuried landmine datasets are needed to develop methods for\nautomatic detection and recognition of mines. For this purpose,\nmine replicas that mimic real-world mines and are designed\nfor training deminers are commercially available, providing a\nsafe way to generate such datasets. However, the creation of\nsuch datasets is extremely impractical.\nThe approach of locating an object under the ground in\na specific position and considering it to stay fixed also after\nweather agents and time is not realistic due to the fact that\nobjects usually move in the soil, caused by varying conditions\nsuch as humidity, vibrations, etc. To approach this issue,\nCounts et al. [5] simulated the terrain using sandpits, inserting\nthe objects knowing their spatial position in all 3 dimensions.\nThis is possible because, differently from real soil, there is\nno need to wait for atmospheric agents for the sand to settle.\nAuthors created the first publicly released dataset composed\nby a sandbox and many superficial and subsurface targets [34].\nTo make the scans, a GPR was attached to a 3D mechanical\npositioning system located at a distance over a sandbox. The\nset of air targets and subsurface targets comprises metallic\nAP and AT mines, rocks, metal spheres, and corrugated\npipes. Despite the effort in creating the dataset, using sand\nand metallic objects limits the applicability to different soil\ncomposition terrains and to plastic or low-metallic landmines.\nIn order to preserve precise spatial localization and address\ndifferent soil composition, later works are mostly based on\ngprMax simulations [20] that allow them to create custom\ndataset considering various objects and soil dielectric prop-\nerties. Using simulations can have positive aspects. In fact, it\nmakes the setting completely reproducible, and also the 3D\nlocation of the objects are known which can be suitable not\nonly for detection but also for localization tasks [7], [22].\nHowever, the simulations divert the effort from generalizing on\ndifferent terrains and objects to terrains that can be reproduced\nby the simulator and objects that the simulator considers\n(e.g., regular shapes such as cylinders, cubes, and cones).\nFurthermore, the simulator may suffer from programming\nerrors and approximations that would bias the algorithms to\nsimulator artefacts that are not present in nature and difficult\nto reveal.\nOn the other hand, when considering holograms, their main\napplication is in optical holography, where numerous works\nand datasets are available [31], [35]. In the domain of landmine\ndetection, the application of holography has been limited to a\nfew studies, and at present, there exists no dataset specifically\ntailored to buried object detection utilizing holographic tech-\nniques. From the experiences of previous works, our approach\nis to create a new dataset for holographic subsurface radars that\nmaintains the veracity of the data and avoids using unrealistic\nsimulators and experimental settings. In so doing, similarly to\n[5], we developed a 3D-positioning structure together with an\nHSR and used them for acquiring different scans of outdoor\nand indoor elements; then, we merged these holographic\nimages.\nFig. 2: left) view of the 3-D mechanical arm and Holographic\nSubsurface Radar (HSR); right) a panoramic view of the\nRobotic platform. This system has been used to acquire the\nbasic elements used to create the dataset.\nIII. METHODS\nIn this section, we present our novel holographic dataset for\nburied objects. We start by describing the acquisition setup\n(Fig. 2) and the collected signals (Fig. 3), then we dig into\nthe pre-processing and the fusion procedure to obtain the\n2D holograms and 3D inverted holograms, and the dataset\ngeneration pipeline (Fig. 4).\nRadar setup\nThe acquisition setup, based on [36] - the system is shown\nin Fig. 2, consists of a 3-D mechanical movement and a\nHolographic Subsurface Radar that are controlled through the\nRobot Operating System (ROS). The radar operates at 1.9 GHz\nand it is mounted on the positioner support, which, in less\nthan 3 minutes, covers a surface of 30 × 30 cm, capturing\nthe signal every 100 ms. We collect in a zig-zag scan a\nlist of two-value signals, amplitude, and phase respectively,\nmeaning the ensemble of reflections of soil and buried objects\nin a particular point of the positioner. Fig. 3a shows scattered\namplitude and phase collected in the first stage. In order\nto represent the time-series signals S(t) and the positioning\ninformation P(t) in a single spatial dimension image H, a\ntransformation T : S, P →H is needed. In particular, the\ntransformation corresponds to a spatial interpolation (among\nP) of real and imaginary components of the signal S. The\nresulting image is a complex image of 60 × 60 pixels so that\nH ∈C60×60, and every pixel is located at 0, 5cm distance;\namplitude and phase elements of H are shown in Fig. 3b.\n\n\nIEEE JOURNAL OF SELECTED TOPICS IN APPLIED EARTH OBSERVATIONS AND REMOTE SENSING, VOL. XX, NO. X, MONTH YEAR\n4\n(a) Scattered time-series of amp(S) [left] and phase(S) [right]\nbased on positions P.\n(b) Amplitude amp(H) [left] and Phase phase(H).\nFig. 3: Transformation from zig-zag time-serie acquisition\nS, P to H through T : S, P →H.\nAcquisition criteria\nInspired by [37], [38], [39], [40], our approach consists of\nacquiring two sets of data: outdoor HOUT and indoor HIN,\nand then mixing these scans with the pipeline shown in Fig.\n4. Firstly, a collection of 50 terrain patches was considered,\nin specific atmospheric conditions, in which the absence of\nparticular objects is ensured (i.e. mines and clutter). Every\nsquare patch Hout\nj,do is scanned from the four cardinal directions\n(North, South, West, East), forming a set of 200 scans as\nfollow:\nHOUT =\n\u001a\nHout\nj,do\n\f\f\f\f\ndo ∈{N, S, W, E};\nj = 1, . . . , 50\n\u001b\n(1)\nSecondly, airborne scans in a laboratory environment of\n13 objects ok (including AP landmines, pottery objects and\nclutters). Every object was located both at distance h = 4cm\nand h = 8cm from the source. The object is oriented to each of\nthe cardinal orientations di ∈{N, S, W, E} and is placed with\na slope s of 0◦or 20◦in the di direction. To be noticed that\nfor indoor objects the orientation is di while do for outdoor\nobjects. Let HIN being the set of all possible indoor scans, it\nis composed by all possible 16 configurations of every one of\nthe 13 ok objects, creating 208 total indoor scans as follow:\nHIN =\n\n\n\n\n\n\n\nHin\nk,h,di,s\n\f\f\f\f\f\f\f\f\nk = 1, . . . , 13;\nh ∈{4; 8};\ndi ∈{N, S, W, E};\ns ∈{0; 20}\n\n\n\n\n\n\n\n(2)\nThe implemented system provided us with precise control\nover object locations, including their coordinates and slope,\nwhile also providing knowledge of the material properties of\nthe object.\nDuring the scanning process, several measures were im-\nplemented to ensure accuracy. For indoor scans, the mobile\nplatform was raised at least 1 meter above the ground to\nminimize interference from ground reflections. Additionally,\ncare was taken to maintain a safe distance from reflective\nobjects such as metallic furniture and cables in the laboratory.\nThe 3D structure, mounted on an autonomous guidance sys-\ntem for automatic demining, was equipped with appropriate\ncounterweights and oscillation damping systems to ensure\nminimal movement and clean signal reception by the HSR. In\noutdoor scans, proper calibration was required to ensure that\nthe HSR did not come into contact with the ground, which\ncould damage the radar and result in anomalies in the scans.\nFurthermore, the robot platform was secured firmly on all four\nwheels to prevent excessive oscillation on jagged terrain.\nHologram fusion\nIn [40], one of the earliest works on buried object analysis\nusing GPR, the authors study the effect of the height of the\nradar with respect to the surface. The surface depth profile\nis measured with a LIDAR and the effect on the acquisitions\nis modeled with a simulator in order to subtract it from the\nimages, leading to positive effects on target detection. Fol-\nlowing this approach, we aim at doing the opposite operation\nwith consistent holograms: adding the HSR response of a\nHIN object acquired in air to a not homogeneous HOUT soil\nmedium holographic scan.\nIn this way, the two sets of HOUT and HIN can be\nused together to represent scenes in which a particular ob-\nject configuration Hin\ni,h,di,s ∈HIN is located into the soil\nHout\nj,do ∈HOUT . However, the different permittivity of the air\nand soil media of the indoor and outdoor scans require to\nimplement a weighting criterion. We employed a weighted\nsum of indoor and outdoor holograms using the following\nformula:\nH = α × Hin + (1 −α) × Hout\n(3)\nwhere α determines the weight assigned to each hologram\nand must be chosen to ensure a realistic and balanced repre-\nsentation of both indoor and outdoor scenes in the final mixed\ndataset.\nThe α coefficient can be chosen based on two principle\nfactors: (i) the dielectric permittivity differences between the\nair and the soil composition that affect the attenuation of\nmicrowaves; (ii) empirical analysis. In our work we have\ndetermined the best coefficient using the latter approach, which\nwill be shown in the next section.\nInversion theory\nAn important consideration noted in [40] is that using the\nbackprojection algorithm [41] helps to mitigate surface effects.\nThis algorithm shares the same principles as the angular\nspectrum method phase reconstruction for holographic data.\nFrom this knowledge, and inspired from [32], we adopted the\nangular spectrum algorithm to mitigate surface noise. In the\nsystem configuration, the source is located at z = 0 and the\n\n\nIEEE JOURNAL OF SELECTED TOPICS IN APPLIED EARTH OBSERVATIONS AND REMOTE SENSING, VOL. XX, NO. X, MONTH YEAR\n5\nFig. 4: Dataset creation pipeline from indoor and outdoor scan acquisition [left] to pre-processing [middle] to 2D and 3D\nimage creation [right]. w indicates the weight used to fuse the hologram images.\nHologram H is considered as H0. The target is characterized\nby a reflective function Hz = f(H0, z) which lead to the\ndefinition of the reflection perceived at the transceiver calcu-\nlated by the superposition of each point on the target plane\nat distance plane z. The image reconstruction is numerically\ncalculated by the following formula:\nf(H0, z) = FT −1\n2D\nn\nFT2D\n\b\nH0\t\ne−jz√\nk2−k2x−k2y\no\n(4)\nwhere FT represents the Fourier Transform operation, H0\nis the hologram at z = 0, kx and ky represent the spatial\nfrequencies in the x and y directions, respectively, and kz\nrepresents the wavevector in the z direction (i.e., the direction\nof propagation of the electromagnetic radiation). The output\nof the function is the complex field f at a distance z from the\nhologram H0.\nFollowing the above formulation, [42] defines a MATLAB\nalgorithms of Angular Spectrum and Convolution reconstruc-\ntion while [43], [44] adopted the Python language in structur-\ning an open source tool which performs digital holograms and\nlight scattering. In our case, we use HoloPy [44], a tool that\nis able to forward propagating light from a scattering as well\nas backward propagating light from a digital hologram. This\nallows us to obtain H = f(H0)z=0,...,d, where H ∈C60×60×d\nand d is the number of slices that we want to recreate. Similar\nto the approach we employed for holographic images, we\ncalculated the inverted complex fields H and merged them by\nutilizing the same coefficient as for Holograms (w = 0.17).\nBuried objects\nThe dataset has been carefully constructed with the inclu-\nsion of three distinct types of objects. The first type consists\nof landmines objects (first row of Fig. 5), which are highly\npresent in Europe and East-Europe post-conflict countries, as\nwell as in many other African and Asian countries. Their\nmaterial composition vary for different electromechanical pa-\nrameters as well as density, dielectric permittivity and metal\nconductivity. In particular, PMN-4 has a 1cm metallic ring\nsurrounding the hood while the Butterfly landmine has no\nmetallic concentration. Our choice to include also low-metal\nand plastic landmines (replicas) are due to the fact that\nDataset\n#scans\n#mines\n#clutters\nCLS\nDET\nSEG\nCounts et al. [5]\n14\n7\n4*\n✓\n✓\n✗\nGiannakis et al. [23]\n4k\n2\n5\n✓\n✗\n✗\nBestagini et al. [8]\n114\n9\n-\n✓\n✓\n✗\nKafedziski et al. [7]\n48 †\n9\n-\n-\n-\n-\nPham et al. [22]\n100 + 50 †\n-\n-\n-\n-\n-\nHoloMine\n41.8k\n7\n6\n✓\n✓\n✓\n*in addition, dozens of stones were located on the surface.\nTABLE I: Comparison of HoloMine with related datasets. †\ndenotes the datasets are created with the gprMax simulator\n[20]. CLS (Classification), DET (Detection), and SEG (Seg-\nmentation) show which tasks the datasets support.\nplastics used to build them have low density and a non-\nuniform surface, making them more difficult to detect than\nmetal objects; indeed, they have been designed to be hard or\nimpossible to be detected by metal detectors. The second type\nof clutter object included in the dataset are common clutters\nsuch as stones, wood and can, which are commonly observed\nin a post-conflict terrain (first three objects of second row in\nFig. 5). Despite the particular shape of the considered objects,\nwe are interested in the holographic response of materials\ndifferent than plastic and metal. Finally, the third type of\nclutter object included in the dataset is pottery, which are often\npresent buried in the soil and can be mistaken for buried mines\n(last three objects of second row in Fig. 5). In fact, we included\ndifferent types of pottery: shallow clay pot, a pot with holes\nand deep clay pot. The inclusion of these three clutter object\ntypes in the dataset aims to create a diverse range of scenarios\nand conditions that can be encountered in real-world landmine\ndetection tasks. This will allow researchers to develop and\ntest algorithms that are robust and accurate in a variety of\nsituations.\nData annotations and tasks\nOur dataset currently consists of both indoor and outdoor\nscans of various types of buried objects and soil, alongside\ntheir corresponding configuration details that facilitate easy\ndata annotation for Recognition tasks. Recognition is a central\ntask in computer vision that involves identifying and localizing\nobjects of interest in an image or a video. It typically involves\nthree sub-tasks: classification, detection, and segmentation.\n\n\nIEEE JOURNAL OF SELECTED TOPICS IN APPLIED EARTH OBSERVATIONS AND REMOTE SENSING, VOL. XX, NO. X, MONTH YEAR\n6\n(a) PMN-4\n(b) PMN-1\n(c) VS-50\n(d) TYPE 72\n(e) M-14\n(f) PMA-2\n(g) Butterfly\n(h) Bullet\n(i) Stone\n(j) Wood cylinder\n(k) Can\n(l) Clay pot\n(m) Clay pot 2\n(n) Clay pot 3\nFig. 5: Objects considered for indoor scans. On the first row, landmines replicas are reported, namely (from left to right):\nPMN-4 (d=95mm, h=46mm), PMN-1 (d=95mm, h=55mm), VS-50 (d=90mm, h=45mm), TYPE 72 (d=78mm, h=38mm), M-14\n(d=56mm, h=40mm), PMA-2 (d=68mm, h=61mm), and Butterfly (l1=112mm, l2=60mm, h=15mm). The second row shows the\nBullet (d=20mm, l=120mm), some clutter (stone (l1=110mm, l2=56mm, h=34mm), wood cylinder (d=35mm, h=40mm), and\ncrumpled can (l1=110mm, l2=62mm, h=15mm), and some pottery objects (perforated clay pot (d=180mm, h=28mm), clay pot\n(d=170mm, h=24mm), and deep clay pot (l1=120mm, l2=265mm, h=135mm)).\nClassification refers to assigning a label or a category to an\nobject or a region in an image. Detection involves localizing\nobjects of interest and predicting their labels or categories.\nSegmentation is the task of partitioning an image into multiple\nregions or segments, where each segment corresponds to a\ndistinct object or a part of an object. In the context of\nlandmine clearance, the tasks of detection, localization, and\nidentification correspond to the sub-tasks of detection and clas-\nsification in computer vision. Detection refers to the process\nof identifying the location of buried landmines in a given area,\nwhile localization involves accurately pinpointing the location\nof the landmines. Identification involves recognizing the type\nof the detected landmines. Table I presents an inventory of\ndatasets that incorporate GPR radars, which are either based\non real-world measurements, simulations, or a combination of\nboth. The table enumerates their structure and characteristics,\nincluding the number of scans, the number of different mine\ntypes, the types of clutter objects, and the tasks for which the\nannotations can be employed. Notably, our dataset is distinc-\ntive due to its significant size and its ability to facilitate com-\nprehensive Recognition tasks for buried landmine detection,\nwhich includes classification, detection, and segmentation. It\ncomprises both indoor and outdoor scans of different types\nof buried objects and soil, along with associated configuration\ndetails that facilitate simple data annotation. Furthermore, our\ndataset is exceptional in that it is not produced via simulations,\nunlike other similar datasets.\nTo generate labels for the classification task, represented\nin Fig. 6, we employed various techniques based on the\ncomplexity of the task. In fact, the classification task can\nbe evaluated in terms of binary classification (mine/clutter),\nternary classification (mine/clutter/pottery) or multi-class clas-\nsification (a class for each type of buried object). For the\nbinary classification task, where the classes are mine and non-\nmine, we selected 80% mines and objects for the train-set\nand used the remaining objects for the test-set. By ensuring\nthat no object could be present in both train and test sets,\neven from any of its 16 possible configurations, our dataset\nenables a more robust evaluation. Nonetheless, in the case\nof soil patches, there was no distinction between terrain that\nwas observed during training and during test process, since\nboth landmines and clutter were embedded in each of the\npatches. This is possible because soil patches have a relatively\nhomogeneous texture and appearance, making it difficult to\ndistinguish one from another, which means that introducing\ndifferent objects or clutter in different patches does not sig-\nnificantly affect the overall appearance of the soil patch. To\naccomplish the three-class classification task, a similar labeling\napproach is employed. In this case, 80% of the mines, clutters,\nand pottery objects are chosen for the train-set, and the rest\nof the objects in all of their configurations, in each of the 200\nterrain scans, are reserved for the test-set. However, For the\n13-class classification task, a different approach was used: we\nrandomly split the data after performed the fusion of indoor\nand outdoor scans. To ensure a balanced distribution of objects\nacross the train and test sets, we randomly split the data into\n80% train-set and 20% test-set, while ensuring that all objects\nin a particular configuration were present in the same set.\nTo generate annotations for detection and segmentation, we\nused a combination of manual and automatic methods. For\ndetection, we automatically labeled the position and size of\nthe bounding boxes around each object in the 2D images since\nwe have precise information about the location, dimensions,\nmaterial, and shape of each object. We also provided a binary\nmask for each bounding box to indicate which pixels belong\nto the object and which do not. For segmentation, we used\nan automatic algorithm in CVAT [45] to generate initial\nsegmentations of the objects. We then manually corrected any\nerrors in the segmentations.\nThe annotations for both detection and segmentation are\n\n\nIEEE JOURNAL OF SELECTED TOPICS IN APPLIED EARTH OBSERVATIONS AND REMOTE SENSING, VOL. XX, NO. X, MONTH YEAR\n7\nFig. 6: Representation of available labels for our HoloMine\ndataset. For visualization purposes, only the amplitudes H0\nand Hz are shown.\nprovided in a standard format for easy use with common deep\nlearning frameworks.\nDeep learning models\nIn this work, we focus on deep learning methods for buried\nlandmine detection, as they have shown promising results\nin various computer vision tasks. Specifically, we consider\nsome of the most popular and widely used deep learning\nmodels, including ResNet [46], ViT [47], U-Net [48], and\nEfficientNet [49] for 2D images and ViT3D [50] and U-Net3D\n[51] for 3D images. These models have demonstrated excellent\nperformance in various classification tasks and are thus well-\nsuited to be used as baseline methods for the task of buried\nlandmine detection.\nTo validate the effectiveness of our dataset and establish\nbenchmark results, we trained and tested several deep learning\nmodels on the synthetic holographic data. Regarding 2D\nclassifications, ResNet and EfficientNet are based on convolu-\ntional neural networks, while ViT is based on the transformer\narchitecture that uses self-attention mechanisms, and U-Net is\na popular encoder-decoder architecture used in medical image\nanalysis tasks. As for 3D classifications, we have evaluated\ntwo models: ViT3D and U-Net3D. These models extend the\nViT and U-Net models, respectively, to 3D data.\nModels modifications. Deep learning models are usually\ndesigned for specific input data sizes, such as images larger\nthan 255 pixels per side and with 3 channels (RGB). In our\ncase, we have a complex 60 × 60 image and we needed\nto decide how to use the available information. We chose\nto focus on selecting amplitude components and analyzing\nreal 2D and 3D images, while leaving other approaches for\nfuture development discussed in the Future Work section.\nBecause we had a grayscale image, we had to modify the\narchitecture of the models. In particular, ResNet, U-Net and\nEfficientNet have 3 input channels, so we adapted the first\nconvolutional layer of the three models to accept grayscale\ninput. Additionally, the last classification layer of ResNet had\nto be characterized to receive a smaller number of inputs due\nto the fact that the input images are significantly smaller.\nAnother approach could be to maintain the same network\nsize by adding padding to the input image. Despite adding\nzero-padding to the holograms is a common technique used\nto increase the field of view or the spatial resolution of the\nmicrowave hologram, adding too much zero-padding can lead\nto overfitting. In this case, the dimensions of cropped input\nimages for ResNet50 224×224, which means 13 times bigger\nthan our images size, making padding unfeasible. Regarding\nthe U-Net, since it is not designed for classification tasks but\nfor segmentation tasks where the output has the same size as\nthe input, we also had to add a classifier at the end of the\nnetwork. In the experiments, we did not consider pre-trained\nnetworks. This is because we were interested in knowing\nthe performance of the network not due to prior knowledge\nobtained from other data. Furthermore, although it is easy to\nfind pre-trained ResNet, it is not as easy with 3D models.\nIn the supplementary material extensive analysis on training\nprocedure will be discussed.\nMetrics. For landmine detection, it is generally better to pri-\noritize recall over precision. This is because the consequences\nof missing a landmine (false negative) are much more severe\nthan falsely detecting a non-landmine object (false positive). In\nother words, it is more important to detect as many landmines\nas possible, even if that means some false positives than to\nmiss any landmines. However, it is still important to strive for\na balance between recall and precision to minimize both false\npositives and false negatives. Based on this, for evaluating our\nbenchmarks, we choose the F1 metric for classification tasks.\nF1 is a combination of precision and recall, which balances\nthe trade-off between them:\nF1 = 2 · precision · recall\nprecision + recall\n(5)\nThis choice of metric is appropriate for our dataset and task,\nwhere we need to balance the accuracy of identifying buried\nobjects with the ability to correctly identify the absence of\nsuch objects. We use the Torchmetrics implementation using\nthe specific binary and multiclass functions.\nIV. EXPERIMENTS\nIn this section, we will present both the coefficient optimiza-\ntion experiments and the deep learning model experiments on\n2D and 3D holographic images.\nA. Coefficient Optimization for Hologram Fusion\nOur approach to landmine holographic imaging is to fuse\nsynthetic in-air holograms Hin and outdoor scans Hout,\nusing a properly designed coefficient. One option is based on\nthe dielectric permittivity of the air and soil. The dielectric\npermittivity of the air is Erair ≃1 and the estimation of the\ndielectric permittivity of the soil in the real field, with medium-\nhigh moisture content Ersoil ≃6. This way, apart from a\nscaling factor c that is applied to every resulting hologram,\nthe function we consider is:\nH = α × Hin + (1 −α) × Hout ≈\nα\n(1 −α)Hin + Hout (6)\n\n\nIEEE JOURNAL OF SELECTED TOPICS IN APPLIED EARTH OBSERVATIONS AND REMOTE SENSING, VOL. XX, NO. X, MONTH YEAR\n8\nwhere\nα\n1−α can be posed as the same ratio between\nErair\nErsoil = 1\n6.\nSolving this simple linear equation we obtain the α to be\nα = 1\n7 = 0.143.\nIn addition to this, we also perform an empirical study to\nestimate α. We have collected a number of experimental holo-\ngraphic scans of the same objects from different perspectives.\nIntuitively, the holograms obtained from the same object in\nthe same soil patch, but from a slightly different perspective,\nshould be more similar than the scans of other objects.\nFig. 7: Distances across intra-class (green) and extra-class\n(red) holograms using the convolution-based score. The\nrounded element corresponds to the “bullet”, the triangle to\nthe “PMN1”, the cylinder to the “PMN4”, and the square\nto “M-14”. N, E, W, and S corresponds to the shift of the\ncorresponding object toward North, East, West, and South.\nThe green arrows indicate the orientation of the objects.\nAs shown in Figure 7, we have collected numerous scans\nof objects (Bullet, PMN-1, PMN-4, M-14) from different\norientations (north, west, south, east) and with some controlled\nshifts, moving the objects one or two steps to the north,\neast, west, and south (N, E, W, S) and some combination of\nthose (2N2W, 2N2E, etc.). In the figure, the rounded element\ncorresponds to Bullet, the triangle to the PMN1, the cylinder\nto the PMN4, and the square to M-14. In particular, the\norientations indicate the degree of rotation from one scan to\nanother, and the shifts mean 2 cm to North, South, West, and\nEast (N, S, W, E respectively). To evaluate the similarity, we\nhave designed a convolution-based correlation metric between\nholographic scans where we measure the pairwise convolution\nscore among the same and different object-soil holograms.\nAs can be seen from Figure 7, the green line corresponds\nto the same object-soil holograms and their similarity score is\nbetween 0.90 and 1.2, with an average of 1.004. In contrast, the\nred ones correspond to different landmine-soil combinations\nand the scores vary from 0.12 to 0.5, with an average of 0.302.\nWith this setting, in order to find the optimal α coeffi-\ncient, we aim at combining Hin and Hout with varying α\nand calculating the convolution-based score (correlation) with\nrespect to the original natural scan. The original natural scans\nFig. 8: Convolution-based score (correlation) among the syn-\nthetic hologram with varying α and the natural scan in the\nsame condition and setting. Every oblique line corresponds\nto one experimental setting, and the line colors correspond\nto Bullet (fuchsia), PMN-1 (cyan), PMN-4 (blue), and M-14\n(yellow). The horizontal lines correspond to convolution-based\nscores for positive pairs (green dashes) or negative pairs (red\ndashes). The dark green and red indicate the means of these\ntwo sets of measurements.\nare acquired in the same weather condition of Hout but with\nthe landmine well-positioned under the soil. Once we have\nacquired all the natural scans, we remove all landmines from\nthe soil and further scan the soil alone (Hout) and the landmine\nin-air (Hin) for the creation of the synthetic data.\nFigure 8 reports the values of different synthetic holograms\ncorrelation to their respective natural scans, varying the α\ncoefficient. The green-colored horizontal lines correspond to\nconvolution-based correlations (obtained from Fig. 7), and\nthe dark-green horizontal line corresponds to the optimal α\ncoefficient obtained by averaging the per-sample coefficient,\nobtaining 1.004 as the “correlation alpha score”. With the\nsame logic, the red horizontal lines correspond to the not-\ncorrelated convolution-based scores, and the darker red line to\nthe uncorrelated mean. The other colors, as illustrated in the\ncaption, correspond to the similarity between the mixed object-\nsoil scans and the ground truth, at the variation of the alpha\ncoefficient (x-axis). Optimal α corresponds to α∗= 0.14. In\nconclusion, by considering the dielectric permittivity of soil\nand air, and by empirically studying the correlation between\nsynthetic and natural holographic images, we obtain similar\nresults: i.e. α∗= 0.14. Thus, the α coefficient used for\nhologram fusion is set to 0.14 for all the objects.\nB. Quantitative results\nWe conducted experiments to evaluate the performance\nof different deep learning model baselines on our proposed\nburied landmine detection dataset. A noteworthy trend in the\ntables is the trade-off between model complexity (measured\nby parameter count) and performance. Among the models\nevaluated, ResNet and EfficientNet are the smallest and largest,\nrespectively. From Table II, it can be observed that despite\nhaving less than half the parameters of EfficientNet, ResNet\n\n\nIEEE JOURNAL OF SELECTED TOPICS IN APPLIED EARTH OBSERVATIONS AND REMOTE SENSING, VOL. XX, NO. X, MONTH YEAR\n9\nModel\nParams\nbinary\nternary\nmulti\nU-Net\n35.8M\n67,1 ± 2,6\n52,67 ± 1,2\n20,9 ± 2,4\nResNet\n25.7M\n55,7 ± 0,3\n33,4 ± 0,15\n24,7 ± 2,8\nEfficientNet\n63.8 M\n40,3 ± 0,9\n33,15 ± 0,4\n8,1 ± 0,3\nViT\n50.6 M\n69,3 ± 0,5\n44,9 ± 1,2\n19,7 ± 1,3\nTABLE II: Experimental results for 2D classification tasks on\nthe Buried Landmine Detection dataset. We report the f1-micro\nscore for each model and task considering multiple runs, along\nwith the number of parameters.\nModel\nbinary\nternary\nmulti\nU-Net 3D\n60,6 ± 4,1\n47,67 ± 3,2\n19,9 ± 2,8\nViT 3D\n62,2 ± 3,2\n38,7 ± 2,5\n16,5 ± 3,1\nTABLE III: Experimental results for 3D classification tasks\non the Buried Landmine Detection dataset. We report the f1-\nmicro score for each model and task considering multiple runs,\nalong with the number of parameters.\noutperforms it in every classification task, especially in multi-\nclass classification, which is the most challenging. A simi-\nlar pattern is evident when comparing the best convolution-\nbased model (U-Net) with the transformer-based model (ViT).\nDespite ViT being 50% larger than U-Net, it only performs\nslightly better in the binary task and underperforms in all other\ntasks. This emphasizes the importance of balancing model\ncomplexity and performance in deep learning models designed\nfor a specific task. Moreover, the results suggest that 2D\nmodels may be more effective for detecting buried landmines\nthan 3D models. This could be due to several factors, such as\nnoise in the latter layer added during reconstruction phase or\nunderfitting due to the complexity of the dataset and model\ndimensions. This finding contradicts the logical assumption\nthat 3D models can capture more spatial information and have\na better understanding of the shape and structure of buried\nobjects compared to 2D models. Further investigation may be\nrequired to gain a better understanding of the capabilities of\n3D models versus 2D models.\nThe effect of objects’ sizes on detection/classification im-\npacts the predictions, but that it seems that the material of\nthe landmine (the “PMN-4” has a metallic ring, the “Can” is\nhighly reflective, and so on) is more important.\nV. CONCLUSIONS\nIn this paper we have presented a novel synthetic dataset\nsupported by exhaustive empirical analysis, for buried land-\nmines detection and classification, to foster the development\nof automated demining systems capable of dealing with buried\nlandmines. The dataset has been created using a holographic\nsubsurface radar and comprises 2D holographic images and\n3D holographic inverted scans. To the best of our knowledge,\nthis is the largest dataset of this type, in terms of a number\nof images and variety of mines and types of clutter objects.\nOur experiments demonstrate that, while deep learning models\nshow promise in buried landmine detection, there is still\nsignificant room for improvement to achieve the high levels\nof accuracy necessary for real-world use. In fact, even if some\nmodels achieve F1−micro scores as high as 69%, these results\nin the context of landmine detection are unsatisfactory. By\nreleasing this dataset we aim at fostering further research in the\nfield, encouraging the development of more sophisticated deep\nlearning architectures and training strategies that can enhance\nthe detection performance.\nIn our future work we plan to extend the dataset by\nadding other types of sensors, such as metal detectors and\ntime-of-flight (ToF) cameras, to account for more classes of\nmines (e.g. tripwire mines) and to better distinguish different\ntypes of mines. Additionally, we aim to improve computer\nvision approaches for the detection and classification of mines.\nIndeed, this paper only scratched the surface of the dataset’s\npotential, as it focused solely on the classification task and\nemployed only the real data (extracted amplitude components)\nfrom the complex data. As shown by the results obtained by\nthe baselines, the problem is far from being solved and requires\nmore effort from the computer vision community; we hope\nthat the availability of this new large dataset will help the\ncommunity to advance the research in this domain.\nACKNOWLEDGMENT\nThis research work is funded by ASMARA project of\nTuscany Region, and NATO SPS G-7563 project.\nREFERENCES\n[1] “Landmine report 2023, the 25th annual landmine monitor report,\nA global network working for a world free of landmines,” http://\nthe-monitor.org/reports/landmine-monitor-2023, 2023, accessed: 2024-\n06-25. 1\n[2] A. Khamis, M. Ashraf, and A. Abdulbaky, “Landmines and uxos\nin nwc: a domain review,” in Proc. of International Workshop on\nRecent Advances in Robotics and Sensor Technology for Humanitarian\nDemining and Counter-IEDs (RST).\nIEEE, 2016, pp. 1–6. 1\n[3] “APOPO NGO: Anti-persoonsmijnen ontmijnende product ontwikkeling\n- anti-personnel landmines detection product development,” http://www.\napopo.org/, 2006, accessed: 2023-04-05. 1\n[4] C. Gooneratne, S. Mukhopahyay, and G. Gupta, “A review of sens-\ning technologies for landmine detection: Unmanned vehicle based\napproach,” in Proc. of 2nd International Conference on Autonomous\nRobots and Agents, 2004, pp. 13–15. 1\n[5] T. Counts, A. Cafer, W. Scott, J. Jr.McClellan, and K. Kim, “Mul-\ntistatic ground-penetrating radar experiments,” IEEE Transactions on\nGeoscience and Remote Sensing, vol. 45, no. 8, 2007. 1, 3, 5\n[6] S. Lameri, F. Lombardi, P. Bestagini, M. Lualdi, and S. Tubaro, “Land-\nmine detection from GPR data using convolutional neural networks,”\nin Proc. of 25th European Signal Processing Conference (EUSIPCO),\n2017, pp. 508–512. 1, 2\n[7] V. Kafedziski, S. Pecov, and D. Tanevski, “Detection and classification\nof land mines from ground penetrating radar data using Faster R-CNN,”\nin Proc. of 26th Telecommunications Forum (TELFOR), 2018. 1, 2, 3,\n5\n[8] P. Bestagini, F. Lombardi, M. Lualdi, F. Picetti, and S. Tubaro, “Land-\nmine detection using autoencoders on multipolarization GPR volumetric\ndata,” IEEE Transactions on Geoscience and Remote Sensing, vol. 59,\nno. 1, pp. 182–195, 2021. 1, 2, 5\n[9] L.\nSafatly,\nM.\nBaydoun,\nM.\nAlipour,\nA.\nAl-Takach,\nK.\nAtab,\nM.\nAl-Husseini,\nA.\nEl-Hajj,\nand\nH.\nGhaziri,\n“Detection\nand\nclassification of landmines using machine learning applied to metal\ndetector data,” Journal of Experimental & Theoretical Artificial\nIntelligence, vol. 33, no. 2, pp. 203–226, 2021. [Online]. Available:\nhttps://doi.org/10.1080/0952813X.2020.1735529 1\n[10] C. Priya, S. Ashok, B. Maji, and K. Kumaran, “Deep learning based\nthermal image processing approach for detection of buried objects and\nmines,” Engineering Journal, vol. 25, pp. 61–67, 03 2021. 1\n[11] “The CMAC: Cambodian mine action centre,,” https://cmac.gov.kh/,\naccessed: 2023-04-05. 1\n[12] G. Pochanin, L. Capineri, T. Bechtel, V. Ruban, P. Falorni, F. Crawford,\nT. Ogurtsova, and L. Bossi, “Radar systems for landmine detection,” in\nProc. of IEEE Ukrainian Microwave Week (UkrMW), 2020, pp. 1118–\n1122. 1\n\n\nIEEE JOURNAL OF SELECTED TOPICS IN APPLIED EARTH OBSERVATIONS AND REMOTE SENSING, VOL. XX, NO. X, MONTH YEAR\n10\n[13] L.\nDoswald-Beck,\nP.\nHerby,\nand\nJ.\nDorais-Slakmon,\n“Basic\nfacts:\nthe\nhuman\ncost\nof\nlandmines,”\nhttps://www.icrc.org/en/doc/resources/documents/misc/57jmcy.htm.\n1\n[14] J. W. Goodman, Introduction to Fourier optics, 3rd ed.\nEnglewood,\nColo: Roberts & Co, 2005, oCLC: ocm56632414. 1\n[15] U. Schnars and W. Jueptner, Digital holography: digital hologram\nrecording, numerical reconstruction, and related techniques.\nBerlin:\nSpringer, 2005. 1\n[16] A. Zhuravlev, S. Ivashov, V. Razevig, I. Vasiliev, and A. Bugaev, “Holo-\ngraphic subsurface radar RASCAN-5,” in Proc. of 7th International\nWorkshop on Advanced Ground Penetrating Radar, Jul. 2013. 1\n[17] D. J. David, “Ground penetrating radar,” Institution of Engineering and\nTechnology, London, U.K., 2004. 2\n[18] C. ´Ekes and B. Neducza, “Robot mounted GPR for pipe inspection,” in\nProc. of 14th International Conference on Ground Penetrating Radar\n(GPR).\nIEEE, 2012, pp. 160–164. 2\n[19] F. Giovanneschi, K. Mishra, and M. Gonzalez-Huici, New Methodologies\nfor Understanding Radar Data.\nScitech Publishing, Jan. 2021, ch.\nModern GPR target recognition methods, pp. 197–252. 2\n[20] C. Warren, G. Antonios, and G. Iraklis, “GprMax: Open source software\nto simulate electromagnetic wave propagation for ground penetrating\nradar,” Computer Physics Communications, vol. 209, no. 163-70, 2016.\n2, 3, 5\n[21] C.-C. Yang and N. Bose, “Landmine detection and classification with\ncomplex-valued hybrid neural network using scattering parameters\ndataset,” IEEE Transactions on Neural Networks, vol. 16, no. 3, pp.\n743–753, 2005. 2\n[22] M.-T. Pham and S. Lefevre, “Buried object detection from b-scan\nground penetrating radar data using Faster-RCNN,” in Proc. of IEEE\nInternational Geoscience and Remote Sensing Symposium (IGARSS),\n2018. 2, 3, 5\n[23] I. Giannakis, A. Giannopoulos, C. Warren, and N. Davidson, “Numerical\nmodelling and neural networks for landmine detection using ground\npenetrating radar,” in Proc. of 8th International Workshop on Advanced\nGround Penetrating Radar (IWAGPR), 2015. 2, 5\n[24] L. Bossi, P. Falorni, and L. Capineri, “Versatile electronics for\nmicrowave holographic RADAR based on software defined radio\ntechnology,” Electronics, vol. 11, no. 18, p. 2883, Sep 2022. [Online].\nAvailable: http://dx.doi.org/10.3390/electronics11182883 2\n[25] T. D. Bechtel, G. P. Pochanin, S. Truskavetsky, M. Dimitri, V. P.\nRuban, O. Orlenko, T. Byndych, A. Sherstyuk, K. Viatkin, F. Crawford,\nP. Falorni, A. Bulletti, and L. Capineri, “Terrain analysis in eastern\nUkraine and the design of a robotic platform carrying gpr sensors\nfor landmine detection,” 2018 17th International Conference on\nGround Penetrating Radar (GPR), pp. 1–4, 2018. [Online]. Available:\nhttps://api.semanticscholar.org/CorpusID:52119540 2\n[26] S. I. Ivashov, V. V. Razevig, I. A. Vasiliev, A. V. Zhuravlev, T. D.\nBechtel, and L. Capineri, “Holographic subsurface radar of RASCAN\ntype: Development and applications,” IEEE Journal of Selected Topics\nin Applied Earth Observations and Remote Sensing, vol. 4, no. 4, pp.\n763–778, 2011. 2\n[27] S. H., B. A.M., and C. J., “Electrode arrays applicable to EIT based\nmine detection: A comparison of spatial sensitivity distributions,” in\nProc. of International Conference on Requirements and Technologies\nfor the Detection, Removal and Neutralization of Landmines and UXO,\n2003. 2\n[28] G. Borgioli, L. Bossi, L. Capineri, P. Falorni, T. D. Bechtel,\nF. Crawford, M. Inagaki, G. P. Pochanin, V. P. Ruban, L. Varyanitza-\nRoschupkina, and T. M. Ogurtsova, “A hologram reconstruction\nalgorithm\nfor\nlandmine\nrecognition\nand\nclassification\nbased\non\nmicrowave holographic radar data,” 2018 Progress in Electromagnetics\nResearch Symposium (PIERS-Toyama), pp. 1938–1944, 2018. [Online].\nAvailable: https://api.semanticscholar.org/CorpusID:57379254 2\n[29] V. V. Razevig, S. I. Ivashov, M. Chizh, A. V. Zhuravlev, and L. Capineri,\n“Influence of electrical properties of media on reconstruction of\nmicrowave holograms recorded by subsurface radar,” 2019 IEEE\nInternational Conference on Microwaves, Antennas, Communications\nand Electronic Systems (COMCAS), pp. 1–5, 2019. [Online]. Available:\nhttps://api.semanticscholar.org/CorpusID:210694437 2\n[30] L.\nBossi,\nP.\nFalorni,\nand\nL.\nCapineri,\n“Versatile\nelectronics\nfor\nmicrowave\nholographic\nradar\nbased\non\nsoftware\ndefined\nradio\ntechnology,”\nElectronics,\n2022.\n[Online].\nAvailable:\nhttps://api.semanticscholar.org/CorpusID:252244896 2\n[31] Y. Rivenson, Y. Wu, and A. Ozcan, “Deep learning in holography and\ncoherent imaging.” Nature, Light Sci Appl, vol. 8, no. 85, 2019. 2, 3\n[32] D. Sheen, D. McMakin, and T. Hall, “Three-dimensional millimeter-\nwave imaging for concealed weapon detection,” IEEE Transactions on\nMicrowave Theory and Techniques, 2001. 3, 4\n[33] G. Tricoles and N. Farhat, “Microwave holography: Applications and\ntechniques,” Proceedings of the IEEE, 1977. 3\n[34] “Multistatic beamforming data, Waymond R. Scott georgia tech,” https:\n//waymond-scott.ece.gatech.edu/, accessed: 2023-04-05. 3\n[35] D. GABOR, “A new microscopic principle,” Nature, vol. 161, no.\n4098, pp. 777–778, 1948. [Online]. Available: https://doi.org/10.1038/\n161777a0 3\n[36] L. Bossi, P. Falorni, G. Pochanin, T. Bechtel, J. Sinton, F. Crawford,\nT. Ogurtsova, V. Ruban, and L. Capineri, “Design of a robotic platform\nfor landmine detection based on Industry 4.0 paradigm with data sensors\nintegration,” in Proc. of IEEE International Workshop on Metrology for\nIndustry 4.0 & IoT.\nIEEE, 2020, pp. 16–20. 3\n[37] B. Burns, “Comparison of measured ground penetrating radar response\nof soil surface to FDTD model,” in Proc. of IEEE International Sym-\nposium on Antennas and Propagation & USNC/URSI National Radio\nScience Meeting, 2018. 4\n[38] C. Rappaport, M. El-Shenawee, and H. Zhan, “Suppressing GPR clutter\nfrom randomly rough ground surfaces to enhance nonmetallic mine\ndetection,” Subsurface Sensing Technologies and Applications, vol. 4,\nno. 4, pp. 311–326, 2003. 4\n[39] B. Burns and N. Namazi, “Using 3d soil surface profile to predict and\nremove the surface response in stripmap sar,” in Proc. of 16th European\nConference on Antennas and Propagation (EuCAP), 03 2022, pp. 1–4.\n4\n[40] W. Clark, B. Burns, K. Sherbondy, J. Ralston, and C. Rappaport,\n“Surface effects on ground penetrating radar imagery,” in Proc. of IEEE\nAntennas and Propagation Society International Symposium, 2005. 4\n[41] A. W. Doerry, “Computed tomography: the details,” Sandia National\nLaboratories (SNL), Tech. Rep., 07 2007. 4\n[42] N. Georges T., A. Rola, and W. Logan, Analog and Digital Holography\nwith MATLAB.\nSociety of Photo-Optical Instrumentation Engineers\n(SPIE), 2015. 5\n[43] R. De la Fuente, “diffractsim: A flexible Python diffraction simulator.”\n5\n[44] Digital Holographic Microscopy for 3D Imaging of Complex Fluids and\nBiological Systems, Irvine, CA, 2010. 5\n[45] CVAT.ai Corporation, “Computer Vision Annotation Tool (CVAT),” 9\n2022. [Online]. Available: https://github.com/opencv/cvat 6\n[46] K. He, X. Zhang, S. Ren, and J. Sun, “Deep residual learning for image\nrecognition,” in Proc. of IEEE Conference on Computer Vision and\nPattern Recognition (CVPR), 2016, pp. 770–778. 7\n[47] A.\nDosovitskiy,\nL.\nBeyer,\nA.\nKolesnikov,\nD.\nWeissenborn,\nX. Zhai, T. Unterthiner, M. Dehghani, M. Minderer, G. Heigold,\nS.\nGelly,\nJ.\nUszkoreit,\nand\nN.\nHoulsby,\n“An\nimage\nis\nworth\n16x16\nwords:\nTransformers\nfor\nimage\nrecognition\nat\nscale,”\nCoRR,\nvol.\nabs/2010.11929,\n2020.\n[Online].\nAvailable:\nhttps://arxiv.org/abs/2010.11929 7\n[48] O. Ronneberger, P. Fischer, and T. Brox, “U-net: Convolutional networks\nfor biomedical image segmentation,” in Proc. of 18th International\nConference on Medical Image Computing and Computer-Assisted In-\ntervention (MICCAI).\nSpringer, 2015, pp. 234–241. 7\n[49] M. Tan and Q. Le, “Efficientnet: Rethinking model scaling for convolu-\ntional neural networks,” in Proc. of International Conference on Machine\nLearning.\nPMLR, 2019, pp. 6105–6114. 7\n[50] J. Lahoud, J. Cao, F. S. Khan, H. Cholakkal, R. M. Anwer, S. Khan,\nand M.-H. Yang, “3d vision with transformers: A survey,” 2022.\n[Online]. Available: https://arxiv.org/abs/2208.04309 7\n[51]\n¨O. C¸ ic¸ek, A. Abdulkadir, S. S. Lienkamp, T. Brox, and O. Ronneberger,\n“3D U-Net: Learning dense volumetric segmentation from sparse\nannotation,” 2016. [Online]. Available: https://arxiv.org/abs/1606.06650\n7\n\n\nIEEE JOURNAL OF SELECTED TOPICS IN APPLIED EARTH OBSERVATIONS AND REMOTE SENSING, VOL. XX, NO. X, MONTH YEAR\n11\nEmanuele Vivoli Emanuele Vivoli is a third-year\nPhD student at the MICC Lab, University of Flo-\nrence, and a second-year PhD student at the Com-\nputer Vision Center (CVC), Autonomous Univer-\nsity of Barcelona. His research interests encompass\nmulti-modal learning (vision and language integra-\ntion), sensors, and robotic platforms, with a focus on\nmulti-spectrum and multi-modal sensory data fusion.\nThroughout his academic career, Emanuele has made\nsignificant contributions as a first author to various\nconferences and journal articles. His work covers a\ndiverse range of topics, including document and table analysis, understanding\ncomics and manga, creating datasets and frameworks, and exploring multi-\nsensory data integration.\nLorenzo\nCapineri\nLorenzo Capineri. Scientific\nQualification as Full Professor in Electronics. His\ncurrent research activities are in the design of ul-\ntrasonic guided waves devices, buried objects detec-\ntion with ground penetrating radar and holographic\nradar. He has worked on several research projects\nin collaboration with national (Gilardoni spa) and\ninternational industries (National Semiconductors,\nTexas Instruments, Marvell, Thales Alenia Space\nItalia), and research institutions: the Italian Research\nCouncil (CNR), the Italian Space Agency (ASI)\nand the European Space Agency (ESA), AEA Technology and UKAEA\n(England), ISTC (International Science and Technology Centre) (Moscow,\nRussia), European Commission Joint Research Centre (Ispra) and NATO\n(Brussels, Belgium). He is coauthor of 7 Italian patents and coauthor of 4\nbook chapters and about 300 peer-revied scientific and technical papers. He\nis IEEE senior member since 2007 and member since 1983 and vice-president\nof the IEEE Italy Sensors Chapter. Co-chair of IWAGPR2015 conference and\nmember of scientific and technical committee of IUS-IEEE, GPR, PIERS,\nURSI-GASS and IWAGPR conferences. Fellow of Electromagnetic Academy\nand Fellow British Institute of Non-Destructive Testing.\nMarco Bertini Marco Bertini is an Associate Pro-\nfessor in Computer Science at the University of\nFlorence, Italy. He is the director of the Media\nIntegration and Communication Center of the Uni-\nversity of Florence. His interests are focused on\nmultimedia and computer vision. On these subjects\nhe has addressed semantic analysis, automatic con-\ntent indexing, semantic retrieval and video quality\nimprovement, applying these techniques to different\ndomains among which cultural heritage. He is author\nof more than 30 journal papers and more than 150\npeer-reviewed conference papers. He has been involved in 10 EU research\nprojects as WP coordinator and researcher, among which IM3I, euTV,\nORUSSI, UMETECH, AI4Media and ReInHerit. He has been general and\nprogram co-chair of several conferences on multimedia. He is co-founder of\nSmall Pixels, an academic spin-off working on GenAI solutions to improve\nvideo quality and video compression.\n\n\n",
  "metadata": {
    "source_file": "dataset/pdfs/arxiv_2502.21054v1.pdf",
    "total_pages": 11,
    "title": "HoloMine: A Synthetic Dataset for Buried Landmines Recognition using Microwave Holographic Imaging",
    "authors": [
      "Emanuele Vivoli",
      "Lorenzo Capineri",
      "Marco Bertini"
    ],
    "abstract": "The detection and removal of landmines is a complex and risky task that\nrequires advanced remote sensing techniques to reduce the risk for the\nprofessionals involved in this task. In this paper, we propose a novel\nsynthetic dataset for buried landmine detection to provide researchers with a\nvaluable resource to observe, measure, locate, and address issues in landmine\ndetection. The dataset consists of 41,800 microwave holographic images (2D) and\ntheir holographic inverted scans (3D) of different types of buried objects,\nincluding landmines, clutter, and pottery objects, and is collected by means of\na microwave holography sensor.\n  We evaluate the performance of several state-of-the-art deep learning models\ntrained on our synthetic dataset for various classification tasks. While the\nresults do not yield yet high performances, showing the difficulty of the\nproposed task, we believe that our dataset has significant potential to drive\nprogress in the field of landmine detection thanks to the accuracy and\nresolution obtainable using holographic radars.\n  To the best of our knowledge, our dataset is the first of its kind and will\nhelp drive further research on computer vision methods to automatize mine\ndetection, with the overall goal of reducing the risks and the costs of the\ndemining process.",
    "published_date": "2025-02-28",
    "source": "arxiv"
  }
}