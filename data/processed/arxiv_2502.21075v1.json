{
  "id": "arxiv_2502.21075v1",
  "text": "Spatial Reasoning with Denoising Models\nChristopher Wewer 1 Bart Pogodzinski 1 Bernt Schiele 1 Jan Eric Lenssen 1\nSRMs (Ours)\nStandard DDPM\nPlaying MNIST Sudoku with Image Generators‚Ä¶.\nFigure 1: We introduce Spatial Reasoning Models (SRMs), a framework to systematically investigate diffusion/flow-based\ngenerative models with respect to their reasoning capabilities over multiple variables. We introduce benchmarks that allow\nquantification of higher-level reasoning capabilities and show that manual and automatic schemes for sequentialization can\nheavily reduce hallucination. Here, we show the solving process of one of the benchmarks, a Sudoku game consisting of\nMNIST images, which is solved correctly by our SRMs, while standard diffusion models fail.\nAbstract\nWe introduce Spatial Reasoning Models (SRMs),\na framework to perform reasoning over sets of\ncontinuous variables via denoising generative\nmodels. SRMs infer continuous representations\non a set of unobserved variables, given observa-\ntions on observed variables. Current generative\nmodels on spatial domains, such as diffusion and\nflow matching models, often collapse to hallucina-\ntion in case of complex distributions. To measure\nthis, we introduce a set of benchmark tasks that\ntest the quality of complex reasoning in generative\nmodels and can quantify hallucination. The SRM\nframework allows to report key findings about\nimportance of sequentialization in generation, the\nassociated order, as well as the sampling strate-\ngies during training. It demonstrates, for the first\ntime, that order of generation can successfully be\npredicted by the denoising network itself. Using\nthese findings, we can increase the accuracy of\nspecific reasoning tasks from < 1% to > 50%.\nOur project website provides additional videos,\ncode, and the benchmark datasets.\n1Max Planck Institute for Informatics, Saarland Informat-\nics Campus, Germany. Correspondence to: Christopher Wewer\n<cwewer@mpi-inf.mpg.de>, Bart Pogodzinski <bpogodzi@mpi-\ninf.mpg.de>, Jan Eric Lenssen <jlenssen@mpi-inf.mpg.de>.\n1. Introduction\nConditional generative models, such as GPTs (Radford et al.,\n2018) or denoising models like diffusion/flow-based mod-\nels (Ho et al., 2020; Song et al., 2021; Lipman et al., 2023;\nLiu et al., 2023), promise significant advances in practical\nreasoning. They allow to model highly complex and multi-\nmodal distributions by learning to sample from them. While\nreasoning capabilities of LLMs are extensively explored\nin many recent works (Huang & Chang, 2023), similar ef-\nforts in continuous, spatial domains are needed to profit\nfrom the semantic structure that can be learned from high-\ndimensional, continuous data. Our work approaches this\ngoal by providing a novel framework to benchmark and ad-\nvance the reasoning capabilities of diffusion/flow-based gen-\nerative models, which we deem of large importance for the\nfurther development of large image, video, and physically-\ngrounded world models (Agarwal et al., 2025).\nThe process of reasoning can be defined as inferring the\nstates of unobserved variables xi, given a distinct set of\nobserved variables yj (Kwan et al., 2008), with varying de-\npendencies between all variables, loosely inspired by tradi-\ntional fields of probabilistic graphical models and Bayesian\nnetworks. Most reasoning tasks are subject to a high degree\nof inherent uncertainty due to incompleteness of informa-\ntion given in the observed variables. Thus, it is natural to\ntackle reasoning problems with probabilistic inference, i.e.,\nmodeling p(x1, ..., xn | y1, ..., ym). When reasoning across\n1\narXiv:2502.21075v1  [cs.CV]  28 Feb 2025\n\n\nSpatial Reasoning with Denoising Models\n(a) Training Data\n(b) Conditioning image and generation output, standard DDPM\nFigure 2: MNIST Sudoku. One of our reasoning benchmarks. (a) A dataset of correct Sudokus, consisting of random\nMNIST images. (b) When training a conditional diffusion model on correct examples it fails to conditionally generate\ncorrect solutions for hard Sudokus (almost 0% accuracy). In contrast, SRMs achieve > 50% accuracy for these cases.\nhigher-dimensional continuous domains, such as images\nor image patches, these distributions become complex and\nmulti-modal, preventing the application of traditional ap-\nproaches that rely on Gaussian assumptions or predefined\nfamilies of discrete distributions.\nGenerative models for spatial domains typically learn to\nsample from an approximated data distribution p(x1, .., xn).\nTo perform reasoning, it is desired that such a model ab-\nstracts from the low-level data space and is able to detect\nhigh-level patterns that occur in seen data. To obtain an\ninsight into the level of such capabilities of existing diffu-\nsion/flow models, we introduce a set of benchmarks. One\nexample based on the well-known Sudoku game, where each\nnumber from 1 to 9 must occur exactly once in each row,\ncolumn and 3x3 block, is shown in Fig. 2. A (conditional)\ndiffusion model is trained to generate or complete correct\nSudokus consisting of varying MNIST digits. While the gen-\nerated images look realistic on the first glance, as individual\nnumbers are high-quality samples from the MNIST dataset,\nthe generation process fails to sample correct instances. We\nidentify this effect as an instance of hallucination, where\nthe model falls back to superficial solutions that satisfy the\npixel-wise MSE loss well enough, in case it fails to capture\nthe actual, complex patterns in the underlying distribution.\nIn the space of large language models (LLMs), chain-of-\nthought prompting has achieved successes in fighting such\nhallucinations by prompting the model to make smaller,\nsequential steps towards the solution (Wei et al., 2022). In-\nspired by these advances, we develop and investigate strate-\ngies in our spatial setting that can lead to similar effects.\nThe chain-rule of probabilities lets us decompose\np(x1, .., xn) =\nn\nY\ni=1\np(xœÄ(i)|{xœÄ(j)}n\nj=i+1)\n(1)\nfor arbitrary permutations œÄ. While all orders œÄ model the\ncorrect distribution in theory, the individual orders lead to\nchains of varying complexity in the individual distributions,\ndetermined by hidden dependencies, potentially leading to\nvarying amounts of hallucination during sampling. We be-\nlieve investigating strategies to find (1) the correct amount of\nsequentialization and (2) the best order with least amount of\nhallucination is a promising venture for further development\nof continuous generative models.\nTo this end, we introduce Spatial Reasoning Models (SRMs),\nan architecture-agnostic framework to formulate (soft or\nhard) sequentialization strategies that can be used for rea-\nsoning on sets of continuous variables without canonical\norder. Within this framework, we create multiple of such\nstrategies and perform an exhaustive evaluation on bench-\nmark tasks as described above.\nIn summary, our contributions are\n‚Ä¢ a general framework for reasoning over sets of contin-\nuous variables with denoising generative models,\n‚Ä¢ a novel algorithm for t-sampling during training, which\nadjusts for multiple variables,\n‚Ä¢ different task-specific and task-agnostic, soft and hard\nvariants of sequentialization within reasoning models,\n‚Ä¢ a benchmark to quantitatively measure hallucination in\nreasoning over visual domains.\nWe can summarize the key findings as\n‚Ä¢ diffusion/flow-based generative models are capable of\nsimple visual reasoning but fall back to hallucination\nwhen the modeled distribution becomes too complex,\n‚Ä¢ inducing sequentialization can simplify the task by\ndecomposing into simpler distributions, reducing hal-\nlucination, and improving reasoning,\n‚Ä¢ greedy orders based on predicted uncertainty can sig-\nnificantly improve reasoning quality further,\n‚Ä¢ the choice of training t-sampling strategies is crucial\nwhen adjusting for sequentialization.\nOur framework, code, and benchmarks are available on our\nproject website for further investigation and development.\n2. Related Work\nProbabilistic reasoning is currently receiving a lot of at-\ntention, mostly driven by recent advancements in large\nlanguage models (LLMs) (Huang & Chang, 2023; Plaat\net al., 2024) that allow to generate tokens from a discrete\ncodebook. To leverage their capabilities, many modalities\n2\n\n\nSpatial Reasoning with Denoising Models\nhave been mapped to such discrete spaces, using special-\nized tokenizers (van den Oord et al., 2017), allowing to\nreason about originally continuous domains to certain de-\ngrees (Chen et al., 2023). Vision Language Models (VLMs)\nhave been heavily used to connect spatial domains with\nlanguage, to perform reasoning about images in the text\ndomain (Chen et al., 2024b). In this work, we move in\na different direction and investigate reasoning capabilities\nacross continuous domains by generative models that have\nexplicitly been designed to work on these domains, such as\nDDPM (Ho et al., 2020), DDIM (Song et al., 2021), recti-\nfied flow (Liu et al., 2023), or flow matching (Lipman et al.,\n2023). Investigating reasoning capabilities of such models\nhas remained largely unexplored so far.\nClosest to our work are recent methods that introduce differ-\ning levels of noise in sequential generation with diffusion\nmodels (Wu et al., 2023; Zhang et al., 2024; Ruhe et al.,\n2024; Chen et al., 2024a). AR-Diffusion (Wu et al., 2023)\nperformed generation via diffusion on text spaces. Later, the\nidea was extended to sequential, continuous spaces, such\nas human poses (Zhang et al., 2024), or videos (Ruhe et al.,\n2024; Chen et al., 2024a), which also introduced overlap-\nping via different noise levels of variables in purely sequen-\ntial settings. Our work extends this direction to arbitrary\nspatial settings without canonical orders. Also, we heavily\nimprove on the training sampling strategy used in Diffusion\nForcing (Chen et al., 2024a). Another recent related work\nis MAR (Li et al., 2024), which performs autoregressive\ngeneration of image patches via denoising in random order.\n3. Spatial Reasoning Models\nIn this section, we introduce our spatial reasoning mod-\nels. We begin with formulating our general framework in\nSec. 3.1. After training a SRM as outlined in Sec. 3.2, it can\nbe leveraged with various sampling strategies. We introduce\na selection of those in Sec. 3.3.\n3.1. General Framework\nOur goal is to learn to reason over sets of continuous ran-\ndom variables. Practical examples of such variables can be\npatches of images, frames of videos, or even multiple views\nof a 3D scene. For our SRM setting, we define reasoning\nover a set of continuous random variables as sampling\nÀÜxt1\n1 , ..., ÀÜxtn\nn ‚àºq(xt1\n1 , ..., xtn\nn | xt‚Ä≤\n1\n1 , ..., xt‚Ä≤\nn\nn ),\n(2)\nwhere xti\ni denotes the variable xi with noise level ti during\nthe denoising process and ti ‚â§t‚Ä≤\ni. Spatiality is (optionally)\nencoded via positional encodings on the variables. Choosing\nnoise levels ti allows explicit control over amount and order\nof sequentialization, as discussed further in Sec. 3.1.2.\nBelief propagation.\nThe above paradigm is loosely\ninspired by belief propagation through Bayesian net-\nworks (Pearl, 1982), propagating information from observed\nto unobserved variables via sequential probabilistic infer-\nence. However, the set of assumptions is drastically reduced.\nIt does not make any assumptions about distributions of x0\ni\nand does not strictly require the Markov assumption about\nconditional independence between variables, as required\nfor tractability in Bayesian networks. Instead, the network\ncan (but not has to) be conditioned on all other variables,\nutilizing compression capabilities of neural networks.\n3.1.1. SAMPLING IN CONTINUOUS DOMAINS\nWe first introduce our formulation for sampling a single\ncontinuous random variable. Denoising generative models\nare the established state-of-the-art for learning continuous\ndata distributions (Dhariwal & Nichol, 2021). While there\nare multiple different derivations like score matching (Song\n& Ermon, 2019), DDPM (Ho et al., 2020), or the recently\nmore popular (conditional) flow matching (Lipman et al.,\n2023), they all share the same idea of learning a step-wise\nmapping of scalar or higher-dimensional continuous vari-\nables xt from a simple and known Gaussian distribution\nx1 ‚àºN(0, I) to the complex and unknown data distribu-\ntion x0 ‚àºq. With small enough step sizes t‚Ä≤ ‚àít (Ho et al.,\n2020), each step itself can be modeled by sampling from a\nGaussian distribution (with possibly zero variance)\nxt ‚àºN(¬µŒ∏(xt‚Ä≤), Œ£Œ∏(xt‚Ä≤)),\n(3)\nparameterized by a neural network with weights Œ∏, trained to\ndenoise noisy versions of samples from the data distribution.\nTraining examples are constructed by interpolating between\nsamples x0 ‚àºq and Gaussian noise œµ ‚àºN(0, I) as\nxt = a(t)x0 + b(t)œµ,\n(4)\nwhere t\n‚àà\n[0, 1] is a continuous level of noise and\na, b : [0, 1] 7‚Üí[0, 1] define interpolation weights. While\nDDPM (Ho et al., 2020) limits itself to a subset of possible\nnoise schedules, alternatives like rectified flows were re-\ncently explored as general Gaussian probability paths in the\ncontext of conditional flow matching (Lipman et al., 2023).\nIn this work, we construct a specific reverse distribution, i.e.,\nmean and variance in Eq. 3 for arbitrary noise schedules a, b\nwith its marginal distribution satisfying Eq. 4, similar as but\nmore general than DDIM (Song et al., 2021). We provide\nall details and proofs in Appendix A. As a result, our formu-\nlation can combine non-diffusion noise schedules such as\nfrom rectified flows (Liu et al., 2023) (a(t) = 1‚àít, b(t) = t)\nwith stochastic sampling as in DDPM and follow-ups such\nas learning the variances of the reverse distributions (Nichol\n& Dhariwal, 2021).\n3\n\n\nSpatial Reasoning with Denoising Models\n(a) Amount of Sequentialization\n(b) Order of Sequentialization\nFigure 3: Investigated degrees of freedom. (a) The SRM framework allows to define different amounts of sequentialization,\ni.e. parallel generation, autoregressive generation or mixtures with varying overlap, modeled by differing levels of noise\non individual variables at the same time. (b) Further, it provides different options to define the order of sequentialization,\nallowing random ordering, a greedy heuristic based on predicted uncertainty and manually-defined graphs.\n3.1.2. SAMPLING IN SPATIAL DOMAINS\nWe model our spatial reasoning problems as inferring sets of\ncontinuous random variables, unifying previous denoising\ngenerative approaches and spatially autoregressive methods.\nOn the one hand, existing diffusion- and flow-based models\nlike popular image generators (Rombach et al., 2022) reason\nonly along the noise dimension by assuming single, shared\nnoise levels for all variables at any point in time during the\ndenoising process. By setting t1 = ... = tn and t‚Ä≤\n1 = ... =\nt‚Ä≤\nn in Eq. 2, this special case is subsumed by our framework.\nWe hypothesize potential limitations of this approach in\nthe presence of complex dependencies between spatially\ndistinct variables, as in the case of MNIST Sudoku (Fig.2).\nOn the other hand, spatially autoregressive approaches like\nMAR (Li et al., 2024) learn to sample a next variable xi con-\nditioned on the history of previously sampled variables xj\nfor j ‚ààJ and {{i}, J , K} being a partitioning of {1, ..., n}.\nOur framework covers this specific way of sampling by set-\nting tj = t‚Ä≤\nj = 0 for j ‚ààJ and tk = t‚Ä≤\nk = 1 for k ‚ààK.\nAlthough the application of the chain-rule can decompose\nthe complex joint distribution of variables into potentially\nsimpler conditional distributions, we argue that potential\nimprovements depend on the order, which is usually simply\nset to be random or a raster scan.\nThese two special instances depict the extreme cases of our\nframework. Given that both have their own strengths and\nweaknesses, we aim to explore the space in between. There-\nfore, we train spatial reasoning models to jointly denoise\nmultiple variables but with individual noise levels.\n3.2. Training\nWe parameterize a SRM as a noise prediction network œµŒ∏\nthat is trained to regress the ground truth noise œµ ‚àºN(0, I)\nL¬µ = Eœµ,t,x‚à•œµŒ∏(xt) ‚àíœµ‚à•2,\n(5)\nwhere t := (t1, ..., tn), x := (x1, ..., xn), and xt :=\n(xt1\n1 , ..., xtn\nn ). Additionally, we let the network predict the\nvariance of the reverse process in Eq. 3, optimized for the\nvariational lower bound (Nichol & Dhariwal, 2021). As\nshown in previous works (Esser et al., 2024), the training\nof a denoising network is very sensitive to the sampling of\nnoise levels. This is especially true for our setting of indi-\nvidual noise levels for a possibly large number of variables.\n3.2.1. NOISE LEVEL SAMPLING\nSampling noise levels during training of diffusion models\nallows the model to learn denoising images of all noise\nlevels t. In SRMs, the image patches also act as conditioning\nto other patches, so we need to ensure that the whole t\ndistribution is similar to what happens during inference.\nAt the beginning of inference, all patches pi start with\nti = 1, so the mean noise level is initially ¬Øt = 1. Similarly,\nat the end of inference, all patches reach ti = 0, giving\n¬Øt = 0. For diffusion models with linear time schedules,\nor our SRM with a parallel schedule, the mean noise level\ndecreases by a fixed amount per inference step ‚àÜ¬Øt = ‚àí1\nN ,\nwhere N is the number of inference steps. In the autore-\ngressive generation, a similar relation holds ‚àÜ¬Øt = ‚àí\n1\nM¬∑P ,\nwhere M is the number of steps per patch, and P is the\nnumber of patches. In both cases, ‚àÜ¬Øt does not depend on\nthe noise level, which suggests that with a sufficient num-\nber of inference steps, ¬Øt should ideally follow a uniform\ndistribution. See Fig. 9 in appendix for visualization.\nDiffusion Forcing (Chen et al., 2024a) suggests to indepen-\ndently sample a noise level vector t ‚àºU([0, 1]n), ensuring\na uniform marginal distribution, ti ‚àºU(0, 1). However, this\nleads to the mean ¬Øt following a Bates distribution, which is\nhighly concentrated around 0.5 ‚Äì significantly different from\nthe distribution encountered during inference (c.f. Fig. 4a).\nAs a result, a trained model is undertrained for early (and\nlate) inference steps, where most patches have noise levels\nclose to 1 (and 0), heavily reducing performance as demon-\nstrated in Sec. 4.6.\n4\n\n\nSpatial Reasoning with Denoising Models\n(a) Uniform t (Diffusion Forcing)\n(b) Uniform ¬Øt (ours)\nFigure 4: The left plot shows the joint distribution of noise\nlevels ti and mean noise levels ¬Øt for Diffusion Forcing train-\ning, while the right plot shows the same for our Uniform ¬Øt\napproach. In Diffusion Forcing, the distribution of ti is cor-\nrectly modeled but ¬Øt is overly concentrated around ¬Øt = 0.5,\nwhich does not reflect the distribution seen during inference.\nOur Uniform ¬Øt addresses this issue, though it introduces\nsome bias in the distribution of individual ti which we ad-\ndress by per-patch loss weighting.\nTo address this issue, we introduce a two-step sampling\nstrategy called Uniform ¬Øt. We first sample ¬Øt ‚àºU(0, 1), and\nthen generate t ‚àºp(t | ¬Øt) using our recursive allocation\nsampling algorithm (Appendix C.1). The algorithm allows\ncontrol of the sharpness of the p(t | ¬Øt) ‚Äì the spread of\nindividual ti around ¬Øt. This makes it adaptable to different\ninference scenarios flexible for different inference settings.\nFor example, in the parallel generation, ti should stay close\nto ¬Øt (high sharpness). In contrast, autoregression benefits\nfrom greater cross-patch noise level variance.\nUniform ¬Øt sampling preserves the uniform mean distribution\nbut oversamples individual patch noise levels close to ti = 0\nand ti = 1 (c.f. Fig. 4b). This occurs because if ¬Øt ‚âà0 is\nsampled, all ti must be close to 0 and similarly for ¬Øt ‚âà1,\n‚àÄiti ‚âà1. On the other hand, for ¬Øt ‚âà0.5, the ti samples\ncan take any value within the range. To counteract this bias\ntowards sampling ti ‚âà0 or ti ‚âà1, we introduce per-patch\nloss weights wt =\n1\np(t), where p(t) is empirically estimated.\n3.2.2. UNCERTAINTY ESTIMATION\nTo sample variables in a meaningful order, we propose to\ntrain the denoising network to predict the uncertainty in its\nnoise prediction. As common in heteroscedastic uncertainty\nestimation (Seitzer et al., 2022), we model the uncertainty\nas standard deviation œÉŒ∏(xt) and minimize the negative\nlog-likelihood (NLL) of the ground truth noise œµ\nLœÉ = Eœµ,t,x ‚àílog N(œµ|œµŒ∏(xt), œÉŒ∏(xt)2I).\n(6)\nTo avoid deteriorating the noise prediction, we only train\nthe uncertainty estimation with this loss and a small weight.\n3.3. Sampling\nA trained SRM can be used for various sampling techniques\nand therefore benchmark them fairly using a single model.\nWe investigate different amounts and orders of sequential-\nization for the denoising of spatial variables (see Fig. 3).\nRegarding the amount of sequentialization, we explore par-\nallel generation as usual in denoising generative models, the\nother extreme of fully autoregressive sampling, and a mix-\nture achieved by overlapping the denoising step intervals of\nthe different variables by a variable amount.\nBesides the amount of sequentialization, we further com-\npare different orders of variables. Leveraging the estimated\nuncertainty in the noise prediction from Sec. 3.2.2, we pro-\npose to adaptively sample the next variable with the lowest\nuncertainty. This strategy follows the assumption that more\nuncertain variables can benefit from stronger conditioning of\nmany clean variables later during sampling. For some tasks,\nwe know the dependency structure between spatial variables\nin advance. Considering our Sudoku example, a cell de-\npends directly on the other cells in its row, column, and 3x3\nblock. Encoding this information in form of an adjacency\nmatrix, we propose to propagate certainty based on each\nvariable‚Äôs noise level to sample the most certain variable\nnext. We include a random order as further baseline.\n4. Experiments\nWe evaluate SRMs for reasoning on three new benchmark\ndatasets that we introduce in Sec. 4.1. We consider images\nsplit into patches as our sets of continuous random variables\nand use 2D UNets for denoising as described in Sec. 4.2.\nBesides our main findings detailed in Sec. 4.3 to 4.5, we\nprovide additional ablations in Sec. 4.6.\n4.1. Benchmark Datasets\nWe introduce three different datasets to quantify reasoning\ncapabilities. They are aimed at different aspects to be tested.\nThe MNIST Sudoku dataset captures complex (NP-hard)\ndependencies that need to be understood. The Counting\nPixels dataset is an easier task that can be solved in a greedy\nfashion. Finally, we introduce the Counting Polygons FFHQ\ndataset, which moves closer to real-world images.\nMNIST Sudoku Dataset\nWe create a dataset based on\none million correct Sudoku instances by randomly sam-\npling MNIST representatives for each cell (see Fig. 2a for\nexamples). The classification of Sudoku images into cor-\nrect and incorrect ones is then done via an application of a\npre-trained MNIST digit classifier MLP on each cell and a\ncheck whether all Sudoku rules are fulfilled. To avoid classi-\nfication errors distorting our reasoning results, we limit the\nset of MNIST digit representatives to the top 1000 training\nexamples per class of the classifier w.r.t. its confidence.\n5\n\n\nSpatial Reasoning with Denoising Models\n(a) Even Pixels dataset\n(b) Counting Polygons FFHQ dataset\nFigure 5: Two further datasets. In addition to MNIST Sudoku, we introduce two further datasets. (a) The counting pixel\ndataset requires the model to generate images with an equal number of pixels per color. (b) The counting polygon dataset\nrequires that all images contain two numbers: one for the number of polygons and one for the number of polygon edges.\nFor testing, we use a held-out dataset split of valid Sudokus\nand apply random masking of cells with the number of\nmasked ones randomly sampled from the intervals [1, 27],\n[28, 54], and [55, 81], resulting in three levels of difficulty\neasy, medium, and hard, respectively. As metrics, we con-\nsider accuracy as well as the sum of L1-distances of row-,\ncolumn-, and block-wise digit histograms to the all ones\nvector (zero if correct), averaged over all test examples.\nThe game Sudoku involves complex spatial dependencies,\nwhereas the distribution of individual cells being MNIST\nnumbers is simple to fit by a generative model. Note that\nthe general task of solving Sudokus for a variable grid size\nis NP-complete and that depending on the level of masking,\nthere can be multiple valid solutions resulting in uncertainty.\nFor our graph-based order for sequentialization during sam-\npling, we encode the direct dependencies between each cell\nand its neighbors within a row, column, and block as the ad-\njacency matrix. Additionally, we provide results for oracle\nalgorithms that directly solve discrete Sudokus by randomly\nsampling a number for the next cell from all possible digits\navoiding collisions with neighbors if possible. The order\nof cells is chosen either randomly or in a greedy fashion,\nwith the next cell being the one with the largest number of\nalready sampled neighbors in the constructed graph.\nEven Pixels Dataset\nWe construct a dataset of images\nwhere each pixel is assigned one of two opposite colors\n(c.f. Fig. 5a). The number of pixels of each color is always\nequal. The task requires a model to learn this implicit con-\nstraint without explicit supervision. We detail our evaluation\nprocedure in Appendix D.\nCounting Polygons FFHQ Dataset\nWe also introduce a\ndataset in which each image contains a set of randomly posi-\ntioned polygons and numbers (see Fig. 5b), where: The num-\nber of polygons, N, is randomly sampled from {1, . . . , 9},\neach polygon has K vertices, sampled from {3, . . . , 7} and\nthe numbers N and K are explicitly present in the image.\nThe model‚Äôs task is to generate images following this rule\nand therefore to capture the relationship between the number\nof polygons, vertices, and the digits.\nTo introduce real-world complexity, we place these synthetic\nobjects over backgrounds sampled from the FFHQ dataset.\nThis forces the model to notice and learn meaningful spatial\ndependencies in a setting much closer to the real world.\nWe train a ResNet classifier to estimate correctness. More\ndetails are given in Appendix E.\n4.2. Experimental Setup\nWe compare SRMs in pixel space with standard denois-\ning diffusion models that are equivalent in architecture and\ntraining up to the sampling of individual spatial variables,\nwhich are chosen to be image patches of task-specific sizes\nfor our visual reasoning tasks. Since our MNIST Sudoku\nbenchmark can be seen as an instance of inpainting, the\nbaseline diffusion model is additionally conditioned on the\nincomplete Sudoku and its mask via concatenation in the\ninput. Note that this is not necessary for SRMs, as already\ngiven variables are identified by the noise level zero. If\nnot stated otherwise, we use stochastic sampling similar\nto DDPM with 1000 steps (network evaluations) indepen-\ndent of the method of sequentialization during sampling.\nWhile SRMs are agnostic to different architectures, we use\nlightweight versions of widely established 2D UNets with\nspatial attention in low-resolution layers to avoid results\nbeing dominated by too extreme overparameterization. We\ndescribe the exact sampling process in Appendix A and\nimplementation details in Appendix F.\n4.3. MNIST Sudoku Results\nWe provide a quantitative comparison of SRM with different\nsampling strategies, a standard diffusion model as baseline,\nand the task-specific discrete oracle algorithms in Tab. 1.\nWhile the (inpainting) diffusion model that does fully paral-\nlel denoising of all patches is able to solve easy examples\nwith a large number of given cells, its performance dete-\nriorates drastically with weaker conditioning. SRM with\nparallel sampling behaves similar, indicating that this sam-\npling strategy is inappropriate for the Sudoku task with\ncomplex dependencies, independent of the network training.\nFor all spatially autoregressive sampling methods, having an\noverlap between denoising intervals of patches sampled one\nafter the other, decreases the performance compared to the\nfull autoregressive extreme. This highlights the importance\nof spatial sequentialization for reasoning.\nFurthermore, our results clearly show that the order of se-\nquentialization matters. SRM with a random order achieves\nmediocre performance. As the model always sees the entire\n6\n\n\nSpatial Reasoning with Denoising Models\nEasy\nMedium\nHard\nModel\nSampling\nL1‚Üì\nAcc‚Üë\nL1‚Üì\nAcc‚Üë\nL1‚Üì\nAcc‚Üë\nDiffusion Model\nParallel\n0.032\n0.994\n3.924\n0.536\n14.120\n0.008\nParallel\n0.012\n0.998\n3.312\n0.590\n19.156\n0.010\nPredicted Order w/o Overlap\n0.012\n0.998\n1.616\n0.754\n3.212\n0.516\nPredicted Order + Overlap\n0.000\n1.000\n1.816\n0.716\n4.340\n0.422\nRandom Order w/o Overlap\n0.012\n0.998\n3.828\n0.568\n12.612\n0.024\nRandom Order + Overlap\n0.000\n1.000\n4.172\n0.542\n13.896\n0.020\nGraph-based Order w/o Overlap\n0.020\n0.996\n2.544\n0.662\n5.816\n0.266\nSRM (Ours)\nGraph-based Order + Overlap\n0.000\n1.000\n3.240\n0.576\n6.036\n0.238\nRandom\n-\n0.751\n-\n0.059\n-\n0.000\nOracle\nGreedy\n-\n1.000\n-\n0.987\n-\n0.672\nTable 1: MNIST Sudoku Quantitative Results. While standard DDPM diffusion models fail to solve the hard Sudoku\ncases (accuracy near 0%, SRMs achieve an accuracy of > 50%). Interestingly, the Sudoku task particularly profits from\npredicted uncertainty, which heavily outperforms random sequentialization order and also the graph-based ordering. We\nprovide the accuracy of a combinatorial Sudoku solver using a greedy strategy (without backtracking) as reference (Oracle).\n(noisy) Sudoku, the network learns that the distribution of\nthe currently denoised patch does not only depend on all pre-\nviously denoised cells but also on the possible solutions for\nall future ones, explaining the advantage over the random\noracle (which fails completely). Using task-specific knowl-\nedge about spatial dependencies in form of a general graph\nhelps to significantly improve the order of sequentialization\nand as a result sampling from the correct distribution.\nHowever, we achieve the best performance by a large margin\nwith the task-agnostic order based on the predicted uncer-\ntainty as described in Sec. 3.2.2. An example for such a\nsampling process is visualized in Fig. 7. We depict three\npairs of close steps at the start, middle, and end of sampling.\nBy following an exclusion procedure for the digit one in\nthe middle right block using clean conditionings only, we\nunderstand why the model correctly predicted the lowest\nuncertainty for that patch at the start. Moving to the middle\ncase, the chosen cell is also completely determined by the\nconditioning, which only becomes visible if one takes into\naccount other cells that are not yet denoised but already\ndetermined by applying the rules of Sudoku. We encourage\nthe reader to verify this for themselves. In the end, we have\na case of multiple valid solutions, from which SRMs, being\ngenerative models, are able to sample. We further demon-\nstrate the sample diversity for multiple incomplete Sudokus\nin Fig. 6. We provide videos on our project website that\nvisualize the full sampling process for multiple examples.\nOverall, we improve the correctness of samples in the hard\nsetting from 0.8% to 51.6% (cf. Tab. 1) using the same\ntrained model, only varying the sampling strategy.\n4.4. Even Pixels Results\nTab. 2 shows the quantitative comparison of our best settings\nfor all sampling methods. We can see a clear gap between\nthe diffusion baseline and SRM. While the diffusion model\nMasked Input\nSample 1\nSample 2\nSample 3\nFigure 6: Sample Diversity. SRMs can sample multiple\ndifferent, correct solutions given an incomplete observation.\nSamling\n#E‚Üì\nAcc‚Üë\nDiffusion Model\n1.270\n0.250\nOurs, Parallel\n5.184\n0.054\nOurs, Predicted Order + Overlap\n0.534\n0.518\nOurs, Random Order + Overlap\n0.584\n0.476\nTable 2: Even Pixels Experiments. SRMs clearly outper-\nform a standard diffusion model in this task. Random order\nand predicted order perform similar, with a slight advantage\nfor the predicted one. See Fig. 8 for overlap analysis.\nmust learn to balance pixel colors evenly on a global level,\nsequentially eliminating differences in pixel counts can sim-\nplify the task. This behavior can be further encouraged\nby lowering the sharpness of our noise level sampling dur-\ning training (cf. Sec. 3.2.1), i.e., slightly biasing the SRM\ntraining towards spatially autoregressive generation.\n7\n\n\nSpatial Reasoning with Denoising Models\nSample ùê±ùê≠\nNoise level ùê≠\nUncertainty ùùàùúΩ(ùê±ùê≠)\nSingle Step ‡∑úùê±ùüé\nSampling Process\n‚Ä¶\n‚Ä¶\nFigure 7: Sequentialization with uncertainty-based order.\nWe visualize the sampling process with the current sample\nxt, noise level t, estimated uncertainty (darker = lower)\nœÉŒ∏(xt), and the single step to t = 0 result ÀÜx0. SRMs are\nable to reason over spatial variables by capturing complex\ndependencies (first two blocks) and handle uncertainty, e.g.,\nin the case of multiple valid solutions as in the last block.\nUnlike for the MNIST Sudoku experiment, we find over-\nlapping denoising of variables to be beneficial and further\nvisualize this relationship in Fig. 8. For both predicted and\nrandom order, the accuracy gradually increases with a higher\noverlap until a sweet spot at 0.95, after which it falls quickly.\nThis shows that depending on the data distribution, mixtures\nof parallel and sequential generation enabled by SRMs can\nbe advantageous. We can see a small, consistent advantage\nof the predicted uncertainty order over the random one.\n4.5. Counting Polygon Results\nFor the final counting polygons on FFHQ dataset, we pro-\nvide the quantitative results in Tab. 3. SRM outperforms the\ndiffusion model consistently independent of the sampling\nmethod. This indicates potential of our training with indi-\nvidual noise levels, as this form of spatial disentanglement\nFigure 8: Even pixel accuracy for different overlap.\nLarger overlap is better for generating an even number of\npixels. However, when approaching the parallel setting at\n1.0, the performance heavily drops.\nSampling\nAcc‚Üë\nDiffusion Model\n0.132\nOurs, Parallel\n0.166\nOurs, Predicted Order w/o Overlap\n0.144\nOurs, Predicted Order + Overlap\n0.142\nOurs, Random Order w/o Overlap\n0.164\nOurs, Random Order + Overlap\n0.186\nTable 3: Counting Polygon FFHQ Experiments. Al-\nthough this task is generally hard and not solved well, all\nSRM settings clearly outperform standard diffusion models.\nmight be generally beneficial for certain data distributions.\nUnlike for the other two benchmarks, there is no clearly\nwinning sampling strategy, as all methods perform simi-\nlarly in terms of generating matching polygon and vertex\nnumbers. We attribute this to two main differences of the\ndataset. First, using real images for backgrounds makes the\ntask significantly more complex, as the denoising objective\nbecomes less sensitive to the dependencies between num-\nbers and polygons and capacity of the denoising network is\nspent for fitting the distribution of FFHQ faces. Secondly,\nthe simultaneous generation of matching numbers and poly-\ngons can be approached in a coarse-to-fine manner with the\nnumbers being more high-frequency details compared to\nlarger low-frequency polygons. Still, the task of counting\nis inherently sequential and we can see the best result for a\nrandom order with overlapping patch denoising.\n4.6. Ablations\nIn Tab. 4, we provide the results of an ablation w.r.t. the\nnoise level sampling from Sec. 3.2.1 on the hard difficulty\nof the MNIST Sudoku dataset. Enforcing a uniformly dis-\ntributed mean during training is essential for all sampling\nmethods. While independent uniform sampling of noise\nlevels might be good enough for a very small number of\nvariables as in Diffusion Forcing (Chen et al., 2024a), high\nand low mean noise levels quickly become severely under-\nsampled when we increase it. As these two cases represent\n8\n\n\nSpatial Reasoning with Denoising Models\nSampling / t-Sampling\nUniform t\nOurs\nParallel\n0.000\n0.008\nPredicted Order w/o Overlap\n0.018\n0.516\nPredicted Order + Overlap\n0.008\n0.422\nRandom Order w/o Overlap\n0.000\n0.024\nRandom Order + Overlap\n0.000\n0.020\nGraph-based Order w/o Overlap\n0.012\n0.266\nGraph-based Order + Overlap\n0.010\n0.238\nTable 4: Noise Level Sampling Ablation. Ablation per-\nformed on MNIST Sudoku hard. Our strategy for sampling\nt‚Äôs during training is crucial for all strategies to work.\nstart and end points at test time, the input to the network is\nimmediately out of the training distribution during sampling.\nWe provide additional ablations in Appendix G.\n5. Conclusion\nWe introduced Spatial Reasoning Models (SRMs), a frame-\nwork that allows to reason over sets of continuous, spatial\nvariables. Our framework allows parameterization for sev-\neral different strategies of sequentialization and generation\norder. We introduced three benchmark tasks, which demon-\nstrate that SRMs significantly outperform standard diffusion\nmodels in higher level reasoning tasks. Of particular interest\nis an automatic order prediction based on uncertainty.\nFuture Directions\nWhile we made significant steps for-\nward, our models are still far away from solving the given\ntasks in an optimal fashion. However, we believe that the\npresented paradigm is able to achieve even better results. A\nparticular topic for future research can be more advanced\nstrategies for automatic prediction of generation order. Also,\nwe speculate that backtracking-like strategies that allow to\nincrease noise levels again hold much potential.\nImpact Statement\nThis paper presents fundamental research with the goal\nof advancing reasoning capabilities of generative models.\nThere are many potential societal consequences of advances\nin this direction further down the road, however, none are\nimmediate enough to be specifically highlighted here.\nAcknowledgements\nThis work was partially supported by the Saarland/Intel Joint\nProgram on the Future of Graphics and Media. We thank\nThomas Wimmer for proofreading and helpful discussions.\nReferences\nAgarwal, N., Ali, A., Bala, M., Balaji, Y., Barker, E., Cai,\nT., et al. Cosmos world foundation model platform for\nphysical ai, 2025. URL https://arxiv.org/abs/\n2501.03575.\nBishop, C. M. and Nasrabadi, N. M. Pattern recognition\nand machine learning, volume 4. Springer, 2006.\nChen, B., Monso, D. M., Du, Y., Simchowitz, M., Tedrake,\nR., and Sitzmann, V. Diffusion forcing: Next-token pre-\ndiction meets full-sequence diffusion. In Advances in\nNeural Information Processing Systems, 2024a.\nChen, B., Xu, Z., Kirmani, S., Ichter, B., Sadigh, D., Guibas,\nL., and Xia, F. Spatialvlm: Endowing vision-language\nmodels with spatial reasoning capabilities. In Proceed-\nings of the IEEE/CVF Conference on Computer Vision\nand Pattern Recognition (CVPR), pp. 14455‚Äì14465, June\n2024b.\nChen, L., Li, B., Shen, S., Yang, J., Li, C., Keutzer, K.,\nDarrell, T., and Liu, Z. Large language models are visual\nreasoning coordinators. In Proceedings of the 37th Inter-\nnational Conference on Neural Information Processing\nSystems, NIPS ‚Äô23, Red Hook, NY, USA, 2023. Curran\nAssociates Inc.\nDhariwal, P. and Nichol, A. Diffusion models beat gans\non image synthesis. In Advances in Neural Information\nProcessing Systems, 2021.\nEsser, P., Kulal, S., Blattmann, A., Entezari, R., M¬®uller, J.,\nSaini, H., Levi, Y., Lorenz, D., Sauer, A., Boesel, F., et al.\nScaling rectified flow transformers for high-resolution\nimage synthesis. In International Conference on Machine\nLearning, 2024.\nHo, J., Jain, A., and Abbeel, P. Denoising diffusion prob-\nabilistic models.\nIn Advances in Neural Information\nProcessing Systems, 2020.\nHuang, J. and Chang, K. C.-C. Towards reasoning in large\nlanguage models: A survey. In Rogers, A., Boyd-Graber,\nJ., and Okazaki, N. (eds.), Findings of the Association for\nComputational Linguistics: ACL 2023, pp. 1049‚Äì1065,\nToronto, Canada, July 2023. Association for Computa-\ntional Linguistics.\nKwan, M., Chow, K.-P., Law, F., and Lai, P. Reasoning\nabout evidence using bayesian networks. In Advances\nin Digital Forensics IV, pp. 275‚Äì289, Boston, MA, 2008.\nSpringer US.\nLi, T., Tian, Y., Li, H., Deng, M., and He, K. Autore-\ngressive image generation without vector quantization.\nIn Advances in Neural Information Processing Systems,\n2024.\nLipman, Y., Chen, R. T. Q., Ben-Hamu, H., Nickel, M.,\nand Le, M. Flow matching for generative modeling. In\n9\n\n\nSpatial Reasoning with Denoising Models\nInternational Conference on Learning Representations,\n2023.\nLiu, X., Gong, C., and Liu, Q.\nFlow straight and fast:\nLearning to generate and transfer data with rectified flow.\nIn International Conference on Learning Representations,\n2023.\nNichol, A. Q. and Dhariwal, P. Improved denoising diffusion\nprobabilistic models. In International Conference on\nMachine Learning, 2021.\nPearl, J. Reverend bayes on inference engines: a distributed\nhierarchical approach.\nIn Proceedings of the Second\nAAAI Conference on Artificial Intelligence, AAAI‚Äô82, pp.\n133‚Äì136. AAAI Press, 1982.\nPlaat, A., Wong, A., Verberne, S., Broekens, J., van Stein,\nN., and Back, T. Reasoning with large language models,\na survey, 2024. URL https://arxiv.org/abs/\n2407.11511.\nRadford, A., Narasimhan, K., Salimans, T., and Sutskever,\nI. Improving language understanding by generative pre-\ntraining. 2018.\nRombach, R., Blattmann, A., Lorenz, D., Esser, P., and\nOmmer, B. High-resolution image synthesis with latent\ndiffusion models. In Computer Vision and Pattern Recog-\nnition (CVPR), 2022.\nRuhe, D., Heek, J., Salimans, T., and Hoogeboom, E.\nRolling diffusion models. In International Conference on\nMachine Learning, 2024.\nSeitzer, M., Tavakoli, A., Antic, D., and Martius, G. On\nthe pitfalls of heteroscedastic uncertainty estimation with\nprobabilistic neural networks. In International Confer-\nence on Learning Representations, 2022.\nSong, J., Meng, C., and Ermon, S. Denoising diffusion\nimplicit models. In International Conference on Learning\nRepresentations, 2021.\nSong, Y. and Ermon, S. Generative modeling by estimating\ngradients of the data distribution. In Advances in Neural\nInformation Processing Systems, 2019.\nvan den Oord, A., Vinyals, O., and kavukcuoglu, k. Neural\ndiscrete representation learning. In Guyon, I., Luxburg,\nU. V., Bengio, S., Wallach, H., Fergus, R., Vishwanathan,\nS., and Garnett, R. (eds.), Advances in Neural Information\nProcessing Systems, volume 30, 2017.\nWei, J., Wang, X., Schuurmans, D., Bosma, M., Ichter, B.,\nXia, F., Chi, E. H., Le, Q. V., and Zhou, D. Chain-of-\nthought prompting elicits reasoning in large language\nmodels. In Advances in Neural Information Processing\nSystems, 2022.\nWu, T., Fan, Z., Liu, X., Gong, Y., Shen, Y., Jiao, J., Zheng,\nH.-T., Li, J., Wei, Z., Guo, J., Duan, N., and Chen, W.\nAr-diffusion: Auto-regressive diffusion model for text\ngeneration. In Advances in Neural Information Process-\ning Systems, 2023.\nZhang, Z., Liu, R., Aberman, K., and Hanocka, R. Tedi:\nTemporally-entangled diffusion for long-term motion syn-\nthesis. In SIGGRAPH, Technical Papers, 2024. doi:\n10.1145/3641519.3657515.\n10\n\n\nSpatial Reasoning with Denoising Models\nThe appendix is structured as follows. First, the detailed unified denoising framework is given in Sec. A. Then, graph-based\nsampling strategies are given in Sec. B. It follows a detailed description of the Uniform ¬Øt sampling in Sec. C and dataset\ndescriptions in Sec. D and Sec. E. The appendix concludes with further details about experimental setup in Sec. F. Please\nalso take a look at our project website with, among other things, videos showing Sudoku reasoning over time.\nA. Generation Process\nNotation\nGiven a noise schedule a, b : [0, 1] 7‚Üí[0, 1] for continuous levels of noise t ‚àà[0, 1], we define at := a(t), bt :=\nb(t) for short notation. Furthermore, as we consider a single (possibly higher-dimensional) continuous random variable for\nsimplicity, we write xt for the variable at noise level t instead of using superscript as in the main paper.\nReverse Distribution\nSimilarly to DDIM (Song et al., 2021), we define a family of inference distributions indexed by the\nfunction œÉ : {(t‚àó, t) ‚àà[0, 1]2 | t‚àó< t} 7‚ÜíR‚â•0 with œÉt‚àó,t := œÉ(t‚àó, t) ‚â§bt‚àófor a fixed-sized schedule of continuous noise\nlevels ti ‚àà[0, 1] with 1 ‚â§i ‚â§N, N ‚ààN‚â•2, t1 = 0, tN = 1, and ti‚àí1 < ti:\nqœÉ(x0:1|x0) := qœÉ(x1|x0)\nN\nY\ni=2\nqœÉ(xti‚àí1|xti, x0),\n(7)\nwhere qœÉ(x1|x0) = N(a1x0, b2\n1I) and for all 0 ‚â§ti‚àí1 < ti ‚â§1:\nqœÉ(xti‚àí1|xti, x0) = N\n\u0012\nati‚àí1x0 + xti ‚àíatix0\nbti\nq\nb2\nti‚àí1 ‚àíœÉ2\nti‚àí1,ti, œÉ2\nti‚àí1,tiI\n\u0013\n.\n(8)\nWe show that the choice of the mean ensures the desired marginal distribution qœÉ(xt|x0) = N(atx0, b2\ntI).\nProof. By construction, the statement holds for t = 1. Let 0 ‚â§t‚àó< 1, then we have\nqœÉ(xt|x0) = N(atx0, b2\ntI)\n(9)\nqœÉ(xt‚àó|xt, x0) = N\n\u0012\nat‚àóx0 + xt ‚àíatx0\nbt\nq\nb2\nt‚àó‚àíœÉ2\nt‚àó,t, œÉ2\nt‚àó,tI\n\u0013\n.\n(10)\nFrom (Bishop & Nasrabadi, 2006) (2.115), we have that qœÉ(xt‚àó|x0) is a normal distribution N(¬µ, Œ£) with:\n¬µ = at‚àóx0 + atx0 ‚àíatx0\nbt\nq\nb2\nt‚àó‚àíœÉ2\nt‚àó,t = at‚àóx0\n(11)\nŒ£ = œÉ2\nt‚àó,tI + b2\nt‚àó‚àíœÉ2\nt‚àó,t\nb2\nt\nb2\ntI = b2\nt‚àóI\n(12)\nTherefore, qœÉ(xt|x0) = N(atx0, b2\ntI) holds for all t ‚àà[0, 1].\nVia simple variable substitution œµ = zt‚àíatx0\nbt\nand x0 = zt‚àíbtœµ\nat\n, we obtain the corresponding distributions for alternative\nconditionings:\nqœÉ(xt‚àó|œµ, x0) = N\n\u0010\nat‚àóx0 + œµ\nq\nb2\nt‚àó‚àíœÉ2\nt‚àó,t, œÉ2\nt‚àó,tI\n\u0011\n(13)\nqœÉ(xt‚àó|œµ, xt) = N\n\u0012at‚àóxt\nat\n+ (\nq\nb2\nt‚àó‚àíœÉ2\nt‚àó,t ‚àíat‚àóbt\nat\n)œµ, œÉ2\nt‚àó,tI\n\u0013\n,\n(14)\nwhere we use Eq. 13 as the posterior distribution approximated by minimizing the variational lower bound and Eq. 14 for\nthe following definition of our generative process by replacing the ground truth epsilon with the prediction of the denoising\nneural network\nqŒ∏,œÉ(xt‚àó|, xt) = N\n\u0012at‚àóxt\nat\n+ (\nq\nb2\nt‚àó‚àíœÉ2\nt‚àó,t ‚àíat‚àóbt\nat\n)œµŒ∏(xt), Œ£t‚àó,t\n\u0013\n,\n(15)\nwhere Œ£t‚àó,t can be either fixed as in DDPM (Ho et al., 2020), e.g., to equivalent upper Œ£t‚àó,t =\nbt\nbt‚àóœÉ2\nt‚àó,tI and lower bounds\nŒ£t‚àó,t = œÉ2\nt‚àó,tI depending on q(x0) being isotropic noise or a delta function, or learned by the network as an interpolation\nbetween these two optimized for the VLB, as proposed by (Nichol & Dhariwal, 2021) for DDPM. In all experiments of the\npaper, we choose the last option.\n11\n\n\nSpatial Reasoning with Denoising Models\nChoice of œÉ\nFor the choice of the posterior standard deviation œÉt‚àó,t, we follow DDIM (Song et al., 2021) and consider\nthe following special case. If and only if œÉ(t‚àó, t) = bt‚àó\np\n1 ‚àí(atbt‚àó/(at‚àóbt))2 for 0 ‚â§t‚àó< t ‚â§1, the forward process\nbecomes Markovian, i.e., qœÉ(xt|xt‚àó, x0) = qœÉ(xt|xt‚àó).\nProof. Using the abbreviation œÉ for œÉ(t‚àó, t), we have\nqœÉ(xt|x0) = N(atx0, bt)\n(16)\nqœÉ(xt‚àó|xt, x0) = N\n\u0012\nat‚àóx0 + xt ‚àíatx0\nbt\nq\nb2\nt‚àó‚àíœÉ2, œÉ2I\n\u0013\n(17)\nFrom (Bishop & Nasrabadi, 2006) (2.116), we have qœÉ(xt|xt‚àó, x0) = N(¬µ, Œ£) with:\nŒ£ =\n\u0012 1\nb2\nt\n+ b2\nt‚àó‚àíœÉ(t‚àó, t)2\nb2\nt\n1\nœÉ(t‚àó, t)2\n\u0013‚àí1\nI = b2\ntœÉ(t‚àó, t)2\nb2\nt‚àó\nI\n(18)\n¬µ = b2\ntœÉ2\nb2\nt‚àó\n\"p\nb2\nt‚àó‚àíœÉ2\nbtœÉ2\n\u0012\nxt +\n\u0012at\nbt\nq\nb2\nt‚àó‚àíœÉ2 ‚àíat‚àó\n\u0013\nx0\n\u0013\n+ atx0\nb2\nt\n#\n(19)\nWe can see that ¬µ becomes independent of x0 for the case:\np\nb2\nt‚àó‚àíœÉ2\nbtœÉ2\n\u0012at\nbt\nq\nb2\nt‚àó‚àíœÉ2 ‚àíat‚àó\n\u0013\n+ at\nb2\nt\n= 0\n(20)\n‚áê‚áí\nat\nbtœÉ2 (b2\nt‚àó‚àíœÉ2) ‚àíat‚àó\nœÉ2\nq\nb2\nt‚àó‚àíœÉ2 + at\nbt\n= 0\n(21)\n‚áê‚áíat(b2\nt‚àó‚àíœÉ2) ‚àíat‚àóbt\nq\nb2\nt‚àó‚àíœÉ2 + atœÉ2 = 0\n(22)\n‚áê‚áíatb2\nt‚àó= at‚àóbt\nq\nb2\nt‚àó‚àíœÉ2\n(23)\n‚áê‚áíœÉ = bt‚àó\ns\n1 ‚àí\n\u0012atbt‚àó\nat‚àóbt\n\u00132\n(24)\nWe define œÉŒ∑(t‚àó, t) := Œ∑ ¬∑ bt‚àó\np\n1 ‚àí(atbt‚àó/(at‚àóbt))2 for Œ∑ ‚àà[0, 1] as the variance of the posterior distribution. By setting\nŒ∑ = 0 we obtain deterministic sampling equivalent to DDIM with discrete diffusion noise schedules and equivalent to\nflow-based methods (Lipman et al., 2023) when solving the generative ODE with the Euler method. However, by setting\nŒ∑ = 1 we enable stochastic sampling with general noise schedules (Gaussian probability paths in the context of flow\nmatching), which has not yet been explored up to our best knowledge.\nB. Graph-Sequential sampling\nThe graph-based sampling order is motivated by the idea that the dependency structure between patches can be exploited to\nestimate the level of knowledge about a given patch i based on the noise levels of patches connected to it. By leveraging\nthese dependencies, the sampling process can be guided in a structured and efficient manner, ensuring that patches with\nstronger conditioning from their neighbours are prioritized during denoising.\nThe adjacency matrix is defined as A ‚ààR(N¬∑M)√ó(N¬∑M), where (N, M) are the dimensions of the image patch grid. In the\ncase of Sudoku, this grid is of size (9, 9). The adjacency matrix is a binary mask where all elements of the same row, column,\nor 3 √ó 3 subgrid are connected. Other elements are not connected (represented by a value of 0 in the adjacency matrix).\nWhen selecting the next patch to evaluate, we take arg maxpatch((1 ‚àít) ¬∑ A) ‚äôK, where t ‚àà[0, 1]M¬∑N is the current noise\nlevel vector, and K ‚àà{0, 1} is a mask with 1 for all patches that didn‚Äôt start denoising process and 0 otherwise. So we\npropagate 1 ‚àít (denoising level) through the graph, and select a patch that has the noise level ti = 1, but has the strongest\nconditioning from its predecessors.\n12\n\n\nSpatial Reasoning with Denoising Models\nB.1. Drawbacks\nThe certainty obtained using this algorithm is solely noise-level based. It cannot distinguish whether a patch is being\nconditioned by the same number across its row, column, and subgrid (weak conditioning) or by three different numbers\n(strong conditioning). As a result, the model with predicted uncertainty (as described in Sec. 3.2.2) can surpass the\nperformance of the graph-based approach (Tab. 1).\nC. Uniform ¬Øt sampling\nFor better intuition of why Uniform ¬Øt should be one of our goals, we show the distributions of individual ti and ¬Øt in Fig. 9.\n(a) Parallel\n(b) Autoregressive\nFigure 9: The distributions of individual patch noise level ti and mean over the image ¬Øt in parallel sampling (left) and\nautoregressive generation (right). In a parallel generation, all patches have the same noise level throughout inference, so\nboth ti and ¬Øt marginal distributions are uniform. Autoregressive generation‚Äôs ti distribution is very dense around 0 and 1, as\nduring inference only one patch can have value other than 0 or 1 ‚Äì the one currently generated. It‚Äôs important, that regardless\nof which inference strategy we choose, the distribution of ¬Øt remains uniform.\nC.1. Recursive allocation sampling t ‚àºp(t | ¬Øt)\nTo sample t ‚àºp(t | ¬Øt), where t ‚àà[0, 1]d, we generate a vector with a specified mean ¬Øt by a recursive sum allocation\nalgorithm. The key idea is to define the total sum of the sampled vector as s = d ¬∑ ¬Øt, then recursively partition s into two\nsum contributions from the first and second halves of the vector. This process is illustrated in Algorithm 1.\nAlgorithm 1 Recursive Sampling of a sum constrained Vector\nRequire: s (total sum), d (vector dimension)\nEnsure: A vector x ‚àà[0, 1]d such that P xi = s\n1: Function GetSumConstrainedVector(S, d)\n2: if d = 1 then\n3:\noutput [S] {End of recursion for 1 element}\n4: end if\n5: d1 ‚Üê‚åäd/2‚åã{Get Split dimension}\n6: d2 ‚Üêd ‚àíd1\n7: smax\n1\n‚Üêmin(s, d1) {Define upper bounds of the contributions}\n8: smax\n2\n‚Üêmin(s, d2)\n9: smin\n1\n‚Üêmax(0, s ‚àísmax\n2\n) {Define lower bound}\n10: Sample r ‚àºpsplit(r|d), where r ‚àà[0, 1] {Sample a split point}\n11: s1 ‚Üêsmin\n1\n+ (smax\n1\n‚àísmin\n1\n) ¬∑ r\n12: s2 ‚Üês ‚àís1\n13: output GetSumConstrainedVector(s1, d1) ‚à™GetSumConstrainedVector(s2, d2)\nThe algorithm first determines the range of possible contributions from the first half of the vector, (smin\n1\n, smax\n1\n). Then it\nsamples a split point from a distribution psplit(r|d), which has support on [0, 1]. The sampled value is then scaled to the\nappropriate range of split points.\n13\n\n\nSpatial Reasoning with Denoising Models\nThe split distribution psplit(d) is modelled as a symmetrical case of a Beta distribution, empirically tuned to match the\nnatural mid-point splitting behaviour of independently sampled uniform noise vectors. Explicitly,\npsplit(r|d) = Beta(r|Œ±, Œ≤),\n(25)\nwhere\nŒ± = Œ≤ = (d ‚àí1 ‚àí(d mod 2))1.05 ¬∑ sharpness.\n(26)\nIn a uniformly sampled vector t ‚àºU([0, 1]n) as the number of patches d increases, extreme split points become less likely.\nFor example with 100 patches and ¬Øt = 0.5 s1 could be between 0 and 50 but it is highly unlikely that all patches in the\nfirst half of the vector will be ones and all in the second half will be zeros. Instead, s1 is most likely to be close to 25.\nThat is why the split point distribution gets more center-heavy with higher vector dimensionality d ‚Äì we model this by\nincreasing the Œ± and Œ≤ parameters for higher d as in Eq. 26. For sharpness = 1 and ¬Øt = 0.5 the distribution of t ‚àà[0, 1]n\nclosely resembles U([0, 1]n) regardless of n. Higher sharpness results in distributions more tightly centred around ¬Øt, while\nsharpness ‚àà(0, 1) leads to oversampling values closer to 0 and 1. The effect of the sharpness parameter on the distribution\nis illustrated in Fig. 10. Its influence on the Even Pixels dataset is presented in Tab. 7.\nFigure 10: Distributions of ti noise level values given different sharpness (x-axis) and mean noise level ¬Øt.\nThe advantage of this algorithm over, for example, iterative perturbation methods is that it can be easily parallelized across\nthe batch dimension, ensuring efficient utilization of computational resources. Additionally, it exhibits stable execution time,\na crucial property for maintaining predictable and consistent performance in the training pipeline.\n14\n\n\nSpatial Reasoning with Denoising Models\nD. Even Pixels Evaluation\nFor evaluation, we generate a hue histogram from the model‚Äôs output and identify the peak hue hmax. We then count the\nnumber of pixels closer to hmax than to its complementary hue h‚àó\nmax = (hmax + 180‚ó¶) mod 360‚ó¶. The error is computed\nas the absolute difference between this count and half the total number of pixels\nerror =\n\f\f\f\f#(pixels closer to hmax than h‚àó\nmax) ‚àíwidth ¬∑ height\n2\n\f\f\f\f\nThe accuracy indicates in which fraction of samples where the pixel hue counts equal (error = 0).\nE. Counting Polygons Dataset\nE.1. objects color selection\nThe color of the numbers and polygons is chosen in HSV space hsv(c, 1.0, 0.9), where\nc = arg min\nh {(histogram(Himg) ‚àóGœÉ) (h)}\nand GœÉ is a Gaussian kernel with a small œÉ. In other words, we search for the hue with the lowest count in the smoothed hue\nhistogram of an image. We found this method as an intuitive approach to increase the visibility of the objects on the FFHQ\nbackground.\nE.2. Evaluation\nTo assess the generative model‚Äôs ability to learn the implicit counting constraint, we employ a ResNet-50-based classifier\nwith three independent prediction heads:\n‚Ä¢ Predicting the set of two numbers (N, K) present in the image.\n‚Ä¢ Predicting the number of polygons.\n‚Ä¢ Predicting the number of vertices per polygon.\nThe classifier is trained on a dataset with similar image compositions but without enforcing any consistency between the\nnumbers and the actual object counts. For evaluation, the classifier detects the numbers present in the generated image\nand compares them to the true polygon and vertex counts. A generated image is classified as correct if the set of extracted\nnumbers is the same as the set of actual polygon and vertex counts (regardless of order): correct ‚áî{num1, num2} =\n{#polygons, #vertices}. The evaluation metric accuracy is computed as the fraction of images on which this number-object\ncorrespondence is correct.\nF. Implementation Details\nFor reasoning in the spatial visual domain, we divide images into patches of a fixed size. While we use the size of a cell, i.e.,\nMNIST example 28 √ó 28 as the patch size for the MNIST Sudoku dataset with image resolution 252 √ó 252, we choose\npatch sizes of 4 √ó 4 and 8 √ó 8 for the even pixel and counting polygons datasets with resolutions 32 √ó 32 and 128 √ó 128,\nrespectively.\nAlthough SRMs are agnostic w.r.t. the architecture choice, we choose simple 2D UNets for all experiments, as they are\nwidely established for image generation. We provide all architecture and training hyperparameters in Tab. 5.\nFor training the SRMs with individual noise levels per patch and the estimation of its uncertainty in the noise prediction,\nwe additionally apply to simple architecture modifications. Instead of conditioning the UNet on a single encoding of the\nnoise level t, we compute a map with per-pixel noise levels, where all pixels within a patch share the same t. This map is\nbilinearly interpolated to the spatial resolution of the feature maps in each layer, encoded using a shared MLP, and finally\nused to compute scale and shift maps applied pixel-wise to the features. While this modification is specific to UNets, similar\nadjustments can be made for other architectures like transformers, which already consider patches as tokens in the vision\n15\n\n\nSpatial Reasoning with Denoising Models\nMNIST Sudoku\nEven Pixels\nCounting Polygons FFHQ\nChannels\n128\n64\n128\nDepth\n2\n2\n2\nChannel multipliers\n1, 1, 2, 2, 4, 4\n1, 2, 2, 4\n1, 1, 2, 2, 4\nHead channels\n64\n64\n64\nAttention resolution\n16, 8\n8, 4\n16, 8\nParameters\n118M\n19.7M\n76.8M\nEffective batch size\n56\n2048\n56\nIterations\n250k\n100k\n250k\nLearning Rate\n1e-4\n8e-4\n1e-4\nTable 5: Hyperparameters used for all experiments.\nDeterministic\nStochastic\nSampling\nL1‚Üì\nAcc‚Üë\nL1‚Üì\nAcc‚Üë\nParallel\n26.288\n0.004\n19.156\n0.010\nPredicted Order w/o Overlap\n3.652\n0.500\n3.212\n0.516\nPredicted Order + Overlap\n4.192\n0.420\n4.340\n0.422\nGraph-based Order w/o Overlap\n6.212\n0.240\n5.816\n0.266\nGraph-based Order + Overlap\n6.652\n0.188\n6.036\n0.238\nTable 6: Ablation over Deterministic vs. Stochastic Sampling on MNIST Sudoku hard. Stochastic sampling almost\nconsistently outperforms deterministic sampling, highlighting the benefits of our generative process combining arbitrary\n(non-diffusion) noise schedules with stochastic sampling.\nSharpness\n0.50\n0.75\n1.00\nSampling\n#E‚Üì\nAcc‚Üë\n#E‚Üì\nAcc‚Üë\n#E‚Üì\nAcc‚Üë\nParallel\n3.580\n0.096\n5.184\n0.054\n4.076\n0.074\nPredicted Order + Overlap\n0.840\n0.368\n0.534\n0.518\n0.590\n0.484\nRandom Order + Overlap\n0.776\n0.342\n0.584\n0.476\n0.656\n0.430\nTable 7: Sharpness Ablation on Even Pixels. By lowering the sharpness hyperparameter of our noise level sampling\nalgorithm, we can train SRMs to be more tailored towards sequential sampling methods.\ndomain. In order to predict a single uncertainty per patch, our denoising network outputs an additional one-dimensional\nfeature map, on which we apply 2D average pooling with the kernel size and stride corresponding to the patch size of our\nspatial variables. The result is interpreted as log-variance of the predicted noise.\nG. Additional Ablations\nWe provide additional ablation studies considering hyperparameter choices for our experiments. Tab. 6 compares the\nperformance of deterministic and stochastic sampling on the hard difficulty of the MNIST Sudoku dataset by setting either\nŒ∑ = 0 or Œ∑ = 1 in the generation process described in Sec. A. We can see that stochastic sampling is favorable for spatial\nreasoning, which we enable in combination with arbitrary noise schedules.\nIn Tab. 7, we ablate the choice of the sharpness hyperparameter in our noise level sampling algorithm for training SRMs. On\nthe Even Pixels dataset, we can oversample noise level combinations for spatial variables that are more likely in sequential\nsampling strategies by lowering the sharpness. This can result in additional performance boosts depending on the data\ndistribution.\n16\n\n\n",
  "metadata": {
    "source_file": "dataset/pdfs/arxiv_2502.21075v1.pdf",
    "total_pages": 16,
    "title": "Spatial Reasoning with Denoising Models",
    "authors": [
      "Christopher Wewer",
      "Bart Pogodzinski",
      "Bernt Schiele",
      "Jan Eric Lenssen"
    ],
    "abstract": "We introduce Spatial Reasoning Models (SRMs), a framework to perform\nreasoning over sets of continuous variables via denoising generative models.\nSRMs infer continuous representations on a set of unobserved variables, given\nobservations on observed variables. Current generative models on spatial\ndomains, such as diffusion and flow matching models, often collapse to\nhallucination in case of complex distributions. To measure this, we introduce a\nset of benchmark tasks that test the quality of complex reasoning in generative\nmodels and can quantify hallucination. The SRM framework allows to report key\nfindings about importance of sequentialization in generation, the associated\norder, as well as the sampling strategies during training. It demonstrates, for\nthe first time, that order of generation can successfully be predicted by the\ndenoising network itself. Using these findings, we can increase the accuracy of\nspecific reasoning tasks from <1% to >50%.",
    "published_date": "2025-02-28",
    "source": "arxiv"
  }
}