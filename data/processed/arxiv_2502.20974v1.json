{
  "id": "arxiv_2502.20974v1",
  "text": "Improving Open-world Continual Learning under the\nConstraints of Scarce Labeled Data\nYujie Li1,2, Xiangkun Wang1, Xin Yangâˆ—1, Marcello Bonsangue2, Junbo Zhang3, Tianrui Li4\n1School of Computer and Artificial Intelligence, Southwestern University of Finance and Economics, China\n2The Leiden Institute of Advanced Computer Science, Leiden University, Netherlands\n3JD Intelligent Cities Research, China\n4School of Computing and Artificial Intelligence, Southwest Jiaotong University, China\n{liyj1201, xiangkunwang18}@gmail.com, yangxin@swufe.edu.cn, m.m.bonsangue@liacs.leidenuniv.nl,\nmsjunbozhang@outlook.com, trli@swjtu.edu.cn\nTask 1\nBase Task\nClass 3\nTask n\nClass i\n. . .\n. . .\nClass 1\nClass 2\n    is [class 1],      is [class 2], . . .,\n and now I can tell       is [class i],\nbut I can't tell what is      .\n    is [class 1],      is [class 2], . . .,\n     is [class 2] and      is [class 3].\n    is [class 1],      is [class 2],\n    is [class 3], but I can't tell what is       . \n    is [class 1],      is [class 2],\n     is [class 1], and        is [class 2].\n. . .\n. . .\n(w/ large labeled data)\nFigure 1: The illustration of open-world continual learning with few-shot data (OFCL) framework. As new tasks (Task 1, ..., Task ğ‘›,\netc.) are introduced with new classes (Class 3, ..., Class ğ‘–, etc.) in few-shot labeled examples, unknown samples may appear during\ntesting and the learner struggles with severer forgetting and overfitting. Hence, the OFCL requires the agent to detect open samples in\ntesting and learn new categories from scarce labeled data over time.\nABSTRACT\nOpen-world continual learning (OWCL) adapts to sequential tasks\nwith open samples, learning knowledge incrementally while pre-\nventing forgetting. However, existing OWCL still requires a large\namount of labeled data for training, which is often impractical in real-\nworld applications. Given that new categories/entities typically come\nwith limited annotations and are in small quantities, a more realistic\nsituation is OWCL with scarce labeled data, i.e., few-shot training\nsamples. Hence, this paper investigates the problem of open-world\nfew-shot continual learning (OFCL), challenging in (i) learning un-\nbounded tasks without forgetting previous knowledge and avoiding\noverfitting, (ii) constructing compact decision boundaries for open\ndetection with limited labeled data, and (iii) transferring knowledge\nabout knowns and unknowns and even update the unknowns to\nknowns once the labels of open samples are learned. In response, we\npropose a novel OFCL framework that integrates three key compo-\nnents: (1) an instance-wise token augmentation (ITA) that represents\nand enriches sample representations with additional knowledge, (2)\na margin-based open boundary (MOB) that supports open detection\nwith new tasks emerge over time, and (3) an adaptive knowledge\nâˆ—Corresponding author.\nspace (AKS) that endows unknowns with knowledge for the updat-\ning from unknowns to knowns. Finally, extensive experiments show\nthe proposed OFCL framework outperforms all baselines remarkably\nwith practical importance and reproducibility. The source code is\nreleased at https://github.com/liyj1201/OFCL.\nKEYWORDS\nOpen-world Continual Learning, Knowledge Transfer, Continual\nLearning, Scarce Labeled Data, Data Mining\n1\nINTRODUCTION\nRecently, open-world continual learning (OWCL) [15, 21] is an\nemerging machine learning paradigm where a model continuously\nlearns from a sequence of tasks/data in an open environment where\nunseen classes may emerge during tests over time. Unlike tradi-\ntional continual learning (CL) that operates in a closed and fixed set\nof classes (i.e., the closed-world assumption), OWCL requires the\nmodel to not only learn new knowledge and update knowledge incre-\nmentally but also to recognize and adapt to open, previously unseen\nclasses without forgetting [5]. Therefore, OWCL provides a more\ncomprehensive formulation of real-world scenarios by involving the\narXiv:2502.20974v1  [cs.LG]  28 Feb 2025\n\n\nLi and Wang, et al.\npresence of open classes during tests, making it more suitable for\nmanaging the complexities of open data content [19, 21].\nDespite the increasing attention towards OWCL research, existing\nstudies [14, 16] face a major limitation due to their reliance on large\namounts of training data for learning each new task. This requirement\nfor abundant training samples, however, often contradicts the nature\nof the open and dynamic data, where practical applications usually\nencounter new tasks (or classes) with scarce labeled data or few-shot\ntraining samples [2, 38]. For instance, on social media platforms,\nuser-uploaded images (e.g., user-generated photos or social media\nposts) often feature novel objects or scenes that lack corresponding\nlabeled data. Unfortunately, obtaining sufficient manual and ground-\ntruth labels for training each new task or class is often impractical.\nHence, current OWCL models must be extended to operate with\nscarce labeled examples.\nTherefore, motivated by the demands of real-world applications,\nwe investigate the problem of OWCL under the restrictions of scarce\nlabeled data, i.e., Open-world Few-shot Continual Learning (OFCL).\nAs depicted in Figure 1, the scarce labeled data exacerbates the issues\nof misclassifying open samples into seen classes and catastrophic\nforgetting (CF) due to insufficient knowledge representation. Ac-\ncordingly, OFCL faces the following two key challenges: (1) Open\nDetection: The few-shot training/labeled data in OWCL increases\nthe difficulty of establishing robust boundaries for open detection.\n(2) Knowledge Transfer: Given the scarce labeled data, the learner\nnot only needs to transfer knowledge by incrementally acquiring new\nknowledge without CF but also be able to update the knowledge of\nopen samples to known classes once the labels of open samples are\nlearned. Therefore, to address these challenges, we propose a novel\nframework, termed OFCL, designed to tackle open-world continual\nlearning with scarce labeled data.\nSpecifically, we first propose an instance-wise token augmenta-\ntion (ITA) aimed at acquiring additional â€˜knowledgeâ€™ to mitigate the\ninadequate representation caused by scarce labeled data. Moreover,\nITA can facilitate knowledge transfer by matching learnable tokens\nto each sample embedding. Additionally, given the scarce labeled\ndata where certain exemplar points (hubs) appear among the nearest\nneighbors of many other points, test samples will be assigned to\nit regardless of their true label, resulting in low accuracy [10]. To\nmitigate this, inspired by the embedding representations on a hyper-\nsphere [30], we introduce a novel and compact margin-based open\nboundary (MOB) and an adaptive knowledge space (AKS) consisting\nof learnable hyperspheres, where each hypersphere is characterized\nby a class centroid and an associated radius. In particular, enables\nthe formulation of compact decision boundaries between known and\nunknown samples, thereby enhancing open detection. Simultane-\nously, the AKS encourages the model to learn incrementally from\nunknowns and classify previously encountered unknown samples\nin new tasks, effectively transforming unknowns into knowns over\ntime. Extensive experimental results demonstrate that the proposed\nnovel OFCL framework significantly surpasses all baseline methods,\nhighlighting its practical significance and reproducibility.\nIn summary, our contributions can be outlined as follows:\nâ€¢ Driven by practical applications, this paper formulates the\nproblem of open-world continual learning with scarce la-\nbeled data and tries to address the challenges of open de-\ntection and knowledge transfer with limited ground-truth\ndata.\nâ€¢ Technically, we introduce instance-wise token augmenta-\ntions (ITA) for enhancing the semantic information of em-\nbeddings and mitigating forgetting. Subsequently, we pro-\npose a margin-based open boundary (MOB) and an adaptive\nknowledge space (AKS) to incorporate knowledge learned\nfrom knowns and unknowns, fostering knowledge transfer,\naccumulation, and even updating the unknowns.\nâ€¢ Extensive comparisons with competitive OWCL approaches,\nfew-shot incremental learning methods and open detec-\ntion baselines demonstrate the superior performance of our\nOFCL framework. Additional studies also show the effec-\ntiveness and robustness of the proposed OFCL framework.\n2\nRELATED WORK\n2.1\nOpen-world Continual Learning (OWCL)\nIn contrast to the closed-world assumption, open-world continual\nlearning aims to reject examples from unseen classes (not appearing\nin training) and incrementally learn the open/unseen classes [5, 14],\nsimilar to learning in the real world that is full of unknowns or novel\nobjects [20, 21]. The innovative framework SOLA [21] enables AI\nagents to learn and adapt by themselves via their interactions with\nhumans and the open environment. PointCLIP [45] combines CLIP\nand GPT-3 to enable zero-shot classification, segmentation, and\nopen-set detection. Zhao et al. [42] introduce an Open World Object\nDetection (OWOD) framework containing an auxiliary proposal ad-\nvisor and a Class-specific Expelling Classifier (CEC). [16] proposes\nto integrate out-of-distribution detection with continual learning for\nopen-world continual learning.\nHowever, as mentioned in section 1, more and more real-world\nscenarios pose a greater challenge due to the limitation of extremely\nscarce training/labeled samples. Consequently, addressing open-\nworld learning in scarce labeled data becomes not only highly prac-\ntical but also increasingly challenging.\nCL Baselines\nOpen-world Assumption\nFew-shot Data\nTOPIC [29]\nâœ—\nâœ“\nALICE [24]\nâœ—\nâœ“\nSoftNet [38]\nâœ—\nâœ“\nSOLA [21]\nâœ“\nâœ—\nCEC [42]\nâœ“\nâœ—\nPro-KT [19]\nâœ“\nâœ—\nFeSSSS [3]\nâœ“\nâœ“\nTable 1: Competitive CL Baselines (selected) under Open-World\nAssumption and Few-Shot Data Constraints.\n\n\nImproving Open-world Continual Learning under the Constraints of Scarce Labeled Data\n2.2\nFew-shot Learning\nFew-shot learning [24, 29, 43] aims to learn new tasks with limited\ntraining data while avoiding the loss of previously learned informa-\ntion. TOPIC [29] introduces the few-shot learning with continual\nlearning benchmark setup and proposes a neural gas structure to\nbalance between the past and the current tasks. SvF [41] employs\nfrequency-aware regularization and feature space composition for\na balanced approach. CEC [40] decoupled feature extraction and\nclassification through a pre-trained backbone and a non-parametric\nclass mean classifier. SoftNet [38] utilizes a partial-frozen strategy,\nselectively masking a sub-network from a pre-trained network to\nprevent forgetting.\nWhile current methods yield satisfactory results, they remain\nrooted in the closed-world assumption, lacking the capability to iden-\ntify and address open/unknown samples during test phases [18, 39].\nFurthermore, there is a lack of methods for constructing a compre-\nhensive knowledge space that facilitates knowledge accumulation,\ntransfer, and updating throughout the incremental learning process.\nHence, given the open-world assumption, existing methods suffer\neven more from overfitting and CF, often leading to misinterpretation\nor revision of incorrect knowledge.\nMore recently (as shown in Table 1), [3, 8] tried to rethink ex-\nisting few-shot incremental learning under the open-set hypothesis.\nFeSSSS [2, 3] extended a variable-few-shot learning model to the\nopen world, detecting unknown samples by a simple Softmax thresh-\nolding approach (MSP [12]). Hyper-RPL [8] utilized the hyperbolic\nreciprocal point learning into a distillation-based framework to alle-\nviate the overfitting and forgetting. However, although both works\nmade attempts, they merely combined existing few-shot incremental\nlearning with simple open-set recognition methods, overlooking the\nchallenges posed by scarce labeled data in OWCL and facing signif-\nicant limitations in constructing compact open-set boundaries and\nadapting to dynamic environments.\n3\nMETHODOLOGY\nIn this section, we begin by formulating the OFCL problem. Then,\nwe detail the instance-wise token augmentation (ITA) for knowledge\ntransfer and present margin-based open boundary (MOB). Lastly, we\nintroduce an adaptive knowledge base (AKB) designed to represent\nknowledge from unknowns and to facilitate updating unknowns into\nknowns in a hypersphere-based embedding space.\nRemarks. Different from existing works, this paper addresses the\nlimitations of OWCL by focusing on a more practical and challeng-\ning few-shot learning scenario, introducing an innovative concept\nof OFCL. By integrating previous prompt-based learning strategies,\nour model can effectively adapt to limited labeled samples by ITA.\nMoreover, MOB leverages hyperspherical embeddings to construct\nmargin-based boundaries adaptively, ensuring compact and robust\nrepresentations for open detection. AKS, on the other hand, pio-\nneers an adaptive way to knowledge accumulation, transfer and re-\nplay, facilitating efficient knowledge utilization for both known and\nunknown samples, overcoming the limitations in previous OWCL\nmethods (e.g., logits-based thresholds in Pro-KT [19]).\n3.1\nProblem Statement\nOur investigated problem, Open-world few-shot continual learning\n(OFCL), aims to incrementally learn within an open-world assump-\ntion where unseen or open samples may appear in the test phase, and\ngeneralize well on new tasks with scarce labeled training data. It is\nimportant to note that we assume only the base task to have ample\ntraining samples (as shown in Figure 1), while each subsequent new\ntask (ğ‘¡> 0) only involves scarce labeled training samples.\nProblem Definition. Given tasks {1, ...,ğ‘¡, ...}, each training set\ncan be organized as ğ‘-way ğ¾-shot format ğ·ğ‘¡\nğ‘¡ğ‘Ÿ= {(ğ‘¥ğ‘¡,ğ¶) | ğ‘¥ğ‘¡âˆˆ\nğ‘‹ğ‘¡\nğ‘¡ğ‘Ÿ(ğ¶),ğ¶âˆˆğ¶ğ¿ğ‘†ğ‘¡\nğ‘¡ğ‘Ÿ}, where ğ‘‹ğ‘¡\nğ‘¡ğ‘Ÿ(ğ¶) is a set of ğ¾-samples of the class\nğ¶, ğ¶ğ¿ğ‘†ğ‘¡\nğ‘¡ğ‘Ÿis the set of ğ‘classes in the current task ğ‘¡. Similarly, the\ntest set of task ğ‘¡can be defined as ğ·ğ‘¡\nğ‘¡ğ‘’= {(ğ‘¥ğ‘¡,ğ¶) | ğ‘¥ğ‘¡âˆˆğ‘‹ğ‘¡\nğ‘¡ğ‘’(ğ¶),ğ¶âˆˆ\nğ¶ğ¿ğ‘†ğ‘¡\nğ‘¡ğ‘’}. Here, due to the open-world assumption, we do not assume\nany â€˜relationsâ€™ between the classes in the test set and the training set.\nSpecifically, some test samples may be unknown/open, i.e. belong-\ning to the set (ğ¶ğ¿ğ‘†ğ‘¡\nğ‘¡ğ‘’âˆ’ğ¶ğ¿ğ‘†ğ‘¡\nğ‘¡ğ‘Ÿ). In testing, we evaluate on all the test\nsamples ğ·1\nğ‘¡ğ‘’âˆª... âˆªğ·ğ‘¡\nğ‘¡ğ‘’continually. Hence, the purpose of OFCL is\nto develop a unified classifier ğ‘“ğœƒwith parameter ğœƒthat (1) detects un-\nknown/open samples, (2) classifies known samples correctly, and (3)\nsupports the transforming of unknowns into knowns incrementally.\n3.2\nInstance-wise Token Augmentation (ITA)\nInspired by the strong few-shot learning ability of prompt tuning [25,\n35, 36] methods, we propose a knowledge augmentation paradigm\nfor OFCL, referred to as Instance-wise Token Augmentation (ITA).\nNotably, ITA can facilitate the representation, accumulation, and\ntransfer of knowledge across various tasks to improve the knowledge\ntransfer.\nGiven a task ğ‘¡with its training set ğ·ğ‘¡\nğ‘¡ğ‘Ÿ, the learner first initializes\na batch of random tokens pğ‘¡as:\npğ‘¡= (ğ‘ğ‘¡\n1, ..., ğ‘ğ‘¡\nğ‘–, ..., ğ‘ğ‘¡\nğ‘™), with ğ‘ğ‘¡\nğ‘–âˆˆRğ¿ğ‘Ã—ğ·ğ‘’.\n(1)\nwhere ğ‘™is the number of additional tokens, ğ¿ğ‘ƒis the token length\nand ğ·ğ‘’is the embedding dimension. During the training of task\nğ‘¡, we maintain a token frequency set ğœˆğ‘¡= (ğœˆ1, ...,ğœˆğ‘˜, ...), where ğœˆğ‘˜\nrepresents the frequency of each ğ‘ğ‘¡\nğ‘˜is selected to be appended into\nsample embeddings.\nHence, the essence of ITA lies in identifying and matching impor-\ntant tokens for sample augmentations. Here, we design an instance-\nwise mechanism to select useful additional tokens by looking up the\ntop-ğ¾keys:\n(kâˆ—, pâˆ—) = argmin\nğ¾\nğ‘™âˆ‘ï¸\nğ‘–=1\nğ‘ ğ‘–ğ‘š(hğ‘¡,ğ‘˜ğ‘¡\nğ‘–) Â· ğœˆğ‘–, with hğ‘¡= Q(ğ‘¥ğ‘¡),\n(2)\nwhere ğ‘˜ğ‘¡\nğ‘–is the key associated with token ğ‘ğ‘¡\nğ‘–, the ğ‘ ğ‘–ğ‘š(Â·, Â·) is a cosine\nsimilarity function and the Q is a query function encoding an input\nğ‘¥ğ‘¡to the same dimension as the keys. Next, the input embedding hğ‘¡\nis augmented by the above subset pâˆ—âŠ‚pt:\nhâ€²ğ‘¡= hğ‘¡âŠ•pâˆ—,\n(3)\nwhere âŠ•denotes a dimension-wise concatenation.\nSubsequently, the improved loss function can be formulated as:\nLğ‘ğ‘¢ğ‘”= L(ğ‘“ğœƒ(ğ‘“ğ‘ğ‘Ÿ(hâ€²ğ‘¡), yğ‘¡) + ğœ†Â·\nğ‘™âˆ‘ï¸\nğ‘–=1\nğ‘ ğ‘–ğ‘š(hğ‘¡,ğ‘˜ğ‘¡\nğ‘–),\n(4)\n\n\nLi and Wang, et al.\n...\n...\nTask t\nITA (Sec. 3.2)\nCNN\n...\n...\n...\nBase Task\nTask 1\n Transformer\n...\n...\n...\nRepresentation\nAugmented Token\nQuery Token\n...\nQuery\nLoss\nCE\nLoss\nFew-shot labeled training samples\nmargin\nPrototype-based Loss\nMOB (Sec. 3.3)\nMoB\nLoss\nR\nOurs\nR\nless positive samples, more negative samples:\n...\nR\nR\nHyperspheres Pool\nR\n...\n...\n...\nAugmented\nAKS (Sec. 3.4)\n...\n...\nOpen Internet test samples\n...\nunknown\nknown\nOutput\nFigure 2: The overall OFCL framework consists of three key components: (1) ITA (Yellow): enhancing the samples by matching them\nwith appropriate additional tokens; (2) MOB (Purple): constructing compact decision boundaries of knowns by margin-based loss\nfunction for open detection; (3) AKS (Red): incorporating knowledge learned from both knowns and unknowns, and facilitating the\ntransition from unknowns to knowns.\nwhere hğ‘¡is the set of training samples projected embeddings, yğ‘¡are\nthe training labels, ğœ†is a trade-off parameter, ğ‘“ğ‘ğ‘Ÿis the pre-trained\nbackbone. The first addend is the classification loss, and the second\none is a surrogate loss to pull selected keys closer to corresponding\nquery features.\nDifferent from previous prompt-based CL methods, our proposed\nITA stores the tokens learned from each task into a unified token\nbank (K, P), treating them as knowledge to avoid forgetting. During\ntesting, the model selects appropriate tokens from the token bank\n(K, P) for each test sample. Hence, the proposed ITA not only en-\nables the model to leverage prior knowledge but also mitigates the\nissue of overfitting with scarce labeled samples.\n3.3\nMargin-based Open Boundary (MOB)\nBy leveraging the augmented training samples, we facilitate the\nformation of more precise and compact decision boundaries for open\nsample detection. In contrast to existing approaches, our strategy\ngoes beyond simply merging current continual learning techniques\nwith open-set recognition.\nThus, we introduce the MOB in a hypersphere space to construct\ncompact boundaries from known samples or training classes, thereby\nnaturally improving the open detection for OFCL. Hyperspheres out-\nperform Euclidean distance in open-set recognition by reducing the\nhubness problem [30], where certain points disproportionately dom-\ninate nearest-neighbor lists, leading to misclassifications. In OFCL,\nwhere new, unseen classes may appear, the ability of hyperspherical\nembeddings to adapt is critical. These embeddings can continuously\nevolve as new data points are added, unlike Euclidean embeddings\nwhich can become skewed by hubs. Hyperspherical embeddings\nmaintain robustness in dynamic, low-sample environments, improv-\ning their suitability for open-set recognition.\nGiven a class ğ¶âˆˆğ¶ğ¿ğ‘†ğ‘¡\nğ‘¡ğ‘Ÿ, we divide all samples into a positive set\nx+ = {ğ‘¥ğ‘¡|(ğ‘¥ğ‘¡,ğ¶) âˆˆğ·ğ‘¡\nğ‘¡ğ‘Ÿ} containing all sample of the class ğ¶at task\nğ‘¡, and a negative set xâˆ’= {ğ‘¥ğ‘¡|(ğ‘¥ğ‘¡,ğ¶â€²) âˆˆğ·ğ‘¡\nğ‘¡ğ‘Ÿ,ğ¶â€² â‰ ğ¶} containing\nall other samples of the same task. Our intuition here comes from\ncontrastive learning, where training samples belonging to ğ¶serve\nas positive samples, while all other training samples are treated as\nnegative instances (in Figure 2). Hence, the MOB loss function\nLğ‘šğ‘ğ‘Ÿğ‘”ğ‘–ğ‘›for constructing decision boundaries of knowns can be\nformulated as:\nLğ‘šğ‘ğ‘Ÿğ‘”ğ‘–ğ‘›= 1\nğ‘Â·\nâˆ‘ï¸\nğ¶âˆˆğ¶ğ¿ğ‘†ğ‘¡ğ‘Ÿ\n(ğœ†Â· ğ‘Ÿ2\nğ¶\n+ 1\nğ›¼Â· ğ‘™ğ‘œğ‘”[1 +\nâˆ‘ï¸\nğ‘¥âˆˆx+\nğ‘’ğ›¼Â·(ğ‘‘ğ‘–ğ‘ (cğ¶,ğ‘“ğ‘ğ‘Ÿ(ğ‘¥))âˆ’ğ‘Ÿğ¶)]\n+ 1\nğ›½Â· ğ‘™ğ‘œğ‘”[1 +\nâˆ‘ï¸\nğ‘¥âˆˆxâˆ’\nğ‘’âˆ’ğ›½Â·(ğ‘‘ğ‘–ğ‘ (cğ¶,ğ‘“ğ‘ğ‘Ÿ(ğ‘¥))âˆ’(ğ‘Ÿğ¶+ğ‘š))]),\n(5)\nwhere ğ‘is the number of classes in the training set and ğ‘šis the\nmargin, ğ‘Ÿğ¶denotes the hypersphere radius of class ğ¶around the\ncentroid cğ¶that we discuss below, ğ‘‘ğ‘–ğ‘ (Â·, Â·) is a distance function,\nğœ†is a constant that balances the trade-off between the regulation\nof radius and margin loss item, and ğ›¼and ğ›½are scaling factors for\npositive and negative sets, respectively. Note that the pre-trained\nbackbone function ğ‘“ğ‘ğ‘Ÿhere takes as input a sample instead of the\nembedding of an input as in Equation 4.\n\n\nImproving Open-world Continual Learning under the Constraints of Scarce Labeled Data\nSpecifically, we employ three key components in the MOB:\n(1) known classes centroids: learning a centroid as the center of\na hypersphere for each known class; (2) margin and radius: enforc-\ning a margin between different classes while automatically learning\na radius for each class; (3) open boundary: identifying unknowns re-\nlying on the establishment of compact boundaries for known classes.\nKnown Classes Centroids. Hyperspherical embeddings distrib-\nute data more uniformly, avoiding central clustering, and methods\nlike noHub [30] preserve class structure while maintaining unifor-\nmity. This balance allows hyperspheres to continuously adapt in\ndynamic, low-sample environments, improving accuracy in open-set\nscenarios. Hence, we define an embedding space full of hyperspheres\nwhere points cluster around a single centroid representation for each\nclass.\nGiven a class ğ¶from task ğ‘¡, its centroid cğ¶is:\ncğ¶=\n1\n|x+|\nâˆ‘ï¸\nğ‘¥ğ‘¡âˆˆx+\nğ‘“ğ‘ğ‘Ÿ(ğ‘¥ğ‘¡).\n(6)\nNotable, during the training process of {1, ...,ğ‘¡, ...}, the model\nstores all learned centroids incrementally. Each centroid is treated\nas the center of a hypersphere, and thus next, an appropriate radius\nneeds to be determined for establishing compact boundaries between\nknowns and unknowns.\nMargin and Radius. Given a class ğ¶with few-shot training\nsamples, the number of negative samples |xâˆ’| is typically much\nlarger than the number of positive samples |x+|. To preserve distinct\ndistributions for different classes, we constrain the distance between\nthe class centroid cğ¶and every positive sample ğ‘¥âˆˆx+ to be less\nthan a learnable radius:\nğ‘‘ğ‘–ğ‘ (cğ¶, ğ‘“ğ‘ğ‘Ÿ(ğ‘¥)) < ğ‘Ÿğ¶,\n(7)\nwhere the radius ğ‘Ÿğ¶is optimized by Equation 5. Accordingly, for\nevery negative sample ğ‘¥âˆˆxâˆ’of class ğ¶:\nğ‘‘ğ‘–ğ‘ (cğ¶, ğ‘“ğ‘ğ‘Ÿ(ğ‘¥)) > ğ‘Ÿğ¶+ ğ‘š,\n(8)\nwhere ğ‘šis the margin.\nHence, the hypersphere of class ğ¶is constructed by optimizing\nthe radius ğ‘Ÿğ¶as:\nğ‘Ÿğ¶= ğ‘ğœ({ğ‘‘ğ‘–ğ‘ (cğ¶, ğ‘“ğ‘ğ‘Ÿ(ğ‘¥)) âˆ’ğ‘š| ğ‘¥âˆˆxâˆ’}),\n(9)\nwhere ğ‘ğœ(Â·) is a quantile function and ğœserves as the constraint\ngoverning deviations. Each hypersphere learned from task ğ‘¡is for-\nmulated as:\n(ğ¶ğ¿ğ‘†ğ‘¡\nğ‘¡ğ‘Ÿ, Cğ‘¡, Rğ‘¡) = {(ğ¶ğ‘¡\n1, cğ¶ğ‘¡\n1,ğ‘Ÿğ¶ğ‘¡\n1 ), ..., (ğ¶ğ‘¡\nğ‘, cğ¶ğ‘¡\nğ‘,ğ‘Ÿğ¶ğ‘¡\nğ‘)},\nwhere ğ‘is the number of classes in ğ¶ğ¿ğ‘†ğ‘¡\nğ‘¡ğ‘Ÿ.\nDuring the training process of {1, ...,ğ‘¡, ...}, the model stores all\nlearned hyperspheres together:\n(ğ¶ğ¿ğ‘†ğ‘¡ğ‘Ÿ, C, R) = {(ğ¶ğ¿ğ‘†1\nğ‘¡ğ‘Ÿ, C1, R1), ..., (ğ¶ğ¿ğ‘†ğ‘¡\nğ‘¡ğ‘Ÿ, Cğ‘¡, Rğ‘¡), ...}.\nOpen Detection. In testing phrases, given a test sample ğ‘¥from\nan arbitrary task, we initially project ğ‘¥into all learned hyperspheres.\nSubsequently, to determine whether the test sample ğ‘¥is unknown,\nwe check the inclusion of ğ‘¥in all hyperspheres: If there is a class ğ¶\nsuch that the sample is contained within the hypersphere of ğ¶then ğ‘¥\nis classified within ğ¶, otherwise, ğ‘¥is identified as unknown.\nThen, the open detection procedure at task ğ‘¡is:\nStep 1: Identify the centroid câˆ—\nğ¶closest to ğ‘¥;\nStep 2: Calculate the distance between the selected centroid câˆ—\nğ¶\nand the test sample ğ‘¥;\nStep 3: If ğ‘‘âˆ—â‰¤ğ‘Ÿâˆ—, then ğ‘¥belongs to class ğ¶otherwise it is\nclassified as unknown.\nIn MOB, we treat the hypersphere centers as learnable parameters,\ndynamically updating them based on deep feature representations\nduring continual learning. Our method shares similarities with deep\ndistance metric classifiers that employ margin-based loss functions.\nMoreover, the prototypes are set to hypersphere centers, which are\nadaptively updated throughout the learning process, i.e., in the adap-\ntive knowledge space (AKS).\n3.4\nAdaptive Knowledge Space (AKS)\nConsidering (ğ¶ğ¿ğ‘†ğ‘¡ğ‘Ÿ, C, R) as the knowledge learned from knowns,\nwe present an Adaptive Knowledge Space (AKS), designed not\nonly to store and transfer knowledge about unknowns acquired from\npreviously learned tasks, but also to facilitate updating unknown\nknowledge into known knowledge during OFCL.\nUnknown Knowledge Representation. After identifying unknowns,\nwe then employ clustering on the identified unknown samples as\nfollows: Given a detected unknown sample ğ‘¥let Î“ğœ–(ğ‘¥) represent\nthe ğœ–-neighborhood of ğ‘¥, ğ‘€ğ‘–ğ‘›ğ‘ƒğ‘¡ğ‘ denotes the minimum number of\nobjects in Î“ğœ–(ğ‘¥), and ğœŒ(ğ‘¥) = |Î“ğœ–(ğ‘¥)| be its density value. We define\nthe boolean function ğ‘‡(ğ‘¥) = 1 if ğœŒ(ğ‘¥ğ‘—) â‰¥ğ‘€ğ‘–ğ‘›ğ‘ƒğ‘¡ğ‘ and ğ‘‡(ğ‘¥) = 0\notherwise. If ğ‘‡(ğ‘¥) = 1, the unknown sample ğ‘¥is clustered with\ndensity-reachable points, and the entire space is partitioned into ğ‘€\ngroups {ğº1,ğº2, ...,ğºğ‘€}. Otherwise, ğ‘¥is treated as a noise. Each\ngroup is then assigned a group centroid, which is determined using\nEquation 6. The corresponding radius is obtained by Equation 9.\nSince there are no ground-truth labels for unknowns, we generate\na set of pseudo-labels and assign them to each group. Similar to\nhyperspheres learned from known samples, we have :\n(ğ¶ğ¿ğ‘†ğ‘¡\nğ‘œğ‘ğ‘’ğ‘›, Cğ‘¡, Rğ‘¡) = {(ğ¶ğ‘¡\n1, cğ¶ğ‘¡\n1,ğ‘Ÿğ¶ğ‘¡\n1 ), ..., (ğ¶ğ‘¡\nğ‘€, cğ¶ğ‘¡\nğ‘€\n,ğ‘Ÿğ¶ğ‘¡\nğ‘€\n)}.\nUpdating Unknowns to Knowns. At task ğ‘¡the integrated adaptive\nknowledge space consists of all the learned hyperspheres during\ntraining (ğ¶ğ¿ğ‘†ğ‘¡ğ‘Ÿ, C, R) together with all the new (ğ¶ğ¿ğ‘†ğ‘¡ğ‘œğ‘ğ‘’ğ‘›, Cğ‘¡, Rğ‘¡)\nassociated with the unknowns at all task until ğ‘¡. Because of this\nincremental growth, if previously encountered unknowns reappear,\nthey are classified with corresponding pseudo-labels. However, if a\nnew hypersphere learned during a subsequent taskâ€™s training overlaps\nwith an existing hypersphere with a pseudo-label, then we integrate\nthe corresponding pseudo-category into the newly trained categories,\nthus facilitating a transition from unknowns to knowns.\n3.5\nOverall Objective\nAt any task ğ‘¡, OFCL first obtains ğ¿-additional tokens via Lğ‘ğ‘¢ğ‘”and\nstores all the newly learned additional tokens together with those\npreviously learned. Subsequently, each sample is augmented by\nadditional knowledge, and an adaptive knowledge space contain-\ning knowledge learned from knowns and unknowns is constructed.\nHence, the overall objective is:\nmin\n(Cğ‘¡,Rğ‘¡),ğœƒ,(kğ‘¡,pğ‘¡)ğ›¾Â· Lğ‘šğ‘ğ‘Ÿğ‘”ğ‘–ğ‘›+ (1 âˆ’ğ›¾) Â· Lğ‘ğ‘¢ğ‘”,\n(10)\nwhere the ğ›¾is a balance between Lğ‘šğ‘ğ‘Ÿğ‘”ğ‘–ğ‘›and Lğ‘ğ‘”ğ‘¢.\n\n\nLi and Wang, et al.\nAlgorithm 1 : Training Process of the OFCL framework\nInput: the training set ğ·ğ‘¡\nğ‘¡ğ‘Ÿ= {(Xğ‘¡, Yğ‘¡)}, the set of training classes\nğ¶ğ¿ğ‘†ğ‘¡\nğ‘¡ğ‘Ÿ, the token bank (K, P) = {(kğ‘¡, pğ‘¡)}ğ‘‡\nğ‘¡=1, a trainable classifier\nğ‘“ğœƒ, a backbone ğ‘“ğ‘ğ‘Ÿand the hyperparameter balance ğ›¾.\nInitialize: (K, P), ğ‘“ğœƒ.\n1: for t = 1, 2, ..., ğ‘‡do\n2:\nfor each epoch do\n3:\nfor (xğ‘¡, yğ‘¡) in each training set ğ·ğ‘¡ğ‘Ÿ\nğ‘¡with class ğ¶ğ¿ğ‘†ğ‘¡\nğ‘¡ğ‘Ÿdo\n4:\nMap xğ‘›to hğ‘¡;\n5:\nGet the similarity of â„ğ‘¡and each key of (kğ‘¡, pğ‘¡);\n6:\nSelect augmentation tokens with (kâˆ—, pâˆ—) Equation 2;\n7:\nEnhance hğ‘¡to hâ€²ğ‘¡with pâˆ—via Equation 3;\n8:\nCalculate the augmented feature by ğ‘“ğ‘ğ‘Ÿ(hâ€²ğ‘¡);\n9:\nCalculate cğ¶for each class ğ¶in ğ¶ğ¿ğ‘†ğ‘¡\nğ‘¡ğ‘Ÿvia Equation 6;\n10:\nObtain positive and negative set of class ğ¶: x+, xâˆ’;\n11:\nObtain margin and radius via Equation 9\n12:\nCalculate the overall loss via Equation 10;\n13:\nend for\n14:\nUpdate ğ‘“ğœƒ, (K, P), the radius ğ‘Ÿğ¶and margin ğ‘šby backprop-\nagation;\n15:\nend for\n16:\nUpdate the overall AKS with 1) Hyperspheres learned from\nğ·ğ‘¡\nğ‘¡ğ‘Ÿ: (ğ¶ğ¿ğ‘†ğ‘¡\nğ‘¡ğ‘Ÿ, Cğ‘¡, Rğ‘¡) and 2) the Hyperspheres learned from\nunknowns: (ğ¶ğ¿ğ‘†ğ‘¡ğ‘œğ‘ğ‘’ğ‘›, Cğ‘¡, Rğ‘¡).\n17: end for\nTo better illustrate the proposed OFCL framework, we detail the\ntraining process in Algorithm 1. First, the token bank and classifier\nare initialized. Then, for each time step ğ‘¡, multiple training epochs\nare conducted, where each sample (xğ‘¡, yğ‘¡) undergoes feature map-\nping, similarity computation with stored keys, augmentation via\ntoken selection, and enhancement through the backbone network.\nClass-wise centroids, positive and negative sets, margins, and radii\nare computed to derive the overall loss, which is minimized via\nbackpropagation. Finally, the AKS is updated with hyperspheres rep-\nresenting both known and unknown knowledge, enabling continual\nadaptation to evolving data distributions.\nAccordingly, after learning task t, the model follows four steps\nduring inference:\nStep 1: Integrate new task knowledge (i.e., knowledge from la-\nbeled samples) into the current knowledge space, updating unknowns\nto knowns once the labels for open samples are learned.\nStep 2: During testing, detect open samples and ensure they are\nnot misclassified as known categories.\nStep 3: For samples identified as knowns, classify them correctly\nwhile avoiding forgetting of previous tasks.\nStep 4: Update the knowledge space adaptively by incorporating\nthe new knowledge from the open sample into the current knowledge\nspace.\nIn summary, our OFCL framework not only enhances the rep-\nresentation of known classes but also improves decision boundary\ncompactness for open detection. This integration demonstrates our\ninnovative development of existing techniques to address the unique\nchallenges of OFCL.\n4\nEXPERIMENTS AND RESULTS\n4.1\nExperimental Setup\nDatasets. We follow the dataset configuration in TOPIC [29]: (1)\nThe CUB200 dataset [32] encompasses 11,788 images depicting\n200 distinct bird species. We partition the 200 classes into 100\nbase classes for task 0 and 100 incremental classes for 10 tasks.\nEach task consists of 10 classes, with each class having 5 training\nsamples (i.e., a 10-way 5-shot setup). (2) The MiniImageNet dataset\n[31] comprises 100 classes with a total of 60,000 RGB images. We\npartition the 100 classes into 60 base classes for an initial base task\nand 40 incremental classes for 8 tasks. Each task consists of 5 classes,\neach with 5 training samples (i.e., a 5-way 5-shot configuration).\nImplementation Details. (1) We randomly shuffled the order of\ntasks in experiments. All results are the averages obtained from\nthree random shuffles. (2) Due to the current absence of available\ncomparative baselines for OFCL, we divided our experiments into\ntwo parts for clear and fair comparisons: unknown detection and\nknown classifications. (3) All baselines are trained by the Adam\noptimizer with a batch size of 25 and a learning rate of 0.03.\nBaselines. To ensure comprehensive and fair comparisons, we\nconsider two parts in the evaluation:\nUnknown Detection: we compare our OFCL against 8 com-\npetitive open detection baselines: MSP [12], KL [11], SSD [27],\nMaxLogit [4], Energy [22], ViM [33], KNN-based OOD [28], NNGuide\n[23].\nKnown Classification: we evaluate OFCL against 15 benchmark\ncontinual learning methods with scarce labeled data: iCaRL [26],\nTOPIC [29], CEC [40], Meta-FSCIL [7], ALICE [24], FeSSSS [2],\nPro-KT [19], LIMIT [44], NC-FSCIL [37], MCNet [13], SoftNet\n[38], CoSR [34], M-FSCIL [17], FSIL-GAN [1], and CPE-CLIP [9].\nMetrics. For unknown detection, we use the average area under\nthe ROC across all learned ğ‘-tasks ğ´ğ‘ˆğ¶ğ‘and the average false\npositive rate across ğ‘-tasks ğ¹ğ‘ƒğ‘…ğ‘as metrics [6]. For known clas-\nsification, we apply averaged accuracy ğ´ğ¶ğ¶ğ‘as the metric, where\nğ´ğ¶ğ¶ğ‘is calculated over ğ‘new tasks. To measure forgetting, we\ncalculate the performance dropping rate PD = ğ´ğ¶ğ¶0 âˆ’ğ´ğ¶ğ¶ğ‘, where\nğ´ğ¶ğ¶0 is the classification accuracy in the base task [19].\nResults on Unknown Detection. Table 2 presents the results of\nunknown detection. Notably, the baselines exhibit poor performance\nunder the OFCL setting, underscoring their difficulty in adapting to\nreal-world scenarios.\nIn contrast, OFCL consistently outperforms all compared methods\nacross various configurations, as indicated by its superior ğ´ğ‘ˆğ¶ğ‘and\nğ¹ğ‘ƒğ‘…ğ‘values. This consistent advantage underscores the robustness\nand adaptability of OFCL in handling diverse learning conditions.\nThe ability of OFCL to delineate precise decision boundaries and\nestablish an adaptive knowledge space further highlights the effec-\ntiveness of our proposed approach in addressing complex knowledge\nboundaries. By dynamically integrating open-set detection with con-\ntinual learning, OFCL effectively mitigates the challenges posed\nby evolving knowledge distributions. Overall, OFCL demonstrates\nsignificant improvements demonstrated by OFCL in open detection\nperformance within real-world scenarios characterized by knowl-\nedge boundaries.\n\n\nImproving Open-world Continual Learning under the Constraints of Scarce Labeled Data\nDataset\nMethods\nğ´ğ‘ˆğ¶ğ‘â†‘\nğ¹ğ‘ƒğ‘…ğ‘â†“\nCUB200\n(10-way 5-shot)\nMSP\n61.34\n92.95\nKL\n60.81\n93.10\nSSD\n37.70\n99.52\nMaxLogits\n61.31\n92.43\nEnergy\n60.81\n93.10\nViM\n54.16\n97.91\nKNN-based OOD\n37.20\n99.16\nNNGuide\n50.26\n96.97\nOFCL\n69.72\n69.96\nMiniImageNet\n(5-way 5-shot)\nMSP\n49.78\n94.91\nKL\n46.61\n95.10\nSSD\n50.64\n95.18\nMaxLogits\n46.78\n94.65\nEnergy\n46.61\n95.10\nViM\n59.56\n89.87\nKNN-based OOD\n52.88\n93.78\nNNGuide\n52.47\n90.95\nOFCL\n76.20\n71.30\nTable 2: Results(%) regarding unknown detection. We report the\nresults over 10 tasks for CUB200 (10-way 5-shot) and 8 tasks for\nMiniImageNet (5-way 5-shot).\nFigure 3: Visualizations of Known Classification.\nResults on Known Classification. In this experiment, we evaluate\nthe modelâ€™s performance on known classification against various\ncompetitive benchmarks under a same setting. Table 3 and Table 4\npresent the accuracy scores achieved by different methods on the\nCUB200 and MiniImageNet datasets, respectively.\nDespite the challenges of the OFCL problem, the proposed frame-\nwork consistently outperforms other baselines, demonstrating lower\ndrop rates and higher final accuracy across all classes. These results\nhighlight the effectiveness of instance-wise token augmentations in\nmitigating catastrophic forgetting and overfitting. Furthermore, as\nshown in Figure 3, the growing performance advantage of OFCL\nover time suggests superior adaptability in long-term learning sce-\nnarios compared to existing baselines.\nNotable, on the MiniImageNet dataset, CPE-CLIP achieves a PD\nscore of 7.46, outperforming ours. CPE-CLIP enhances CLIPâ€™s pre-\ntraining mechanism, improving performance across various cross-\nmodal tasks (e.g., image retrieval, text generation). Its pre-training\ndataset overlaps with MiniImageNet, which may contribute to its\ncompetitive PD score. Additionally, in the base task, our model\nachieves an ğ´ğ¶ğ¶ğ‘of 96, compared to 90 for CPE-CLIP, further\ncontributing to the higher PD score. Hence, these results further\nunderscore the robustness of our OFCL in CL scenarios.\n4.2\nAblation Studies\nWe conduct ablation studies, analyzing the impact of three key com-\nponents: 1) the additional tokens selection mechanism in ITA, 2)\nthe whole instance-wise token augmentation, and 3) the whole AKS.\nThe average final accuracy ğ´ğ¶ğ¶ğ‘represents the mean accuracy over\nthe past ğ‘tasks, and results are presented in Table 5.\nFirst, removing the additional token selection mechanism in ITA\nleads to a noticeable decline in both known classification and un-\nknown detection performance. This highlights its critical role in\nmitigating overfitting at knowledge boundaries and enhancing open-\nset detection. Second, eliminating ITA results in the most significant\ndegradation in known classification, underscoring its effectiveness\nin reducing overfitting and addressing CF. Finally, removing the en-\ntire AKS module completely disables open-set detection. As shown\nin Table 5, this also degrades knowns classification performance,\nindicating that the softmax mechanism alone is insufficient for dis-\ntinguishing between known classes.\nMoreover, our method is highly decoupled from specific back-\nbone architectures, as it operates at the input and output levels,\nensuring broad adaptability. To validate this flexibility, we con-\nducted an ablation study using ViT, a widely adopted large-scale\nimage classification model, as the backbone with fine-tuning. On\nthe CUB200 dataset, OFCL achieves a significantly higher known\nclassification accuracy (63.80%) compared to ViT with fine-tuning\nalone (21.19%). This substantial performance gap demonstrates that\nstrong representational capacity alone is insufficient, highlighting the\neffectiveness of our framework in facilitating structured knowledge\ntransfer and open-set adaptation.\n4.3\nAdditional Results\nTime and Space Complexity. As new tasks continually emerge,\nthe complexity of AKS scales linearly with O(ğ‘›). For the CUB200,\nafter training all tasks, the final AKS only occupies 0.048 MB. As\nfor the MiniImageNet, the final AKS requires 0.024 MB. The lookup\ntime for instance-wise tokens matching is 0.001 seconds, and the\ndecision time is less than 0.01 seconds.\n1\n5\n10\n20\n25\nAdditional token size\n1\n5\n10\n20\n25\nToken length\n56.93\n67.89\n68.32\n69.39\n67.01\n64.66\n67.52\n67.84\n68.45\n68.26\n67.9\n69.76\n68.08\n67.47\n65.36\n67.32\n68.97\n63.3\n62.67\n61.29\n67.5\n67.68\n66.35\n60.66\n60.62\n(a)\n5\n10\n15\n20\n25\n30\nTotal # of additional tokens for each task\n55\n60\n65\n70\n75\n80\nACCN\nAUCN\nFPRN\n(b)\nFigure 4: (a): ğ´ğ¶ğ¶ğ‘w.r.t token length ğ¿ğ‘ƒand additional token\nsize ğ¾, given ğ‘™= 25. (b): ğ´ğ¶ğ¶ğ‘w.r.t. ğ‘™(i.e., the total number\nof additional tokens of each task) with ğ¿ğ‘ƒ= 5 and ğ¾= 5 (take\nCUB200 for illustration).\nParameter Sensitivity Analysis. Consider the crucial hyperpa-\nrameters, namely (1) the margin ğ‘šand the constraint governing\ndeviations ğœ(in Equation 9), and (2) the token length ğ¿ğ‘ƒ, additional\ntoken size ğ¾, and the amount of additional tokens per task ğ‘™.\n\n\nLi and Wang, et al.\nMethods\nğ´ğ¶ğ¶ğ‘in each task (%) â†‘\nPDâ†“\n0\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\niCaRL\n68.68\n52.65\n48.61\n44.16\n36.62\n29.52\n27.83\n26.26\n24.01\n23.89\n21.16\n47.52\nTOPIC\n68.68\n62.49\n54.81\n49.99\n45.25\n41.40\n38.35\n35.36\n32.22\n28.31\n26.28\n42.40\nCEC\n75.85\n71.94\n68.50\n63.50\n62.43\n58.27\n57.73\n55.81\n54.83\n53.52\n52.28\n23.57\nMeta-FC\n75.90\n72.41\n68.78\n64.78\n62.96\n59.99\n58.30\n56.85\n54.78\n53.82\n52.64\n23.26\nALICE\n77.40\n72.70\n70.60\n67.20\n65.90\n63.40\n62.90\n61.90\n60.50\n60.60\n60.10\n17.30\nFeSSSS\n79.60\n73.46\n70.32\n66.38\n63.97\n59.63\n58.19\n57.56\n55.01\n54.31\n52.98\n26.62\nPro-KT\n82.90\n74.15\n72.82\n62.46\n59.69\n54.88\n51.56\n48.57\n47.32\n46.86\n47.68\n35.22\nLIMIT\n76.32\n74.18\n72.68\n69.19\n68.79\n65.64\n63.57\n62.69\n61.47\n60.44\n58.45\n17.87\nNC-FSCIL\n80.45\n75.98\n72.30\n70.28\n68.17\n65.16\n64.43\n63.25\n60.66\n60.01\n59.44\n21.01\nMCNet\n77.57\n73.96\n70.47\n65.81\n66.16\n63.81\n62.09\n61.82\n60.41\n60.09\n59.08\n18.49\nSoftNet\n78.07\n74.58\n71.37\n67.54\n65.37\n62.60\n61.07\n59.37\n57.53\n57.21\n56.75\n21.32\nCoSR\n74.87\n73.15\n68.23\n63.50\n62.72\n59.10\n57.46\n55.73\n53.28\n52.31\n51.75\n23.12\nM-FSCIL\n81.04\n79.73\n76.62\n73.30\n71.22\n68.90\n66.87\n65.02\n63.90\n62.49\n60.40\n20.64\nFSIL-GAN\n81.27\n78.03\n75.61\n73.72\n70.49\n68.19\n66.58\n65.63\n63.21\n60.92\n59.43\n21.84\nCPE-CLIP\n81.58\n78.52\n76.68\n71.86\n71.52\n70.23\n67.66\n66.52\n65.09\n64.47\n64.60\n16.98\nOFCL\n76.67\n81.09\n76.80\n76.20\n74.80\n72.44\n71.52\n69.17\n70.33\n68.17\n68.92\n7.74\nTable 3: Averaged classification accuracy (%) on CUB200 (10-way 5-shot).\nMethods\nğ´ğ¶ğ¶ğ‘in each task (%) â†‘\nPD â†“\n0\n1\n2\n3\n4\n5\n6\n7\n8\niCaRL\n61.31\n46.32\n42.94\n37.63\n30.49\n24.00\n20.89\n18.80\n17.21\n44.10\nTOPIC\n61.31\n50.09\n45.17\n41.16\n37.48\n35.52\n32.19\n29.46\n24.42\n36.89\nCEC\n72.00\n66.83\n62.97\n59.43\n56.70\n53.73\n51.19\n49.24\n47.63\n24.37\nMeta-FSCIL\n72.04\n67.94\n63.77\n60.29\n57.58\n55.16\n52.9\n50.79\n49.19\n24.41\nALICE\n80.60\n70.60\n67.40\n64.50\n62.50\n60.00\n57.80\n56.80\n55.70\n24.90\nFeSSSS\n81.50\n77.04\n72.92\n69.56\n67.27\n64.34\n62.07\n60.55\n58.87\n22.63\nPro-KT\n98.59\n79.82\n77.85\n71.82\n70.34\n69.18\n70.13\n69.27\n69.73\n28.86\nLIMIT\n72.32\n68.47\n64.30\n60.78\n57.95\n55.07\n52.70\n50.72\n49.19\n23.13\nNC-FSCIL\n84.02\n76.80\n72.00\n67.83\n66.35\n64.04\n61.46\n59.54\n58.31\n25.71\nMCNet\n72.33\n67.70\n63.50\n60.34\n57.59\n54.70\n52.13\n50.41\n49.08\n23.25\nSoftNet\n76.63\n70.13\n65.92\n62.52\n59.49\n56.56\n53.71\n51.72\n50.48\n26.15\nCoSR\n71.92\n66.91\n62.71\n59.59\n56.63\n53.78\n51.01\n49.23\n47.93\n23.99\nM-FSCIL\n93.45\n91.82\n87.09\n88.07\n86.75\n87.15\n85.68\n84.80\n85.37\n8.08\nFSIL-GAN\n69.87\n62.91\n59.81\n58.86\n57.12\n54.07\n50.64\n48.14\n46.14\n23.73\nCPE-CLIP\n90.23\n89.56\n87.42\n86.80\n86.51\n85.08\n83.43\n83.38\n82.77\n7.46\nOFCL\n96.00\n91.65\n89.17\n84.90\n86.46\n87.18\n87.57\n85.71\n87.12\n10.88\nTable 4: Averaged classification accuracy (%) on MiniImageNet (5-way 5-shot).\nUnknowns\nDetection\nCUB200\nMiniImageNet\nğ´ğ‘ˆğ¶ğ‘ğ¹ğ‘ƒğ‘…ğ‘ğ´ğ‘ˆğ¶ğ‘\nğ¹ğ‘ƒğ‘…ğ‘\nw/o selection mechanism 66.68 69.96 75.73\n80.54\nw/o ITA\n67.06 75.83 70.61\n86.71\nw/o AKS\n-\n-\n-\n-\nOFCL\n69.72 69.85 76.20\n71.30\nKnowns\nClassification\nCUB200\nMiniImageNet\nğ´ğ¶ğ¶ğ‘\nPD\nğ´ğ¶ğ¶ğ‘\nPD\nw/o selection mechanism 54.52 12.48 61.34\n29.66\nw/o ITA\n50.33 31.14 51.42\n34.58\nw/o AKS\n55.24 28.42 63.02\n34.78\nOFCL\n63.80\n8.20\n65.24\n25.56\nTable 5: Ablation studies.\nFigure 4 (a) shows that using a large selection size ğ¾and a\nlong token length ğ¿ğ‘ƒmay lead to knowledge under-fitting, whereas\nFigure 4 (b) demonstrates that the impact of ğ‘™remains relatively\n0.5    1    1.5    2    2.5\n0.4 0.3 0.2 0.1  0\n(a)\n0.5    1    1.5    2    2.5\n0.4 0.3 0.2 0.1  0\n(b)\nFigure 5: (a) and (b): ğ´ğ‘ˆğ¶ğ‘and ğ¹ğ‘ƒğ‘…ğ‘w.r.t constraint governing\ndeviations ğœand margin ğ‘š(CUB200 dataset).\nstable within the range 5 â‰¤ğ‘™â‰¤30. The parameter ğœacts as a\nconstraint, governing deviations and regulating boundary violations.\nA smaller ğœimposes a more compact boundary. As depicted in\nFigure 5, when ğ‘š= 0.5, performance decreases as ğœincreases.\nHowever, for larger margins, performance improves with increasing\n\n\nImproving Open-world Continual Learning under the Constraints of Scarce Labeled Data\nğœ, indicating the robustness of open detection is sensitive for the\nmargin ğ‘š. Hence, we can safely conclude that our OFCL framework\nexhibits admirable robustness across various configurations.\n5\nCONCLUSIONS AND FUTURE WORK\nIn this paper, we introduced OFCL, a novel framework designed\nto tackle open-world continual learning with scarce labeled data.\nTechnically, the core of our proposed framework lies in its ability to\ndynamically adapt the knowledge space, enabling efficient mining,\nrepresentation, and accumulation of knowledge for both knowns\nand unknowns. Hence, the proposed OFCL not only enhances the\nrepresentation of known classes but also improves the compactness\nof decision boundaries for open detection.\nIn addition, the OFCL framework is designed to be inherently\ncompatible with multiple backbones for getting embeddings, making\nit plug-and-play with generalization capability. Effectively integrat-\ning LLMs into our model is an important direction for future work.\nMoreover, we will focus on enhancing the interpretability and de-\nveloping methods for test-time adaptation to improve knowledge\nrepresentation for unknowns.\nREFERENCES\n[1] Aishwarya Agarwal, Biplab Banerjee, Fabio Cuzzolin, and Subhasis Chaudhuri.\n2022. Semantics-driven generative replay for few-shot class incremental learning.\nIn Proceedings of the 30th ACM International Conference on Multimedia. 5246â€“\n5254.\n[2] Touqeer Ahmad, Akshay Raj Dhamija, Steve Cruz, Ryan Rabinowitz, Chunchun\nLi, Mohsen Jafarzadeh, and Terrance E Boult. 2022. Few-shot class incremental\nlearning leveraging self-supervised features. In Proceedings of the IEEE/CVF\nConference on Computer Vision and Pattern Recognition. 3900â€“3910.\n[3] Touqeer Ahmad, Akshay Raj Dhamija, Mohsen Jafarzadeh, Steve Cruz, Ryan\nRabinowitz, Chunchun Li, and Terrance E Boult. 2022. Variable few shot class\nincremental and open world learning. In Proceedings of the IEEE/CVF Conference\non Computer Vision and Pattern Recognition (Workshop). 3688â€“3699.\n[4] Steven Basart, Mazeika Mantas, Mostajabi Mohammadreza, Steinhardt Jacob,\nand Song Dawn. 2022. Scaling Out-of-Distribution Detection for Real-World\nSettings. In International Conference on Machine Learning.\n[5] Abhijit Bendale and Terrance Boult. 2015. Towards open world recognition. In\nProceedings of the IEEE Conference on Computer Vision and Pattern Recognition.\n1893â€“1902.\n[6] Robin Chan, Matthias Rottmann, and Hanno Gottschalk. 2021. Entropy max-\nimization and meta classification for out-of-distribution detection in semantic\nsegmentation. In Proceedings of the IEEE/CVF International Conference on\nComputer Vision. 5128â€“5137.\n[7] Zhixiang Chi, Li Gu, Huan Liu, Yang Wang, Yuanhao Yu, and Jin Tang. 2022.\nMetafscil: A meta-learning approach for few-shot class incremental learning.\nIn Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern\nRecognition. 14166â€“14175.\n[8] Yawen Cui, Zitong Yu, Wei Peng, Qi Tian, and Li Liu. 2024. Rethinking Few-Shot\nClass-Incremental Learning With Open-Set Hypothesis in Hyperbolic Geometry.\nIEEE Transactions on Multimedia 26 (2024), 5897â€“5910.\n[9] Marco Dâ€™Alessandro, Alberto Alonso, Enrique CalabrÃ©s, and Mikel Galar. 2023.\nMultimodal parameter-efficient few-shot class incremental learning. In Proceed-\nings of the IEEE/CVF International Conference on Computer Vision. 3393â€“3403.\n[10] Nanyi Fei, Yizhao Gao, Zhiwu Lu, and Tao Xiang. 2021. Z-score normalization,\nhubness, and few-shot learning. In Proceedings of the IEEE/CVF International\nConference on Computer Vision. 142â€“151.\n[11] Dan Hendrycks, Steven Basart, Mantas Mazeika, Andy Zou, Joseph Kwon, Mo-\nhammadreza Mostajabi, Jacob Steinhardt, and Dawn Song. 2022. Scaling Out-of-\nDistribution Detection for Real-World Settings. In International Conference on\nMachine Learning. PMLR, 8759â€“8773.\n[12] Dan Hendrycks and Kevin Gimpel. 2016. A Baseline for Detecting Misclas-\nsified and Out-of-Distribution Examples in Neural Networks. In International\nConference on Learning Representations.\n[13] Zhong Ji, Zhishen Hou, Xiyao Liu, Yanwei Pang, and Xuelong Li. 2023. Memo-\nrizing complementation network for few-shot class-incremental learning. IEEE\nTransactions on Image Processing 32 (2023), 937â€“948.\n[14] KJ Joseph, Salman Khan, Fahad Shahbaz Khan, and Vineeth N Balasubramanian.\n2021. Towards open world object detection. In Proceedings of the IEEE/CVF\nConference on Computer Vision and Pattern Recognition. 5830â€“5840.\n[15] Gyuhak Kim, Changnan Xiao, Tatsuya Konishi, Zixuan Ke, and Bing Liu. 2022.\nA theoretical study on solving continual learning. Advances in neural information\nprocessing systems 35 (2022), 5065â€“5079.\n[16] Gyuhak Kim, Changnan Xiao, Tatsuya Konishi, Zixuan Ke, and Bing Liu. 2023.\nOpen-World Continual Learning: Unifying Novelty Detection and Continual\nLearning. arXiv preprint arXiv:2304.10038 (2023).\n[17] Jinze Li, Yan Bai, Yihang Lou, Xiongkun Linghu, Jianzhong He, Shaoyun Xu, and\nTao Bai. 2022. Memory-Based Label-Text Tuning for Few-Shot Class-Incremental\nLearning. arXiv preprint arXiv:2207.01036 (2022).\n[18] Miaomiao Li, Jiaqi Zhu, Yang Wang, Yi Yang, Yilin Li, and Hongan Wang. 2024.\nRulePrompt: Weakly Supervised Text Classification with Prompting PLMs and\nSelf-Iterative Logical Rules. In Proceedings of the ACM on Web Conference 2024.\n4272â€“4282.\n[19] Yujie Li, Xin Yang, Hao Wang, Xiangkun Wang, and Tianrui Li. 2024. Learning to\nPrompt Knowledge Transfer for Open-World Continual Learning. In Proceedings\nof the AAAI Conference on Artificial Intelligence, Vol. 38(12). 13700â€“13708.\n[20] Huiwei Lin, Shanshan Feng, Baoquan Zhang, Hongliang Qiao, Xutao Li, and\nYunming Ye. 2023. UER: A Heuristic Bias Addressing Approach for Online\nContinual Learning. In Proceedings of the 31st ACM International Conference\non Multimedia. Association for Computing Machinery, New York, NY, USA,\n96â€“104.\n[21] Bing Liu, Sahisnu Mazumder, Eric Robertson, and Scott Grigsby. 2023. AI\nAutonomy: Self-initiated Open-world Continual Learning and Adaptation. AI\nMagazine (2023).\n[22] Weitang Liu, Xiaoyun Wang, John Owens, and Yixuan Li. 2020. Energy-based\nout-of-distribution detection. Advances in Neural Information Processing Systems\n33 (2020), 21464â€“21475.\n[23] Jaewoo Park, Yoon Gyo Jung, and Andrew Beng Jin Teoh. 2023. Nearest neigh-\nbor guidance for out-of-distribution detection. In Proceedings of the IEEE/CVF\nInternational Conference on Computer Vision. 1686â€“1695.\n[24] Can Peng, Kun Zhao, Tianren Wang, Meng Li, and Brian C Lovell. 2022. Few-shot\nclass-incremental learning from an open-set perspective. In European Conference\non Computer Vision. Springer, 382â€“397.\n[25] Chengwei Qin and Shafiq Joty. 2021.\nLfpt5: A unified framework for life-\nlong few-shot language learning based on prompt tuning of t5. arXiv preprint\narXiv:2110.07298 (2021).\n[26] Sylvestre-Alvise Rebuffi, Alexander Kolesnikov, Georg Sperl, and Christoph H\nLampert. 2017. icarl: Incremental classifier and representation learning. In Pro-\nceedings of the IEEE Conference on Computer Vision and Pattern Recognition.\n2001â€“2010.\n[27] Vikash Sehwag, Mung Chiang, and Prateek Mittal. 2021. Ssd: A unified frame-\nwork for self-supervised. In International Conference on Machine Learning.\n[28] Yiyou Sun, Yifei Ming, Xiaojin Zhu, and Yixuan Li. 2022. Out-of-distribution\ndetection with deep nearest neighbors. In International Conference on Machine\nLearning. PMLR, 20827â€“20840.\n[29] Xiaoyu Tao, Xiaopeng Hong, Xinyuan Chang, Songlin Dong, Xing Wei, and\nYihong Gong. 2020. Few-shot class-incremental learning. In Proceedings of\nthe IEEE/CVF Conference on Computer Vision and Pattern Recognition. 12183â€“\n12192.\n[30] Daniel J Trosten, Rwiddhi Chakraborty, Sigurd LÃ¸kse, Kristoffer Knutsen Wick-\nstrÃ¸m, Robert Jenssen, and Michael C Kampffmeyer. 2023. Hubs and hyper-\nspheres: Reducing hubness and improving transductive few-shot learning with\nhyperspherical embeddings. In Proceedings of the IEEE/CVF Conference on\nComputer Vision and Pattern Recognition. 7527â€“7536.\n[31] Oriol Vinyals, Charles Blundell, Timothy Lillicrap, Daan Wierstra, et al. 2016.\nMatching networks for one shot learning. Advances in Neural Information Pro-\ncessing Systems 29 (2016).\n[32] Catherine Wah, Steve Branson, Peter Welinder, Pietro Perona, and Serge Belongie.\n2011. The caltech-ucsd birds-200-2011 dataset.\n[33] Haoqi Wang, Zhizhong Li, Litong Feng, and Wayne Zhang. 2022. Vim: Out-\nof-distribution with virtual-logit matching. In Proceedings of the IEEE/CVF\nConference on Computer Vision and Pattern Recognition. 4921â€“4930.\n[34] Xin Wang, Yue Liu, Jiapei Fan, Weigao Wen, Hui Xue, and Wenwu Zhu. 2023.\nContinual Few-shot Learning with Transformer Adaptation and Knowledge Regu-\nlarization. In Proceedings of the ACM Web Conference, Vol. 2023.\n[35] Zifeng Wang, Zizhao Zhang, Sayna Ebrahimi, Ruoxi Sun, Han Zhang, Chen-Yu\nLee, Xiaoqi Ren, Guolong Su, Vincent Perot, Jennifer Dy, et al. 2022. Dualprompt:\nComplementary prompting for rehearsal-free continual learning. In European\nConference on Computer Vision. Springer, 631â€“648.\n[36] Zifeng Wang, Zizhao Zhang, Chen-Yu Lee, Han Zhang, Ruoxi Sun, Xiaoqi Ren,\nGuolong Su, Vincent Perot, Jennifer Dy, and Tomas Pfister. 2022. Learning to\nprompt for continual learning. In Proceedings of the IEEE/CVF Conference on\nComputer Vision and Pattern Recognition. 139â€“149.\n[37] Yibo Yang, Haobo Yuan, Xiangtai Li, Zhouchen Lin, Philip Torr, and Dacheng Tao.\n2022. Neural Collapse Inspired Feature-Classifier Alignment for Few-Shot Class-\nIncremental Learning. In The Eleventh International Conference on Learning\nRepresentations.\n\n\nLi and Wang, et al.\n[38] Jaehong Yoon, Sultan Madjid, Sung Ju Hwang, Chang-Dong Yoo, et al. 2023. On\nthe Soft-Subnetwork for Few-Shot Class Incremental Learning. In International\nConference on Learning Representations (ICLR) 2023. International Conference\non Learning Representations.\n[39] Zhiqi Yu, Jingjing Li, Zhekai Du, Fengling Li, Lei Zhu, and Yang Yang. 2023.\nNoise-Robust Continual Test-Time Domain Adaptation. In Proceedings of the\n31st ACM International Conference on Multimedia. Association for Computing\nMachinery, New York, NY, USA, 2654â€“2662.\n[40] Chi Zhang, Nan Song, Guosheng Lin, Yun Zheng, Pan Pan, and Yinghui Xu. 2021.\nFew-shot incremental learning with continually evolved classifiers. In Proceedings\nof the IEEE/CVF Conference on Computer Vision and Pattern Recognition. 12455â€“\n12464.\n[41] Hanbin Zhao, Yongjian Fu, Mintong Kang, Qi Tian, Fei Wu, and Xi Li. 2021.\nMgsvf: Multi-grained slow vs. fast framework for few-shot class-incremental\nlearning.\nIEEE Transactions on Pattern Analysis and Machine Intelligence\n(2021).\n[42] Xiaowei Zhao, Yuqing Ma, Duorui Wang, Yifan Shen, Yixuan Qiao, and Xiang-\nlong Liu. 2023. Revisiting open world object detection. IEEE Transactions on\nCircuits and Systems for Video Technology (2023).\n[43] Da-Wei Zhou, Fu-Yun Wang, Han-Jia Ye, Liang Ma, Shiliang Pu, and De-Chuan\nZhan. 2022. Forward compatible few-shot class-incremental learning. In Proceed-\nings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition.\n9046â€“9056.\n[44] Da-Wei Zhou, Han-Jia Ye, Liang Ma, Di Xie, Shiliang Pu, and De-Chuan Zhan.\n2022. Few-shot class-incremental learning by sampling multi-phase tasks. IEEE\nTransactions on Pattern Analysis and Machine Intelligence (2022).\n[45] Xiangyang Zhu, Renrui Zhang, Bowei He, Ziyu Guo, Ziyao Zeng, Zipeng Qin,\nShanghang Zhang, and Peng Gao. 2023. Pointclip v2: Prompting clip and gpt for\npowerful 3d open-world learning. In Proceedings of the IEEE/CVF International\nConference on Computer Vision. 2639â€“2650.\n\n\n",
  "metadata": {
    "source_file": "dataset/pdfs/arxiv_2502.20974v1.pdf",
    "total_pages": 10,
    "title": "Improving Open-world Continual Learning under the Constraints of Scarce Labeled Data",
    "authors": [
      "Yujie Li",
      "Xiangkun Wang",
      "Xin Yang",
      "Marcello Bonsangue",
      "Junbo Zhang",
      "Tianrui Li"
    ],
    "abstract": "Open-world continual learning (OWCL) adapts to sequential tasks with open\nsamples, learning knowledge incrementally while preventing forgetting. However,\nexisting OWCL still requires a large amount of labeled data for training, which\nis often impractical in real-world applications. Given that new\ncategories/entities typically come with limited annotations and are in small\nquantities, a more realistic situation is OWCL with scarce labeled data, i.e.,\nfew-shot training samples. Hence, this paper investigates the problem of\nopen-world few-shot continual learning (OFCL), challenging in (i) learning\nunbounded tasks without forgetting previous knowledge and avoiding overfitting,\n(ii) constructing compact decision boundaries for open detection with limited\nlabeled data, and (iii) transferring knowledge about knowns and unknowns and\neven update the unknowns to knowns once the labels of open samples are learned.\nIn response, we propose a novel OFCL framework that integrates three key\ncomponents: (1) an instance-wise token augmentation (ITA) that represents and\nenriches sample representations with additional knowledge, (2) a margin-based\nopen boundary (MOB) that supports open detection with new tasks emerge over\ntime, and (3) an adaptive knowledge space (AKS) that endows unknowns with\nknowledge for the updating from unknowns to knowns. Finally, extensive\nexperiments show the proposed OFCL framework outperforms all baselines\nremarkably with practical importance and reproducibility. The source code is\nreleased at https://github.com/liyj1201/OFCL.",
    "published_date": "2025-02-28",
    "source": "arxiv"
  }
}