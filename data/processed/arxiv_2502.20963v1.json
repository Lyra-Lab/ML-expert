{
  "id": "arxiv_2502.20963v1",
  "text": "RETRIEVAL AUGMENTED GENERATION FOR TOPIC MODELING \n1 \n \n \n \n \n \nRetrieval Augmented Generation for Topic Modeling in Organizational Research:  \n \nAn Introduction with Empirical Demonstration \n \n \n \nGerion Spielberger1, Florian Artinger2, Jochen Reb3 and Rudolf Kerschreiter1 \n1Division of Social, Organizational, and Economic Psychology, Freie Universität Berlin, \nGermany \n2Berlin International University of Applied Sciences, Germany \n3Lee Kong Chiang School of Business, Singapore Management University, Singapore \n \n \n \n \n \nAuthor Note \nGerion Spielberger \nEmail: gerion.spielberger@fu-berlin.de \nFlorian Artinger \nhttps://orcid.org/0000-0001-9572-2329 \nEmail: artinger@berlin-international.de \nJochen Reb \nhttps://orcid.org/0000-0003-0233-8016 \nEmail: jreb@smu.edu.sg \nRudolf Kerschreiter \nhttps://orcid.org/0000-0003-0281-0261 \nEmail: rudolf.kerschreiter@fu-berlin.de \nWe have no conflicts of interests to disclose. \n\n\nRETRIEVAL AUGMENTED GENERATION FOR TOPIC MODELING \n2 \n \nAbstract \nAnalyzing textual data is the cornerstone of qualitative research. While traditional methods such \nas grounded theory and content analysis are widely used, they are labor-intensive and time-\nconsuming. Topic modeling offers an automated complement. Yet, existing approaches, \nincluding LLM-based topic modeling, still struggle with issues such as high data preprocessing \nrequirements, interpretability, and reliability. This paper introduces Agentic Retrieval-\nAugmented Generation (Agentic RAG) as a method for topic modeling with LLMs. It integrates \nthree key components: (1) retrieval, enabling automatized access to external data beyond an \nLLM’s pre-trained knowledge; (2) generation, leveraging LLM capabilities for text synthesis; \nand (3) agent-driven learning, iteratively refining retrieval and query formulation processes. \nTo empirically validate Agentic RAG for topic modeling, we reanalyze a Twitter/X dataset, \npreviously examined by Mu et al. (2024a). Our findings demonstrate that the approach is more \nefficient, interpretable and at the same time achieves higher reliability and validity in \ncomparison to the standard machine learning approach but also in comparison to LLM \nprompting for topic modeling. These results highlight Agentic RAG’s ability to generate \nsemantically relevant and reproducible topics, positioning it as a robust, scalable, and \ntransparent alternative for AI-driven qualitative research in leadership, managerial, and \norganizational research. \n \nKeywords: qualitative data analysis, retrieval augmented generation, topic modeling, machine learning \n \n \n\n\nRETRIEVAL AUGMENTED GENERATION FOR TOPIC MODELING \n3 \n \nIntroduction \nQualitative research relies heavily on analyzing textual data in the form of interviews, \nopen-ended survey responses, email communication, news, or company documents. Doing \nsuch analyses is both time-intensive and resource-demanding, even with the aid of widely-\nused qualitative data analysis software. One well-established method for qualitative data \nanalysis in managerial research is topic modeling, a machine learning approach that identifies \nrelevant topics within textual datasets (Blei et al., 2003; Tonidandel et al., 2022). Topic \nmodeling can be considered a partly automated approach of traditional qualitative data \nanalysis techniques such as grounded theory or content analysis (Baumer et al., 2017; \nSchmiedel et al., 2019; van der Velde & Gerpott, 2023). While topic modeling has effectively \nreduced the need for human involvement for coding, the process itself remains labor-\nintensive, and the resulting topics are often difficult to interpret (Mu et al., 2024a; Schmiedel \net al., 2019). \nAdvancements in Artificial Intelligence (AI) and Large Language Models (LLMs) \nsuggest significant potential in improving the processing and contextual understanding of \ntextual data, providing promising solutions to these challenges. Indeed, as LLMs continue to \nevolve, they are increasingly applied to automate traditional text analysis frameworks, \nincluding grounded theory (Übellacker, 2024) and topic modeling (Mu et al., 2024a; Mu et \nal., 2024b). Recent studies demonstrate that LLMs can identify relevant topics in textual \ndatasets with a high alignment to human coding, underlining their potential for qualitative \ndata analysis (Mu et al., 2024a; Mu et al., 2024b). However, significant challenges remain in \nterms of transparency and leave room for improvements with regards to efficiency, validity, \nand reliability for text data analysis with the integration of LLMs. \nTo address these challenges, this paper proposes incorporating Agentic Retrieval-\nAugmented Generation (Agentic RAG) into the topic modeling process, particularly in the \ncontext of social science and organizational research. LLMs are trained on vast amounts of \n\n\nRETRIEVAL AUGMENTED GENERATION FOR TOPIC MODELING \n4 \n \npublicly available data. A key advantage of Agentic RAG is that it uses the capabilities of \nLLMs with respect to handling natural language and applies these capabilities to data that the \nLLM was not previously trained on. RAG enables access to up-to-date, domain-specific, and \nproprietary information, including research databases, interview transcripts, and other \nspecialized datasets. In other words, it ‘augments’ the knowledge base of the LLM from \nwhich it ‘retrieves’ information. \nIn this article, we argue that, through this powerful “global-local” combination, \ntogether with the integration of LLM agents for better retrieval quality, Agentic RAG can \nsubstantially improve topic modeling with regards to four dimensions: (1) efficiency, (2) \ntransparency, (3) validity, and (4) reliability. We do so by laying out the limitations of present \napproaches, explaining the benefits of Agentic RAG and testing it on an empirical dataset. \nOverall, this research makes two key contributions. First, our study introduces Agentic \nRAG to organizational scholarship and elaborates how it improves topic modeling compared \nto both traditional methods and LLM-based prompting approaches, with a particular focus on \nthe dimensions of efficiency and transparency. Second, the study validates the functionality of \nAgentic RAG by empirically assessing its validity and reliability, providing measurable \nevidence of its effectiveness. \nTheoretical Background \nTraditional Textual Data Analysis \nQualitative data analysis holds significant importance in organizational research, such \nas in understanding leadership behavior through qualitative interviews, the analysis of voice \nor video-recordings of leader-employee interactions through multimodal LLMs that can \nanalyze not only text, but also sounds or images (Mu, H. et al., 2024). For simplicity, our \nfocus here will be text, including text that is transcribed from audio data. Traditionally, \nqualitative data analysis has been dominated by two primary methodological approaches: \ngrounded theory and content analysis. While case study research (Eisenhardt, 1989; Pratt, \n\n\nRETRIEVAL AUGMENTED GENERATION FOR TOPIC MODELING \n5 \n \n2025) provides a valuable framework for contextual analysis and theory development, our \nemphasis is on methodological approaches for analyzing qualitative data rather than on case-\nbased research designs. Grounded theory and content analysis, in particular, serve as the \nfoundation for many qualitative studies, offering systematic methods for identifying themes \nand patterns in textual data. Both approaches employ manual coding and remain widely \nutilized in contemporary research. Gioia et al. (2013) systematized the grounded theory \napproach within the context of organizational studies, integrating it into the inductive research \nprocess for qualitative data analysis. The primary objective of this approach is to develop a \ntheory grounded in the data. In contrast, content analysis aims to address specific research \nquestions by identifying and analyzing themes or patterns within textual data (Duriau et al., \n2007). Grounded theory and content analysis have been enhanced by computational tools in \nrecent years. Software such as MAXQDA and other computer-assisted qualitative data \nanalysis software have facilitated the structuring of the research process and the performance \nof quantitative analyses, such as word distributions (O’Kane et al., 2021). Both methods \ninvolve time-consuming processes for coding and interpretation, requiring substantial \nanalytical effort and resources. \nTopic Modeling \nIn recent years, topic modeling has emerged as an automated method for content \nanalysis and grounded theory, offering advantages such as reduced coding effort, the capacity \nto analyze larger datasets and increased objectivity (Baumer et al., 2017; Blei et al., 2003; \nSchmiedel et al., 2019; van der Velde & Gerpott, 2023). Topic modeling is a machine \nlearning approach that identifies the most relevant topics within a dataset using statistical \nalgorithms. Researchers can contextualize and interpret the results to generate a theory from \nthe data or answer a specific research question. Topic modeling has gained increasing \npopularity in organizational research (Schmiedel et al., 2019; Tonidandel et al., 2022; van der \nVelde & Gerpott, 2023). \n\n\nRETRIEVAL AUGMENTED GENERATION FOR TOPIC MODELING \n6 \n \nIn the following section we discuss three methods for topic modeling: (1) the \ntraditional method with Latent Dirichlet Allocation (LDA) as well as (2) using an LLM with \nprompting. We then introduce (3) Agentic RAG for topic modeling. \nMethods for Topic Modeling \nTraditional Topic Modeling with Latent Dirichlet Allocation (LDA) \nTopic Modeling using the LDA algorithm is one of the most widely used methods \n(Blei et al., 2003; Schmiedel et al., 2019). It is based on a statistical model that incorporates \nnatural language processing to identify groups of frequently co-occurring words within textual \ndata. Before applying the algorithm to the data, the dataset requires extensive preprocessing. \nThis process typically includes steps such as data cleaning (e.g., removing stop words) and \ntext standardization like lemmatization and stemming. After preprocessing, the algorithm \ngenerates lists of subtopics of co-occurring and semantically related terms. These lists must \nthen be analyzed and interpreted by the researcher to assign overarching labels to the main \ntopics.  \nAlthough the well-established topic modeling approach can aid the textual data \nanalysis process by reducing resources for human coding, it has several limitations. First, the \ntopic modeling process using LDA remains resource-intense, requires data cleaning, as well \nas manual coding and interpretation for accurate topic identification (Schmiedel et al., 2019). \nA second limitation of LDA is its reliance on preprocessing steps, such as stemming and \nlemmatization, which can significantly influence model performance (Chuang et al., 2015; \nSchofield & Mimno, 2016). While these steps aim to standardize the data, they can lead to \ninformation loss and potential miss of important linguistic nuances that contribute to a richer \nunderstanding of the text. Third, the topics generated by LDA frequently lack intuitive \nalignment with human understanding, making them challenging to interpret without additional \ncontextual information (Gillings & Hardie, 2023; Mu et al., 2024a).  \n\n\nRETRIEVAL AUGMENTED GENERATION FOR TOPIC MODELING \n7 \n \nLLM Prompting for Topic Modeling \nAs LLMs become more prevalent and popular in society and research, many \nresearchers are evaluating the potential of LLMs. Recently, studies have been utilizing LLMs \nfor item and scale development (Fyffe et al., 2024), data analysis (Tai et al., 2024), and also \ntopic modeling (Mu et al., 2024a). LLMs demonstrate high efficiency in processing \nsubstantial amounts of textual data. In a series of experiments, Mu et al. (2024a) developed an \napproach whereby LLMs (e.g., GPT and LLaMA) were used to extract relevant topics from \nextensive datasets to perform topic modeling via prompts. Because of the capacity limitations \nof the models, the data was provided in subsets and from each subset the most relevant topics \nwere identified by the LLM. In a final step, all identified topics from every chunk were \nsummarized with another prompt to a final number of ten main topics. Because the data is \nprocessed based on the formulation of the prompt, we refer to this approach as LLM \nprompting. \nTheir findings suggest that LLMs generate topics more aligned with human coding \nthan those produced by methods like LDA. The performance of the LLM was strong even \nwhen applied to datasets with limited context, such as short tweets. This demonstrates a clear \nadvantage over LDA, which often struggles to extract meaningful insights from short or \nhighly condensed text data (Laureate et al., 2023). \nThese results highlight the potential of LLMs for research tasks such as topic \nmodeling, offering significant time savings in human data processing while maintaining high-\nquality results. However, several critical limitations need to be discussed. One limitation is \nthe issue of feeding the data in subsets, due to LLM capacities. This is not only inefficient but \nalso prone to the risk of errors. Multiple steps of feeding data as well as summarizing the \ngenerated subtopics topics are needed. Moreover, retrieval using LLMs presents additional \nchallenges, such as hallucinations and a lack of transparency, making the process a \"black \nbox\". Hallucinations occur when LLMs generate information that seems plausible but is \n\n\nRETRIEVAL AUGMENTED GENERATION FOR TOPIC MODELING \n8 \n \nincorrect, fabricated, or unsupported by any data. It stems on the one hand from the inherent \nstochasticity of the LLMs where words or sequences of words are predicted probabilistically – \nby design some predictions will fail. On the other hand, hallucinations can stem from \ninsufficient training data, whereby the topic that the user queries is insufficiently covered; a \nproblem which is heightened by feeding the data in subsets. Hallucinations are one of the \nmajor issues of LLMs and generative AI in general.  \nAs reported in the study of Mu et al. (2024a) the authors experimented with multiple \nprompt variations and even adding seed topics (example topics as an anchor for the LLM), \nhighlighting the significant impact of prompt formulation on output quality. This reliance on \nprecise prompt design brings complexity and unpredictability into the process and may \nhamper reproducibility. A third critical issue is the lack of transparency. While LLMs are \nhighly capable, many of them provide – at least at present – limited insight into how the \noutput is generated. Consequently, in most cases it remains unclear whether the output \nrepresents the best possible result or merely the first sufficient one identified by the LLM. \nMore generally, at present it is often not possible to reconstruct how the model arrived at its \noutput. Particularly in a scientific context, in which it is central to understand the chain of \nthought that leads to a particular result, such a limitation may be troublesome.  \nAgentic RAG in Textual Data Analysis  \nTo address limitations of current LLM-based approaches for topic modeling, we \npropose an enhanced approach: agentic Retrieval-Augmented Generation (Agentic RAG). \nAgentic RAG extents traditional RAG by incorporating specialized LLM agents to enhance \nthe data processing. \nRAG, first introduced by Lewis et al., (2021) is a framework to enlarge the knowledge \nbase of an LLM by integrating external data sources. This approach enables interaction with \nthe data through queries (similar to prompts). By integrating an external retriever, RAG \nidentifies and retrieves data relevant to the query. This retrieved information from the data is \n\n\nRETRIEVAL AUGMENTED GENERATION FOR TOPIC MODELING \n9 \n \ncombined with the query and contextual knowledge, allowing the LLM to generate an \ninformed response. The integration of LLM agents (in our case the ReAct agent) for Agentic \nRAG further refines the process by incorporating evaluation and reformulation mechanisms. \nIf the retrieved information does not meet the evaluation criteria, the query is reformulated, \nand another retrieval iteration is initiated. This iterative process continues until the question is \nsufficiently answered, thereby optimizing the overall workflow. \nFrom Naïve to Agentic RAG \nThe RAG framework is designed to enhance the capabilities of a LLM by making \nexternal data accessible to it. LLMs are trained on vast amounts of data, enabling them to \nperform impressively across a wide range of tasks and topics. However, their knowledge is \ninherently limited to the public data. Consequently, if we seek information on events or \ndevelopments that are proprietary like research data, the LLM cannot provide accurate or up-\nto-date responses. \nThe most basic form of RAG is referred to as “Naïve RAG” as it consists only of the \nbasic building blocks, illustrated in Figure 1. In the first step of the process, the original data, \nsuch as documents or text, is split into smaller segments called \"chunks,\" which may consist \nof a few sentences or a short paragraph, depending on the chunking strategy used. Each chunk \nis then encoded into a numerical vector (embedding) using a pre-trained model that captures \nthe semantic meaning of the text. These vectors are stored as documents in a vector database \noptimized for searching based on similarity and serves as the knowledge base. When a \nresearcher poses a question in form of a query, the LLM transforms the query into a vector, \nwhich is then compared against the stored vectors in the knowledge base using a retriever \nmodel to find the most semantically relevant documents. The most relevant documents are \nretrieved and, together with the initial query, fed to the LLM, which uses them as input to \ngenerate a coherent response, synthesizing the retrieved information with its internal \nknowledge to provide an accurate answer to the query. While RAG enhances the retrieval and \n\n\nRETRIEVAL AUGMENTED GENERATION FOR TOPIC MODELING \n10 \n \ngeneration process, its performance remains constrained by its linear and static design (Singh \net al., 2025). To achieve greater adaptability and performance tailored to specific needs, it can \nbe further advanced through the integration of LLM agents. \nFigure 1 \nIllustration of the key components of Naïve RAG\n \nAgentic RAG \nThe RAG framework allows potential for advancement at each key step of the RAG \nprocess, including chunking, embedding, retrieval, and prompting. Users can customize the \nprocess for their specific needs. It also allows the integration of LLM agents for better \nretrieval quality. LLM agents are intelligent entities that can execute specific tasks \nautonomously (Singh et al., 2025). In our approach, we use the ReAct agent, which operates \non two principles: \"Reason\" and \"Act\" (Yao et al., 2023). The agent requires the LLM to \nexplicitly articulate its “reasoning” process, followed by a description of the subsequent \naction.  \nThe tasks of the ReAct agent involve assessing generated outputs, reformulating \nqueries and re-retrieving data as needed to optimize results using the ReAct agent (Yao et al., \n2023). In each retrieval cycle, results are analyzed, and if they do not meet the criteria —such \nas failing to fully address the initial query, lacking factual consistency, containing ambiguous \nor conflicting information—, the agent reformulates the query and initiates another iteration, \n\n\nRETRIEVAL AUGMENTED GENERATION FOR TOPIC MODELING \n11 \n \nfollowed by further result analysis. This iterative process offers several advantages. First, it \nreduces dependency on a perfectly crafted initial query, allowing for more flexible, dynamic \nadjustments based on retrieval outcomes. If specific criteria are required for query \nreformulation, they can be predefined to ensure consistency. Second, the agent’s iterative \nreassessment avoids premature satisfaction with early results, ensuring that the retrieved \noutput is not simply the first plausible option but the most contextually aligned and accurate \nresult. These “Reasoning” and “Acting” functions of the agent are textualized in the generated \noutput, making it more transparent for the researcher. Figure 2 illustrates an excerpt of the \nReAct agent’s “reasoning” and “acting” process during topic identification. The example \ndemonstrates two distinct steps in the agent's workflow: In the first step the agent first \nformulates a query to retrieve relevant documents from the knowledge base. It strategically \nuses diverse phrasings to ensure a comprehensive data search. In the second step, after \nretrieving relevant documents, the agent evaluates the data and extracts key topics related to \nvaccine hesitancy, ensuring each topic remains concise and relevant. By capturing the agent’s \n“thoughts”, “actions”, and “reasoning”, Figure 2 highlights how Agentic RAG enhances \ntransparency and provides researchers with insight into the LLM’s decision-making process. \nThis structured approach ensures that the output is not only data-driven but also interpretable, \nreducing the “black-box” nature of LLM-generated results. \n \n \n \n \n \n \n \n \n\n\nRETRIEVAL AUGMENTED GENERATION FOR TOPIC MODELING \n12 \n \nFigure 2 \nExample of the ReAct Agents “thought” process in action \n=== Agent thoughts: \nThought: To identify topics related to COVID-19 vaccine hesitancy, I will \nperform multiple queries using the 'retriever' tool. I will use diverse \nphrasings to ensure a comprehensive exploration of the data. \n>>> Calling tool: 'retriever' with arguments: {'query': 'Identify specific \ntopics related to COVID-19 vaccine hesitancy.'} \nRetrieved documents: (…) \nThought: Based on the retrieved documents, I will now identify specific \ntopics related to COVID-19 vaccine hesitancy, ensuring each topic is no \nmore than three words. \n \nAction: \n{ \n  \"action\": \"final_answer\", \n  \"action_input\": { \n    \"answer\": [ \n      \"Topic 1: Risk-Benefit Analysis\", \n      \"Topic 2: Vaccine Safety\", \n      \"Topic 3: Long-Term Effects\", \n      \"Topic 4: Natural Immunity\", \n      \"Topic 5: Political Motivation\", \n      \"Topic 6: Vaccine Efficacy\", \n      \"Topic 7: Vaccine Side Effects\", \n      \"Topic 8: Vaccine Misinformation\", \n      \"Topic 9: Vaccine Trust\", \n      \"Topic 10: Vaccine Mandates\" \n    ] \n  } \n} \n===== Extracting action ===== \n=== Agent thoughts: \nThought: Based on the retrieved documents, I will now identify specific \ntopics related to COVID-19 vaccine hesitancy, ensuring each topic is no \nmore than three words. \n>>> Calling tool: 'final_answer' with arguments: {'answer': ['Topic 1: \nRisk-Benefit Analysis', 'Topic 2: Vaccine Safety', 'Topic 3: Long-Term \nEffects', 'Topic 4: Natural Immunity', 'Topic 5: Political Motivation', \n'Topic 6: Vaccine Efficacy', 'Topic 7: Vaccine Side Effects', 'Topic 8: \nVaccine Misinformation', 'Topic 9: Vaccine Trust', 'Topic 10: Vaccine \nMandates']} \n \nBenefits of Agentic RAG for Topic Modeling \nBy enlarging the knowledgebase of LLMs with external data and maximizing the \nquality of information retrieval together with the capabilities of LLMs, Agentic RAG matches \nthe requirements for topic modeling and also mitigates the limitations of former approaches \nlike LDA or LLM prompting as employed in Mu et al. (2024a). We propose two qualitative \nadvantages of Agentic RAG compared to LLM prompting: efficiency and transparency. \n\n\nRETRIEVAL AUGMENTED GENERATION FOR TOPIC MODELING \n13 \n \nEven very capable LLMs (e.g., GPT-4/4o) are constrained by a limit of how much text \none can provide, which is quickly reached when processing substantial amounts of data \nsimultaneously. Once this limit is exceeded, the model generates an error. In their study, Mu \net al. (2024a) encountered this limitation and addressed it by providing only subsets of data to \nthe LLM. The model then identified the most relevant topics within each subset which were \nsubsequently summarized in a later step. Agentic RAG, in contrast, processes data as \nnumerical embeddings. This approach significantly reduces computational costs and allows \nfor the inclusion of much larger datasets before reaching the text limit. Consequently, Agentic \nRAG can process an entire dataset, eliminating the need for an additional summarization step. \nThis enhances efficiency by streamlining the process while reducing overall costs.  \nAs detailed above, Agentic RAG enhances transparency by providing insight into the \nmodel's “thought processes” through the ReAct Agent making the LLMs “reasoning” and \n“acting” processes visible. This also increases error detection and makes the system and \ntherefore the quality of the results more comprehendible. Researchers can gain a clearer \nunderstanding of the output generation process by employing LLM agents that require the \nmodel to evaluate outputs and automatically enhance retrieval through query reformulation. \nQuantitative Evaluation of Agentic RAG for Topic Modeling \nBeyond improving efficiency and transparency, Agentic RAG has the potential to \nenhance two critical aspects of topic modeling: validity and reliability. To systematically \nassess these dimensions, we outline the rationale behind our evaluation criteria before \npresenting the empirical validation.  \nFirst, we argue that validity is improved because the Agentic RAG framework ensures \nthat the LLM generates results exclusively based on the provided dataset, rather than relying \non its pre-trained knowledge base. This structure is reducing the model’s susceptibility to \nhallucinations (Lewis et al., 2021). Furthermore, the iterative evaluation, reformulation and \nre-retrieval processes implemented by the agent ensure that the model incorporates all \n\n\nRETRIEVAL AUGMENTED GENERATION FOR TOPIC MODELING \n14 \n \nrelevant information, rather than stopping at the first plausible result. This structured approach \nminimizes the risk of irrelevant or incomplete topic generation, enhancing the overall validity \nof the extracted topics. \nSecond, reliability is strengthened through an iterative retrieval and query \nreformulation process facilitated by the ReAct agent. By continually refining and retrieving \nonly the most relevant segments, this approach ensures that the model consistently generates \nsimilar topics when applied repeatedly to the same dataset. Moreover, since retrieval is \nanchored in an external knowledge base rather than solely dependent on a stochastic \ngenerative model, the topics remain more stable across runs, reducing variability and \nincreasing methodological robustness. \nThese advantages suggest that Agentic RAG strengthens both the accuracy and \nstability of topic modeling, positioning it as a robust alternative to LDA and standard LLM-\nbased prompting. To empirically assess these claims, we conducted a systematic evaluation of \nAgentic RAG, performing topic modeling on a publicly available dataset and assessing \nvalidity and reliability using quantitative metrics. \nMethods \nThe code implementation of Agentic RAG in this study is inspired by the Hugging Face \nAgentic RAG framework (https://huggingface.co/learn/cookbook/agent_rag). For the \nempirical evaluation, we used OpenAIs GPT-4o (https://openai.com/) as the underlying \nlanguage model, ensuring state-of-the-art reasoning and retrieval capabilities. To promote \ntransparency and reproducibility, the complete codebase is publicly available at \n(https://github.com/GerionGit/Agentic-RAG). \nDataset \nFor empirical validation, we conducted an Agentic RAG topic modeling analysis on \nthe dataset used by Mu et al. (2024a), enabling a direct comparison of performance with their \n\n\nRETRIEVAL AUGMENTED GENERATION FOR TOPIC MODELING \n15 \n \nresults. Mu et al. (2024a) analyzed two publicly accessible datasets using their LLM-based \ntopic modeling approach, demonstrating the capability of LLMs to perform topic modeling \neffectively compared to traditional methods such as LDA. To assess the potential \nimprovements offered by Agentic RAG, we focused on the VAXX dataset, comparing our \nresults to those presented by Mu et al. (2024a). The VAXX dataset, originally compiled by \nPoddar et al. (2022), consists of Twitter data (tweets) related to COVID-19 vaccine hesitancy. \nTo ensure comparability, we used the dataset provided by Mu et al. (2024a) as a CSV file. \nThe data was processed using the Agentic RAG workflow we developed, incorporating \nmodifications to align with the methodological steps outlined by Mu et al. (2024a).  \nTo evaluate the consistency and therefore reliability of the identified topics, we \nrepeated the process of extracting the 10 most relevant topics using Agentic RAG five times. \nThis iterative approach allowed us to assess the reliability of the results. The outcomes of our \nanalysis are summarized in Table 1. \nMeasures \nTo evaluate both the validity and reliability of our results, we employ cosine \nsimilarity, a widely used metric in natural language processing. Cosine similarity measures \nthe degree of similarity between two vectors in a multidimensional space. Within the Agentic \nRAG framework, our data is represented as vectors encoding the semantic meaning of words. \nThus, cosine similarity provides a suitable method for assessing the similarity between topics \nas well as the overall alignment between the generated outputs and the dataset. \nTo evaluate validity of the generated topics, we calculate a relevance score between \nthe generated topics and the dataset with cosine similarity. This score reflects the relevance of \nthe topic list in relation to the dataset, providing a weighted measure of how well the topics \ncapture the underlying content. We extend this analysis by applying the same approach to \ntopic lists generated by other methods, such as the model presented in Mu et al. (2024a) and \n\n\nRETRIEVAL AUGMENTED GENERATION FOR TOPIC MODELING \n16 \n \ntraditional LDA, allowing for a comparative evaluation of topic relevance across different \nmethodologies. The key steps in this process are summarized in Table 1. \nTable 1 \nEvaluating validity \nStep \nDescription \n1. Encoding Topics as \nEmbeddings \nA set of top topics was selected for each method (e.g., Round 1 from \nAgentic RAG, LLaMA Expt. 3 + Summarization from Mu et al., 2024a). \nThese topics were encoded into vector representations using a pre-trained \nSentenceTransformer model (all-MiniLM-L6-v2). \n2. Reverse Retrieval of \nDocuments \nFor each topic, a similarity search was conducted against a vectorized \nknowledge base to retrieve the most relevant documents. This step \nleveraged the similarity search functionality of the retriever’s vector \ndatabase. \n3. Cosine Similarity \nCalculation \nThe cosine similarity between the vector representation of each topic and \nthe embeddings of the retrieved documents was calculated, quantifying \nthe semantic alignment between topics and dataset content. \n4. Weighted Average \nCalculation \nTo ensure that more frequently occurring topics had a proportionate \ninfluence, a weighted average relevance score was computed based on the \nnumber of retrieved documents per topic. \n5. Comparison Across \nMethods \nThe entire process was repeated for each topic modeling method (basic \nprompting, LDA, and Agentic RAG), enabling a direct comparison of \ntopic relevance scores. \n \nTo evaluate reliability, we calculate the consistency of generated topics across five \nindependent rounds of topic modeling with Agentic RAG. High consistency between rounds \nindicates reliable topic generation, as it demonstrates the method's stability under similar \nconditions. Table 2 summarizes the key steps in this evaluation. \n \n \n \n \n \n\n\nRETRIEVAL AUGMENTED GENERATION FOR TOPIC MODELING \n17 \n \nTable 2  \nEvaluating reliability \nStep \nDescription \n1. Topic Generation Across 5 \nRounds \nAgentic RAG was executed independently five times, each iteration \nproducing a set of 10 topics based on the dataset. \n2. Embedding of Topics \nTopics from each round were transformed into dense vector \nembeddings using a pre-trained SentenceTransformer model (all-\nMiniLM-L6-v2), enabling semantic comparisons. \n3. Cosine Similarity \nCalculation \nPairwise cosine similarity matrices were computed for each pair of \nrounds to quantify the semantic overlap between generated topics. \n4. Average Highest \nSimilarity \nFor each pair of rounds, the highest cosine similarity for each topic \nin the first round was identified. The average of these maximum \nvalues was then calculated to assess topic alignment across \niterations. \n5. Reliability Metric \n \nThe mean of the highest similarity scores between Round 1 and \nsubsequent rounds served as the reliability metric. Higher values \nindicate greater consistency in topic generation. \n \nResults \nTo examine validity and reliability, we conducted five rounds of topic modeling using \nAgentic RAG on the COVID-19 vaccine hesitancy dataset, which was previously analyzed in \nthe study by Mu et al. (2024a). Each round generated a set of 10 topics. The extracted topics \nfrom all five rounds are presented in Table 3.  At first glance, the topics appear highly \nconsistent across the five rounds, with minor variations in wording and categorization (e.g., \nPolitical Influence vs. Political Motivation; Health Bureaucracy vs. Vaccine Transparency), \nsuggesting a stable and replicable topic structure.  \n \n \n\n\nRETRIEVAL AUGMENTED GENERATION FOR TOPIC MODELING \n18 \n \nTable 3 \nTopics generated in five rounds of topic modeling with Agentic RAG \nTopic \nRound 1 \nRound 2  \nRound 3 \nRound 4 \nRound 5 \n1 \nVaccine \nSafety \nVaccine Safety \nVaccine Safety \nVaccine Safety \nVaccine Safety \n2 \nSide Effects \nSide Effects \nSide Effects \nSide Effects \nSide Effects \n3 \nTrust Issues \nTrust Issues \nTrust Issues \nTrust Issues \nTrust in \nGovernment \n4 \nPolitical \nInfluence \nPolitical \nInfluence \nPolitical \nMotivation \nPolitical \nInfluence \nPolitical \nMotivation \n5 \nLong-term \nEffects \nLong-term \nEffects \nLong-term \nEffects \nLong-term \nEffects \nLong-Term \nEffects \n6 \nEfficacy \nDoubts \nEfficacy \nConcerns \nEfficacy \nConcerns \nEfficacy Doubts \nVaccine \nEfficacy \n7 \nRisk \nPerception \nRisk Perception \nRisk-Benefit \nAnalysis \nRisk-Benefit \nAnalysis \nRisk-Benefit \nAnalysis \n8 \nMandatory \nVaccination \nMandatory \nVaccination \nControl \nConcerns \nMandatory \nVaccination \nMandatory \nVaccination \n9 \nHealth \nBureaucracy \nVaccine \nTransparency \nVaccine \nNecessity \nTransparency \nConcerns \nVaccine \nDevelopment \nSpeed \n10 \nConspiracy \nTheories \nNatural \nImmunity \nNatural \nImmunity \nConspiracy \nTheories \nNatural \nImmunity \n \nTo quantify the validity of topics generated by Agentic RAG, we calculated weighted \ncosine similarity between the extracted topics in each method and the full dataset. This \napproach measures how closely the extracted topics align with the semantic structure of the \noriginal data. The results, presented in Figure 3, indicate that Agentic RAG achieves a higher \nweighted relevance score (0.43) compared to both LLM prompting (0.33) and traditional \nLDA (0.27) both from the evaluation of Mu et al. (2024a). These findings suggest that \nAgentic RAG generates topics that are more aligned with the dataset than those produced by \nalternative methods. \n \n \n\n\nRETRIEVAL AUGMENTED GENERATION FOR TOPIC MODELING \n19 \n \n \nFigure 3 \nEvaluating Validity across Topic Modeling Methods \n \nNote. Comparison of weighted relevance scores for three topic modeling methods: LLM Prompting Mu et al. \n(2024a), Latent Dirichlet Allocation (LDA), and Agentic RAG. Bars represent the mean weighted relevance \nscores across topics, with error bars indicating standard errors (+/-1 SE). \n \n \nTo quantify reliability, we measured topic similarity scores between Round 1 and each \nsubsequent round using cosine similarity. Higher similarity scores indicate greater reliability \nacross iterations, demonstrating the method’s stability. As shown in Figure 4, similarity \nscores range from 0.71 to 0.90, with the highest stability observed between Round 1 and \nRound 4 (0.90) and the lowest between Round 1 and Round 5 (0.71). \n \n \n \n\n\nRETRIEVAL AUGMENTED GENERATION FOR TOPIC MODELING \n20 \n \nFigure 4 \nEvaluating Reliability of Agentic RAG across five Iterations of Topic Modeling \n \nNote. Average similarity scores across rounds compared to Round 1, assessing the reliability \nof Agentic RAG topic modeling results. Bars represent the mean similarity scores, with error \nbars indicating standard errors. Higher values suggest greater consistency of topic \nrepresentations across iterations. \n \nOverall, our empirical evaluation demonstrates that Agentic RAG outperforms both \nLDA and basic LLM prompting in terms of topic validity, generating topics that are stronger \naligned to the dataset, indicated by higher weighted cosine similarity scores. Additionally, the \nresults confirm that Agentic RAG produces consistent topics across multiple iterations, \nensuring a high level of reliability in topic modeling outcomes. These findings underscore the \neffectiveness of Agentic RAG as a robust and scalable alternative to existing topic modeling \napproaches. \n\n\nRETRIEVAL AUGMENTED GENERATION FOR TOPIC MODELING \n21 \n \nDiscussion \nThe primary contribution of this paper is to advance text analysis using LLMs and \nenhance the qualitative data analysis process in organizational research. By introducing \nAgentic RAG for topic modeling, we illustrate how this approach addresses key limitations of \ntraditional qualitative methods, such as grounded theory and content analysis, while also \novercoming challenges associated with existing LLM-based approaches, such as LLM \nprompting. At the same time, Agentic RAG retains the strengths of these methodologies, \nmaking it a robust alternative. Specifically, this approach enhances four critical dimensions of \nqualitative data analysis: efficiency, transparency, validity, and reliability.  \nWhile existing LLM-based methods for topic modeling reduce human coding \nresources, our Agentic RAG approach goes further by reducing preprocessing requirements. \nInstead of feeding raw data subsets to the LLM, the data is represented as embeddings in a \nvector store, which significantly reduces computational costs and the need for resource-\nintensive preprocessing and summarization steps. This streamlined workflow enhances \noverall efficiency by simplifying the interaction between data and the model. \nWith respect to transparency, the integration of the ReAct LLM agent provides \nimportant insights into the \"reasoning\" and “acting” process of the LLM, making it possible to \ntrace and understand the steps taken during topic generation. Transparency is an important \nconcern in LLM-based methods, particularly for scientific applications where interpretability \nand reliability are crucial. By addressing this issue, Agentic RAG contributes to increasing the \ntrustworthiness and usability of LLM-based tools in qualitative research. \nOur empirical findings highlight the quantifiable strengths of Agentic RAG, \nparticularly in validity and reliability. We show that the generated topics with Agentic RAG \nwere more relevant to the dataset, by scoring higher weighted cosine similarity compared to \ntraditional methods like LDA and LLM prompting. Furthermore, the reliability of Agentic \nRAG was demonstrated through high consistency scores across multiple iterations of topic \n\n\nRETRIEVAL AUGMENTED GENERATION FOR TOPIC MODELING \n22 \n \ngenerating. This reliability confirms that the generated topics are reproducible, making it a \nuseful tool for scientific purposes.  \nThe introduced scores for validity and reliability not only facilitate comparisons with \nother topic modeling methods but also serve as diagnostic tools for assessing and refining the \nresults of the topic modeling. Furthermore, the flexibility of the Agentic RAG framework \nallows it to be implemented with various LLMs (e.g., LLaMA), ensuring its continued \napplicability as more advanced models are developed. \nFine-Tuning LLM vs. Agentic RAG \nOne may argue, that fine-tuning might be a more straight-forward solution for topic \nmodeling with LLMs. Fine-tuning is a highly functional process of adjusting parameters of a \npre-trained model for a specific task and is associated with very high computational costs for \ntraining. In a study, Mu et al. (2024b) addressed the issue of hallucinations in LLM-based \ntopic modeling by fine-tuning a model using Direct Preference Optimization (DPO) \ntechnique. DPO is a streamlined version of fine-tuning without requiring extensive human \nannotations. This method involves pretraining the model on a subset of the dataset for a \nspecific task before applying the fine-tuned model to the entire dataset to extract the most \nrelevant topics. According to the authors, their approach successfully reduced the number of \nhallucinated topics while producing coherent and relevant topics.  \nWe argue that Agentic RAG is a superior method for topic modeling than fine-tuning, \nfor several reasons. First, fine-tuning an LLM requires substantial computational resources, \nwhereas Agentic RAG operates efficiently on standard computer hardware. Second, fine-\ntuning is inherently a more static approach, as it depends on pretraining and may struggle with \ngeneralizing to unseen or unfamiliar data (Gao et al., 2024). Third, fine-tuning typically \nrequires a predefined data structure for both input and output, making it less adaptable to new \ndatasets. In contrast, RAG—particularly Agentic RAG—is more flexible, easier to evaluate, \nand provides greater interpretability (Gao et al., 2024). We suggest that Agentic RAG is more \n\n\nRETRIEVAL AUGMENTED GENERATION FOR TOPIC MODELING \n23 \n \napplicable for the task of topic modeling due to its adaptability and efficiency. Fourth, in \ncontrast to LLM prompting or fine-tuning, Agentic RAG shows the reasoning process that the \nmodel uses to generate an output, such providing the necessary transparency for a scientific \ncontext.  \nAgentic RAG for Organizational Research \nIn organizational research, Agentic RAG can bridge the gap between traditional \nqualitative methods, such as grounded theory and content analysis, and modern LLM based \napproaches. Given the capability of LLMs to effectively process textual data, even in sparse \ncontexts, they present significant potential for improving qualitative data analysis. By \nadvancing the information retrieval process and improving contextualization, Agentic RAG \nexpands the applicability of AI-based methods for research purposes.  \nBaumer et al. (2017) compared traditional grounded theory with topic modeling, \nconcluding that each approach captures unique aspects and topics that the other might \noverlook. While grounded theory benefits from its expert-driven interpretive depth, topic \nmodeling provides an objective, data-driven perspective. The integration of contextual \nunderstanding and objectivity through Agentic RAG enhances the qualitative data analysis \nprocess, delivering more accurate and contextually relevant results, that are more aligned with \nhuman understanding and offer a more comprehensive perspective on qualitative data.  \nLimitations \nDespite the demonstrated advantages of Agentic RAG for topic modeling and \nqualitative data analysis, several limitations remain. First, our analysis utilized only a single \nLLM for topic generation. While the Agentic RAG framework is model-agnostic and can be \nimplemented with any capable LLM, such as LLaMa, our evaluation was limited to GPT4-o. \nGiven that Mu et al. (2024a) applied LLM-based topic modeling using both GPT models and \nLLaMa—reporting superior results with the latter—we anticipate that integrating LLaMa into \nAgentic RAG would yield similar or even improved outcomes. This will be addressed in \n\n\nRETRIEVAL AUGMENTED GENERATION FOR TOPIC MODELING \n24 \n \nfuture evaluations. Second, our study assessed Agentic RAG using only one dataset. While \ninitial tests on additional datasets suggest promising results, further validation is necessary to \nestablish the approach’s generalizability. Moreover, while validity and reliability were \nobjectively assessed through a secondary model, additional evaluations are required to further \nsubstantiate these metrics.  \nFuture Directions \nThe integration of LLMs into research is still in its early stages, and textual data \nanalysis provides an ideal foundation for exploring and refining their potential. Given the vast \nopportunities for further advancements, future research should extend this work by \nexperimenting with different LLM agents, alternative datasets, and diverse LLM \narchitectures. By systematically varying these key components and identifying where each \napproach performs best, the research process can be continuously optimized. The presented \n“reasoning” process by the ReAct agent is only an initial step in how LLM agents can support \ntextual data analysis. As research on LLM agents continues to evolve rapidly, future studies \nshould explore how these agents can further enhance the data analysis process. \nBeyond text analysis, RAG also offers the potential for multimodal data analysis, \nintegrating visual, audio, and video data. This expansion could transform data collection and \ninterpretation across multiple research fields. \nA critical aspect for future exploration is transparency. While this study has addressed \nthe need for greater interpretability in AI-driven research, it remains essential for future work \nto further enhance the transparency of LLM-based methodologies, ensuring that their \ndecision-making processes are as comprehensible as possible. \n \n \n\n\nRETRIEVAL AUGMENTED GENERATION FOR TOPIC MODELING \n25 \n \nReferences \nBaumer, E. P. S., Mimno, D., Guha, S., Quan, E., & Gay, G. K. (2017). Comparing grounded \ntheory and topic modeling: Extreme divergence or unlikely convergence? Journal of \nthe Association for Information Science and Technology, 68(6), 1397–1410. \nhttps://doi.org/10.1002/asi.23786 \nBlei, D. M., Ng, A. Y., & Jordan, M. I. (2003). Latent Dirichlet Allocation. Journal of \nmachine Learning research, 3(Jan), 993–1022. \nChuang, J., Roberts, M. E., Stewart, B. M., Weiss, R., Tingley, D., Grimmer, J., & Heer, J. \n(2015). TopicCheck: Interactive Alignment for Assessing Topic Model Stability. \nProceedings of the 2015 Conference of the North American Chapter of the Association \nfor Computational Linguistics: Human Language Technologies, 175–184. \nhttps://doi.org/10.3115/v1/N15-1018 \nDuriau, V. J., Reger, R. K., & Pfarrer, M. D. (2007). A Content Analysis of the Content \nAnalysis Literature in Organization Studies: Research Themes, Data Sources, and \nMethodological Refinements. Organizational Research Methods, 10(1), Article 1. \nhttps://doi.org/10.1177/1094428106289252 \nEisenhardt, K. M. (1989). Building Theories from Case Study Research. \nFeuerriegel, S., Maarouf, A., Bär, D., Geissler, D., Schweisthal, J., Pröllochs, N., Robertson, \nC. E., Rathje, S., Hartmann, J., Mohammad, S. M., Netzer, O., Siegel, A. A., Plank, \nB., & Van Bavel, J. J. (2025). Using natural language processing to analyse text data \nin behavioural science. Nature Reviews Psychology, 1–16. \nhttps://doi.org/10.1038/s44159-024-00392-z \nFyffe, S., Lee, P., & Kaplan, S. (2024). “Transforming” Personality Scale Development: \nIllustrating the Potential of State-of-the-Art Natural Language Processing. \nOrganizational Research Methods, 27(2), 265–300. \nhttps://doi.org/10.1177/10944281231155771 \n\n\nRETRIEVAL AUGMENTED GENERATION FOR TOPIC MODELING \n26 \n \nGao, Y., Xiong, Y., Gao, X., Jia, K., Pan, J., Bi, Y., Dai, Y., Sun, J., Wang, M., & Wang, H. \n(2024). Retrieval-Augmented Generation for Large Language Models: A Survey (No. \narXiv:2312.10997; Nummer arXiv:2312.10997). arXiv. \nhttp://arxiv.org/abs/2312.10997 \nGillings, M., & Hardie, A. (2023). The interpretation of topic models for scholarly analysis: \nAn evaluation and critique of current practice. Digital Scholarship in the Humanities, \n38(2), Article 2. https://doi.org/10.1093/llc/fqac075 \nGioia, D. A., Corley, K. G., & Hamilton, A. L. (2013). Seeking Qualitative Rigor in Inductive \nResearch: Notes on the Gioia Methodology. Organizational Research Methods, 16(1), \nArticle 1. https://doi.org/10.1177/1094428112452151 \nLaureate, C. D. P., Buntine, W., & Linger, H. (2023). A systematic review of the use of topic \nmodels for short text social media analysis. Artificial Intelligence Review, 56(12), \n14223–14255. https://doi.org/10.1007/s10462-023-10471-x \nLewis, P., Perez, E., Piktus, A., Petroni, F., Karpukhin, V., Goyal, N., Küttler, H., Lewis, M., \nYih, W., Rocktäschel, T., Riedel, S., & Kiela, D. (2021a). Retrieval-Augmented \nGeneration for Knowledge-Intensive NLP Tasks (No. arXiv:2005.11401; Nummer \narXiv:2005.11401). arXiv. http://arxiv.org/abs/2005.11401 \nLewis, P., Perez, E., Piktus, A., Petroni, F., Karpukhin, V., Goyal, N., Küttler, H., Lewis, M., \nYih, W., Rocktäschel, T., Riedel, S., & Kiela, D. (2021b). Retrieval-Augmented \nGeneration for Knowledge-Intensive NLP Tasks (No. arXiv:2005.11401). arXiv. \nhttp://arxiv.org/abs/2005.11401 \nMu, H., Zhang, S., Li, Q., Liu, T., & Xu, H. (2024). Dynamic Multi-Modal Representation \nLearning For Topic Modeling. 2024 IEEE International Conference on Multimedia \nand Expo (ICME), 1–6. https://doi.org/10.1109/ICME57554.2024.10688179 \nMu, Y., Bai, P., Bontcheva, K., & Song, X. (2024a). Addressing Topic Granularity and \nHallucination in Large Language Models for Topic Modelling (No. \n\n\nRETRIEVAL AUGMENTED GENERATION FOR TOPIC MODELING \n27 \n \narXiv:2405.00611; Nummer arXiv:2405.00611). arXiv. \nhttp://arxiv.org/abs/2405.00611 \nMu, Y., Dong, C., Bontcheva, K., & Song, X. (2024b). Large Language Models Offer an \nAlternative to the Traditional Approach of Topic Modelling (No. arXiv:2403.16248). \narXiv. http://arxiv.org/abs/2403.16248 \nO’Kane, P., Smith, A., & Lerman, M. P. (2021). Building Transparency and Trustworthiness \nin Inductive Research Through Computer-Aided Qualitative Data Analysis Software. \nOrganizational Research Methods, 24(1), Article 1. \nhttps://doi.org/10.1177/1094428119865016 \nPoddar, S., Samad, A. M., Mukherjee, R., Ganguly, N., & Ghosh, S. (2022). CAVES: A \nDataset to facilitate Explainable Classification and Summarization of Concerns \ntowards COVID Vaccines. Proceedings of the 45th International ACM SIGIR \nConference on Research and Development in Information Retrieval, 3154–3164. \nhttps://doi.org/10.1145/3477495.3531745 \nPratt, M. G. (2025). On the Evolution of Qualitative Methods in Organizational Research. \nSchmiedel, T., Müller, O., & Vom Brocke, J. (2019). Topic Modeling as a Strategy of Inquiry \nin Organizational Research: A Tutorial With an Application Example on \nOrganizational Culture. Organizational Research Methods, 22(4), Article 4. \nhttps://doi.org/10.1177/1094428118773858 \nSchofield, A., & Mimno, D. (2016). Comparing Apples to Apple: The Effects of Stemmers on \nTopic Models. Transactions of the Association for Computational Linguistics, 4, 287–\n300. https://doi.org/10.1162/tacl_a_00099 \nSingh, A., Ehtesham, A., Kumar, S., & Khoei, T. T. (2025). Agentic Retrieval-Augmented \nGeneration: A Survey on Agentic RAG (No. arXiv:2501.09136). arXiv. \nhttps://doi.org/10.48550/arXiv.2501.09136 \n\n\nRETRIEVAL AUGMENTED GENERATION FOR TOPIC MODELING \n28 \n \nTai, R. H., Bentley, L. R., Xia, X., Sitt, J. M., Fankhauser, S. C., Chicas-Mosier, A. M., & \nMonteith, B. G. (2024). An Examination of the Use of Large Language Models to Aid \nAnalysis of Textual Data. International Journal of Qualitative Methods, 23, \n16094069241231168. https://doi.org/10.1177/16094069241231168 \nTonidandel, S., Summerville, K. M., Gentry, W. A., & Young, S. F. (2022). Using structural \ntopic modeling to gain insight into challenges faced by leaders. The Leadership \nQuarterly, 33(5), Article 5. https://doi.org/10.1016/j.leaqua.2021.101576 \nÜbellacker, T. (2024). AcademiaOS: Automating Grounded Theory Development in \nQualitative Research with Large Language Models (No. arXiv:2403.08844; Nummer \narXiv:2403.08844). arXiv. http://arxiv.org/abs/2403.08844 \nvan der Velde, A., & Gerpott, F. H. (2023). When subordinates do not follow: A typology of \nsubordinate resistance as perceived by leaders. The Leadership Quarterly, 34(5), \nArticle 5. https://doi.org/10.1016/j.leaqua.2023.101687 \nYao, S., Zhao, J., Yu, D., Du, N., Shafran, I., Narasimhan, K., & Cao, Y. (2023). ReAct: \nSynergizing Reasoning and Acting in Language Models (No. arXiv:2210.03629; \nNummer arXiv:2210.03629). arXiv. http://arxiv.org/abs/2210.03629 \n \n \n\n\nRETRIEVAL AUGMENTED GENERATION FOR TOPIC MODELING \n29 \n \nAppendix \nTable 4 \nGlossary of specific terms \nTerms \nMeaning \nArtificial Intelligence \n(AI) \nThe field of computer science that focuses on creating systems \ncapable of performing tasks that typically require human \nintelligence, such as understanding natural language, recognizing \npatterns, and making decisions. \nEmbeddings \nNumerical vector representations of words, phrases, or texts that \ncapture their semantic meaning. Embeddings allow machines to \nunderstand and compare the meaning of words or documents \nbased on their context and usage. \nLarge Language Model \n(LLM) \nA type of artificial intelligence model trained on vast amounts of \ntext data to understand and generate human language. Examples \ninclude GPT-4 and LLaMA. LLMs are capable of tasks such as \ntext generation, summarization, and answering questions. \nLemmatization  \nA technique that groups together words that have the same inflected \nforms. For example, lemmatization reduces ‘better’ to ‘good’ \n(Feuerriegel et al., 2025). \nLLM Agent \nA specialized component within an AI system that guides the \nbehavior of an LLM by executing specific tasks, such as retrieving \nrelevant data, evaluating outputs, and refining prompts or queries \nto improve the accuracy and relevance of the model's responses. \nLLM Fine-Tuning \nThe process of adapting a pre-trained LLM to a specific task or \ndomain by training it on a smaller, specialized dataset. This \ncustomization improves the model's performance and accuracy for \nparticular applications, such as domain-specific text generation or \nclassification, while maintaining its general language \nunderstanding capabilities. \nMachine Learning  \nA subset of artificial intelligence that involves training algorithms \non data to recognize patterns and make predictions without being \nexplicitly programmed. In text analysis, ML models are used for \ntasks such as classification, clustering, and topic modeling. \nQuery \nA request for information or data, typically formulated as a \nquestion or a search phrase. In topic modeling and retrieval \nsystems, a query is used to retrieve relevant documents or \ninformation from a knowledge base. \nStemming \nA technique similar to lemmatization used to reduce words to their \nbase or root form. For instance, stemming reduces the words \n‘fishing’, ‘fished’ and ‘fisher’ to ‘fish’. Stemming is a common \nfeature reduction technique (Feuerriegel et al., 2025). \nStop Word removal \nThe process of removing common words (e.g., ‘and’, ‘the’ and \n‘is’) that appear frequently in texts but offer little value in \nunderstanding the meaning. Stop word removal reduces noise \n(Feuerriegel et al., 2025).  \n \nNote. Terms appearing in italics throughout the text are defined in this glossary. \n \n \n\n\nRETRIEVAL AUGMENTED GENERATION FOR TOPIC MODELING \n30 \n \nTable 4  \nTopics generated with LLM prompting and LDA \nLLM prompting (Mu et al. 2024a) \nLDA (Mu et al. 2024a) \nSafety & Side Effects \nVaccine Safety \nMedical & Health Concerns \nCOVID-19 Vaccination \nTrust & Misinformation \nVaccine Safety \nPolitical & Social Influences \nCOVID vaccine \nEconomic & Corporate Concerns \nVaccine effectiveness \nEfficacy Doubts \nCOVID-19 Vaccine \nAutonomy & Personal Beliefs \nVaccine Allergies \nMandatory Vaccination Concerns \nCOVID-19 Vaccine \nAccess & Availability \nCOVID-19 Vaccination \nOthers \nCOVID-19 Vaccination \n \n\n\n",
  "metadata": {
    "source_file": "dataset/pdfs/arxiv_2502.20963v1.pdf",
    "total_pages": 30,
    "title": "Retrieval Augmented Generation for Topic Modeling in Organizational Research: An Introduction with Empirical Demonstration",
    "authors": [
      "Gerion Spielberger",
      "Florian Artinger",
      "Jochen Reb",
      "Rudolf Kerschreiter"
    ],
    "abstract": "Analyzing textual data is the cornerstone of qualitative research. While\ntraditional methods such as grounded theory and content analysis are widely\nused, they are labor-intensive and time-consuming. Topic modeling offers an\nautomated complement. Yet, existing approaches, including LLM-based topic\nmodeling, still struggle with issues such as high data preprocessing\nrequirements, interpretability, and reliability. This paper introduces Agentic\nRetrieval-Augmented Generation (Agentic RAG) as a method for topic modeling\nwith LLMs. It integrates three key components: (1) retrieval, enabling\nautomatized access to external data beyond an LLM's pre-trained knowledge; (2)\ngeneration, leveraging LLM capabilities for text synthesis; and (3)\nagent-driven learning, iteratively refining retrieval and query formulation\nprocesses. To empirically validate Agentic RAG for topic modeling, we reanalyze\na Twitter/X dataset, previously examined by Mu et al. (2024a). Our findings\ndemonstrate that the approach is more efficient, interpretable and at the same\ntime achieves higher reliability and validity in comparison to the standard\nmachine learning approach but also in comparison to LLM prompting for topic\nmodeling. These results highlight Agentic RAG's ability to generate\nsemantically relevant and reproducible topics, positioning it as a robust,\nscalable, and transparent alternative for AI-driven qualitative research in\nleadership, managerial, and organizational research.",
    "published_date": "2025-02-28",
    "source": "arxiv"
  }
}