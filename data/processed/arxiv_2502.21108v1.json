{
  "id": "arxiv_2502.21108v1",
  "text": "Large Language Model-Based Benchmarking\nExperiment Settings for Evolutionary\nMulti-Objective Optimization\nLie Meng Pang, Hisao Ishibuchi\nGuangdong Provincial Key Laboratory of Brain-inspired Intelligent Computation,\nDepartment of Computer Science and Engineering,\nSouthern University of Science and Technology,\nShenzhen 518055, China\npanglm@sustech.edu.cn, hisao@sustech.edu.cn\nAbstract—When we manually design an evolutionary opti-\nmization algorithm, we implicitly or explicitly assume a set of\ntarget optimization problems. In the case of automated algorithm\ndesign, target optimization problems are usually explicitly shown.\nRecently, the use of large language models (LLMs) for the design\nof evolutionary multi-objective optimization (EMO) algorithms\nhave been examined in some studies. In those studies, target\nmulti-objective problems are not always explicitly shown. It\nis well known in the EMO community that the performance\nevaluation results of EMO algorithms depend on not only test\nproblems but also many other factors such as performance\nindicators, reference point, termination condition, and population\nsize. Thus, it is likely that the designed EMO algorithms by\nLLMs depends on those factors. In this paper, we try to examine\nthe implicit assumption about the performance comparison of\nEMO algorithms in LLMs. For this purpose, we ask LLMs to\ndesign a benchmarking experiment of EMO algorithms. Our\nexperiments show that LLMs often suggest classical benchmark\nsettings: Performance examination of NSGA-II, MOEA/D and\nNSGA-III on ZDT, DTLZ and WFG by HV and IGD under the\nstandard parameter specifications.\nIndex Terms—Benchmarking; evolutionary multi-objective op-\ntimization; large language models; parameter settings\nI. INTRODUCTION\nAutomated algorithm design has been actively studied in the\nfield of evolutionary multi-objective optimization (EMO) [1]–\n[6]. Those studies can be categorized into online approaches\nand offline approaches. The goal of online approaches is to\nfind a good non-dominated solution set for a given problem\nby adjusting an EMO algorithm in an online manner. The\ngoal of offline approaches is to design a high-performance\nEMO algorithm for a given set of multi-objective optimization\nproblems. Similar approaches are algorithm selection where\nan appropriate EMO algorithm from a pre-specified algorithm\npool is selected for a given multi-objective problem [7]. A\nclassifier such as a decision tree and a multilayer feed-forward\nneural network is trained based on a given set of multi-\nobjective optimization problems. In the offline automated\nThis work was supported by National Natural Science Foundation of China\n(Grant No. 62250710163, 62376115), Guangdong Provincial Key Laboratory\n(Grant No. 2020B121201001) (Corresponding author: Hisao Ishibuchi)\nalgorithm design and algorithm selection, it is important to\nuse an appropriate set of multi-objective problems for EMO\nalgorithm design and classifier design. This is because the\nperformance of EMO algorithms (and almost all optimization\nalgorithms) depends on the problem. It is well known that\nthe performance evaluation results strongly depend on test\nproblems [8], performance indicators [9] and various param-\neter specifications such as the termination condition and the\npopulation size [10].\nRecently, the use of large language models (LLMs) in the\ndesign of new algorithms has been actively examined in the\nfield of evolutionary computation [11], [12]. In the EMO field,\nLLMs have also been used as black-box search operators\nto enhance the performance of EMO algorithms [13]–[15].\nIn [16], a new LLM-based framework was proposed to au-\ntonomously design evolutionary operators for solving multi-\nobjective optimization problems. These studies have shown\npromising results and suggested the potential of using LLMs\nto design new EMO algorithms.\nIn general, if we want to design an efficient EMO algorithm\nfor a specific application problem, we will ask LLMs to\ndesign an efficient EMO algorithm for the given application\nproblem under specific conditions (e.g., available computation\ntime). On the contrary, if we want to design a general-purpose\nEMO algorithm which is applicable to a wide variety of\nmulti-objective problems under various conditions, we will\nask LLMs to design an efficient EMO algorithm without\ngiving any particular settings for performance evaluation of\nEMO algorithms. Then, LLMs will design a high-performance\ngeneral-purpose EMO algorithm. In this case, our question is:\nWhat implicit assumptions are used in LLMs to evaluate EMO\nalgorithms?\nIn order to address this question, we use LLMs to design\na benchmarking experiment for evaluating the performance\nof EMO algorithms. Specifically, we ask LLMs to do the\nfollowing:\n1) Choice of EMO algorithms to be evaluated.\n2) Choice of test problems.\narXiv:2502.21108v1  [cs.NE]  28 Feb 2025\n\n\nFig. 1. Pareto fronts of the DTLZ2, Minus-DTLZ2, RWA2, and RWA6 problems.\n3) Choice of performance indicators including the parameter\nspecifications in each selected performance indicator.\n4) Parameter specifications in the selected EMO algorithms\nsuch as the termination condition, the population size,\nand the mutation and crossover probabilities.\nBy iterating this request, we obtain a number of benchmark-\ning experiment settings. Then we analyze the obtained settings\n(e.g., we examine which EMO algorithms and test problems\nare suggested by LLMs). Our computational experiments show\nthat somewhat classical benchmarking experimental settings\nare suggested. A typical suggestion is to examine the perfor-\nmance of NSGA-II [18], MOEA/D [19], SMS-EMOA [20] and\nNSGA-III [21] on ZDT [22], DTLZ [23], WFG [24] using the\nhypervolume indicator with a reference point r = (r, r, . . . , r)\nwhere r = 1.1, and the IGD indicator with a reference\npoint set of 10,000 uniformly generated points on the Pareto\nfront. In this paper, we report which EMO algorithms (test\nproblems, performance indicators) are frequently suggested\nby two LLMs (i.e., ChatGPT [25] and DeepSeek [26]) for\nthe benchmarking of EMO algorithms. We also report the\nsuggested specifications for EMO algorithms (e.g., population\nsize, crossover operator, crossover probability, mutation oper-\nator, mutation probability) and performance indicators (e.g.,\nreference point for HV and reference point set for IGD).\nThis paper is organized as follows. Section II provides a\nbrief overview of the key factors influencing the performance\nof EMO algorithms. Section III describes the two LLMs and\nthe methodology used in this study. Section IV presents the\nresults and analyzes the responses provided by the LLMs.\nFinally, Section V concludes the paper.\nII. PERFORMANCE EVALUATION OF EMO ALGORITHMS\nIn this section, we explain several important factors that\nhave significant effects on the performance of EMO algo-\nrithms. These factors are considered in the design of a bench-\nmarking experiment for EMO algorithms.\nA. EMO Algorithms\nWhen a new EMO algorithm is proposed, its performance\nis typically evaluated by comparing it with other EMO algo-\nrithms. The new algorithm is usually designed to outperform\nthe selected ones. Thus, the choice of algorithms to be\ncompared is important. It significantly affects the performance\nevaluation results. However, with more than a hundred EMO\nalgorithms proposed in the literature, it is very difficult to\nchoose their appropriate subset for performance evaluation in\na convincing manner. A common approach is to select the\nmost well-known algorithms along with several state-of-the-\nart algorithms. Based on the number of citations of their\noriginal papers (as shown in Table I), the following EMO\nalgorithms are frequently used in the literature: NSGA-II,\nSPEA2, MOEA/D, and NSGA-III.\nTABLE I\nNUMBER OF CITATIONS OF THE ORIGINAL PAPER FOR EACH EMO\nALGORITHM ON GOOGLE SCHOLAR (ACCESSED ON JANUARY 16, 2025)\nEMO algorithm\nNumber of citations\nNSGA-II\n59630\nSPEA2\n10540\nMOEA/D\n9799\nNSGA-III\n6336\nB. Test Problems\nTest problems also play a critical role in the performance\ncomparison of EMO algorithms. The choice of test problems\ncan lead to completely different evaluation results. Historically,\nZDT [22] and DTLZ [23] were frequently used in the 2000s.\nIn the 2010s, WFG [24] became commonly used alongside\nZDT and DTLZ. In the 2020s, various test problems, such\nas Minus-DTLZ and Minus-WFG [8], MaF [27], and real-\nworld problems [28]–[30], were increasingly used in the EMO\ncommunity in addition to ZDT, DTLZ, and WFG. This is\nbecause some recent studies have pointed out that the DTLZ\nand WFG test problems are too regular and unrealistic [17].\nAs shown in Fig. 1, the Pareto front of DTLZ2 has a triangular\nsimplex shape. In contrast, the Pareto front of Minus-DTLZ2\nis inverted triangular, which is more realistic as explained in\n[17]. The Pareto fronts of the two real-world problems (i.e.,\nRWA2 and RWA6) have irregular shapes.\nC. Performance Indicators\nAs overall performance indicators, the hypervolume (HV)\n[31] and inverted generational distance (IGD) [32] indicators\nhave been frequently used. A reference point is needed for\n\n\nFig. 2.\n(Near) Optimal HV distribution for three- and five-objective DTLZ1 and Minus-DTLZ1 with different specifications of reference point. For the\nfive-objective problems, the solutions are projected into the f1 −f2 −f3 space for better visualization.\nHV calculation, and a reference point set is needed for IGD\ncalculation. A slightly worse point than the nadir point in\nthe objective space is usually used as the reference point for\nHV. The reference point set for IGD is usually a set of a\nlarge number of uniformly sampled points on the Pareto front\n(e.g., 10,000 points). In general, the HV-based and IGD-based\nperformance comparison results depend on the specification of\nthe reference point and the reference point set, respectively.\nOne interesting observation in the literature [9] is that the\neffect of the reference point on the HV optimal solution\ndistribution is small for triangular Pareto fronts but large for\ninverted triangular Pareto fronts. Fig. 2 shows the (near) HV-\noptimal distributions of solutions obtained by SMS-EMOA\non the three-objective and five-objective DTLZ1 and Minus-\nDTLZ1 for three different reference point specifications. The\nreference point is specified as r = (r, r, . . . , r) where r = 1.1,\n1.5, and 2. We can observe the following in Fig. 2:\n(i) The reference point specification is not very important\nfor triangular Pareto fronts. For example, the HV-optimal\nsolution distribution of the three-objective DTLZ1 prob-\nlem can uniformly cover the entire Pareto front when any\nreference point with a value worse than the nadir point\n(such as r = 1.1 and 2) is used.\n(ii) The reference point specification is very important for\nirregular Pareto fronts (e.g., inverted triangular shape).\nFor example, r = 1.1 is suitable for the three-objective\nMinus-DTLZ1 problem as the HV-optimal solution dis-\ntribution covers the entire Pareto front. When r = 2,\nmany solutions lie on the boundary of the Pareto front,\nand only a small number of solutions are inside. That\nis, the HV-optimal solution distribution is sensitive to the\nreference point specification when the Pareto front shape\nis irregular.\n(iii) An appropriate specification of the reference point de-\npends on the number of objectives. r = 1.1 is suitable\nfor three-objective problems but it is too small (i.e., too\nclose to the Pareto front) in the case of five-objective\nproblems (the optimal distribution of solutions does not\nspread over the entire Pareto front when r = 1.1). It\nseems that r = 2 is a better specification than r = 1.1\nfor the five-objective problems since boundary solutions\nare obtained.\nIII. METHODOLOGY\nGenerally, large language models (LLMs) are deep neu-\nral networks that have been specifically trained on massive\namounts of text data to perform tasks related to human natural\nlanguage usage [33]. LLMs have been widely used in a variety\nof applications such as text generation, code generation, code\ncompletion, biomedicine [34]. In the field of EMO, the use\nof LLMs as evolutionary optimizers and automatic designers\nof evolutionary operators has been explored in some studies\n[13]–[16]. These studies implicitly assume that LLMs possess\nrich domain knowledge that can be used to assist or accelerate\nevolutionary processes. Thus, a natural question arises from\nthese studies: What kind of implicit knowledge do LLMs use\nto assist the search process or to help design and generate new\nEMO algorithms?\nIn this study, we attempt to answer this question by analyz-\ning the responses provided by two LLMs, namely ChatGPT-4o\n[25] and DeepSeek-V3 [26]. We choose these two LLMs based\non the following considerations:\n• The ChatGPT series is one of the most well-known\nclosed-source LLMs developed by OpenAI, and they have\n\n\nbeen used in [13]–[16]. ChatGPT-4o is the company’s\nlatest flagship model. Thus, we consider it as a represen-\ntative closed-source LLM in our study.\n• DeepSeek-V3 is a fully open-source LLM developed by\nDeepSeek, which has recently demonstrated remarkable\nperformance in terms of language understanding and rea-\nsoning capabilities. It was reported that its performance\nis comparable to leading closed-source LLMs, such as\nthe ChatGPT series [35]. Thus, we use DeepSeek-V3 as\na representative open-source LLM in our study.\nIn our experiment, we assigned the LLMs the role of an\nexpert in the EMO field and posed questions related to the\nbenchmarking of EMO algorithms in a zero-shot manner. For\neach question, we collected 10 responses from the LLMs\nto account for the stochastic nature in their outputs. For\nparameters such as temperature in the LLMs, we used the\ndefault settings provided by each LLM.\nIV. RESULTS\nIn this section, we present the results obtained from the two\nLLMs for a series of questions related to the benchmarking\nof EMO algorithms. First, we provide the following prompt\nto the LLMs to obtain general suggestions for benchmarking\nEMO algorithms:\nYou are an expert in evolutionary multi-objective optimiza-\ntion (EMO). What are your suggestions for benchmarking\nEMO algorithms? Keep your response short and concise.\nAmong the 10 responses provided by the two LLMs, the\nfollowing suggestions are almost always included:\n• Use diverse test problems\n• Include real-world problems\n• Use established performance metrics like HV and IGD\n• Conduct scalability testing for both decision and objective\nspaces\n• Ensure reproducibility\n• Perform statistical validation\n• Use visual tools like the Pareto front for interpretability\n• Perform runtime analysis\n• Perform parameter sensitivity analysis to ensure robust-\nness\nThese suggestions are reasonable and align with the current\nunderstanding in the community regarding the benchmarking\nof EMO algorithms. In the subsequent subsections, we ask the\ntwo LLMs more detailed questions related to each category,\nincluding suggestions for EMO algorithms, test problems,\nperformance indicators, and other parameter settings.\nA. Suggested EMO Algorithms\nFirst, we asked the LLMs to suggest how many EMO\nalgorithms should be included in a benchmarking experiment.\nBoth LLMs suggested including five to ten EMO algorithms\nin the experiment. Based on this suggestion, we then asked\nthe LLMs to suggest five EMO algorithms for benchmarking,\nusing the following prompt:\nTABLE II\nPERCENTAGE OF TIMES EACH ALGORITHM WAS SUGGESTED BY\nCHATGPT-4O AND DEEPSEEK-V3 IN RESPONSE TO THE REQUEST FOR\nFIVE EMO ALGORITHMS (BASED ON 10 RESPONSES PER MODEL).\nAlgorithm\nChatGPT-4o (%)\nDeepSeek-V3 (%)\nNSGA-II\n100\n100\nMOEA/D\n100\n100\nSPEA2\n100\n100\nNSGA-III\n100\n100\nRVEA\n60\n0\nR-NSGA-II\n20\n0\nHypE\n20\n60\nIBEA\n0\n40\nTABLE III\nPERCENTAGE OF TIMES EACH ALGORITHM WAS SUGGESTED BY\nCHATGPT-4O AND DEEPSEEK-V3 IN RESPONSE TO THE REQUEST FOR\nFIVE STATE-OF-THE-ART EMO ALGORITHMS (BASED ON 10 RESPONSES\nPER MODEL).\nAlgorithm\nChatGPT-4o (%)\nDeepSeek-V3 (%)\nRVEA\n100\n40\nNSGA-III\n80\n100\nMOEA/D-DRA\n80\n0\nHypE\n80\n100\nAGE-II\n60\n0\nU-NSGA-III\n40\n0\nSMS-EMOA\n30\n30\nMOEA/D-DE\n20\n70\nCMA-ES/MA\n10\n0\nMOEA/DD\n0\n30\nLMEA\n0\n40\nAR-MOEA\n0\n90\nYou are an expert in evolutionary multi-objective optimiza-\ntion (EMO). Please suggest five EMO algorithms for bench-\nmarking. Keep your response short and concise.\nTable II shows the percentage of times each algorithm\nwas included in the responses given by the LLMs. Both\nChatGPT-4o and DeepSeek-V3 consistently suggested NSGA-\nII, MOEA/D, SPEA2, and NSGA-III for benchmarking in all\nof their 10 responses. RVEA was suggested by ChatGPT-4o in\n60% of its responses, while DeepSeek-V3 did not suggest it in\nany of its 10 responses. In contrast, DeepSeek-V3 suggested\nHypE and IBEA in 60% and 40% of its responses, respectively.\nNext, we slightly modified the prompt by asking the\nLLMs to suggest “five state-of-the-art EMO algorithms” for\nbenchmarking. Table III shows the percentage of times each\nalgorithm was included in the responses given by the LLMs.\nFor ChatGPT-4o, RVEA was always suggested as a state-of-\nthe-art EMO algorithm, whereas NSGA-III and HypE were\nalways suggested by DeepSeek-V3 in all 10 responses. Based\non Table III, it seems that ChatGPT-4o and DeepSeek-V3 have\nsomewhat different knowledge about state-of-the-art EMO al-\ngorithms. For example, MOEA/D-DRA was suggested in 80%\nof the responses by ChatGPT-4o, while it was not suggested\nby DeepSeek-V3. AR-MOEA was suggested by DeepSeek-\nV3 in 90% of the responses, while it was not suggested by\nChatGPT-4o.\n\n\nTABLE IV\nPERCENTAGE OF TIMES EACH PROBLEM WAS SUGGESTED BY\nCHATGPT-4O AND DEEPSEEK-V3 IN RESPONSE TO THE REQUEST FOR\nSUGGESTING TEST PROBLEMS FOR BENCHMARKING (BASED ON 10\nRESPONSES PER MODEL).\nProblems\nChatGPT-4o (%)\nDeepSeek-V3 (%)\nZDT suite\n100\n100\nDTLZ suite\n100\n100\nWFG suite\n100\n100\nUF suite\n70\n100\nReal-world problems\n70\n0\nCEC competition problems\n50\n0\nCF suite\n10\n0\nLZ suite\n0\n100\nB. Suggested Test Problems\nTo understand the implicit knowledge in the LLMs about\nthe test problems for EMO, we asked the following question:\nYou are an expert in evolutionary multi-objective optimiza-\ntion (EMO). Please suggest test problems for benchmarking\nEMO algorithms. Keep your response short and concise.\nTable IV shows the percentage of times each test problem\nwas included in the responses given by the LLMs. The LLMs\nsuggested a number of test suites in each of the 10 responses,\nas listed in Table IV. All the ZDT, DTLZ, and WFG test suites\nare included in all the responses from both LLMs. This is not\nsurprising since these three test suites are the most well-known\nin the EMO field and have been used in many studies. It is also\ninteresting to note that there is no variation in the responses\ngiven by DeepSeek-V3: All 10 responses consistently include\nthe ZDT, DTLZ, WFG, UF, and LZ suites as the suggested test\nproblems. For ChatGPT-4o, it suggested real-world problems\nin 70% of its responses, whereas DeepSeek-V3 did not suggest\nany real-world problems. The real-world problems suggested\nby ChatGPT-4o include: portfolio optimization, vehicle rout-\ning, engineering design (e.g., gear design, truss optimization),\nknapsack problems, scheduling problems, and network routing\nproblems.\nNext, we slightly modified the prompt by specifically asking\nthe LLMs to suggest “test suites” for benchmarking. The\nresults are shown in Table V. In general, the results are\nvery similar to the results in Table IV. For DeepSeek-V3, its\nresponses are the same as those in Table IV where the ZDT,\nDTLZ, WFG, UF, and LZ suites were always suggested. The\nresponses from ChatGPT-4o were slightly different from those\nin Table IV, where the frequency of the CEC competition\nproblems and CF suites increased from 50% and 10% to 70%\nand 50%, respectively. Additionally, MaF was included in the\nresponse, while real-world problems were suggested less often\nin comparison to Table IV.\nFinally, we ask the LLMs to suggest “only one test suite” for\nbenchmarking EMO algorithms. Both the LLMs consistently\nsuggested the DTLZ suite in all their responses.\nTABLE V\nPERCENTAGE OF TIMES EACH PROBLEM SUITE WAS SUGGESTED BY\nCHATGPT-4O AND DEEPSEEK-V3 IN RESPONSE TO THE REQUEST FOR\nSUGGESTING TEST SUITES FOR BENCHMARKING (BASED ON 10\nRESPONSES PER MODEL).\nTest suite\nChatGPT-4o (%)\nDeepSeek-V3 (%)\nZDT suite\n100\n100\nDTLZ suite\n100\n100\nWFG suite\n100\n100\nUF suite\n70\n100\nCEC competition problems\n70\n0\nCF suite\n50\n0\nMaF suite\n30\n0\nReal-world problems\n20\n0\nLZ suite\n0\n100\nTABLE VI\nPERCENTAGE OF TIMES EACH PERFORMANCE INDICATOR WAS\nSUGGESTED BY CHATGPT-4O AND DEEPSEEK-V3 IN RESPONSE TO THE\nREQUEST FOR SUGGESTING PERFORMANCE INDICATORS FOR\nBENCHMARKING (BASED ON 10 RESPONSES PER MODEL).\nPerformance indicator\nChatGPT-4o (%)\nDeepSeek-V3 (%)\nHV\n100\n100\nIGD\n100\n100\nϵ-indicator\n90\n100\nSpacing\n80\n40\nComputational time\n50\n0\nSpread\n30\n100\nGD\n30\n60\nConvergence metric\n10\n0\nR2\n10\n0\nC. Suggested Performance Indicators\nIn this subsection, we focus on the performance indicators\nfor evaluating EMO algorithms. We first asked the LLMs\nto suggest performance indicators for benchmarking EMO\nalgorithms, using the following prompt:\nYou are an expert in evolutionary multi-objective optimiza-\ntion (EMO). Please suggest performance indicators for\nbenchmarking EMO algorithms. Keep your response short\nand concise.\nTable VI shows the percentage of times each performance\nindicator was included in the responses given by the LLMs.\nFor ChatGPT-4o, HV and IGD were always suggested, while\nϵ-indicator and spread were included in 90 % and 80% of\nthe responses, respectively. For DeepSeek-V3, HV, IGD, ϵ-\nindicator, and spread were always included in the responses.\nAgain, we observe that the responses from ChatGPT-4o and\nDeepSeek-V3 are slightly different. Compared to DeepSeek-\nV3, ChatGPT-4o suggested more indicators, including compu-\ntational time, convergence metric, and R2.\nNext, we asked the LLMs to suggest “only a single per-\nformance indicator” for benchmarking EMO algorithms using\nthe following prompt:\n\n\nFig. 3. Two Pareto-optimal solution sets with different solution distributions for the normalized ten-objective Minus-DTLZ1 problem, each containing 275\nsolutions.\nYou are an expert in evolutionary multi-objective optimiza-\ntion (EMO). I want to use a single performance indicator\nfor benchmarking EMO algorithms. Could you suggest an\nappropriate one? Keep your response short and concise.\nBoth LLMs consistently suggested HV as the most appro-\npriate performance indicator in all 10 responses. The LLMs\nincluded the following reason for the suggestion of HV in\ntheir responses: “HV can comprehensively assess both the\nconvergence and diversity of a solution set simultaneously”.\nThis aligns with knowledge in the EMO community, where\nHV is primarily used because it is the only Pareto-compliant\nindicator. However, the explanation about “Pareto-compliant”\nwas not included in the responses.\n1) Suggested reference point for HV: Since the calculation\nof HV requires the specification of a reference point, we\nfurther asked the LLMs to provide suggestions on how to\nspecify a reference point for benchmarking EMO algorithms.\nIn general, both LLMs suggested choosing a point slightly\nworse than the nadir point of the problem, with the common\npractice of adding a small offset (e.g., 10% or 20%) to the\nnadir point. Normalization of the objective space for HV\ncalculation was suggested in some of their responses. In that\ncase, a reference point of (1.1, ..., 1.1) was suggested.\nNext, we asked the LLMs to suggest the reference point\nspecification for two-objective, three-objective, five-objective\nand ten-objective problems after normalizing the objective\nspace so that the ideal point is (0, ..., 0) and the nadir point is\n(1, . . . , 1). The population size for each number of objectives is\nalso provided in the prompt. For two-objective, three-objective,\nfive-objective, and ten-objective problems, with the population\nsizes are about 100, 100, 120, and 275, respectively. The\nprompt for asking the reference point specification for two-\nobjective problems is shown as follows:\nYou are an expert in evolutionary multi-objective optimiza-\ntion (EMO). For hypervolume calculation, how to specify a\nreference point for a 2-objective problem after the normal-\nization of the objective space so that the ideal point is (0, 0,\n. . . , 0) and the nadir point is (1, 1, ..., 1). The population\nsize is about 100. Keep your response short and concise.\nIn all responses given by the two LLMs, the suggested\nreference points were (1.1, ..., 1.1) for two-objective, three-\nobjective, five-objective, and ten-objective problems. Whereas\n(1.1, ..., 1.1) is a frequently-used reference point, it is not\nalways appropriate especially for many-objective problems, as\nwe have explained in Section II.C. It should also be noted\nthat it is needed to use a different reference point specification\ndepending on the population size and the number of objectives,\nas highlighted in a recent study [9]. In order to obtain more\nreasonable comparison results using HV, the following refer-\nence point specification method in the normalized objective\nspace was proposed in [9]:\nr = 1 + 1/H.\n(1)\nThe value of H is specified based on the following formula-\ntion:\nCH+m−1\nm−1\n≤N < CH+m\nm−1 ,\n(2)\nwhere m is the number of objectives and N is the population\nsize. As an example, given a solution set with 275 solutions\n(i.e., N = 275) for a ten-objective problem, we can obtain\nH = 3, and the reference point should be specified as (4/3,\n..., 4/3).\nFig. 3 provides an example that demonstrates the importance\nof using an appropriate reference point specification based on\nthe population size. In Fig. 3, both Solution Set A and Solution\nSet B are Pareto-optimal solution sets, each containing 275\nsolutions. By visual evaluation, it is clear that A is better than\nB, since A covers the entire Pareto front, while B covers only\nthe inside solutions. However, using the reference point (1.1,\n..., 1.1), B is evaluated as better than A: HV(B) = 2.3975 ×\n10−6 > HV(A) = 1.3264 × 10−6. When the reference point\nis specified as (4/3, ..., 4/3), A is evaluated as better than\nB: HV(A) = 0.0054 > HV(B) = 0.0035. Thus, the reference\npoint specification proposed in [9] leads to more intuitively\nacceptable comparison results, whereas such a specification\nwas not suggested by the two LLMs.\n2) Suggested reference point set for IGD: In addition to\nHV, IGD is another frequently-used indicator in the EMO field.\nA reference point set is required for the calculation of the IGD\nvalue. In order to understand what are the knowledge of the\n\n\nLLMs regarding the specification of the reference point set for\nIGD, we ask the following question:\nYou are an expert in evolutionary multi-objective optimiza-\ntion (EMO). Please suggest how to specify a reference\npoint set for IGD calculation when benchmarking EMO\nalgorithms. Keep your response short and concise.\nIn general, both LLMs include the following suggestions\nfor specifying the IGD reference point set in their responses:\n• If the the true Pareto is available, use a well-distributed\n(uniformly-distributed) set sampled from the true Pareto\nfront.\n• If the true Pareto front is not available, approximate the\ntrue Pareto front by combining non-dominated solutions\nfrom all algorithms and sampling uniformly.\n• Ensure the reference set is sufficiently large (e.g., 1,000\nto 10,000 points) to accurately represent the Pareto front.\nNext, we asked the LLMs to suggest how many reference\npoints are needed in the reference point set. When the prompt\ndid not explicitly mention the number of objectives, both\nLLMs suggested using 1,000 to 10,000 uniformly distributed\nreference points on the Pareto front in most of their responses.\nThen, we explicitly asked the LLMs to suggest the number\nof reference points for two-objective, three-objective, five-\nobjective, and ten-objective problems.\nFor ChatGPT-4o, the following number of reference points\nwere suggested (summarized based on ten responses):\n• Two-objective: 500 to 10,000 points\n• Three-objective: 5,000 to 10,000 points\n• Five-objective: 20,000 to 100,000 points\n• Ten-objective: 500,000 to 1,000,000 or more points\nFor DeepSeek-V3, the following number of reference points\nwere suggested (summarized based on ten responses):\n• Two-objective: 1,000 to 10,000 points\n• Three-objective: 10,000 to 50,000 points\n• Five-objective: 50,000 to 100,000 points\n• Ten-objective: 100,000 to 1,000,000 points\nThese responses show that both LLMs understand the need\nfor a large number of uniformly distributed reference points\nfor IGD calculation. They also understand the importance of\nscaling the number of reference points based on the number\nof objectives. As a result, the number of reference points is\nadjusted accordingly for a different number of objectives.\nHowever, it is worth mentioning that the use of a large\nnumber of uniformly distributed reference points can lead\nto counterintuitive performance comparison results in many-\nobjective cases. A solution set with smaller diversity can\nhave a better (i.e., smaller) IGD value than a well-distributed\nsolution set over the entire Pareto front due to the bias of the\nIGD indicator (i.e., no boundary solutions are included in the\noptimal distribution of solutions for the IGD indicators), as\nexplained in [36].\nD. Suggested Parameter Values in EMO Algorithms\nFinally, in this subsection, we aim to understand the knowl-\nedge of parameter values in EMO algorithms from the two\nLLMs, particularly about the population size specification, and\nthe choice of crossover and mutation operators.\n1) Population size: We asked the LLMs how to determine\nthe population size for EMO algorithms and requested that\nthey suggest the population size for two-objective, three-\nobjective, five-objective, and ten-objective problems for bench-\nmarking EMO algorithms, respectively. Both LLMs explained\nthat the population size for EMO algorithms typically depends\non the number of objectives and the problem’s complexity.\nThey also explained that a larger population size is needed for\nhigher-dimensional objective spaces to help maintain diversity.\nFor ChatGPT-4o, the suggested population sizes are sum-\nmarized based on its ten responses as follows:\n• Two-objective: 100 to 300 individuals\n• Three-objective: 120 to 500 individuals\n• Five-objective: 200 to 1,000 individuals\n• Ten-objective: 500 to 5,000 individuals\nFor DeepSeek-V3, the suggested population sizes are sum-\nmarized based on its ten responses as follows:\n• Two-objective: 100 to 200 individuals\n• Three-objective: 120 to 300 individuals\n• Five-objective: 200 to 500 individuals\n• Ten-objective: 300 to 1,000 individuals\nAs we can see, the suggested population sizes are scaled\nup based on the number of objectives, with up to 5,000\nsuggested by ChatGPT-4o for ten-objective problems. While\nthese suggestions seem reasonable, in the EMO community,\na population size of less than 300 (with many studies using\n275) is typically used for ten-objective problems. This is\nbecause using a large population size (e.g., 5,000) means a\nsmall number of generations (which often deteriorates the\nperformance of many EMO algorithms) when the total number\nof solution evaluations is used as the termination condition.\n2) Crossover operators: Next, we asked the LLMs for\nsuggestions on selecting the crossover operator and proba-\nbility. Both LLMs included the simulated binary crossover\n(SBX) and uniform crossover in their responses. However,\nChatGPT-4o occasionally incorrectly explained that SBX is\nfor binary-coded problems, whereas SBX is actually used\nfor real-coded problems. In addition, ChatGPT-4o suggested\nother crossover operators, such as the blend crossover and\ndifferential evolution crossover, with the crossover probability\nbetween 0.8 and 1.0 in most of its responses. As for DeepSeek-\nV3, it consistently suggested SBX crossover (for real-coded\nproblems) and uniform crossover (for binary-coded problems)\nin all ten responses, with a crossover probability of 0.9.\n3) Mutation operators: For the choice of mutation opera-\ntors and mutation probability, both LLMs consistently sug-\ngested polynomial mutation (for real-coded problems) and\nbit-flip mutation (for binary-coded problems) in all their\nresponses. Additionally, ChatGPT-4o suggested other mutation\n\n\noperators, including Gaussian mutation and non-uniform muta-\ntion, in some of its responses. As for the mutation probability,\nChatGPT-4o suggested setting it between 0.01 and 0.1 in most\nof its responses. For DeepSeek-V3, the mutation probability\nwas suggested to be set as 1/n, where n is the number of\ndecision variables.\nV. CONCLUDING REMARKS\nIn order to understand the implicit knowledge used in LLMs\nfor designing EMO algorithms, this study asked two large\nlanguage models (LLMs) for their suggestions on benchmark-\ning EMO algorithms. As shown by the results presented in\nthis paper, the LLMs suggest historically widely-used settings\nfor benchmarking. Whereas those settings have been used\nin many papers in the literature, they are not necessarily\ngood settings in many points such as the reality of test\nproblems and the reference point (set) specification for HV\n(IGD) calculation. Our results may imply that the LLM-based\ngeneral purpose automated algorithm design will be adjusted\nto the suggested settings, which may mean that the designed\nalgorithm works very well on the suggested test problems\nbased on the suggested performance evaluation mechanisms.\nWe hope that LLMs will suggest better settings in the near\nfuture.\nREFERENCES\n[1] T. St¨utzle and M. L´opez-Ib´a˜nez, “Automated design of metaheuristic\nalgorithms,” Handbook of Metaheuristics, pp. 541-579, 2018.\n[2] L. C. T. Bezerra, M. L´opez-Ib´a˜nez, and T. St¨utzle, “Automatically design-\ning state-of-the-art multi-and many-objective evolutionary algorithms,”\nEvolutionary Computation, vol. 28, pp. 195-226, 2020.\n[3] C. P. Almeida, R. A. Gonc¸alves, S. Venske, R. L¨uders, and M. Delgado,\n“Hyper-heuristics using multi-armed bandit models for multi-objective\noptimization,” Applied Soft Computing, vol. 95, Article 106520, 2020.\n[4] J. Heise and S. Mostaghim, “Online learning hyper-heuristics in multi-\nobjective evolutionary algorithms,” in Proceedings of the International\nConference on Evolutionary Multi-Criterion Optimization, 2023, Leiden,\nThe Netherlands, pp. 162-175.\n[5] A. J. Nebro, M. L´opez-Ib´a˜nez, J. Garc´ıa-Nieto, and C. A. Coello Coello,\n“On the automatic design of multi-objective particle swarm optimizers:\nexperimentation and analysis,” Swarm Intelligence, vol. 18, pp. 105-139,\n2024.\n[6] K. Xue, R-X. Tan, X. Huang, and C. Qian, “Offline multi-objective\noptimization,” In Proceedings of the 41st International Conference on\nMachine Learning (ICML’24), 2024, Vienna, Austria, pp. 55595-55624.\n[7] Y. Tian, S. Peng, T. Rodemann, X. Zhang, and Y. Jin, “Automated\nselection of evolutionary multi-objective optimization algorithms,” in\nProceedings of the 2019 IEEE Symposium Series on Computational\nIntelligence (SSCI), 2019, Xiamen, China, pp. 3225-3232.\n[8] H. Ishibuchi, Y. Setoguchi, H. Masuda, and Y. Nojima, “Performance\nof decomposition-based many-objective algorithms strongly depends on\nPareto front shapes,” IEEE Transactions on Evolutionary Computation,\nvol. 21, no. 2, pp. 169-190, 2017.\n[9] H. Ishibuchi, R. Imada, Y. Setoguchi, and Y. Nojima, “How to specify a\nreference point in hypervolume calculation for fair performance compar-\nison,” Evolutionary Computation, vol. 26, no. 3, pp. 411-440, 2018.\n[10] H. Ishibuchi, L. M. Pang, and K. Shang, “Difficulties in fair perfor-\nmance comparison of multi-objective evolutionary algorithms [research\nfrontier],” IEEE Computational Intelligence Magazine, vol. 17, no. 1, pp.\n86-101, 2022.\n[11] N. van Stein and T. B¨ack, “LLaMEA: A Large Language Model\nEvolutionary Algorithm for Automatically Generating Metaheuristics”, in\nIEEE Transactions on Evolutionary Computation, 2004 (Early Access).\n[12] X. Wu, S-H. Wu, J. Wu, L. Feng, K. C. Tan, “Evolutionary computation\nin the era of large language model: survey and roadmap,” in IEEE\nTransactions on Evolutionary Computation, 2004 (Early Access).\n[13] F. Liu, Z. Wang, S. Yao, X. Tong, M. Yuan, and Q. Zhang, “Large\nlanguage model for multi-objective evolutionary optimization,” arXiv\npreprint arXiv:2310.12541, 2024.\n[14] W. Liu, L. Chen, and Z. Tang, “Large language model aided multi-\nobjective evolutionary algorithm: a low-cost adaptive approach,” arXiv\npreprint arXiv:2410.02301, 2024.\n[15] Z. Wang, S. Liu, and K. C. Tan, “Large language model-aided evolution-\nary search for constrained multiobjective optimization,” in Proceedings of\nInternational Conference on Intelligent Computing (ICIC 2024)), 2024,\npp 218-230.\n[16] Y. Huang, S. Wu, W. Zhang, J. Wu, L. Feng, and K. C. Tan,\n“Autonomous multi-objective optimization using large language model,”\narXiv preprint arXiv:2406.08987, 2024.\n[17] H. Ishibuchi, L. He, and K. Shang, “Regular Pareto front shape is\nnot realistic,” in Proceedings of 2019 IEEE Congress on Evolutionary\nComputation (CEC), 2019, Wellington, New Zealand, pp. 2034-2041.\n[18] K. Deb, A. Pratap, S. Agarwal, and T. Meyarivan, “A fast and elitist\nmultiobjective genetic algorithm: NSGA-II,” IEEE Transactions on Evo-\nlutionary Computation, vol. 6, no. 2, pp. 182-197, 2002.\n[19] Q. Zhang and H. Li, “MOEA/D: A multiobjective evolutionary algorithm\nbased on decomposition,” IEEE Transactions on Evolutionary Computa-\ntion, vol. 11, no. 6, pp. 712-731, 2007.\n[20] N. Beume, B. Naujoks, M. Emmerich, “SMS-EMOA: multiobjective\nselection based on dominated hypervolume,” European Journal of Oper-\national Research, vol. 181, no. 3, pp. 1653-1669, 2007.\n[21] K. Deb and H. Jain, “An evolutionary many-objective optimization\nalgorithm using reference-point-based nondominated sorting approach,\npart I: solving problems with box constraints,” IEEE Transactions on\nEvolutionary Computation, vol. 18, no. 4, pp. 577-601, 2014.\n[22] E. Zitzler, K. Deb, and L. Thiele, “Comparison of multiobjective\nevolutionary algorithms: empirical results,” Evolutionary Computation,\nvol. 8, no. 2, pp. 173-195, 2000.\n[23] K. Deb, L. Thiele, M. Laumanns, and E. Zitzler, “Scalable test problems\nfor evolutionary multiobjective optimization,” Advanced Information and\nKnowledge Processing: Evolutionary Multi-objective Optimization, pp.\n105-145, Springer, London, 2005.\n[24] S. Huband, P. Hingston, L. Barone, and L. While, “A review of\nmultiobjective test problems and a scalable test problem toolkit,” IEEE\nTransactions on Evolutionary Computation, vol. 10, no. 5, pp. 477-506,\n2006.\n[25] OpenAI, “ChatGPT-4o,” [Online]. Available: https://platform.openai.\ncom/docs/models/gpt-4o. [Accessed: Jan. 15, 2025].\n[26] DeepSeek, “DeepSeek V3,” [Online]. Available: https://github.com/\ndeepseek-ai/DeepSeek-V3. [Accessed: Jan. 15, 2025].\n[27] R. Cheng et al., “A benchmark test suite for evolutionary many-objective\noptimization,” Complex & Intelligent Systems, vol. 3, pp. 67-81, 2017.\n[28] R. Tanabe and H. Ishibuchi, “An easy-to-use real-world multi-objective\noptimization problem suite,” Applied Soft Computing, vol. 89, 2020,\nArticle no. 106078.\n[29] C. He, Y. Tian, H. Wang, and Y. Jin, “A repository of real-world datasets\nfor data-driven evolutionary multiobjective optimization,” Complex &\nIntelligent Systems, vol. 6, pp. 189-197, 2020.\n[30] S. Zapotecas-Mart´ınez, A. Abel Garc´ıa-N´ajera, and A. Menchaca-\nM´endez, “Engineering applications of multi-objective evolutionary algo-\nrithms: a test suite of box-constrained real-world problems,” Engineering\nApplications of Artificial Intelligence, vol. 123, Part A, Article No.\n106192, 2023.\n[31] E. Zitzler and L. Thiele, “Multiobjective optimization using evolutionary\nalgorithms – A comparative case study,” Lecture Notes in Computer\nScience 1498: Parallel Problem Solving from Nature – PPSN V, pp. 292-\n301, Springer, Berlin, 1998.\n[32] C. A. Coello Coello and M. Reyes Sierra, “A study of the parallelization\nof a coevolutionary multi-objective evolutionary algorithm,” in Proceed-\nings of Mexican International Conference on Artificial Intelligence, 2004,\npp. 688–697.\n[33] M. Shanahan, “Talking about large language models,” Communications\nof the ACM, vol. 67, no. 2, pp. 68-79, 2024.\n[34] P. Kumar, “Large language models (LLMs): survey, technical frame-\nworks, and future challenges,” Artificial Intelligence Review, vol. 57,\nArticle No. 260, 2024.\n[35] DeepSeek-AI,\n“DeepSeek-V3\ntechnical\nreport,”\narXiv\npreprint\narXiv:2412.19437v1, 2024.\n[36] H. Ishibuchi, R. Imada, Y. Setoguchi, and Y. Nojima, ”Reference point\nspecification in inverted generational distance for triangular linear Pareto\n\n\nfront,” IEEE Transactions on Evolutionary Computation, vol. 22, no. 6,\npp. 961-975, 2018.\n\n\n",
  "metadata": {
    "source_file": "dataset/pdfs/arxiv_2502.21108v1.pdf",
    "total_pages": 9,
    "title": "Large Language Model-Based Benchmarking Experiment Settings for Evolutionary Multi-Objective Optimization",
    "authors": [
      "Lie Meng Pang",
      "Hisao Ishibuchi"
    ],
    "abstract": "When we manually design an evolutionary optimization algorithm, we implicitly\nor explicitly assume a set of target optimization problems. In the case of\nautomated algorithm design, target optimization problems are usually explicitly\nshown. Recently, the use of large language models (LLMs) for the design of\nevolutionary multi-objective optimization (EMO) algorithms have been examined\nin some studies. In those studies, target multi-objective problems are not\nalways explicitly shown. It is well known in the EMO community that the\nperformance evaluation results of EMO algorithms depend on not only test\nproblems but also many other factors such as performance indicators, reference\npoint, termination condition, and population size. Thus, it is likely that the\ndesigned EMO algorithms by LLMs depends on those factors. In this paper, we try\nto examine the implicit assumption about the performance comparison of EMO\nalgorithms in LLMs. For this purpose, we ask LLMs to design a benchmarking\nexperiment of EMO algorithms. Our experiments show that LLMs often suggest\nclassical benchmark settings: Performance examination of NSGA-II, MOEA/D and\nNSGA-III on ZDT, DTLZ and WFG by HV and IGD under the standard parameter\nspecifications.",
    "published_date": "2025-02-28",
    "source": "arxiv"
  }
}