{
  "id": "arxiv_2502.21048v1",
  "text": "Data-free Universal Adversarial Perturbation with Pseudo-semantic Prior\nChanhui Lee\nYeonghwan Song\nJeany Son\nas584868@gm.gist.ac.kr\nyeonghwan.song@gm.gist.ac.kr\njeany@gist.ac.kr\nAI Graduate School, GIST\nAbstract\nData-free Universal Adversarial Perturbation (UAP) is\nan image-agnostic adversarial attack that deceives deep\nneural networks using a single perturbation generated\nsolely from random noise, without any data priors. How-\never, traditional data-free UAP methods often suffer from\nlimited transferability due to the absence of semantic in-\nformation in random noise. To address this, we propose a\nnovel data-free universal attack approach that generates a\npseudo-semantic prior recursively from the UAPs, enrich-\ning semantic contents within the data-free UAP framework.\nOur method is based on the observation that UAPs inher-\nently contain latent semantic information, enabling the gen-\nerated UAP to act as an alternative data prior, by capturing\na diverse range of semantics through region sampling. We\nfurther introduce a sample reweighting technique to empha-\nsize hard examples by focusing on samples that are less af-\nfected by the UAP. By leveraging the semantic information\nfrom the pseudo-semantic prior, we also incorporate input\ntransformations, typically ineffective in data-free UAPs due\nto the lack of semantic content in random priors, to boost\nblack-box transferability. Comprehensive experiments on\nImageNet show that our method achieves state-of-the-art\nperformance in average fooling rate by a substantial mar-\ngin, significantly improves attack transferability across var-\nious CNN architectures compared to existing data-free UAP\nmethods, and even surpasses data-dependent UAP methods.\n1. Introduction\nDeep neural networks (DNNs) have become widely used in\ncomputer vision, achieving remarkable performance across\na diverse range of tasks, such as image classification [7, 34],\nobject detection [25, 26], semantic segmentation [27], and\nvisual tracking [1, 42]. Despite these successes, DNNs are\nvulnerable to carefully crafted, imperceptible perturbations\nin input data, causing the model to make highly confident\nyet incorrect predictions. This vulnerability poses signifi-\ncant challenges for deploying DNNs in critical applications,\nsuch as autonomous driving [5] and security systems [2],\nDogsled: 42.8%\nGrey whale: 26.4%\nSki: 99.9%\nSki: 96.7%\nPuck: 70.6%\nBrain coral: 53.0%\nSlot: 20.4%\nSafe: 75.8%\n(a) Whole image\n(b) Cropped and resized images\nFigure 1. Diverse semantic contents in both a real-image and UAP:\n(a) A whole image from the ImageNet dataset (top) and our gen-\nerated data-free UAP (bottom) from DenseNet-121, shown at iter-\nation 900 during the training phase. The Top-1 class and its score\nare shown below each image. (b) Cropped regions from the whole\nimage (top) and our UAP (bottom). Those regions contain diverse\nsemantics that differ from the class of the original images.\nand has led to increased research into adversarial attacks\nthat generate adversarial examples.\nTo craft the adversarial examples with high transfer-\nability across various DNN architectures, there have been\nmany adversarial attack methods using a specific target im-\nage [3, 6, 11, 18, 32, 39]. However, these methods generate\na unique perturbation for each target image, which is time-\nconsuming, impractical for real-world scenarios, and limits\ntheir generalization to other images. To tackle this limi-\ntation, the Universal Adversarial Perturbation (UAP) [19]\nintroduced an image-agnostic attack that generates a sin-\ngle image-agnostic adversarial perturbation, which is capa-\nble of attacking a wide range of unknown images. Many\nstudies [15, 22, 24, 30] focus on developing data-dependent\nUAPs that target unknown models, thereby enhancing trans-\nferability across diverse and unseen scenarios. While these\nUAPs deceive diverse categories of images with a single\nperturbation, they still rely on large-scale data samples and\ntheir labels from the target domain to capture diverse se-\nmantics, such as the ImageNet [28] dataset.\nAccessing data priors from the target domain is often\n1\narXiv:2502.21048v1  [cs.CV]  28 Feb 2025\n\n\nimpractical, leading to recent interest in data-free UAP\nmethods [12, 14, 16, 20, 21, 23, 41].\nData-free UAP\nposes a greater challenge than conventional data-dependent\nUAP generation tasks, as it restricts the employment of\nany prior knowledge of the target domain dataset. Prior\nworks [16, 20, 21] have attempted to craft UAPs from ran-\ndom noise without any dataset, by maximizing activations\nin convolutional neural networks (CNNs) layers. However,\nthese methods solely rely on random priors, such as Gaus-\nsian noise or jigsaw patterns, which lack semantic informa-\ntion and thus offer limited transferability to unseen models.\nTo overcome this limitation, several works [12, 23] utilize\nauxiliary data samples generated by optimizing against the\noutputs of a surrogate model. Although these methods al-\nlow the use of semantic information in synthetic data, the\ncrafted UAPs often show inferior transferability due to over-\nfitted data to the surrogate model.\nIn this paper, we explore how to leverage semantic in-\nformation directly from the UAP itself, without any dataset\npriors, to address these challenges. Our approach is inspired\nby the observation that even a single generated UAP con-\ntains diverse semantic information as well as its dominant\nlabel, as shown in Figure 1. We find that the generated UAP\nencodes diverse semantic features, similar to a real-world\nimage with various semantic contents across different re-\ngions.\nFor example, in Figure 1, while the whole UAP\nis predicted as ‘Safe’ due to its tendency to have a domi-\nnant label, cropped regions within the UAP are predicted\nas classes like ‘Brain coral,’ ‘Puck,’ and ‘Slot.’ This obser-\nvation motivates us to utilize UAP as a semantic prior for\ntraining within a data-free UAP framework.\nInspired by this insight, we propose a novel data-free\nUAP method, called PSP-UAP, which generates pseudo-\nsemantic priors from a UAP during training. To capture\nmore diverse semantics in pseudo-semantic priors, we ran-\ndomly crop and resize regions to extract semantic samples\nand treat them as images to fool.\nThis approach effec-\ntively addresses the data-free constraint in UAP generation\nby leveraging richer semantic information inherent in the\nUAP, rather than relying solely on random noise. How-\never, randomly cropped semantic samples often vary in in-\nformativeness, and simply averaging their activations can\ndisrupt the generation of an optimal UAP. To mitigate this\nproblem, we introduce a sample reweighting to focus on\nhard examples less deceived by an attack with a current\nUAP. To further improve the attack transferability, we in-\ncorporate input transformations [40, 43], primarily used in\nimage-specific adversarial attacks, into our data-free UAP\nframework. This approach has remained unexplored in ex-\nisting data-free UAP methods, as random priors lack se-\nmantic information, limiting its effectiveness. In contrast,\nour pseudo-semantic prior contains richer semantic content\nthan random priors, enabling improved transferability to un-\nknown models through input transformations.\nThe main contributions can be summarized as follows:\n• We propose PSP-UAP, a novel data-free universal attack\nmethod that generates pseudo-semantic priors from the\nUAP itself, using inherent semantic information of the\nUAP as an alternative data source during training.\n• Our sample reweighting method prioritizes challenging\nexamples during UAP training, minimizing the influence\nof uninformative samples that arise from random sam-\npling within our pseudo-semantic prior.\n• We are the first to incorporate input transformations\ninto the data-free UAP framework by leveraging pseudo-\nsemantic priors with diverse semantic cues, boosting\ntransferability across various CNN architectures in black-\nbox settings.\n• Our method achieves outstanding performance over the\nstate-of-the-art data-free UAP methods by a substantial\nmargin, and even outperforms existing data-dependent\nUAP methods.\n2. Related Work\nData-dependent\nUniversal\nAttack.\nData-dependent\nUAPs aim to generate a single perturbation that misleads\nany image sample.\nUAP [19] first proposed finding the\nminimal universal adversarial perturbation at each step\nby DeepFool [18] method.\nSPGD-UAP [30] combined\nthe stochastic gradient method with the projected gradient\ndescent (PGD) [17] attack method. SGA-UAP [15] used\nstochastic gradient aggregation in mini-batch to address\ngradient vanishing and quantization errors. AT-UAP [12]\nintegrated image-specific and image-agnostic attacks to\nimprove the robustness of universal perturbation. NAG [22]\nand GAP [24] applied generative adversarial frameworks to\ncraft perturbations. Although these works [15, 22, 24, 30]\nincrease the transferability of black-box attacks, they\nrequire the training dataset, making it impractical when the\nadversary does not have any prior of the target domain.\nData-free Universal Attack.\nData-free universal attack\naims to craft UAPs without any dataset to be used for\ntraining, thereby alleviating the data access requirement\npresented in data-dependent universal attacks. Generating\nUAP without prior knowledge of the target domain is more\npractical and suitable for real-world applications. Fast Fea-\nture Fool (FFF) [20] first proposed a data-free universal ad-\nversarial attack by maximizing the feature activation val-\nues of all CNN layers. Generalizable Data-free UAP (GD-\nUAP) [21] improved FFF [20] attack method with satura-\ntion check strategy on the training stage. AT-UAP [12] also\nperformed experiments in a data-free manner by applying\nadversarial attacks to random noise. Prior-Driven Uncer-\ntainty Approximation (PD-UA) [14] introduced an attack\nmethod to train UAP by maximizing the uncertainty approx-\n2\n\n\nsg\nInput \nTransfor-\nmation\nor\nRandom Prior \nℒ\nδ୲\nDKL\n-1\nDraw x from Pseudo-\nSemantic Prior\nx\n~\nSemantic Sample \n+ δ୲\nLearnable\nFrozen\nStop Gradient\n𝒜௜\n௙(·)\nSample \nReweighting\n𝒞(·)\nUAP\nFigure 2. Overall pipeline of the proposed PSP-UAP. The pseudo-semantic prior is created by adding random noise to the UAP. Semantic\nsamples are then generated by randomly cropping and resizing the pseudo-semantic prior. Input transformation is applied to both adversarial\nand clean versions of the semantic samples to calculate sample reweighting. Finally, the loss is defined as the product of sample reweighting\nand the activations of the semantic samples, from which gradients are computed to update the model.\nimation of the model with the prior patterns, and Cosine-\nUAP [41] proposed the minimizing cosine similarity to craft\nUAPs in a self-supervised manner. AAA [23] crafted class\nimpressions with logits to train a generative model to opti-\nmize UAPs. TRM-UAP [16] increased the ratio of positive\nand negative activations on the shallow convolution layers\nand adapted curriculum learning to enhance attack transfer-\nability stably. Despite employing various methods to gen-\nerate UAPs in a data-free setting, they face significant chal-\nlenges due to the lack of information on both the target mod-\nels and domains. Additionally, these works substantially\nrely on random priors to generate UAPs, and auxiliary data\ndirectly utilizes label information, leading to overfitting on\nsurrogate models.\nInput\nTransformation\nAttack.\nInput\ntransformation\nmethods have emerged as one of the effective ways to im-\nprove attack transferability in image-specific adversarial at-\ntacks. Diverse input method (DIM) [40], translate invariant\nmethod (TIM) [4], and scale invariant method (SIM) [13]\nrevealed the DNN models’ invariant properties to transfor-\nmations such as resizing, translation, and scaling before the\ngradient calculation. SIA [38] applied various transforma-\ntions to the input image while maintaining its overall struc-\nture. Admix [37] created admixed images by blending a\nsmall fraction of images from different categories into the\ninput image. Block shuffle and rotation (BSR) [36] ran-\ndomly shuffled and rotated the sub-blocks of the input im-\nage to reduce the variance in attention heatmaps across dif-\nferent models.\nL2T [43] used reinforcement learning to\nincrease the diversity of transformed images by selecting\nthe optimal transformation combinations. To fully leverage\nour pseudo-semantic prior, we incorporate input transfor-\nmations into our data-free UAP method to further enhance\nblack-box transferability.\n3. Methodology\nIn this section, we present our motivation and approach for\ngenerating the pseudo-semantic prior. We then describe our\nsample reweighting strategy for optimizing UAP, followed\nby input transformations applied to semantic samples de-\nrived from the pseudo-semantic prior.\n3.1. Preliminaries of data-free UAP\nUniversal adversarial attacks aim to optimize a single per-\nturbation δ using a model f that effectively deceives most\nof the samples I in the target domain dataset, with the pixel\nintensities of δ restricted by a constraint parameter ϵ:\nf(I + δ) ̸= f(I),\ns.t. ∥δ∥∞≤ϵ.\n(1)\nHowever, in data-free settings where the target dataset is in-\naccessible, UAPs are typically trained using simple random\npriors, such as Gaussian noises or jigsaw images [16, 41].\nGiven these random priors pz, GD-UAP [21] introduced an\nactivation maximizing loss as follows:\nL = −Ez∼pz\nL\nX\ni=1\nlog ∥Af\ni (z + δ)∥2,\n(2)\ns.t. ∥δ∥∞≤ϵ,\nwhere Af\ni (·) indicates the activation of the i-th layer of the\nsurrogate network f, L denotes the number of layers in f,\nand z represents pseudo-data sampled from a simple ran-\ndom prior distribution, pz. This loss is designed to overac-\ntivate features extracted from multiple convolutional layers\nof the surrogate model without input images. Consequently,\nthe distorted activation interferes with feature extraction,\nleading CNN models to make incorrect predictions [20, 21].\n3\n\n\n3.2. Pseudo-Semantic Prior\nAlthough data-free UAP methods [16, 21] use random pri-\nors, such as Gaussian noises or artificial jigsaw puzzles, to\nmimic the statistical properties of image datasets, they are\nstill limited by a lack of semantic information. Furthermore,\nsince UAPs are trained by maximizing activations in net-\nwork layers, they tend to overfit to surrogate models. Opti-\nmizing UAPs without semantic content and relying on acti-\nvation or outputs of surrogate networks, reduces their effec-\ntiveness in disrupting real images in unseen models, leading\nto degraded performances in black box transferability.\nTo address these issues, we aim to enhance the seman-\ntic content within a data-free UAP framework, inspired by\nprevious works [15, 16, 19, 41] that demonstrate the pres-\nence of dominant labels in generated UAPs. For instance,\nearly works [15, 19] observed that untargeted UAPs often\ncause misclassification toward a dominant label, a property\nthat also holds in data-free settings [16]. Cosine-UAP [41]\nfurther showed that the logit distribution of UAPs tends to\ndominate that of the input data x. This suggests that, al-\nthough the UAP is a subtle perturbation, it behaves like a\nsingle image with strong semantic information, guiding the\nmodel toward classification with a dominant label.\nInspired by this observation, we leverage the inherent\nsemantic information in UAPs by treating the combina-\ntion of UAP and random noise as a single image, termed\nthe pseudo-semantic prior, to resolve the lack of semantic\ncontent in data-free UAP training. As shown in Figure 1\nand Figure 3, the generated UAPs exhibit diverse seman-\ntic labels across different regions. Although regions within\nthe UAP are classified under the same label, the attention\nheatmaps generated by Grad-CAM [29] show distinct pat-\nterns, suggesting that diverse semantic patterns are embed-\nded within the UAP.\nBuilding on the above insight, we generate pseudo-data\nsamples from the pseudo-semantic prior to enrich the se-\nmantic content, which we refer to as semantic samples xn:\nx ∼px|pz,δt = {z + δt|z ∈pz},\n(3)\n{x1, x2, ..., xN} = C(x; N),\n(4)\nwhere z and δt denote random noise sampled from pz and\nthe UAP being trained in t-th iteration, respectively. The\npseudo-semantic prior px denotes a set of adversarial ex-\namples with δt derived from the random prior distribution.\nC is a sampler that draws N numbers of semantic samples\nxn from px by applying crop and resize operations. Specif-\nically, we randomly crop a region of the UAP, and resize it\nto the original scale of the UAP size. We believe that lever-\naging the generated semantic information embedded in dif-\nferent regions of the UAP provides more effective guidance\nfor successfully attacking target features than relying solely\non random noise.\n3.3. Sample Reweighting\nSemantic samples are randomly drawn from the pseudo-\nsemantic prior, leading to an imbalance in difficulty due\nto variations in semantic content; some samples are easily\nfooled by the UAP, while others are more difficult to de-\nceive. To tackle this, we propose a new sample reweighting\nmethod that prioritizes harder-to-fool samples.\nSpecifically, we compute the weight of each sample us-\ning the KL divergence between the original input and its ad-\nversarial counterpart during training. We define the original\ndistribution P and the adversarial distribution Q from each\nsemantic sample and its corresponding adversarial example\ngenerated by the current UAP, respectively, as follows:\nP(xn) = f(xn),\n(5)\nQ(xn) = f(xn + δt),\n(6)\nwhere f(·) is the temperature-scaled softmax output of a\nsurrogate model. Then, we calculate the weights of each\nsemantic sample using the KL-divergence:\nwn = DKL(P(xn)∥Q(xn))−1.\n(7)\nThe large KL-divergence value indicates that δt has signifi-\ncantly altered the distribution of xn, whereas a small value\nsuggests an ineffective attack. Thus, we take the recipro-\ncal of KL-divergence values to assign greater weights to se-\nmantic samples where the attack results in minimal distri-\nbutional change. We reweight the semantic samples using\nthe weights generated from Eq. (7), considering the influ-\nence of the UAP on each sampled xn, which enables us to\noptimize the UAP effectively.\n3.4. Input Transformation\nTo enhance black-box attack transferability, we incorporate\ninput transformation techniques into our semantic samples.\nWhile input transformation is commonly used in image-\nspecific adversarial attacks, it has been less explored in\ndata-free UAPs due to the limited semantic information in\nrandom priors. In our method, however, the semantic sam-\nples generated from pseudo-semantic priors contain diverse\nsemantic cues, making input transformations more effective\nin a data-free setting.\nFollowing L2T [43], which shows that rotation, scaling,\nand shuffling are particularly effective for improving attack\ntransferability, we randomly select one of these transforma-\ntions and apply it to each semantic sample. For rotation,\nthe angle α is drawn from a truncated normal distribution\nwithin the range −θ ≤α ≤θ. Scaling is applied with a\nuniform distribution within the bounds βlow ≤β ≤βhigh.\nShuffling involves randomly rearranging m × m blocks.\nDuring optimization, applying input transformations to our\nPSP-UAP increases the variation of semantic samples and\nenhances the black-box attack transferability.\n4\n\n\nAlgorithm 1 Pseudo-semantic Prior Universal Attack\nInput: Surrogate model f, number of semantic samples N,\nmaximum perturbation magnitude ϵ, learning rate η, maxi-\nmum iteration number T, convergence threshold Fmax, val-\nidation test hyperparameter H, saturation threshold r.\nOutput: Universal adversarial perturbation δ.\n1: Initialize δ0 ∼U(−ϵ, ϵ), t = 0, F = 0\n2: while t < T and F < Fmax do\n3:\nt = t + 1\n4:\nGenerate the random noise set z ∼pz\n5:\nUpdate pseudo-semantic prior px with δt via Eq. (3)\n6:\nSample N semantic samples xn via Eq. (4)\n7:\nSelect and apply transformation T ∈{rotation, scal-\ning, shuffling}\n8:\nCompute the weight w via Eq. (5), (6), and (7)\n9:\nCalculate the gradient ∇L of the loss in Eq. (8)\n10:\nUpdate δt = δt−1 + η · ∇L\n11:\nClip δt = min(ϵ, max(δt, −ϵ))\n12:\nCompute the saturation rate ˆr and adjust δt if r < ˆr\n13:\nif t%H == 0 then\n14:\nConduct the fooling rate test FR\n15:\nif FR is not the best fooling rate then\n16:\nF = F + 1\n17:\nend if\n18:\nend if\n19: end while\n20: return δt\n3.5. Overall Loss\nWe integrate the pseudo-semantic prior, sample reweight-\ning, and input transformation into Eq. (2) to optimize the\nproposed PSP-UAP. The final loss function of our PSP-UAP\nis defined as follows:\nL = −Ex∼px\nN\nX\nn=1\nl\nX\ni=1\nlog (wn∥Af\ni (T(xn + δt))∥2),\n(8)\nwhere Af\ni (·) denotes the activation of the i-th layer in net-\nwork f, xn represent the n-th semantic sample extracted\nfrom the pseudo-semantic prior px, δt denotes the UAP at\nthe t-th iteration, wn is the weight of xn from Eq. (7), l in-\ndicates the number of the convolutional layers used in the\nactivation sum, T(·) denotes a randomly selected transform\nfor input transformation, and N is the number of semantic\nsamples extracted from one pseudo-semantic prior.\nBy optimizing the overall loss, we fully leverage the gen-\nerated semantic samples as data to produce a highly trans-\nferable UAP, even without prior knowledge of the target do-\nmain. The overall PSP-UAP framework and detailed algo-\nrithm are shown in Figure 2 and Algorithm 1, respectively.\nBucket\nCowboy hat\nHook\nHook\nFigure 3. Semantic samples derived from an adversarial example\nduring training, along with their predicted labels and GradCAM\nheatmaps from Dense-121. Despite originating from the same ex-\nample, the variations in predicted labels and heatmaps indicate that\nthese semantic samples capture diverse semantic features.\nAttack\nAlexNet VGG16 VGG19 RN152 Google\nAvg.\nFFF [20]\n80.92\n47.10\n43.62\n-\n56.44\n-\nAAA [23]\n89.04\n71.59\n72.84\n60.72\n75.28\n73.89\nGD-UAP [21]\n85.24\n90.01\n87.34\n45.96\n45.87\n70.88\nPD-UAP [14]\n-\n70.69\n64.98\n46.39\n67.12\n-\nCosine-UAP [41]\n91.07\n89.48\n86.81\n65.35\n87.57\n84.05\nAT-UAP-U [12]\n96.66\n94.50\n92.85\n73.15\n82.60\n87.95\nTRM-UAP [16]\n93.53\n94.30\n91.35\n67.46\n85.32\n86.39\nPSP-UAP (Ours)\n91.77\n96.26\n94.65\n85.65\n81.43\n89.95\nTable 1. FR (%) of our PSP-UAP and other data-free universal\nattack methods for white-box attacks.\n4. Experiments\nExperimental Setup.\nWe follow the experiment setup in\nexisting data-free universal attacks [16, 21] to evaluate the\nperformance of our PSP-UAP. We evaluate the proposed\nmethod on ImageNet [28] validation set with five ImageNet\npre-trained CNN models, AlexNet [10], VGG16 [31],\nVGG19 [31], ResNet152 (RN152) [7], and GoogleNet [33],\nwhich are commonly used in data-free UAP methods.\nWe further explore four additional CNN models including\nDenseNet121 [9], MobileNet-v3-Large [8], ResNet50 [7],\nand Inception-v3 [35], pre-trained on ImageNet dataset.\nEvaluation Metrics.\nTo effectively evaluate the attack\nperformance of our proposed method, we use the fool-\ning rate (FR) which is widely used in universal attacks\n[16, 19]. FR indicates the proportion of samples with label\nchanges when applying UAP.\nBaselines.\nThe proposed method is compared with the\nfollowing data-free universal attacks, including FFF [20],\nGD-UAP [21],\nPD-UA [14],\nCosine-UAP [41],\nAT-\nUAP [12], and TRM-UAP [16]. Since AT-UAP includes\nboth data-free (AT-UAP-U) and data-dependent (AT-UAP-\n5\n\n\nModel\nAttack\nAlexNet\nVGG16\nVGG19\nResNet152\nGoogleNet\nAverage\nAlexNet\nAT-UAP-U\n96.66±0.12*\n72.33±0.50\n67.24±0.18\n43.63±0.29\n62.01±0.32\n68.37\nTRM-UAP\n93.53±0.07*\n60.10±0.24\n57.08±0.15\n27.31±0.30\n32.70±0.22\n54.14\nPSP-UAP (Ours)\n91.77±0.32*\n76.56±0.67\n74.07±0.54\n49.20±1.12\n66.00±0.75\n71.52\nVGG16\nAT-UAP-U\n54.15±0.70\n94.50±0.21*\n86.65±0.70\n36.96±1.03\n48.53±1.32\n64.16\nTRM-UAP\n47.53±0.51\n94.30±0.12*\n89.68±0.14\n61.43±0.40\n53.95±0.59\n69.38\nPSP-UAP (Ours)\n50.40±0.53\n96.26±0.21*\n92.60±0.33\n74.10±1.10\n64.89±0.66\n75.65\nVGG19\nAT-UAP-U\n62.05±1.01\n88.96±0.50\n92.85±0.48*\n42.72±0.51\n60.99±1.41\n69.51\nTRM-UAP\n46.01±0.44\n89.82±0.15\n91.35±0.30*\n47.19±0.46\n46.48±0.78\n64.17\nPSP-UAP (Ours)\n48.93±0.72\n94.55±0.14\n94.65±0.10*\n67.13±1.37\n58.83±1.19\n72.81\nResNet152\nAT-UAP-U\n49.78±0.68\n62.78±0.71\n60.54±0.49\n73.15±1.15*\n48.37±0.49\n58.92\nTRM-UAP\n53.56±0.75\n77.20±0.35\n73.30±0.41\n67.46±0.35*\n57.54±0.50\n65.81\nPSP-UAP (Ours)\n58.82±1.17\n88.59±1.38\n87.35±0.92\n85.65±1.70*\n76.00±1.33\n79.28\nGoogleNet\nAT-UAP-U\n55.65±0.37\n71.38±0.83\n68.25±0.59\n43.03±0.42\n82.60±0.72*\n64.18\nTRM-UAP\n60.10±1.16\n79.66±0.95\n79.98±1.06\n58.85±1.94\n85.32±0.04*\n72.78\nPSP-UAP (Ours)\n65.22±0.56\n78.43±0.73\n79.26±0.73\n57.63±0.66\n81.43±0.49*\n72.39\nTable 2. Black-box attack transferability of the UAP synthesized by our PSP-UAP method compared to other data-free universal attacks,\nAT-UAP-U [12] and TRM-UAP [16]. We show the mean and standard deviation of FR with five runs. Bold FR (%) denotes the best\nperformance. The UAPs are crafted on AlexNet, VGG16, VGG19, ResNet152, and GoogleNet. * indicate FR of the white-box model.\nModel\nAttack\nResNet50\nDenseNet121\nMobileNet-v3-L\nInception-v3\nAverage\nResNet50\nTRM-UAP\n73.26±0.82*\n54.42±1.23\n61.25±1.48\n37.36±0.69\n56.57\nPSP-UAP (Ours)\n77.60±0.42*\n66.11±0.87\n70.50±1.10\n42.32±1.32\n64.13\nDenseNet121\nTRM-UAP\n35.24±2.55\n70.10±2.07*\n34.17±1.77\n32.11±2.38\n42.91\nPSP-UAP (Ours)\n53.03±0.90\n85.81±1.17*\n50.22±0.58\n50.73±0.78\n59.95\nMobileNet-v3-L\nTRM-UAP\n39.47±1.11\n40.37±0.47\n73.07±0.96*\n30.11±0.81\n45.76\nPSP-UAP (Ours)\n54.38±1.40\n54.62±1.82\n90.39±0.23*\n46.29±0.69\n61.42\nInception-v3\nTRM-UAP\n53.53±0.57\n54.93±0.54\n67.16±0.60\n64.22±0.33*\n59.96\nPSP-UAP (Ours)\n57.60±0.26\n57.50±0.59\n70.20±0.56\n65.38±0.51*\n62.67\nTable 3. FR (%) for the UAPs crafted by TRM-UAP [16] and our PSP-UAP across additional CNN models. The UAPs are crafted on\nResNet50, DenseNet121, MobileNet-v3-Large, and Inception-v3. * indicates the white-box model.\nS) versions, we evaluate both in our experiments. We also\ncompared our method with SGA-UAP [15] which is one of\nthe state-of-the-art data-dependent universal attacks.\nImplementation Details.\nOur experiments are imple-\nmented on PyTorch with a single NVIDIA A6000 GPU.\nWe set ϵ = 10/255 to restrict ℓ∞-norm, the maximum\niteration T as 10, 000, and the saturation threshold r to\n0.001%, following the setting in TRM-UAP [16, 21]. For\ninput transformations, we set θ = 6 for rotation, βlow\n= 0.8 and βhigh = 4 for scaling, and m = 2 for ran-\ndom shuffling.\nMoreover, the number of semantic sam-\nples N is set to 10. We define temperature parameter τ ∈\n{1.0, 5.0, 5.0, 3.0, 5.0} corresponding to AlexNet, VGG16,\nVGG19, ResNet152, GoogleNet. For the additional CNN\nmodels, we set τ ∈{3.0, 10.0, 2.0, 3.0} corresponding to\nResNet50, DenseNet121, MobileNet-v3-Large, Inception-\nv3. We follow the same curriculum learning and saturation\ncheck strategy of TRM-UAP. We set different ratios to use\nthe activation of intermediate layers across different mod-\nels. To ensure a fair evaluation, we find the optimal pa-\nrameters for TRM-UAP on RN50, DN121, MB-v3-L, and\nInc-v3 through our best efforts.\n4.1. Evaluation on White-Box Attack\nWe first evaluate UAPs generated by our PSP-UAP on vari-\nous CNN models under the white-box setting. We compare\nthe attack performance of our UAPs with other data-free\nuniversal attacks on the ImageNet validation set, as shown\nin Table 1. While the FR on AlexNet and GoogleNet is\nslightly lower than other methods, our approach achieves\nthe highest average FR across all universal attack meth-\nods. Notably, the improvement on ResNet152 is substan-\ntial, with a 12.5% increase in the FR, demonstrating that\nour PSP-UAP performs exceptionally well, particularly on\ndeeper and more complex CNN models.\n4.2. Evaluation on Black-Box Attack\nComparison with SoTA Data-free UAPs.\nWe evaluate\nthe transferability of our UAPs on commonly used CNN\nmodels in the black-box scenario. Table 2 represents the\nattack performance across different settings, with columns\nrepresenting target models and rows indicating surrogate\nmodels used for crafting the UAPs. As shown in Table 2,\nPSP-UAP achieves superior results than other data-free at-\ntack methods across most models, with performance com-\n6\n\n\nModel\nData\nAttack\nAlexNet\nVGG16\nVGG19\nResNet152\nGoogleNet\nAverage\nAlexNet\n✓\nSGA-UAP\n97.43*\n66.41\n60.96\n35.76\n49.71\n62.05\nAT-UAP-S\n97.01±0.11*\n62.37±1.37\n57.72±0.62\n33.40±0.77\n47.31±1.65\n59.56\n✗\nPSP-UAP (Ours)\n91.77±0.32*\n76.56±0.67\n74.07±0.54\n49.20±1.12\n66.00±0.75\n71.52\nVGG16\n✓\nSGA-UAP\n49.02\n98.36*\n94.17\n49.02\n55.78\n69.27\nAT-UAP-S\n45.58±0.29\n97.51±0.08*\n91.53±0.22\n47.16±0.95\n53.63±0.90\n67.08\n✗\nPSP-UAP (Ours)\n50.40±0.53\n96.26±0.21*\n92.60±0.33\n74.10±1.10\n64.89±0.66\n75.65\nVGG19\n✓\nSGA-UAP\n50.67\n95.52\n97.69*\n51.08\n56.87\n70.37\nAT-UAP-S\n46.04±0.58\n93.49±0.17\n97.56±0.04*\n43.53±0.57\n52.58±0.81\n66.64\n✗\nPSP-UAP (Ours)\n48.93±0.72\n94.55±0.14\n94.65±0.10*\n67.13±1.37\n58.83±1.19\n72.81\nResNet152\n✓\nSGA-UAP\n51.59\n81.77\n79.01\n94.04*\n64.05\n74.09\nAT-UAP-S\n47.33±0.89\n81.93±0.94\n78.72±0.91\n91.52±0.78*\n61.32±0.98\n72.16\n✗\nPSP-UAP (Ours)\n58.82±1.17\n88.59±1.38\n87.35±0.92\n85.65±1.70*\n76.00±1.33\n79.28\nGoogleNet\n✓\nSGA-UAP\n62.56\n83.62\n82.11\n59.09\n92.12*\n75.90\nAT-UAP-S\n55.90±0.62\n78.71±0.67\n76.01±0.45\n54.49±0.29\n90.82±0.29*\n71.19\n✗\nPSP-UAP (Ours)\n65.22±0.56\n78.43±0.73\n79.26±0.73\n57.63±0.66\n81.43±0.49*\n72.39\nTable 4. FR (%) of our PSP-UAP and data-dependent UAPs. SGA-UAP [15] and AT-UAP-S [12]. The ”data” column indicates whether\na dataset was used to train UAPs (data-dependent UAP, ✓) or not (data-free UAP, ✗). * indicates the white-box model.\nparable to, but slightly below, TRM-UAP on GoogleNet.\nNotably, in strictly black-box settings (excluding the white-\nbox scenario where GoogleNet attacks itself), PSP-UAP\nachieves an average FR of 70.1% compared to TRM-\nUAP’s 69.6%, demonstrating better transferability.\nExtended Evaluation with Additional CNN Models.\nTo\nfurther explore the effectiveness of the proposed PSP-UAP,\nwe conduct additional experiments on widely used CNN\nmodels, including ResNet50, DenseNet121, MobileNet-v3-\nLarge, and Inception-v3. We compare the attack perfor-\nmance of PSP-UAP with TRM-UAP as shown in Table 3.\nNote that we limit the comparison to TRM-UAP since the\npublic code for AT-UAP has not yet been released. The\nresults demonstrate that our PSP-UAP consistently outper-\nforms TRM-UAP in terms of FR with a substantial mar-\ngin. The substantial improvement demonstrates PSP-UAP’s\nstrong generalization across diverse CNN models, high-\nlighting the robustness of our approach.\nComparison with Data-dependent UAPs.\nTo verify\nwhether our method effectively alleviates the lack of prior\nknowledge, we compare our method to state-of-the-art data-\ndependent universal attacks in the black-box scenario. As\nshown in Table 4, the FR of white-box attacks is inevitably\nhigher for SGA-UAP and AT-UAP-S, as they fully utilize\nthe target domain dataset. On the other hand, PSP-UAP ex-\nhibits superior transferability, as observed in the black-box\nsetting. Our method outperforms by achieving a higher av-\nerage FR across most models, surpassing data-dependent\napproaches. Furthermore, even in cases where some FR re-\nsults are lower, they do not fall significantly behind the data-\ndependent universal methods. These results indicate that\nour semantic samples prove to be effective as data for train-\ning the UAP, successfully overcoming the limitation posed\nby the absence of a target domain.\n(a) DenseNet121\n(b) ResNet152\n(c) AlexNet\nIter 100\nIter 1700\nIter 900\nFinal UAP\nFigure 4. Visualization of UAPs crafted by PSP-UAP during train-\ning on DenseNet121, ResNet152, and AlexNet. From left to right,\nthe UAPs are shown at iterations 100, 900, 1700, and the final\nUAP after training. Pixel values are scaled to [0, 255].\n4.3. Ablation Study\nWe conduct ablation experiments to explore the effec-\ntiveness of the proposed pseudo-semantic prior, sample\nreweighting, and applying input transformation techniques\non the semantic samples.\nIn the following experiments,\nwe generate UAPs on ResNet152 and evaluate them across\nvarious CNN models (e.g., AlexNet, VGG16, VGG19,\nResNet152, and GoogleNet).\nImpact of Each Proposed Component.\nWe investigate\nhow each component of PSP-UAP such as pseudo-semantic\nprior, sample reweighting, and input transformation affects\n7\n\n\nAlexNet\nVGG16\nVGG19\nResNet152\nGoogleNet\nTarget Model\n30\n40\n50\n60\n70\n80\n90\nFooling Rate (%)\nRP\nPSP\nPSP+T\nPSP+RW\nPSP+RW+T\nFigure 5. Ablation study on each proposed component in PSP-\nUAP. RP and PSP refer to training a UAP using random noises\nand semantic samples drawn from pseudo-semantic prior, respec-\ntively. RW and T denote the use of sample reweighting, and input\ntransformation, respectively.\nattack performance. For a fair comparison, we assign the\nnumber of random noises and semantic samples to 10.\nAs shown in Figure 5, our pseudo-semantic prior method\nachieves a higher FR rather than random prior when used\nas an input prior. Additionally, applying sample reweight-\ning to the semantic samples improves the FR in both white-\nbox and black-box attacks. Incorporating input transfor-\nmation into semantic samples enhances the attack perfor-\nmance. Remarkably, combining both sample reweighting\nand input transformation yields the greatest overall perfor-\nmance improvement.\nInput Transformation to Other Data-free UAP.\nWe\nevaluate the effect of applying input transformations to se-\nmantic samples in our method against random noise within\nTRM-UAP [16], using the same transformation T(·). To\nensure a fair evaluation, we set the number of samples\nN = 10 for both random noise and semantic samples. Fig-\nure 6 shows that the FR of TRM-UAP decreases when in-\nput transformations are applied. In contrast, applying trans-\nformations to semantic samples drawn from our pseudo-\nsemantic prior increases the FR compared to using seman-\ntic samples alone.\nWe believe this improvement results\nfrom the richer semantic content in our pseudo-semantic\nprior compared to random noise, enabling the UAP to learn\na wider variety of patterns through input transformations.\nThe Number of Semantic Samples.\nWe report the attack\nperformance with respect to the number of samples N in\nFigure 7 to analyze the impact of the sample size on our\nmethod. Empirically, we set N = 10 as it achieves the\nhighest attack performance, though results show generally\nstable performances across different sample sizes. Notably,\neven with N = 1, our method achieves superior attack per-\nformance compared to other data-free methods.\nAlexNet\nVGG16\nVGG19\nResNet152\nGoogleNet\nTarget Model\n30\n40\n50\n60\n70\n80\n90\nFooling Rate (%)\nTRM\nTRM+T\nPSP\nPSP+T\nFigure 6. Comparison of UAP performance with transformations\napplied to random noises in TRM-UAP [16] and to semantic sam-\nples drawn from pseudo-semantic priors in our method. T denotes\ninput transformation.\nThe Number of Semantic Samples\nFooling Rate (%)\n1\n2\n8\n6\n10\n4\n20\n60\n80\n70\n50\n90\nAlexNet\nVGG16\nVGG19\nResNet152\nGoogleNet\nFigure 7. Ablation study on the hyperparameter N. The FR (%)\nof UAPs generated with different numbers of semantic samples\n(N) is evaluated across various models.\nUAP Visualization.\nIn Figure 4, we visualize the UAPs\nat each training iteration to verify that the pseudo-semantic\nprior, constructed from UAPs in the training phase, captures\na variety of inherent patterns. We observe that the UAPs\ncontain more diverse patterns in the early stages of train-\ning. We believe this variability allows us to obtain semantic\nsamples with a broad range of patterns, through which the\nUAP learns diverse semantic representations.\n5. Conclusion\nIn this paper, we proposed a novel data-free universal at-\ntack method, called PSP-UAP. To address the lack of prior\nknowledge in the target domain, we employed the UAP as\na prior enriched with semantic information, allowing us to\ndraw semantic samples directly from the pseudo-semantic\nprior. Additionally, we introduced sample reweighting to\nensure a balanced attack across semantic samples. To fur-\nther enhance the transferability of UAP, we applied the input\ntransformation attack methods to the semantic samples. We\ndemonstrated the exceptional transferability of our method\nby comparing PSP-UAP alongside both data-free and data-\ndependent universal attack approaches across various CNN\nmodels on the ImageNet validation dataset.\n8\n\n\nReferences\n[1] Luca Bertinetto, Jack Valmadre, Joao F Henriques, Andrea\nVedaldi, and Philip HS Torr. Fully-convolutional siamese\nnetworks for object tracking. In ECCV Workshops, 2016. 1\n[2] Nicholas Carlini and David Wagner. Towards evaluating the\nrobustness of neural networks. In IEEE Symposium on Secu-\nrity and Privacy (SP), 2017. 1\n[3] Yinpeng Dong, Fangzhou Liao, Tianyu Pang, Hang Su, Jun\nZhu, Xiaolin Hu, and Jianguo Li. Boosting adversarial at-\ntacks with momentum. In CVPR, 2018. 1\n[4] Yinpeng Dong, Tianyu Pang, Hang Su, and Jun Zhu.\nEvading defenses to transferable adversarial examples by\ntranslation-invariant attacks. In CVPR, 2019. 3\n[5] Kevin Eykholt, Ivan Evtimov, Earlence Fernandes, Bo Li,\nAmir Rahmati, Chaowei Xiao, Atul Prakash, Tadayoshi\nKohno, and Dawn Song. Robust physical-world attacks on\ndeep learning visual classification. In CVPR, 2018. 1\n[6] Ian J Goodfellow, Jonathon Shlens, and Christian Szegedy.\nExplaining and harnessing adversarial examples. In ICLR,\n2015. 1\n[7] Kaiming He, Xiangyu Zhang, Shaoqing Ren, and Jian Sun.\nDeep residual learning for image recognition.\nIn CVPR,\n2016. 1, 5\n[8] Andrew Howard, Mark Sandler, Grace Chu, Liang-Chieh\nChen, Bo Chen, Mingxing Tan, Weijun Wang, Yukun Zhu,\nRuoming Pang, Vijay Vasudevan, et al. Searching for mo-\nbilenetv3. In CVPR, 2019. 5\n[9] Gao Huang, Zhuang Liu, Laurens Van Der Maaten, and Kil-\nian Q Weinberger.\nDensely connected convolutional net-\nworks. In CVPR, 2017. 5\n[10] Alex Krizhevsky, Ilya Sutskever, and Geoffrey E Hinton.\nImagenet classification with deep convolutional neural net-\nworks. In NeurIPS, 2012. 5\n[11] Alexey Kurakin, Ian J Goodfellow, and Samy Bengio. Ad-\nversarial examples in the physical world. In Artificial intel-\nligence safety and security. Chapman and Hall/CRC, 2018.\n1\n[12] Maosen Li, Yanhua Yang, Kun Wei, Xu Yang, and Heng\nHuang. Learning universal adversarial perturbation by ad-\nversarial example. In AAAI, 2022. 2, 5, 6, 7\n[13] Jiadong Lin, Chuanbiao Song, Kun He, Liwei Wang, and\nJohn E Hopcroft. Nesterov accelerated gradient and scale\ninvariance for adversarial attacks. In ICLR, 2020. 3\n[14] Hong Liu, Rongrong Ji, Jie Li, Baochang Zhang, Yue Gao,\nYongjian Wu, and Feiyue Huang. Universal adversarial per-\nturbation via prior driven uncertainty approximation.\nIn\nICCV, 2019. 2, 5\n[15] Xuannan Liu, Yaoyao Zhong, Yuhang Zhang, Lixiong Qin,\nand Weihong Deng. Enhancing generalization of universal\nadversarial perturbation through gradient aggregation.\nIn\nICCV, 2023. 1, 2, 4, 6, 7\n[16] Yiran Liu, Xin Feng, Yunlong Wang, Wu Yang, and Di Ming.\nTrm-uap: Enhancing the transferability of data-free universal\nadversarial perturbation via truncated ratio maximization. In\nICCV, 2023. 2, 3, 4, 5, 6, 8, 1\n[17] Aleksander Madry, Aleksandar Makelov, Ludwig Schmidt,\nDimitris Tsipras, and Adrian Vladu. Towards deep learning\nmodels resistant to adversarial attacks. In ICLR, 2018. 2\n[18] Seyed-Mohsen Moosavi-Dezfooli, Alhussein Fawzi, and\nPascal Frossard. Deepfool: a simple and accurate method\nto fool deep neural networks. In CVPR, 2016. 1, 2\n[19] Seyed-Mohsen Moosavi-Dezfooli, Alhussein Fawzi, Omar\nFawzi, and Pascal Frossard. Universal adversarial perturba-\ntions. In CVPR, 2017. 1, 2, 4, 5\n[20] KR Mopuri, U Garg, and R Venkatesh Babu. Fast feature\nfool: A data independent approach to universal adversarial\nperturbations. In BMVC, 2017. 2, 3, 5\n[21] Konda Reddy Mopuri, Aditya Ganeshan, and R Venkatesh\nBabu. Generalizable data-free objective for crafting univer-\nsal adversarial perturbations. TPAMI, 41(10), 2018. 2, 3, 4,\n5, 6, 1\n[22] Konda Reddy Mopuri, Utkarsh Ojha, Utsav Garg, and\nR Venkatesh Babu. Nag: Network for adversary generation.\nIn CVPR, 2018. 1, 2\n[23] Konda\nReddy\nMopuri,\nPhani\nKrishna\nUppala,\nand\nR Venkatesh Babu. Ask, acquire, and attack: Data-free uap\ngeneration using class impressions. In ECCV, 2018. 2, 3, 5\n[24] Omid Poursaeed, Isay Katsman, Bicheng Gao, and Serge Be-\nlongie. Generative adversarial perturbations. In CVPR, 2018.\n1, 2\n[25] J Redmon. You only look once: Unified, real-time object\ndetection. In CVPR, 2016. 1\n[26] Shaoqing Ren, Kaiming He, Ross Girshick, and Jian Sun.\nFaster r-cnn: Towards real-time object detection with region\nproposal networks. TPAMI, 39(6):1137–1149, 2016. 1\n[27] Olaf Ronneberger, Philipp Fischer, and Thomas Brox. U-net:\nConvolutional networks for biomedical image segmentation.\nIn MICCAI, 2015. 1\n[28] Olga Russakovsky, Jia Deng, Hao Su, Jonathan Krause, San-\njeev Satheesh, Sean Ma, Zhiheng Huang, Andrej Karpathy,\nAditya Khosla, Michael Bernstein, et al.\nImagenet large\nscale visual recognition challenge. IJCV, 115, 2015. 1, 5\n[29] Ramprasaath R Selvaraju, Michael Cogswell, Abhishek Das,\nRamakrishna Vedantam, Devi Parikh, and Dhruv Batra.\nGrad-cam:\nVisual explanations from deep networks via\ngradient-based localization. In ICCV, 2017. 4\n[30] Ali Shafahi, Mahyar Najibi, Zheng Xu, John Dickerson,\nLarry S Davis, and Tom Goldstein.\nUniversal adversarial\ntraining. In AAAI, 2020. 1, 2\n[31] Karen Simonyan and Andrew Zisserman. Very deep convo-\nlutional networks for large-scale image recognition. In ICLR,\n2015. 5\n[32] Christian Szegedy, Wojciech Zaremba, Ilya Sutskever, Joan\nBruna, Dumitru Erhan, Ian Goodfellow, and Rob Fergus. In-\ntriguing properties of neural networks. In ICLR, 2014. 1\n[33] Christian Szegedy, Wei Liu, Yangqing Jia, Pierre Sermanet,\nScott Reed, Dragomir Anguelov, Dumitru Erhan, Vincent\nVanhoucke, and Andrew Rabinovich.\nGoing deeper with\nconvolutions. In CVPR, 2015. 5\n[34] Christian Szegedy, Vincent Vanhoucke, Sergey Ioffe, Jon\nShlens, and Zbigniew Wojna. Rethinking the inception ar-\nchitecture for computer vision. In CVPR, 2016. 1\n9\n\n\n[35] Christian Szegedy, Vincent Vanhoucke, Sergey Ioffe, Jon\nShlens, and Zbigniew Wojna. Rethinking the inception ar-\nchitecture for computer vision. In CVPR, 2016. 5\n[36] Kunyu Wang, Xuanran He, Wenxuan Wang, and Xiaosen\nWang. Boosting adversarial transferability by block shuffle\nand rotation. In CVPR, 2024. 3\n[37] Xiaosen Wang, Xuanran He, Jingdong Wang, and Kun He.\nAdmix: Enhancing the transferability of adversarial attacks.\nIn ICCV, 2021. 3\n[38] Xiaosen Wang, Zeliang Zhang, and Jianping Zhang. Struc-\nture invariant transformation for better adversarial transfer-\nability. In ICCV, 2023. 3\n[39] Chaowei Xiao, Bo Li, Jun-Yan Zhu, Warren He, Mingyan\nLiu, and Dawn Song. Generating adversarial examples with\nadversarial networks. In IJCAI, 2018. 1\n[40] Cihang Xie, Zhishuai Zhang, Yuyin Zhou, Song Bai, Jianyu\nWang, Zhou Ren, and Alan L Yuille. Improving transferabil-\nity of adversarial examples with input diversity. In CVPR,\n2019. 2, 3\n[41] Chaoning Zhang, Philipp Benz, Adil Karjauv, and In So\nKweon.\nData-free universal adversarial perturbation and\nblack-box attack. In ICCV, 2021. 2, 3, 4, 5\n[42] Yifu Zhang, Chunyu Wang, Xinggang Wang, Wenjun Zeng,\nand Wenyu Liu. Fairmot: On the fairness of detection and re-\nidentification in multiple object tracking. IJCV, 129:3069–\n3087, 2021. 1\n[43] Rongyi Zhu, Zeliang Zhang, Susan Liang, Zhuo Liu, and\nChenliang Xu. Learning to transform dynamically for better\nadversarial transferability. In CVPR, 2024. 2, 3, 4\n10\n\n\nA. Additional Experiments on CNN Models\nImpact of Each Proposed Component\nIn the main\nmanuscript, we evaluate the impact of each component on\nattack performance by generating UAPs using ResNet152.\nIn this section, we extend our ablation study to other mod-\nels, with the results summarized in Figure 8. AlexNet is ab-\nbreviated as AN, ResNet152 as RN152, GoogleNet as GN,\nResNet50 as RN50, DenseNet121 as DN121, MobileNet-\nv3-Large as MN-v3, and Inception-v3 as Inc-v3. We ob-\nserve consistent trends across models, where the incorpo-\nration of pseudo-semantic priors (PSP), sample reweight-\ning, and input transformation enhances the attack perfor-\nmance of the generated UAPs. However, the effect of PSP\nis less pronounced in AlexNet, while input transformations\nhave a reduced impact on white-box attack performance.\nAdditionally, in experiments with VGG19 and Inception-\nv3, several models demonstrate reduced performance when\nsample reweighting is applied alone. Despite these minor\ndegradations, our full model, which combines all compo-\nnents, achieves a significantly higher black-box fooling rate\non average, demonstrating its robustness even when indi-\nvidual components show limited effectiveness.\nTransferability Experiments\nWe conduct additional ex-\nperiments to explore the black-box attack transferabil-\nity across various models further.\nWe generate UAPs\non ResNet50, DenseNet121, MobileNet-v3-Large, and\nInception-v3,\nand attack AlexNet,\nVGG16,\nVGG19,\nResNet152, and GoogleNet. The results in Table 5 demon-\nstrate that our method persistently surpasses TRM-UAP in\nattack performance, even when the target model changes,\nhighlighting its superiority.\nImpact of Epsilon\nWe evaluate the impact of ϵ which is\na constraint parameter that restricts the pixel intensity of\nthe generated UAPs used in Eq. (8) of the main manuscript.\nNote that, for experiments in the main manuscript, we set\nϵ = 10, following the conventional setting of data-free UAP\nmethods. To further analyze its effect, we compare the FR\nof our method with TRM-UAP using various ϵ values of\n8, 10, and 16. The results, shown in Table 6, show that\nour method consistently outperforms TRM-UAP in terms of\nFR across different values of ϵ. These experiments demon-\nstrate that the pseudo-semantic prior retains sufficient value\nas the data prior, even under varying levels of constraints.\nQualititive Results\nWe illustrate adversarial examples at-\ntacked by our generated UAPs using ResNet152 in Figure 9\nwith different ϵ ∈{8, 10, 16}. As expected, smaller ϵ values\nresult in minimal degradation to the original image, whereas\nlarger ϵ values highlight more artifacts introduced by the\nUAP. Similarly, as shown in Table 6, smaller ϵ values lead\nto lower performance compared to larger ϵ values.\nAN\nVGG16 VGG19 RN152\nGN\n20\n40\n60\n80\n100\nAlexNet\nAN\nVGG16 VGG19 RN152\nGN\n20\n40\n60\n80\n100\nVGG16\nAN\nVGG16 VGG19 RN152\nGN\n20\n40\n60\n80\n100\nVGG19\nAN\nVGG16 VGG19 RN152\nGN\n20\n40\n60\n80\n100\nGoogleNet\nRN50\nDN121\nMN-v3-L\nInc-v3\n20\n40\n60\n80\n100\nFooling Rate (%)\nResNet50\nRN50\nDN121\nMN-v3-L\nInc-v3\n20\n40\n60\n80\n100\nDenseNet121\nRN50\nDN121\nMN-v3-L\nInc-v3\n20\n40\n60\n80\n100\nMobileNet-v3-Large\nRN50\nDN121\nMN-v3-L\nInc-v3\n20\n40\n60\n80\n100\nInception-v3\nRP\nPSP\nPSP+T\nPSP+RW\nPSP+RW+T\nFigure 8. Ablation study on each proposed component in PSP-\nUAP on various CNN models. RP and PSP refer to training a UAP\nusing random noises and semantic samples drawn from pseudo-\nsemantic prior. RW and T denote the use of sample reweighting,\nand input transformation, respectively. All experiments, including,\nRP are conducted with the number of samples, N, set to 10.\nWe also visualize the final UAPs crafted for each model\nand the intermediate UAPs used during the training phase\nto generate the pseudo-semantic prior in Figure 11. As dis-\ncussed in the main manuscript, visually diverse patterns can\nbe observed across different iterations, even on the same\nsurrogate model. This demonstrates that our method effec-\ntively crafts UAPs even in the absence of prior knowledge\nby generating diverse semantic samples.\nB. Ablation Study on Hyperparameters\nIn this section, we demonstrate an ablation study on the\nhyperparameters used in our PSP-UAP framework, includ-\ning the ratios of convolutional layers to calculate the loss,\ntemperature parameters in the sample reweighting, and the\nranges for rotation, scaling, and shuffling in the input trans-\nformation. To determine the optimal set of parameters, we\nfollow the setting used in previous works [16, 21].\nRatio of Convolutional Layers\nWe follow the same pro-\ncess outlined in TRM-UAP [16] to determine l′ in Eq. (8)\nby searching for the optimal ratio of convolutional layers.\nFor this, we use only our pseudo-semantic priors, exclud-\ning sample reweighting and input transformation. Figure 10\n1\n\n\nModel\nAttack\nAN\nVGG16\nVGG19\nRN152\nGN\nAverage\nRN50\nTRM\n46.46±0.80\n73.82±0.85\n72.43±0.91\n52.64±1.18\n58.59±1.57\n60.79\nPSP\n51.80±0.80\n82.02±0.60\n82.09±0.65\n60.90±1.14\n62.22±1.22\n67.81\nDN121\nTRM\n45.79±1.64\n49.95±1.54\n49.60±0.98\n31.36±0.84\n47.87±2.36\n44.91\nPSP\n59.04±0.76\n67.79±0.85\n69.86±0.99\n43.72±0.26\n72.82±2.04\n62.65\nMN-v3\nTRM\n45.47±0.49\n49.13±0.71\n48.69±0.64\n28.67±0.58\n36.15±0.92\n41.62\nPSP\n66.50±1.30\n77.52±0.51\n75.96±0.50\n49.56±0.72\n69.78±0.35\n67.86\nInc-v3\nTRM\n58.72±0.56\n71.77±0.25\n70.82±0.12\n45.84±0.47\n62.87±0.41\n62.01\nPSP\n54.84±0.55\n78.38±0.64\n75.52±0.55\n52.82±0.54\n65.24±0.78\n65.36\nTable 5. Black-box attack transferability across models is analyzed. UAPs crafted on ResNet50, DenseNet121, MobileNet-v3-Large, and\nInception-v3 are evaluated on AlexNet, VGG16, VGG19, ResNet152, and GoogleNet.\nModel\nδ∞constraint\nAttack\nRN50\nDN121\nMN-v3-L\nInc-v3\nAverage\nRN50\nϵ = 8\nTRM-UAP\n55.39*\n39.80\n39.02\n22.87\n39.27\nPSP-UAP\n66.41*\n50.90\n54.06\n28.98\n50.09\nϵ = 10\nTRM-UAP\n73.26*\n54.42\n61.25\n37.36\n56.57\nPSP-UAP\n77.60*\n66.11\n70.50\n42.32\n64.13\nϵ = 16\nTRM-UAP\n94.61*\n80.74\n75.21\n58.16\n77.18\nPSP-UAP\n94.88*\n90.53\n90.35\n74.21\n87.49\nDN121\nϵ = 8\nTRM-UAP\n29.82\n59.12*\n30.43\n24.70\n36.01\nPSP-UAP\n37.56\n67.51*\n44.38\n32.34\n45.45\nϵ = 10\nTRM-UAP\n35.24\n70.10*\n34.17\n32.11\n42.91\nPSP-UAP\n53.03\n85.81*\n50.22\n50.73\n59.95\nϵ = 16\nTRM-UAP\n64.64\n88.80*\n60.90\n51.88\n66.55\nPSP-UAP\n77.89\n96.84*\n77.10\n73.87\n81.42\nMN-v3-L\nϵ = 8\nTRM-UAP\n37.41\n36.35\n79.71*\n30.79\n46.06\nPSP-UAP\n43.47\n44.41\n79.94*\n35.39\n50.80\nϵ = 10\nTRM-UAP\n39.47\n40.37\n73.07*\n30.11\n45.76\nPSP-UAP\n54.38\n54.62\n90.39*\n46.29\n61.42\nϵ = 16\nTRM-UAP\n63.21\n63.95\n96.70*\n47.49\n67.83\nPSP-UAP\n81.40\n83.45\n99.03*\n76.83\n85.18\nInc-v3\nϵ = 8\nTRM-UAP\n43.02\n44.55\n54.33\n48.85*\n47.68\nPSP-UAP\n46.53\n45.43\n57.12\n52.58*\n50.41\nϵ = 10\nTRM-UAP\n53.53\n54.93\n67.16\n64.22*\n59.96\nPSP-UAP\n57.60\n57.50\n70.20\n65.38*\n62.67\nϵ = 16\nTRM-UAP\n78.90\n79.06\n88.40\n91.81*\n84.54\nPSP-UAP\n83.58\n82.21\n89.24\n93.56*\n87.14\nTable 6. FR (%) results for the UAPs constrained by ϵ = 8, 10 and 16, crafted on ResNet50, DenseNet121, MobileNet-v3-Large, and\nInception-v3. * denotes the white-box model.\nshows the results, with yellow lines indicating outcomes\nand the yellow star marking the convolutional layer ratios\nused in our experiments. Based on this, the ratios are set\nto 100%, 100%, 100%, 65%, 55%, 70%, 90%, 90%, 20%\nfor AlexNet, VGG16, VGG19, ResNet152, GoogleNet,\nResNet50, DenseNet121, MobileNet-v3-Large, Inception-\nv3, respectively. Note that, for a fair comparison with TRM-\nUAP in Table 3 of our main manuscript and Table 5 in\nthis supplementary material, we made every effort to con-\nduct comprehensive experiments to determine the optimal\npositive truncation rate (PTR) and negative truncation rate\n(NTR) for TRM-UAP.\nTemperature Parameters\nAfter determining the optimal\nconvolution layer ratio, we use it as a basis to find the tem-\nperature parameter τ, used in Eq. (6) for the temperature-\nscaled softmax output, by incrementally increasing it from\n1 to 10 in steps of 1. The results are shown in Figure 10,\nwith blue lines representing the outcomes and the blue stars\nindicating the temperature values used in our experiments.\nOur observations indicate that variations in the temperature\nparameter τ have minimal impact on the results.\nIn Table 7 and Table 8, we report the performances of\nour PSP-UAP with a fixed temperature (τ = 4, referred\nto as PSP-I) alongside PSP-UAP with optimal temperature\nvalues (PSP-D) and TRM-UAP for comparison. Even with\na fixed temperature, the performance difference is minimal,\nand our method consistently outperforms TRM-UAP by a\nsignificant margin. This highlights the robustness of our ap-\nproach, achieving strong results over TRM-UAP even with-\nout tuning the temperature parameter.\n2\n\n\nCradle\nWool\nTeddy\nDishrag\nMobile home\nYurt\nYurt\nDromedary\nRock beauty\nBrain coral\nBrain coral\nTheater curtain\nSkunk\nShower curtain\nShower curtain\nTraffic light\nCinema\nRestaurant\nCastle\nChurch\nChurch\nClean\n𝝐= 𝟖 \n𝝐= 𝟏𝟎 \n𝝐= 𝟏𝟔 \nClean\n𝝐= 𝟖 \n𝝐= 𝟏𝟎 \n𝝐= 𝟏𝟔 \nShower curtain\nTheater curtain\nTheater curtain\nFigure 9. Qualitative results of our method. The leftmost column represents the original images, while the remaining three columns\ncorrespond to adversarial images generated with ϵ = 8, 10, and 16 (from left to right). The predicted labels are displayed below each\nimage. The UAPs are crafted on ResNet152.\n0.1\n0.2\n0.3\n0.4\n0.5\n0.6\n0.7\n0.8\n0.9\n1.0\n40\n60\n80\n100\nFooling Rate (%)\nAlexNet\n0.1\n0.2\n0.3\n0.4\n0.5\n0.6\n0.7\n0.8\n0.9\n1.0\n40\n60\n80\n100\nVGG16\n0.1\n0.2\n0.3\n0.4\n0.5\n0.6\n0.7\n0.8\n0.9\n1.0\n40\n60\n80\n100\nVGG19\n0.1\n0.2\n0.3\n0.4\n0.5\n0.6\n0.7\n0.8\n0.9\n1.0\n30\n50\n70\n90\nFooling Rate (%)\nResNet152\n0.1\n0.2\n0.3\n0.4\n0.5\n0.6\n0.7\n0.8\n0.9\n1.0\n30\n50\n70\n90\nGoogleNet\n0.1\n0.2\n0.3\n0.4\n0.5\n0.6\n0.7\n0.8\n0.9\n1.0\n30\n50\n70\n90\nResNet50\n0.1\n0.2\n0.3\n0.4\n0.5\n0.6\n0.7\n0.8\n0.9\n1.0\n40\n60\n80\n100\nFooling Rate (%)\nDenseNet121\n0.1\n0.2\n0.3\n0.4\n0.5\n0.6\n0.7\n0.8\n0.9\n1.0\n40\n60\n80\n100\nMobileNet-v3-Large\n0.1\n0.2\n0.3\n0.4\n0.5\n0.6\n0.7\n0.8\n0.9\n1.0\n40\n60\n80\nInception-v3\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\nTemperature\nRatio of convolution layers\nFigure 10. Parameter study on the ratio of convolutional layers and the temperature parameter for sample reweighting.\nInput Transformations\nTo evaluate the impact of hyper-\nparameters for input transformation, we conduct an ablation\nstudy on hyperparameters for rotation, scaling, and shuf-\nfling. Specifically, we perform a comparative analysis on\nResNet152 with θ ∈{3, 6, 9, 12}, βhigh ∈{2, 4, 6, 8}, and\nm ∈{2, 3, 4, 5} to determine the optimal parameter values,\nextending the evaluation across other models. Each trans-\nformation experiment is conducted independently to isolate\nand analyze its impact on attack performance. To prevent\nexcessive semantic information loss from extreme scaling,\nthe minimal bound of the scale factor, βlow, is set to 0.8.\nBased on the analysis in Figure 12, we set θ = 6, βhigh = 4,\nand m = 2 in our experiments. Consequently, by inte-\ngrating input transformation into a data-free framework, our\nmethod achieves high black-box attack transferability while\npreserving white-box performance as much as possible.\n3\n\n\n(d) GoogleNet\n(a) AlexNet\n1 %\n30 %\n20 %\nFinal UAP\n40 %\n50 %\n60 %\n10 %\n70 %\n(b) VGG16\n(c) VGG19\n(e) Inception-v3\n(f) ResNet50\n(g) MobileNet-v3-Large\n(h) ResNet152\n(i) DenseNet121\nFigure 11. Visualization of the UAPs crafted by various CNN models in the training phase. The percentage above the figure corresponds\nto the progress of training iterations (e.g., 1000 iterations out of 10000 = 10%)\n4\n\n\nModel\nAttack\nAN\nVGG16\nVGG19\nRN152\nGN\nAvg.\nAN\nTRM\n93.53*\n60.10\n57.08\n27.31\n32.70\n54.14\nPSP-I 91.59*\n74.95\n72.70\n47.66\n65.54\n70.49\nPSP-D 91.77*\n76.56\n74.07\n49.20\n66.00\n71.52\nVGG16\nTRM\n47.53\n94.30*\n89.68\n61.43\n53.95\n69.38\nPSP-I 48.90\n96.10*\n91.86\n70.75\n58.45\n73.21\nPSP-D 50.40\n96.26*\n92.60\n74.10\n64.89\n75.65\nVGG19\nTRM\n46.01\n89.82\n91.35*\n47.19\n46.48\n64.17\nPSP-I 46.57\n94.07\n93.88*\n66.08\n57.33\n71.59\nPSP-D 48.93\n94.55\n94.56*\n67.13\n58.83\n72.80\nRN152\nTRM\n53.56\n77.20\n73.30\n67.46*\n57.54\n65.81\nPSP-I 57.17\n87.40\n86.34\n84.85*\n71.86\n77.24\nPSP-D 58.82\n88.59\n87.35\n85.65*\n76.00\n79.29\nGN\nTRM\n60.10\n79.66\n79.98\n58.85\n85.32* 72.78\nPSP-I 66.06\n78.88\n79.61\n56.95\n81.04* 72.51\nPSP-D 65.22\n78.43\n79.26\n57.63\n81.43* 72.39\nTable 7. Ablation study on the sample reweighting temperature pa-\nrameter, τ. PSP-I and PSP-D refer to fixing the τ to 4 and adapting\nit for each model.\n3\n6\n9\n12\n60\n70\n80\n90\nFooling Rate (%)\nRotation\n2\n4\n6\n8\n35\n55\n75\n95\nScale\n2\n3\n4\n5\n50\n65\n80\n95\nShuffle\nAlexNet\nVGG16\nVGG19\nResNet152\nGoogleNet\nFigure 12. Hyperparameter analysis on input transformation tech-\nniques. Each transformation is individually applied to semantic\nsamples during UAP training. Gray dashed lines represent the\nvalue used in our experiments.\nC. Limitations and Discussions\nApplying input transformations in our data-free UAP\nframework occasionally leads to a decrease in white-box\nattack performance. Unlike data-dependent approaches that\nrely on cross-entropy or logits, our method in Eq. (8) uti-\nlizes activations from all layers.\nWhile this comprehen-\nsive use of layer activations provides several advantages, it\nalso increases sensitivity to unintended side effects of input\ntransformations, as shallower features are generally more\naffected than deeper ones. Consequently, although input\ntransformations boost black-box attack transferability, they\nmay cause a slight decline in white-box performance.\nIn addition, since our method does not rely on target im-\nages or models, the adversarial examples generated may ex-\nhibit artifacts from the UAP itself, particularly when the im-\nages contain large plain regions, making them less visually\nclean compared to image-specific attacks. However, this\nis not a limitation unique to our approach but a common\nchallenge for UAP methods, where a single UAP is used to\nattack a wide range of images.\nModel\nAttack\nRN50\nDN121\nMN-v3\nInc-v3\nAvg.\nRN50\nTRM\n73.26*\n54.42\n61.25\n37.36\n56.57\nPSP-I\n76.41*\n64.89\n69.32\n42.03\n63.16\nPSP-D\n77.60*\n66.11\n70.50\n42.32\n64.13\nDN121\nTRM\n35.24\n70.10*\n34.17\n32.11\n42.91\nPSP-I\n53.30\n84.95*\n49.79\n49.59\n59.40\nPSP-D\n53.03\n85.81*\n50.22\n50.73\n59.95\nMN-v3\nTRM\n39.47\n40.37\n73.07*\n30.11\n45.76\nPSP-I\n54.88\n53.56\n89.85*\n45.92\n61.05\nPSP-D\n54.38\n54.62\n90.39*\n46.29\n61.42\nInc-v3\nTRM\n53.53\n54.93\n67.16\n64.22*\n59.96\nPSP-I\n57.56\n57.15\n69.94\n64.83*\n62.37\nPSP-D\n57.60\n57.50\n70.20\n65.38*\n62.67\nTable 8. Ablation study on the sample reweighting temperature\nparameter, τ, for additional CNN models. PSP-I and PSP-D refer\nto fixing the τ to 4 and adapting it for each model.\nD. Reproducibility\nOur code will be publicly released if our paper is accepted.\nFor reproducibility, we have included the code in the sup-\nplementary materials, with detailed algorithms provided in\nthe main manuscript and hyperparameters outlined in this\nsupplementary document.\n5\n\n\n",
  "metadata": {
    "source_file": "dataset/pdfs/arxiv_2502.21048v1.pdf",
    "total_pages": 15,
    "title": "Data-free Universal Adversarial Perturbation with Pseudo-semantic Prior",
    "authors": [
      "Chanhui Lee",
      "Yeonghwan Song",
      "Jeany Son"
    ],
    "abstract": "Data-free Universal Adversarial Perturbation (UAP) is an image-agnostic\nadversarial attack that deceives deep neural networks using a single\nperturbation generated solely from random noise, without any data priors.\nHowever, traditional data-free UAP methods often suffer from limited\ntransferability due to the absence of semantic information in random noise. To\naddress this, we propose a novel data-free universal attack approach that\ngenerates a pseudo-semantic prior recursively from the UAPs, enriching semantic\ncontents within the data-free UAP framework. Our method is based on the\nobservation that UAPs inherently contain latent semantic information, enabling\nthe generated UAP to act as an alternative data prior, by capturing a diverse\nrange of semantics through region sampling. We further introduce a sample\nreweighting technique to emphasize hard examples by focusing on samples that\nare less affected by the UAP. By leveraging the semantic information from the\npseudo-semantic prior, we also incorporate input transformations, typically\nineffective in data-free UAPs due to the lack of semantic content in random\npriors, to boost black-box transferability. Comprehensive experiments on\nImageNet show that our method achieves state-of-the-art performance in average\nfooling rate by a substantial margin, significantly improves attack\ntransferability across various CNN architectures compared to existing data-free\nUAP methods, and even surpasses data-dependent UAP methods.",
    "published_date": "2025-02-28",
    "source": "arxiv"
  }
}