[
  {
    "title": "LLM Post-Training: A Deep Dive into Reasoning Large Language Models",
    "authors": [
      "Komal Kumar",
      "Tajamul Ashraf",
      "Omkar Thawakar",
      "Rao Muhammad Anwer",
      "Hisham Cholakkal",
      "Mubarak Shah",
      "Ming-Hsuan Yang",
      "Phillip H. S. Torr",
      "Salman Khan",
      "Fahad Shahbaz Khan"
    ],
    "abstract": "Large Language Models (LLMs) have transformed the natural language processing\nlandscape and brought to life diverse applications. Pretraining on vast\nweb-scale data has laid the foundation for these models, yet the research\ncommunity is now increasingly shifting focus toward post-training techniques to\nachieve further breakthroughs. While pretraining provides a broad linguistic\nfoundation, post-training methods enable LLMs to refine their knowledge,\nimprove reasoning, enhance factual accuracy, and align more effectively with\nuser intents and ethical considerations. Fine-tuning, reinforcement learning,\nand test-time scaling have emerged as critical strategies for optimizing LLMs\nperformance, ensuring robustness, and improving adaptability across various\nreal-world tasks. This survey provides a systematic exploration of\npost-training methodologies, analyzing their role in refining LLMs beyond\npretraining, addressing key challenges such as catastrophic forgetting, reward\nhacking, and inference-time trade-offs. We highlight emerging directions in\nmodel alignment, scalable adaptation, and inference-time reasoning, and outline\nfuture research directions. We also provide a public repository to continually\ntrack developments in this fast-evolving field:\nhttps://github.com/mbzuai-oryx/Awesome-LLM-Post-training.",
    "pdf_url": "http://arxiv.org/pdf/2502.21321v1",
    "published": "2025-02-28",
    "source": "arxiv",
    "id": "2502.21321v1",
    "categories": [
      "cs.CL",
      "cs.CV"
    ]
  },
  {
    "title": "Topological Quantum Dark Matter via Global Anomaly Cancellation",
    "authors": [
      "Juven Wang"
    ],
    "abstract": "Standard Model (SM) with 15 Weyl fermions per family (lacking the 16th, the\nsterile right-handed neutrino $\\nu_R$) suffers from mixed gauge-gravitational\nanomalies tied to baryon number plus or minus lepton number ${\\bf B} \\pm {\\bf\nL}$ symmetry. Including $\\nu_R$ per family can cancel these anomalies, but when\n${\\bf B} \\pm {\\bf L}$ symmetry is preserved as discrete finite subgroups rather\nthan a continuous U(1), the perturbative local anomalies become nonperturbative\nglobal anomalies. In this work, we systematically enumerate these\ngauge-gravitational global anomalies involving discrete ${\\bf B} \\pm {\\bf L}$\nthat are enhanced from the fermion parity $\\mathbb{Z}_2^{\\rm F}$ to\n$\\mathbb{Z}_{2N}^{\\rm F}$, with $N=2,3,4,6,9$, etc. The ${\\bf B} \\pm {\\bf L}$\ndiscreteness is constrained by multi-fermion deformations beyond-the-SM and the\nfamily number $N_f$. Unlike the free quadratic $\\nu_R$ Majorana mass gap\npreserving the minimal $\\mathbb{Z}_2^{\\rm F}$, we explore novel scenarios\ncanceling $({\\bf B} \\pm {\\bf L})$-gravitational anomalies while preserving the\n$\\mathbb{Z}_{2N}^{\\rm F}$ discrete symmetries, featuring 4d interacting gapped\ntopological orders (potentially with or without low-energy TQFT descriptions)\nor gapless sectors (e.g., conformal field theories). We propose anomalous\nsectors as quantum dark matter to cancel SM's global anomalies. We find the\n$N_f=3$ uniqueness, when the $\\mathbb{Z}_{2N}^{\\rm F}$ representation from the\nfaithful ${\\bf B} + {\\bf L}$ for baryons at $N=N_c=3$ is extended to the\nfaithful ${\\bf Q} + N_c {\\bf L}$ for quarks at $N=N_c N_f=9$, this symmetry\nextension matches with the topological order dark matter construction. Key\nimplications include: (1) a 5th force mediating between SM and dark matter via\ndiscrete gauge fields. (2) dark matter as topological order quantum matter with\ngapped anyon excitations at ends of extended defects. (3) topological\nleptogenesis.",
    "pdf_url": "http://arxiv.org/pdf/2502.21319v1",
    "published": "2025-02-28",
    "source": "arxiv",
    "id": "2502.21319v1",
    "categories": [
      "hep-th"
    ]
  },
  {
    "title": "How far can we go with ImageNet for Text-to-Image generation?",
    "authors": [
      "L. Degeorge",
      "A. Ghosh",
      "N. Dufour",
      "D. Picard",
      "V. Kalogeiton"
    ],
    "abstract": "Recent text-to-image (T2I) generation models have achieved remarkable results\nby training on billion-scale datasets, following a `bigger is better' paradigm\nthat prioritizes data quantity over quality. We challenge this established\nparadigm by demonstrating that strategic data augmentation of small,\nwell-curated datasets can match or outperform models trained on massive\nweb-scraped collections. Using only ImageNet enhanced with well-designed text\nand image augmentations, we achieve a +2 overall score over SD-XL on GenEval\nand +5 on DPGBench while using just 1/10th the parameters and 1/1000th the\ntraining images. Our results suggest that strategic data augmentation, rather\nthan massive datasets, could offer a more sustainable path forward for T2I\ngeneration.",
    "pdf_url": "http://arxiv.org/pdf/2502.21318v1",
    "published": "2025-02-28",
    "source": "arxiv",
    "id": "2502.21318v1",
    "categories": [
      "cs.CV"
    ]
  },
  {
    "title": "Assessing zero-shot generalisation behaviour in graph-neural-network interatomic potentials",
    "authors": [
      "Chiheb Ben Mahmoud",
      "Zakariya El-Machachi",
      "Krystian A. Gierczak",
      "John L. A. Gardner",
      "Volker L. Deringer"
    ],
    "abstract": "With the rapidly growing availability of machine-learned interatomic\npotential (MLIP) models for chemistry, much current research focuses on the\ndevelopment of generally applicable and ``foundational'' MLIPs. An important\nquestion in this context is whether, and how well, such models can transfer\nfrom one application domain to another. Here, we assess this transferability\nfor an MLIP model at the interface of materials and molecular chemistry.\nSpecifically, we study GO-MACE-23, a model designed for the extended covalent\nnetwork of graphene oxide, and quantify its zero-shot performance for small,\nisolated molecules and chemical reactions outside its direct scope--in direct\ncomparison with a state-of-the-art model which has been trained in-domain. Our\nwork provides quantitative insight into the transfer and generalisation ability\nof graph-neural-network potentials and, more generally, makes a step towards\nthe more widespread applicability of MLIPs in chemistry.",
    "pdf_url": "http://arxiv.org/pdf/2502.21317v1",
    "published": "2025-02-28",
    "source": "arxiv",
    "id": "2502.21317v1",
    "categories": [
      "physics.chem-ph",
      "cond-mat.mtrl-sci"
    ]
  },
  {
    "title": "Doping dependence of 2-spinon excitations in the doped 1D cuprate Ba$_2$CuO$_{3+δ}$",
    "authors": [
      "Jiarui Li",
      "Daniel Jost",
      "Ta Tang",
      "Ruohan Wang",
      "Yong Zhong",
      "Zhuoyu Chen",
      "Mirian Garcia-Fernandez",
      "Jonathan Pelliciari",
      "Valentina Bisogni",
      "Brian Moritz",
      "Kejin Zhou",
      "Yao Wang",
      "Thomas P. Devereaux",
      "Wei-Sheng Lee",
      "Zhi-Xun Shen"
    ],
    "abstract": "Recent photoemission experiments on the quasi-one-dimensional Ba-based\ncuprates suggest that doped holes experience an attractive potential not\ncaptured using the simple Hubbard model. This observation has garnered\nsignificant attention due to its potential relevance to Cooper pair formation\nin high-$T_c$ cuprate superconductors. To scrutinize this assertion, we\nexamined signatures of such an attractive potential in doped 1D cuprates\nBa$_2$CuO$_{3+\\delta}$ by measuring the dispersion of the 2-spinon excitations\nusing Cu $L_3$-edge resonant inelastic X-ray scattering (RIXS). Upon doping,\nthe 2-spinon excitations appear to weaken, with a shift of the minimal position\ncorresponding to the nesting vector of the Fermi points, $q_F$. Notably, we\nfind that the energy scale of the 2-spinons near the Brillouin zone boundary is\nsubstantially softened compared to that predicted by the Hubbard model in\none-dimension. Such a discrepancy implies missing ingredients, which lends\nsupport for the presence of an additional attractive potential between holes.",
    "pdf_url": "http://arxiv.org/pdf/2502.21316v1",
    "published": "2025-02-28",
    "source": "arxiv",
    "id": "2502.21316v1",
    "categories": [
      "cond-mat.str-el"
    ]
  },
  {
    "title": "Identifying Emerging Concepts in Large Corpora",
    "authors": [
      "Sibo Ma",
      "Julian Nyarko"
    ],
    "abstract": "We introduce a new method to identify emerging concepts in large text\ncorpora. By analyzing changes in the heatmaps of the underlying embedding\nspace, we are able to detect these concepts with high accuracy shortly after\nthey originate, in turn outperforming common alternatives. We further\ndemonstrate the utility of our approach by analyzing speeches in the U.S.\nSenate from 1941 to 2015. Our results suggest that the minority party is more\nactive in introducing new concepts into the Senate discourse. We also identify\nspecific concepts that closely correlate with the Senators' racial, ethnic, and\ngender identities. An implementation of our method is publicly available.",
    "pdf_url": "http://arxiv.org/pdf/2502.21315v1",
    "published": "2025-02-28",
    "source": "arxiv",
    "id": "2502.21315v1",
    "categories": [
      "cs.CL",
      "cs.CY"
    ]
  },
  {
    "title": "Raccoon: Multi-stage Diffusion Training with Coarse-to-Fine Curating Videos",
    "authors": [
      "Zhiyu Tan",
      "Junyan Wang",
      "Hao Yang",
      "Luozheng Qin",
      "Hesen Chen",
      "Qiang Zhou",
      "Hao Li"
    ],
    "abstract": "Text-to-video generation has demonstrated promising progress with the advent\nof diffusion models, yet existing approaches are limited by dataset quality and\ncomputational resources. To address these limitations, this paper presents a\ncomprehensive approach that advances both data curation and model design. We\nintroduce CFC-VIDS-1M, a high-quality video dataset constructed through a\nsystematic coarse-to-fine curation pipeline. The pipeline first evaluates video\nquality across multiple dimensions, followed by a fine-grained stage that\nleverages vision-language models to enhance text-video alignment and semantic\nrichness. Building upon the curated dataset's emphasis on visual quality and\ntemporal coherence, we develop RACCOON, a transformer-based architecture with\ndecoupled spatial-temporal attention mechanisms. The model is trained through a\nprogressive four-stage strategy designed to efficiently handle the complexities\nof video generation. Extensive experiments demonstrate that our integrated\napproach of high-quality data curation and efficient training strategy\ngenerates visually appealing and temporally coherent videos while maintaining\ncomputational efficiency. We will release our dataset, code, and models.",
    "pdf_url": "http://arxiv.org/pdf/2502.21314v1",
    "published": "2025-02-28",
    "source": "arxiv",
    "id": "2502.21314v1",
    "categories": [
      "cs.CV"
    ]
  },
  {
    "title": "Unsupervised Parameter Efficient Source-free Post-pretraining",
    "authors": [
      "Abhishek Jha",
      "Tinne Tuytelaars",
      "Yuki M. Asano"
    ],
    "abstract": "Following the success in NLP, the best vision models are now in the billion\nparameter ranges. Adapting these large models to a target distribution has\nbecome computationally and economically prohibitive. Addressing this challenge,\nwe introduce UpStep, an Unsupervised Parameter-efficient Source-free\npost-pretraining approach, designed to efficiently adapt a base model from a\nsource domain to a target domain: i) we design a self-supervised training\nscheme to adapt a pretrained model on an unlabeled target domain in a setting\nwhere source domain data is unavailable. Such source-free setting comes with\nthe risk of catastrophic forgetting, hence, ii) we propose center vector\nregularization (CVR), a set of auxiliary operations that minimize catastrophic\nforgetting and additionally reduces the computational cost by skipping\nbackpropagation in 50\\% of the training iterations. Finally iii) we perform\nthis adaptation process in a parameter-efficient way by adapting the pretrained\nmodel through low-rank adaptation methods, resulting in a fraction of\nparameters to optimize. We utilize various general backbone architectures, both\nsupervised and unsupervised, trained on Imagenet as our base model and adapt\nthem to a diverse set of eight target domains demonstrating the adaptability\nand generalizability of our proposed approach.",
    "pdf_url": "http://arxiv.org/pdf/2502.21313v1",
    "published": "2025-02-28",
    "source": "arxiv",
    "id": "2502.21313v1",
    "categories": [
      "cs.CV",
      "cs.LG"
    ]
  },
  {
    "title": "AutoComb: Automated Comb Sign Detector for 3D CTE Scans",
    "authors": [
      "Shashwat Gupta",
      "Sarthak Gupta",
      "Akshan Agrawal",
      "Mahim Naaz",
      "Rajanikanth Yadav",
      "Priyanka Bagade"
    ],
    "abstract": "Comb Sign is an important imaging biomarker to detect multiple\ngastrointestinal diseases. It shows up as increased blood flow along the\nintestinal wall indicating potential abnormality, which helps doctors diagnose\ninflammatory conditions. Despite its clinical significance, current detection\nmethods are manual, time-intensive, and prone to subjective interpretation due\nto the need for multi-planar image-orientation. To the best of our knowledge,\nwe are the first to propose a fully automated technique for the detection of\nComb Sign from CTE scans. Our novel approach is based on developing a\nprobabilistic map that shows areas of pathological hypervascularity by\nidentifying fine vascular bifurcations and wall enhancement via processing\nthrough stepwise algorithmic modules. These modules include utilising deep\nlearning segmentation model, a Gaussian Mixture Model (GMM), vessel extraction\nusing vesselness filter, iterative probabilistic enhancement of vesselness via\nneighborhood maximization and a distance-based weighting scheme over the\nvessels. Experimental results demonstrate that our pipeline effectively\nidentifies Comb Sign, offering an objective, accurate, and reliable tool to\nenhance diagnostic accuracy in Crohn's disease and related hypervascular\nconditions where Comb Sign is considered as one of the important biomarkers.",
    "pdf_url": "http://arxiv.org/pdf/2502.21311v1",
    "published": "2025-02-28",
    "source": "arxiv",
    "id": "2502.21311v1",
    "categories": [
      "eess.IV",
      "cs.CV"
    ]
  },
  {
    "title": "FANformer: Improving Large Language Models Through Effective Periodicity Modeling",
    "authors": [
      "Yihong Dong",
      "Ge Li",
      "Xue Jiang",
      "Yongding Tao",
      "Kechi Zhang",
      "Hao Zhu",
      "Huanyu Liu",
      "Jiazheng Ding",
      "Jia Li",
      "Jinliang Deng",
      "Hong Mei"
    ],
    "abstract": "Periodicity, as one of the most important basic characteristics, lays the\nfoundation for facilitating structured knowledge acquisition and systematic\ncognitive processes within human learning paradigms. However, the potential\nflaws of periodicity modeling in Transformer affect the learning efficiency and\nestablishment of underlying principles from data for large language models\n(LLMs) built upon it. In this paper, we demonstrate that integrating effective\nperiodicity modeling can improve the learning efficiency and performance of\nLLMs. We introduce FANformer, which integrates Fourier Analysis Network (FAN)\ninto attention mechanism to achieve efficient periodicity modeling, by\nmodifying the feature projection process of attention mechanism. Extensive\nexperimental results on language modeling show that FANformer consistently\noutperforms Transformer when scaling up model size and training tokens,\nunderscoring its superior learning efficiency. To further validate the\neffectiveness of FANformer, we pretrain a FANformer-1B on 1 trillion tokens.\nFANformer-1B exhibits marked improvements on downstream tasks compared to\nopen-source LLMs with similar model parameters or training tokens. The results\nposition FANformer as an effective and promising architecture for advancing\nLLMs.",
    "pdf_url": "http://arxiv.org/pdf/2502.21309v1",
    "published": "2025-02-28",
    "source": "arxiv",
    "id": "2502.21309v1",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ]
  },
  {
    "title": "Solar prosumage under different pricing regimes: Interactions with the transmission grid",
    "authors": [
      "Dana Kirchem",
      "Mario Kendziorski",
      "Enno Wiebrow",
      "Wolf-Peter Schill",
      "Claudia Kemfert",
      "Christian von Hirschhausen"
    ],
    "abstract": "Solar prosumers, residential electricity consumers equipped with photovoltaic\n(PV) systems and battery storage, are transforming electricity markets. Their\ninteractions with the transmission grid under varying tariff designs are not\nyet fully understood. We explore the influence of different pricing regimes on\nprosumer investment and dispatch decisions and their subsequent impact on the\ntransmission grid. Using an integrated modeling approach that combines two\nopen-source dispatch, investment and grid models, we simulate prosumage\nbehavior in Germany's electricity market under real-time pricing or\ntime-invariant pricing, as well as under zonal or nodal pricing. Our findings\nshow that zonal pricing favors prosumer investments, while time-invariant\npricing rather hinders it. In comparison, regional solar availability emerges\nas a larger driver for rooftop PV investments. The impact of prosumer\nstrategies on grid congestion remains limited within the scope of our\nmodel-setup, in which home batteries cannot be used for energy arbitrage.",
    "pdf_url": "http://arxiv.org/pdf/2502.21306v1",
    "published": "2025-02-28",
    "source": "arxiv",
    "id": "2502.21306v1",
    "categories": [
      "econ.GN",
      "q-fin.EC"
    ]
  },
  {
    "title": "CurviTrack: Curvilinear Trajectory Tracking for High-speed Chase of a USV",
    "authors": [
      "Parakh M. Gupta",
      "Ondřej Procházka",
      "Tiago Nascimento",
      "Martin Saska"
    ],
    "abstract": "Heterogeneous robot teams used in marine environments incur time-and-energy\npenalties when the marine vehicle has to halt the mission to allow the\nautonomous aerial vehicle to land for recharging. In this paper, we present a\nsolution for this problem using a novel drag-aware model formulation which is\ncoupled with MPC, and therefore, enables tracking and landing during high-speed\ncurvilinear trajectories of an USV without any communication. Compared to the\nstate-of-the-art, our approach yields 40% decrease in prediction errors, and\nprovides a 3-fold increase in certainty of predictions. Consequently, this\nleads to a 30% improvement in tracking performance and 40% higher success in\nlanding on a moving USV even during aggressive turns that are unfeasible for\nconventional marine missions. We test our approach in two different real-world\nscenarios with marine vessels of two different sizes and further solidify our\nresults through statistical analysis in simulation to demonstrate the\nrobustness of our method.",
    "pdf_url": "http://arxiv.org/pdf/2502.21303v1",
    "published": "2025-02-28",
    "source": "arxiv",
    "id": "2502.21303v1",
    "categories": [
      "cs.RO",
      "cs.SY",
      "eess.SY"
    ]
  },
  {
    "title": "Hybrid Team Tetris: A New Platform For Hybrid Multi-Agent, Multi-Human Teaming",
    "authors": [
      "Kaleb Mcdowell",
      "Nick Waytowich",
      "Javier Garcia",
      "Stephen Gordon",
      "Bryce Bartlett",
      "Jeremy Gaston"
    ],
    "abstract": "Metcalfe et al (1) argue that the greatest potential for human-AI\npartnerships lies in their application to highly complex problem spaces.\nHerein, we discuss three different forms of hybrid team intelligence and posit\nthat across all three forms, the hybridization of man and machine intelligence\ncan be effective under the right conditions. We foresee two significant\nresearch and development (R&D) challenges underlying the creation of effective\nhybrid intelligence. First, rapid advances in machine intelligence and/or\nfundamental changes in human behaviors or capabilities over time can outpace\nR&D. Second, the future conditions under which hybrid intelligence will operate\nare unknown, but unlikely to be the same as the conditions of today. Overcoming\nboth of these challenges requires a deep understanding of multiple\nhuman-centric and machine-centric disciplines that creates a large barrier to\nentry into the field. Herein, we outline an open, shareable research platform\nthat creates a form of hybrid team intelligence that functions under\nrepresentative future conditions. The intent for the platform is to facilitate\nnew forms of hybrid intelligence research allowing individuals with\nhuman-centric or machine-centric backgrounds to rapidly enter the field and\ninitiate research. Our hope is that through open, community research on the\nplatform, state-of-the-art advances in human and machine intelligence can\nquickly be communicated across what are currently different R&D communities and\nallow hybrid team intelligence research to stay at the forefront of scientific\nadvancement.",
    "pdf_url": "http://arxiv.org/pdf/2502.21300v1",
    "published": "2025-02-28",
    "source": "arxiv",
    "id": "2502.21300v1",
    "categories": [
      "cs.HC"
    ]
  },
  {
    "title": "Persuasion Should be Double-Blind: A Multi-Domain Dialogue Dataset With Faithfulness Based on Causal Theory of Mind",
    "authors": [
      "Dingyi Zhang",
      "Deyu Zhou"
    ],
    "abstract": "Persuasive dialogue plays a pivotal role in human communication, influencing\nvarious domains. Recent persuasive dialogue datasets often fail to align with\nreal-world interpersonal interactions, leading to unfaithful representations.\nFor instance, unrealistic scenarios may arise, such as when the persuadee\nexplicitly instructs the persuader on which persuasion strategies to employ,\nwith each of the persuadee's questions corresponding to a specific strategy for\nthe persuader to follow. This issue can be attributed to a violation of the\n\"Double Blind\" condition, where critical information is fully shared between\nparticipants. In actual human interactions, however, key information such as\nthe mental state of the persuadee and the persuasion strategies of the\npersuader is not directly accessible. The persuader must infer the persuadee's\nmental state using Theory of Mind capabilities and construct arguments that\nalign with the persuadee's motivations. To address this gap, we introduce\nToMMA, a novel multi-agent framework for dialogue generation that is guided by\ncausal Theory of Mind. This framework ensures that information remains\nundisclosed between agents, preserving \"double-blind\" conditions, while causal\nToM directs the persuader's reasoning, enhancing alignment with human-like\npersuasion dynamics. Consequently, we present CToMPersu, a multi-domain,\nmulti-turn persuasive dialogue dataset that tackles both double-blind and\nlogical coherence issues, demonstrating superior performance across multiple\nmetrics and achieving better alignment with real human dialogues. Our dataset\nand prompts are available at https://github.com/DingyiZhang/ToMMA-CToMPersu .",
    "pdf_url": "http://arxiv.org/pdf/2502.21297v1",
    "published": "2025-02-28",
    "source": "arxiv",
    "id": "2502.21297v1",
    "categories": [
      "cs.CL"
    ]
  },
  {
    "title": "Oscillatory finite-time singularities in rockbursts",
    "authors": [
      "Qinghua Lei",
      "Didier Sornette"
    ],
    "abstract": "Forecasting violent rockbursts remains a formidable challenge due to\nsignificant uncertainties involved. One major uncertainty arises from the\nintermittency of rock failure processes, typically characterised by a series of\nprogressively shorter quiescent phases punctuated by sudden accelerations,\nrather than a smooth continuous progression towards the final breakdown. This\nnon-monotonic evolution of rock mass deformation complicates rockburst\nprediction, challenging conventional time-to-failure models that often assume a\nsmooth power law accelerating behaviour. Here, we introduce a generalised\ntime-to-failure model called log-periodic power law singularity (LPPLS) model\nto effectively capture the intermittent dynamics of damage and rupture\nprocesses in rock leading up to violent rockbursts. We perform parametric and\nnonparametric tests on 11 historical rockburst events at three underground\nmines, documenting empirical evidence and providing theoretical arguments to\ndemonstrate the significance of log-periodic oscillatory power law finite-time\nsingularities. Log-periodicity in these rockburst events is likely driven by\nthe interaction of subparallel propagating cracks, the diffusion of\nstress-triggering processes, or the interplay between stress drop and stress\ncorrosion. Our results and insights obtained have significant implications for\nnot only understanding but also forecasting rockbursts, as recognising and\ncharacterising log-periodicity can help transform intermittency from\ntraditionally perceived noise into valuable predictive information.",
    "pdf_url": "http://arxiv.org/pdf/2502.21296v1",
    "published": "2025-02-28",
    "source": "arxiv",
    "id": "2502.21296v1",
    "categories": [
      "physics.geo-ph"
    ]
  },
  {
    "title": "On the role of 5-wave resonances in the nonlinear dynamics of the Fermi-Pasta-Ulam-Tsingou lattice",
    "authors": [
      "Tiziana Comito",
      "Matteo Lotriglia",
      "Miguel D. Bustamante"
    ],
    "abstract": "We study the dynamics of the $(\\alpha+\\beta)$ Fermi-Pasta-Ulam-Tsingou\nlattice (FPUT lattice, for short) for an arbitrary number $N$ of interacting\nparticles, in regimes of small enough nonlinearity so that a Birkhoff-Gustavson\ntype of normal form can be found using tools from wave-turbulence theory.\nSpecifically, we obtain the so-called Zakharov equation for $4$-wave resonant\ninteractions and its extension to $5$-wave resonant interactions by Krasitskii,\nbut we introduce an important new feature: even the generic terms in these\nnormal forms contain $resonant$ $interactions$ $only$, via a $unique$ canonical\ntransformation. The resulting normal forms provide an approximation to the\noriginal FPUT lattice that possesses a significant number of exact quadratic\nconservation laws, beyond the quadratic part of the Hamiltonian. We call the\nnew equations \"exact-resonance evolution equations\" and examine their\nproperties: (i) Heisenberg representation's slow evolution allows us to\nimplement numerical methods with large time steps to obtain relevant dynamical\ninformation, such as Lyapunov exponents. (ii) We introduce tests, such as\nconvergence of the normal form transformation and truncation error\nverification, to successfully validate our exact-resonance evolution equations.\n(iii) The systematic construction of new quadratic invariants (via the resonant\ncluster matrix) allows us to use finite-time Lyapunov exponent calculations to\nquantify the level of nonlinearity at which the original FPUT lattice is well\napproximated by the exact-resonance evolution equations. We show numerical\nexperiments in the case $N=9$, but the theory and numerical methods are valid\nfor arbitrary values of $N$. We conclude that, when $3$ divides $N$, at small\nenough nonlinearity the FPUT lattice's dynamics and nontrivial hyperchaos are\ngoverned by $5$-wave resonant interactions.",
    "pdf_url": "http://arxiv.org/pdf/2502.21293v1",
    "published": "2025-02-28",
    "source": "arxiv",
    "id": "2502.21293v1",
    "categories": [
      "nlin.CD",
      "nlin.PS"
    ]
  },
  {
    "title": "Bilevel Optimized Implicit Neural Representation for Scan-Specific Accelerated MRI Reconstruction",
    "authors": [
      "Hongze Yu",
      "Jeffrey A. Fessler",
      "Yun Jiang"
    ],
    "abstract": "Deep Learning (DL) methods can reconstruct highly accelerated magnetic\nresonance imaging (MRI) scans, but they rely on application-specific large\ntraining datasets and often generalize poorly to out-of-distribution data.\nSelf-supervised deep learning algorithms perform scan-specific reconstructions,\nbut still require complicated hyperparameter tuning based on the acquisition\nand often offer limited acceleration. This work develops a bilevel-optimized\nimplicit neural representation (INR) approach for scan-specific MRI\nreconstruction. The method automatically optimizes the hyperparameters for a\ngiven acquisition protocol, enabling a tailored reconstruction without training\ndata. The proposed algorithm uses Gaussian process regression to optimize INR\nhyperparameters, accommodating various acquisitions. The INR includes a\ntrainable positional encoder for high-dimensional feature embedding and a small\nmultilayer perceptron for decoding. The bilevel optimization is computationally\nefficient, requiring only a few minutes per typical 2D Cartesian scan. On\nscanner hardware, the subsequent scan-specific reconstruction-using\noffline-optimized hyperparameters-is completed within seconds and achieves\nimproved image quality compared to previous model-based and self-supervised\nlearning methods.",
    "pdf_url": "http://arxiv.org/pdf/2502.21292v1",
    "published": "2025-02-28",
    "source": "arxiv",
    "id": "2502.21292v1",
    "categories": [
      "eess.IV",
      "eess.SP"
    ]
  },
  {
    "title": "MIGE: A Unified Framework for Multimodal Instruction-Based Image Generation and Editing",
    "authors": [
      "Xueyun Tian",
      "Wei Li",
      "Bingbing Xu",
      "Yige Yuan",
      "Yuanzhuo Wang",
      "Huawei Shen"
    ],
    "abstract": "Despite significant progress in diffusion-based image generation,\nsubject-driven generation and instruction-based editing remain challenging.\nExisting methods typically treat them separately, struggling with limited\nhigh-quality data and poor generalization. However, both tasks require\ncapturing complex visual variations while maintaining consistency between\ninputs and outputs. Therefore, we propose MIGE, a unified framework that\nstandardizes task representations using multimodal instructions. It treats\nsubject-driven generation as creation on a blank canvas and instruction-based\nediting as modification of an existing image, establishing a shared\ninput-output formulation. MIGE introduces a novel multimodal encoder that maps\nfree-form multimodal instructions into a unified vision-language space,\nintegrating visual and semantic features through a feature fusion mechanism.\nThis unification enables joint training of both tasks, providing two key\nadvantages: (1) Cross-Task Enhancement: By leveraging shared visual and\nsemantic representations, joint training improves instruction adherence and\nvisual consistency in both subject-driven generation and instruction-based\nediting. (2) Generalization: Learning in a unified format facilitates\ncross-task knowledge transfer, enabling MIGE to generalize to novel\ncompositional tasks, including instruction-based subject-driven editing.\nExperiments show that MIGE excels in both subject-driven generation and\ninstruction-based editing while setting a state-of-the-art in the new task of\ninstruction-based subject-driven editing. Code and model have been publicly\navailable at https://github.com/Eureka-Maggie/MIGE.",
    "pdf_url": "http://arxiv.org/pdf/2502.21291v2",
    "published": "2025-02-28",
    "source": "arxiv",
    "id": "2502.21291v2",
    "categories": [
      "cs.CV"
    ]
  },
  {
    "title": "Contextualizing biological perturbation experiments through language",
    "authors": [
      "Menghua Wu",
      "Russell Littman",
      "Jacob Levine",
      "Lin Qiu",
      "Tommaso Biancalani",
      "David Richmond",
      "Jan-Christian Huetter"
    ],
    "abstract": "High-content perturbation experiments allow scientists to probe biomolecular\nsystems at unprecedented resolution, but experimental and analysis costs pose\nsignificant barriers to widespread adoption. Machine learning has the potential\nto guide efficient exploration of the perturbation space and extract novel\ninsights from these data. However, current approaches neglect the semantic\nrichness of the relevant biology, and their objectives are misaligned with\ndownstream biological analyses. In this paper, we hypothesize that large\nlanguage models (LLMs) present a natural medium for representing complex\nbiological relationships and rationalizing experimental outcomes. We propose\nPerturbQA, a benchmark for structured reasoning over perturbation experiments.\nUnlike current benchmarks that primarily interrogate existing knowledge,\nPerturbQA is inspired by open problems in perturbation modeling: prediction of\ndifferential expression and change of direction for unseen perturbations, and\ngene set enrichment. We evaluate state-of-the-art machine learning and\nstatistical approaches for modeling perturbations, as well as standard LLM\nreasoning strategies, and we find that current methods perform poorly on\nPerturbQA. As a proof of feasibility, we introduce Summer (SUMMarize, retrievE,\nand answeR, a simple, domain-informed LLM framework that matches or exceeds the\ncurrent state-of-the-art. Our code and data are publicly available at\nhttps://github.com/genentech/PerturbQA.",
    "pdf_url": "http://arxiv.org/pdf/2502.21290v1",
    "published": "2025-02-28",
    "source": "arxiv",
    "id": "2502.21290v1",
    "categories": [
      "cs.AI",
      "cs.LG",
      "q-bio.QM"
    ]
  },
  {
    "title": "Flow-Driven Rotor Simulations of Seyi-Chunlei Ducted Turbine",
    "authors": [
      "Seyi Oluwadare",
      "Chunlei Liang"
    ],
    "abstract": "This paper proposes an improved Clarkson Ducted Wind Turbine (DWT) design\nusing a new diffuser based on the Selig S1223 airfoil at an angle of attack\n(AoA) of 20 degrees and a smaller tip clearance. This proposed design is hereby\nnamed Selig20 Clarkson Ducted Turbine or Seyi-Chunlei Ducted Turbine (SCDT)\ncompared to the original Clarkson Ducted Wind Turbine (CDWT). In both SCDT and\nCDWT configurations, the rotor is placed a distance behind the throat of the\nduct. For in-depth analysis, we employ a flow-driven-rotor (FDR) model of a\ncommercial CFD package, Simerics-MP+, based on unstructured-grid finite-volume\nsolutions of Unsteady Reynolds-Averaged Navier-Stokes (URANS) equations for the\nflow field that are two-way fully coupled with a dynamic solution of the\nrigid-body rotation of the turbine rotor. The FDR model successfully predicts\nthe optimal thrust coefficient, whereas the prescribed rotation model fails to\ndo so. Although the optimal Cp predicted by the FDR model is fairly close to\nthe prediction from the prescribed motion model, FDR is generally more accurate\nin predicting underperformance under ambient wind conditions away from the\noptimal tip speed ratio. FDR offers a new path to simulate ducted wind turbines\nin ambient wind conditions. The Seyi-Chunlei Ducted Turbine is confirmed to\nhave a Cpt peak approximately 7% higher than that of the Clarkson DWT. SCDT\nalso has a wider range of optimal tip speed ratios, enabling it to harvest more\nwind energy under ambient conditions.",
    "pdf_url": "http://arxiv.org/pdf/2502.21289v1",
    "published": "2025-02-28",
    "source": "arxiv",
    "id": "2502.21289v1",
    "categories": [
      "physics.flu-dyn"
    ]
  },
  {
    "title": "Enabling AutoML for Zero-Touch Network Security: Use-Case Driven Analysis",
    "authors": [
      "Li Yang",
      "Mirna El Rajab",
      "Abdallah Shami",
      "Sami Muhaidat"
    ],
    "abstract": "Zero-Touch Networks (ZTNs) represent a state-of-the-art paradigm shift\ntowards fully automated and intelligent network management, enabling the\nautomation and intelligence required to manage the complexity, scale, and\ndynamic nature of next-generation (6G) networks. ZTNs leverage Artificial\nIntelligence (AI) and Machine Learning (ML) to enhance operational efficiency,\nsupport intelligent decision-making, and ensure effective resource allocation.\nHowever, the implementation of ZTNs is subject to security challenges that need\nto be resolved to achieve their full potential. In particular, two critical\nchallenges arise: the need for human expertise in developing AI/ML-based\nsecurity mechanisms, and the threat of adversarial attacks targeting AI/ML\nmodels. In this survey paper, we provide a comprehensive review of current\nsecurity issues in ZTNs, emphasizing the need for advanced AI/ML-based security\nmechanisms that require minimal human intervention and protect AI/ML models\nthemselves. Furthermore, we explore the potential of Automated ML (AutoML)\ntechnologies in developing robust security solutions for ZTNs. Through case\nstudies, we illustrate practical approaches to securing ZTNs against both\nconventional and AI/ML-specific threats, including the development of\nautonomous intrusion detection systems and strategies to combat Adversarial ML\n(AML) attacks. The paper concludes with a discussion of the future research\ndirections for the development of ZTN security approaches.",
    "pdf_url": "http://arxiv.org/pdf/2502.21286v1",
    "published": "2025-02-28",
    "source": "arxiv",
    "id": "2502.21286v1",
    "categories": [
      "cs.CR",
      "cs.LG",
      "cs.NI",
      "68T01, 90C31",
      "I.2.1; I.2.6; C.2.0"
    ]
  },
  {
    "title": "Controlled Model Debiasing through Minimal and Interpretable Updates",
    "authors": [
      "Federico Di Gennaro",
      "Thibault Laugel",
      "Vincent Grari",
      "Marcin Detyniecki"
    ],
    "abstract": "Traditional approaches to learning fair machine learning models often require\nrebuilding models from scratch, generally without accounting for potentially\nexisting previous models. In a context where models need to be retrained\nfrequently, this can lead to inconsistent model updates, as well as redundant\nand costly validation testing. To address this limitation, we introduce the\nnotion of controlled model debiasing, a novel supervised learning task relying\non two desiderata: that the differences between new fair model and the existing\none should be (i) interpretable and (ii) minimal. After providing theoretical\nguarantees to this new problem, we introduce a novel algorithm for algorithmic\nfairness, COMMOD, that is both model-agnostic and does not require the\nsensitive attribute at test time. In addition, our algorithm is explicitly\ndesigned to enforce minimal and interpretable changes between biased and\ndebiased predictions -a property that, while highly desirable in high-stakes\napplications, is rarely prioritized as an explicit objective in fairness\nliterature. Our approach combines a concept-based architecture and adversarial\nlearning and we demonstrate through empirical results that it achieves\ncomparable performance to state-of-the-art debiasing methods while performing\nminimal and interpretable prediction changes.",
    "pdf_url": "http://arxiv.org/pdf/2502.21284v1",
    "published": "2025-02-28",
    "source": "arxiv",
    "id": "2502.21284v1",
    "categories": [
      "cs.LG",
      "stat.ML"
    ]
  },
  {
    "title": "Reconstruction of spider system's observables from orbital period modulations via the Applegate mechanism",
    "authors": [
      "Vittorio De Falco",
      "Amodio Carleo",
      "Alessandro Ridolfi",
      "Alessandro Corongiu"
    ],
    "abstract": "Redback and black widow pulsars are two classes of peculiar binary systems\ncharacterized by very short orbital periods, very low mass companions, and, in\nseveral cases, regular eclipses in their pulsed radio signal. Long-term timing\nrevealed systematic but unpredictable variations in the orbital period, which\ncan most likely be explained by the so-called Applegate mechanism. This relies\non the magnetic dynamo activity generated inside the companion star and\ntriggered by the pulsar wind, which induces a modification of the star's\noblateness (or quadrupole variation). This, in turn, couples with the orbit by\ngravity, causing a consequent change in the orbital period. The Applegate\ndescription limits to provide estimates of physical quantities by highlighting\ntheir orders of magnitude. Therefore, we derive the time-evolution differential\nequations underlying the Applegate model, that is, we track such physical\nquantities in terms of time. Our strategy is to employ the orbital period\nmodulations, measured by fitting the observational data, and implementing a\nhighly accurate approximation scheme to finally reconstruct the dynamics of the\nspider system under study and the relative observables. Among the latter is the\nmagnetic field activity inside the companion star, which is still a matter of\ndebate for its complex theoretical modeling and the ensuing expensive numerical\nsimulations. As an application, we exploit our methodology to examine two\nspider sources: 47 Tuc W (redback) and 47 Tuc O (black widow). The results\nobtained are analyzed and then discussed with the literature.",
    "pdf_url": "http://arxiv.org/pdf/2502.21283v1",
    "published": "2025-02-28",
    "source": "arxiv",
    "id": "2502.21283v1",
    "categories": [
      "astro-ph.HE",
      "hep-th"
    ]
  },
  {
    "title": "Large Sample Inference with Dynamic Information Borrowing",
    "authors": [
      "Sergey Tarima",
      "Silvia Calderazzo",
      "Mary Homan"
    ],
    "abstract": "Large sample behavior of dynamic information borrowing (DIB) estimators is\ninvestigated. Asymptotic properties of several DIB approaches (adaptive risk\nminimization, adaptive LASSO, Bayesian procedures with empirical power prior,\nfully Bayesian procedures, and a Bayes-frequentist compromise) are explored\nagainst shrinking to zero alternatives. As shown theoretically and with\nsimulations, local asymptotic distributions of DIB estimators are often\nnon-normal. A simple Gaussian setting with external information borrowing\nillustrates that none of the considered DIB methods outperforms others in terms\nof mean squared error (MSE): at different conflict values, the MSEs of DIBs are\nchanging between the MSEs of the maximum likelihood estimators based on the\ncurrent and pooled data. To uniquely determine an optimality criterion for DIB,\na prior distribution on the conflict needs be either implicitly or explicitly\ndetermined using data independent considerations. Data independent assumptions\non the conflict are also needed for DIB-based hypothesis testing. New families\nof DIB estimators parameterized by a sensitivity-to-conflict parameter S are\nsuggested and their use is illustrated in an infant mortality example. The\nchoice of S is determined in a data-independent manner by a cost-benefit\ncompromise associated with the use of external data.",
    "pdf_url": "http://arxiv.org/pdf/2502.21282v1",
    "published": "2025-02-28",
    "source": "arxiv",
    "id": "2502.21282v1",
    "categories": [
      "stat.ME"
    ]
  },
  {
    "title": "Back to the Future Cyclopean Stereo: a human perception approach unifying deep and geometric constraints",
    "authors": [
      "Sherlon Almeida da Silva",
      "Davi Geiger",
      "Luiz Velho",
      "Moacir Antonelli Ponti"
    ],
    "abstract": "We innovate in stereo vision by explicitly providing analytical 3D surface\nmodels as viewed by a cyclopean eye model that incorporate depth\ndiscontinuities and occlusions. This geometrical foundation combined with\nlearned stereo features allows our system to benefit from the strengths of both\napproaches. We also invoke a prior monocular model of surfaces to fill in\nocclusion regions or texture-less regions where data matching is not\nsufficient. Our results already are on par with the state-of-the-art purely\ndata-driven methods and are of much better visual quality, emphasizing the\nimportance of the 3D geometrical model to capture critical visual information.\nSuch qualitative improvements may find applicability in virtual reality, for a\nbetter human experience, as well as in robotics, for reducing critical errors.\nOur approach aims to demonstrate that understanding and modeling geometrical\nproperties of 3D surfaces is beneficial to computer vision research.",
    "pdf_url": "http://arxiv.org/pdf/2502.21280v1",
    "published": "2025-02-28",
    "source": "arxiv",
    "id": "2502.21280v1",
    "categories": [
      "cs.CV"
    ]
  },
  {
    "title": "Does Generation Require Memorization? Creative Diffusion Models using Ambient Diffusion",
    "authors": [
      "Kulin Shah",
      "Alkis Kalavasis",
      "Adam R. Klivans",
      "Giannis Daras"
    ],
    "abstract": "There is strong empirical evidence that the state-of-the-art diffusion\nmodeling paradigm leads to models that memorize the training set, especially\nwhen the training set is small. Prior methods to mitigate the memorization\nproblem often lead to a decrease in image quality. Is it possible to obtain\nstrong and creative generative models, i.e., models that achieve high\ngeneration quality and low memorization? Despite the current pessimistic\nlandscape of results, we make significant progress in pushing the trade-off\nbetween fidelity and memorization. We first provide theoretical evidence that\nmemorization in diffusion models is only necessary for denoising problems at\nlow noise scales (usually used in generating high-frequency details). Using\nthis theoretical insight, we propose a simple, principled method to train the\ndiffusion models using noisy data at large noise scales. We show that our\nmethod significantly reduces memorization without decreasing the image quality,\nfor both text-conditional and unconditional models and for a variety of data\navailability settings.",
    "pdf_url": "http://arxiv.org/pdf/2502.21278v1",
    "published": "2025-02-28",
    "source": "arxiv",
    "id": "2502.21278v1",
    "categories": [
      "cs.LG",
      "stat.ML"
    ]
  },
  {
    "title": "Log-Periodic Precursors to Volcanic Eruptions: Evidence from 34 Events",
    "authors": [
      "Qinghua Lei",
      "Didier Sornette"
    ],
    "abstract": "Forecasting volcanic eruptions remains a formidable challenge due to the\ninherent complexity and variability of volcanic processes. A key source of\nuncertainty arises from the sporadic nature of volcanic unrest, which is often\ncharacterised by intermittent phases of quiescent deceleration and sudden\nacceleration, rather than a consistent, predictable progression towards\neruption. This seemingly erratic pattern complicates volcano forecasting as it\nchallenges conventional time-to-failure models that often assume a simple\nsmooth power law acceleration. We propose a log-periodic power law singularity\nmodel, which effectively captures the intermittent and non-monotonic rupture\ndynamics characteristic of reawakening volcanoes at the site scale.\nMathematically, generalising the power law exponent by extending it from real\nto complex numbers, this model captures the partial break of continuous scale\ninvariance to discrete scale invariance that is inherent to the intermittent\ndynamics of damage and rupture processes in heterogeneous crustal systems. By\nperforming parametric and nonparametric tests on a large dataset of 34\nhistorical eruptions worldwide, we present empirical evidence and theoretical\narguments demonstrating the statistical significance of log-periodic\noscillations decorating power law finite-time singularities during pre-eruptive\nvolcanic unrest. Log-periodicity in volcanoes may originate from various\nmechanisms, including diffusion-dominated magma flow, magma-driven propagation\nof subparallel dykes, interaction between stress drop and stress corrosion,\nand/or interplay of inertia, damage, and healing within volcanic systems. Our\nresults have important implications for volcano forecasting, because\nunderstanding and characterising log-periodicity could turn the intermittency\nof volcanic activity from a challenge into a valuable asset for improving\npredictions.",
    "pdf_url": "http://arxiv.org/pdf/2502.21277v1",
    "published": "2025-02-28",
    "source": "arxiv",
    "id": "2502.21277v1",
    "categories": [
      "physics.geo-ph"
    ]
  },
  {
    "title": "Utilizing Quantum Fingerprints in Plant Cells to Evaluate Plant productivity",
    "authors": [
      "Umadini Ranasinghe",
      "Abigail L. Stressinger",
      "Guangpeng Xu",
      "Yasmin Sarhan",
      "Fred Harrington",
      "James Berry",
      "Tim Thomay"
    ],
    "abstract": "Overcoming the strong chlorophyll background poses a significant challenge\nfor measuring and optimizing plant growth. This research investigates the novel\napplication of specialized quantum light emitters introduced into intact leaves\nof tobacco (Nicotiana tabacum), a well-characterized model plant system for\nstudies of plant health and productivity. Leaves were harvested from plants\ncultivated under two distinct conditions: low light (LL), representing\nunhealthy leaves with reduced photosynthesis. and high light (HL), representing\nhealthy leaves with highly active photosynthesis. Higher-order correlation data\nwere collected and analyzed using machine learning (ML) techniques,\nspecifically a Convolutional Neural Network (CNN), to classify the photon\nemitter states. This CNN efficiently identified unique patterns and created\ndistinct fingerprints for Nicotiana leaves grown under LL and HL, demonstrating\nsignificantly different quantum profiles between the two conditions. These\nquantum fingerprints serve as a foundation for a novel unified analysis of\nplant growth parameters associated with different photosynthetic states. By\nemploying CNN, the emitter profiles were able to reproducibly classify the\nleaves as healthy or unhealthy. This model achieved high probability values for\neach classification, confirming its accuracy and reliability. The findings of\nthis study pave the way for broader applications, including the application of\nadvanced quantum and machine learning technologies in plant health monitoring\nsystems.",
    "pdf_url": "http://arxiv.org/pdf/2502.21275v1",
    "published": "2025-02-28",
    "source": "arxiv",
    "id": "2502.21275v1",
    "categories": [
      "physics.bio-ph"
    ]
  },
  {
    "title": "BAnG: Bidirectional Anchored Generation for Conditional RNA Design",
    "authors": [
      "Roman Klypa",
      "Alberto Bietti",
      "Sergei Grudinin"
    ],
    "abstract": "Designing RNA molecules that interact with specific proteins is a critical\nchallenge in experimental and computational biology. Existing computational\napproaches require a substantial amount of experimentally determined RNA\nsequences for each specific protein or a detailed knowledge of RNA structure,\nrestricting their utility in practice. To address this limitation, we develop\nRNA-BAnG, a deep learning-based model designed to generate RNA sequences for\nprotein interactions without these requirements. Central to our approach is a\nnovel generative method, Bidirectional Anchored Generation (BAnG), which\nleverages the observation that protein-binding RNA sequences often contain\nfunctional binding motifs embedded within broader sequence contexts. We first\nvalidate our method on generic synthetic tasks involving similar localized\nmotifs to those appearing in RNAs, demonstrating its benefits over existing\ngenerative approaches. We then evaluate our model on biological sequences,\nshowing its effectiveness for conditional RNA sequence design given a binding\nprotein.",
    "pdf_url": "http://arxiv.org/pdf/2502.21274v1",
    "published": "2025-02-28",
    "source": "arxiv",
    "id": "2502.21274v1",
    "categories": [
      "cs.LG",
      "cs.AI",
      "q-bio.BM"
    ]
  },
  {
    "title": "Adaptive Keyframe Sampling for Long Video Understanding",
    "authors": [
      "Xi Tang",
      "Jihao Qiu",
      "Lingxi Xie",
      "Yunjie Tian",
      "Jianbin Jiao",
      "Qixiang Ye"
    ],
    "abstract": "Multimodal large language models (MLLMs) have enabled open-world visual\nunderstanding by injecting visual input as extra tokens into large language\nmodels (LLMs) as contexts. However, when the visual input changes from a single\nimage to a long video, the above paradigm encounters difficulty because the\nvast amount of video tokens has significantly exceeded the maximal capacity of\nMLLMs. Therefore, existing video-based MLLMs are mostly established upon\nsampling a small portion of tokens from input data, which can cause key\ninformation to be lost and thus produce incorrect answers. This paper presents\na simple yet effective algorithm named Adaptive Keyframe Sampling (AKS). It\ninserts a plug-and-play module known as keyframe selection, which aims to\nmaximize the useful information with a fixed number of video tokens. We\nformulate keyframe selection as an optimization involving (1) the relevance\nbetween the keyframes and the prompt, and (2) the coverage of the keyframes\nover the video, and present an adaptive algorithm to approximate the best\nsolution. Experiments on two long video understanding benchmarks validate that\nAdaptive Keyframe Sampling improves video QA accuracy (beyond strong baselines)\nupon selecting informative keyframes. Our study reveals the importance of\ninformation pre-filtering in video-based MLLMs. Code is available at\nhttps://github.com/ncTimTang/AKS.",
    "pdf_url": "http://arxiv.org/pdf/2502.21271v1",
    "published": "2025-02-28",
    "source": "arxiv",
    "id": "2502.21271v1",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG"
    ]
  },
  {
    "title": "Dynamical Decoupling of Generalization and Overfitting in Large Two-Layer Networks",
    "authors": [
      "Andrea Montanari",
      "Pierfrancesco Urbani"
    ],
    "abstract": "The inductive bias and generalization properties of large machine learning\nmodels are -- to a substantial extent -- a byproduct of the optimization\nalgorithm used for training. Among others, the scale of the random\ninitialization, the learning rate, and early stopping all have crucial impact\non the quality of the model learnt by stochastic gradient descent or related\nalgorithms. In order to understand these phenomena, we study the training\ndynamics of large two-layer neural networks. We use a well-established\ntechnique from non-equilibrium statistical physics (dynamical mean field\ntheory) to obtain an asymptotic high-dimensional characterization of this\ndynamics. This characterization applies to a Gaussian approximation of the\nhidden neurons non-linearity, and empirically captures well the behavior of\nactual neural network models.\n  Our analysis uncovers several interesting new phenomena in the training\ndynamics: $(i)$ The emergence of a slow time scale associated with the growth\nin Gaussian/Rademacher complexity; $(ii)$ As a consequence, algorithmic\ninductive bias towards small complexity, but only if the initialization has\nsmall enough complexity; $(iii)$ A separation of time scales between feature\nlearning and overfitting; $(iv)$ A non-monotone behavior of the test error and,\ncorrespondingly, a `feature unlearning' phase at large times.",
    "pdf_url": "http://arxiv.org/pdf/2502.21269v1",
    "published": "2025-02-28",
    "source": "arxiv",
    "id": "2502.21269v1",
    "categories": [
      "stat.ML",
      "cond-mat.dis-nn",
      "cs.LG"
    ]
  },
  {
    "title": "Stochastic dynamics at the back of a gene drive propagation wave",
    "authors": [
      "Léna Kläy",
      "Léo Girardin",
      "Florence Débarre",
      "Vincent Calvez"
    ],
    "abstract": "Gene drive alleles bias their own inheritance to offspring. They can fix in a\nwild-type population in spite of a fitness cost, and even lead to the\neradication of the target population if the fitness cost is high. However, this\noutcome may be prevented or delayed if areas previously cleared by the drive\nare recolonised by wild-type individuals. Here, we investigate the conditions\nunder which these stochastic wild-type recolonisation events are likely and\nwhen they are unlikely to occur in one spatial dimension. More precisely, we\nexamine the conditions ensuring that the last individual carrying a wild-type\nallele is surrounded by a large enough number of drive homozygous individuals,\nresulting in a very low chance of wild-type recolonisation. To do so, we make a\ndeterministic approximation of the distribution of drive alleles within the\nwave, and we split the distribution of wild-type alleles into a deterministic\npart and a stochastic part. Our analytical and numerical results suggest that\nthe probability of wild-type recolonisation events increases with lower fitness\nof drive individuals, with smaller migration rate, and also with smaller local\ncarrying capacity. Numerical simulations show that these results extend to two\nspatial dimensions. We also demonstrate that, if a wild-type recolonisation\nevent were to occur, the probability of a following drive reinvasion event\ndecreases with smaller values of the intrinsic growth rate of the population.\nOverall, our study paves the way for further analysis of wild-type\nrecolonisation at the back of eradication traveling waves.",
    "pdf_url": "http://arxiv.org/pdf/2502.21268v1",
    "published": "2025-02-28",
    "source": "arxiv",
    "id": "2502.21268v1",
    "categories": [
      "q-bio.PE"
    ]
  },
  {
    "title": "ReaLJam: Real-Time Human-AI Music Jamming with Reinforcement Learning-Tuned Transformers",
    "authors": [
      "Alexander Scarlatos",
      "Yusong Wu",
      "Ian Simon",
      "Adam Roberts",
      "Tim Cooijmans",
      "Natasha Jaques",
      "Cassie Tarakajian",
      "Cheng-Zhi Anna Huang"
    ],
    "abstract": "Recent advances in generative artificial intelligence (AI) have created\nmodels capable of high-quality musical content generation. However, little\nconsideration is given to how to use these models for real-time or cooperative\njamming musical applications because of crucial required features: low latency,\nthe ability to communicate planned actions, and the ability to adapt to user\ninput in real-time. To support these needs, we introduce ReaLJam, an interface\nand protocol for live musical jamming sessions between a human and a\nTransformer-based AI agent trained with reinforcement learning. We enable\nreal-time interactions using the concept of anticipation, where the agent\ncontinually predicts how the performance will unfold and visually conveys its\nplan to the user. We conduct a user study where experienced musicians jam in\nreal-time with the agent through ReaLJam. Our results demonstrate that ReaLJam\nenables enjoyable and musically interesting sessions, and we uncover important\ntakeaways for future work.",
    "pdf_url": "http://arxiv.org/pdf/2502.21267v1",
    "published": "2025-02-28",
    "source": "arxiv",
    "id": "2502.21267v1",
    "categories": [
      "cs.HC",
      "cs.AI"
    ]
  },
  {
    "title": "Token-level Ensembling of Models with Different Vocabularies",
    "authors": [
      "Rachel Wicks",
      "Kartik Ravisankar",
      "Xinchen Yang",
      "Philipp Koehn",
      "Matt Post"
    ],
    "abstract": "Model ensembling is a technique to combine the predicted distributions of two\nor more models, often leading to improved robustness and performance. For\nensembling in text generation, the next token's probability distribution is\nderived from a weighted sum of the distributions of each individual model. This\nrequires the underlying models to share the same subword vocabulary, limiting\nthe applicability of ensembling, since many open-sourced models have distinct\nvocabularies. In research settings, experimentation or upgrades to vocabularies\nmay introduce multiple vocabulary sizes. This paper proposes an inference-time\nonly algorithm that allows for ensembling models with different vocabularies,\nwithout the need to learn additional parameters or alter the underlying models.\nInstead, the algorithm ensures that tokens generated by the ensembled models\n\\textit{agree} in their surface form. We apply this technique to combinations\nof traditional encoder-decoder models and decoder-only LLMs and evaluate on\nmachine translation. In addition to expanding to model pairs that were\npreviously incapable of token-level ensembling, our algorithm frequently\nimproves translation performance over either model individually.",
    "pdf_url": "http://arxiv.org/pdf/2502.21265v1",
    "published": "2025-02-28",
    "source": "arxiv",
    "id": "2502.21265v1",
    "categories": [
      "cs.CL"
    ]
  },
  {
    "title": "Foundation Models -- A Panacea for Artificial Intelligence in Pathology?",
    "authors": [
      "Nita Mulliqi",
      "Anders Blilie",
      "Xiaoyi Ji",
      "Kelvin Szolnoky",
      "Henrik Olsson",
      "Sol Erika Boman",
      "Matteo Titus",
      "Geraldine Martinez Gonzalez",
      "Julia Anna Mielcarz",
      "Masi Valkonen",
      "Einar Gudlaugsson",
      "Svein R. Kjosavik",
      "José Asenjo",
      "Marcello Gambacorta",
      "Paolo Libretti",
      "Marcin Braun",
      "Radzislaw Kordek",
      "Roman Łowicki",
      "Kristina Hotakainen",
      "Päivi Väre",
      "Bodil Ginnerup Pedersen",
      "Karina Dalsgaard Sørensen",
      "Benedicte Parm Ulhøi",
      "Pekka Ruusuvuori",
      "Brett Delahunt",
      "Hemamali Samaratunga",
      "Toyonori Tsuzuki",
      "Emilius A. M. Janssen",
      "Lars Egevad",
      "Martin Eklund",
      "Kimmo Kartasalo"
    ],
    "abstract": "The role of artificial intelligence (AI) in pathology has evolved from aiding\ndiagnostics to uncovering predictive morphological patterns in whole slide\nimages (WSIs). Recently, foundation models (FMs) leveraging self-supervised\npre-training have been widely advocated as a universal solution for diverse\ndownstream tasks. However, open questions remain about their clinical\napplicability and generalization advantages over end-to-end learning using\ntask-specific (TS) models. Here, we focused on AI with clinical-grade\nperformance for prostate cancer diagnosis and Gleason grading. We present the\nlargest validation of AI for this task, using over 100,000 core needle biopsies\nfrom 7,342 patients across 15 sites in 11 countries. We compared two FMs with a\nfully end-to-end TS model in a multiple instance learning framework. Our\nfindings challenge assumptions that FMs universally outperform TS models. While\nFMs demonstrated utility in data-scarce scenarios, their performance converged\nwith - and was in some cases surpassed by - TS models when sufficient labeled\ntraining data were available. Notably, extensive task-specific training\nmarkedly reduced clinically significant misgrading, misdiagnosis of challenging\nmorphologies, and variability across different WSI scanners. Additionally, FMs\nused up to 35 times more energy than the TS model, raising concerns about their\nsustainability. Our results underscore that while FMs offer clear advantages\nfor rapid prototyping and research, their role as a universal solution for\nclinically applicable medical AI remains uncertain. For high-stakes clinical\napplications, rigorous validation and consideration of task-specific training\nremain critically important. We advocate for integrating the strengths of FMs\nand end-to-end learning to achieve robust and resource-efficient AI pathology\nsolutions fit for clinical use.",
    "pdf_url": "http://arxiv.org/pdf/2502.21264v2",
    "published": "2025-02-28",
    "source": "arxiv",
    "id": "2502.21264v2",
    "categories": [
      "cs.CV",
      "cs.AI"
    ]
  },
  {
    "title": "RuCCoD: Towards Automated ICD Coding in Russian",
    "authors": [
      "Aleksandr Nesterov",
      "Andrey Sakhovskiy",
      "Ivan Sviridov",
      "Airat Valiev",
      "Vladimir Makharev",
      "Petr Anokhin",
      "Galina Zubkova",
      "Elena Tutubalina"
    ],
    "abstract": "This study investigates the feasibility of automating clinical coding in\nRussian, a language with limited biomedical resources. We present a new dataset\nfor ICD coding, which includes diagnosis fields from electronic health records\n(EHRs) annotated with over 10,000 entities and more than 1,500 unique ICD\ncodes. This dataset serves as a benchmark for several state-of-the-art models,\nincluding BERT, LLaMA with LoRA, and RAG, with additional experiments examining\ntransfer learning across domains (from PubMed abstracts to medical diagnosis)\nand terminologies (from UMLS concepts to ICD codes). We then apply the\nbest-performing model to label an in-house EHR dataset containing patient\nhistories from 2017 to 2021. Our experiments, conducted on a carefully curated\ntest set, demonstrate that training with the automated predicted codes leads to\na significant improvement in accuracy compared to manually annotated data from\nphysicians. We believe our findings offer valuable insights into the potential\nfor automating clinical coding in resource-limited languages like Russian,\nwhich could enhance clinical efficiency and data accuracy in these contexts.",
    "pdf_url": "http://arxiv.org/pdf/2502.21263v1",
    "published": "2025-02-28",
    "source": "arxiv",
    "id": "2502.21263v1",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.DB"
    ]
  },
  {
    "title": "Modeling Human Beliefs about AI Behavior for Scalable Oversight",
    "authors": [
      "Leon Lang",
      "Patrick Forré"
    ],
    "abstract": "Contemporary work in AI alignment often relies on human feedback to teach AI\nsystems human preferences and values. Yet as AI systems grow more capable,\nhuman feedback becomes increasingly unreliable. This raises the problem of\nscalable oversight: How can we supervise AI systems that exceed human\ncapabilities? In this work, we propose to model the human evaluator's beliefs\nabout the AI system's behavior to better interpret the human's feedback. We\nformalize human belief models and theoretically analyze their role in inferring\nhuman values. We then characterize the remaining ambiguity in this inference\nand conditions for which the ambiguity disappears. To mitigate reliance on\nexact belief models, we then introduce the relaxation of human belief model\ncovering. Finally, we propose using foundation models to construct covering\nbelief models, providing a new potential approach to scalable oversight.",
    "pdf_url": "http://arxiv.org/pdf/2502.21262v1",
    "published": "2025-02-28",
    "source": "arxiv",
    "id": "2502.21262v1",
    "categories": [
      "cs.AI",
      "cs.LG"
    ]
  },
  {
    "title": "PET Image Denoising via Text-Guided Diffusion: Integrating Anatomical Priors through Text Prompts",
    "authors": [
      "Boxiao Yu",
      "Savas Ozdemir",
      "Jiong Wu",
      "Yizhou Chen",
      "Ruogu Fang",
      "Kuangyu Shi",
      "Kuang Gong"
    ],
    "abstract": "Low-dose Positron Emission Tomography (PET) imaging presents a significant\nchallenge due to increased noise and reduced image quality, which can\ncompromise its diagnostic accuracy and clinical utility. Denoising diffusion\nprobabilistic models (DDPMs) have demonstrated promising performance for PET\nimage denoising. However, existing DDPM-based methods typically overlook\nvaluable metadata such as patient demographics, anatomical information, and\nscanning parameters, which should further enhance the denoising performance if\nconsidered. Recent advances in vision-language models (VLMs), particularly the\npre-trained Contrastive Language-Image Pre-training (CLIP) model, have\nhighlighted the potential of incorporating text-based information into visual\ntasks to improve downstream performance. In this preliminary study, we proposed\na novel text-guided DDPM for PET image denoising that integrated anatomical\npriors through text prompts. Anatomical text descriptions were encoded using a\npre-trained CLIP text encoder to extract semantic guidance, which was then\nincorporated into the diffusion process via the cross-attention mechanism.\nEvaluations based on paired 1/20 low-dose and normal-dose 18F-FDG PET datasets\ndemonstrated that the proposed method achieved better quantitative performance\nthan conventional UNet and standard DDPM methods at both the whole-body and\norgan levels. These results underscored the potential of leveraging VLMs to\nintegrate rich metadata into the diffusion framework to enhance the image\nquality of low-dose PET scans.",
    "pdf_url": "http://arxiv.org/pdf/2502.21260v1",
    "published": "2025-02-28",
    "source": "arxiv",
    "id": "2502.21260v1",
    "categories": [
      "eess.IV"
    ]
  },
  {
    "title": "RoboBrain: A Unified Brain Model for Robotic Manipulation from Abstract to Concrete",
    "authors": [
      "Yuheng Ji",
      "Huajie Tan",
      "Jiayu Shi",
      "Xiaoshuai Hao",
      "Yuan Zhang",
      "Hengyuan Zhang",
      "Pengwei Wang",
      "Mengdi Zhao",
      "Yao Mu",
      "Pengju An",
      "Xinda Xue",
      "Qinghang Su",
      "Huaihai Lyu",
      "Xiaolong Zheng",
      "Jiaming Liu",
      "Zhongyuan Wang",
      "Shanghang Zhang"
    ],
    "abstract": "Recent advancements in Multimodal Large Language Models (MLLMs) have shown\nremarkable capabilities across various multimodal contexts. However, their\napplication in robotic scenarios, particularly for long-horizon manipulation\ntasks, reveals significant limitations. These limitations arise from the\ncurrent MLLMs lacking three essential robotic brain capabilities: Planning\nCapability, which involves decomposing complex manipulation instructions into\nmanageable sub-tasks; Affordance Perception, the ability to recognize and\ninterpret the affordances of interactive objects; and Trajectory Prediction,\nthe foresight to anticipate the complete manipulation trajectory necessary for\nsuccessful execution. To enhance the robotic brain's core capabilities from\nabstract to concrete, we introduce ShareRobot, a high-quality heterogeneous\ndataset that labels multi-dimensional information such as task planning, object\naffordance, and end-effector trajectory. ShareRobot's diversity and accuracy\nhave been meticulously refined by three human annotators. Building on this\ndataset, we developed RoboBrain, an MLLM-based model that combines robotic and\ngeneral multi-modal data, utilizes a multi-stage training strategy, and\nincorporates long videos and high-resolution images to improve its robotic\nmanipulation capabilities. Extensive experiments demonstrate that RoboBrain\nachieves state-of-the-art performance across various robotic tasks,\nhighlighting its potential to advance robotic brain capabilities.",
    "pdf_url": "http://arxiv.org/pdf/2502.21257v1",
    "published": "2025-02-28",
    "source": "arxiv",
    "id": "2502.21257v1",
    "categories": [
      "cs.RO",
      "cs.CV"
    ]
  },
  {
    "title": "ALVI Interface: Towards Full Hand Motion Decoding for Amputees Using sEMG",
    "authors": [
      "Aleksandr Kovalev",
      "Anna Makarova",
      "Petr Chizhov",
      "Matvey Antonov",
      "Gleb Duplin",
      "Vladislav Lomtev",
      "Viacheslav Gostevskii",
      "Vladimir Bessonov",
      "Andrey Tsurkan",
      "Mikhail Korobok",
      "Aleksejs Timčenko"
    ],
    "abstract": "We present a system for decoding hand movements using surface EMG signals.\nThe interface provides real-time (25 Hz) reconstruction of finger joint angles\nacross 20 degrees of freedom, designed for upper limb amputees. Our offline\nanalysis shows 0.8 correlation between predicted and actual hand movements. The\nsystem functions as an integrated pipeline with three key components: (1) a\nVR-based data collection platform, (2) a transformer-based model for\nEMG-to-motion transformation, and (3) a real-time calibration and feedback\nmodule called ALVI Interface. Using eight sEMG sensors and a VR training\nenvironment, users can control their virtual hand down to finger joint movement\nprecision, as demonstrated in our video: youtube link.",
    "pdf_url": "http://arxiv.org/pdf/2502.21256v1",
    "published": "2025-02-28",
    "source": "arxiv",
    "id": "2502.21256v1",
    "categories": [
      "cs.LG",
      "q-bio.NC"
    ]
  },
  {
    "title": "A novel boundary integrated neural networks for in plane fracture mechanics analysis of elastic and piezoelectric materials",
    "authors": [
      "Peijun Zhang",
      "Yan Gu",
      "Okyay Altay",
      "Chuanzeng Zhang"
    ],
    "abstract": "In this study, we propose a novel approach, termed boundary integrated neural\nnetworks (BINNs), for analyzing in-plane crack problems within the framework of\nlinear elastic fracture mechanics. The proposed approach integrates artificial\nneural networks (ANNs) with classical boundary integral equations (BIEs),\nenabling an efficient and accurate evaluation of partial differential equations\n(PDEs) associated with fracture mechanics. Additionally, novel special\nANN-based crack-tip elements, the Special crack-tip Neural Networks(SPNNs) are\ndeveloped to improve the modeling of displacement and stress fields in regions\nnear crack tips. These specialized elements integrate the asymptotic\ncharacteristics of fracture mechanics into the neural network framework,\nensuring enhanced accuracy in capturing the intricate singularities and steep\ngradients near the crack tips. Compared to conventional simulation tools in\nfracture mechanics, the present method offers several distinct advantages.\nFirst, by embedding higher-order fracture mechanics principles into the neural\nnetworks, the method achieves a more accurate and reliable representation of\nthe near-tip fields, even when using relatively large crack-tip elements.\nSecond, the SPNNs, which incorporates information about varying near-tip\nsingularity orders, improve the method's versatility in solving problems\ninvolving complex and diverse crack-tips geometries. Moreover, the method\ndemonstrates excellent computational efficiency due to the dimensionality\nreduction achieved by employing BIEs. Numerical experiments confirm that the\nproposed framework serves as a reliable, robust, and accurate tool for\naddressing fracture mechanics problems, offering substantial advantages over\nconventional numerical approaches.",
    "pdf_url": "http://arxiv.org/pdf/2502.21253v1",
    "published": "2025-02-28",
    "source": "arxiv",
    "id": "2502.21253v1",
    "categories": [
      "cs.CE"
    ]
  },
  {
    "title": "Short-Rate Derivatives in a Higher-for-Longer Environment",
    "authors": [
      "Aram Karakhanyan",
      "Takis Konstantopoulos",
      "Matthew Lorig",
      "Evgenii Samutichev"
    ],
    "abstract": "We introduce a class of short-rate models that exhibit a ``higher for\nlonger'' phenomenon. Specifically, the short-rate is modeled as a general\ntime-homogeneous one-factor Markov diffusion on a finite interval. The lower\nendpoint is assumed to be regular, exit or natural according to boundary\nclassification while the upper endpoint is assumed to be regular with absorbing\nbehavior. In this setting, we give an explicit expression for price of a\nzero-coupon bond (as well as more general interest rate derivatives) in terms\nof the transition density of the short-rate under a new probability measure,\nand the solution of a non-linear ordinary differential equation (ODE). We then\nnarrow our focus to a class of models for which the transition density and ODE\ncan be solved explicitly. For models within this class, we provide conditions\nunder which the lower endpoint is regular, exit and natural. Finally, we study\ntwo specific models -- one in which the lower endpoint is exit and another in\nwhich the lower endpoint is natural. In these two models, we give an explicit\nsolution of transition density of the short-rate as a (generalized)\neigenfunction expansion. We provide plots of the transition density,\n(generalized) eigenfunctions, bond prices and the associated yield curve.",
    "pdf_url": "http://arxiv.org/pdf/2502.21252v1",
    "published": "2025-02-28",
    "source": "arxiv",
    "id": "2502.21252v1",
    "categories": [
      "q-fin.MF"
    ]
  },
  {
    "title": "Learning-Driven Annealing with Adaptive Hamiltonian Modification for Solving Large-Scale Problems on Quantum Devices",
    "authors": [
      "Sebastian Schulz",
      "Dennis Willsch",
      "Kristel Michielsen"
    ],
    "abstract": "We present Learning-Driven Annealing (LDA), a framework that links individual\nquantum annealing evolutions into a global solution strategy to mitigate\nhardware constraints such as short annealing times and integrated control\nerrors. Unlike other iterative methods, LDA does not tune the annealing\nprocedure (e.g. annealing time or annealing schedule), but instead learns about\nthe problem structure to adaptively modify the problem Hamiltonian. By\ndeforming the instantaneous energy spectrum, LDA suppresses transitions into\nhigh-energy states and focuses the evolution into low-energy regions of the\nHilbert space. We demonstrate the efficacy of LDA by developing a hybrid\nquantum-classical solver for large-scale spin glasses. The hybrid solver is\nbased on a comprehensive study of the internal structure of spin glasses,\noutperforming other quantum and classical algorithms (e.g., reverse annealing,\ncyclic annealing, simulated annealing, Gurobi, Toshiba's SBM, VeloxQ and D-Wave\nhybrid) on 5580-qubit problem instances in both runtime and lowest energy. LDA\nis a step towards practical quantum computation that enables today's quantum\ndevices to compete with classical solvers.",
    "pdf_url": "http://arxiv.org/pdf/2502.21246v1",
    "published": "2025-02-28",
    "source": "arxiv",
    "id": "2502.21246v1",
    "categories": [
      "quant-ph"
    ]
  },
  {
    "title": "TimesBERT: A BERT-Style Foundation Model for Time Series Understanding",
    "authors": [
      "Haoran Zhang",
      "Yong Liu",
      "Yunzhong Qiu",
      "Haixuan Liu",
      "Zhongyi Pei",
      "Jianmin Wang",
      "Mingsheng Long"
    ],
    "abstract": "Time series analysis is crucial in diverse scenarios. Beyond forecasting,\nconsiderable real-world tasks are categorized into classification, imputation,\nand anomaly detection, underscoring different capabilities termed time series\nunderstanding in this paper. While GPT-style models have been positioned as\nfoundation models for time series forecasting, the BERT-style architecture,\nwhich has made significant advances in natural language understanding, has not\nbeen fully unlocked for time series understanding, possibly attributed to the\nundesirable dropout of essential elements of BERT. In this paper, inspired by\nthe shared multi-granularity structure between multivariate time series and\nmultisentence documents, we design TimesBERT to learn generic representations\nof time series including temporal patterns and variate-centric characteristics.\nIn addition to a natural adaptation of masked modeling, we propose a parallel\ntask of functional token prediction to embody vital multi-granularity\nstructures. Our model is pre-trained on 260 billion time points across diverse\ndomains. Leveraging multi-granularity representations, TimesBERT achieves\nstate-of-the-art performance across four typical downstream understanding\ntasks, outperforming task-specific models and language pre-trained backbones,\npositioning it as a versatile foundation model for time series understanding.",
    "pdf_url": "http://arxiv.org/pdf/2502.21245v1",
    "published": "2025-02-28",
    "source": "arxiv",
    "id": "2502.21245v1",
    "categories": [
      "cs.LG"
    ]
  },
  {
    "title": "Anatomically-guided masked autoencoder pre-training for aneurysm detection",
    "authors": [
      "Alberto Mario Ceballos-Arroyo",
      "Jisoo Kim",
      "Chu-Hsuan Lin",
      "Lei Qin",
      "Geoffrey S. Young",
      "Huaizu Jiang"
    ],
    "abstract": "Intracranial aneurysms are a major cause of morbidity and mortality\nworldwide, and detecting them manually is a complex, time-consuming task.\nAlbeit automated solutions are desirable, the limited availability of training\ndata makes it difficult to develop such solutions using typical supervised\nlearning frameworks. In this work, we propose a novel pre-training strategy\nusing more widely available unannotated head CT scan data to pre-train a 3D\nVision Transformer model prior to fine-tuning for the aneurysm detection task.\nSpecifically, we modify masked auto-encoder (MAE) pre-training in the following\nways: we use a factorized self-attention mechanism to make 3D attention\ncomputationally viable, we restrict the masked patches to areas near arteries\nto focus on areas where aneurysms are likely to occur, and we reconstruct not\nonly CT scan intensity values but also artery distance maps, which describe the\ndistance between each voxel and the closest artery, thereby enhancing the\nbackbone's learned representations. Compared with SOTA aneurysm detection\nmodels, our approach gains +4-8% absolute Sensitivity at a false positive rate\nof 0.5. Code and weights will be released.",
    "pdf_url": "http://arxiv.org/pdf/2502.21244v1",
    "published": "2025-02-28",
    "source": "arxiv",
    "id": "2502.21244v1",
    "categories": [
      "cs.CV"
    ]
  },
  {
    "title": "Semantic Volume: Quantifying and Detecting both External and Internal Uncertainty in LLMs",
    "authors": [
      "Xiaomin Li",
      "Zhou Yu",
      "Ziji Zhang",
      "Yingying Zhuang",
      "Swair Shah",
      "Anurag Beniwal"
    ],
    "abstract": "Large language models (LLMs) have demonstrated remarkable performance across\ndiverse tasks by encoding vast amounts of factual knowledge. However, they are\nstill prone to hallucinations, generating incorrect or misleading information,\noften accompanied by high uncertainty. Existing methods for hallucination\ndetection primarily focus on quantifying internal uncertainty, which arises\nfrom missing or conflicting knowledge within the model. However, hallucinations\ncan also stem from external uncertainty, where ambiguous user queries lead to\nmultiple possible interpretations. In this work, we introduce Semantic Volume,\na novel mathematical measure for quantifying both external and internal\nuncertainty in LLMs. Our approach perturbs queries and responses, embeds them\nin a semantic space, and computes the determinant of the Gram matrix of the\nembedding vectors, capturing their dispersion as a measure of uncertainty. Our\nframework provides a generalizable and unsupervised uncertainty detection\nmethod without requiring white-box access to LLMs. We conduct extensive\nexperiments on both external and internal uncertainty detection, demonstrating\nthat our Semantic Volume method consistently outperforms existing baselines in\nboth tasks. Additionally, we provide theoretical insights linking our measure\nto differential entropy, unifying and extending previous sampling-based\nuncertainty measures such as the semantic entropy. Semantic Volume is shown to\nbe a robust and interpretable approach to improving the reliability of LLMs by\nsystematically detecting uncertainty in both user queries and model responses.",
    "pdf_url": "http://arxiv.org/pdf/2502.21239v1",
    "published": "2025-02-28",
    "source": "arxiv",
    "id": "2502.21239v1",
    "categories": [
      "cs.CL"
    ]
  },
  {
    "title": "Transforming Tuberculosis Care: Optimizing Large Language Models For Enhanced Clinician-Patient Communication",
    "authors": [
      "Daniil Filienko",
      "Mahek Nizar",
      "Javier Roberti",
      "Denise Galdamez",
      "Haroon Jakher",
      "Sarah Iribarren",
      "Weichao Yuwen",
      "Martine De Cock"
    ],
    "abstract": "Tuberculosis (TB) is the leading cause of death from an infectious disease\nglobally, with the highest burden in low- and middle-income countries. In these\nregions, limited healthcare access and high patient-to-provider ratios impede\neffective patient support, communication, and treatment completion. To bridge\nthis gap, we propose integrating a specialized Large Language Model into an\nefficacious digital adherence technology to augment interactive communication\nwith treatment supporters. This AI-powered approach, operating within a\nhuman-in-the-loop framework, aims to enhance patient engagement and improve TB\ntreatment outcomes.",
    "pdf_url": "http://arxiv.org/pdf/2502.21236v1",
    "published": "2025-02-28",
    "source": "arxiv",
    "id": "2502.21236v1",
    "categories": [
      "cs.AI",
      "cs.CL",
      "cs.HC"
    ]
  },
  {
    "title": "A new block covariance regression model and inferential framework for massively large neuroimaging data",
    "authors": [
      "Hyoshin Kim",
      "Sujit K. Ghosh",
      "Emily C. Hector"
    ],
    "abstract": "Some evidence suggests that people with autism spectrum disorder exhibit\npatterns of brain functional dysconnectivity relative to their typically\ndeveloping peers, but specific findings have yet to be replicated. To\nfacilitate this replication goal with data from the Autism Brain Imaging Data\nExchange (ABIDE), we propose a flexible and interpretable model for\nparticipant-specific voxel-level brain functional connectivity. Our approach\nefficiently handles massive participant-specific whole brain voxel-level\nconnectivity data that exceed one trillion data points. The key component of\nthe model is to leverage the block structure induced by defined regions of\ninterest to introduce parsimony in the high-dimensional connectivity matrix\nthrough a block covariance structure. Associations between brain functional\nconnectivity and participant characteristics -- including eye status during the\nresting scan, sex, age, and their interactions -- are estimated within a\nBayesian framework. A spike-and-slab prior facilitates hypothesis testing to\nidentify voxels associated with autism diagnosis. Simulation studies are\nconducted to evaluate the empirical performance of the proposed model and\nestimation framework. In ABIDE, the method replicates key findings from the\nliterature and suggests new associations for investigation.",
    "pdf_url": "http://arxiv.org/pdf/2502.21235v1",
    "published": "2025-02-28",
    "source": "arxiv",
    "id": "2502.21235v1",
    "categories": [
      "stat.ME"
    ]
  },
  {
    "title": "Quantum information elements in Quantum Gravity states and processes",
    "authors": [
      "Daniele Oriti"
    ],
    "abstract": "We summarize basic features of quantum gravity states and processes, common\nto a number of related quantum gravity formalisms, and sharing a purely\ncombinatorial and algebraic language, and a discrete geometric interpretation.\nWe emphasize how, in this context, entanglement is a seed of topological and\ngeometric properties, and how a pre-geometric, discrete notion of quantum\ncausality can be implemented, as well as some recent results (based on random\ntensor network techniques) on the conditions for information transmission and\nholographic behaviour in quantum gravity states. Together, these features\nindicate that quantum information concepts and tools play a key role in\ndefining the fundamental structure of quantum spacetime.",
    "pdf_url": "http://arxiv.org/pdf/2502.21234v1",
    "published": "2025-02-28",
    "source": "arxiv",
    "id": "2502.21234v1",
    "categories": [
      "gr-qc",
      "hep-th",
      "quant-ph"
    ]
  },
  {
    "title": "Structure and Dynamics of Deep Eutectic Systems from Cluster-Optimized Energy Functions",
    "authors": [
      "Kai Töpfer",
      "Jingchun Wang",
      "Shimoni Patel",
      "Markus Meuwly"
    ],
    "abstract": "Generating energy functions for heterogeneous systems suitable for\nquantitative and predictive atomistic simulations is a challenging undertaking.\nThe present work combines a cluster-based approach with electronic structure\ncalculations at the density functional theory level and machine learning-based\nenergy functions for a spectroscopic reporter for eutectic mixtures consisting\nof water, acetamide and KSCN. Two water models are considered: TIP3P which is\nconsistent with the CGenFF energy function and TIP4P which - as a water model -\nis superior to TIP4P. Both fitted models, {\\bf M2$^{\\rm TIP3P}$} and {\\bf\n  M2$^{\\rm TIP4P}$}, yield favourable thermodynamic, structural, spectroscopic\nand transport properties from extensive molecular dynamics simulations. In\nparticular, the slow and fast decay times from 2-dimensional infrared\nspectroscopy and the viscosity for water-rich mixtures are described\nrealistically and consistent with experiments. On the other hand, including the\nco-solvent (acetamide) in the present case is expected to further improve the\ncomputed viscosity for low-water content. It is concluded that such a\ncluster-based approach is a promising and generalizable route for routine\nparametrization of heterogeneous, electrostatically dominated systems.",
    "pdf_url": "http://arxiv.org/pdf/2502.21233v1",
    "published": "2025-02-28",
    "source": "arxiv",
    "id": "2502.21233v1",
    "categories": [
      "physics.chem-ph"
    ]
  },
  {
    "title": "A quantum walk inspired model for distributed computing on arbitrary graphs",
    "authors": [
      "Mathieu Roget",
      "Giuseppe Di Molfetta"
    ],
    "abstract": "A discrete time quantum walk is known to be the single-particle sector of a\nquantum cellular automaton. For a long time, these models have interested the\ncommunity for their nice properties such as locality or translation invariance.\nThis work introduces a model of distributed computation for arbitrary graphs\ninspired by quantum cellular automata. As a by-product, we show how this model\ncan reproduce the dynamic of a quantum walk on graphs. In this context, we\ninvestigate the communication cost for two interaction schemes. Finally, we\nexplain how this particular quantum walk can be applied to solve the search\nproblem and present numerical results on different types of topologies.",
    "pdf_url": "http://arxiv.org/pdf/2502.21232v1",
    "published": "2025-02-28",
    "source": "arxiv",
    "id": "2502.21232v1",
    "categories": [
      "quant-ph",
      "cs.DC"
    ]
  },
  {
    "title": "ByteScale: Efficient Scaling of LLM Training with a 2048K Context Length on More Than 12,000 GPUs",
    "authors": [
      "Hao Ge",
      "Junda Feng",
      "Qi Huang",
      "Fangcheng Fu",
      "Xiaonan Nie",
      "Lei Zuo",
      "Haibin Lin",
      "Bin Cui",
      "Xin Liu"
    ],
    "abstract": "Scaling long-context ability is essential for Large Language Models (LLMs).\nTo amortize the memory consumption across multiple devices in long-context\ntraining, inter-data partitioning (a.k.a. Data Parallelism) and intra-data\npartitioning (a.k.a. Context Parallelism) are commonly used. Current training\nframeworks predominantly treat the two techniques as orthogonal, and establish\nstatic communication groups to organize the devices as a static mesh (e.g., a\n2D mesh). However, the sequences for LLM training typically vary in lengths, no\nmatter for texts, multi-modalities or reinforcement learning. The mismatch\nbetween data heterogeneity and static mesh causes redundant communication and\nimbalanced computation, degrading the training efficiency.\n  In this work, we introduce ByteScale, an efficient, flexible, and scalable\nLLM training framework for large-scale mixed training of long and short\nsequences. The core of ByteScale is a novel parallelism strategy, namely Hybrid\nData Parallelism (HDP), which unifies the inter- and intra-data partitioning\nwith a dynamic mesh design. In particular, we build a communication optimizer,\nwhich eliminates the redundant communication for short sequences by data-aware\nsharding and dynamic communication, and further compresses the communication\ncost for long sequences by selective offloading. Besides, we also develop a\nbalance scheduler to mitigate the imbalanced computation by parallelism-aware\ndata assignment. We evaluate ByteScale with the model sizes ranging from 7B to\n141B, context lengths from 256K to 2048K, on a production cluster with more\nthan 12,000 GPUs. Experiment results show that ByteScale outperforms the\nstate-of-the-art training system by up to 7.89x.",
    "pdf_url": "http://arxiv.org/pdf/2502.21231v1",
    "published": "2025-02-28",
    "source": "arxiv",
    "id": "2502.21231v1",
    "categories": [
      "cs.DC",
      "cs.AI",
      "cs.LG"
    ]
  },
  {
    "title": "A Method of Selective Attention for Reservoir Based Agents",
    "authors": [
      "Kevin McKee"
    ],
    "abstract": "Training of deep reinforcement learning agents is slowed considerably by the\npresence of input dimensions that do not usefully condition the reward\nfunction. Existing modules such as layer normalization can be trained with\nweight decay to act as a form of selective attention, i.e. an input mask, that\nshrinks the scale of unnecessary inputs, which in turn accelerates training of\nthe policy. However, we find a surprising result that adding numerous\nparameters to the computation of the input mask results in much faster\ntraining. A simple, high dimensional masking module is compared with layer\nnormalization and a model without any input suppression. The high dimensional\nmask resulted in a four-fold speedup in training over the null hypothesis and a\ntwo-fold speedup in training over the layer normalization method.",
    "pdf_url": "http://arxiv.org/pdf/2502.21229v1",
    "published": "2025-02-28",
    "source": "arxiv",
    "id": "2502.21229v1",
    "categories": [
      "cs.LG"
    ]
  },
  {
    "title": "ECLeKTic: a Novel Challenge Set for Evaluation of Cross-Lingual Knowledge Transfer",
    "authors": [
      "Omer Goldman",
      "Uri Shaham",
      "Dan Malkin",
      "Sivan Eiger",
      "Avinatan Hassidim",
      "Yossi Matias",
      "Joshua Maynez",
      "Adi Mayrav Gilady",
      "Jason Riesa",
      "Shruti Rijhwani",
      "Laura Rimell",
      "Idan Szpektor",
      "Reut Tsarfaty",
      "Matan Eyal"
    ],
    "abstract": "To achieve equitable performance across languages, multilingual large\nlanguage models (LLMs) must be able to abstract knowledge beyond the language\nin which it was acquired. However, the current literature lacks reliable ways\nto measure LLMs' capability of cross-lingual knowledge transfer. To that end,\nwe present ECLeKTic, a multilingual closed-book QA (CBQA) dataset that\nEvaluates Cross-Lingual Knowledge Transfer in a simple, black-box manner. We\ndetected information with uneven coverage across languages by controlling for\npresence and absence of Wikipedia articles in 12 languages. We generated\nknowledge-seeking questions in a source language, for which the answer appears\nin a relevant Wikipedia article and translated them to all other 11 languages,\nfor which the respective Wikipedias lack equivalent articles. Assuming that\nWikipedia reflects the prominent knowledge in the LLM's training data, to solve\nECLeKTic's CBQA task the model is required to transfer knowledge between\nlanguages. Experimenting with 8 LLMs, we show that SOTA models struggle to\neffectively share knowledge across, languages even if they can predict the\nanswer well for queries in the same language the knowledge was acquired in.",
    "pdf_url": "http://arxiv.org/pdf/2502.21228v2",
    "published": "2025-02-28",
    "source": "arxiv",
    "id": "2502.21228v2",
    "categories": [
      "cs.CL",
      "cs.AI"
    ]
  },
  {
    "title": "Large Seebeck coefficient driven by \"pudding mold\" flat band in hole-doped CuRhO$_2$",
    "authors": [
      "Amitayush Jha Thakur",
      "Maximilian Thees",
      "Franck Fortuna",
      "Emmanouil Frantzeskakis",
      "Daisuke Shiga",
      "Hiromichi Kuriyama",
      "Minoru Nohara",
      "Hidenori Takagi",
      "Hiroshi Kumigashira",
      "Andrés F. Santander-Syro"
    ],
    "abstract": "We report the measurement, using angle-resolved photoemission spectroscopy,\nof the metallic electronic structure of the hole-doped thermoelectric oxide\nCuRh$_{0.9}$Mg$_{0.1}$O$_2$. The material is found to have a ``pudding mold''\ntype band structure, with a nearly flat band edge located near the Fermi level,\nwhich is thought to be the origin of the thermoelectric behavior of this\nmaterial. The experimental data match the density functional theory of the\nundoped parent compound, simply corrected by a rigid shift of the bands.\nTransport calculations based on the observed band structure yield a Seebeck\ncoefficient of $\\sim 200 \\,\\mu$V/K for the undoped parent material, consistent\nwith experimental measurements. Our results show that CuRhO$_2$ is a textbook\nexample of how pure band-structural effects can result in a large\nthermoelectric figure of merit, demonstrating that flat band edges in oxides\nare a realistic route for the efficient conversion of thermal energy.",
    "pdf_url": "http://arxiv.org/pdf/2502.21225v1",
    "published": "2025-02-28",
    "source": "arxiv",
    "id": "2502.21225v1",
    "categories": [
      "cond-mat.str-el",
      "cond-mat.mtrl-sci"
    ]
  },
  {
    "title": "Detecting Linguistic Diversity on Social Media",
    "authors": [
      "Sidney Wong",
      "Benjamin Adams",
      "Jonathan Dunn"
    ],
    "abstract": "This chapter explores the efficacy of using social media data to examine\nchanging linguistic behaviour of a place. We focus our investigation on\nAotearoa New Zealand where official statistics from the census is the only\nsource of language use data. We use published census data as the ground truth\nand the social media sub-corpus from the Corpus of Global Language Use as our\nalternative data source. We use place as the common denominator between the two\ndata sources. We identify the language conditions of each tweet in the social\nmedia data set and validated our results with two language identification\nmodels. We then compare levels of linguistic diversity at national, regional,\nand local geographies. The results suggest that social media language data has\nthe possibility to provide a rich source of spatial and temporal insights on\nthe linguistic profile of a place. We show that social media is sensitive to\ndemographic and sociopolitical changes within a language and at low-level\nregional and local geographies.",
    "pdf_url": "http://arxiv.org/pdf/2502.21224v1",
    "published": "2025-02-28",
    "source": "arxiv",
    "id": "2502.21224v1",
    "categories": [
      "cs.CL"
    ]
  },
  {
    "title": "The IDEA detector concept for FCC-ee",
    "authors": [
      "The IDEA Study Group"
    ],
    "abstract": "A detector concept, named IDEA, optimized for the physics and running\nconditions at the FCC-ee is presented. After discussing the expected running\nconditions and the main physics drivers, a detailed description of the\nindividual sub-detectors is given. These include: a very light tracking system\nwith a powerful vertex detector inside a large drift chamber surrounded by a\nsilicon wrapper, a high resolution dual readout crystal electromagnetic\ncalorimeter, an HTS based superconducting solenoid, a dual readout fiber\ncalorimeter and three layers of muon chambers embedded in the magnet flux\nreturn yoke. Some examples of the expected detector performance, based on fast\nand full simulation, are also given.",
    "pdf_url": "http://arxiv.org/pdf/2502.21223v2",
    "published": "2025-02-28",
    "source": "arxiv",
    "id": "2502.21223v2",
    "categories": [
      "physics.ins-det",
      "hep-ex"
    ]
  },
  {
    "title": "XAIxArts Manifesto: Explainable AI for the Arts",
    "authors": [
      "Nick Bryan-Kinns",
      "Shuoyang Jasper Zheng",
      "Francisco Castro",
      "Makayla Lewis",
      "Jia-Rey Chang",
      "Gabriel Vigliensoni",
      "Terence Broad",
      "Michael Clemens",
      "Elizabeth Wilson"
    ],
    "abstract": "Explainable AI (XAI) is concerned with how to make AI models more\nunderstandable to people. To date these explanations have predominantly been\ntechnocentric - mechanistic or productivity oriented. This paper introduces the\nExplainable AI for the Arts (XAIxArts) manifesto to provoke new ways of\nthinking about explainability and AI beyond technocentric discourses.\nManifestos offer a means to communicate ideas, amplify unheard voices, and\nfoster reflection on practice. To supports the co-creation and revision of the\nXAIxArts manifesto we combine a World Caf\\'e style discussion format with a\nliving manifesto to question four core themes: 1) Empowerment, Inclusion, and\nFairness; 2) Valuing Artistic Practice; 3) Hacking and Glitches; and 4)\nOpenness. Through our interactive living manifesto experience we invite\nparticipants to actively engage in shaping this XIAxArts vision within the CHI\ncommunity and beyond.",
    "pdf_url": "http://arxiv.org/pdf/2502.21220v1",
    "published": "2025-02-28",
    "source": "arxiv",
    "id": "2502.21220v1",
    "categories": [
      "cs.HC",
      "cs.AI"
    ]
  },
  {
    "title": "Brickify: Enabling Expressive Design Intent Specification through Direct Manipulation on Design Tokens",
    "authors": [
      "Xinyu Shi",
      "Yinghou Wang",
      "Ryan Rossi",
      "Jian Zhao"
    ],
    "abstract": "Expressing design intent using natural language prompts requires designers to\nverbalize the ambiguous visual details concisely, which can be challenging or\neven impossible. To address this, we introduce Brickify, a visual-centric\ninteraction paradigm -- expressing design intent through direct manipulation on\ndesign tokens. Brickify extracts visual elements (e.g., subject, style, and\ncolor) from reference images and converts them into interactive and reusable\ndesign tokens that can be directly manipulated (e.g., resize, group, link,\netc.) to form the visual lexicon. The lexicon reflects users' intent for both\nwhat visual elements are desired and how to construct them into a whole. We\ndeveloped Brickify to demonstrate how AI models can interpret and execute the\nvisual lexicon through an end-to-end pipeline. In a user study, experienced\ndesigners found Brickify more efficient and intuitive than text-based prompts,\nallowing them to describe visual details, explore alternatives, and refine\ncomplex designs with greater ease and control.",
    "pdf_url": "http://arxiv.org/pdf/2502.21219v1",
    "published": "2025-02-28",
    "source": "arxiv",
    "id": "2502.21219v1",
    "categories": [
      "cs.HC"
    ]
  },
  {
    "title": "Self Consistent Field Theory of isotropic-nematic interfaces and disclinations in a semiflexible molecule nematic",
    "authors": [
      "Longyu Qing",
      "Jorge Viñals"
    ],
    "abstract": "A Self Consistent Field Theory description of equilibrium, but non uniform,\nconfigurations adopted by semi flexible liquid crystal molecules is presented.\nTwo cases are considered, isotropic-nematic phase boundaries, and topological\ndefects in the nematic phase (disclinations). Nematogens are modeled by\nworm-like chains, with microscopic interaction potential of the Maier-Saupe\ntype, with an added isotropic excluded volume contribution. The thermodynamic\nfields obtained by numerical minimization of the free energy are the molecular\ndensity and the nematic tensor order parameter. Interfaces with both\nhomeotropic and planar alignment are studied, as well as biaxiality and\nanisotropy around $\\pm 1/2$ disclinations. The effects induced by fluid\ncompressibility, interaction strength, and elastic anisotropy that follows from\nchain flexibility on both types of non-uniform configurations are discussed.\nDefect core sizes decrease as the system becomes less compressible, eventually\nreaching a constant value in the incompressible limit. The core size is\ninfluenced by the nematic interaction strength and chain persistence length,\ndecreasing as the order increases in the nematic region through manipulation of\npersistence length and nematic interaction. Additionally, when the far field\nnematic order is fixed, the core size increases with the persistence length.",
    "pdf_url": "http://arxiv.org/pdf/2502.21218v1",
    "published": "2025-02-28",
    "source": "arxiv",
    "id": "2502.21218v1",
    "categories": [
      "cond-mat.soft"
    ]
  },
  {
    "title": "Dynamic Markov Blanket Detection for Macroscopic Physics Discovery",
    "authors": [
      "Jeff Beck",
      "Maxwell J. D. Ramstead"
    ],
    "abstract": "The free energy principle (FEP), along with the associated constructs of\nMarkov blankets and ontological potentials, have recently been presented as the\ncore components of a generalized modeling method capable of mathematically\ndescribing arbitrary objects that persist in random dynamical systems; that is,\na mathematical theory of ``every'' ``thing''. Here, we leverage the FEP to\ndevelop a mathematical physics approach to the identification of objects,\nobject types, and the macroscopic, object-type-specific rules that govern their\nbehavior. We take a generative modeling approach and use variational Bayesian\nexpectation maximization to develop a dynamic Markov blanket detection\nalgorithm that is capable of identifying and classifying macroscopic objects,\ngiven partial observation of microscopic dynamics. This unsupervised algorithm\nuses Bayesian attention to explicitly label observable microscopic elements\naccording to their current role in a given system, as either the internal or\nboundary elements of a given macroscopic object; and it identifies macroscopic\nphysical laws that govern how the object interacts with its environment.\nBecause these labels are dynamic or evolve over time, the algorithm is capable\nof identifying complex objects that travel through fixed media or exchange\nmatter with their environment. This approach leads directly to a flexible class\nof structured, unsupervised algorithms that sensibly partition complex\nmany-particle or many-component systems into collections of interacting\nmacroscopic subsystems, namely, ``objects'' or ``things''. We derive a few\nexamples of this kind of macroscopic physics discovery algorithm and\ndemonstrate its utility with simple numerical experiments, in which the\nalgorithm correctly labels the components of Newton's cradle, a burning fuse,\nthe Lorenz attractor, and a simulated cell.",
    "pdf_url": "http://arxiv.org/pdf/2502.21217v1",
    "published": "2025-02-28",
    "source": "arxiv",
    "id": "2502.21217v1",
    "categories": [
      "q-bio.NC"
    ]
  },
  {
    "title": "An Algebraic Framework for Hierarchical Probabilistic Abstraction",
    "authors": [
      "Nijesh Upreti",
      "Vaishak Belle"
    ],
    "abstract": "Abstraction is essential for reducing the complexity of systems across\ndiverse fields, yet designing effective abstraction methodology for\nprobabilistic models is inherently challenging due to stochastic behaviors and\nuncertainties. Current approaches often distill detailed probabilistic data\ninto higher-level summaries to support tractable and interpretable analyses,\nthough they typically struggle to fully represent the relational and\nprobabilistic hierarchies through single-layered abstractions. We introduce a\nhierarchical probabilistic abstraction framework aimed at addressing these\nchallenges by extending a measure-theoretic foundation for hierarchical\nabstraction. The framework enables modular problem-solving via layered\nmappings, facilitating both detailed layer-specific analysis and a cohesive\nsystem-wide understanding. This approach bridges high-level conceptualization\nwith low-level perceptual data, enhancing interpretability and allowing layered\nanalysis. Our framework provides a robust foundation for abstraction analysis\nacross AI subfields, particularly in aligning System 1 and System 2 thinking,\nthereby supporting the development of diverse abstraction methodologies.",
    "pdf_url": "http://arxiv.org/pdf/2502.21216v1",
    "published": "2025-02-28",
    "source": "arxiv",
    "id": "2502.21216v1",
    "categories": [
      "cs.AI"
    ]
  },
  {
    "title": "An analytical solution for horizontal velocity profiles in the hurricane boundary layer",
    "authors": [
      "Kishore R. Sathia",
      "Marco G. Giometto"
    ],
    "abstract": "Theoretical analyses of the hurricane boundary layer have traditionally\nrelied on slab models, which provide a limited description of wind profiles.\nLiterature on height-resolving methods is typically based on linear analyses,\nwhich may fall short of capturing the full sensitivity of the solution to\nvariations in input parameters. This work proposes an approximate analytical\nsolution of a nonlinear single-column model for horizontal winds that uses a\nconstant eddy viscosity and is valid outside the eyewall. Building on\nliterature that uses a linearized system of equations, we use a series\nexpansion to account for the nonlinearities. We find that a first-order\ncorrection is sufficient for most practical cases. This solution helps provide\na simplified understanding of the sensitivity of the radial and tangential wind\nprofiles to input parameters such as the distance from the hurricane eye and\nthe Coriolis force.",
    "pdf_url": "http://arxiv.org/pdf/2502.21215v1",
    "published": "2025-02-28",
    "source": "arxiv",
    "id": "2502.21215v1",
    "categories": [
      "physics.flu-dyn"
    ]
  },
  {
    "title": "What is ontic and what is epistemic in the Quantum Mechanics of Spin?",
    "authors": [
      "Ariel Caticha"
    ],
    "abstract": "Entropic Dynamics (ED) provides a framework that allows the reconstruction of\nthe quantum formalism by insisting on ontological and epistemic clarity and\nadopting entropic methods and information geometry. Our present goal is to\nextend the ED framework to account for spin. The result is a realist\n{\\psi}-epistemic model in which the ontology consists of a particle described\nby a definite position plus a discrete variable that describes Pauli's peculiar\ntwo-valuedness. The resulting dynamics of probabilities is, as might be\nexpected, described by the Pauli equation. What may be unexpected is that the\ngenerators of transformations -- Hamiltonians and angular momenta including\nspin, are all granted clear epistemic status. To the old question `what is\nspinning?' ED provides a crisp answer: nothing is spinning.",
    "pdf_url": "http://arxiv.org/pdf/2502.21214v1",
    "published": "2025-02-28",
    "source": "arxiv",
    "id": "2502.21214v1",
    "categories": [
      "quant-ph"
    ]
  },
  {
    "title": "Transformers Learn to Implement Multi-step Gradient Descent with Chain of Thought",
    "authors": [
      "Jianhao Huang",
      "Zixuan Wang",
      "Jason D. Lee"
    ],
    "abstract": "Chain of Thought (CoT) prompting has been shown to significantly improve the\nperformance of large language models (LLMs), particularly in arithmetic and\nreasoning tasks, by instructing the model to produce intermediate reasoning\nsteps. Despite the remarkable empirical success of CoT and its theoretical\nadvantages in enhancing expressivity, the mechanisms underlying CoT training\nremain largely unexplored. In this paper, we study the training dynamics of\ntransformers over a CoT objective on an in-context weight prediction task for\nlinear regression. We prove that while a one-layer linear transformer without\nCoT can only implement a single step of gradient descent (GD) and fails to\nrecover the ground-truth weight vector, a transformer with CoT prompting can\nlearn to perform multi-step GD autoregressively, achieving near-exact recovery.\nFurthermore, we show that the trained transformer effectively generalizes on\nthe unseen data. With our technique, we also show that looped transformers\nsignificantly improve final performance compared to transformers without\nlooping in the in-context learning of linear regression. Empirically, we\ndemonstrate that CoT prompting yields substantial performance improvements.",
    "pdf_url": "http://arxiv.org/pdf/2502.21212v1",
    "published": "2025-02-28",
    "source": "arxiv",
    "id": "2502.21212v1",
    "categories": [
      "cs.LG",
      "cs.AI"
    ]
  },
  {
    "title": "A decision analysis model for colorectal cancer screening",
    "authors": [
      "Daniel Corrales",
      "David Ríos Insua",
      "Marino J. González"
    ],
    "abstract": "Background and Objective. With minor differences, most national colorectal\ncancer (CRC) screening programs in Europe consist of one-size-fits-all\naged-based strategies. This paper provides a decision analysis-based approach\nto personalized CRC screening, supporting decisions concerning whether and\nwhich screening method to consider and/or whether a colonoscopy should be\nadministered.\n  Methods. We use an influence diagram which characterizes CRC risk with\nrespect to different variables of interest and includes comfort, costs,\ncomplications, and information as decision criteria, the last one assessed\nthrough information theory measures. The criteria are integrated with a\nmulti-attribute utility model. Optimal screening policies are then computed.\n  Results. The proposed model is used to support personalized individual\nscreening based on relevant characteristics. It serves to assess existing\nnational screening programs and design new ones. In particular, it suggests\nreplacing current age-based strategies followed in many European countries by\nmore personalized strategies based on the type of model proposed. Additionally,\nthe model facilitates benchmarking of novel screening devices.\n  Conclusions. This work creates a framework supporting personalized CRC\nscreening improving upon current age-based screening strategies.",
    "pdf_url": "http://arxiv.org/pdf/2502.21210v1",
    "published": "2025-02-28",
    "source": "arxiv",
    "id": "2502.21210v1",
    "categories": [
      "stat.AP"
    ]
  },
  {
    "title": "End-to-End Deep Learning in Phase Noisy Coherent Optical Link",
    "authors": [
      "Omar Alnaseri",
      "Yassine Himeur"
    ],
    "abstract": "In coherent optical orthogonal frequency-division multiplexing (CO-OFDM)\nfiber communications, a novel end-to-end learning framework to mitigate Laser\nPhase Noise (LPN) impairments is proposed in this paper. Inspired by\nAutoencoder (AE) principles, the proposed approach trains a model to learn\nrobust symbol sequences capable of combat LPN, even from low-cost distributed\nfeedback (DFB) lasers with linewidths up to 2 MHz. This allows for the use of\nhigh-level modulation formats and large-scale Fast Fourier Transform (FFT)\nprocessing, maximizing spectral efficiency in CO-OFDM systems. By eliminating\nthe need for complex traditional techniques, this approach offers a potentially\nmore efficient and streamlined solution for CO-OFDM systems. The most\nsignificant achievement of this study is the demonstration that the proposed\nAE-based model can enhance system performance by reducing the bit error rate\n(BER) to below the threshold of forward error correction (FEC), even under\nsevere phase noise conditions, thus proving its effectiveness and efficiency in\npractical deployment scenarios.",
    "pdf_url": "http://arxiv.org/pdf/2502.21209v1",
    "published": "2025-02-28",
    "source": "arxiv",
    "id": "2502.21209v1",
    "categories": [
      "eess.SP"
    ]
  },
  {
    "title": "Chronologically Consistent Large Language Models",
    "authors": [
      "Songrun He",
      "Linying Lv",
      "Asaf Manela",
      "Jimmy Wu"
    ],
    "abstract": "Large language models are increasingly used in social sciences, but their\ntraining data can introduce lookahead bias and training leakage. A good\nchronologically consistent language model requires efficient use of training\ndata to maintain accuracy despite time-restricted data. Here, we overcome this\nchallenge by training chronologically consistent large language models\ntimestamped with the availability date of their training data, yet accurate\nenough that their performance is comparable to state-of-the-art open-weight\nmodels. Lookahead bias is model and application-specific because even if a\nchronologically consistent language model has poorer language comprehension, a\nregression or prediction model applied on top of the language model can\ncompensate. In an asset pricing application, we compare the performance of\nnews-based portfolio strategies that rely on chronologically consistent versus\nbiased language models and estimate a modest lookahead bias.",
    "pdf_url": "http://arxiv.org/pdf/2502.21206v1",
    "published": "2025-02-28",
    "source": "arxiv",
    "id": "2502.21206v1",
    "categories": [
      "q-fin.GN",
      "q-fin.TR"
    ]
  },
  {
    "title": "Stability of axial free-boundary hyperplanes in circular cones",
    "authors": [
      "Gian Paolo Leonardi",
      "Giacomo Vianello"
    ],
    "abstract": "Given an axially-symmetric, $(n+1)$-dimensional convex cone $\\Omega\\subset\n\\mathbb{R}^{n+1}$, we study the stability of the free-boundary minimal surface\n$\\Sigma$ obtained by intersecting $\\Omega$ with a $n$-plane that contains the\naxis of $\\Omega$. In the case $n=2$, $\\Sigma$ is always unstable, as a special\ncase of the vertex-skipping property recently proved in a paper by the same\nauthors. Conversely, as soon as $n \\ge 3$ and $\\Omega$ has a sufficiently large\naperture (depending on the dimension $n$), we show that $\\Sigma$ is strictly\nstable. For our stability analysis, we introduce a Lipschitz flow\n$\\Sigma_{t}[f]$ of deformations of $\\Sigma$ associated with a\ncompactly-supported, scalar deformation field $f$, which satisfies the key\nproperty $\\partial \\Sigma_{t}[f] \\subset \\partial \\Omega$ for all $t\\in\n\\mathbb{R}$. Then, we compute the lower-right second variation of the area of\n$\\Sigma$ along the flow, and ultimately show that it is positive by exploiting\nits connection with a functional inequality studied in the context of\nreaction-diffusion problems.",
    "pdf_url": "http://arxiv.org/pdf/2502.21205v2",
    "published": "2025-02-28",
    "source": "arxiv",
    "id": "2502.21205v2",
    "categories": [
      "math.AP",
      "math.CA"
    ]
  },
  {
    "title": "Approximation of anisotropic pair potentials using multivariate interpolation",
    "authors": [
      "Mohammadreza Fakhraei",
      "Chris A. Kieslich",
      "Michael P. Howard"
    ],
    "abstract": "The interaction between two particles with shape or interaction anisotropy\ncan be modeled using a pairwise potential energy function that depends on their\nrelative position and orientation; however, this function is often challenging\nto mathematically formulate. Data-driven approaches for approximating\nanisotropic pair potentials have gained significant interest due to their\nflexibility and generality but often require large sets of training data,\npotentially limiting their feasibility when training data is computationally\ndemanding to collect. Here, we investigate the use of multivariate polynomial\ninterpolation to approximate anisotropic pair potentials from a limited set of\nprescribed particle configurations. We consider both standard Chebyshev\npolynomial interpolation as well as mixed-basis polynomial interpolation that\nuses trigonometric polynomials for coordinates along which the pair potential\nis known to be periodic. We exploit mathematical reasoning and physical\nknowledge to refine the interpolation domain and to design our interpolants. We\ntest our approach on two-dimensional and three-dimensional model anisotropic\nnanoparticles, finding satisfactory approximations can be constructed in all\ncases.",
    "pdf_url": "http://arxiv.org/pdf/2502.21203v1",
    "published": "2025-02-28",
    "source": "arxiv",
    "id": "2502.21203v1",
    "categories": [
      "cond-mat.soft"
    ]
  },
  {
    "title": "The PanAf-FGBG Dataset: Understanding the Impact of Backgrounds in Wildlife Behaviour Recognition",
    "authors": [
      "Otto Brookes",
      "Maksim Kukushkin",
      "Majid Mirmehdi",
      "Colleen Stephens",
      "Paula Dieguez",
      "Thurston C. Hicks",
      "Sorrel Jones",
      "Kevin Lee",
      "Maureen S. McCarthy",
      "Amelia Meier",
      "Emmanuelle Normand",
      "Erin G. Wessling",
      "Roman M. Wittig",
      "Kevin Langergraber",
      "Klaus Zuberbühler",
      "Lukas Boesch",
      "Thomas Schmid",
      "Mimi Arandjelovic",
      "Hjalmar Kühl",
      "Tilo Burghardt"
    ],
    "abstract": "Computer vision analysis of camera trap video footage is essential for\nwildlife conservation, as captured behaviours offer some of the earliest\nindicators of changes in population health. Recently, several high-impact\nanimal behaviour datasets and methods have been introduced to encourage their\nuse; however, the role of behaviour-correlated background information and its\nsignificant effect on out-of-distribution generalisation remain unexplored. In\nresponse, we present the PanAf-FGBG dataset, featuring 20 hours of wild\nchimpanzee behaviours, recorded at over 350 individual camera locations.\nUniquely, it pairs every video with a chimpanzee (referred to as a foreground\nvideo) with a corresponding background video (with no chimpanzee) from the same\ncamera location. We present two views of the dataset: one with overlapping\ncamera locations and one with disjoint locations. This setup enables, for the\nfirst time, direct evaluation of in-distribution and out-of-distribution\nconditions, and for the impact of backgrounds on behaviour recognition models\nto be quantified. All clips come with rich behavioural annotations and metadata\nincluding unique camera IDs and detailed textual scene descriptions.\nAdditionally, we establish several baselines and present a highly effective\nlatent-space normalisation technique that boosts out-of-distribution\nperformance by +5.42% mAP for convolutional and +3.75% mAP for\ntransformer-based models. Finally, we provide an in-depth analysis on the role\nof backgrounds in out-of-distribution behaviour recognition, including the so\nfar unexplored impact of background durations (i.e., the count of background\nframes within foreground videos).",
    "pdf_url": "http://arxiv.org/pdf/2502.21201v2",
    "published": "2025-02-28",
    "source": "arxiv",
    "id": "2502.21201v2",
    "categories": [
      "cs.CV",
      "cs.AI"
    ]
  },
  {
    "title": "Negative correlations in Ising models of credit risk",
    "authors": [
      "Chiara Emonti",
      "Roberto Fontana"
    ],
    "abstract": "We analyze a subclass of Ising models in the context of credit risk, focusing\non Dandelion models when the correlations $\\rho$ between the central node and\neach non-central node are negative. We establish the possible range of values\nfor $\\rho$ and derive an explicit formula linking the correlation between any\npair of non-central nodes to $\\rho$. The paper concludes with a simulation\nstudy.",
    "pdf_url": "http://arxiv.org/pdf/2502.21199v1",
    "published": "2025-02-28",
    "source": "arxiv",
    "id": "2502.21199v1",
    "categories": [
      "stat.AP"
    ]
  },
  {
    "title": "AI-Enhanced Self-Triggering for Extensive Air Showers: Performance and FPGA Feasibility",
    "authors": [
      "Qader Dorosti"
    ],
    "abstract": "Cosmic-ray detection with radio antennas has traditionally depended on\nexternal triggers from particle detectors, constraining sensitivity and\nincreasing complexity. Previous attempts at fully standalone, radio-only\ntriggers have often failed under intense radio frequency interference, making\ngenuine air-shower signals difficult to isolate. We present a\nproof-of-principle artificial intelligence-based self-triggering system that\novercomes these limitations. By training a deep learning model on both real\nnoise data and injected cosmic-ray-like pulses, we achieve an exceptionally low\nfalse-positive rate alongside high detection efficiency. Configurable operating\npoints can suppress false positives below 0.01\\% while retaining more than 88\\%\nof genuine signals, and can even eliminate false positives entirely at a modest\nreduction in signal efficiency. This flexibility makes single-station\ncosmic-ray detection feasible without requiring external trigger inputs.\nApplying our approach to real-world noise conditions reduces the initial\nfalse-positive event rate by several orders of magnitude, supporting\nlarge-scale deployments. Extrapolation to dedicated hardware implementations,\nsuch as FPGAs, indicates that sub-\\SI{}{\\micro\\second} inference times are\nachievable, enabling real-time autonomous triggering. These results highlight\nthe transformative potential of artificial intelligence for enhancing radio\ndetection sensitivity and inaugurate a new generation of fully self-triggered\ncosmic-ray observatories.",
    "pdf_url": "http://arxiv.org/pdf/2502.21198v1",
    "published": "2025-02-28",
    "source": "arxiv",
    "id": "2502.21198v1",
    "categories": [
      "astro-ph.IM",
      "physics.ins-det"
    ]
  },
  {
    "title": "Joint Modeling in Recommendations: A Survey",
    "authors": [
      "Xiangyu Zhao",
      "Yichao Wang",
      "Bo Chen",
      "Jingtong Gao",
      "Yuhao Wang",
      "Xiaopeng Li",
      "Pengyue Jia",
      "Qidong Liu",
      "Huifeng Guo",
      "Ruiming Tang"
    ],
    "abstract": "In today's digital landscape, Deep Recommender Systems (DRS) play a crucial\nrole in navigating and customizing online content for individual preferences.\nHowever, conventional methods, which mainly depend on single recommendation\ntask, scenario, data modality and user behavior, are increasingly seen as\ninsufficient due to their inability to accurately reflect users' complex and\nchanging preferences. This gap underscores the need for joint modeling\napproaches, which are central to overcoming these limitations by integrating\ndiverse tasks, scenarios, modalities, and behaviors in the recommendation\nprocess, thus promising significant enhancements in recommendation precision,\nefficiency, and customization. In this paper, we comprehensively survey the\njoint modeling methods in recommendations. We begin by defining the scope of\njoint modeling through four distinct dimensions: multi-task, multi-scenario,\nmulti-modal, and multi-behavior modeling. Subsequently, we examine these\nmethods in depth, identifying and summarizing their underlying paradigms based\non the latest advancements and potential research trajectories. Ultimately, we\nhighlight several promising avenues for future exploration in joint modeling\nfor recommendations and provide a concise conclusion to our findings.",
    "pdf_url": "http://arxiv.org/pdf/2502.21195v1",
    "published": "2025-02-28",
    "source": "arxiv",
    "id": "2502.21195v1",
    "categories": [
      "cs.IR"
    ]
  },
  {
    "title": "Class prior estimation for positive-unlabeled learning when label shift occurs",
    "authors": [
      "Jan Mielniczuk",
      "Wojciech Rejchel",
      "Paweł Teisseyre"
    ],
    "abstract": "We study estimation of class prior for unlabeled target samples which is\npossibly different from that of source population. It is assumed that for the\nsource data only samples from positive class and from the whole population are\navailable (PU learning scenario). We introduce a novel direct estimator of\nclass prior which avoids estimation of posterior probabilities and has a simple\ngeometric interpretation. It is based on a distribution matching technique\ntogether with kernel embedding and is obtained as an explicit solution to an\noptimisation task. We establish its asymptotic consistency as well as a\nnon-asymptotic bound on its deviation from the unknown prior, which is\ncalculable in practice. We study finite sample behaviour for synthetic and real\ndata and show that the proposal, together with a suitably modified version for\nlarge values of source prior, works on par or better than its competitors.",
    "pdf_url": "http://arxiv.org/pdf/2502.21194v1",
    "published": "2025-02-28",
    "source": "arxiv",
    "id": "2502.21194v1",
    "categories": [
      "stat.ML",
      "cs.LG"
    ]
  },
  {
    "title": "Towards High-performance Spiking Transformers from ANN to SNN Conversion",
    "authors": [
      "Zihan Huang",
      "Xinyu Shi",
      "Zecheng Hao",
      "Tong Bu",
      "Jianhao Ding",
      "Zhaofei Yu",
      "Tiejun Huang"
    ],
    "abstract": "Spiking neural networks (SNNs) show great potential due to their energy\nefficiency, fast processing capabilities, and robustness. There are two main\napproaches to constructing SNNs. Direct training methods require much memory,\nwhile conversion methods offer a simpler and more efficient option. However,\ncurrent conversion methods mainly focus on converting convolutional neural\nnetworks (CNNs) to SNNs. Converting Transformers to SNN is challenging because\nof the presence of non-linear modules. In this paper, we propose an Expectation\nCompensation Module to preserve the accuracy of the conversion. The core idea\nis to use information from the previous T time-steps to calculate the expected\noutput at time-step T. We also propose a Multi-Threshold Neuron and the\ncorresponding Parallel Parameter normalization to address the challenge of\nlarge time steps needed for high accuracy, aiming to reduce network latency and\npower consumption. Our experimental results demonstrate that our approach\nachieves state-of-the-art performance. For example, we achieve a top-1 accuracy\nof 88.60\\% with only a 1\\% loss in accuracy using 4 time steps while consuming\nonly 35\\% of the original power of the Transformer. To our knowledge, this is\nthe first successful Artificial Neural Network (ANN) to SNN conversion for\nSpiking Transformers that achieves high accuracy, low latency, and low power\nconsumption on complex datasets. The source codes of the proposed method are\navailable at https://github.com/h-z-h-cell/Transformer-to-SNN-ECMT.",
    "pdf_url": "http://arxiv.org/pdf/2502.21193v1",
    "published": "2025-02-28",
    "source": "arxiv",
    "id": "2502.21193v1",
    "categories": [
      "cs.CV"
    ]
  },
  {
    "title": "Concentration around a stable equilibrium for the non-autonomous $Φ_3^4$ model",
    "authors": [
      "Dimitri Faure"
    ],
    "abstract": "We consider time-dependent singular stochastic partial differential equations\non the three-dimensional torus. These equations are only well-posed after one\nadds renormalization terms. In order to construct a well-defined notion of\nsolution, one should put the equation in a more general setting, like the one\nof regularity structures. In this article, we consider the alternative paradigm\nof paracontrolled distributions, and get concentration results around a stable\ndeterministic equilibrium for solutions of non-autonomous generalizations of\nthe $(\\Phi_3^4)$ model.",
    "pdf_url": "http://arxiv.org/pdf/2502.21192v1",
    "published": "2025-02-28",
    "source": "arxiv",
    "id": "2502.21192v1",
    "categories": [
      "math.PR"
    ]
  },
  {
    "title": "Joint Near-Field Sensing and Visibility Region Detection with Extremely Large Aperture Arrays",
    "authors": [
      "Huiping Huang",
      "Alireza Pourafzal",
      "Hui Chen",
      "Musa Furkan Keskin",
      "Mengting Li",
      "Yu Ge",
      "Fredrik Tufvesson",
      "Henk Wymeersch",
      "Xuesong Cai"
    ],
    "abstract": "In this paper, we consider near-field localization and sensing with an\nextremely large aperture array under partial blockage of array antennas, where\nspherical wavefront and spatial non-stationarity are accounted for. We propose\nan Ising model to characterize the clustered sparsity feature of the blockage\npattern, develop an algorithm based on alternating optimization for joint\nchannel parameter estimation and visibility region detection, and further\nestimate the locations of the user and environmental scatterers. The simulation\nresults confirm the effectiveness of the proposed algorithm compared to\nconventional methods.",
    "pdf_url": "http://arxiv.org/pdf/2502.21191v1",
    "published": "2025-02-28",
    "source": "arxiv",
    "id": "2502.21191v1",
    "categories": [
      "eess.SP"
    ]
  },
  {
    "title": "SYN-LUNGS: Towards Simulating Lung Nodules with Anatomy-Informed Digital Twins for AI Training",
    "authors": [
      "Fakrul Islam Tushar",
      "Lavsen Dahal",
      "Cindy McCabe",
      "Fong Chi Ho",
      "Paul Segars",
      "Ehsan Abadi",
      "Kyle J. Lafata",
      "Ehsan Samei",
      "Joseph Y. Lo"
    ],
    "abstract": "AI models for lung cancer screening are limited by data scarcity, impacting\ngeneralizability and clinical applicability. Generative models address this\nissue but are constrained by training data variability. We introduce SYN-LUNGS,\na framework for generating high-quality 3D CT images with detailed annotations.\nSYN-LUNGS integrates XCAT3 phantoms for digital twin generation, X-Lesions for\nnodule simulation (varying size, location, and appearance), and DukeSim for CT\nimage formation with vendor and parameter variability. The dataset includes\n3,072 nodule images from 1,044 simulated CT scans, with 512 lesions and 174\ndigital twins. Models trained on clinical + simulated data outperform clinical\nonly models, achieving 10% improvement in detection, 2-9% in segmentation and\nclassification, and enhanced synthesis.By incorporating anatomy-informed\nsimulations, SYN-LUNGS provides a scalable approach for AI model development,\nparticularly in rare disease representation and improving model reliability.",
    "pdf_url": "http://arxiv.org/pdf/2502.21187v1",
    "published": "2025-02-28",
    "source": "arxiv",
    "id": "2502.21187v1",
    "categories": [
      "cs.LG"
    ]
  },
  {
    "title": "Scalable Decision-Making in Stochastic Environments through Learned Temporal Abstraction",
    "authors": [
      "Baiting Luo",
      "Ava Pettet",
      "Aron Laszka",
      "Abhishek Dubey",
      "Ayan Mukhopadhyay"
    ],
    "abstract": "Sequential decision-making in high-dimensional continuous action spaces,\nparticularly in stochastic environments, faces significant computational\nchallenges. We explore this challenge in the traditional offline RL setting,\nwhere an agent must learn how to make decisions based on data collected through\na stochastic behavior policy. We present Latent Macro Action Planner (L-MAP),\nwhich addresses this challenge by learning a set of temporally extended\nmacro-actions through a state-conditional Vector Quantized Variational\nAutoencoder (VQ-VAE), effectively reducing action dimensionality. L-MAP employs\na (separate) learned prior model that acts as a latent transition model and\nallows efficient sampling of plausible actions. During planning, our approach\naccounts for stochasticity in both the environment and the behavior policy by\nusing Monte Carlo tree search (MCTS). In offline RL settings, including\nstochastic continuous control tasks, L-MAP efficiently searches over discrete\nlatent actions to yield high expected returns. Empirical results demonstrate\nthat L-MAP maintains low decision latency despite increased action\ndimensionality. Notably, across tasks ranging from continuous control with\ninherently stochastic dynamics to high-dimensional robotic hand manipulation,\nL-MAP significantly outperforms existing model-based methods and performs\non-par with strong model-free actor-critic baselines, highlighting the\neffectiveness of the proposed approach in planning in complex and stochastic\nenvironments with high-dimensional action spaces.",
    "pdf_url": "http://arxiv.org/pdf/2502.21186v2",
    "published": "2025-02-28",
    "source": "arxiv",
    "id": "2502.21186v2",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.RO"
    ]
  },
  {
    "title": "A Survey of Link Prediction in Temporal Networks",
    "authors": [
      "Jiafeng Xiong",
      "Ahmad Zareie",
      "Rizos Sakellariou"
    ],
    "abstract": "Temporal networks have gained significant prominence in the past decade for\nmodelling dynamic interactions within complex systems. A key challenge in this\ndomain is Temporal Link Prediction (TLP), which aims to forecast future\nconnections by analysing historical network structures across various\napplications including social network analysis. While existing surveys have\naddressed specific aspects of TLP, they typically lack a comprehensive\nframework that distinguishes between representation and inference methods. This\nsurvey bridges this gap by introducing a novel taxonomy that explicitly\nexamines representation and inference from existing methods, providing a novel\nclassification of approaches for TLP. We analyse how different representation\ntechniques capture temporal and structural dynamics, examining their\ncompatibility with various inference methods for both transductive and\ninductive prediction tasks. Our taxonomy not only clarifies the methodological\nlandscape but also reveals promising unexplored combinations of existing\ntechniques. This taxonomy provides a systematic foundation for emerging\nchallenges in TLP, including model explainability and scalable architectures\nfor complex temporal networks.",
    "pdf_url": "http://arxiv.org/pdf/2502.21185v1",
    "published": "2025-02-28",
    "source": "arxiv",
    "id": "2502.21185v1",
    "categories": [
      "cs.AI",
      "cs.SI"
    ]
  },
  {
    "title": "HQColon: A Hybrid Interactive Machine Learning Pipeline for High Quality Colon Labeling and Segmentation",
    "authors": [
      "Martina Finocchiaro",
      "Ronja Stern",
      "Abraham George Smith",
      "Jens Petersen",
      "Kenny Erleben",
      "Melanie Ganz"
    ],
    "abstract": "High-resolution colon segmentation is crucial for clinical and research\napplications, such as digital twins and personalized medicine. However, the\nleading open-source abdominal segmentation tool, TotalSegmentator, struggles\nwith accuracy for the colon, which has a complex and variable shape, requiring\ntime-intensive labeling. Here, we present the first fully automatic\nhigh-resolution colon segmentation method. To develop it, we first created a\nhigh resolution colon dataset using a pipeline that combines region growing\nwith interactive machine learning to efficiently and accurately label the colon\non CT colonography (CTC) images. Based on the generated dataset consisting of\n435 labeled CTC images we trained an nnU-Net model for fully automatic colon\nsegmentation. Our fully automatic model achieved an average symmetric surface\ndistance of 0.2 mm (vs. 4.0 mm from TotalSegmentator) and a 95th percentile\nHausdorff distance of 1.0 mm (vs. 18 mm from TotalSegmentator). Our\nsegmentation accuracy substantially surpasses TotalSegmentator. We share our\ntrained model and pipeline code, providing the first and only open-source tool\nfor high-resolution colon segmentation. Additionally, we created a large-scale\ndataset of publicly available high-resolution colon labels.",
    "pdf_url": "http://arxiv.org/pdf/2502.21183v1",
    "published": "2025-02-28",
    "source": "arxiv",
    "id": "2502.21183v1",
    "categories": [
      "cs.CV",
      "cs.LG"
    ]
  },
  {
    "title": "Effect of inflow conditions on tip vortex breakdown in a high Reynolds number wind turbine wake",
    "authors": [
      "Mano Grunwald",
      "Claudia E. Brunner"
    ],
    "abstract": "Understanding the re-energization of wind turbine wakes is crucial for the\ndesign and control of wind farms. Close to the rotor, this process is\ndetermined by the dynamics of the tip vortices. Here, we experimentally\ninvestigate the downstream evolution of the tip vortices for different inflow\nconditions. The experiments were performed in the Variable Density Turbulence\nTunnel at the Max Planck Institute for Dynamics and Self-Organization, which\nuses pressurized $\\mathrm{SF}_6$ as the working fluid to achieve a turbine\ndiameter-based Reynolds number of $\\mathrm{Re}_D=2.9\\times10^6$. An active\nturbulence grid was used to generate atmospheric inflow conditions with varying\nlevels of mean shear and turbulence intensity. Hot wire measurements of the\nstreamwise velocity component were conducted in the inflow and the wake of a\nmodel wind turbine MoWiTO 0.6 for various tip speed ratios and are used to\ninvestigate the scaling of tip vortex breakdown in the near wake. While the\nscaling is only weakly affected by variations in mean velocity shear, both\nturbulence intensity and tip speed ratio have a strong effect on vortex\nbreakdown.",
    "pdf_url": "http://arxiv.org/pdf/2502.21182v1",
    "published": "2025-02-28",
    "source": "arxiv",
    "id": "2502.21182v1",
    "categories": [
      "physics.flu-dyn"
    ]
  },
  {
    "title": "Reducing Reward Dependence in RL Through Adaptive Confidence Discounting",
    "authors": [
      "Muhammed Yusuf Satici",
      "David L. Roberts"
    ],
    "abstract": "In human-in-the-loop reinforcement learning or environments where calculating\na reward is expensive, the costly rewards can make learning efficiency\nchallenging to achieve. The cost of obtaining feedback from humans or\ncalculating expensive rewards means algorithms receiving feedback at every step\nof long training sessions may be infeasible, which may limit agents' abilities\nto efficiently improve performance. Our aim is to reduce the reliance of\nlearning agents on humans or expensive rewards, improving the efficiency of\nlearning while maintaining the quality of the learned policy. We offer a novel\nreinforcement learning algorithm that requests a reward only when its knowledge\nof the value of actions in an environment state is low. Our approach uses a\nreward function model as a proxy for human-delivered or expensive rewards when\nconfidence is high, and asks for those explicit rewards only when there is low\nconfidence in the model's predicted rewards and/or action selection. By\nreducing dependence on the expensive-to-obtain rewards, we are able to learn\nefficiently in settings where the logistics or expense of obtaining rewards may\notherwise prohibit it. In our experiments our approach obtains comparable\nperformance to a baseline in terms of return and number of episodes required to\nlearn, but achieves that performance with as few as 20% of the rewards.",
    "pdf_url": "http://arxiv.org/pdf/2502.21181v1",
    "published": "2025-02-28",
    "source": "arxiv",
    "id": "2502.21181v1",
    "categories": [
      "cs.LG"
    ]
  },
  {
    "title": "$Δ$-model correction of Foundation Model based on the models own understanding",
    "authors": [
      "Mads-Peter Verner Christiansen",
      "Bjørk Hammer"
    ],
    "abstract": "Foundation models of interatomic potentials, so called universal potentials,\nmay require fine-tuning or residual corrections when applied to specific\nsubclasses of materials. In the present work, we demonstrate how such\naugmentation can be accomplished via $\\Delta$-learning based on the\nrepresentation already embedded in the universal potentials. The $\\Delta$-model\nintroduced is a Gaussian Process Regression (GPR) model and various types of\naggregation (global, species-separated, and atomic) of the representation\nvector are discussed. Employing a specific universal potential, CHGNet [Deng et\nal., Nat. Mach. Intell. 5, 1031 (2023)], in a global structure optimization\nsetting, we find that it correctly describes the energetics of the \"8\" Cu\noxide, which is an ultra-thin oxide film on Cu(111). The universal potential\nmodel even predicts a more favorable structure compared to that discussed in\nrecent DFT-based literature. Moving to sulfur adatom overlayers on Cu(111),\nAg(111), and Au(111) the CHGNet model, however, requires corrections. We\ndemonstrate that these are efficiently provided via the GPR-based\n$\\Delta$-model formulated on the CHGNet's own internal atomic embedding\nrepresentation. The need for corrections is tracked to the scarcity of\nmetal-sulfur atomic environments in the materials project database that CHGNet\nis trained on leading to an overreliance on sulfur-sulfur atomic environments.\nOther universal potentials trained on the same data, MACE-MP0, SevenNet-0, and\nORB-v2-only-MPtrj show similar behavior, but with varying degrees of error,\ndemonstrating the general need for augmentation schemes for universal potential\nmodels.",
    "pdf_url": "http://arxiv.org/pdf/2502.21179v1",
    "published": "2025-02-28",
    "source": "arxiv",
    "id": "2502.21179v1",
    "categories": [
      "cond-mat.mtrl-sci"
    ]
  },
  {
    "title": "Prospection and dispersal in metapopulations: a perspective from opinion dynamics models",
    "authors": [
      "Daniela Molas",
      "Daniel Campos"
    ],
    "abstract": "Dispersal is often used by living beings to gather information from\nconspecifics, integrating it with personal experience to guide decision-making.\nThis mechanism has only recently been studied experimentally, facilitated by\nadvancements in tracking animal groups over extended periods. Such studies\nenable the analysis of the adaptive dynamics underlying sequential decisions\nand collective choices. Here, we present a theoretical framework based on the\nVoter Model to investigate these processes. The model, originally designed to\nstudy opinion or behavioral consensus within groups through imitation, is\nadapted to include the prospection of others' decisions as a mechanism for\nupdating personal criteria. We demonstrate that several properties of our model\n(such as average consensus times and polarization dynamic) can be analytically\nmapped onto those of the classical Voter Model under simplifying assumptions.\nFinally, we discuss the potential of this framework for studying more complex\nscenarios.",
    "pdf_url": "http://arxiv.org/pdf/2502.21178v1",
    "published": "2025-02-28",
    "source": "arxiv",
    "id": "2502.21178v1",
    "categories": [
      "cond-mat.stat-mech"
    ]
  },
  {
    "title": "Modeling discrete common-shock risks through matrix distributions",
    "authors": [
      "Martin Bladt",
      "Eric C. K. Cheung",
      "Oscar Peralta",
      "Jae-Kyung Woo"
    ],
    "abstract": "We introduce a novel class of bivariate common-shock discrete phase-type\n(CDPH) distributions to describe dependencies in loss modeling, with an\nemphasis on those induced by common shocks. By constructing two jointly\nevolving terminating Markov chains that share a common evolution up to a random\ntime corresponding to the common shock component, and then proceed\nindependently, we capture the essential features of risk events influenced by\nshared and individual-specific factors. We derive explicit expressions for the\njoint distribution of the termination times and prove various class and\ndistributional properties, facilitating tractable analysis of the risks.\nExtending this framework, we model random sums where aggregate claims are sums\nof continuous phase-type random variables with counts determined by these\ntermination times, and show that their joint distribution belongs to the\nmultivariate phase-type or matrix-exponential class. We develop estimation\nprocedures for the CDPH distributions using the expectation-maximization\nalgorithm and demonstrate the applicability of our models through simulation\nstudies and an application to bivariate insurance claim frequency data.",
    "pdf_url": "http://arxiv.org/pdf/2502.21172v1",
    "published": "2025-02-28",
    "source": "arxiv",
    "id": "2502.21172v1",
    "categories": [
      "math.ST",
      "stat.TH"
    ]
  },
  {
    "title": "Adaptive Illumination-Invariant Synergistic Feature Integration in a Stratified Granular Framework for Visible-Infrared Re-Identification",
    "authors": [
      "Yuheng Jia",
      "Wesley Armour"
    ],
    "abstract": "Visible-Infrared Person Re-Identification (VI-ReID) plays a crucial role in\napplications such as search and rescue, infrastructure protection, and\nnighttime surveillance. However, it faces significant challenges due to\nmodality discrepancies, varying illumination, and frequent occlusions. To\novercome these obstacles, we propose \\textbf{AMINet}, an Adaptive Modality\nInteraction Network. AMINet employs multi-granularity feature extraction to\ncapture comprehensive identity attributes from both full-body and upper-body\nimages, improving robustness against occlusions and background clutter. The\nmodel integrates an interactive feature fusion strategy for deep intra-modal\nand cross-modal alignment, enhancing generalization and effectively bridging\nthe RGB-IR modality gap. Furthermore, AMINet utilizes phase congruency for\nrobust, illumination-invariant feature extraction and incorporates an adaptive\nmulti-scale kernel MMD to align feature distributions across varying scales.\nExtensive experiments on benchmark datasets demonstrate the effectiveness of\nour approach, achieving a Rank-1 accuracy of $74.75\\%$ on SYSU-MM01, surpassing\nthe baseline by $7.93\\%$ and outperforming the current state-of-the-art by\n$3.95\\%$.",
    "pdf_url": "http://arxiv.org/pdf/2502.21163v1",
    "published": "2025-02-28",
    "source": "arxiv",
    "id": "2502.21163v1",
    "categories": [
      "cs.CV"
    ]
  },
  {
    "title": "Parallel-Learning of Invariant and Tempo-variant Attributes of Single-Lead Cardiac Signals: PLITA",
    "authors": [
      "Adtian Atienza",
      "Jakob E. Bardram",
      "Sadasivan Puthusserypady"
    ],
    "abstract": "Wearable sensing devices, such as Holter monitors, will play a crucial role\nin the future of digital health. Unsupervised learning frameworks such as\nSelf-Supervised Learning (SSL) are essential to map these single-lead\nelectrocardiogram (ECG) signals with their anticipated clinical outcomes. These\nsignals are characterized by a tempo-variant component whose patterns evolve\nthrough the recording and an invariant component with patterns that remain\nunchanged. However, existing SSL methods only drive the model to encode the\ninvariant attributes, leading the model to neglect tempo-variant information\nwhich reflects subject-state changes through time. In this paper, we present\nParallel-Learning of Invariant and Tempo-variant Attributes (PLITA), a novel\nSSL method designed for capturing both invariant and tempo-variant ECG\nattributes. The latter are captured by mandating closer representations in\nspace for closer inputs on time. We evaluate both the capability of the method\nto learn the attributes of these two distinct kinds, as well as PLITA's\nperformance compared to existing SSL methods for ECG analysis. PLITA performs\nsignificantly better in the set-ups where tempo-variant attributes play a major\nrole.",
    "pdf_url": "http://arxiv.org/pdf/2502.21162v1",
    "published": "2025-02-28",
    "source": "arxiv",
    "id": "2502.21162v1",
    "categories": [
      "cs.LG"
    ]
  },
  {
    "title": "Charge symmetry breaking in hypernuclei within RMF model",
    "authors": [
      "Ting-Ting Sun",
      "Yusuke Tanimura",
      "Hiroyuki Sagawa",
      "Emiko Hiyama"
    ],
    "abstract": "We study the charge symmetry breaking (CSB) effect in the binding energy of\nmirror hypernuclei in the mass region $A=7\\sim 48$ in relativistic mean field\n(RMF) models introducing $NN$ and $\\Lambda N$ interactions. The\nphenomenological $\\Lambda N$ CSB interaction is introduced and the strength\nparameter is fitted to reproduce the experimental binding energy difference\nbetween the mirror hypernuclei $^{12}_\\Lambda$B and $^{12}_\\Lambda$C. This\nmodel is applied to calculate the CSB energy anomaly in mirror hypernuclei with\nthe mass $A=7\\sim48$. The model is further applied to predict the binding\nenergy difference of mirror hypernuclei of $A$=40 with the isospin $T=1/2$,\n$3/2$ and $5/2$ nuclei together with various hyper Ca isotopes and their mirror\nhypernuclei. Finally the binding energy systematics of $A=$48 hypernuclei are\npredicted with/without the CSB effect by the PK1 and TM2 energy density\nfunctionals (EDFs).",
    "pdf_url": "http://arxiv.org/pdf/2502.21161v1",
    "published": "2025-02-28",
    "source": "arxiv",
    "id": "2502.21161v1",
    "categories": [
      "nucl-th"
    ]
  },
  {
    "title": "Imperfect preparation and Trojan attack on the phase modulator in the decoy-state BB84 protocol",
    "authors": [
      "Aleksei Reutov"
    ],
    "abstract": "Quantum key distribution (QKD) provides a theoretically secure method for\ncryptographic key exchange by leveraging quantum mechanics, but practical\nimplementations face vulnerabilities such as Trojan horse attack on phase\nmodulators. This work analyzes the security of QKD systems under such attacks,\nconsidering both ideal and imperfect state preparation scenarios. The Trojan\nattack model is generalized to arbitrary states of probing pulses and\nconservative bounds of information leakage through side-channel of special form\nare introduced. The quantum coin imbalance, a critical security parameter,\nremains low (on the order of $10^{-7}$ for ideal state preparation and\n$10^{-5}$ for imperfect preparation) with this new approach and presence\nadditional hardware passive countermeasures. Numerical simulations confirm\nnonzero secure key rate at distances over 100 km through optical fiber channel.",
    "pdf_url": "http://arxiv.org/pdf/2502.21160v1",
    "published": "2025-02-28",
    "source": "arxiv",
    "id": "2502.21160v1",
    "categories": [
      "quant-ph"
    ]
  },
  {
    "title": "BBGKY hierarchy for quantum error mitigation",
    "authors": [
      "Theo Saporiti",
      "Oleg Kaikov",
      "Vasily Sazonov",
      "Mohamed Tamaazousti"
    ],
    "abstract": "Mitigation of quantum errors is critical for current NISQ devices. In the\ncurrent work, we address this task by treating the execution of quantum\nalgorithms as the time evolution of an idealized physical system. We use\nknowledge of its physics to assist the mitigation of the quantum noise produced\non the real device. In particular, the time evolution of the idealized system\nobeys a corresponding BBGKY hierarchy of equations. This is the basis for the\nnovel error mitigation scheme that we propose. Specifically, we employ a subset\nof the BBGKY hierarchy as supplementary constraints in the ZNE method for error\nmitigation. We ensure that the computational cost of the scheme scales\npolynomially with the system size. We test our method on digital quantum\nsimulations of the lattice Schwinger model under noise levels mimicking\nrealistic quantum hardware. We demonstrate that our scheme systematically\nimproves the error mitigation for the measurements of the particle number and\nthe charge within this system. Relative to ZNE we obtain an average reduction\nof the error by 18.2% and 52.8% for the respective above observables. We\npropose further applications of the BBGKY hierarchy for quantum error\nmitigation.",
    "pdf_url": "http://arxiv.org/pdf/2502.21159v1",
    "published": "2025-02-28",
    "source": "arxiv",
    "id": "2502.21159v1",
    "categories": [
      "quant-ph",
      "hep-lat"
    ]
  },
  {
    "title": "CONSeg: Voxelwise Glioma Conformal Segmentation",
    "authors": [
      "Danial Elyassirad",
      "Benyamin Gheiji",
      "Mahsa Vatanparast",
      "Amir Mahmoud Ahmadzadeh",
      "Shahriar Faghani"
    ],
    "abstract": "Background and Purpose: Glioma segmentation is crucial for clinical decisions\nand treatment planning. Uncertainty quantification methods, including conformal\nprediction (CP), can enhance segmentation models reliability. This study aims\nto use CP in glioma segmentation. Methods: We used the UCSF and UPenn glioma\ndatasets, with the UCSF dataset split into training (70%), validation (10%),\ncalibration (10%), and test (10%) sets, and the UPenn dataset divided into\nexternal calibration (30%) and external test (70%) sets. A UNet model was\ntrained, and its optimal threshold was set to 0.5 using prediction\nnormalization. To apply CP, the conformal threshold was selected based on the\ninternal/external calibration nonconformity score, and CP was subsequently\napplied to the internal/external test sets, with coverage reported for all. We\ndefined the uncertainty ratio (UR) and assessed its correlation with the Dice\nscore coefficient (DSC). Additionally, we categorized cases into certain and\nuncertain groups based on UR and compared their DSC. We also evaluate the\ncorrelation between UR and DSC of the BraTS fusion model segmentation (BFMS),\nand compare DSC in the certain and uncertain subgroups. Results: The base model\nachieved a DSC of 0.8628 and 0.8257 on the internal and external test sets,\nrespectively. The CP coverage was 0.9982 for the internal test set and 0.9977\nfor the external test set. Statistical analysis showed a significant negative\ncorrelation between UR and DSC for test sets (p<0.001). UR was also linked to\nsignificantly lower DSCs in the BFMS (p<0.001). Additionally, certain cases had\nsignificantly higher DSCs than uncertain cases in test sets and the BFMS\n(p<0.001). Conclusion: CP effectively quantifies uncertainty in glioma\nsegmentation. Using CONSeg improves the reliability of segmentation models and\nenhances human-computer interaction.",
    "pdf_url": "http://arxiv.org/pdf/2502.21158v1",
    "published": "2025-02-28",
    "source": "arxiv",
    "id": "2502.21158v1",
    "categories": [
      "eess.IV"
    ]
  },
  {
    "title": "Cryptis: Cryptographic Reasoning in Separation Logic",
    "authors": [
      "Arthur Azevedo de Amorim",
      "Amal Ahmed",
      "Marco Gaboardi"
    ],
    "abstract": "We introduce Cryptis, an extension of the Iris separation logic that can be\nused to verify cryptographic components using the symbolic model of\ncryptography. The combination of separation logic and cryptographic reasoning\nallows us to prove the correctness of a protocol and later reuse this result to\nverify larger systems that rely on the protocol. To make this integration\npossible, we propose novel specifications for authentication protocols that\nallow agents in a network to agree on the use of system resources. We evaluate\nour approach by verifying various authentication protocols and a key-value\nstore server that uses these authentication protocols to connect to clients.\nOur results are formalized in Coq.",
    "pdf_url": "http://arxiv.org/pdf/2502.21156v1",
    "published": "2025-02-28",
    "source": "arxiv",
    "id": "2502.21156v1",
    "categories": [
      "cs.CR",
      "cs.LO"
    ]
  },
  {
    "title": "Hypergraph Multi-Modal Learning for EEG-based Emotion Recognition in Conversation",
    "authors": [
      "Zijian Kang",
      "Yueyang Li",
      "Shengyu Gong",
      "Weiming Zeng",
      "Hongjie Yan",
      "Lingbin Bian",
      "Wai Ting Siok",
      "Nizhuan Wang"
    ],
    "abstract": "Emotional Recognition in Conversation (ERC) is an important method for\ndiagnosing health conditions such as autism or depression, as well as\nunderstanding emotions in individuals who struggle to express their feelings.\nCurrent ERC methods primarily rely on complete semantic textual information,\nincluding audio and visual data, but face challenges in integrating\nphysiological signals such as electroencephalogram (EEG). This paper proposes a\nnovel Hypergraph Multi-Modal Learning Framework (Hyper-MML), designed to\neffectively identify emotions in conversation by integrating EEG with audio and\nvideo information to capture complex emotional dynamics. Experimental results\ndemonstrate that Hyper-MML significantly outperforms traditional methods in\nemotion recognition. This is achieved through a Multi-modal Hypergraph Fusion\nModule (MHFM), which actively models higher-order relationships between\nmulti-modal signals, as validated on the EAV dataset. Our proposed Hyper-MML\nserves as an effective communication tool for healthcare professionals,\nenabling better engagement with patients who have difficulty expressing their\nemotions.",
    "pdf_url": "http://arxiv.org/pdf/2502.21154v1",
    "published": "2025-02-28",
    "source": "arxiv",
    "id": "2502.21154v1",
    "categories": [
      "cs.HC"
    ]
  },
  {
    "title": "Hidden States and Dynamics of Fractional Fillings in tMoTe2 Moiré Superlattices",
    "authors": [
      "Yiping Wang",
      "Jeongheon Choe",
      "Eric Anderson",
      "Weijie Li",
      "Julian Ingham",
      "Eric A. Arsenault",
      "Yiliu Li",
      "Xiaodong Hu",
      "Takashi Taniguchi",
      "Kenji Watanabe",
      "Xavier Roy",
      "Dmitri Basov",
      "Di Xiao",
      "Raquel Queiroz",
      "James C. Hone",
      "Xiaodong Xu",
      "X. -Y. Zhu"
    ],
    "abstract": "The fractional quantum anomalous Hall (FQAH) effect was recently discovered\nin twisted MoTe2 bilayers (tMoTe2). Experiments to date have revealed Chern\ninsulators from hole doping at v = -1, -2/3, -3/5, and -4/7 (per moir\\'e unit\ncell). In parallel, theories predict that, between v = -1 and -3, there exist\nexotic quantum phases, such as the coveted fractional topological insulators\n(FTI), fractional quantum spin Hall (FQSH) states, and non-abelian fractional\nstates. Here we employ transient optical spectroscopy on tMoTe2 to reveal\nnearly 20 hidden states at fractional fillings that are absent in static\noptical sensing or transport measurements. A pump pulse selectively excites\ncharge across the correlated or pseudo gaps, leading to the disordering\n(melting) of correlated states. A probe pulse detects the subsequent melting\nand recovery dynamics via exciton and trion sensing. Besides the known states,\nwe observe additional fractional fillings between v = 0 and -1 and a large\nnumber of states on the electron doping side (v > 0). Most importantly, we\nobserve new states at fractional fillings of the Chern bands at v = -4/3, -3/2,\n-5/3, -7/3, -5/2, and -8/3. These states are potential candidates for the\npredicted exotic topological phases. Moreover, we show that melting of\ncorrelated states occurs on two distinct time scales, 2-4 ps and 180-270 ps,\nattributed to electronic and phonon mechanisms, respectively. We discuss the\ndiffering dynamics of the electron and hole doped states from the distinct\nmoir\\'e conduction and valence bands.",
    "pdf_url": "http://arxiv.org/pdf/2502.21153v1",
    "published": "2025-02-28",
    "source": "arxiv",
    "id": "2502.21153v1",
    "categories": [
      "cond-mat.str-el"
    ]
  },
  {
    "title": "A Review on Generative AI For Text-To-Image and Image-To-Image Generation and Implications To Scientific Images",
    "authors": [
      "Zineb Sordo",
      "Eric Chagnon",
      "Daniela Ushizima"
    ],
    "abstract": "This review surveys the state-of-the-art in text-to-image and image-to-image\ngeneration within the scope of generative AI. We provide a comparative analysis\nof three prominent architectures: Variational Autoencoders, Generative\nAdversarial Networks and Diffusion Models. For each, we elucidate core\nconcepts, architectural innovations, and practical strengths and limitations,\nparticularly for scientific image understanding. Finally, we discuss critical\nopen challenges and potential future research directions in this rapidly\nevolving field.",
    "pdf_url": "http://arxiv.org/pdf/2502.21151v1",
    "published": "2025-02-28",
    "source": "arxiv",
    "id": "2502.21151v1",
    "categories": [
      "cs.CV"
    ]
  },
  {
    "title": "Same accuracy, twice as fast: continuous training surpasses retraining from scratch",
    "authors": [
      "Eli Verwimp",
      "Guy Hacohen",
      "Tinne Tuytelaars"
    ],
    "abstract": "Continual learning aims to enable models to adapt to new datasets without\nlosing performance on previously learned data, often assuming that prior data\nis no longer available. However, in many practical scenarios, both old and new\ndata are accessible. In such cases, good performance on both datasets is\ntypically achieved by abandoning the model trained on the previous data and\nre-training a new model from scratch on both datasets. This training from\nscratch is computationally expensive. In contrast, methods that leverage the\npreviously trained model and old data are worthy of investigation, as they\ncould significantly reduce computational costs. Our evaluation framework\nquantifies the computational savings of such methods while maintaining or\nexceeding the performance of training from scratch. We identify key\noptimization aspects -- initialization, regularization, data selection, and\nhyper-parameters -- that can each contribute to reducing computational costs.\nFor each aspect, we propose effective first-step methods that already yield\nsubstantial computational savings. By combining these methods, we achieve up to\n2.7x reductions in computation time across various computer vision tasks,\nhighlighting the potential for further advancements in this area.",
    "pdf_url": "http://arxiv.org/pdf/2502.21147v1",
    "published": "2025-02-28",
    "source": "arxiv",
    "id": "2502.21147v1",
    "categories": [
      "cs.LG",
      "cs.CV"
    ]
  },
  {
    "title": "Unmasking Stealthy Attacks on Nonlinear DAE Models of Power Grids",
    "authors": [
      "Abdallah Alalem Albustami",
      "Ahmad F. Taha",
      "Elias Bou-Harb"
    ],
    "abstract": "Smart grids are inherently susceptible to various types of malicious\ncyberattacks that have all been documented in the recent literature.\nTraditional cybersecurity research on power systems often utilizes simplified\nmodels that fail to capture the interactions between dynamic and steady-state\nbehaviors, potentially underestimating the impact of cyber threats. This paper\npresents the first attempt to design and assess stealthy false data injection\nattacks (FDIAs) against nonlinear differential algebraic equation (NDAE) models\nof power networks. NDAE models, favored in industry for their ability to\naccurately capture both dynamic and steady-state behaviors, provide a more\naccurate representation of power system behavior by coupling dynamic and\nalgebraic states. We propose novel FDIA strategies that simultaneously evade\nboth dynamic and static intrusion detection systems while respecting the\nalgebraic power flow and operational constraints inherent in NDAE models. We\ndemonstrate how the coupling between dynamic and algebraic states in NDAE\nmodels significantly restricts the attacker's ability to manipulate state\nestimates while maintaining stealthiness. This highlights the importance of\nusing more comprehensive power system models in cybersecurity analysis and\nreveals potential vulnerabilities that may be overlooked in simplified\nrepresentations. The proposed attack strategies are validated through\nsimulations on the IEEE 39-bus system.",
    "pdf_url": "http://arxiv.org/pdf/2502.21146v1",
    "published": "2025-02-28",
    "source": "arxiv",
    "id": "2502.21146v1",
    "categories": [
      "eess.SY",
      "cs.SY"
    ]
  },
  {
    "title": "Hidden $sl(2)-$Symmetry of the Generalized Landau-Zener Vibronic Model",
    "authors": [
      "L. M. Nieto",
      "S. Zarrinkamar"
    ],
    "abstract": "The one-dimensional harmonic vibronic model, which is a generalization of the\nso-called linear Landau-Zener model and appears in the form of coupled\nSchr\\\"{o}dinger equations, is revisited. After decoupling the components, the\nresulting fourth-order equation is shown to have a hidden $sl(2)$ algebra. The\nso-called exceptional part of the spectrum is then expressed in a rather simple\nway. For completeness, the eigenfunctions are obtained via the Bethe ansatz\napproach directly in position space.",
    "pdf_url": "http://arxiv.org/pdf/2502.21145v1",
    "published": "2025-02-28",
    "source": "arxiv",
    "id": "2502.21145v1",
    "categories": [
      "quant-ph",
      "math-ph",
      "math.MP"
    ]
  },
  {
    "title": "Variational Bayesian Pseudo-Coreset",
    "authors": [
      "Hyungi Lee",
      "Seungyoo Lee",
      "Juho Lee"
    ],
    "abstract": "The success of deep learning requires large datasets and extensive training,\nwhich can create significant computational challenges. To address these\nchallenges, pseudo-coresets, small learnable datasets that mimic the entire\ndata, have been proposed. Bayesian Neural Networks, which offer predictive\nuncertainty and probabilistic interpretation for deep neural networks, also\nface issues with large-scale datasets due to their high-dimensional parameter\nspace. Prior works on Bayesian Pseudo-Coresets (BPC) attempt to reduce the\ncomputational load for computing weight posterior distribution by a small\nnumber of pseudo-coresets but suffer from memory inefficiency during BPC\ntraining and sub-optimal results. To overcome these limitations, we propose\nVariational Bayesian Pseudo-Coreset (VBPC), a novel approach that utilizes\nvariational inference to efficiently approximate the posterior distribution,\nreducing memory usage and computational costs while improving performance\nacross benchmark datasets.",
    "pdf_url": "http://arxiv.org/pdf/2502.21143v1",
    "published": "2025-02-28",
    "source": "arxiv",
    "id": "2502.21143v1",
    "categories": [
      "cs.LG"
    ]
  },
  {
    "title": "Multimodal Dreaming: A Global Workspace Approach to World Model-Based Reinforcement Learning",
    "authors": [
      "Léopold Maytié",
      "Roland Bertin Johannet",
      "Rufin VanRullen"
    ],
    "abstract": "Humans leverage rich internal models of the world to reason about the future,\nimagine counterfactuals, and adapt flexibly to new situations. In Reinforcement\nLearning (RL), world models aim to capture how the environment evolves in\nresponse to the agent's actions, facilitating planning and generalization.\nHowever, typical world models directly operate on the environment variables\n(e.g. pixels, physical attributes), which can make their training slow and\ncumbersome; instead, it may be advantageous to rely on high-level latent\ndimensions that capture relevant multimodal variables. Global Workspace (GW)\nTheory offers a cognitive framework for multimodal integration and information\nbroadcasting in the brain, and recent studies have begun to introduce efficient\ndeep learning implementations of GW. Here, we evaluate the capabilities of an\nRL system combining GW with a world model. We compare our GW-Dreamer with\nvarious versions of the standard PPO and the original Dreamer algorithms. We\nshow that performing the dreaming process (i.e., mental simulation) inside the\nGW latent space allows for training with fewer environment steps. As an\nadditional emergent property, the resulting model (but not its comparison\nbaselines) displays strong robustness to the absence of one of its observation\nmodalities (images or simulation attributes). We conclude that the combination\nof GW with World Models holds great potential for improving decision-making in\nRL agents.",
    "pdf_url": "http://arxiv.org/pdf/2502.21142v1",
    "published": "2025-02-28",
    "source": "arxiv",
    "id": "2502.21142v1",
    "categories": [
      "cs.AI",
      "cs.LG",
      "q-bio.NC"
    ]
  },
  {
    "title": "Predicting clinical outcomes from patient care pathways represented with temporal knowledge graphs",
    "authors": [
      "Jong Ho Jhee",
      "Alberto Megina",
      "Pacôme Constant Dit Beaufils",
      "Matilde Karakachoff",
      "Richard Redon",
      "Alban Gaignard",
      "Adrien Coulet"
    ],
    "abstract": "Background: With the increasing availability of healthcare data, predictive\nmodeling finds many applications in the biomedical domain, such as the\nevaluation of the level of risk for various conditions, which in turn can guide\nclinical decision making. However, it is unclear how knowledge graph data\nrepresentations and their embedding, which are competitive in some settings,\ncould be of interest in biomedical predictive modeling. Method: We simulated\nsynthetic but realistic data of patients with intracranial aneurysm and\nexperimented on the task of predicting their clinical outcome. We compared the\nperformance of various classification approaches on tabular data versus a\ngraph-based representation of the same data. Next, we investigated how the\nadopted schema for representing first individual data and second temporal data\nimpacts predictive performances. Results: Our study illustrates that in our\ncase, a graph representation and Graph Convolutional Network (GCN) embeddings\nreach the best performance for a predictive task from observational data. We\nemphasize the importance of the adopted schema and of the consideration of\nliteral values in the representation of individual data. Our study also\nmoderates the relative impact of various time encoding on GCN performance.",
    "pdf_url": "http://arxiv.org/pdf/2502.21138v1",
    "published": "2025-02-28",
    "source": "arxiv",
    "id": "2502.21138v1",
    "categories": [
      "cs.LG",
      "cs.AI"
    ]
  },
  {
    "title": "Dynamically Local-Enhancement Planner for Large-Scale Autonomous Driving",
    "authors": [
      "Nanshan Deng",
      "Weitao Zhou",
      "Bo Zhang",
      "Junze Wen",
      "Kun Jiang",
      "Zhong Cao",
      "Diange Yang"
    ],
    "abstract": "Current autonomous vehicles operate primarily within limited regions, but\nthere is increasing demand for broader applications. However, as models scale,\ntheir limited capacity becomes a significant challenge for adapting to novel\nscenarios. It is increasingly difficult to improve models for new situations\nusing a single monolithic model. To address this issue, we introduce the\nconcept of dynamically enhancing a basic driving planner with local driving\ndata, without permanently modifying the planner itself. This approach, termed\nthe Dynamically Local-Enhancement (DLE) Planner, aims to improve the\nscalability of autonomous driving systems without significantly expanding the\nplanner's size. Our approach introduces a position-varying Markov Decision\nProcess formulation coupled with a graph neural network that extracts\nregion-specific driving features from local observation data. The learned\nfeatures describe the local behavior of the surrounding objects, which is then\nleveraged to enhance a basic reinforcement learning-based policy. We evaluated\nour approach in multiple scenarios and compared it with a one-for-all driving\nmodel. The results show that our method outperforms the baseline policy in both\nsafety (collision rate) and average reward, while maintaining a lighter scale.\nThis approach has the potential to benefit large-scale autonomous vehicles\nwithout the need for largely expanding on-device driving models.",
    "pdf_url": "http://arxiv.org/pdf/2502.21134v1",
    "published": "2025-02-28",
    "source": "arxiv",
    "id": "2502.21134v1",
    "categories": [
      "cs.RO",
      "cs.AI"
    ]
  },
  {
    "title": "Einleitung [Introduction]",
    "authors": [
      "Vincent C. Müller"
    ],
    "abstract": "Hilary Putnam's biography and philosophical development reflect the history\nof Anglo-Saxon philosophy over the last 40 years. Putnam has influenced this\nhistory significantly for almost as long. In this introduction, the main aim is\nto present the context in which Putnam stands and from which his philosophical\ncontributions can be understood. In the context of a sketch of Putnam's\nphilosophical development, a preliminary historical classification of his work\nwill also be attempted, even if this is not the place for a comprehensive\ncritique or presentation: The introduction must remain at a fairly elementary\nlevel and of course cannot replace a reading of the texts. Since Putnam's work\nis certainly part of a rapprochement between 'analytic' and 'continental'\nphilosophy, the introduction to the texts translated here should finally make\nclear what Putnam has to offer non-analytically oriented readers.\n  Hilary Putnams Biographie und philosophische Entwicklung spiegeln die\nGeschichte der angels\\\"achsischen Philosophie in den letzten 40 Jahren. Beinahe\nebenso lange hat Putnam diese Geschichte wesentlich beeinflu{\\ss}t. In der\nvorliegenden Einleitung soll vor allem der Kontext dargestellt werden, in dem\nPutnam steht und aus dem heraus verst\\\"andlich wird, was er philosophisch zu\nsagen hat. Im Rahmen einer Skizze von Putnams philosophischer Entwicklung soll\nzudem eine vorl\\\"aufige philosophiehistorische Einordnung versucht werden, auch\nwenn hier nicht der Ort f\\\"ur eine umfassende Kritik oder Darstellung sein\nkann: Die Einleitung mu{\\ss} auf recht elementarem Niveau bleiben und kann eine\nLekt\\\"ure der Texte nat\\\"urlich nicht ersetzen. Da Putnams Werk sicherlich Teil\neiner Ann\\\"aherung von 'analytischer' und 'kontinentaler' Philosophie ist, soll\nbei der Einf\\\"uhrung in die hier \\\"ubersetzten Texte schlie{\\ss}lich deutlich\nwerden, was Putnam nicht analytisch orientierten Lesern zu bieten hat.",
    "pdf_url": "http://arxiv.org/pdf/2502.21131v1",
    "published": "2025-02-28",
    "source": "arxiv",
    "id": "2502.21131v1",
    "categories": [
      "physics.hist-ph",
      "cs.AI"
    ]
  },
  {
    "title": "Microscopic Propagator Imaging (MPI) with Diffusion MRI",
    "authors": [
      "Tommaso Zajac",
      "Gloria Menegaz",
      "Marco Pizzolato"
    ],
    "abstract": "We propose Microscopic Propagator Imaging (MPI) as a novel method to retrieve\nthe indices of the microscopic propagator which is the probability density\nfunction of water displacements due to diffusion within the nervous tissue\nmicrostructures. Unlike the Ensemble Average Propagator indices or the\nDiffusion Tensor Imaging metrics, MPI indices are independent from the\nmesoscopic organization of the tissue such as the presence of multiple axonal\nbundle directions and orientation dispersion. As a consequence, MPI indices are\nmore specific to the volumes, sizes, and types of microstructures, like axons\nand cells, that are present in the tissue. Thus, changes in MPI indices can be\nmore directly linked to alterations in the presence and integrity of\nmicrostructures themselves. The methodology behind MPI is rooted on zonal\nmodeling of spherical harmonics, signal simulation, and machine learning\nregression, and is demonstrated on both synthetic and Human Diffusion MRI data.",
    "pdf_url": "http://arxiv.org/pdf/2502.21129v1",
    "published": "2025-02-28",
    "source": "arxiv",
    "id": "2502.21129v1",
    "categories": [
      "q-bio.NC",
      "cs.LG",
      "physics.bio-ph",
      "physics.med-ph",
      "I.6.5"
    ]
  },
  {
    "title": "CuPID: Leveraging Masked Single-Lead ECG Modelling for Enhancing the Representations",
    "authors": [
      "Adtian Atienza",
      "Gouthamaan Manimaran",
      "Jakob E. Bardram",
      "Sadasivan Puthusserypady"
    ],
    "abstract": "Wearable sensing devices, such as Electrocardiogram (ECG) heart-rate\nmonitors, will play a crucial role in the future of digital health. This\ncontinuous monitoring leads to massive unlabeled data, incentivizing the\ndevelopment of unsupervised learning frameworks. While Masked Data Modelling\n(MDM) techniques have enjoyed wide use, their direct application to single-lead\nECG data is suboptimal due to the decoder's difficulty handling irregular\nheartbeat intervals when no contextual information is provided. In this paper,\nwe present Cueing the Predictor Increments the Detailing (CuPID), a novel MDM\nmethod tailored to single-lead ECGs. CuPID enhances existing MDM techniques by\ncueing spectrogram-derived context to the decoder, thus incentivizing the\nencoder to produce more detailed representations. This has a significant impact\non the encoder's performance across a wide range of different configurations,\nleading CuPID to outperform state-of-the-art methods in a variety of downstream\ntasks.",
    "pdf_url": "http://arxiv.org/pdf/2502.21127v1",
    "published": "2025-02-28",
    "source": "arxiv",
    "id": "2502.21127v1",
    "categories": [
      "cs.LG"
    ]
  },
  {
    "title": "A general partitioning strategy for non-centralized control",
    "authors": [
      "Alessandro Riccardi",
      "Luca Laurenti",
      "Bart De Schutter"
    ],
    "abstract": "Partitioning is a fundamental challenge for non-centralized control of\nlarge-scale systems, such as hierarchical, decentralized, distributed, and\ncoalitional strategies. The problem consists of finding a decomposition of a\nnetwork of dynamical systems into system units for which local controllers can\nbe designed. Unfortunately, despite its critical role, a generalized approach\nto partitioning applicable to every system is still missing from the\nliterature. This paper introduces a novel partitioning framework that\nintegrates an algorithmic selection of fundamental system units (FSUs),\nconsidered indivisible entities, with an aggregative procedure, either\nalgorithmic or optimization-based, to select composite system units (CSUs) made\nof several FSUs. A key contribution is the introduction of a global network\nmetric, the partition index, which quantitatively balances intra- and inter-CSU\ninteractions, with a granularity parameter accounting for the size of CSUs,\nallowing for their selection at different levels of aggregation. The proposed\nmethod is validated through case studies in distributed model predictive\ncontrol (DMPC) for linear and hybrid systems, showing significant reductions in\ncomputation time and cost while maintaining or improving control performance\nw.r.t. conventional strategies.",
    "pdf_url": "http://arxiv.org/pdf/2502.21126v1",
    "published": "2025-02-28",
    "source": "arxiv",
    "id": "2502.21126v1",
    "categories": [
      "eess.SY",
      "cs.SY"
    ]
  },
  {
    "title": "Eukaryotes evade information storage-replication rate trade-off with endosymbiont assistance leading to larger genomes",
    "authors": [
      "Parthasarathi Sahu",
      "Sashikanta Barik",
      "Koushik Ghosh",
      "Hemachander Subramanian"
    ],
    "abstract": "Genome length varies widely among organisms, from compact genomes of\nprokaryotes to vast and complex genomes of eukaryotes. In this study, we\ntheoretically identify the evolutionary pressures that may have driven this\ndivergence in genome length. We use a parameter-free model to study genome\nlength evolution under selection pressure to minimize replication time and\nmaximize information storage capacity. We show that prokaryotes tend to reduce\ngenome length, constrained by a single replication origin, while eukaryotes\nexpand their genomes by incorporating multiple replication origins. We propose\na connection between genome length and cellular energetics, suggesting that\nendosymbiotic organelles, mitochondria and chloroplasts, evolutionarily\nregulate the number of replication origins, thereby influencing genome length\nin eukaryotes. We show that the above two selection pressures also lead to\nstrict equalization of the number of purines and their corresponding\nbase-pairing pyrimidines within a single DNA strand, known as Chagraff's second\nparity rule, a hitherto unexplained observation in genomes of nearly all known\nspecies. This arises from the symmetrization of replichore length, another\nobservation that has been shown to hold across species, which our model\nreproduces. The model also reproduces other experimentally observed phenomena,\nsuch as a general preference for deletions over insertions, and elongation and\nhigh variance of genome lengths under reduced selection pressure for\nreplication rate, termed the C-value paradox. We highlight the possibility of\nregulation of the firing of latent replication origins in response to cues from\nthe extracellular environment leading to the regulation of cell cycle rates in\nmulticellular eukaryotes.",
    "pdf_url": "http://arxiv.org/pdf/2502.21125v1",
    "published": "2025-02-28",
    "source": "arxiv",
    "id": "2502.21125v1",
    "categories": [
      "q-bio.GN"
    ]
  },
  {
    "title": "Synthesis and characterizations of arsenic doped FeSe bulks",
    "authors": [
      "Priya Singh",
      "Manasa Manasa",
      "Mohammad Azam",
      "Tatiana Zajarniuk",
      "Konrad Kwatek",
      "Tomasz Cetner",
      "Andrzej Morawski",
      "Jan Mizeracki",
      "Shiv J. Singh"
    ],
    "abstract": "FeSe(11) family has a simple crystal structure belonging to iron-based\nsuperconductors (FBS) and has many stable phases including hexagonal and\ntetragonal structures, but only the tetragonal phase exhibits the\nsuperconductivity. In this study, we have investigated the effects of chemical\npressure induced by As-doping at Se-sites in the FeSe system by preparing a\nseries of FeSe1-xAsx (x = 0.005, 0.01, 0.02, 0.05, 0.1, and 0.2) bulks. A broad\ncharacterization has been performed on these samples using structural,\nmicrostructural, transport, and magnetic measurements. The obtained lattice\nparameters are increased by As-doping, which suggests the successful insertion\nof As at Se-sites into the tetragonal lattice for low doping contents up to 5%,\nwhereas the higher As-substitution appears in the form of the FeAs impurity\nphase. The temperature dependence of the resistivity of all samples has similar\nbehaviour and depicts the highest onset transition temperature of around 11.5\nK, but the zero resistivity is not reached until the measured temperature of 7\nK, which could be due to the presence of the impurity phases. Our study\nsuggests that a dopant with a large ionic radius, i.e., Arsenic, promotes the\nformation of the hexagonal phase of the 11 family and is effective for a small\namount of doping level for the superconducting properties, whereas higher\nAs-doping levels reduce the superconducting properties.",
    "pdf_url": "http://arxiv.org/pdf/2502.21124v1",
    "published": "2025-02-28",
    "source": "arxiv",
    "id": "2502.21124v1",
    "categories": [
      "cond-mat.supr-con",
      "cond-mat.mtrl-sci"
    ]
  },
  {
    "title": "Causality Is Key to Understand and Balance Multiple Goals in Trustworthy ML and Foundation Models",
    "authors": [
      "Ruta Binkyte",
      "Ivaxi Sheth",
      "Zhijing Jin",
      "Mohammad Havaei",
      "Bernhard Schölkopf",
      "Mario Fritz"
    ],
    "abstract": "Ensuring trustworthiness in machine learning (ML) systems is crucial as they\nbecome increasingly embedded in high-stakes domains. This paper advocates for\nintegrating causal methods into machine learning to navigate the trade-offs\namong key principles of trustworthy ML, including fairness, privacy,\nrobustness, accuracy, and explainability. While these objectives should ideally\nbe satisfied simultaneously, they are often addressed in isolation, leading to\nconflicts and suboptimal solutions. Drawing on existing applications of\ncausality in ML that successfully align goals such as fairness and accuracy or\nprivacy and robustness, this paper argues that a causal approach is essential\nfor balancing multiple competing objectives in both trustworthy ML and\nfoundation models. Beyond highlighting these trade-offs, we examine how\ncausality can be practically integrated into ML and foundation models, offering\nsolutions to enhance their reliability and interpretability. Finally, we\ndiscuss the challenges, limitations, and opportunities in adopting causal\nframeworks, paving the way for more accountable and ethically sound AI systems.",
    "pdf_url": "http://arxiv.org/pdf/2502.21123v2",
    "published": "2025-02-28",
    "source": "arxiv",
    "id": "2502.21123v2",
    "categories": [
      "cs.LG",
      "cs.AI"
    ]
  },
  {
    "title": "The Complexity-Performance Tradeoff in Resource Allocation for URLLC Exploiting Dynamic CSI",
    "authors": [
      "Federico Librino",
      "Paolo Santi"
    ],
    "abstract": "The challenging applications envisioned for the future Internet of Things\nnetworks are making it urgent to develop fast and scalable resource allocation\nalgorithms able to meet the stringent reliability and latency constraints\ntypical of the Ultra Reliable, Low Latency Communications (URLLC).\n  However, there is an inherent tradeoff between complexity and performance to\nbe addressed: sophisticated resource allocation methods providing optimized\nspectrum utilization are challenged by the scale of applications and the\nconcomitant stringent latency constraints. Whether non-trivial resource\nallocation approaches can be successfully applied in large-scale network\ninstances is still an open question that this paper aims to address. More\nspecifically, we consider a scenario in which Channel State Information (CSI)\nis used to improve spectrum allocation in a radio environment that experiences\nchannel time correlation.\n  Channel correlation allows the usage of CSI for longer time before an update,\nthus lowering the overhead burden. Following this intuition, we propose a\ndynamic pilot transmission allocation scheme in order to adaptively tune the\nCSI age.\n  We systematically analyze the improvement of this approach applied to a\nsophisticated, recently introduced graph-based resource allocation method that\nwe extend here to account for CSI.\n  The results show that, even in very dense networks and accounting for the\nhigher computational time of the graph-based approach, this algorithm is able\nto improve spectrum efficiency by over 12% as compared to a greedy heuristic,\nand that dynamic pilot transmissions allocation can further boost its\nperformance in terms of fairness, while concomitantly further increase spectrum\nefficiency of 3-5%. \\",
    "pdf_url": "http://arxiv.org/pdf/2502.21121v1",
    "published": "2025-02-28",
    "source": "arxiv",
    "id": "2502.21121v1",
    "categories": [
      "cs.NI"
    ]
  },
  {
    "title": "SEE: See Everything Every Time -- Adaptive Brightness Adjustment for Broad Light Range Images via Events",
    "authors": [
      "Yunfan Lu",
      "Xiaogang Xu",
      "Hao Lu",
      "Yanlin Qian",
      "Pengteng Li",
      "Huizai Yao",
      "Bin Yang",
      "Junyi Li",
      "Qianyi Cai",
      "Weiyu Guo",
      "Hui Xiong"
    ],
    "abstract": "Event cameras, with a high dynamic range exceeding $120dB$, significantly\noutperform traditional embedded cameras, robustly recording detailed changing\ninformation under various lighting conditions, including both low- and\nhigh-light situations. However, recent research on utilizing event data has\nprimarily focused on low-light image enhancement, neglecting image enhancement\nand brightness adjustment across a broader range of lighting conditions, such\nas normal or high illumination. Based on this, we propose a novel research\nquestion: how to employ events to enhance and adaptively adjust the brightness\nof images captured under broad lighting conditions? To investigate this\nquestion, we first collected a new dataset, SEE-600K, consisting of 610,126\nimages and corresponding events across 202 scenarios, each featuring an average\nof four lighting conditions with over a 1000-fold variation in illumination.\nSubsequently, we propose a framework that effectively utilizes events to\nsmoothly adjust image brightness through the use of prompts. Our framework\ncaptures color through sensor patterns, uses cross-attention to model events as\na brightness dictionary, and adjusts the image's dynamic range to form a broad\nlight-range representation (BLR), which is then decoded at the pixel level\nbased on the brightness prompt. Experimental results demonstrate that our\nmethod not only performs well on the low-light enhancement dataset but also\nshows robust performance on broader light-range image enhancement using the\nSEE-600K dataset. Additionally, our approach enables pixel-level brightness\nadjustment, providing flexibility for post-processing and inspiring more\nimaging applications. The dataset and source code are publicly available\nat:https://github.com/yunfanLu/SEE.",
    "pdf_url": "http://arxiv.org/pdf/2502.21120v1",
    "published": "2025-02-28",
    "source": "arxiv",
    "id": "2502.21120v1",
    "categories": [
      "cs.CV"
    ]
  },
  {
    "title": "Detection of the 2175Å UV Bump at z>7: Evidence for Rapid Dust Evolution in a Merging Reionisation-Era Galaxy",
    "authors": [
      "Katherine Ormerod",
      "Joris Witstok",
      "Renske Smit",
      "Anna de Graaff",
      "Jakob M. Helton",
      "Michael V. Maseda",
      "Irene Shivaei",
      "Andrew J. Bunker",
      "Stefano Carniani",
      "Francesco D'Eugenio",
      "Rachana Bhatawdekar",
      "Jacopo Chevallard",
      "Marijn Franx",
      "Nimisha Kumari",
      "Roberto Maiolino",
      "Pierluigi Rinaldi",
      "Brant Robertson",
      "Sandro Tacchella"
    ],
    "abstract": "Dust is a fundamental component of the interstellar medium (ISM) within\ngalaxies, as dust grains are highly efficient absorbers of UV and optical\nphotons. Accurately quantifying this obscuration is crucial for interpreting\ngalaxy spectral energy distributions (SEDs). The extinction curves in the Milky\nWay (MW) and Large Magellanic Cloud (LMC) exhibit a strong feature known as the\n2175A UV bump, most often attributed to small carbonaceous dust grains. This\nfeature was recently detected in faint galaxies out to z~7 suggesting rapid\nformation channels. Here we report the detection of a strong UV bump in a\nluminous Lyman-break galaxy at z = 7.11235, GNWY-7379420231, through\nobservations taken as part of the NIRSpec Wide GTO survey. We fit a dust\nattenuation curve that is consistent with the MW extinction curve within\n1{\\sigma}, in a galaxy just ~700 Myr after the Big Bang. From the integrated\nspectrum, we infer a young mass-weighted age (t* ~ 22-59 Myr) for this galaxy,\nhowever spatially resolved SED fitting unveils the presence of an older stellar\npopulation (t* ~ 252 Myr). Furthermore, morphological analysis provides\nevidence for a potential merger. The underlying older stellar population\nsuggests the merging system could be pre-enriched, with the dust illuminated by\na merger-induced starburst. Moreover, turbulence driven by stellar feedback in\nthis bursty region may be driving PAH formation through top-down shattering.\nThe presence of a UV bump in GNWY-7379420231 solidifies growing evidence for\nthe rapid evolution of dust properties within the first billion years of cosmic\ntime.",
    "pdf_url": "http://arxiv.org/pdf/2502.21119v1",
    "published": "2025-02-28",
    "source": "arxiv",
    "id": "2502.21119v1",
    "categories": [
      "astro-ph.GA"
    ]
  },
  {
    "title": "The two filter formula reconsidered: Smoothing in partially observed Gauss--Markov models without information parametrization",
    "authors": [
      "Filip Tronarp"
    ],
    "abstract": "In this article, the two filter formula is re-examined in the setting of\npartially observed Gauss--Markov models. It is traditionally formulated as a\nfilter running backward in time, where the Gaussian density is parametrized in\n``information form''. However, the quantity in the backward recursion is\nstrictly speaking not a distribution, but a likelihood. Taking this observation\nseriously, a recursion over log-quadratic likelihoods is formulated instead,\nwhich obviates the need for ``information'' parametrization. In particular, it\ngreatly simplifies the square-root formulation of the algorithm. Furthermore,\nformulae are given for producing the forward Markov representation of the a\nposteriori distribution over paths from the proposed likelihood representation.",
    "pdf_url": "http://arxiv.org/pdf/2502.21116v1",
    "published": "2025-02-28",
    "source": "arxiv",
    "id": "2502.21116v1",
    "categories": [
      "stat.ME",
      "cs.LG"
    ]
  },
  {
    "title": "Extremely large magnetoresistance and chiral anomaly in the nodal-line semimetal ZrAs2",
    "authors": [
      "Junjian Mi",
      "Sheng Xu",
      "Shuxiang Li",
      "Chenxi Jiang",
      "Zheng Li",
      "Qian Tao",
      "Zhu-An Xu"
    ],
    "abstract": "We performed the detailed magnetotransport measurements and first principle\ncalculations to study the electronic properties of the transition metal\ndipnictides ZrAs2, which is a topological nodal-line semimetal. Extremely large\nunsaturated magnetoresistance (MR) which is up to 1.9 * 10^4 % at 2 K and 14 T\nwas observed with magnetic field along the c-axis. The nonlinear magnetic field\ndependence of Hall resistivity indicates the multi-band features, and the\nelectron and hole are nearly compensated according to the analysis of the\ntwo-band model, which may account for the extremely large unsaturated MR at low\ntemperatures. The evident Shubnikov-de Haas (SdH) oscillations at low\ntemperatures are observed and four distinct oscillation frequencies are\nextracted. The first principle calculations and angle-dependent SdH\noscillations reveal that the Fermi surface consists of three pockets with\ndifferent anisotropy. The observed twofold symmetry MR with electric field\nalong the b-axis direction is consistent with our calculated Fermi surface\nstructures. Furthermore, the negative magnetoresistance (NMR) with magnetic\nfield in parallel with electric field is observed, which is an evident feature\nof the chiral anomaly.",
    "pdf_url": "http://arxiv.org/pdf/2502.21115v1",
    "published": "2025-02-28",
    "source": "arxiv",
    "id": "2502.21115v1",
    "categories": [
      "cond-mat.mtrl-sci"
    ]
  },
  {
    "title": "Optimizing Large Language Models for ESG Activity Detection in Financial Texts",
    "authors": [
      "Mattia Birti",
      "Francesco Osborne",
      "Andrea Maurino"
    ],
    "abstract": "The integration of Environmental, Social, and Governance (ESG) factors into\ncorporate decision-making is a fundamental aspect of sustainable finance.\nHowever, ensuring that business practices align with evolving regulatory\nframeworks remains a persistent challenge. AI-driven solutions for\nautomatically assessing the alignment of sustainability reports and\nnon-financial disclosures with specific ESG activities could greatly support\nthis process. Yet, this task remains complex due to the limitations of\ngeneral-purpose Large Language Models (LLMs) in domain-specific contexts and\nthe scarcity of structured, high-quality datasets. In this paper, we\ninvestigate the ability of current-generation LLMs to identify text related to\nenvironmental activities. Furthermore, we demonstrate that their performance\ncan be significantly enhanced through fine-tuning on a combination of original\nand synthetically generated data. To this end, we introduce ESG-Activities, a\nbenchmark dataset containing 1,325 labelled text segments classified according\nto the EU ESG taxonomy. Our experimental results show that fine-tuning on\nESG-Activities significantly enhances classification accuracy, with open models\nsuch as Llama 7B and Gemma 7B outperforming large proprietary solutions in\nspecific configurations. These findings have important implications for\nfinancial analysts, policymakers, and AI researchers seeking to enhance ESG\ntransparency and compliance through advanced natural language processing\ntechniques.",
    "pdf_url": "http://arxiv.org/pdf/2502.21112v1",
    "published": "2025-02-28",
    "source": "arxiv",
    "id": "2502.21112v1",
    "categories": [
      "cs.AI",
      "cs.CE",
      "cs.CL",
      "cs.CY",
      "cs.IR"
    ]
  },
  {
    "title": "Rare event modeling with self-regularized normalizing flows: what can we learn from a single failure?",
    "authors": [
      "Charles Dawson",
      "Van Tran",
      "Max Z. Li",
      "Chuchu Fan"
    ],
    "abstract": "Increased deployment of autonomous systems in fields like transportation and\nrobotics have seen a corresponding increase in safety-critical failures. These\nfailures can be difficult to model and debug due to the relative lack of data:\ncompared to tens of thousands of examples from normal operations, we may have\nonly seconds of data leading up to the failure. This scarcity makes it\nchallenging to train generative models of rare failure events, as existing\nmethods risk either overfitting to noise in the limited failure dataset or\nunderfitting due to an overly strong prior. We address this challenge with\nCalNF, or calibrated normalizing flows, a self-regularized framework for\nposterior learning from limited data. CalNF achieves state-of-the-art\nperformance on data-limited failure modeling and inverse problems and enables a\nfirst-of-a-kind case study into the root causes of the 2022 Southwest Airlines\nscheduling crisis.",
    "pdf_url": "http://arxiv.org/pdf/2502.21110v1",
    "published": "2025-02-28",
    "source": "arxiv",
    "id": "2502.21110v1",
    "categories": [
      "cs.LG",
      "stat.ML"
    ]
  },
  {
    "title": "\"No negatives needed\": weakly-supervised regression for interpretable tumor detection in whole-slide histopathology images",
    "authors": [
      "Marina D'Amato",
      "Jeroen van der Laak",
      "Francesco Ciompi"
    ],
    "abstract": "Accurate tumor detection in digital pathology whole-slide images (WSIs) is\ncrucial for cancer diagnosis and treatment planning. Multiple Instance Learning\n(MIL) has emerged as a widely used approach for weakly-supervised tumor\ndetection with large-scale data without the need for manual annotations.\nHowever, traditional MIL methods often depend on classification tasks that\nrequire tumor-free cases as negative examples, which are challenging to obtain\nin real-world clinical workflows, especially for surgical resection specimens.\nWe address this limitation by reformulating tumor detection as a regression\ntask, estimating tumor percentages from WSIs, a clinically available target\nacross multiple cancer types. In this paper, we provide an analysis of the\nproposed weakly-supervised regression framework by applying it to multiple\norgans, specimen types and clinical scenarios. We characterize the robustness\nof our framework to tumor percentage as a noisy regression target, and\nintroduce a novel concept of amplification technique to improve tumor detection\nsensitivity when learning from small tumor regions. Finally, we provide\ninterpretable insights into the model's predictions by analyzing visual\nattention and logit maps. Our code is available at\nhttps://github.com/DIAGNijmegen/tumor-percentage-mil-regression.",
    "pdf_url": "http://arxiv.org/pdf/2502.21109v1",
    "published": "2025-02-28",
    "source": "arxiv",
    "id": "2502.21109v1",
    "categories": [
      "eess.IV",
      "cs.CV"
    ]
  },
  {
    "title": "Large Language Model-Based Benchmarking Experiment Settings for Evolutionary Multi-Objective Optimization",
    "authors": [
      "Lie Meng Pang",
      "Hisao Ishibuchi"
    ],
    "abstract": "When we manually design an evolutionary optimization algorithm, we implicitly\nor explicitly assume a set of target optimization problems. In the case of\nautomated algorithm design, target optimization problems are usually explicitly\nshown. Recently, the use of large language models (LLMs) for the design of\nevolutionary multi-objective optimization (EMO) algorithms have been examined\nin some studies. In those studies, target multi-objective problems are not\nalways explicitly shown. It is well known in the EMO community that the\nperformance evaluation results of EMO algorithms depend on not only test\nproblems but also many other factors such as performance indicators, reference\npoint, termination condition, and population size. Thus, it is likely that the\ndesigned EMO algorithms by LLMs depends on those factors. In this paper, we try\nto examine the implicit assumption about the performance comparison of EMO\nalgorithms in LLMs. For this purpose, we ask LLMs to design a benchmarking\nexperiment of EMO algorithms. Our experiments show that LLMs often suggest\nclassical benchmark settings: Performance examination of NSGA-II, MOEA/D and\nNSGA-III on ZDT, DTLZ and WFG by HV and IGD under the standard parameter\nspecifications.",
    "pdf_url": "http://arxiv.org/pdf/2502.21108v1",
    "published": "2025-02-28",
    "source": "arxiv",
    "id": "2502.21108v1",
    "categories": [
      "cs.NE"
    ]
  },
  {
    "title": "Generating patient cohorts from electronic health records using two-step retrieval-augmented text-to-SQL generation",
    "authors": [
      "Angelo Ziletti",
      "Leonardo D'Ambrosi"
    ],
    "abstract": "Clinical cohort definition is crucial for patient recruitment and\nobservational studies, yet translating inclusion/exclusion criteria into SQL\nqueries remains challenging and manual. We present an automated system\nutilizing large language models that combines criteria parsing, two-level\nretrieval augmented generation with specialized knowledge bases, medical\nconcept standardization, and SQL generation to retrieve patient cohorts with\npatient funnels. The system achieves 0.75 F1-score in cohort identification on\nEHR data, effectively capturing complex temporal and logical relationships.\nThese results demonstrate the feasibility of automated cohort generation for\nepidemiological research.",
    "pdf_url": "http://arxiv.org/pdf/2502.21107v1",
    "published": "2025-02-28",
    "source": "arxiv",
    "id": "2502.21107v1",
    "categories": [
      "cs.CL"
    ]
  },
  {
    "title": "A Non-contrast Head CT Foundation Model for Comprehensive Neuro-Trauma Triage",
    "authors": [
      "Youngjin Yoo",
      "Bogdan Georgescu",
      "Yanbo Zhang",
      "Sasa Grbic",
      "Han Liu",
      "Gabriela D. Aldea",
      "Thomas J. Re",
      "Jyotipriya Das",
      "Poikavila Ullaskrishnan",
      "Eva Eibenberger",
      "Andrei Chekkoury",
      "Uttam K. Bodanapally",
      "Savvas Nicolaou",
      "Pina C. Sanelli",
      "Thomas J. Schroeppel",
      "Yvonne W. Lui",
      "Eli Gibson"
    ],
    "abstract": "Recent advancements in AI and medical imaging offer transformative potential\nin emergency head CT interpretation for reducing assessment times and improving\naccuracy in the face of an increasing request of such scans and a global\nshortage in radiologists. This study introduces a 3D foundation model for\ndetecting diverse neuro-trauma findings with high accuracy and efficiency.\nUsing large language models (LLMs) for automatic labeling, we generated\ncomprehensive multi-label annotations for critical conditions. Our approach\ninvolved pretraining neural networks for hemorrhage subtype segmentation and\nbrain anatomy parcellation, which were integrated into a pretrained\ncomprehensive neuro-trauma detection network through multimodal fine-tuning.\nPerformance evaluation against expert annotations and comparison with CT-CLIP\ndemonstrated strong triage accuracy across major neuro-trauma findings, such as\nhemorrhage and midline shift, as well as less frequent critical conditions such\nas cerebral edema and arterial hyperdensity. The integration of neuro-specific\nfeatures significantly enhanced diagnostic capabilities, achieving an average\nAUC of 0.861 for 16 neuro-trauma conditions. This work advances foundation\nmodels in medical imaging, serving as a benchmark for future AI-assisted\nneuro-trauma diagnostics in emergency radiology.",
    "pdf_url": "http://arxiv.org/pdf/2502.21106v1",
    "published": "2025-02-28",
    "source": "arxiv",
    "id": "2502.21106v1",
    "categories": [
      "eess.IV",
      "cs.CV"
    ]
  },
  {
    "title": "Extending the OmpSs-2 Programming Model for Hybrid Quantum-Classical Programming",
    "authors": [
      "Philip Döbler",
      "David Álvarez",
      "Lucas J. Menger",
      "Thomas Lippert",
      "Vicenç Beltran",
      "Manpreet Singh Jattana"
    ],
    "abstract": "The OmpSs-2 programming model is used in HPC programs to parallelize code and\noffload code to accelerators. In this work, we extend the offloading capability\nto quantum computers. We explain the necessary changes to the Clang compiler\nand the Nanos6 runtime, which are both part of OmpSs-2. In addition, we develop\na simulator that simulates a quantum computer in the network and receives the\njobs offloaded by the runtime. Four detailed examples show how our programming\nmodel can be used to write hybrid quantum-classical software. The examples are\nrandom number generation, a parameter scan using the mean-field ansatz, a\nvariational algorithm using this ansatz, and handwritten digit recognition\nusing a hybrid convolutional neural network.",
    "pdf_url": "http://arxiv.org/pdf/2502.21104v1",
    "published": "2025-02-28",
    "source": "arxiv",
    "id": "2502.21104v1",
    "categories": [
      "cs.ET",
      "quant-ph"
    ]
  },
  {
    "title": "AuthSim: Towards Authentic and Effective Safety-critical Scenario Generation for Autonomous Driving Tests",
    "authors": [
      "Yukuan Yang",
      "Xucheng Lu",
      "Zhili Zhang",
      "Zepeng Wu",
      "Guoqi Li",
      "Lingzhong Meng",
      "Yunzhi Xue"
    ],
    "abstract": "Generating adversarial safety-critical scenarios is a pivotal method for\ntesting autonomous driving systems, as it identifies potential weaknesses and\nenhances system robustness and reliability. However, existing approaches\npredominantly emphasize unrestricted collision scenarios, prompting non-player\ncharacter (NPC) vehicles to attack the ego vehicle indiscriminately. These\nworks overlook these scenarios' authenticity, rationality, and relevance,\nresulting in numerous extreme, contrived, and largely unrealistic collision\nevents involving aggressive NPC vehicles. To rectify this issue, we propose a\nthree-layer relative safety region model, which partitions the area based on\ndanger levels and increases the likelihood of NPC vehicles entering relative\nboundary regions. This model directs NPC vehicles to engage in adversarial\nactions within relatively safe boundary regions, thereby augmenting the\nscenarios' authenticity. We introduce AuthSim, a comprehensive platform for\ngenerating authentic and effective safety-critical scenarios by integrating the\nthree-layer relative safety region model with reinforcement learning. To our\nknowledge, this is the first attempt to address the authenticity and\neffectiveness of autonomous driving system test scenarios comprehensively.\nExtensive experiments demonstrate that AuthSim outperforms existing methods in\ngenerating effective safety-critical scenarios. Notably, AuthSim achieves a\n5.25% improvement in average cut-in distance and a 27.12% enhancement in\naverage collision interval time, while maintaining higher efficiency in\ngenerating effective safety-critical scenarios compared to existing methods.\nThis underscores its significant advantage in producing authentic scenarios\nover current methodologies.",
    "pdf_url": "http://arxiv.org/pdf/2502.21100v1",
    "published": "2025-02-28",
    "source": "arxiv",
    "id": "2502.21100v1",
    "categories": [
      "cs.RO",
      "cs.AI"
    ]
  },
  {
    "title": "Re-evaluating Theory of Mind evaluation in large language models",
    "authors": [
      "Jennifer Hu",
      "Felix Sosa",
      "Tomer Ullman"
    ],
    "abstract": "The question of whether large language models (LLMs) possess Theory of Mind\n(ToM) -- often defined as the ability to reason about others' mental states --\nhas sparked significant scientific and public interest. However, the evidence\nas to whether LLMs possess ToM is mixed, and the recent growth in evaluations\nhas not resulted in a convergence. Here, we take inspiration from cognitive\nscience to re-evaluate the state of ToM evaluation in LLMs. We argue that a\nmajor reason for the disagreement on whether LLMs have ToM is a lack of clarity\non whether models should be expected to match human behaviors, or the\ncomputations underlying those behaviors. We also highlight ways in which\ncurrent evaluations may be deviating from \"pure\" measurements of ToM abilities,\nwhich also contributes to the confusion. We conclude by discussing several\ndirections for future research, including the relationship between ToM and\npragmatic communication, which could advance our understanding of artificial\nsystems as well as human cognition.",
    "pdf_url": "http://arxiv.org/pdf/2502.21098v1",
    "published": "2025-02-28",
    "source": "arxiv",
    "id": "2502.21098v1",
    "categories": [
      "cs.AI",
      "cs.CL"
    ]
  },
  {
    "title": "LLM Post-Training: A Deep Dive into Reasoning Large Language Models",
    "authors": [
      "Komal Kumar",
      "Tajamul Ashraf",
      "Omkar Thawakar",
      "Rao Muhammad Anwer",
      "Hisham Cholakkal",
      "Mubarak Shah",
      "Ming-Hsuan Yang",
      "Phillip H. S. Torr",
      "Salman Khan",
      "Fahad Shahbaz Khan"
    ],
    "abstract": "Large Language Models (LLMs) have transformed the natural language processing\nlandscape and brought to life diverse applications. Pretraining on vast\nweb-scale data has laid the foundation for these models, yet the research\ncommunity is now increasingly shifting focus toward post-training techniques to\nachieve further breakthroughs. While pretraining provides a broad linguistic\nfoundation, post-training methods enable LLMs to refine their knowledge,\nimprove reasoning, enhance factual accuracy, and align more effectively with\nuser intents and ethical considerations. Fine-tuning, reinforcement learning,\nand test-time scaling have emerged as critical strategies for optimizing LLMs\nperformance, ensuring robustness, and improving adaptability across various\nreal-world tasks. This survey provides a systematic exploration of\npost-training methodologies, analyzing their role in refining LLMs beyond\npretraining, addressing key challenges such as catastrophic forgetting, reward\nhacking, and inference-time trade-offs. We highlight emerging directions in\nmodel alignment, scalable adaptation, and inference-time reasoning, and outline\nfuture research directions. We also provide a public repository to continually\ntrack developments in this fast-evolving field:\nhttps://github.com/mbzuai-oryx/Awesome-LLM-Post-training.",
    "pdf_url": "http://arxiv.org/pdf/2502.21321v1",
    "published": "2025-02-28",
    "source": "arxiv",
    "id": "2502.21321v1",
    "categories": [
      "cs.CL",
      "cs.CV"
    ]
  },
  {
    "title": "Raccoon: Multi-stage Diffusion Training with Coarse-to-Fine Curating Videos",
    "authors": [
      "Zhiyu Tan",
      "Junyan Wang",
      "Hao Yang",
      "Luozheng Qin",
      "Hesen Chen",
      "Qiang Zhou",
      "Hao Li"
    ],
    "abstract": "Text-to-video generation has demonstrated promising progress with the advent\nof diffusion models, yet existing approaches are limited by dataset quality and\ncomputational resources. To address these limitations, this paper presents a\ncomprehensive approach that advances both data curation and model design. We\nintroduce CFC-VIDS-1M, a high-quality video dataset constructed through a\nsystematic coarse-to-fine curation pipeline. The pipeline first evaluates video\nquality across multiple dimensions, followed by a fine-grained stage that\nleverages vision-language models to enhance text-video alignment and semantic\nrichness. Building upon the curated dataset's emphasis on visual quality and\ntemporal coherence, we develop RACCOON, a transformer-based architecture with\ndecoupled spatial-temporal attention mechanisms. The model is trained through a\nprogressive four-stage strategy designed to efficiently handle the complexities\nof video generation. Extensive experiments demonstrate that our integrated\napproach of high-quality data curation and efficient training strategy\ngenerates visually appealing and temporally coherent videos while maintaining\ncomputational efficiency. We will release our dataset, code, and models.",
    "pdf_url": "http://arxiv.org/pdf/2502.21314v1",
    "published": "2025-02-28",
    "source": "arxiv",
    "id": "2502.21314v1",
    "categories": [
      "cs.CV"
    ]
  },
  {
    "title": "FANformer: Improving Large Language Models Through Effective Periodicity Modeling",
    "authors": [
      "Yihong Dong",
      "Ge Li",
      "Xue Jiang",
      "Yongding Tao",
      "Kechi Zhang",
      "Hao Zhu",
      "Huanyu Liu",
      "Jiazheng Ding",
      "Jia Li",
      "Jinliang Deng",
      "Hong Mei"
    ],
    "abstract": "Periodicity, as one of the most important basic characteristics, lays the\nfoundation for facilitating structured knowledge acquisition and systematic\ncognitive processes within human learning paradigms. However, the potential\nflaws of periodicity modeling in Transformer affect the learning efficiency and\nestablishment of underlying principles from data for large language models\n(LLMs) built upon it. In this paper, we demonstrate that integrating effective\nperiodicity modeling can improve the learning efficiency and performance of\nLLMs. We introduce FANformer, which integrates Fourier Analysis Network (FAN)\ninto attention mechanism to achieve efficient periodicity modeling, by\nmodifying the feature projection process of attention mechanism. Extensive\nexperimental results on language modeling show that FANformer consistently\noutperforms Transformer when scaling up model size and training tokens,\nunderscoring its superior learning efficiency. To further validate the\neffectiveness of FANformer, we pretrain a FANformer-1B on 1 trillion tokens.\nFANformer-1B exhibits marked improvements on downstream tasks compared to\nopen-source LLMs with similar model parameters or training tokens. The results\nposition FANformer as an effective and promising architecture for advancing\nLLMs.",
    "pdf_url": "http://arxiv.org/pdf/2502.21309v1",
    "published": "2025-02-28",
    "source": "arxiv",
    "id": "2502.21309v1",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ]
  },
  {
    "title": "Solar prosumage under different pricing regimes: Interactions with the transmission grid",
    "authors": [
      "Dana Kirchem",
      "Mario Kendziorski",
      "Enno Wiebrow",
      "Wolf-Peter Schill",
      "Claudia Kemfert",
      "Christian von Hirschhausen"
    ],
    "abstract": "Solar prosumers, residential electricity consumers equipped with photovoltaic\n(PV) systems and battery storage, are transforming electricity markets. Their\ninteractions with the transmission grid under varying tariff designs are not\nyet fully understood. We explore the influence of different pricing regimes on\nprosumer investment and dispatch decisions and their subsequent impact on the\ntransmission grid. Using an integrated modeling approach that combines two\nopen-source dispatch, investment and grid models, we simulate prosumage\nbehavior in Germany's electricity market under real-time pricing or\ntime-invariant pricing, as well as under zonal or nodal pricing. Our findings\nshow that zonal pricing favors prosumer investments, while time-invariant\npricing rather hinders it. In comparison, regional solar availability emerges\nas a larger driver for rooftop PV investments. The impact of prosumer\nstrategies on grid congestion remains limited within the scope of our\nmodel-setup, in which home batteries cannot be used for energy arbitrage.",
    "pdf_url": "http://arxiv.org/pdf/2502.21306v1",
    "published": "2025-02-28",
    "source": "arxiv",
    "id": "2502.21306v1",
    "categories": [
      "econ.GN",
      "q-fin.EC"
    ]
  },
  {
    "title": "Oscillatory finite-time singularities in rockbursts",
    "authors": [
      "Qinghua Lei",
      "Didier Sornette"
    ],
    "abstract": "Forecasting violent rockbursts remains a formidable challenge due to\nsignificant uncertainties involved. One major uncertainty arises from the\nintermittency of rock failure processes, typically characterised by a series of\nprogressively shorter quiescent phases punctuated by sudden accelerations,\nrather than a smooth continuous progression towards the final breakdown. This\nnon-monotonic evolution of rock mass deformation complicates rockburst\nprediction, challenging conventional time-to-failure models that often assume a\nsmooth power law accelerating behaviour. Here, we introduce a generalised\ntime-to-failure model called log-periodic power law singularity (LPPLS) model\nto effectively capture the intermittent dynamics of damage and rupture\nprocesses in rock leading up to violent rockbursts. We perform parametric and\nnonparametric tests on 11 historical rockburst events at three underground\nmines, documenting empirical evidence and providing theoretical arguments to\ndemonstrate the significance of log-periodic oscillatory power law finite-time\nsingularities. Log-periodicity in these rockburst events is likely driven by\nthe interaction of subparallel propagating cracks, the diffusion of\nstress-triggering processes, or the interplay between stress drop and stress\ncorrosion. Our results and insights obtained have significant implications for\nnot only understanding but also forecasting rockbursts, as recognising and\ncharacterising log-periodicity can help transform intermittency from\ntraditionally perceived noise into valuable predictive information.",
    "pdf_url": "http://arxiv.org/pdf/2502.21296v1",
    "published": "2025-02-28",
    "source": "arxiv",
    "id": "2502.21296v1",
    "categories": [
      "physics.geo-ph"
    ]
  },
  {
    "title": "On the role of 5-wave resonances in the nonlinear dynamics of the Fermi-Pasta-Ulam-Tsingou lattice",
    "authors": [
      "Tiziana Comito",
      "Matteo Lotriglia",
      "Miguel D. Bustamante"
    ],
    "abstract": "We study the dynamics of the $(\\alpha+\\beta)$ Fermi-Pasta-Ulam-Tsingou\nlattice (FPUT lattice, for short) for an arbitrary number $N$ of interacting\nparticles, in regimes of small enough nonlinearity so that a Birkhoff-Gustavson\ntype of normal form can be found using tools from wave-turbulence theory.\nSpecifically, we obtain the so-called Zakharov equation for $4$-wave resonant\ninteractions and its extension to $5$-wave resonant interactions by Krasitskii,\nbut we introduce an important new feature: even the generic terms in these\nnormal forms contain $resonant$ $interactions$ $only$, via a $unique$ canonical\ntransformation. The resulting normal forms provide an approximation to the\noriginal FPUT lattice that possesses a significant number of exact quadratic\nconservation laws, beyond the quadratic part of the Hamiltonian. We call the\nnew equations \"exact-resonance evolution equations\" and examine their\nproperties: (i) Heisenberg representation's slow evolution allows us to\nimplement numerical methods with large time steps to obtain relevant dynamical\ninformation, such as Lyapunov exponents. (ii) We introduce tests, such as\nconvergence of the normal form transformation and truncation error\nverification, to successfully validate our exact-resonance evolution equations.\n(iii) The systematic construction of new quadratic invariants (via the resonant\ncluster matrix) allows us to use finite-time Lyapunov exponent calculations to\nquantify the level of nonlinearity at which the original FPUT lattice is well\napproximated by the exact-resonance evolution equations. We show numerical\nexperiments in the case $N=9$, but the theory and numerical methods are valid\nfor arbitrary values of $N$. We conclude that, when $3$ divides $N$, at small\nenough nonlinearity the FPUT lattice's dynamics and nontrivial hyperchaos are\ngoverned by $5$-wave resonant interactions.",
    "pdf_url": "http://arxiv.org/pdf/2502.21293v1",
    "published": "2025-02-28",
    "source": "arxiv",
    "id": "2502.21293v1",
    "categories": [
      "nlin.CD",
      "nlin.PS"
    ]
  },
  {
    "title": "ReaLJam: Real-Time Human-AI Music Jamming with Reinforcement Learning-Tuned Transformers",
    "authors": [
      "Alexander Scarlatos",
      "Yusong Wu",
      "Ian Simon",
      "Adam Roberts",
      "Tim Cooijmans",
      "Natasha Jaques",
      "Cassie Tarakajian",
      "Cheng-Zhi Anna Huang"
    ],
    "abstract": "Recent advances in generative artificial intelligence (AI) have created\nmodels capable of high-quality musical content generation. However, little\nconsideration is given to how to use these models for real-time or cooperative\njamming musical applications because of crucial required features: low latency,\nthe ability to communicate planned actions, and the ability to adapt to user\ninput in real-time. To support these needs, we introduce ReaLJam, an interface\nand protocol for live musical jamming sessions between a human and a\nTransformer-based AI agent trained with reinforcement learning. We enable\nreal-time interactions using the concept of anticipation, where the agent\ncontinually predicts how the performance will unfold and visually conveys its\nplan to the user. We conduct a user study where experienced musicians jam in\nreal-time with the agent through ReaLJam. Our results demonstrate that ReaLJam\nenables enjoyable and musically interesting sessions, and we uncover important\ntakeaways for future work.",
    "pdf_url": "http://arxiv.org/pdf/2502.21267v1",
    "published": "2025-02-28",
    "source": "arxiv",
    "id": "2502.21267v1",
    "categories": [
      "cs.HC",
      "cs.AI"
    ]
  },
  {
    "title": "ALVI Interface: Towards Full Hand Motion Decoding for Amputees Using sEMG",
    "authors": [
      "Aleksandr Kovalev",
      "Anna Makarova",
      "Petr Chizhov",
      "Matvey Antonov",
      "Gleb Duplin",
      "Vladislav Lomtev",
      "Viacheslav Gostevskii",
      "Vladimir Bessonov",
      "Andrey Tsurkan",
      "Mikhail Korobok",
      "Aleksejs Timčenko"
    ],
    "abstract": "We present a system for decoding hand movements using surface EMG signals.\nThe interface provides real-time (25 Hz) reconstruction of finger joint angles\nacross 20 degrees of freedom, designed for upper limb amputees. Our offline\nanalysis shows 0.8 correlation between predicted and actual hand movements. The\nsystem functions as an integrated pipeline with three key components: (1) a\nVR-based data collection platform, (2) a transformer-based model for\nEMG-to-motion transformation, and (3) a real-time calibration and feedback\nmodule called ALVI Interface. Using eight sEMG sensors and a VR training\nenvironment, users can control their virtual hand down to finger joint movement\nprecision, as demonstrated in our video: youtube link.",
    "pdf_url": "http://arxiv.org/pdf/2502.21256v1",
    "published": "2025-02-28",
    "source": "arxiv",
    "id": "2502.21256v1",
    "categories": [
      "cs.LG",
      "q-bio.NC"
    ]
  },
  {
    "title": "Anatomically-guided masked autoencoder pre-training for aneurysm detection",
    "authors": [
      "Alberto Mario Ceballos-Arroyo",
      "Jisoo Kim",
      "Chu-Hsuan Lin",
      "Lei Qin",
      "Geoffrey S. Young",
      "Huaizu Jiang"
    ],
    "abstract": "Intracranial aneurysms are a major cause of morbidity and mortality\nworldwide, and detecting them manually is a complex, time-consuming task.\nAlbeit automated solutions are desirable, the limited availability of training\ndata makes it difficult to develop such solutions using typical supervised\nlearning frameworks. In this work, we propose a novel pre-training strategy\nusing more widely available unannotated head CT scan data to pre-train a 3D\nVision Transformer model prior to fine-tuning for the aneurysm detection task.\nSpecifically, we modify masked auto-encoder (MAE) pre-training in the following\nways: we use a factorized self-attention mechanism to make 3D attention\ncomputationally viable, we restrict the masked patches to areas near arteries\nto focus on areas where aneurysms are likely to occur, and we reconstruct not\nonly CT scan intensity values but also artery distance maps, which describe the\ndistance between each voxel and the closest artery, thereby enhancing the\nbackbone's learned representations. Compared with SOTA aneurysm detection\nmodels, our approach gains +4-8% absolute Sensitivity at a false positive rate\nof 0.5. Code and weights will be released.",
    "pdf_url": "http://arxiv.org/pdf/2502.21244v1",
    "published": "2025-02-28",
    "source": "arxiv",
    "id": "2502.21244v1",
    "categories": [
      "cs.CV"
    ]
  },
  {
    "title": "Transforming Tuberculosis Care: Optimizing Large Language Models For Enhanced Clinician-Patient Communication",
    "authors": [
      "Daniil Filienko",
      "Mahek Nizar",
      "Javier Roberti",
      "Denise Galdamez",
      "Haroon Jakher",
      "Sarah Iribarren",
      "Weichao Yuwen",
      "Martine De Cock"
    ],
    "abstract": "Tuberculosis (TB) is the leading cause of death from an infectious disease\nglobally, with the highest burden in low- and middle-income countries. In these\nregions, limited healthcare access and high patient-to-provider ratios impede\neffective patient support, communication, and treatment completion. To bridge\nthis gap, we propose integrating a specialized Large Language Model into an\nefficacious digital adherence technology to augment interactive communication\nwith treatment supporters. This AI-powered approach, operating within a\nhuman-in-the-loop framework, aims to enhance patient engagement and improve TB\ntreatment outcomes.",
    "pdf_url": "http://arxiv.org/pdf/2502.21236v1",
    "published": "2025-02-28",
    "source": "arxiv",
    "id": "2502.21236v1",
    "categories": [
      "cs.AI",
      "cs.CL",
      "cs.HC"
    ]
  },
  {
    "title": "Bulk-edge correspondence at the spin-to-integer quantum Hall effect crossover in topological superconductors",
    "authors": [
      "Maksim Parfenov",
      "Igor Burmistrov"
    ],
    "abstract": "The spin and integer quantum Hall effects are two cousins of topological\nphase transitions in two-dimensional electronic systems. Their close\nrelationship makes it possible to transform spin to integer quantum Hall effect\nin two-dimensional topological superconductors by continuous increase in a\nsymmetry breaking Zeeman magnetic field. We study peculiarities of bulk-edge\ncorrespondence and a fate of massless edge and bulk topological (instantons)\nexcitations at such the crossover.",
    "pdf_url": "http://arxiv.org/pdf/2502.21230v1",
    "published": "2025-02-28",
    "source": "arxiv",
    "id": "2502.21230v1",
    "categories": [
      "cond-mat.mes-hall",
      "cond-mat.dis-nn",
      "cond-mat.supr-con"
    ]
  },
  {
    "title": "What is ontic and what is epistemic in the Quantum Mechanics of Spin?",
    "authors": [
      "Ariel Caticha"
    ],
    "abstract": "Entropic Dynamics (ED) provides a framework that allows the reconstruction of\nthe quantum formalism by insisting on ontological and epistemic clarity and\nadopting entropic methods and information geometry. Our present goal is to\nextend the ED framework to account for spin. The result is a realist\n{\\psi}-epistemic model in which the ontology consists of a particle described\nby a definite position plus a discrete variable that describes Pauli's peculiar\ntwo-valuedness. The resulting dynamics of probabilities is, as might be\nexpected, described by the Pauli equation. What may be unexpected is that the\ngenerators of transformations -- Hamiltonians and angular momenta including\nspin, are all granted clear epistemic status. To the old question `what is\nspinning?' ED provides a crisp answer: nothing is spinning.",
    "pdf_url": "http://arxiv.org/pdf/2502.21214v1",
    "published": "2025-02-28",
    "source": "arxiv",
    "id": "2502.21214v1",
    "categories": [
      "quant-ph"
    ]
  },
  {
    "title": "Transformers Learn to Implement Multi-step Gradient Descent with Chain of Thought",
    "authors": [
      "Jianhao Huang",
      "Zixuan Wang",
      "Jason D. Lee"
    ],
    "abstract": "Chain of Thought (CoT) prompting has been shown to significantly improve the\nperformance of large language models (LLMs), particularly in arithmetic and\nreasoning tasks, by instructing the model to produce intermediate reasoning\nsteps. Despite the remarkable empirical success of CoT and its theoretical\nadvantages in enhancing expressivity, the mechanisms underlying CoT training\nremain largely unexplored. In this paper, we study the training dynamics of\ntransformers over a CoT objective on an in-context weight prediction task for\nlinear regression. We prove that while a one-layer linear transformer without\nCoT can only implement a single step of gradient descent (GD) and fails to\nrecover the ground-truth weight vector, a transformer with CoT prompting can\nlearn to perform multi-step GD autoregressively, achieving near-exact recovery.\nFurthermore, we show that the trained transformer effectively generalizes on\nthe unseen data. With our technique, we also show that looped transformers\nsignificantly improve final performance compared to transformers without\nlooping in the in-context learning of linear regression. Empirically, we\ndemonstrate that CoT prompting yields substantial performance improvements.",
    "pdf_url": "http://arxiv.org/pdf/2502.21212v1",
    "published": "2025-02-28",
    "source": "arxiv",
    "id": "2502.21212v1",
    "categories": [
      "cs.LG",
      "cs.AI"
    ]
  },
  {
    "title": "End-to-End Deep Learning in Phase Noisy Coherent Optical Link",
    "authors": [
      "Omar Alnaseri",
      "Yassine Himeur"
    ],
    "abstract": "In coherent optical orthogonal frequency-division multiplexing (CO-OFDM)\nfiber communications, a novel end-to-end learning framework to mitigate Laser\nPhase Noise (LPN) impairments is proposed in this paper. Inspired by\nAutoencoder (AE) principles, the proposed approach trains a model to learn\nrobust symbol sequences capable of combat LPN, even from low-cost distributed\nfeedback (DFB) lasers with linewidths up to 2 MHz. This allows for the use of\nhigh-level modulation formats and large-scale Fast Fourier Transform (FFT)\nprocessing, maximizing spectral efficiency in CO-OFDM systems. By eliminating\nthe need for complex traditional techniques, this approach offers a potentially\nmore efficient and streamlined solution for CO-OFDM systems. The most\nsignificant achievement of this study is the demonstration that the proposed\nAE-based model can enhance system performance by reducing the bit error rate\n(BER) to below the threshold of forward error correction (FEC), even under\nsevere phase noise conditions, thus proving its effectiveness and efficiency in\npractical deployment scenarios.",
    "pdf_url": "http://arxiv.org/pdf/2502.21209v1",
    "published": "2025-02-28",
    "source": "arxiv",
    "id": "2502.21209v1",
    "categories": [
      "eess.SP"
    ]
  },
  {
    "title": "ARIES: Autonomous Reasoning with LLMs on Interactive Thought Graph Environments",
    "authors": [
      "Pedro Gimenes",
      "Zeyu Cao",
      "Jeffrey Wong",
      "Yiren Zhao"
    ],
    "abstract": "Recent research has shown that LLM performance on reasoning tasks can be\nenhanced by scaling test-time compute. One promising approach, particularly\nwith decomposable problems, involves arranging intermediate solutions as a\ngraph on which transformations are performed to explore the solution space.\nHowever, prior works rely on pre-determined, task-specific transformation\nschedules which are subject to a set of searched hyperparameters. In this work,\nwe view thought graph transformations as actions in a Markov decision process,\nand implement policy agents to drive effective action policies for the\nunderlying reasoning LLM agent. In particular, we investigate the ability for\nanother LLM to act as a policy agent on thought graph environments and\nintroduce ARIES, a multi-agent architecture for reasoning with LLMs. In ARIES,\nreasoning LLM agents solve decomposed subproblems, while policy LLM agents\nmaintain visibility of the thought graph states, and dynamically adapt the\nproblem-solving strategy. Through extensive experiments, we observe that using\noff-the-shelf LLMs as policy agents with no supervised fine-tuning (SFT) can\nyield up to $29\\%$ higher accuracy on HumanEval relative to static\ntransformation schedules, as well as reducing inference costs by $35\\%$ and\navoid any search requirements. We also conduct a thorough analysis of observed\nfailure modes, highlighting that limitations on LLM sizes and the depth of\nproblem decomposition can be seen as challenges to scaling LLM-guided\nreasoning.",
    "pdf_url": "http://arxiv.org/pdf/2502.21208v1",
    "published": "2025-02-28",
    "source": "arxiv",
    "id": "2502.21208v1",
    "categories": [
      "cs.AI",
      "cs.LG"
    ]
  },
  {
    "title": "An Adaptive Multiparameter Penalty Selection Method for Multiconstraint and Multiblock ADMM",
    "authors": [
      "Luke Lozenski",
      "Michael T. McCann",
      "Brendt Wohlberg"
    ],
    "abstract": "This work presents a new method for online selection of multiple penalty\nparameters for the alternating direction method of multipliers (ADMM) algorithm\napplied to optimization problems with multiple constraints or functionals with\nblock matrix components. ADMM is widely used for solving constrained\noptimization problems in a variety of fields, including signal and image\nprocessing. Implementations of ADMM often utilize a single hyperparameter,\nreferred to as the penalty parameter, which needs to be tuned to control the\nrate of convergence. However, in problems with multiple constraints, ADMM may\ndemonstrate slow convergence regardless of penalty parameter selection due to\nscale differences between constraints. Accounting for scale differences between\nconstraints to improve convergence in these cases requires introducing a\npenalty parameter for each constraint. The proposed method is able to\nadaptively account for differences in scale between constraints, providing\nrobustness with respect to problem transformations and initial selection of\npenalty parameters. It is also simple to understand and implement. Our\nnumerical experiments demonstrate that the proposed method performs favorably\ncompared to a variety of existing penalty parameter selection methods.",
    "pdf_url": "http://arxiv.org/pdf/2502.21202v1",
    "published": "2025-02-28",
    "source": "arxiv",
    "id": "2502.21202v1",
    "categories": [
      "eess.IV",
      "eess.SP",
      "math.OC"
    ]
  },
  {
    "title": "The PanAf-FGBG Dataset: Understanding the Impact of Backgrounds in Wildlife Behaviour Recognition",
    "authors": [
      "Otto Brookes",
      "Maksim Kukushkin",
      "Majid Mirmehdi",
      "Colleen Stephens",
      "Paula Dieguez",
      "Thurston C. Hicks",
      "Sorrel Jones",
      "Kevin Lee",
      "Maureen S. McCarthy",
      "Amelia Meier",
      "Emmanuelle Normand",
      "Erin G. Wessling",
      "Roman M. Wittig",
      "Kevin Langergraber",
      "Klaus Zuberbühler",
      "Lukas Boesch",
      "Thomas Schmid",
      "Mimi Arandjelovic",
      "Hjalmar Kühl",
      "Tilo Burghardt"
    ],
    "abstract": "Computer vision analysis of camera trap video footage is essential for\nwildlife conservation, as captured behaviours offer some of the earliest\nindicators of changes in population health. Recently, several high-impact\nanimal behaviour datasets and methods have been introduced to encourage their\nuse; however, the role of behaviour-correlated background information and its\nsignificant effect on out-of-distribution generalisation remain unexplored. In\nresponse, we present the PanAf-FGBG dataset, featuring 20 hours of wild\nchimpanzee behaviours, recorded at over 350 individual camera locations.\nUniquely, it pairs every video with a chimpanzee (referred to as a foreground\nvideo) with a corresponding background video (with no chimpanzee) from the same\ncamera location. We present two views of the dataset: one with overlapping\ncamera locations and one with disjoint locations. This setup enables, for the\nfirst time, direct evaluation of in-distribution and out-of-distribution\nconditions, and for the impact of backgrounds on behaviour recognition models\nto be quantified. All clips come with rich behavioural annotations and metadata\nincluding unique camera IDs and detailed textual scene descriptions.\nAdditionally, we establish several baselines and present a highly effective\nlatent-space normalisation technique that boosts out-of-distribution\nperformance by +5.42% mAP for convolutional and +3.75% mAP for\ntransformer-based models. Finally, we provide an in-depth analysis on the role\nof backgrounds in out-of-distribution behaviour recognition, including the so\nfar unexplored impact of background durations (i.e., the count of background\nframes within foreground videos).",
    "pdf_url": "http://arxiv.org/pdf/2502.21201v2",
    "published": "2025-02-28",
    "source": "arxiv",
    "id": "2502.21201v2",
    "categories": [
      "cs.CV",
      "cs.AI"
    ]
  },
  {
    "title": "AI-Enhanced Self-Triggering for Extensive Air Showers: Performance and FPGA Feasibility",
    "authors": [
      "Qader Dorosti"
    ],
    "abstract": "Cosmic-ray detection with radio antennas has traditionally depended on\nexternal triggers from particle detectors, constraining sensitivity and\nincreasing complexity. Previous attempts at fully standalone, radio-only\ntriggers have often failed under intense radio frequency interference, making\ngenuine air-shower signals difficult to isolate. We present a\nproof-of-principle artificial intelligence-based self-triggering system that\novercomes these limitations. By training a deep learning model on both real\nnoise data and injected cosmic-ray-like pulses, we achieve an exceptionally low\nfalse-positive rate alongside high detection efficiency. Configurable operating\npoints can suppress false positives below 0.01\\% while retaining more than 88\\%\nof genuine signals, and can even eliminate false positives entirely at a modest\nreduction in signal efficiency. This flexibility makes single-station\ncosmic-ray detection feasible without requiring external trigger inputs.\nApplying our approach to real-world noise conditions reduces the initial\nfalse-positive event rate by several orders of magnitude, supporting\nlarge-scale deployments. Extrapolation to dedicated hardware implementations,\nsuch as FPGAs, indicates that sub-\\SI{}{\\micro\\second} inference times are\nachievable, enabling real-time autonomous triggering. These results highlight\nthe transformative potential of artificial intelligence for enhancing radio\ndetection sensitivity and inaugurate a new generation of fully self-triggered\ncosmic-ray observatories.",
    "pdf_url": "http://arxiv.org/pdf/2502.21198v1",
    "published": "2025-02-28",
    "source": "arxiv",
    "id": "2502.21198v1",
    "categories": [
      "astro-ph.IM",
      "physics.ins-det"
    ]
  },
  {
    "title": "Towards High-performance Spiking Transformers from ANN to SNN Conversion",
    "authors": [
      "Zihan Huang",
      "Xinyu Shi",
      "Zecheng Hao",
      "Tong Bu",
      "Jianhao Ding",
      "Zhaofei Yu",
      "Tiejun Huang"
    ],
    "abstract": "Spiking neural networks (SNNs) show great potential due to their energy\nefficiency, fast processing capabilities, and robustness. There are two main\napproaches to constructing SNNs. Direct training methods require much memory,\nwhile conversion methods offer a simpler and more efficient option. However,\ncurrent conversion methods mainly focus on converting convolutional neural\nnetworks (CNNs) to SNNs. Converting Transformers to SNN is challenging because\nof the presence of non-linear modules. In this paper, we propose an Expectation\nCompensation Module to preserve the accuracy of the conversion. The core idea\nis to use information from the previous T time-steps to calculate the expected\noutput at time-step T. We also propose a Multi-Threshold Neuron and the\ncorresponding Parallel Parameter normalization to address the challenge of\nlarge time steps needed for high accuracy, aiming to reduce network latency and\npower consumption. Our experimental results demonstrate that our approach\nachieves state-of-the-art performance. For example, we achieve a top-1 accuracy\nof 88.60\\% with only a 1\\% loss in accuracy using 4 time steps while consuming\nonly 35\\% of the original power of the Transformer. To our knowledge, this is\nthe first successful Artificial Neural Network (ANN) to SNN conversion for\nSpiking Transformers that achieves high accuracy, low latency, and low power\nconsumption on complex datasets. The source codes of the proposed method are\navailable at https://github.com/h-z-h-cell/Transformer-to-SNN-ECMT.",
    "pdf_url": "http://arxiv.org/pdf/2502.21193v1",
    "published": "2025-02-28",
    "source": "arxiv",
    "id": "2502.21193v1",
    "categories": [
      "cs.CV"
    ]
  },
  {
    "title": "Integer-valued valuations",
    "authors": [
      "Andrii Ilienko",
      "Ilya Molchanov",
      "Tommaso Visonà"
    ],
    "abstract": "We obtain a complete characterization of planar monotone $\\sigma$-continuous\nvaluations taking integer values, without assuming invariance under any group\nof transformations. We further investigate the consequences of dropping\nmonotonicity or $\\sigma$-continuity and give a full classification of line\nvaluations. We also introduce a construction of the product for valuations of\nthis type.",
    "pdf_url": "http://arxiv.org/pdf/2502.21144v1",
    "published": "2025-02-28",
    "source": "arxiv",
    "id": "2502.21144v1",
    "categories": [
      "math.MG",
      "52A10"
    ]
  },
  {
    "title": "Tracks to Modernity: Railroads, Growth, and Social Movements in Denmark",
    "authors": [
      "Tom Görges",
      "Magnus Ørberg Rove",
      "Paul Sharp",
      "Christian Vedel"
    ],
    "abstract": "How do transport infrastructures shape economic transformation and social\nchange? We examine the impact of railway expansion in nineteenth-century\nDenmark on local population growth, occupational shifts, and the diffusion of\nideas. Using a historical panel dataset and a difference-in-differences\napproach, we document that railway access significantly increased population\ngrowth and accelerated structural change. Moreover, railway-connected areas\nwere more likely to establish key institutions linked to civic engagement and\nthe cooperative movement. These findings suggest that improved market access\nwas not only a driver of economic modernization but also a catalyst for\ninstitutional and cultural transformation.",
    "pdf_url": "http://arxiv.org/pdf/2502.21141v1",
    "published": "2025-02-28",
    "source": "arxiv",
    "id": "2502.21141v1",
    "categories": [
      "econ.GN",
      "q-fin.EC"
    ]
  },
  {
    "title": "A Non-contrast Head CT Foundation Model for Comprehensive Neuro-Trauma Triage",
    "authors": [
      "Youngjin Yoo",
      "Bogdan Georgescu",
      "Yanbo Zhang",
      "Sasa Grbic",
      "Han Liu",
      "Gabriela D. Aldea",
      "Thomas J. Re",
      "Jyotipriya Das",
      "Poikavila Ullaskrishnan",
      "Eva Eibenberger",
      "Andrei Chekkoury",
      "Uttam K. Bodanapally",
      "Savvas Nicolaou",
      "Pina C. Sanelli",
      "Thomas J. Schroeppel",
      "Yvonne W. Lui",
      "Eli Gibson"
    ],
    "abstract": "Recent advancements in AI and medical imaging offer transformative potential\nin emergency head CT interpretation for reducing assessment times and improving\naccuracy in the face of an increasing request of such scans and a global\nshortage in radiologists. This study introduces a 3D foundation model for\ndetecting diverse neuro-trauma findings with high accuracy and efficiency.\nUsing large language models (LLMs) for automatic labeling, we generated\ncomprehensive multi-label annotations for critical conditions. Our approach\ninvolved pretraining neural networks for hemorrhage subtype segmentation and\nbrain anatomy parcellation, which were integrated into a pretrained\ncomprehensive neuro-trauma detection network through multimodal fine-tuning.\nPerformance evaluation against expert annotations and comparison with CT-CLIP\ndemonstrated strong triage accuracy across major neuro-trauma findings, such as\nhemorrhage and midline shift, as well as less frequent critical conditions such\nas cerebral edema and arterial hyperdensity. The integration of neuro-specific\nfeatures significantly enhanced diagnostic capabilities, achieving an average\nAUC of 0.861 for 16 neuro-trauma conditions. This work advances foundation\nmodels in medical imaging, serving as a benchmark for future AI-assisted\nneuro-trauma diagnostics in emergency radiology.",
    "pdf_url": "http://arxiv.org/pdf/2502.21106v1",
    "published": "2025-02-28",
    "source": "arxiv",
    "id": "2502.21106v1",
    "categories": [
      "eess.IV",
      "cs.CV"
    ]
  },
  {
    "title": "Deep learning-based filtering of cross-spectral matrices using generative adversarial networks",
    "authors": [
      "Christof Puhle"
    ],
    "abstract": "In this paper, we present a deep-learning method to filter out effects such\nas ambient noise, reflections, or source directivity from microphone array data\nrepresented as cross-spectral matrices. Specifically, we focus on a generative\nadversarial network (GAN) architecture designed to transform fixed-size\ncross-spectral matrices. Theses models were trained using sound pressure\nsimulations of varying complexity developed for this purpose. Based on the\nresults from applying these methods in a hyperparameter optimization of an\nauto-encoding task, we trained the optimized model to perform five distinct\ntransformation tasks derived from different complexities inherent in our sound\npressure simulations.",
    "pdf_url": "http://arxiv.org/pdf/2502.21097v1",
    "published": "2025-02-28",
    "source": "arxiv",
    "id": "2502.21097v1",
    "categories": [
      "cs.SD",
      "eess.AS",
      "eess.SP"
    ]
  },
  {
    "title": "BST: Badminton Stroke-type Transformer for Skeleton-based Action Recognition in Racket Sports",
    "authors": [
      "Jing-Yuan Chang"
    ],
    "abstract": "Badminton, known for having the fastest ball speeds among all sports,\npresents significant challenges to the field of computer vision, including\nplayer identification, court line detection, shuttlecock trajectory tracking,\nand player stroke-type classification. In this paper, we introduce a novel\nvideo segmentation strategy to extract frames of each player's racket swing in\na badminton broadcast match. These segmented frames are then processed by two\nexisting models: one for Human Pose Estimation to obtain player skeletal\njoints, and the other for shuttlecock trajectory detection to extract\nshuttlecock trajectories. Leveraging these joints, trajectories, and player\npositions as inputs, we propose Badminton Stroke-type Transformer (BST) to\nclassify player stroke-types in singles. To the best of our knowledge,\nexperimental results demonstrate that our method outperforms the previous\nstate-of-the-art on the largest publicly available badminton video dataset,\nShuttleSet, which shows that effectively leveraging ball trajectory is likely\nto be a trend for racket sports action recognition.",
    "pdf_url": "http://arxiv.org/pdf/2502.21085v1",
    "published": "2025-02-28",
    "source": "arxiv",
    "id": "2502.21085v1",
    "categories": [
      "cs.CV"
    ]
  },
  {
    "title": "Training-free and Adaptive Sparse Attention for Efficient Long Video Generation",
    "authors": [
      "Yifei Xia",
      "Suhan Ling",
      "Fangcheng Fu",
      "Yujie Wang",
      "Huixia Li",
      "Xuefeng Xiao",
      "Bin Cui"
    ],
    "abstract": "Generating high-fidelity long videos with Diffusion Transformers (DiTs) is\noften hindered by significant latency, primarily due to the computational\ndemands of attention mechanisms. For instance, generating an 8-second 720p\nvideo (110K tokens) with HunyuanVideo takes about 600 PFLOPs, with around 500\nPFLOPs consumed by attention computations. To address this issue, we propose\nAdaSpa, the first Dynamic Pattern and Online Precise Search sparse attention\nmethod. Firstly, to realize the Dynamic Pattern, we introduce a blockified\npattern to efficiently capture the hierarchical sparsity inherent in DiTs. This\nis based on our observation that sparse characteristics of DiTs exhibit\nhierarchical and blockified structures between and within different modalities.\nThis blockified approach significantly reduces the complexity of attention\ncomputation while maintaining high fidelity in the generated videos. Secondly,\nto enable Online Precise Search, we propose the Fused LSE-Cached Search with\nHead-adaptive Hierarchical Block Sparse Attention. This method is motivated by\nour finding that DiTs' sparse pattern and LSE vary w.r.t. inputs, layers, and\nheads, but remain invariant across denoising steps. By leveraging this\ninvariance across denoising steps, it adapts to the dynamic nature of DiTs and\nallows for precise, real-time identification of sparse indices with minimal\noverhead. AdaSpa is implemented as an adaptive, plug-and-play solution and can\nbe integrated seamlessly with existing DiTs, requiring neither additional\nfine-tuning nor a dataset-dependent profiling. Extensive experiments validate\nthat AdaSpa delivers substantial acceleration across various models while\npreserving video quality, establishing itself as a robust and scalable approach\nto efficient video generation.",
    "pdf_url": "http://arxiv.org/pdf/2502.21079v1",
    "published": "2025-02-28",
    "source": "arxiv",
    "id": "2502.21079v1",
    "categories": [
      "cs.CV"
    ]
  },
  {
    "title": "Enhancing deep neural networks through complex-valued representations and Kuramoto synchronization dynamics",
    "authors": [
      "Sabine Muzellec",
      "Andrea Alamia",
      "Thomas Serre",
      "Rufin VanRullen"
    ],
    "abstract": "Neural synchrony is hypothesized to play a crucial role in how the brain\norganizes visual scenes into structured representations, enabling the robust\nencoding of multiple objects within a scene. However, current deep learning\nmodels often struggle with object binding, limiting their ability to represent\nmultiple objects effectively. Inspired by neuroscience, we investigate whether\nsynchrony-based mechanisms can enhance object encoding in artificial models\ntrained for visual categorization. Specifically, we combine complex-valued\nrepresentations with Kuramoto dynamics to promote phase alignment, facilitating\nthe grouping of features belonging to the same object. We evaluate two\narchitectures employing synchrony: a feedforward model and a recurrent model\nwith feedback connections to refine phase synchronization using top-down\ninformation. Both models outperform their real-valued counterparts and\ncomplex-valued models without Kuramoto synchronization on tasks involving\nmulti-object images, such as overlapping handwritten digits, noisy inputs, and\nout-of-distribution transformations. Our findings highlight the potential of\nsynchrony-driven mechanisms to enhance deep learning models, improving their\nperformance, robustness, and generalization in complex visual categorization\ntasks.",
    "pdf_url": "http://arxiv.org/pdf/2502.21077v1",
    "published": "2025-02-28",
    "source": "arxiv",
    "id": "2502.21077v1",
    "categories": [
      "cs.CV",
      "cs.AI",
      "nlin.AO",
      "q-bio.NC"
    ]
  },
  {
    "title": "Fast 3D point clouds retrieval for Large-scale 3D Place Recognition",
    "authors": [
      "Chahine-Nicolas Zede",
      "Laurent Carrafa",
      "Valérie Gouet-Brunet"
    ],
    "abstract": "Retrieval in 3D point clouds is a challenging task that consists in\nretrieving the most similar point clouds to a given query within a reference of\n3D points. Current methods focus on comparing descriptors of point clouds in\norder to identify similar ones. Due to the complexity of this latter step, here\nwe focus on the acceleration of the retrieval by adapting the Differentiable\nSearch Index (DSI), a transformer-based approach initially designed for text\ninformation retrieval, for 3D point clouds retrieval. Our approach generates 1D\nidentifiers based on the point descriptors, enabling direct retrieval in\nconstant time. To adapt DSI to 3D data, we integrate Vision Transformers to map\ndescriptors to these identifiers while incorporating positional and semantic\nencoding. The approach is evaluated for place recognition on a public benchmark\ncomparing its retrieval capabilities against state-of-the-art methods, in terms\nof quality and speed of returned point clouds.",
    "pdf_url": "http://arxiv.org/pdf/2502.21067v1",
    "published": "2025-02-28",
    "source": "arxiv",
    "id": "2502.21067v1",
    "categories": [
      "cs.CV",
      "cs.IR",
      "68T10, 68T45",
      "I.5.4; I.2.10"
    ]
  },
  {
    "title": "Efficient Transformer-based Decoder for Varshamov-Tenengolts Codes",
    "authors": [
      "Yali Wei",
      "Alan J. X. Guo",
      "Zihui Yan",
      "Yufan Dai"
    ],
    "abstract": "In recent years, the rise of DNA data storage technology has brought\nsignificant attention to the challenge of correcting insertion, deletion, and\nsubstitution (IDS) errors. Among various coding methods for IDS correction,\nVarshamov-Tenengolts (VT) codes, primarily designed for single-error\ncorrection, have emerged as a central research focus. While existing decoding\nmethods achieve high accuracy in correcting a single error, they often fail to\ncorrect multiple IDS errors. In this work, we observe that VT codes retain some\ncapability for addressing multiple errors by introducing a transformer-based VT\ndecoder (TVTD) along with symbol- and statistic-based codeword embedding.\nExperimental results demonstrate that the proposed TVTD achieves perfect\ncorrection of a single error. Furthermore, when decoding multiple errors across\nvarious codeword lengths, the bit error rate and frame error rate are\nsignificantly improved compared to existing hard decision and soft-in soft-out\nalgorithms. Additionally, through model architecture optimization, the proposed\nmethod reduces time consumption by an order of magnitude compared to other soft\ndecoders.",
    "pdf_url": "http://arxiv.org/pdf/2502.21060v1",
    "published": "2025-02-28",
    "source": "arxiv",
    "id": "2502.21060v1",
    "categories": [
      "cs.LG",
      "cs.IT",
      "math.IT"
    ]
  },
  {
    "title": "FC-Attack: Jailbreaking Large Vision-Language Models via Auto-Generated Flowcharts",
    "authors": [
      "Ziyi Zhang",
      "Zhen Sun",
      "Zongmin Zhang",
      "Jihui Guo",
      "Xinlei He"
    ],
    "abstract": "Large Vision-Language Models (LVLMs) have become powerful and widely adopted\nin some practical applications. However, recent research has revealed their\nvulnerability to multimodal jailbreak attacks, whereby the model can be induced\nto generate harmful content, leading to safety risks. Although most LVLMs have\nundergone safety alignment, recent research shows that the visual modality is\nstill vulnerable to jailbreak attacks. In our work, we discover that by using\nflowcharts with partially harmful information, LVLMs can be induced to provide\nadditional harmful details. Based on this, we propose a jailbreak attack method\nbased on auto-generated flowcharts, FC-Attack. Specifically, FC-Attack first\nfine-tunes a pre-trained LLM to create a step-description generator based on\nbenign datasets. The generator is then used to produce step descriptions\ncorresponding to a harmful query, which are transformed into flowcharts in 3\ndifferent shapes (vertical, horizontal, and S-shaped) as visual prompts. These\nflowcharts are then combined with a benign textual prompt to execute a\njailbreak attack on LVLMs. Our evaluations using the Advbench dataset show that\nFC-Attack achieves over 90% attack success rates on Gemini-1.5, Llaval-Next,\nQwen2-VL, and InternVL-2.5 models, outperforming existing LVLM jailbreak\nmethods. Additionally, we investigate factors affecting the attack performance,\nincluding the number of steps and the font styles in the flowcharts. Our\nevaluation shows that FC-Attack can improve the jailbreak performance from 4%\nto 28% in Claude-3.5 by changing the font style. To mitigate the attack, we\nexplore several defenses and find that AdaShield can largely reduce the\njailbreak performance but with the cost of utility drop.",
    "pdf_url": "http://arxiv.org/pdf/2502.21059v1",
    "published": "2025-02-28",
    "source": "arxiv",
    "id": "2502.21059v1",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.CR",
      "cs.LG"
    ]
  },
  {
    "title": "Quantum-aware Transformer model for state classification",
    "authors": [
      "Przemysław Sekuła",
      "Michał Romaszewski",
      "Przemysław Głomb",
      "Michał Cholewa",
      "Łukasz Pawela"
    ],
    "abstract": "Entanglement is a fundamental feature of quantum mechanics, playing a crucial\nrole in quantum information processing. However, classifying entangled states,\nparticularly in the mixed-state regime, remains a challenging problem,\nespecially as system dimensions increase. In this work, we focus on bipartite\nquantum states and present a data-driven approach to entanglement\nclassification using transformer-based neural networks. Our dataset consists of\na diverse set of bipartite states, including pure separable states, Werner\nentangled states, general entangled states, and maximally entangled states. We\npretrain the transformer in an unsupervised fashion by masking elements of\nvectorized Hermitian matrix representations of quantum states, allowing the\nmodel to learn structural properties of quantum density matrices. This approach\nenables the model to generalize entanglement characteristics across different\nclasses of states. Once trained, our method achieves near-perfect\nclassification accuracy, effectively distinguishing between separable and\nentangled states. Compared to previous Machine Learning, our method\nsuccessfully adapts transformers for quantum state analysis, demonstrating\ntheir ability to systematically identify entanglement in bipartite systems.\nThese results highlight the potential of modern machine learning techniques in\nautomating entanglement detection and classification, bridging the gap between\nquantum information theory and artificial intelligence.",
    "pdf_url": "http://arxiv.org/pdf/2502.21055v1",
    "published": "2025-02-28",
    "source": "arxiv",
    "id": "2502.21055v1",
    "categories": [
      "quant-ph",
      "cs.LG",
      "81P45, 68T05",
      "I.2.6"
    ]
  },
  {
    "title": "Proof systems for partial incorrectness logic (partial reverse Hoare logic)",
    "authors": [
      "Yukihiro Oda"
    ],
    "abstract": "Partial incorrectness logic (partial reverse Hoare logic) has recently been\nintroduced as a new Hoare-style logic that over-approximates the weakest\npre-conditions of a program and a post-condition. It is expected to verify\nsystems where the final state must guarantee its initial state, such as\nauthentication, secure communication tools and digital signatures. However, the\nlogic has only been given semantics. This paper defines two proof systems for\npartial incorrectness logic (partial reverse Hoare logic): ordinary and cyclic\nproof systems. They are sound and relatively complete. The relative\ncompleteness of our ordinary proof system is proved by showing that the weakest\npre-condition of a while loop and a post-condition is its loop invariant. The\nrelative completeness of our cyclic proof system is also proved by providing a\nway to transform any cyclic proof into an ordinary proof.",
    "pdf_url": "http://arxiv.org/pdf/2502.21053v1",
    "published": "2025-02-28",
    "source": "arxiv",
    "id": "2502.21053v1",
    "categories": [
      "cs.LO",
      "cs.PL"
    ]
  },
  {
    "title": "Detection of anomalies in cow activity using wavelet transform based features",
    "authors": [
      "Valentin Guien",
      "Violaine Antoine",
      "Romain Lardy",
      "Isabelle Veissier",
      "Luis E C Rocha"
    ],
    "abstract": "In Precision Livestock Farming, detecting deviations from optimal or baseline\nvalues - i.e. anomalies in time series - is essential to allow undertaking\ncorrective actions rapidly. Here we aim at detecting anomalies in 24h time\nseries of cow activity, with a view to detect cases of disease or oestrus.\nDeviations must be distinguished from noise which can be very high in case of\nbiological data. It is also important to detect the anomaly early, e.g. before\na farmer would notice it visually. Here, we investigate the benefit of using\nwavelet transforms to denoise data and we assess the performance of an anomaly\ndetection algorithm considering the timing of the detection. We developed\nfeatures based on the comparisons between the wavelet transforms of the mean of\nthe time series and the wavelet transforms of individual time series instances.\nWe hypothesized that these features contribute to the detection of anomalies in\nperiodic time series using a feature-based algorithm. We tested this hypothesis\nwith two datasets representing cow activity, which typically follows a daily\npattern but can deviate due to specific physiological or pathological\nconditions. We applied features derived from wavelet transform as well as\nstatistical features in an Isolation Forest algorithm. We measured the distance\nof detection between the days annotated abnormal by animal caretakers days and\nthe days predicted abnormal by the algorithm. The results show that\nwavelet-based features are among the features most contributing to anomaly\ndetection. They also show that detections are close to the annotated days, and\noften precede it. In conclusion, using wavelet transforms on time series of cow\nactivity data helps to detect anomalies related to specific cow states. The\ndetection is often obtained on days that precede the day annotated by\ncaretakers, which offer possibility to take corrective actions at an early\nstage.",
    "pdf_url": "http://arxiv.org/pdf/2502.21051v1",
    "published": "2025-02-28",
    "source": "arxiv",
    "id": "2502.21051v1",
    "categories": [
      "cs.LG",
      "cs.CE"
    ]
  },
  {
    "title": "Synthesizing Individualized Aging Brains in Health and Disease with Generative Models and Parallel Transport",
    "authors": [
      "Jingru Fu",
      "Yuqi Zheng",
      "Neel Dey",
      "Daniel Ferreira",
      "Rodrigo Moreno"
    ],
    "abstract": "Simulating prospective magnetic resonance imaging (MRI) scans from a given\nindividual brain image is challenging, as it requires accounting for canonical\nchanges in aging and/or disease progression while also considering the\nindividual brain's current status and unique characteristics. While current\ndeep generative models can produce high-resolution anatomically accurate\ntemplates for population-wide studies, their ability to predict future aging\ntrajectories for individuals remains limited, particularly in capturing\nsubject-specific neuroanatomical variations over time. In this study, we\nintroduce Individualized Brain Synthesis (InBrainSyn), a framework for\nsynthesizing high-resolution subject-specific longitudinal MRI scans that\nsimulate neurodegeneration in both Alzheimer's disease (AD) and normal aging.\nInBrainSyn uses a parallel transport algorithm to adapt the population-level\naging trajectories learned by a generative deep template network, enabling\nindividualized aging synthesis. As InBrainSyn uses diffeomorphic\ntransformations to simulate aging, the synthesized images are topologically\nconsistent with the original anatomy by design. We evaluated InBrainSyn both\nquantitatively and qualitatively on AD and healthy control cohorts from the\nOpen Access Series of Imaging Studies - version 3 dataset. Experimentally,\nInBrainSyn can also model neuroanatomical transitions between normal aging and\nAD. An evaluation of an external set supports its generalizability. Overall,\nwith only a single baseline scan, InBrainSyn synthesizes realistic 3D\nspatiotemporal T1w MRI scans, producing personalized longitudinal aging\ntrajectories. The code for InBrainSyn is available at:\nhttps://github.com/Fjr9516/InBrainSyn.",
    "pdf_url": "http://arxiv.org/pdf/2502.21049v1",
    "published": "2025-02-28",
    "source": "arxiv",
    "id": "2502.21049v1",
    "categories": [
      "cs.CV",
      "cs.AI",
      "eess.IV"
    ]
  },
  {
    "title": "Data-free Universal Adversarial Perturbation with Pseudo-semantic Prior",
    "authors": [
      "Chanhui Lee",
      "Yeonghwan Song",
      "Jeany Son"
    ],
    "abstract": "Data-free Universal Adversarial Perturbation (UAP) is an image-agnostic\nadversarial attack that deceives deep neural networks using a single\nperturbation generated solely from random noise, without any data priors.\nHowever, traditional data-free UAP methods often suffer from limited\ntransferability due to the absence of semantic information in random noise. To\naddress this, we propose a novel data-free universal attack approach that\ngenerates a pseudo-semantic prior recursively from the UAPs, enriching semantic\ncontents within the data-free UAP framework. Our method is based on the\nobservation that UAPs inherently contain latent semantic information, enabling\nthe generated UAP to act as an alternative data prior, by capturing a diverse\nrange of semantics through region sampling. We further introduce a sample\nreweighting technique to emphasize hard examples by focusing on samples that\nare less affected by the UAP. By leveraging the semantic information from the\npseudo-semantic prior, we also incorporate input transformations, typically\nineffective in data-free UAPs due to the lack of semantic content in random\npriors, to boost black-box transferability. Comprehensive experiments on\nImageNet show that our method achieves state-of-the-art performance in average\nfooling rate by a substantial margin, significantly improves attack\ntransferability across various CNN architectures compared to existing data-free\nUAP methods, and even surpasses data-dependent UAP methods.",
    "pdf_url": "http://arxiv.org/pdf/2502.21048v1",
    "published": "2025-02-28",
    "source": "arxiv",
    "id": "2502.21048v1",
    "categories": [
      "cs.CV"
    ]
  },
  {
    "title": "A parallel-in-time solver for nonlinear degenerate time-periodic parabolic problems",
    "authors": [
      "Herbert Egger",
      "Andreas Schafelner"
    ],
    "abstract": "A class of abstract nonlinear time-periodic evolution problems is considered\nwhich arise in electrical engineering and other scientific disciplines. An\nefficient solver is proposed for the systems arising after discretization in\ntime based on a fixed-point iteration. Every step of this iteration amounts to\nthe solution of a discretized time-periodic and time-invariant problem for\nwhich efficient parallel-in-time methods are available. Global convergence with\ncontraction factors independent of the discretization parameters is\nestablished. Together with an appropriate initialization step, a highly\nefficient and reliable solver is obtained. The applicability and performance of\nthe proposed method is illustrated by simulations of a power transformer.\nFurther comparison is made with other solution strategies proposed in the\nliterature.",
    "pdf_url": "http://arxiv.org/pdf/2502.21013v1",
    "published": "2025-02-28",
    "source": "arxiv",
    "id": "2502.21013v1",
    "categories": [
      "math.NA",
      "cs.NA"
    ]
  },
  {
    "title": "MagNet: Multi-Level Attention Graph Network for Predicting High-Resolution Spatial Transcriptomics",
    "authors": [
      "Junchao Zhu",
      "Ruining Deng",
      "Tianyuan Yao",
      "Juming Xiong",
      "Chongyu Qu",
      "Junlin Guo",
      "Siqi Lu",
      "Yucheng Tang",
      "Daguang Xu",
      "Mengmeng Yin",
      "Yu Wang",
      "Shilin Zhao",
      "Yaohong Wang",
      "Haichun Yang",
      "Yuankai Huo"
    ],
    "abstract": "The rapid development of spatial transcriptomics (ST) offers new\nopportunities to explore the gene expression patterns within the spatial\nmicroenvironment. Current research integrates pathological images to infer gene\nexpression, addressing the high costs and time-consuming processes to generate\nspatial transcriptomics data. However, as spatial transcriptomics resolution\ncontinues to improve, existing methods remain primarily focused on gene\nexpression prediction at low-resolution spot levels. These methods face\nsignificant challenges, especially the information bottleneck, when they are\napplied to high-resolution HD data. To bridge this gap, this paper introduces\nMagNet, a multi-level attention graph network designed for accurate prediction\nof high-resolution HD data. MagNet employs cross-attention layers to integrate\nfeatures from multi-resolution image patches hierarchically and utilizes a\nGAT-Transformer module to aggregate neighborhood information. By integrating\nmultilevel features, MagNet overcomes the limitations posed by low-resolution\ninputs in predicting high-resolution gene expression. We systematically\nevaluated MagNet and existing ST prediction models on both a private spatial\ntranscriptomics dataset and a public dataset at three different resolution\nlevels. The results demonstrate that MagNet achieves state-of-the-art\nperformance at both spot level and high-resolution bin levels, providing a\nnovel methodology and benchmark for future research and applications in\nhigh-resolution HD-level spatial transcriptomics. Code is available at\nhttps://github.com/Junchao-Zhu/MagNet.",
    "pdf_url": "http://arxiv.org/pdf/2502.21011v1",
    "published": "2025-02-28",
    "source": "arxiv",
    "id": "2502.21011v1",
    "categories": [
      "cs.CV"
    ]
  },
  {
    "title": "The Last Meridian Circles",
    "authors": [
      "Erik Høg"
    ],
    "abstract": "The aim is to document in some detail the last 35 years of meridian circles,\na type of instrument with a fundamental role in astronomy for a very long time,\nand to do so while witnesses are still alive and can contribute. This is about\nfinding facts. Meridian circles provided fundamental star positions for\ncenturies. These positions were tied to a well-defined celestial coordinate\nsystem of right ascension and declination, and accurate proper motions ensured\na transformation of the positions over long periods of time. This function of\nthe meridian circles has been taken over by space astrometry and VLBI. The\nHipparcos astrometric satellite was approved by ESA in 1980 and launched to a\nsuccessful 3-year mission in 1989, and the successor, Gaia, has in 2025\ncompleted a mission of over 10 years. An account is given of the last 18\nmeridian instruments, which were active for some part of the 35 years until\n2015. This account is based on information found on the internet, and on input\nkindly supplied in correspondence with many colleagues.",
    "pdf_url": "http://arxiv.org/pdf/2502.21005v1",
    "published": "2025-02-28",
    "source": "arxiv",
    "id": "2502.21005v1",
    "categories": [
      "astro-ph.IM"
    ]
  },
  {
    "title": "Real-Time Aerial Fire Detection on Resource-Constrained Devices Using Knowledge Distillation",
    "authors": [
      "Sabina Jangirova",
      "Branislava Jankovic",
      "Waseem Ullah",
      "Latif U. Khan",
      "Mohsen Guizani"
    ],
    "abstract": "Wildfire catastrophes cause significant environmental degradation, human\nlosses, and financial damage. To mitigate these severe impacts, early fire\ndetection and warning systems are crucial. Current systems rely primarily on\nfixed CCTV cameras with a limited field of view, restricting their\neffectiveness in large outdoor environments. The fusion of intelligent fire\ndetection with remote sensing improves coverage and mobility, enabling\nmonitoring in remote and challenging areas. Existing approaches predominantly\nutilize convolutional neural networks and vision transformer models. While\nthese architectures provide high accuracy in fire detection, their\ncomputational complexity limits real-time performance on edge devices such as\nUAVs. In our work, we present a lightweight fire detection model based on\nMobileViT-S, compressed through the distillation of knowledge from a stronger\nteacher model. The ablation study highlights the impact of a teacher model and\nthe chosen distillation technique on the model's performance improvement. We\ngenerate activation map visualizations using Grad-CAM to confirm the model's\nability to focus on relevant fire regions. The high accuracy and efficiency of\nthe proposed model make it well-suited for deployment on satellites, UAVs, and\nIoT devices for effective fire detection. Experiments on common fire benchmarks\ndemonstrate that our model suppresses the state-of-the-art model by 0.44%,\n2.00% while maintaining a compact model size. Our model delivers the highest\nprocessing speed among existing works, achieving real-time performance on\nresource-constrained devices.",
    "pdf_url": "http://arxiv.org/pdf/2502.20979v1",
    "published": "2025-02-28",
    "source": "arxiv",
    "id": "2502.20979v1",
    "categories": [
      "cs.CV"
    ]
  },
  {
    "title": "MultiResolution Low-Rank Regularization of Dynamic Imaging Problems",
    "authors": [
      "Tommi Heikkilä"
    ],
    "abstract": "MultiResolution Low-Rank decomposition is formulated for regularization of\ndynamic image sequences. The decomposition applies a local low-rank\ndecomposition on a sequence of discrete wavelet transforms. Its effective\nformulation as a regularization functional is discussed and numerically tested\nfor dynamic X-ray tomography in comparison to other low-rank methods. The\nresults suggest it is similar to traditional locally low-rank decomposition but\nproduces less severe block artifacts.",
    "pdf_url": "http://arxiv.org/pdf/2502.20977v1",
    "published": "2025-02-28",
    "source": "arxiv",
    "id": "2502.20977v1",
    "categories": [
      "math.NA",
      "cs.NA",
      "15A29, 65F55, 65T60, 65F22"
    ]
  },
  {
    "title": "Reward Dimension Reduction for Scalable Multi-Objective Reinforcement Learning",
    "authors": [
      "Giseung Park",
      "Youngchul Sung"
    ],
    "abstract": "In this paper, we introduce a simple yet effective reward dimension reduction\nmethod to tackle the scalability challenges of multi-objective reinforcement\nlearning algorithms. While most existing approaches focus on optimizing two to\nfour objectives, their abilities to scale to environments with more objectives\nremain uncertain. Our method uses a dimension reduction approach to enhance\nlearning efficiency and policy performance in multi-objective settings. While\nmost traditional dimension reduction methods are designed for static datasets,\nour approach is tailored for online learning and preserves Pareto-optimality\nafter transformation. We propose a new training and evaluation framework for\nreward dimension reduction in multi-objective reinforcement learning and\ndemonstrate the superiority of our method in environments including one with\nsixteen objectives, significantly outperforming existing online dimension\nreduction methods.",
    "pdf_url": "http://arxiv.org/pdf/2502.20957v1",
    "published": "2025-02-28",
    "source": "arxiv",
    "id": "2502.20957v1",
    "categories": [
      "cs.LG"
    ]
  },
  {
    "title": "Concealed Adversarial attacks on neural networks for sequential data",
    "authors": [
      "Petr Sokerin",
      "Dmitry Anikin",
      "Sofia Krehova",
      "Alexey Zaytsev"
    ],
    "abstract": "The emergence of deep learning led to the broad usage of neural networks in\nthe time series domain for various applications, including finance and\nmedicine. While powerful, these models are prone to adversarial attacks: a\nbenign targeted perturbation of input data leads to significant changes in a\nclassifier's output. However, formally small attacks in the time series domain\nbecome easily detected by the human eye or a simple detector model.\n  We develop a concealed adversarial attack for different time-series models:\nit provides more realistic perturbations, being hard to detect by a human or\nmodel discriminator. To achieve this goal, the proposed adversarial attack\nmaximizes an aggregation of a classifier and a trained discriminator loss. To\nmake the attack stronger, we also propose a training procedure for a\ndiscriminator that provides broader coverage of possible attacks. Extensive\nbenchmarking on six UCR time series datasets across four diverse architectures\n- including recurrent, convolutional, state-space, and transformer-based models\n- demonstrates the superiority of our attack for a concealability-efficiency\ntrade-off. Our findings highlight the growing challenge of designing robust\ntime series models, emphasizing the need for improved defenses against\nrealistic and effective attacks.",
    "pdf_url": "http://arxiv.org/pdf/2502.20948v1",
    "published": "2025-02-28",
    "source": "arxiv",
    "id": "2502.20948v1",
    "categories": [
      "cs.LG",
      "cs.AI"
    ]
  },
  {
    "title": "Amortized Conditional Independence Testing",
    "authors": [
      "Bao Duong",
      "Nu Hoang",
      "Thin Nguyen"
    ],
    "abstract": "Testing for the conditional independence structure in data is a fundamental\nand critical task in statistics and machine learning, which finds natural\napplications in causal discovery - a highly relevant problem to many scientific\ndisciplines. Existing methods seek to design explicit test statistics that\nquantify the degree of conditional dependence, which is highly challenging yet\ncannot capture nor utilize prior knowledge in a data-driven manner. In this\nstudy, an entirely new approach is introduced, where we instead propose to\namortize conditional independence testing and devise ACID - a novel\ntransformer-based neural network architecture that learns to test for\nconditional independence. ACID can be trained on synthetic data in a supervised\nlearning fashion, and the learned model can then be applied to any dataset of\nsimilar natures or adapted to new domains by fine-tuning with a negligible\ncomputational cost. Our extensive empirical evaluations on both synthetic and\nreal data reveal that ACID consistently achieves state-of-the-art performance\nagainst existing baselines under multiple metrics, and is able to generalize\nrobustly to unseen sample sizes, dimensionalities, as well as non-linearities\nwith a remarkably low inference time.",
    "pdf_url": "http://arxiv.org/pdf/2502.20925v1",
    "published": "2025-02-28",
    "source": "arxiv",
    "id": "2502.20925v1",
    "categories": [
      "stat.ML",
      "cs.LG"
    ]
  },
  {
    "title": "Preconditioned Block Encodings for Quantum Linear Systems",
    "authors": [
      "Leigh Lapworth",
      "Christoph Sünderhauf"
    ],
    "abstract": "Quantum linear system solvers like the Quantum Singular Value Transformation\n(QSVT) require a block encoding of the system matrix $A$ within a unitary\noperator $U_A$. Unfortunately, block encoding often results in significant\nsubnormalisation and increase in the matrix's effective condition number\n$\\kappa$, affecting the efficiency of solvers. Matrix preconditioning is a\nwell-established classical technique to reduce $\\kappa$ by multiplying $A$ by a\npreconditioner $P$. Here, we study quantum preconditioning for block encodings.\nWe consider four preconditioners and two encoding approaches: (a) separately\nencoding $A$ and its preconditioner $P$, followed by quantum multiplication,\nand (b) classically multiplying $A$ and $P$ before encoding the product in\n$U_{PA}$. Their impact on subnormalisation factors and condition number\n$\\kappa$ are analysed using practical matrices from Computational Fluid\nDynamics (CFD). Our results show that (a) quantum multiplication introduces\nexcessive subnormalisation factors, negating improvements in $\\kappa$. We\nintroduce preamplified quantum multiplication to reduce subnormalisation, which\nis of independent interest. Conversely, we see that (b) encoding of the\nclassical product can significantly improve the effective condition number\nusing the Sparse Approximate Inverse preconditioner with infill. Further, we\nintroduce a new matrix filtering technique that reduces the circuit depth\nwithout adversely affecting the matrix solution. We apply these methods to\nreduce the number of QSVT phase factors by a factor of 25 for an example CFD\nmatrix of size 1024x1024.",
    "pdf_url": "http://arxiv.org/pdf/2502.20908v1",
    "published": "2025-02-28",
    "source": "arxiv",
    "id": "2502.20908v1",
    "categories": [
      "quant-ph"
    ]
  },
  {
    "title": "DexGraspVLA: A Vision-Language-Action Framework Towards General Dexterous Grasping",
    "authors": [
      "Yifan Zhong",
      "Xuchuan Huang",
      "Ruochong Li",
      "Ceyao Zhang",
      "Yitao Liang",
      "Yaodong Yang",
      "Yuanpei Chen"
    ],
    "abstract": "Dexterous grasping remains a fundamental yet challenging problem in robotics.\nA general-purpose robot must be capable of grasping diverse objects in\narbitrary scenarios. However, existing research typically relies on specific\nassumptions, such as single-object settings or limited environments, leading to\nconstrained generalization. Our solution is DexGraspVLA, a hierarchical\nframework that utilizes a pre-trained Vision-Language model as the high-level\ntask planner and learns a diffusion-based policy as the low-level Action\ncontroller. The key insight lies in iteratively transforming diverse language\nand visual inputs into domain-invariant representations, where imitation\nlearning can be effectively applied due to the alleviation of domain shift.\nThus, it enables robust generalization across a wide range of real-world\nscenarios. Notably, our method achieves a 90+% success rate under thousands of\nunseen object, lighting, and background combinations in a ``zero-shot''\nenvironment. Empirical analysis further confirms the consistency of internal\nmodel behavior across environmental variations, thereby validating our design\nand explaining its generalization performance. We hope our work can be a step\nforward in achieving general dexterous grasping. Our demo and code can be found\nat https://dexgraspvla.github.io/.",
    "pdf_url": "http://arxiv.org/pdf/2502.20900v1",
    "published": "2025-02-28",
    "source": "arxiv",
    "id": "2502.20900v1",
    "categories": [
      "cs.RO",
      "cs.AI"
    ]
  },
  {
    "title": "Ultrafast Heterogeneous Melting of Metals under Extreme Non-equilibrium States",
    "authors": [
      "Qiyu Zeng",
      "Xiaoxiang Yu",
      "Bo Chen",
      "Shen Zhang",
      "Kaiguo Chen",
      "Dongdong Kang",
      "Jiayu Dai"
    ],
    "abstract": "The extreme electron-ion nonequilibrium states created by ultrafast laser\nexcitation challenge conventional melting paradigms. Through neural\nnetwork-enhanced multiscale simulations of tungsten and gold nanofilms, we\nidentify electronic pressure relaxation as a critical driver of heterogeneous\nphase transformations. Subpicosecond uniaxial expansion generates density\ndecrease that enable surface-initiated melting far below equilibrium melting\ntemperatures. This ultrafast heterogeneous melting propagates at 2500\nm/s-tenfold faster than thermal mechanisms-with characteristic stationary\ndiffraction peak splitting distinguishing it from thermal expansion dynamics.\nWhile tungsten shows pressure-driven solid-solid transitions, gold exhibits\ncomplete room-temperature amorphization under electronic stress. These results\nestablish hot-electron-mediated lattice destabilization as a universal pathway\nfor laser-induced structural transformations, providing new insights for\ninterpreting time-resolved experiments and controlling laser-matter\ninteractions.",
    "pdf_url": "http://arxiv.org/pdf/2502.20886v1",
    "published": "2025-02-28",
    "source": "arxiv",
    "id": "2502.20886v1",
    "categories": [
      "physics.comp-ph",
      "cond-mat.mtrl-sci",
      "physics.app-ph"
    ]
  },
  {
    "title": "Time-optimal problem in the space of probabilities measures",
    "authors": [
      "Yurii Averboukh",
      "Ekaterina Kolpakova"
    ],
    "abstract": "This paper focuses on the value function in the time-optimal problem for a\ncontinuity equation in the space of probability measures. We derive the dynamic\nprogramming principle for this problem. In particular, we prove that the\nKruzhkov transform of the value function coincides with a unique discontinuous\nviscosity solution to the corresponding Dirichlet problem for the\nHamilton-Jacobi equation. Finally, we establish the $\\Gamma$-convergence of the\nvalue function in a perturbed problem to the value function in the unperturbed\nproblem.",
    "pdf_url": "http://arxiv.org/pdf/2502.20871v1",
    "published": "2025-02-28",
    "source": "arxiv",
    "id": "2502.20871v1",
    "categories": [
      "math.AP",
      "math.OC",
      "math.PR",
      "49J20, 49J52, 49L25, 49N70, 91A23, 49K20, 82C22"
    ]
  },
  {
    "title": "JiTTER: Jigsaw Temporal Transformer for Event Reconstruction for Self-Supervised Sound Event Detection",
    "authors": [
      "Hyeonuk Nam",
      "Yong-Hwa Park"
    ],
    "abstract": "Sound event detection (SED) has significantly benefited from self-supervised\nlearning (SSL) approaches, particularly masked audio transformer for SED\n(MAT-SED), which leverages masked block prediction to reconstruct missing audio\nsegments. However, while effective in capturing global dependencies, masked\nblock prediction disrupts transient sound events and lacks explicit enforcement\nof temporal order, making it less suitable for fine-grained event boundary\ndetection. To address these limitations, we propose JiTTER (Jigsaw Temporal\nTransformer for Event Reconstruction), an SSL framework designed to enhance\ntemporal modeling in transformer-based SED. JiTTER introduces a hierarchical\ntemporal shuffle reconstruction strategy, where audio sequences are randomly\nshuffled at both the block-level and frame-level, forcing the model to\nreconstruct the correct temporal order. This pretraining objective encourages\nthe model to learn both global event structures and fine-grained transient\ndetails, improving its ability to detect events with sharp onset-offset\ncharacteristics. Additionally, we incorporate noise injection during block\nshuffle, providing a subtle perturbation mechanism that further regularizes\nfeature learning and enhances model robustness. Experimental results on the\nDESED dataset demonstrate that JiTTER outperforms MAT-SED, achieving a 5.89%\nimprovement in PSDS, highlighting the effectiveness of explicit temporal\nreasoning in SSL-based SED. Our findings suggest that structured temporal\nreconstruction tasks, rather than simple masked prediction, offer a more\neffective pretraining paradigm for sound event representation learning.",
    "pdf_url": "http://arxiv.org/pdf/2502.20857v1",
    "published": "2025-02-28",
    "source": "arxiv",
    "id": "2502.20857v1",
    "categories": [
      "eess.AS",
      "cs.SD"
    ]
  },
  {
    "title": "MAMUT: A Novel Framework for Modifying Mathematical Formulas for the Generation of Specialized Datasets for Language Model Training",
    "authors": [
      "Jonathan Drechsel",
      "Anja Reusch",
      "Steffen Herbold"
    ],
    "abstract": "Mathematical formulas are a fundamental and widely used component in various\nscientific fields, serving as a universal language for expressing complex\nconcepts and relationships. While state-of-the-art transformer models excel in\nprocessing and understanding natural language, they encounter challenges with\nmathematical notation, which involves a complex structure and diverse\nrepresentations. This study focuses on the development of specialized training\ndatasets to enhance the encoding of mathematical content. We introduce Math\nMutator (MAMUT), a framework capable of generating equivalent and falsified\nversions of a given mathematical formula in LaTeX notation, effectively\ncapturing the mathematical variety in notation of the same concept. Based on\nMAMUT, we have generated four large mathematical datasets containing diverse\nnotation, which can be used to train language models with enhanced mathematical\nembeddings.",
    "pdf_url": "http://arxiv.org/pdf/2502.20855v1",
    "published": "2025-02-28",
    "source": "arxiv",
    "id": "2502.20855v1",
    "categories": [
      "cs.CL",
      "cs.LG"
    ]
  },
  {
    "title": "Oscillation-Reduced MXFP4 Training for Vision Transformers",
    "authors": [
      "Yuxiang Chen",
      "Haocheng Xi",
      "Jun Zhu",
      "Jianfei Chen"
    ],
    "abstract": "Pre-training Transformers in FP4 precision is becoming a promising approach\nto gain substantial speedup, but it comes with a considerable loss of accuracy.\nMicroscaling (MX) data format provides a fine-grained per-group quantization\nmethod to improve the representation ability of the FP4 format and is supported\nby the next-generation Blackwell GPU architecture. However, training with MXFP4\ndata format still results in significant degradation and there is a lack of\nsystematic research on the reason.\n  In this work, we propose a novel training method TetraJet for a more accurate\nFP4 training. We comprehensively evaluate all of the quantizers involved in the\ntraining, and identify the weight oscillation problem in the forward pass as\nthe main source of the degradation in MXFP4 training. Therefore, we introduce\ntwo novel methods, EMA Quantizer (Q-EMA) and Adaptive Ramping Optimizer\n(Q-Ramping), to resolve the oscillation problem. Extensive experiments on\nVision Transformers demonstrate that TetraJet consistently outperforms the\nexisting 4-bit training methods, and Q-EMA & Q-Ramping can provide additional\nenhancement by effectively reducing oscillation. We decreased the accuracy\ndegradation by more than $50\\%$ compared to the baseline, and can even achieve\ncompetitive performance compared to full precision training. The codes are\navailable at https://github.com/thu-ml/TetraJet-MXFP4Training",
    "pdf_url": "http://arxiv.org/pdf/2502.20853v1",
    "published": "2025-02-28",
    "source": "arxiv",
    "id": "2502.20853v1",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CV"
    ]
  },
  {
    "title": "A Laplace duality for integration",
    "authors": [
      "Jean B Lasserre"
    ],
    "abstract": "We consider the integral v(y) = Ky f (x)dx on a domain Ky = {x $\\in$ R d :\ng(x) $\\le$ y}, where g is nonnegative and Ky is compact for all y $\\in$ [0,\n+$\\infty$). Under some assumptions, we show that for every y $\\in$ (0,\n$\\infty$) there exists a distinguished scalar $\\lambda$y $\\in$ (0, +$\\infty$)\nsuch that which is the counterpart analogue for integration of Lagrangian\nduality for optimization. A crucial ingredient is the Laplace transform, the\nanalogue for integration of Legendre-Fenchel transform in optimization. In\nparticular, if both f and g are positively homogeneous then $\\lambda$y is a\nsimple explicitly rational function of y. In addition if g is quadratic form\nthen computing v(y) reduces to computing the integral of f with respect to a\nspecific Gaussian measure for which exact and approximate numerical methods\n(e.g. cubatures) are available.",
    "pdf_url": "http://arxiv.org/pdf/2502.20842v1",
    "published": "2025-02-28",
    "source": "arxiv",
    "id": "2502.20842v1",
    "categories": [
      "math.OC"
    ]
  },
  {
    "title": "Theory of Slidetronics in Ferroelectric van der Waals Layers",
    "authors": [
      "Byeoksong Lee",
      "Minki Lee",
      "Joongoo Kang"
    ],
    "abstract": "Vertically stacked layers derived from non-ferroelectric monolayers offer a\npromising route to two-dimensional (2D) ferroelectrics, where polarization\nswitching occurs via interlayer sliding at sub-unit cell scales. Here, we\ndevelop a theory of slidetronics based on the notion that sliding-induced\nswitching $P \\rightarrow P'$ can also be achieved by applying an appropriate\npoint-group operator $G$ to the entire system, such that $P' = G P$. Interlayer\nsliding and the transformation induced by the generator $G$ are thus equivalent\nin describing the relationship between the initial and final layer\nconfigurations. From this symmetry principle, we deduce that slidetronics can\nbe classified by generators $G$; the generator $G$ must act as a symmetry\noperator for the constituent layers, while it is not a symmetry operator for\nthe stacked layers as a whole; for a given 2D material, $G$ determines the\ninterlayer sliding required for polarization switching; and sliding-induced\ncomplete polarization inversion is impossible in bilayers but can be realized\nin multilayers (e.g., PdSe$_2$ trilayers). These findings provide a framework\nfor designing 2D ferroelectrics with targeted polarization-switching\nproperties, as demonstrated through case studies of real materials.",
    "pdf_url": "http://arxiv.org/pdf/2502.20832v1",
    "published": "2025-02-28",
    "source": "arxiv",
    "id": "2502.20832v1",
    "categories": [
      "cond-mat.mtrl-sci",
      "cond-mat.mes-hall"
    ]
  },
  {
    "title": "CoTMR: Chain-of-Thought Multi-Scale Reasoning for Training-Free Zero-Shot Composed Image Retrieval",
    "authors": [
      "Zelong Sun",
      "Dong Jing",
      "Zhiwu Lu"
    ],
    "abstract": "Zero-Shot Composed Image Retrieval (ZS-CIR) aims to retrieve target images by\nintegrating information from a composed query (reference image and modification\ntext) without training samples. Existing methods primarily combine caption\nmodels and large language models (LLMs) to generate target captions based on\ncomposed queries but face various issues such as incompatibility, visual\ninformation loss, and insufficient reasoning. In this work, we propose CoTMR, a\ntraining-free framework crafted for ZS-CIR with novel Chain-of-thought (CoT)\nand Multi-scale Reasoning. Instead of relying on caption models for modality\ntransformation, CoTMR employs the Large Vision-Language Model (LVLM) to achieve\nunified understanding and reasoning for composed queries. To enhance the\nreasoning reliability, we devise CIRCoT, which guides the LVLM through a\nstep-by-step inference process using predefined subtasks. Considering that\nexisting approaches focus solely on global-level reasoning, our CoTMR\nincorporates multi-scale reasoning to achieve more comprehensive inference via\nfine-grained predictions about the presence or absence of key elements at the\nobject scale. Further, we design a Multi-Grained Scoring (MGS) mechanism, which\nintegrates CLIP similarity scores of the above reasoning outputs with candidate\nimages to realize precise retrieval. Extensive experiments demonstrate that our\nCoTMR not only drastically outperforms previous methods across four prominent\nbenchmarks but also offers appealing interpretability.",
    "pdf_url": "http://arxiv.org/pdf/2502.20826v1",
    "published": "2025-02-28",
    "source": "arxiv",
    "id": "2502.20826v1",
    "categories": [
      "cs.CV",
      "cs.IR"
    ]
  },
  {
    "title": "Can We Simplify Slide-level Fine-tuning of Pathology Foundation Models?",
    "authors": [
      "Jiawen Li",
      "Jiali Hu",
      "Qiehe Sun",
      "Renao Yan",
      "Minxi Ouyang",
      "Tian Guan",
      "Anjia Han",
      "Chao He",
      "Yonghong He"
    ],
    "abstract": "The emergence of foundation models in computational pathology has transformed\nhistopathological image analysis, with whole slide imaging (WSI) diagnosis\nbeing a core application. Traditionally, weakly supervised fine-tuning via\nmultiple instance learning (MIL) has been the primary method for adapting\nfoundation models to WSIs. However, in this work we present a key experimental\nfinding: a simple nonlinear mapping strategy combining mean pooling and a\nmultilayer perceptron, called SiMLP, can effectively adapt patch-level\nfoundation models to slide-level tasks without complex MIL-based learning.\nThrough extensive experiments across diverse downstream tasks, we demonstrate\nthe superior performance of SiMLP with state-of-the-art methods. For instance,\non a large-scale pan-cancer classification task, SiMLP surpasses popular\nMIL-based methods by 3.52%. Furthermore, SiMLP shows strong learning ability in\nfew-shot classification and remaining highly competitive with slide-level\nfoundation models pretrained on tens of thousands of slides. Finally, SiMLP\nexhibits remarkable robustness and transferability in lung cancer subtyping.\nOverall, our findings challenge the conventional MIL-based fine-tuning\nparadigm, demonstrating that a task-agnostic representation strategy alone can\neffectively adapt foundation models to WSI analysis. These insights offer a\nunique and meaningful perspective for future research in digital pathology,\npaving the way for more efficient and broadly applicable methodologies.",
    "pdf_url": "http://arxiv.org/pdf/2502.20823v1",
    "published": "2025-02-28",
    "source": "arxiv",
    "id": "2502.20823v1",
    "categories": [
      "cs.CV"
    ]
  },
  {
    "title": "Multimodal Learning for Just-In-Time Software Defect Prediction in Autonomous Driving Systems",
    "authors": [
      "Faisal Mohammad",
      "Duksan Ryu"
    ],
    "abstract": "In recent years, the rise of autonomous driving technologies has highlighted\nthe critical importance of reliable software for ensuring safety and\nperformance. This paper proposes a novel approach for just-in-time software\ndefect prediction (JIT-SDP) in autonomous driving software systems using\nmultimodal learning. The proposed model leverages the multimodal transformers\nin which the pre-trained transformers and a combining module deal with the\nmultiple data modalities of the software system datasets such as code features,\nchange metrics, and contextual information. The key point for adapting\nmultimodal learning is to utilize the attention mechanism between the different\ndata modalities such as text, numerical, and categorical. In the combining\nmodule, the output of a transformer model on text data and tabular features\ncontaining categorical and numerical data are combined to produce the\npredictions using the fully connected layers. Experiments conducted on three\nopen-source autonomous driving system software projects collected from the\nGitHub repository (Apollo, Carla, and Donkeycar) demonstrate that the proposed\napproach significantly outperforms state-of-the-art deep learning and machine\nlearning models regarding evaluation metrics. Our findings highlight the\npotential of multimodal learning to enhance the reliability and safety of\nautonomous driving software through improved defect prediction.",
    "pdf_url": "http://arxiv.org/pdf/2502.20806v1",
    "published": "2025-02-28",
    "source": "arxiv",
    "id": "2502.20806v1",
    "categories": [
      "cs.SE",
      "cs.AI"
    ]
  },
  {
    "title": "Two-Stream Spatial-Temporal Transformer Framework for Person Identification via Natural Conversational Keypoints",
    "authors": [
      "Masoumeh Chapariniya",
      "Hossein Ranjbar",
      "Teodora Vukovic",
      "Sarah Ebling",
      "Volker Dellwo"
    ],
    "abstract": "In the age of AI-driven generative technologies, traditional biometric\nrecognition systems face unprecedented challenges, particularly from\nsophisticated deepfake and face reenactment techniques. In this study, we\npropose a Two-Stream Spatial-Temporal Transformer Framework for person\nidentification using upper body keypoints visible during online conversations,\nwhich we term conversational keypoints. Our framework processes both spatial\nrelationships between keypoints and their temporal evolution through two\nspecialized branches: a Spatial Transformer (STR) that learns distinctive\nstructural patterns in keypoint configurations, and a Temporal Transformer\n(TTR) that captures sequential motion patterns. Using the state-of-the-art\nSapiens pose estimator, we extract 133 keypoints (based on COCO-WholeBody\nformat) representing facial features, head pose, and hand positions. The\nframework was evaluated on a dataset of 114 individuals engaged in natural\nconversations, achieving recognition accuracies of 80.12% for the spatial\nstream, 63.61% for the temporal stream. We then explored two fusion strategies:\na shared loss function approach achieving 82.22% accuracy, and a feature-level\nfusion method that concatenates feature maps from both streams, significantly\nimproving performance to 94.86%. By jointly modeling both static anatomical\nrelationships and dynamic movement patterns, our approach learns comprehensive\nidentity signatures that are more robust to spoofing than traditional\nappearance-based methods.",
    "pdf_url": "http://arxiv.org/pdf/2502.20803v1",
    "published": "2025-02-28",
    "source": "arxiv",
    "id": "2502.20803v1",
    "categories": [
      "cs.CV"
    ]
  },
  {
    "title": "Plan2Align: Predictive Planning Based Test-Time Preference Alignment in Paragraph-Level Machine Translation",
    "authors": [
      "Kuang-Da Wang",
      "Teng-Ruei Chen",
      "Yu Heng Hung",
      "Shuoyang Ding",
      "Yueh-Hua Wu",
      "Yu-Chiang Frank Wang",
      "Chao-Han Huck Yang",
      "Wen-Chih Peng",
      "Ping-Chun Hsieh"
    ],
    "abstract": "Machine Translation (MT) has been predominantly designed for sentence-level\ntranslation using transformer-based architectures. While next-token prediction\nbased Large Language Models (LLMs) demonstrate strong capabilities in long-text\ntranslation, non-extensive language models often suffer from omissions and\nsemantic inconsistencies when processing paragraphs. Existing preference\nalignment methods improve sentence-level translation but fail to ensure\ncoherence over extended contexts due to the myopic nature of next-token\ngeneration. We introduce Plan2Align, a test-time alignment framework that\ntreats translation as a predictive planning problem, adapting Model Predictive\nControl to iteratively refine translation outputs. Experiments on WMT24\nDiscourse-Level Literary Translation show that Plan2Align significantly\nimproves paragraph-level translation, achieving performance surpassing or on\npar with the existing training-time and test-time alignment methods on\nLLaMA-3.1 8B.",
    "pdf_url": "http://arxiv.org/pdf/2502.20795v1",
    "published": "2025-02-28",
    "source": "arxiv",
    "id": "2502.20795v1",
    "categories": [
      "cs.CL"
    ]
  },
  {
    "title": "Modulation of supernarrow EIT pair via atomic coherence",
    "authors": [
      "Lin Cheng",
      "Zhiyuan Xiong",
      "Shuaishuai Hou",
      "Yijia Sun",
      "Chenyu Dong",
      "Fan Wu",
      "Kun Huang"
    ],
    "abstract": "We report the phenomena of electromagnetically induced transparency (EIT) and\nelectromagnetically induced absorption (EIA) using two identical beams in\nrubidium atomic vapor. The {\\Lambda}-type EIT configuration is employed to\nexamine the EIT spectrum for the D1 line in 87Rb F=2 characteristics16 by\nvarying parameters such as frequency detuning, Iprobe/Ipump, the total power of\nprobe and pump beam. Notably, the pump beam is also investigated in this\nprocess, which has not been previously studied. We study the effect of of the\nphase between the two applied fields and find that EIA and EIT can transform\ninto each other by adjusting the relative phase. These finding may have\napplications in light drag or storage, optical switching, and sensing.",
    "pdf_url": "http://arxiv.org/pdf/2502.20787v1",
    "published": "2025-02-28",
    "source": "arxiv",
    "id": "2502.20787v1",
    "categories": [
      "physics.atom-ph",
      "physics.optics"
    ]
  },
  {
    "title": "On the nonlinearity of Four-Dimensional Conformal Transformations in spinor representation",
    "authors": [
      "Zhi-Peng Wang",
      "X. X. Yi",
      "Hai-Jun Wang"
    ],
    "abstract": "The nonlinearity of the conformal group is an essential factor that ruins the\nglobal conformal invariance for interacting material fields. In this paper we\nattempt to track such nonlinearity from spacetime transformations to spinor\nrepresentations. To this end we rederive the spinor representation by\ngeneralizing the linear fractional transformation from two dimensions to four\ndimensions via replacing complex numbers with biquaternions. To check the\neffect of the nonlinearity we apply the translations and special conformal\ntransformations (SCTs) to Dirac spinors in certain interactions. These two\ntransformations do not lead to nonlinear terms in Yukawa term, but do in\nvector-spinor interaction. And the nonlinear terms would definitely cause $CP$\nviolation.",
    "pdf_url": "http://arxiv.org/pdf/2502.20776v1",
    "published": "2025-02-28",
    "source": "arxiv",
    "id": "2502.20776v1",
    "categories": [
      "hep-th",
      "math-ph",
      "math.MP"
    ]
  },
  {
    "title": "Information Bottleneck-Guided Heterogeneous Graph Learning for Interpretable Neurodevelopmental Disorder Diagnosis",
    "authors": [
      "Yueyang Li",
      "Lei Chen",
      "Wenhao Dong",
      "Shengyu Gong",
      "Zijian Kang",
      "Boyang Wei",
      "Weiming Zeng",
      "Hongjie Yan",
      "Lingbin Bian",
      "Wai Ting Siok",
      "Nizhuan Wang"
    ],
    "abstract": "Developing interpretable models for diagnosing neurodevelopmental disorders\n(NDDs) is highly valuable yet challenging, primarily due to the complexity of\nencoding, decoding and integrating imaging and non-imaging data. Many existing\nmachine learning models struggle to provide comprehensive interpretability,\noften failing to extract meaningful biomarkers from imaging data, such as\nfunctional magnetic resonance imaging (fMRI), or lacking mechanisms to explain\nthe significance of non-imaging data. In this paper, we propose the\nInterpretable Information Bottleneck Heterogeneous Graph Neural Network\n(I2B-HGNN), a novel framework designed to learn from fine-grained local\npatterns to comprehensive global multi-modal interactions. This framework\ncomprises two key modules. The first module, the Information Bottleneck Graph\nTransformer (IBGraphFormer) for local patterns, integrates global modeling with\nbrain connectomic-constrained graph neural networks to identify biomarkers\nthrough information bottleneck-guided pooling. The second module, the\nInformation Bottleneck Heterogeneous Graph Attention Network (IB-HGAN) for\nglobal multi-modal interactions, facilitates interpretable multi-modal fusion\nof imaging and non-imaging data using heterogeneous graph neural networks. The\nresults of the experiments demonstrate that I2B-HGNN excels in diagnosing NDDs\nwith high accuracy, providing interpretable biomarker identification and\neffective analysis of non-imaging data.",
    "pdf_url": "http://arxiv.org/pdf/2502.20769v1",
    "published": "2025-02-28",
    "source": "arxiv",
    "id": "2502.20769v1",
    "categories": [
      "cs.CV"
    ]
  },
  {
    "title": "Enhanced Performance and Stability of Perovskite Solar Cells with Ag-Cu-Zn Alloy Electrodes",
    "authors": [
      "Keshav Kumar Sharma",
      "Ashutosh Ujjwal",
      "Rohit Saini",
      "Ramesh Karuppannan"
    ],
    "abstract": "Though the common metal electrode-based perovskite solar cells have achieved\na power conversion efficiency of >25%, they also play a crucial role in\naccelerating the degradation of the cells. In this study, we investigated phase\ntransition engineering in Ag electrodes via Cu and Zn alloying, transforming\nfrom a cubic to a tetragonal phase. These alloyed electrodes are then thermally\ndeposited as back electrodes in perovskite solar cells. We conducted a\ncomprehensive analysis of the pure Ag and Ag-Cu-Zn alloys deposited atop a\nhole-transport layer for use in Cs0.05(FA0.83MA0.17)0.95Pb(I0.83Br0.17)3-based\nsolar cells. Our findings reveal that solar cells developed with pure Ag\nelectrodes demonstrate a power conversion efficiency (PCE) of 18.71%,\ncharacterized by a fill factor (FF) of 74.8%, an open-circuit voltage (VOC) of\n1.08 V, and a short-circuit current density (JSC) of 23.17 mA/cm2. Conversely,\nsolar cells fabricated with optimized Ag0.875Cu0.120Zn0.005 electrodes exhibit\nenhanced performance metrics, with an FF of 72.5%, VOC of 1.12 V, and JSC of\n23.39 mA/cm2, culminating in an elevated PCE of 19.02%. Moreover, this\nelectrode demonstrates remarkable durability, sustaining operational integrity\nfor 460 hours for the PSCs stored in the N2 glove box, in contrast to the 320\nhours for cells with Ag electrodes. The Ag-Cu-Zn alloys exhibited high\nresistance to corrosion and good adhesion on the hole-transport material layer\ncompared to a layer of Ag. These advancements may lead to the realization of\ncost-effective, durable, and efficient solar energy conversion systems.",
    "pdf_url": "http://arxiv.org/pdf/2502.20765v1",
    "published": "2025-02-28",
    "source": "arxiv",
    "id": "2502.20765v1",
    "categories": [
      "cond-mat.mtrl-sci",
      "physics.app-ph",
      "14J60 (Primary) 14F05, 14J26 (Secondary)",
      "F.2.2; I.2.7"
    ]
  },
  {
    "title": "Visual Attention Exploration in Vision-Based Mamba Models",
    "authors": [
      "Junpeng Wang",
      "Chin-Chia Michael Yeh",
      "Uday Singh Saini",
      "Mahashweta Das"
    ],
    "abstract": "State space models (SSMs) have emerged as an efficient alternative to\ntransformer-based models, offering linear complexity that scales better than\ntransformers. One of the latest advances in SSMs, Mamba, introduces a selective\nscan mechanism that assigns trainable weights to input tokens, effectively\nmimicking the attention mechanism. Mamba has also been successfully extended to\nthe vision domain by decomposing 2D images into smaller patches and arranging\nthem as 1D sequences. However, it remains unclear how these patches interact\nwith (or attend to) each other in relation to their original 2D spatial\nlocation. Additionally, the order used to arrange the patches into a sequence\nalso significantly impacts their attention distribution. To better understand\nthe attention between patches and explore the attention patterns, we introduce\na visual analytics tool specifically designed for vision-based Mamba models.\nThis tool enables a deeper understanding of how attention is distributed across\npatches in different Mamba blocks and how it evolves throughout a Mamba model.\nUsing the tool, we also investigate the impact of different patch-ordering\nstrategies on the learned attention, offering further insights into the model's\nbehavior.",
    "pdf_url": "http://arxiv.org/pdf/2502.20764v1",
    "published": "2025-02-28",
    "source": "arxiv",
    "id": "2502.20764v1",
    "categories": [
      "cs.LG"
    ]
  },
  {
    "title": "Classification of Modular Symmetries in Type IIB Flux Landscape",
    "authors": [
      "Keiya Ishiguro",
      "Takafumi Kai",
      "Tatsuo Kobayashi",
      "Yuichi Koga",
      "Hajime Otsuka"
    ],
    "abstract": "In this work, we study modular symmetries in type IIB flux landscape by\ninvestigating symplectic basis transformations of period vectors on toroidal\norbifolds. To fix explicit cycles of a third-cohomology basis regarding the\nuntwisted complex structure modulus, which is necessary to construct the period\nvectors, we find that the following two symmetries are required for the period\nvectors: (i) ``Scaling duality '' which is a generalized $S$-transformation of\n$PSL(2, \\mathbb{Z})$ and (ii) the modular symmetries to be consistent with\nsymmetries derived from mass spectra of the closed string in type IIB string\ntheory. Furthermore, by considering flux quanta on the cycles, we explore type\nIIB flux vacua on toroidal orientifolds and flux transformations under the\nmodular symmetries of the period vectors.",
    "pdf_url": "http://arxiv.org/pdf/2502.20743v1",
    "published": "2025-02-28",
    "source": "arxiv",
    "id": "2502.20743v1",
    "categories": [
      "hep-th"
    ]
  },
  {
    "title": "Integral formulas and Teodorescu transform for generalized partial-slice monogenic functions",
    "authors": [
      "Manjie Hu",
      "Chao Ding",
      "Yifei Shen",
      "Jiani Wang"
    ],
    "abstract": "The theory of generalized partial-slice monogenic functions is considered as\na syhthesis of the classical Clifford analysis and the theory of slice\nmonogenic functions. In this paper, we investigate the Cauchy integral formula\nand the Plemelj formula for generalized partial-slice monogenic functions.\nFurther, we study some properties of the Teodorescu transform in this context.\nA norm estimation for the Teodorescu transform is discussed as well.",
    "pdf_url": "http://arxiv.org/pdf/2502.20737v1",
    "published": "2025-02-28",
    "source": "arxiv",
    "id": "2502.20737v1",
    "categories": [
      "math.CV",
      "30G35, 32A30, 44A05"
    ]
  },
  {
    "title": "Variational Transformer Ansatz for the Density Operator of Steady States in Dissipative Quantum Many-Body Systems",
    "authors": [
      "Lu Wei",
      "Zhian Jia",
      "Yufeng Wang",
      "Dagomir Kaszlikowski",
      "Haibin Ling"
    ],
    "abstract": "The transformer architecture, known for capturing long-range dependencies and\nintricate patterns, has extended beyond natural language processing. Recently,\nit has attracted significant attention in quantum information and condensed\nmatter physics. In this work, we propose the transformer density operator\nansatz for determining the steady states of dissipative quantum many-body\nsystems. By vectorizing the density operator as a many-body state in a doubled\nHilbert space, the transformer encodes the amplitude and phase of the state's\ncoefficients, with its parameters serving as variational variables. Our design\npreserves translation invariance while leveraging attention mechanisms to\ncapture diverse long-range correlations. We demonstrate the effectiveness of\nour approach by numerically calculating the steady states of dissipative Ising\nand Heisenberg spin chain models, showing that our method achieves excellent\naccuracy in predicting steady states.",
    "pdf_url": "http://arxiv.org/pdf/2502.20723v1",
    "published": "2025-02-28",
    "source": "arxiv",
    "id": "2502.20723v1",
    "categories": [
      "quant-ph",
      "cond-mat.dis-nn",
      "cond-mat.str-el",
      "physics.comp-ph"
    ]
  },
  {
    "title": "Generating Clinically Realistic EHR Data via a Hierarchy- and Semantics-Guided Transformer",
    "authors": [
      "Guanglin Zhou",
      "Sebastiano Barbieri"
    ],
    "abstract": "Generating realistic synthetic electronic health records (EHRs) holds\ntremendous promise for accelerating healthcare research, facilitating AI model\ndevelopment and enhancing patient privacy. However, existing generative methods\ntypically treat EHRs as flat sequences of discrete medical codes. This approach\noverlooks two critical aspects: the inherent hierarchical organization of\nclinical coding systems and the rich semantic context provided by code\ndescriptions. Consequently, synthetic patient sequences often lack high\nclinical fidelity and have limited utility in downstream clinical tasks. In\nthis paper, we propose the Hierarchy- and Semantics-Guided Transformer (HiSGT),\na novel framework that leverages both hierarchical and semantic information for\nthe generative process. HiSGT constructs a hierarchical graph to encode\nparent-child and sibling relationships among clinical codes and employs a graph\nneural network to derive hierarchy-aware embeddings. These are then fused with\nsemantic embeddings extracted from a pre-trained clinical language model (e.g.,\nClinicalBERT), enabling the Transformer-based generator to more accurately\nmodel the nuanced clinical patterns inherent in real EHRs. Extensive\nexperiments on the MIMIC-III and MIMIC-IV datasets demonstrate that HiSGT\nsignificantly improves the statistical alignment of synthetic data with real\npatient records, as well as supports robust downstream applications such as\nchronic disease classification. By addressing the limitations of conventional\nraw code-based generative models, HiSGT represents a significant step toward\nclinically high-fidelity synthetic data generation and a general paradigm\nsuitable for interpretable medical code representation, offering valuable\napplications in data augmentation and privacy-preserving healthcare analytics.",
    "pdf_url": "http://arxiv.org/pdf/2502.20719v1",
    "published": "2025-02-28",
    "source": "arxiv",
    "id": "2502.20719v1",
    "categories": [
      "cs.LG",
      "cs.AI"
    ]
  },
  {
    "title": "A Quantum-Empowered SPEI Drought Forecasting Algorithm Using Spatially-Aware Mamba Network",
    "authors": [
      "Po-Wei Tang",
      "Chia-Hsiang Lin",
      "Jian-Kai Huang",
      "Alfredo R. Huete"
    ],
    "abstract": "Due to the intensifying impacts of extreme climate changes, drought\nforecasting (DF), which aims to predict droughts from historical meteorological\ndata, has become increasingly critical for monitoring and managing water\nresources. Though drought conditions often exhibit spatial climatic coherence\namong neighboring regions, benchmark deep learning-based DF methods overlook\nthis fact and predict the conditions on a region-by-region basis. Using the\nStandardized Precipitation Evapotranspiration Index (SPEI), we designed and\ntrained a novel and transformative spatially-aware DF neural network, which\neffectively captures local interactions among neighboring regions, resulting in\nenhanced spatial coherence and prediction accuracy. As DF also requires\nsophisticated temporal analysis, the Mamba network, recognized as the most\naccurate and efficient existing time-sequence modeling, was adopted to extract\ntemporal features from short-term time frames. We also adopted quantum neural\nnetworks (QNN) to entangle the spatial features of different time instances,\nleading to refined spatiotemporal features of seven different meteorological\nvariables for effectively identifying short-term climate fluctuations. In the\nlast stage of our proposed SPEI-driven quantum spatially-aware Mamba network\n(SQUARE-Mamba), the extracted spatiotemporal features of seven different\nmeteorological variables were fused to achieve more accurate DF. Validation\nexperiments across El Ni\\~no, La Ni\\~na, and normal years demonstrated the\nsuperiority of the proposed SQUARE-Mamba, remarkably achieving an average\nimprovement of more than 9.8% in the coefficient of determination index (R^2)\ncompared to baseline methods, thereby illustrating the promising roles of the\ntemporal quantum entanglement and Mamba temporal analysis to achieve more\naccurate DF.",
    "pdf_url": "http://arxiv.org/pdf/2502.20703v1",
    "published": "2025-02-28",
    "source": "arxiv",
    "id": "2502.20703v1",
    "categories": [
      "eess.SP"
    ]
  },
  {
    "title": "Solving the Riccati Equation",
    "authors": [
      "Everardo Rivera-Oliva"
    ],
    "abstract": "In this study, the Riccati equation is resolved using the generalized\nrecursive integrating factor method. By applying a non-linear transformation to\nthe dependent variable $y(x)$ of the Riccati equation, a second-order linear\ndifferential equation is derived for a variable $u(x)$ that is related to\n$y(x)$ through the aforementioned transformation. The second-order differential\nequation is then addressed using the aforementioned integrating factors method\nto derive the general solution for $u(x)$, which is subsequently transformed\nback to obtain the general solution for $y(x)$, thereby resolving the Riccati\nequation. The general solution to the Riccati equation is presented, followed\nby solving a few illustrative application examples.",
    "pdf_url": "http://arxiv.org/pdf/2502.20688v1",
    "published": "2025-02-28",
    "source": "arxiv",
    "id": "2502.20688v1",
    "categories": [
      "math-ph",
      "math.MP"
    ]
  },
  {
    "title": "EDM: Equirectangular Projection-Oriented Dense Kernelized Feature Matching",
    "authors": [
      "Dongki Jung",
      "Jaehoon Choi",
      "Yonghan Lee",
      "Somi Jeong",
      "Taejae Lee",
      "Dinesh Manocha",
      "Suyong Yeon"
    ],
    "abstract": "We introduce the first learning-based dense matching algorithm, termed\nEquirectangular Projection-Oriented Dense Kernelized Feature Matching (EDM),\nspecifically designed for omnidirectional images. Equirectangular projection\n(ERP) images, with their large fields of view, are particularly suited for\ndense matching techniques that aim to establish comprehensive correspondences\nacross images. However, ERP images are subject to significant distortions,\nwhich we address by leveraging the spherical camera model and geodesic flow\nrefinement in the dense matching method. To further mitigate these distortions,\nwe propose spherical positional embeddings based on 3D Cartesian coordinates of\nthe feature grid. Additionally, our method incorporates bidirectional\ntransformations between spherical and Cartesian coordinate systems during\nrefinement, utilizing a unit sphere to improve matching performance. We\ndemonstrate that our proposed method achieves notable performance enhancements,\nwith improvements of +26.72 and +42.62 in AUC@5{\\deg} on the Matterport3D and\nStanford2D3D datasets.",
    "pdf_url": "http://arxiv.org/pdf/2502.20685v1",
    "published": "2025-02-28",
    "source": "arxiv",
    "id": "2502.20685v1",
    "categories": [
      "cs.CV"
    ]
  },
  {
    "title": "Disentangling Feature Structure: A Mathematically Provable Two-Stage Training Dynamics in Transformers",
    "authors": [
      "Zixuan Gong",
      "Jiaye Teng",
      "Yong Liu"
    ],
    "abstract": "Transformers may exhibit two-stage training dynamics during the real-world\ntraining process. For instance, when training GPT-2 on the Counterfact dataset,\nthe answers progress from syntactically incorrect to syntactically correct to\nsemantically correct. However, existing theoretical analyses hardly account for\nthis two-stage phenomenon. In this paper, we theoretically demonstrate how such\ntwo-stage training dynamics occur in transformers. Specifically, we analyze the\ndynamics of transformers using feature learning techniques under in-context\nlearning regimes, based on a disentangled two-type feature structure. Such\ndisentanglement of feature structure is general in practice, e.g., natural\nlanguages contain syntax and semantics, and proteins contain primary and\nsecondary structures. To our best known, this is the first rigorous result\nregarding a two-stage optimization process in transformers. Additionally, a\ncorollary indicates that such a two-stage process is closely related to the\nspectral properties of the attention weights, which accords well with empirical\nfindings.",
    "pdf_url": "http://arxiv.org/pdf/2502.20681v1",
    "published": "2025-02-28",
    "source": "arxiv",
    "id": "2502.20681v1",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ]
  },
  {
    "title": "Dimension Agnostic Neural Processes",
    "authors": [
      "Hyungi Lee",
      "Chaeyun Jang",
      "Dongbok Lee",
      "Juho Lee"
    ],
    "abstract": "Meta-learning aims to train models that can generalize to new tasks with\nlimited labeled data by extracting shared features across diverse task\ndatasets. Additionally, it accounts for prediction uncertainty during both\ntraining and evaluation, a concept known as uncertainty-aware meta-learning.\nNeural Process(NP) is a well-known uncertainty-aware meta-learning method that\nconstructs implicit stochastic processes using parametric neural networks,\nenabling rapid adaptation to new tasks. However, existing NP methods face\nchallenges in accommodating diverse input dimensions and learned features,\nlimiting their broad applicability across regression tasks. To address these\nlimitations and advance the utility of NP models as general regressors, we\nintroduce Dimension Agnostic Neural Processes(DANP). DANP incorporates\nDimension Aggregator Block(DAB) to transform input features into a\nfixed-dimensional space, enhancing the model's ability to handle diverse\ndatasets. Furthermore, leveraging the Transformer architecture and latent\nencoding layers, DANP learns a wider range of features that are generalizable\nacross various tasks. Through comprehensive experimentation on various\nsynthetic and practical regression tasks, we empirically show that DANP\noutperforms previous NP variations, showcasing its effectiveness in overcoming\nthe limitations of traditional NP models and its potential for broader\napplicability in diverse regression scenarios.",
    "pdf_url": "http://arxiv.org/pdf/2502.20661v1",
    "published": "2025-02-28",
    "source": "arxiv",
    "id": "2502.20661v1",
    "categories": [
      "cs.LG"
    ]
  },
  {
    "title": "Wavelet-based density sketching with functional hierarchical tensor",
    "authors": [
      "Xun Tang",
      "Lexing Ying"
    ],
    "abstract": "We introduce the functional hierarchical tensor under a wavelet basis (FHT-W)\nansatz for high-dimensional density estimation in lattice models. Recently, the\nfunctional tensor network has emerged as a suitable candidate for density\nestimation due to its ability to calculate the normalization constant exactly,\na defining feature not enjoyed by neural network alternatives such as\nenergy-based models or diffusion models. While current functional tensor\nnetwork models show good performance for lattice models with weak or moderate\ncouplings, we show that they face significant model capacity constraints when\napplied to lattice models with strong coupling. To address this issue, this\nwork proposes to perform density estimation on the lattice model under a\nwavelet transformation. Motivated by the literature on scale separation, we\nperform iterative wavelet coarsening to separate the lattice model into\ndifferent scales. Based on this multiscale structure, we design a new\nfunctional hierarchical tensor ansatz using a hierarchical tree topology,\nwhereby information on the finer scale is further away from the root node of\nthe tree. Our experiments show that the numerical rank of typical lattice\nmodels is significantly lower under appropriate wavelet transformation.\nFurthermore, we show that our proposed model allows one to model challenging\nGaussian field models and Ginzburg-Landau models.",
    "pdf_url": "http://arxiv.org/pdf/2502.20655v1",
    "published": "2025-02-28",
    "source": "arxiv",
    "id": "2502.20655v1",
    "categories": [
      "math.NA",
      "cs.NA"
    ]
  },
  {
    "title": "Consistency Evaluation of News Article Summaries Generated by Large (and Small) Language Models",
    "authors": [
      "Colleen Gilhuly",
      "Haleh Shahzad"
    ],
    "abstract": "Text summarizing is a critical Natural Language Processing (NLP) task with\napplications ranging from information retrieval to content generation. Large\nLanguage Models (LLMs) have shown remarkable promise in generating fluent\nabstractive summaries but they can produce hallucinated details not grounded in\nthe source text. Regardless of the method of generating a summary, high quality\nautomated evaluations remain an open area of investigation. This paper embarks\non an exploration of text summarization with a diverse set of techniques,\nincluding TextRank, BART, Mistral-7B-Instruct, and OpenAI GPT-3.5-Turbo. The\ngenerated summaries are evaluated using traditional metrics such as the\nRecall-Oriented Understudy for Gisting Evaluation (ROUGE) Score and\nBidirectional Encoder Representations from Transformers (BERT) Score, as well\nas LLM-powered evaluation methods that directly assess a generated summary's\nconsistency with the source text. We introduce a meta evaluation score which\ndirectly assesses the performance of the LLM evaluation system (prompt +\nmodel). We find that that all summarization models produce consistent summaries\nwhen tested on the XL-Sum dataset, exceeding the consistency of the reference\nsummaries.",
    "pdf_url": "http://arxiv.org/pdf/2502.20647v1",
    "published": "2025-02-28",
    "source": "arxiv",
    "id": "2502.20647v1",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG",
      "I.2.7"
    ]
  },
  {
    "title": "Can LLM Assist in the Evaluation of the Quality of Machine Learning Explanations?",
    "authors": [
      "Bo Wang",
      "Yiqiao Li",
      "Jianlong Zhou",
      "Fang Chen"
    ],
    "abstract": "EXplainable machine learning (XML) has recently emerged to address the\nmystery mechanisms of machine learning (ML) systems by interpreting their\n'black box' results. Despite the development of various explanation methods,\ndetermining the most suitable XML method for specific ML contexts remains\nunclear, highlighting the need for effective evaluation of explanations. The\nevaluating capabilities of the Transformer-based large language model (LLM)\npresent an opportunity to adopt LLM-as-a-Judge for assessing explanations. In\nthis paper, we propose a workflow that integrates both LLM-based and human\njudges for evaluating explanations. We examine how LLM-based judges evaluate\nthe quality of various explanation methods and compare their evaluation\ncapabilities to those of human judges within an iris classification scenario,\nemploying both subjective and objective metrics. We conclude that while\nLLM-based judges effectively assess the quality of explanations using\nsubjective metrics, they are not yet sufficiently developed to replace human\njudges in this role.",
    "pdf_url": "http://arxiv.org/pdf/2502.20635v1",
    "published": "2025-02-28",
    "source": "arxiv",
    "id": "2502.20635v1",
    "categories": [
      "cs.HC",
      "cs.LG"
    ]
  },
  {
    "title": "Are LLMs Ready for Practical Adoption for Assertion Generation?",
    "authors": [
      "Vaishnavi Pulavarthi",
      "Deeksha Nandal",
      "Soham Dan",
      "Debjit Pal"
    ],
    "abstract": "Assertions have been the de facto collateral for simulation-based and formal\nverification of hardware designs for over a decade. The quality of hardware\nverification, i.e., detection and diagnosis of corner-case design bugs, is\ncritically dependent on the quality of the assertions. With the onset of\ngenerative AI such as Transformers and Large-Language Models (LLMs), there has\nbeen a renewed interest in developing novel, effective, and scalable techniques\nof generating functional and security assertions from design source code. While\nthere have been recent works that use commercial-of-the-shelf (COTS) LLMs for\nassertion generation, there is no comprehensive study in quantifying the\neffectiveness of LLMs in generating syntactically and semantically correct\nassertions. In this paper, we first discuss AssertionBench from our prior work,\na comprehensive set of designs and assertions to quantify the goodness of a\nbroad spectrum of COTS LLMs for the task of assertion generations from hardware\ndesign source code. Our key insight was that COTS LLMs are not yet ready for\nprime-time adoption for assertion generation as they generate a considerable\nfraction of syntactically and semantically incorrect assertions. Motivated by\nthe insight, we propose AssertionLLM, a first of its kind LLM model,\nspecifically fine-tuned for assertion generation. Our initial experimental\nresults show that AssertionLLM considerably improves the semantic and syntactic\ncorrectness of the generated assertions over COTS LLMs.",
    "pdf_url": "http://arxiv.org/pdf/2502.20633v1",
    "published": "2025-02-28",
    "source": "arxiv",
    "id": "2502.20633v1",
    "categories": [
      "cs.LG"
    ]
  },
  {
    "title": "Real and bi-Lipschitz versions of the Theorem of Nobile",
    "authors": [
      "José Edson Sampaio"
    ],
    "abstract": "The famous Theorem of Nobile says that a pure dimensional complex analytic\nset $X$ is analytically smooth if, and only if, its Nash transformation\n$\\eta\\colon \\mathcal{N}(X)\\to X$ is an analytic isomorphism. This result was\nproven in 1975 and since then, as far as the author knows, no answer has been\ngiven to the real case, even more so when one only asks for $C^{k}$ smoothness.\nIn this paper, we prove the real version of the Theorem of Nobile asking only\n$C^{k}$ smoothness, i.e., we prove that for a pure dimensional real analytic\nset $X$ the following statements are equivalent:\n  (1) $X$ is a real analytic (resp. $C^{k+1,1}$) submanifold;\n  (2) the mapping $\\eta\\colon\\mathcal{N}(X)\\to X$ is a real analytic (resp.\n$C^{k,1}$) diffeomorphism;\n  (3) the mapping $\\eta\\colon\\mathcal{N}(X)\\to X$ is a $C^{\\infty}$ (resp.\n$C^{k,1}$) diffeomorphism;\n  (4) $X$ is a $C^{\\infty}$ (resp. $C^{k+1,1}$) submanifold.\n  In this paper, we also prove the bi-Lipschitz version of the Theorem of\nNobile. More precisely, we prove that $X$ is analytically smooth if and only if\nits Nash transformation $\\eta\\colon \\mathcal{N}(X)\\to X$ is a homeomorphism\nthat locally bi-Lipschitz.",
    "pdf_url": "http://arxiv.org/pdf/2502.20631v1",
    "published": "2025-02-28",
    "source": "arxiv",
    "id": "2502.20631v1",
    "categories": [
      "math.AG",
      "math.CV",
      "14B05, 32S50"
    ]
  },
  {
    "title": "Towards Privacy-Preserving Split Learning: Destabilizing Adversarial Inference and Reconstruction Attacks in the Cloud",
    "authors": [
      "Griffin Higgins",
      "Roozbeh Razavi-Far",
      "Xichen Zhang",
      "Amir David",
      "Ali Ghorbani",
      "Tongyu Ge"
    ],
    "abstract": "This work aims to provide both privacy and utility within a split learning\nframework while considering both forward attribute inference and backward\nreconstruction attacks. To address this, a novel approach has been proposed,\nwhich makes use of class activation maps and autoencoders as a plug-in strategy\naiming to increase the user's privacy and destabilize an adversary. The\nproposed approach is compared with a dimensionality-reduction-based plug-in\nstrategy, which makes use of principal component analysis to transform the\nfeature map onto a lower-dimensional feature space. Our work shows that our\nproposed autoencoder-based approach is preferred as it can provide protection\nat an earlier split position over the tested architectures in our setting, and,\nhence, better utility for resource-constrained devices in edge-cloud\ncollaborative inference (EC) systems.",
    "pdf_url": "http://arxiv.org/pdf/2502.20629v1",
    "published": "2025-02-28",
    "source": "arxiv",
    "id": "2502.20629v1",
    "categories": [
      "cs.CR"
    ]
  },
  {
    "title": "RTGen: Real-Time Generative Detection Transformer",
    "authors": [
      "Chi Ruan"
    ],
    "abstract": "While open-vocabulary object detectors require predefined categories during\ninference, generative object detectors overcome this limitation by endowing the\nmodel with text generation capabilities. However, existing generative object\ndetection methods directly append an autoregressive language model to an object\ndetector to generate texts for each detected object. This straightforward\ndesign leads to structural redundancy and increased processing time. In this\npaper, we propose a Real-Time GENerative Detection Transformer (RTGen), a\nreal-time generative object detector with a succinct encoder-decoder\narchitecture. Specifically, we introduce a novel Region-Language Decoder\n(RL-Decoder), which innovatively integrates a non-autoregressive language model\ninto the detection decoder, enabling concurrent processing of object and text\ninformation. With these efficient designs, RTGen achieves a remarkable\ninference speed of 60.41 FPS. Moreover, RTGen obtains 18.6 mAP on the LVIS\ndataset, outperforming the previous SOTA method by 3.5 mAP.",
    "pdf_url": "http://arxiv.org/pdf/2502.20622v1",
    "published": "2025-02-28",
    "source": "arxiv",
    "id": "2502.20622v1",
    "categories": [
      "cs.CV"
    ]
  },
  {
    "title": "Continuous Adversarial Text Representation Learning for Affective Recognition",
    "authors": [
      "Seungah Son",
      "Andrez Saurez",
      "Dongsoo Har"
    ],
    "abstract": "While pre-trained language models excel at semantic understanding, they often\nstruggle to capture nuanced affective information critical for affective\nrecognition tasks. To address these limitations, we propose a novel framework\nfor enhancing emotion-aware embeddings in transformer-based models. Our\napproach introduces a continuous valence-arousal labeling system to guide\ncontrastive learning, which captures subtle and multi-dimensional emotional\nnuances more effectively. Furthermore, we employ a dynamic token perturbation\nmechanism, using gradient-based saliency to focus on sentiment-relevant tokens,\nimproving model sensitivity to emotional cues. The experimental results\ndemonstrate that the proposed framework outperforms existing methods, achieving\nup to 15.5% improvement in the emotion classification benchmark, highlighting\nthe importance of employing continuous labels. This improvement demonstrates\nthat the proposed framework is effective in affective representation learning\nand enables precise and contextually relevant emotional understanding.",
    "pdf_url": "http://arxiv.org/pdf/2502.20613v1",
    "published": "2025-02-28",
    "source": "arxiv",
    "id": "2502.20613v1",
    "categories": [
      "cs.CL",
      "cs.AI"
    ]
  },
  {
    "title": "Exploring the Impact of Temperature Scaling in Softmax for Classification and Adversarial Robustness",
    "authors": [
      "Hao Xuan",
      "Bokai Yang",
      "Xingyu Li"
    ],
    "abstract": "The softmax function is a fundamental component in deep learning. This study\ndelves into the often-overlooked parameter within the softmax function, known\nas \"temperature,\" providing novel insights into the practical and theoretical\naspects of temperature scaling for image classification. Our empirical studies,\nadopting convolutional neural networks and transformers on multiple benchmark\ndatasets, reveal that moderate temperatures generally introduce better overall\nperformance. Through extensive experiments and rigorous theoretical analysis,\nwe explore the role of temperature scaling in model training and unveil that\ntemperature not only influences learning step size but also shapes the model's\noptimization direction. Moreover, for the first time, we discover a surprising\nbenefit of elevated temperatures: enhanced model robustness against common\ncorruption, natural perturbation, and non-targeted adversarial attacks like\nProjected Gradient Descent. We extend our discoveries to adversarial training,\ndemonstrating that, compared to the standard softmax function with the default\ntemperature value, higher temperatures have the potential to enhance\nadversarial training. The insights of this work open new avenues for improving\nmodel performance and security in deep learning applications.",
    "pdf_url": "http://arxiv.org/pdf/2502.20604v1",
    "published": "2025-02-28",
    "source": "arxiv",
    "id": "2502.20604v1",
    "categories": [
      "cs.LG",
      "cs.AI"
    ]
  },
  {
    "title": "A finite sufficient set of conditions for catalytic majorization",
    "authors": [
      "David Elkouss",
      "Ananda G. Maity",
      "Aditya Nema",
      "Sergii Strelchuk"
    ],
    "abstract": "The majorization relation has found numerous applications in mathematics,\nquantum information and resource theory, and quantum thermodynamics, where it\ndescribes the allowable transitions between two physical states. In many cases,\nwhen state vector $x$ does not majorize state vector $y$, it is nevertheless\npossible to find a catalyst - another vector $z$ such that $x \\otimes z$\nmajorizes $y \\otimes z$. Determining the feasibility of such catalytic\ntransformation typically involves checking an infinite set of inequalities.\nHere, we derive a finite sufficient set of inequalities that imply catalysis.\nExtending this framework to thermodynamics, we also establish a finite set of\nsufficient conditions for catalytic state transformations under thermal\noperations. For novel examples, we provide a software toolbox implementing\nthese conditions.",
    "pdf_url": "http://arxiv.org/pdf/2502.20588v1",
    "published": "2025-02-27",
    "source": "arxiv",
    "id": "2502.20588v1",
    "categories": [
      "quant-ph",
      "cs.IT",
      "math.IT"
    ]
  },
  {
    "title": "LiteASR: Efficient Automatic Speech Recognition with Low-Rank Approximation",
    "authors": [
      "Keisuke Kamahori",
      "Jungo Kasai",
      "Noriyuki Kojima",
      "Baris Kasikci"
    ],
    "abstract": "Modern automatic speech recognition (ASR) models, such as OpenAI's Whisper,\nrely on deep encoder-decoder architectures, and their encoders are a critical\nbottleneck for efficient deployment due to high computational intensity. We\nintroduce LiteASR, a low-rank compression scheme for ASR encoders that\nsignificantly reduces inference costs while maintaining transcription accuracy.\nOur approach leverages the strong low-rank properties observed in intermediate\nactivations: by applying principal component analysis (PCA) with a small\ncalibration dataset, we approximate linear transformations with a chain of\nlow-rank matrix multiplications, and further optimize self-attention to work in\nthe reduced dimension. Evaluation results show that our method can compress\nWhisper large-v3's encoder size by over 50%, matching Whisper medium's size\nwith better transcription accuracy, thereby establishing a new Pareto-optimal\nfrontier of efficiency and performance. The code of LiteASR is available at\nhttps://github.com/efeslab/LiteASR.",
    "pdf_url": "http://arxiv.org/pdf/2502.20583v1",
    "published": "2025-02-27",
    "source": "arxiv",
    "id": "2502.20583v1",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.SD",
      "eess.AS"
    ]
  },
  {
    "title": "Training Large Neural Networks With Low-Dimensional Error Feedback",
    "authors": [
      "Maher Hanut",
      "Jonathan Kadmon"
    ],
    "abstract": "Training deep neural networks typically relies on backpropagating high\ndimensional error signals a computationally intensive process with little\nevidence supporting its implementation in the brain. However, since most tasks\ninvolve low-dimensional outputs, we propose that low-dimensional error signals\nmay suffice for effective learning. To test this hypothesis, we introduce a\nnovel local learning rule based on Feedback Alignment that leverages indirect,\nlow-dimensional error feedback to train large networks. Our method decouples\nthe backward pass from the forward pass, enabling precise control over error\nsignal dimensionality while maintaining high-dimensional representations. We\nbegin with a detailed theoretical derivation for linear networks, which forms\nthe foundation of our learning framework, and extend our approach to nonlinear,\nconvolutional, and transformer architectures. Remarkably, we demonstrate that\neven minimal error dimensionality on the order of the task dimensionality can\nachieve performance matching that of traditional backpropagation. Furthermore,\nour rule enables efficient training of convolutional networks, which have\npreviously been resistant to Feedback Alignment methods, with minimal error.\nThis breakthrough not only paves the way toward more biologically accurate\nmodels of learning but also challenges the conventional reliance on\nhigh-dimensional gradient signals in neural network training. Our findings\nsuggest that low-dimensional error signals can be as effective as\nhigh-dimensional ones, prompting a reevaluation of gradient-based learning in\nhigh-dimensional systems. Ultimately, our work offers a fresh perspective on\nneural network optimization and contributes to understanding learning\nmechanisms in both artificial and biological systems.",
    "pdf_url": "http://arxiv.org/pdf/2502.20580v1",
    "published": "2025-02-27",
    "source": "arxiv",
    "id": "2502.20580v1",
    "categories": [
      "cs.LG",
      "q-bio.NC"
    ]
  },
  {
    "title": "PFformer: A Position-Free Transformer Variant for Extreme-Adaptive Multivariate Time Series Forecasting",
    "authors": [
      "Yanhong Li",
      "David C. Anastasiu"
    ],
    "abstract": "Multivariate time series (MTS) forecasting is vital in fields like weather,\nenergy, and finance. However, despite deep learning advancements, traditional\nTransformer-based models often diminish the effect of crucial inter-variable\nrelationships by singular token embedding and struggle to effectively capture\ncomplex dependencies among variables, especially in datasets with rare or\nextreme events. These events create significant imbalances and lead to high\nskewness, complicating accurate prediction efforts. This study introduces\nPFformer, a position-free Transformer-based model designed for single-target\nMTS forecasting, specifically for challenging datasets characterized by extreme\nvariability. PFformer integrates two novel embedding strategies: Enhanced\nFeature-based Embedding (EFE) and Auto-Encoder-based Embedding (AEE). EFE\neffectively encodes inter-variable dependencies by mapping related sequence\nsubsets to high-dimensional spaces without positional constraints, enhancing\nthe encoder's functionality. PFformer shows superior forecasting accuracy\nwithout the traditional limitations of positional encoding in MTS modeling. We\nevaluated PFformer across four challenging datasets, focusing on two key\nforecasting scenarios: long sequence prediction for 3 days ahead and rolling\npredictions every four hours to reflect real-time decision-making processes in\nwater management. PFformer demonstrated remarkable improvements, from 20% to\n60%, compared with state-of-the-art models.",
    "pdf_url": "http://arxiv.org/pdf/2502.20571v1",
    "published": "2025-02-27",
    "source": "arxiv",
    "id": "2502.20571v1",
    "categories": [
      "cs.LG",
      "cs.AI"
    ]
  },
  {
    "title": "An Integrated Deep Learning Framework Leveraging NASNet and Vision Transformer with MixProcessing for Accurate and Precise Diagnosis of Lung Diseases",
    "authors": [
      "Sajjad Saleem",
      "Muhammad Imran Sharif"
    ],
    "abstract": "The lungs are the essential organs of respiration, and this system is\nsignificant in the carbon dioxide and exchange between oxygen that occurs in\nhuman life. However, several lung diseases, which include pneumonia,\ntuberculosis, COVID-19, and lung cancer, are serious healthiness challenges and\ndemand early and precise diagnostics. The methodological study has proposed a\nnew deep learning framework called NASNet-ViT, which effectively incorporates\nthe convolution capability of NASNet with the global attention mechanism\ncapability of Vision Transformer ViT. The proposed model will classify the lung\nconditions into five classes: Lung cancer, COVID-19, pneumonia, TB, and normal.\nA sophisticated multi-faceted preprocessing strategy called MixProcessing has\nbeen used to improve diagnostic accuracy. This preprocessing combines wavelet\ntransform, adaptive histogram equalization, and morphological filtering\ntechniques. The NASNet-ViT model performs at state of the art, achieving an\naccuracy of 98.9%, sensitivity of 0.99, an F1-score of 0.989, and specificity\nof 0.987, outperforming other state of the art architectures such as MixNet-LD,\nD-ResNet, MobileNet, and ResNet50. The model's efficiency is further emphasized\nby its compact size, 25.6 MB, and a low computational time of 12.4 seconds,\nhence suitable for real-time, clinically constrained environments. These\nresults reflect the high-quality capability of NASNet-ViT in extracting\nmeaningful features and recognizing various types of lung diseases with very\nhigh accuracy. This work contributes to medical image analysis by providing a\nrobust and scalable solution for diagnostics in lung diseases.",
    "pdf_url": "http://arxiv.org/pdf/2502.20570v1",
    "published": "2025-02-27",
    "source": "arxiv",
    "id": "2502.20570v1",
    "categories": [
      "eess.IV",
      "cs.CV",
      "cs.LG"
    ]
  },
  {
    "title": "Orbital inclination of astrometric binaries and the dearth of face-on orbits in Gaia DR3 solutions",
    "authors": [
      "Valeri V. Makarov"
    ],
    "abstract": "The orbital solutions for astrometric (unresolved) binary stars provided in\nthe Gaia mission Data Release 3 reveal an obvious deficit of face-on orbits\nwith line-of-sight inclinations close to 0 or $\\pi$. This is shown to be an\nintrinsic mathematical feature of the orbit estimation technique involving the\nintermediate Thiele-Innes parameters, which are transformed to the Campbell\ngeometric parameters. A direct condition equation defining the inclination\nangle via the Thiele-Innes values independently of the other orbital elements\nis used to investigate the origin of this near-degeneracy for face-on orbits.\nThe emerging bias and correlation of inclination and semimajor axis are\nillustrated using Monte Carlo simulations for two specific template\nconfigurations representing face-on and edge-on orbits. The results have\nsignificant impact on the interpretation and follow-up confirmation of\nGaia-detected binary systems, including candidate exoplanets and brown dwarf\ncompanions.",
    "pdf_url": "http://arxiv.org/pdf/2502.20553v1",
    "published": "2025-02-27",
    "source": "arxiv",
    "id": "2502.20553v1",
    "categories": [
      "astro-ph.SR",
      "astro-ph.EP"
    ]
  },
  {
    "title": "Toward Fully Autonomous Flexible Chunk-Based Aerial Additive Manufacturing: Insights from Experimental Validation",
    "authors": [
      "Marios-Nektarios Stamatopoulos",
      "Jakub Haluska",
      "Elias Small",
      "Jude Marroush",
      "Avijit Banerjee",
      "George Nikolakopoulos"
    ],
    "abstract": "A novel autonomous chunk-based aerial additive manufacturing framework is\npresented, supported with experimental demonstration advancing aerial 3D\nprinting. An optimization-based decomposition algorithm transforms structures\ninto sub-components, or chunks, treated as individual tasks coordinated via a\ndependency graph, ensuring sequential assignment to UAVs considering\ninter-dependencies and printability constraints for seamless execution. A\nspecially designed hexacopter equipped with a pressurized canister for\nlightweight expandable foam extrusion is utilized to deposit the material in a\ncontrolled manner. To further enhance precise execution of the printing, an\noffset-free Model Predictive Control mechanism is considered compensating\nreactively for disturbances and ground effect during execution. Additionally,\nan interlocking mechanism is introduced in the chunking process to enhance\nstructural cohesion and improve layer adhesion. Extensive experiments\ndemonstrate the framework's effectiveness in constructing precise structures of\nvarious shapes while seamlessly adapting to practical challenges, proving its\npotential for a transformative leap in aerial robotic capability for autonomous\nconstruction.",
    "pdf_url": "http://arxiv.org/pdf/2502.20549v1",
    "published": "2025-02-27",
    "source": "arxiv",
    "id": "2502.20549v1",
    "categories": [
      "cs.RO",
      "cs.SY",
      "eess.SY"
    ]
  },
  {
    "title": "Revisiting Kernel Attention with Correlated Gaussian Process Representation",
    "authors": [
      "Long Minh Bui",
      "Tho Tran Huu",
      "Duy Dinh",
      "Tan Minh Nguyen",
      "Trong Nghia Hoang"
    ],
    "abstract": "Transformers have increasingly become the de facto method to model sequential\ndata with state-of-the-art performance. Due to its widespread use, being able\nto estimate and calibrate its modeling uncertainty is important to understand\nand design robust transformer models. To achieve this, previous works have used\nGaussian processes (GPs) to perform uncertainty calibration for the attention\nunits of transformers and attained notable successes. However, such approaches\nhave to confine the transformers to the space of symmetric attention to ensure\nthe necessary symmetric requirement of their GP's kernel specification, which\nreduces the representation capacity of the model. To mitigate this restriction,\nwe propose the Correlated Gaussian Process Transformer (CGPT), a new class of\ntransformers whose self-attention units are modeled as cross-covariance between\ntwo correlated GPs (CGPs). This allows asymmetries in attention and can enhance\nthe representation capacity of GP-based transformers. We also derive a sparse\napproximation for CGP to make it scale better. Our empirical studies show that\nboth CGP-based and sparse CGP-based transformers achieve better performance\nthan state-of-the-art GP-based transformers on a variety of benchmark tasks.\nThe code for our experiments is available at\nhttps://github.com/MinhLong210/CGP-Transformers.",
    "pdf_url": "http://arxiv.org/pdf/2502.20525v1",
    "published": "2025-02-27",
    "source": "arxiv",
    "id": "2502.20525v1",
    "categories": [
      "cs.LG",
      "cs.AI"
    ]
  },
  {
    "title": "Leveraging Pre-Trained Visual Transformers for Multi-Band Photometric Light Curve Classification",
    "authors": [
      "Daniel Moreno-Cartagena",
      "Pavlos Protopapas",
      "Guillermo Cabrera-Vives",
      "Martina Cádiz-Leyton",
      "Ignacio Becker",
      "Cristóbal Donoso-Oliva"
    ],
    "abstract": "This study investigates the potential of a pre-trained visual transformer\n(VT) model, specifically the Swin Transformer V2 (SwinV2), to classify\nphotometric light curves without the need for feature extraction or multi-band\npreprocessing. The goal is to assess whether this image-based approach can\naccurately differentiate astronomical phenomena and serve as a viable option\nfor working with multi-band photometric light curves. We transformed each\nmulti-band light curve into an image. These images serve as input to the SwinV2\nmodel, which is pre-trained on ImageNet-21K. The datasets employed include the\npublic Catalog of Variable Stars from the Massive Compact Halo Object (MACHO)\nsurvey, using both one and two bands, and the first round of the recent\nExtended LSST Astronomical Time-Series Classification Challenge (ELAsTiCC),\nwhich includes six bands. The performance of the model was evaluated on six\nclasses for the MACHO dataset and 20 distinct classes of variable stars and\ntransient events for the ELAsTiCC dataset. The fine-tuned SwinV2 achieved\nbetter performance than models specifically designed for light curves, such as\nAstromer and the Astronomical Transformer for Time Series and Tabular Data\n(ATAT). When trained on the full MACHO dataset, it attained a macro F1-score of\n80.2 and outperformed Astromer in single-band experiments. Incorporating a\nsecond band further improved performance, increasing the F1-score to 84.1. In\nthe ELAsTiCC dataset, SwinV2 achieved a macro F1-score of 65.5, slightly\nsurpassing ATAT by 1.3.",
    "pdf_url": "http://arxiv.org/pdf/2502.20479v1",
    "published": "2025-02-27",
    "source": "arxiv",
    "id": "2502.20479v1",
    "categories": [
      "astro-ph.IM"
    ]
  },
  {
    "title": "Reconstructing orbits of galaxies in extreme regions (ROGER). IV. Unveiling galaxy evolution patterns in OmegaWINGS clusters",
    "authors": [
      "Hernán Muriel",
      "David Pérez-Millán",
      "Martín de los Rios",
      "Andrea Biviano",
      "Valeria Coenda",
      "Héctor J. Martínez",
      "Andrés N. Ruiz",
      "Benedetta Vulcani",
      "Selene Levis"
    ],
    "abstract": "Clusters of galaxies have proven to be efficient systems in modifying various\nproperties of galaxies, such as star formation or morphology. However,\nprojection effects impose serious challenges in determining how, when, and to\nwhat extent galaxies are affected by the cluster environment. Using innovative\ntechniques to classify galaxies based on their history within the cluster, we\naim to determine how galaxies of different classes are affected by the cluster\nenvironment. We applied the ROGER code to select trajectories of galaxies in\nthe phase space for 35 galaxy clusters from the OmegaWINGS survey. A new\nalgorithm was applied to minimize contamination effects. We found that both\nmorphological transformation and the quenching of star formation begin shortly\nafter galaxies enter the cluster. Even though over the last $2-3$ Gyr, galaxies\nentering clusters have undergone significant transformations in both their star\nformation and morphology these transformation processes are not complete, that\nis, they are not completely quenched and are not early type yet. Backsplash\ngalaxies and recent infallers show a higher fraction of jellyfish galaxies\ncompared to older cluster members, suggesting that the timescale of this\nphenomenon is typically less than 3 Gyr.",
    "pdf_url": "http://arxiv.org/pdf/2502.20446v1",
    "published": "2025-02-27",
    "source": "arxiv",
    "id": "2502.20446v1",
    "categories": [
      "astro-ph.GA"
    ]
  },
  {
    "title": "Duality viewpoint of noninvertible symmetry protected topological phases",
    "authors": [
      "Weiguang Cao",
      "Masahito Yamazaki",
      "Linhao Li"
    ],
    "abstract": "Recent advancements in generalized symmetries have drawn significant\nattention to gapped phases of matter exhibiting novel symmetries, such as\nnoninvertible symmetries. By leveraging the duality transformations, the\nclassification and construction of gapped phases with noninvertible symmetry\ncan be mapped to those involving conventional group symmetries. We demonstrate\nthis approach by classifying symmetry-protected topological phases with a broad\nclass of noninvertible symmetries in arbitrary spacetime dimensions. Our\nresults reveal new classifications that extend beyond those based on group\nsymmetries. Additionally, we construct lattice models in $(1+1)d$ and $(2+1)d$\nthat realize these new phases and explore their anomalous interfaces.",
    "pdf_url": "http://arxiv.org/pdf/2502.20435v1",
    "published": "2025-02-27",
    "source": "arxiv",
    "id": "2502.20435v1",
    "categories": [
      "cond-mat.str-el",
      "hep-th"
    ]
  },
  {
    "title": "Bridging Legal Knowledge and AI: Retrieval-Augmented Generation with Vector Stores, Knowledge Graphs, and Hierarchical Non-negative Matrix Factorization",
    "authors": [
      "Ryan C. Barron",
      "Maksim E. Eren",
      "Olga M. Serafimova",
      "Cynthia Matuszek",
      "Boian S. Alexandrov"
    ],
    "abstract": "Agentic Generative AI, powered by Large Language Models (LLMs) with\nRetrieval-Augmented Generation (RAG), Knowledge Graphs (KGs), and Vector Stores\n(VSs), represents a transformative technology applicable to specialized domains\nsuch as legal systems, research, recommender systems, cybersecurity, and global\nsecurity, including proliferation research. This technology excels at inferring\nrelationships within vast unstructured or semi-structured datasets. The legal\ndomain here comprises complex data characterized by extensive, interrelated,\nand semi-structured knowledge systems with complex relations. It comprises\nconstitutions, statutes, regulations, and case law. Extracting insights and\nnavigating the intricate networks of legal documents and their relations is\ncrucial for effective legal research. Here, we introduce a generative AI system\nthat integrates RAG, VS, and KG, constructed via Non-Negative Matrix\nFactorization (NMF), to enhance legal information retrieval and AI reasoning\nand minimize hallucinations. In the legal system, these technologies empower AI\nagents to identify and analyze complex connections among cases, statutes, and\nlegal precedents, uncovering hidden relationships and predicting legal\ntrends-challenging tasks that are essential for ensuring justice and improving\noperational efficiency. Our system employs web scraping techniques to\nsystematically collect legal texts, such as statutes, constitutional\nprovisions, and case law, from publicly accessible platforms like Justia. It\nbridges the gap between traditional keyword-based searches and contextual\nunderstanding by leveraging advanced semantic representations, hierarchical\nrelationships, and latent topic discovery. This framework supports legal\ndocument clustering, summarization, and cross-referencing, for scalable,\ninterpretable, and accurate retrieval for semi-structured data while advancing\ncomputational law and AI.",
    "pdf_url": "http://arxiv.org/pdf/2502.20364v1",
    "published": "2025-02-27",
    "source": "arxiv",
    "id": "2502.20364v1",
    "categories": [
      "cs.CL",
      "cs.AI"
    ]
  },
  {
    "title": "Evaluating the long-term viability of eye-tracking for continuous authentication in virtual reality",
    "authors": [
      "Sai Ganesh Grandhi",
      "Saeed Samet"
    ],
    "abstract": "Traditional authentication methods, such as passwords and biometrics, verify\na user's identity only at the start of a session, leaving systems vulnerable to\nsession hijacking. Continuous authentication, however, ensures ongoing\nverification by monitoring user behavior. This study investigates the long-term\nfeasibility of eye-tracking as a behavioral biometric for continuous\nauthentication in virtual reality (VR) environments, using data from the\nGazebaseVR dataset. Our approach evaluates three architectures, Transformer\nEncoder, DenseNet, and XGBoost, on short and long-term data to determine their\nefficacy in user identification tasks. Initial results indicate that both\nTransformer Encoder and DenseNet models achieve high accuracy rates of up to\n97% in short-term settings, effectively capturing unique gaze patterns.\nHowever, when tested on data collected 26 months later, model accuracy declined\nsignificantly, with rates as low as 1.78% for some tasks. To address this, we\npropose periodic model updates incorporating recent data, restoring accuracy to\nover 95%. These findings highlight the adaptability required for gaze-based\ncontinuous authentication systems and underscore the need for model retraining\nto manage evolving user behavior. Our study provides insights into the efficacy\nand limitations of eye-tracking as a biometric for VR authentication, paving\nthe way for adaptive, secure VR user experiences.",
    "pdf_url": "http://arxiv.org/pdf/2502.20359v1",
    "published": "2025-02-27",
    "source": "arxiv",
    "id": "2502.20359v1",
    "categories": [
      "cs.CR"
    ]
  },
  {
    "title": "KNOWM Memristors in a Bridge Synapse delay-based Reservoir Computing system for detection of epileptic seizures",
    "authors": [
      "Dawid Przyczyna",
      "Grzegorz Hess",
      "Konrad Szaciłowski"
    ],
    "abstract": "Nanodevices that show the potential for non-linear transformation of\nelectrical signals and various forms of memory can be successfully used in new\ncomputational paradigms, such as neuromorphic or reservoir computing (RC).\nDedicated hardware implementations based on functional neuromorphic structures\nsignificantly reduce energy consumption and/or increase computational\ncapabilities of a given artificial neural network system. Concepts of RC, which\nas a flexible computational paradigm can be highly inclusive, are often used as\na model to describe computations performed in materia. With mostly fixed\ninternal structure, solid-state devices, especially memristors, are studied as\ncomputational substrates in various RC systems. In this work, we present\nsingle-node Echo State Machine (SNESM) RC system based on bridge synapse as a\ncomputational substrate (consisting of 4 memristors and a differential\namplifier) used for epileptic seizure detection. KNOWM memristors were posed as\nideal candidates because of their easy prototyping and reliability of\noperation. In this account, we present an application of commercially available\nKNOWM memristors in various neuromorphic applications, from simple analysis of\nswitching and internal dynamics (elucidated form noise spectroscopy and total\nharmonic distortion analysis) to the classification and recognition of complex\ntime series: epilepsy seizure recognition using a wrist-worn triaxial\naccelerometer.",
    "pdf_url": "http://arxiv.org/pdf/2502.20351v1",
    "published": "2025-02-27",
    "source": "arxiv",
    "id": "2502.20351v1",
    "categories": [
      "physics.med-ph",
      "cs.ET"
    ]
  },
  {
    "title": "Modeling Driver Behavior in Speed Advisory Systems: Koopman-based Approach with Online Update",
    "authors": [
      "Mehmet Fatih Ozkan",
      "Jeff Chrstos",
      "Marcello Canova",
      "Stephanie Stockar"
    ],
    "abstract": "Accurate driver behavior modeling is essential for improving the interaction\nand cooperation of the human driver with the driver assistance system. This\npaper presents a novel approach for modeling the response of human drivers to\nvisual cues provided by a speed advisory system using a Koopman-based method\nwith online updates. The proposed method utilizes the Koopman operator to\ntransform the nonlinear dynamics of driver-speed advisory system interactions\ninto a linear framework, allowing for efficient real-time prediction. An online\nupdate mechanism based on Recursive Least Squares (RLS) is integrated into the\nKoopman-based model to ensure continuous adaptation to changes in driver\nbehavior over time. The model is validated using data collected from a\nhuman-in-the-loop driving simulator, capturing diverse driver-specific\ntrajectories. The results demonstrate that the offline learned Koopman-based\nmodel can closely predict driver behavior and its accuracy is further enhanced\nthrough an online update mechanism with the RLS method.",
    "pdf_url": "http://arxiv.org/pdf/2502.20347v1",
    "published": "2025-02-27",
    "source": "arxiv",
    "id": "2502.20347v1",
    "categories": [
      "eess.SY",
      "cs.SY",
      "math.OC"
    ]
  },
  {
    "title": "Thinking Slow, Fast: Scaling Inference Compute with Distilled Reasoners",
    "authors": [
      "Daniele Paliotta",
      "Junxiong Wang",
      "Matteo Pagliardini",
      "Kevin Y. Li",
      "Aviv Bick",
      "J. Zico Kolter",
      "Albert Gu",
      "François Fleuret",
      "Tri Dao"
    ],
    "abstract": "Recent advancements have demonstrated that the performance of large language\nmodels (LLMs) can be significantly enhanced by scaling computational resources\nat test time. A common strategy involves generating multiple Chain-of-Thought\n(CoT) trajectories and aggregating their outputs through various selection\nmechanisms. This raises a fundamental question: can models with lower\ncomplexity leverage their superior generation throughput to outperform\nsimilarly sized Transformers for a fixed computational budget? To address this\nquestion and overcome the lack of strong subquadratic reasoners, we distill\npure and hybrid Mamba models from pretrained Transformers. Trained on only 8\nbillion tokens, our distilled models show strong performance and scaling on\nmathematical reasoning datasets while being much faster at inference for large\nbatches and long sequences. Despite the zero-shot performance hit due to\ndistillation, both pure and hybrid Mamba models can scale their coverage and\naccuracy performance past their Transformer teacher models under fixed time\nbudgets, opening a new direction for scaling inference compute.",
    "pdf_url": "http://arxiv.org/pdf/2502.20339v1",
    "published": "2025-02-27",
    "source": "arxiv",
    "id": "2502.20339v1",
    "categories": [
      "cs.CL",
      "cs.AI"
    ]
  },
  {
    "title": "EAIRA: Establishing a Methodology for Evaluating AI Models as Scientific Research Assistants",
    "authors": [
      "Franck Cappello",
      "Sandeep Madireddy",
      "Robert Underwood",
      "Neil Getty",
      "Nicholas Lee-Ping Chia",
      "Nesar Ramachandra",
      "Josh Nguyen",
      "Murat Keceli",
      "Tanwi Mallick",
      "Zilinghan Li",
      "Marieme Ngom",
      "Chenhui Zhang",
      "Angel Yanguas-Gil",
      "Evan Antoniuk",
      "Bhavya Kailkhura",
      "Minyang Tian",
      "Yufeng Du",
      "Yuan-Sen Ting",
      "Azton Wells",
      "Bogdan Nicolae",
      "Avinash Maurya",
      "M. Mustafa Rafique",
      "Eliu Huerta",
      "Bo Li",
      "Ian Foster",
      "Rick Stevens"
    ],
    "abstract": "Recent advancements have positioned AI, and particularly Large Language\nModels (LLMs), as transformative tools for scientific research, capable of\naddressing complex tasks that require reasoning, problem-solving, and\ndecision-making. Their exceptional capabilities suggest their potential as\nscientific research assistants but also highlight the need for holistic,\nrigorous, and domain-specific evaluation to assess effectiveness in real-world\nscientific applications. This paper describes a multifaceted methodology for\nEvaluating AI models as scientific Research Assistants (EAIRA) developed at\nArgonne National Laboratory. This methodology incorporates four primary classes\nof evaluations. 1) Multiple Choice Questions to assess factual recall; 2) Open\nResponse to evaluate advanced reasoning and problem-solving skills; 3)\nLab-Style Experiments involving detailed analysis of capabilities as research\nassistants in controlled environments; and 4) Field-Style Experiments to\ncapture researcher-LLM interactions at scale in a wide range of scientific\ndomains and applications. These complementary methods enable a comprehensive\nanalysis of LLM strengths and weaknesses with respect to their scientific\nknowledge, reasoning abilities, and adaptability. Recognizing the rapid pace of\nLLM advancements, we designed the methodology to evolve and adapt so as to\nensure its continued relevance and applicability. This paper describes the\nmethodology state at the end of February 2025. Although developed within a\nsubset of scientific domains, the methodology is designed to be generalizable\nto a wide range of scientific domains.",
    "pdf_url": "http://arxiv.org/pdf/2502.20309v1",
    "published": "2025-02-27",
    "source": "arxiv",
    "id": "2502.20309v1",
    "categories": [
      "cs.AI"
    ]
  },
  {
    "title": "Dual Non-Lorentzian Backgrounds for Matrix Theories",
    "authors": [
      "Chris D. A. Blair",
      "Johannes Lahnsteiner",
      "Niels A. Obers",
      "Ziqi Yan"
    ],
    "abstract": "We study properties of non-Lorentzian geometries arising from BPS decoupling\nlimits of string theory that are central to matrix theory and the AdS/CFT\ncorrespondence. We focus on duality transformations between ten-dimensional\nnon-Lorentzian geometries coupled to matrix theory on D-branes. We demonstrate\nthat T- and S-duality transformations exhibit novel asymmetric properties:\ndepending not only on the choice of transformation but also on the value of the\nbackground fields, the codimension of the foliation structure of the dual\nnon-Lorentzian background may be different or the same. This duality asymmetry\nunderlies features observed in the study of non-commutativity and Morita\nequivalence in matrix and gauge theory. Finally, we show how the holographic\ncorrespondence involving non-commutative Yang-Mills fits into our framework,\nfrom which we further obtain novel holographic examples with non-Lorentzian\nbulk geometries.",
    "pdf_url": "http://arxiv.org/pdf/2502.20310v1",
    "published": "2025-02-27",
    "source": "arxiv",
    "id": "2502.20310v1",
    "categories": [
      "hep-th"
    ]
  },
  {
    "title": "Visible Light Spectroscopy of Liquid Solutes from Femto- to Attoliter Volumes inside a Single Nanofluidic Channel",
    "authors": [
      "Björn Altenburger",
      "Joachim Fritzsche",
      "Christoph Langhammer"
    ],
    "abstract": "UV-Vis spectroscopy is a workhorse in analytical chemistry that finds\napplication in life science, organic synthesis and energy technologies like\nphotocatalysis. In its traditional implementation with cuvettes, it requires\nsample volumes in the milliliter range. Here, we show how Nanofluidic\nScattering Spectroscopy, NSS, which measures visible light scattered from a\nsingle nanochannel in a spectrally resolved way, can reduce this sample volume\nto the attoliter range for solute concentrations in the mM regime, which\ncorresponds to as few as 105 probed molecules. The connection of the\nnanochannel to a microfluidic in-and outlet system enables such measurements in\ncontinuous flow conditions, and the integrated online optical reference system\nensures their long-term stability. On the examples of the non-absorbing solutes\nNaCl and H2O2, and the dyes Brilliant Blue, Allura Red and Fluorescein, we\ndemonstrate that spectral fingerprints can be obtained with good accuracy and\nthat solute concentrations inside the nanochannel can be determined based on\nNSS-spectra. Furthermore, by applying a reverse Kramers-Kronig transformation\nto NSS-spectra, we show that the molar extinction coefficient of the dye\nsolutes can be extracted with excellent agreement with the literature values.\nThese results thus advertise NSS as a versatile tool for the spectroscopic\nanalysis of solutes in situations where nanoscopic sample volumes, as well as\ncontinuous flow measurements, are critical, e.g., in single particle catalysis\nor nanoscale flow cytometry.",
    "pdf_url": "http://arxiv.org/pdf/2502.20298v1",
    "published": "2025-02-27",
    "source": "arxiv",
    "id": "2502.20298v1",
    "categories": [
      "physics.chem-ph",
      "physics.optics"
    ]
  },
  {
    "title": "Solving Maker-Breaker Games on 5-uniform hypergraphs is PSPACE-complete",
    "authors": [
      "Finn Orson Koepke"
    ],
    "abstract": "Let $(X, \\mathcal{F})$ be a hypergraph. The Maker-Breaker game on $(X,\n\\mathcal{F})$ is a combinatorial game between two players, Maker and Breaker.\nBeginning with Maker, the players take turns claiming vertices from $X$ that\nhave not yet been claimed. Maker wins if she manages to claim all vertices of\nsome hyperedge $F \\in \\mathcal{F}$. Breaker wins if he claims at least one\nvertex in every hyperedge.\n  M. L. Rahman and Thomas Watson proved in 2021 that, even when only\nMaker-Breaker games on 6-uniform hypergraphs are considered, the decision\nproblem of determining which player has a winning strategy is PSPACE-complete.\nThey also showed that the problem is NL-hard when considering hypergraphs of\nrank 5.\n  In this paper, we improve the latter result by showing that deciding who wins\nMaker-Breaker games on 5-uniform hypergraphs is still a PSPACE-complete\nproblem. We achieve this by polynomial transformation from the problem of\nsolving the generalized geography game on bipartite digraphs with vertex\ndegrees 3 or less, which is known to be PSPACE-complete.",
    "pdf_url": "http://arxiv.org/pdf/2502.20271v1",
    "published": "2025-02-27",
    "source": "arxiv",
    "id": "2502.20271v1",
    "categories": [
      "cs.DM",
      "math.CO",
      "05C57",
      "G.2.1"
    ]
  },
  {
    "title": "Enhancing 3D Gaze Estimation in the Wild using Weak Supervision with Gaze Following Labels",
    "authors": [
      "Pierre Vuillecard",
      "Jean-Marc Odobez"
    ],
    "abstract": "Accurate 3D gaze estimation in unconstrained real-world environments remains\na significant challenge due to variations in appearance, head pose, occlusion,\nand the limited availability of in-the-wild 3D gaze datasets. To address these\nchallenges, we introduce a novel Self-Training Weakly-Supervised Gaze\nEstimation framework (ST-WSGE). This two-stage learning framework leverages\ndiverse 2D gaze datasets, such as gaze-following data, which offer rich\nvariations in appearances, natural scenes, and gaze distributions, and proposes\nan approach to generate 3D pseudo-labels and enhance model generalization.\nFurthermore, traditional modality-specific models, designed separately for\nimages or videos, limit the effective use of available training data. To\novercome this, we propose the Gaze Transformer (GaT), a modality-agnostic\narchitecture capable of simultaneously learning static and dynamic gaze\ninformation from both image and video datasets. By combining 3D video datasets\nwith 2D gaze target labels from gaze following tasks, our approach achieves the\nfollowing key contributions: (i) Significant state-of-the-art improvements in\nwithin-domain and cross-domain generalization on unconstrained benchmarks like\nGaze360 and GFIE, with notable cross-modal gains in video gaze estimation; (ii)\nSuperior cross-domain performance on datasets such as MPIIFaceGaze and Gaze360\ncompared to frontal face methods. Code and pre-trained models will be released\nto the community.",
    "pdf_url": "http://arxiv.org/pdf/2502.20249v1",
    "published": "2025-02-27",
    "source": "arxiv",
    "id": "2502.20249v1",
    "categories": [
      "cs.CV"
    ]
  },
  {
    "title": "Teasing Apart Architecture and Initial Weights as Sources of Inductive Bias in Neural Networks",
    "authors": [
      "Gianluca Bencomo",
      "Max Gupta",
      "Ioana Marinescu",
      "R. Thomas McCoy",
      "Thomas L. Griffiths"
    ],
    "abstract": "Artificial neural networks can acquire many aspects of human knowledge from\ndata, making them promising as models of human learning. But what those\nnetworks can learn depends upon their inductive biases -- the factors other\nthan the data that influence the solutions they discover -- and the inductive\nbiases of neural networks remain poorly understood, limiting our ability to\ndraw conclusions about human learning from the performance of these systems.\nCognitive scientists and machine learning researchers often focus on the\narchitecture of a neural network as a source of inductive bias. In this paper\nwe explore the impact of another source of inductive bias -- the initial\nweights of the network -- using meta-learning as a tool for finding initial\nweights that are adapted for specific problems. We evaluate four widely-used\narchitectures -- MLPs, CNNs, LSTMs, and Transformers -- by meta-training 430\ndifferent models across three tasks requiring different biases and forms of\ngeneralization. We find that meta-learning can substantially reduce or entirely\neliminate performance differences across architectures and data\nrepresentations, suggesting that these factors may be less important as sources\nof inductive bias than is typically assumed. When differences are present,\narchitectures and data representations that perform well without meta-learning\ntend to meta-train more effectively. Moreover, all architectures generalize\npoorly on problems that are far from their meta-training experience,\nunderscoring the need for stronger inductive biases for robust generalization.",
    "pdf_url": "http://arxiv.org/pdf/2502.20237v1",
    "published": "2025-02-27",
    "source": "arxiv",
    "id": "2502.20237v1",
    "categories": [
      "cs.LG",
      "cs.AI"
    ]
  },
  {
    "title": "DIN-CTS: Low-Complexity Depthwise-Inception Neural Network with Contrastive Training Strategy for Deepfake Speech Detection",
    "authors": [
      "Lam Pham",
      "Dat Tran",
      "Florian Skopik",
      "Alexander Schindler",
      "Silvia Poletti",
      "Fischinger David",
      "Martin Boyer"
    ],
    "abstract": "In this paper, we propose a deep neural network approach for deepfake speech\ndetection (DSD) based on a lowcomplexity Depthwise-Inception Network (DIN)\ntrained with a contrastive training strategy (CTS). In this framework, input\naudio recordings are first transformed into spectrograms using Short-Time\nFourier Transform (STFT) and Linear Filter (LF), which are then used to train\nthe DIN. Once trained, the DIN processes bonafide utterances to extract audio\nembeddings, which are used to construct a Gaussian distribution representing\ngenuine speech. Deepfake detection is then performed by computing the distance\nbetween a test utterance and this distribution to determine whether the\nutterance is fake or bonafide. To evaluate our proposed systems, we conducted\nextensive experiments on the benchmark dataset of ASVspoof 2019 LA. The\nexperimental results demonstrate the effectiveness of combining the\nDepthwise-Inception Network with the contrastive learning strategy in\ndistinguishing between fake and bonafide utterances. We achieved Equal Error\nRate (EER), Accuracy (Acc.), F1, AUC scores of 4.6%, 95.4%, 97.3%, and 98.9%\nrespectively using a single, low-complexity DIN with just 1.77 M parameters and\n985 M FLOPS on short audio segments (4 seconds). Furthermore, our proposed\nsystem outperforms the single-system submissions in the ASVspoof 2019 LA\nchallenge, showcasing its potential for real-time applications.",
    "pdf_url": "http://arxiv.org/pdf/2502.20225v1",
    "published": "2025-02-27",
    "source": "arxiv",
    "id": "2502.20225v1",
    "categories": [
      "cs.SD",
      "cs.CR",
      "eess.AS"
    ]
  },
  {
    "title": "On the relationship between two Sinc-collocation methods for Volterra integral equations of the second kind and their further improvement",
    "authors": [
      "Tomoaki Okayama"
    ],
    "abstract": "Two different Sinc-collocation methods for Volterra integral equations of the\nsecond kind have been independently proposed by Stenger and\nRashidinia--Zarebnia. However, their relationship remains unexplored. This\nstudy theoretically examines the solutions of these two methods, and reveals\nthat they are not generally equivalent, despite coinciding at the collocation\npoints. Strictly speaking, Stenger's method assumes that the kernel of the\nintegral is a function of a single variable, but this study theoretically\njustifies the use of his method in general cases, i.e., the kernel is a\nfunction of two variables. Then, this study rigorously proves that both methods\ncan attain the same, root-exponential convergence. In addition to the\ncontribution, this study improves Stenger's method to attain significantly\nhigher, almost exponential convergence. Numerical examples supporting the\ntheoretical results are also provided.",
    "pdf_url": "http://arxiv.org/pdf/2502.20221v2",
    "published": "2025-02-27",
    "source": "arxiv",
    "id": "2502.20221v2",
    "categories": [
      "math.NA",
      "cs.NA",
      "65R20"
    ]
  },
  {
    "title": "Exploring experimental limit of deep quantum signal processing using a trapped-ion simulator",
    "authors": [
      "J. -T. Bu",
      "Lei Zhang",
      "Zhan Yu",
      "Jing-Bo Wang",
      "W. -Q. Ding",
      "W. -F. Yuan",
      "B. Wang",
      "H. -J. Du",
      "W. -J. Chen",
      "L. Chen",
      "J. -W. Zhang",
      "J. -C. Li",
      "F. Zhou",
      "Xin Wang",
      "M. Feng"
    ],
    "abstract": "Quantum signal processing (QSP), which enables systematic polynomial\ntransformations on quantum data through sequences of qubit rotations, has\nemerged as a fundamental building block for quantum algorithms and data\nre-uploading quantum neural networks. While recent experiments have\ndemonstrated the feasibility of shallow QSP circuits, the inherent limitations\nin scaling QSP to achieve complex transformations on quantum hardware remain an\nopen and critical question. Here we report the first experimental realization\nof deep QSP circuits in a trapped-ion quantum simulator. By manipulating the\nqubit encoded in a trapped $^{43}\\textrm{Ca}^{+}$ ion, we demonstrate\nhigh-precision simulation of some prominent functions used in quantum\nalgorithms and machine learning, with circuit depths ranging from 15 to 360\nlayers and implementation time significantly longer than coherence time of the\nqubit. Our results reveal a crucial trade-off between the precision of function\nsimulation and the concomitant accumulation of hardware noise, highlighting the\nimportance of striking a balance between circuit depth and accuracy in\npractical QSP implementation. This work addresses a key gap in understanding\nthe scalability and limitations of QSP-based algorithms on quantum hardware,\nproviding valuable insights for developing quantum algorithms as well as\npractically realizing quantum singular value transformation and data\nre-uploading quantum machine learning models.",
    "pdf_url": "http://arxiv.org/pdf/2502.20199v1",
    "published": "2025-02-27",
    "source": "arxiv",
    "id": "2502.20199v1",
    "categories": [
      "quant-ph"
    ]
  },
  {
    "title": "Multimodal Representation Alignment for Image Generation: Text-Image Interleaved Control Is Easier Than You Think",
    "authors": [
      "Liang Chen",
      "Shuai Bai",
      "Wenhao Chai",
      "Weichu Xie",
      "Haozhe Zhao",
      "Leon Vinci",
      "Junyang Lin",
      "Baobao Chang"
    ],
    "abstract": "The field of advanced text-to-image generation is witnessing the emergence of\nunified frameworks that integrate powerful text encoders, such as CLIP and T5,\nwith Diffusion Transformer backbones. Although there have been efforts to\ncontrol output images with additional conditions, like canny and depth map, a\ncomprehensive framework for arbitrary text-image interleaved control is still\nlacking. This gap is especially evident when attempting to merge concepts or\nvisual elements from multiple images in the generation process. To mitigate the\ngap, we conducted preliminary experiments showing that large multimodal models\n(LMMs) offer an effective shared representation space, where image and text can\nbe well-aligned to serve as a condition for external diffusion models. Based on\nthis discovery, we propose Dream Engine, an efficient and unified framework\ndesigned for arbitrary text-image interleaved control in image generation\nmodels. Building on powerful text-to-image models like SD3.5, we replace the\noriginal text-only encoders by incorporating versatile multimodal information\nencoders such as QwenVL. Our approach utilizes a two-stage training paradigm,\nconsisting of joint text-image alignment and multimodal interleaved instruction\ntuning. Our experiments demonstrate that this training method is effective,\nachieving a 0.69 overall score on the GenEval benchmark, and matching the\nperformance of state-of-the-art text-to-image models like SD3.5 and FLUX.",
    "pdf_url": "http://arxiv.org/pdf/2502.20172v1",
    "published": "2025-02-27",
    "source": "arxiv",
    "id": "2502.20172v1",
    "categories": [
      "cs.CV",
      "cs.CL"
    ]
  },
  {
    "title": "Similarity-Distance-Magnitude Universal Verification",
    "authors": [
      "Allen Schmaltz"
    ],
    "abstract": "We solve the neural network robustness problem by adding Similarity (i.e.,\ncorrectly predicted depth-matches into training)-awareness and\nDistance-to-training-distribution-awareness to the existing output Magnitude\n(i.e., decision-boundary)-awareness of the softmax function. The resulting sdm\nactivation function provides strong signals of the relative epistemic\n(reducible) predictive uncertainty. We use this novel behavior to further\naddress the complementary HCI problem of mapping the output to\nhuman-interpretable summary statistics over relevant partitions of a held-out\ncalibration set. Estimates of prediction-conditional uncertainty are obtained\nvia a parsimonious learned transform over the class-conditional empirical CDFs\nof the output of a final-layer sdm activation function. For decision-making and\nas an intrinsic model check, estimates of class-conditional accuracy are\nobtained by further partitioning the high-probability regions of this\ncalibrated output into class-conditional, region-specific CDFs. The uncertainty\nestimates from sdm calibration are remarkably robust to test-time distribution\nshifts and out-of-distribution inputs; incorporate awareness of the effective\nsample size; provide estimates of uncertainty from the learning and data\nsplitting processes; and are well-suited for selective classification and\nconditional branching for additional test-time compute based on the predictive\nuncertainty, as for selective LLM generation, routing, and composition over\nmultiple models and retrieval. Finally, we construct sdm networks, LLMs with\nuncertainty-aware verification and interpretability-by-exemplar as intrinsic\nproperties. We provide open-source software implementing these results.",
    "pdf_url": "http://arxiv.org/pdf/2502.20167v1",
    "published": "2025-02-27",
    "source": "arxiv",
    "id": "2502.20167v1",
    "categories": [
      "cs.LG",
      "cs.CL"
    ]
  },
  {
    "title": "Adaptive H&E-IHC information fusion staining framework based on feature extra",
    "authors": [
      "Yifan Jia",
      "Xingda Yu",
      "Zhengyang Ji",
      "Songning Lai",
      "Yutao Yue"
    ],
    "abstract": "Immunohistochemistry (IHC) staining plays a significant role in the\nevaluation of diseases such as breast cancer. The H&E-to-IHC transformation\nbased on generative models provides a simple and cost-effective method for\nobtaining IHC images. Although previous models can perform digital coloring\nwell, they still suffer from (i) coloring only through the pixel features that\nare not prominent in HE, which is easy to cause information loss in the\ncoloring process; (ii) The lack of pixel-perfect H&E-IHC groundtruth pairs\nposes a challenge to the classical L1 loss.To address the above challenges, we\npropose an adaptive information enhanced coloring framework based on feature\nextractors. We first propose the VMFE module to effectively extract the color\ninformation features using multi-scale feature extraction and wavelet transform\nconvolution, while combining the shared decoder for feature fusion. The\nhigh-performance dual feature extractor of H&E-IHC is trained by contrastive\nlearning, which can effectively perform feature alignment of HE-IHC in high\nlatitude space. At the same time, the trained feature encoder is used to\nenhance the features and adaptively adjust the loss in the HE section staining\nprocess to solve the problems related to unclear and asymmetric information. We\nhave tested on different datasets and achieved excellent performance.Our code\nis available at https://github.com/babyinsunshine/CEFF",
    "pdf_url": "http://arxiv.org/pdf/2502.20156v1",
    "published": "2025-02-27",
    "source": "arxiv",
    "id": "2502.20156v1",
    "categories": [
      "cs.CV",
      "cs.AI"
    ]
  },
  {
    "title": "Show and Tell: Visually Explainable Deep Neural Nets via Spatially-Aware Concept Bottleneck Models",
    "authors": [
      "Itay Benou",
      "Tammy Riklin-Raviv"
    ],
    "abstract": "Modern deep neural networks have now reached human-level performance across a\nvariety of tasks. However, unlike humans they lack the ability to explain their\ndecisions by showing where and telling what concepts guided them. In this work,\nwe present a unified framework for transforming any vision neural network into\na spatially and conceptually interpretable model. We introduce a\nspatially-aware concept bottleneck layer that projects \"black-box\" features of\npre-trained backbone models into interpretable concept maps, without requiring\nhuman labels. By training a classification layer over this bottleneck, we\nobtain a self-explaining model that articulates which concepts most influenced\nits prediction, along with heatmaps that ground them in the input image.\nAccordingly, we name this method \"Spatially-Aware and Label-Free Concept\nBottleneck Model\" (SALF-CBM). Our results show that the proposed SALF-CBM: (1)\nOutperforms non-spatial CBM methods, as well as the original backbone, on a\nvariety of classification tasks; (2) Produces high-quality spatial\nexplanations, outperforming widely used heatmap-based methods on a zero-shot\nsegmentation task; (3) Facilitates model exploration and debugging, enabling\nusers to query specific image regions and refine the model's decisions by\nlocally editing its concept maps.",
    "pdf_url": "http://arxiv.org/pdf/2502.20134v1",
    "published": "2025-02-27",
    "source": "arxiv",
    "id": "2502.20134v1",
    "categories": [
      "cs.CV"
    ]
  },
  {
    "title": "Regional climate projections using a deep-learning-based model-ranking and downscaling framework: Application to European climate zones",
    "authors": [
      "Parthiban Loganathan",
      "Elias Zea",
      "Ricardo Vinuesa",
      "Evelyn Otero"
    ],
    "abstract": "Accurate regional climate forecast calls for high-resolution downscaling of\nGlobal Climate Models (GCMs). This work presents a deep-learning-based\nmulti-model evaluation and downscaling framework ranking 32 Coupled Model\nIntercomparison Project Phase 6 (CMIP6) models using a Deep Learning-TOPSIS\n(DL-TOPSIS) mechanism and so refines outputs using advanced deep-learning\nmodels. Using nine performance criteria, five K\\\"oppen-Geiger climate zones --\nTropical, Arid, Temperate, Continental, and Polar -- are investigated over four\nseasons. While TaiESM1 and CMCC-CM2-SR5 show notable biases, ranking results\nshow that NorESM2-LM, GISS-E2-1-G, and HadGEM3-GC31-LL outperform other models.\nFour models contribute to downscaling the top-ranked GCMs to 0.1$^{\\circ}$\nresolution: Vision Transformer (ViT), Geospatial Spatiotemporal Transformer\nwith Attention and Imbalance-Aware Network (GeoSTANet), CNN-LSTM, and CNN-Long\nShort-Term Memory (ConvLSTM). Effectively capturing temperature extremes (TXx,\nTNn), GeoSTANet achieves the highest accuracy (Root Mean Square Error (RMSE) =\n1.57$^{\\circ}$C, Kling-Gupta Efficiency (KGE) = 0.89, Nash-Sutcliffe Efficiency\n(NSE) = 0.85, Correlation ($r$) = 0.92), so reducing RMSE by 20% over ConvLSTM.\nCNN-LSTM and ConvLSTM do well in Continental and Temperate zones; ViT finds\nfine-scale temperature fluctuations difficult. These results confirm that\nmulti-criteria ranking improves GCM selection for regional climate studies and\ntransformer-based downscaling exceeds conventional deep-learning methods. This\nframework offers a scalable method to enhance high-resolution climate\nprojections, benefiting impact assessments and adaptation plans.",
    "pdf_url": "http://arxiv.org/pdf/2502.20132v2",
    "published": "2025-02-27",
    "source": "arxiv",
    "id": "2502.20132v2",
    "categories": [
      "cs.LG",
      "cs.NA",
      "math.NA"
    ]
  },
  {
    "title": "Finite State Automata Inside Transformers with Chain-of-Thought: A Mechanistic Study on State Tracking",
    "authors": [
      "Yifan Zhang",
      "Wenyu Du",
      "Dongming Jin",
      "Jie Fu",
      "Zhi Jin"
    ],
    "abstract": "Chain-of-Thought (CoT) significantly enhances the performance of large\nlanguage models (LLMs) across a wide range of tasks, and prior research shows\nthat CoT can theoretically increase expressiveness. However, there is limited\nmechanistic understanding of the algorithms that Transformer+CoT can learn. In\nthis work, we (1) evaluate the state tracking capabilities of Transformer+CoT\nand its variants, confirming the effectiveness of CoT. (2) Next, we identify\nthe circuit, a subset of model components, responsible for tracking the world\nstate, finding that late-layer MLP neurons play a key role. We propose two\nmetrics, compression and distinction, and show that the neuron sets for each\nstate achieve nearly 100% accuracy, providing evidence of an implicit finite\nstate automaton (FSA) embedded within the model. (3) Additionally, we explore\nthree realistic settings: skipping intermediate steps, introducing data noise,\nand testing length generalization. Our results demonstrate that Transformer+CoT\nlearns robust algorithms (FSA), highlighting its resilience in challenging\nscenarios.",
    "pdf_url": "http://arxiv.org/pdf/2502.20129v1",
    "published": "2025-02-27",
    "source": "arxiv",
    "id": "2502.20129v1",
    "categories": [
      "cs.CL",
      "cs.LG"
    ]
  },
  {
    "title": "FlexiDiT: Your Diffusion Transformer Can Easily Generate High-Quality Samples with Less Compute",
    "authors": [
      "Sotiris Anagnostidis",
      "Gregor Bachmann",
      "Yeongmin Kim",
      "Jonas Kohler",
      "Markos Georgopoulos",
      "Artsiom Sanakoyeu",
      "Yuming Du",
      "Albert Pumarola",
      "Ali Thabet",
      "Edgar Schönfeld"
    ],
    "abstract": "Despite their remarkable performance, modern Diffusion Transformers are\nhindered by substantial resource requirements during inference, stemming from\nthe fixed and large amount of compute needed for each denoising step. In this\nwork, we revisit the conventional static paradigm that allocates a fixed\ncompute budget per denoising iteration and propose a dynamic strategy instead.\nOur simple and sample-efficient framework enables pre-trained DiT models to be\nconverted into \\emph{flexible} ones -- dubbed FlexiDiT -- allowing them to\nprocess inputs at varying compute budgets. We demonstrate how a single\n\\emph{flexible} model can generate images without any drop in quality, while\nreducing the required FLOPs by more than $40$\\% compared to their static\ncounterparts, for both class-conditioned and text-conditioned image generation.\nOur method is general and agnostic to input and conditioning modalities. We\nshow how our approach can be readily extended for video generation, where\nFlexiDiT models generate samples with up to $75$\\% less compute without\ncompromising performance.",
    "pdf_url": "http://arxiv.org/pdf/2502.20126v1",
    "published": "2025-02-27",
    "source": "arxiv",
    "id": "2502.20126v1",
    "categories": [
      "cs.LG",
      "cs.CV"
    ]
  },
  {
    "title": "MITracker: Multi-View Integration for Visual Object Tracking",
    "authors": [
      "Mengjie Xu",
      "Yitao Zhu",
      "Haotian Jiang",
      "Jiaming Li",
      "Zhenrong Shen",
      "Sheng Wang",
      "Haolin Huang",
      "Xinyu Wang",
      "Qing Yang",
      "Han Zhang",
      "Qian Wang"
    ],
    "abstract": "Multi-view object tracking (MVOT) offers promising solutions to challenges\nsuch as occlusion and target loss, which are common in traditional single-view\ntracking. However, progress has been limited by the lack of comprehensive\nmulti-view datasets and effective cross-view integration methods. To overcome\nthese limitations, we compiled a Multi-View object Tracking (MVTrack) dataset\nof 234K high-quality annotated frames featuring 27 distinct objects across\nvarious scenes. In conjunction with this dataset, we introduce a novel MVOT\nmethod, Multi-View Integration Tracker (MITracker), to efficiently integrate\nmulti-view object features and provide stable tracking outcomes. MITracker can\ntrack any object in video frames of arbitrary length from arbitrary viewpoints.\nThe key advancements of our method over traditional single-view approaches come\nfrom two aspects: (1) MITracker transforms 2D image features into a 3D feature\nvolume and compresses it into a bird's eye view (BEV) plane, facilitating\ninter-view information fusion; (2) we propose an attention mechanism that\nleverages geometric information from fused 3D feature volume to refine the\ntracking results at each view. MITracker outperforms existing methods on the\nMVTrack and GMTD datasets, achieving state-of-the-art performance. The code and\nthe new dataset will be available at\nhttps://mii-laboratory.github.io/MITracker/.",
    "pdf_url": "http://arxiv.org/pdf/2502.20111v1",
    "published": "2025-02-27",
    "source": "arxiv",
    "id": "2502.20111v1",
    "categories": [
      "cs.CV",
      "cs.AI"
    ]
  },
  {
    "title": "VDT-Auto: End-to-end Autonomous Driving with VLM-Guided Diffusion Transformers",
    "authors": [
      "Ziang Guo",
      "Konstantin Gubernatorov",
      "Selamawit Asfaw",
      "Zakhar Yagudin",
      "Dzmitry Tsetserukou"
    ],
    "abstract": "In autonomous driving, dynamic environment and corner cases pose significant\nchallenges to the robustness of ego vehicle's decision-making. To address these\nchallenges, commencing with the representation of state-action mapping in the\nend-to-end autonomous driving paradigm, we introduce a novel pipeline,\nVDT-Auto. Leveraging the advancement of the state understanding of Visual\nLanguage Model (VLM), incorporating with diffusion Transformer-based action\ngeneration, our VDT-Auto parses the environment geometrically and contextually\nfor the conditioning of the diffusion process. Geometrically, we use a\nbird's-eye view (BEV) encoder to extract feature grids from the surrounding\nimages. Contextually, the structured output of our fine-tuned VLM is processed\ninto textual embeddings and noisy paths. During our diffusion process, the\nadded noise for the forward process is sampled from the noisy path output of\nthe fine-tuned VLM, while the extracted BEV feature grids and embedded texts\ncondition the reverse process of our diffusion Transformers. Our VDT-Auto\nachieved 0.52m on average L2 errors and 21% on average collision rate in the\nnuScenes open-loop planning evaluation. Moreover, the real-world demonstration\nexhibited prominent generalizability of our VDT-Auto. The code and dataset will\nbe released after acceptance.",
    "pdf_url": "http://arxiv.org/pdf/2502.20108v2",
    "published": "2025-02-27",
    "source": "arxiv",
    "id": "2502.20108v2",
    "categories": [
      "cs.CV",
      "cs.RO"
    ]
  },
  {
    "title": "Electric-field control of photon indistinguishability in cascaded decays in quantum dots",
    "authors": [
      "Gabriel Undeutsch",
      "Maximilian Aigner",
      "Ailton J. Garcia Jr.",
      "Johannes Reindl",
      "Melina Peter",
      "Simon Mader",
      "Christian Weidinger",
      "Saimon F. Covre da Silva",
      "Santanu Manna",
      "Eva Schöll",
      "Armando Rastelli"
    ],
    "abstract": "Photon indistinguishability, entanglement, and antibunching are key\ningredients in quantum optics and photonics. Decay cascades in quantum emitters\noffer a simple method to create entangled photon-pairs with negligible\nmulti-pair generation probability. However, the degree of indistinguishability\nof the photons emitted in a cascade is intrinsically limited by the lifetime\nratio of the involved transitions. Here we show that, for the biexciton-exciton\ncascade in a quantum dot, this ratio can be widely tuned by an applied electric\nfield. Hong-Ou-Mandel interference measurements of two subsequently emitted\nbiexciton photons show that their indistinguishability increases with\nincreasing field, following the theoretically predicted behavior. At the same\ntime, the emission linewidth stays close to the transform-limit, favoring\napplications relying on the interference among photons emitted by different\nsources.",
    "pdf_url": "http://arxiv.org/pdf/2502.20093v1",
    "published": "2025-02-27",
    "source": "arxiv",
    "id": "2502.20093v1",
    "categories": [
      "quant-ph",
      "cond-mat.mes-hall"
    ]
  },
  {
    "title": "Minds on the Move: Decoding Trajectory Prediction in Autonomous Driving with Cognitive Insights",
    "authors": [
      "Haicheng Liao",
      "Chengyue Wang",
      "Kaiqun Zhu",
      "Yilong Ren",
      "Bolin Gao",
      "Shengbo Eben Li",
      "Chengzhong Xu",
      "Zhenning Li"
    ],
    "abstract": "In mixed autonomous driving environments, accurately predicting the future\ntrajectories of surrounding vehicles is crucial for the safe operation of\nautonomous vehicles (AVs). In driving scenarios, a vehicle's trajectory is\ndetermined by the decision-making process of human drivers. However, existing\nmodels primarily focus on the inherent statistical patterns in the data, often\nneglecting the critical aspect of understanding the decision-making processes\nof human drivers. This oversight results in models that fail to capture the\ntrue intentions of human drivers, leading to suboptimal performance in\nlong-term trajectory prediction. To address this limitation, we introduce a\nCognitive-Informed Transformer (CITF) that incorporates a cognitive concept,\nPerceived Safety, to interpret drivers' decision-making mechanisms. Perceived\nSafety encapsulates the varying risk tolerances across drivers with different\ndriving behaviors. Specifically, we develop a Perceived Safety-aware Module\nthat includes a Quantitative Safety Assessment for measuring the subject risk\nlevels within scenarios, and Driver Behavior Profiling for characterizing\ndriver behaviors. Furthermore, we present a novel module, Leanformer, designed\nto capture social interactions among vehicles. CITF demonstrates significant\nperformance improvements on three well-established datasets. In terms of\nlong-term prediction, it surpasses existing benchmarks by 12.0% on the NGSIM,\n28.2% on the HighD, and 20.8% on the MoCAD dataset. Additionally, its\nrobustness in scenarios with limited or missing data is evident, surpassing\nmost state-of-the-art (SOTA) baselines, and paving the way for real-world\napplications.",
    "pdf_url": "http://arxiv.org/pdf/2502.20084v1",
    "published": "2025-02-27",
    "source": "arxiv",
    "id": "2502.20084v1",
    "categories": [
      "cs.RO",
      "cs.AI"
    ]
  },
  {
    "title": "Integral representation of solutions to initial-boundary value problems in the framework of the hyperbolic heat equation",
    "authors": [
      "Sergey A. Rukolaine"
    ],
    "abstract": "We consider initial-boundary value problems on a finite interval for the\nsystem of the energy balance equation and modified Fourier's law (constitutive\nequation, commonly called the Cattaneo equation) describing temperature (or\ninternal energy) and heat flux. This hyperbolic system of first-order partial\ndifferential equations is the simplest model of non-Fourier heat conduction.\nBoundary conditions comprise various models of behavior of a physical system at\nthe boundaries, including boundary conditions describing Newton's law, which\nstates that the heat flux at the boundary is directly proportional to the\ndifference in the temperature of the physical system and ambient temperature.\nIn this case the boundary conditions express the relationship of unknown\nfunctions (temperature or internal energy and heat flux) with each other. To\nsolve the problems, we apply the Fokas unified transform method.",
    "pdf_url": "http://arxiv.org/pdf/2502.20057v1",
    "published": "2025-02-27",
    "source": "arxiv",
    "id": "2502.20057v1",
    "categories": [
      "math.AP",
      "cond-mat.stat-mech",
      "math-ph",
      "math.MP"
    ]
  },
  {
    "title": "Fiber-based Ultra-High Speed Diffuse Speckle Contrast Analysis System for Deep Blood Flow Sensing Using a Large SPAD Camera",
    "authors": [
      "Quan Wang",
      "Renzhe Bi",
      "Songhua Zheng",
      "Ahmet T. Erdogan",
      "Yi Qi",
      "Chenxu Li",
      "Yuanyuan Hua",
      "Mingliang Pan",
      "Yining Wang",
      "Neil Finlayson",
      "Malini Olivo",
      "Robert K. Henderson",
      "David Uei-Day Li"
    ],
    "abstract": "Diffuse speckle contrast analysis (DSCA), also called speckle contrast\noptical spectroscopy(SCOS), has emerged as a groundbreaking optical imaging\ntechnique for tracking dynamic biological processes, including blood flow and\ntissue perfusion. Recent advancements in single-photon avalanche diode (SPAD)\ncameras have unlocked exceptional capabilities in sensitivity, time resolution,\nand high frame rate imaging. Despite this, the application of large-format SPAD\narrays in speckle contrast analysis is still relatively uncommon. In this\nstudy, we introduce a pioneering use of a large format SPAD camera for DSCA. By\nharnessing the camera's high temporal resolution and photon detection\nefficiency, we significantly enhance the accuracy and robustness of speckle\ncontrast measurements. Our experimental results demonstrate the system's\nremarkable ability to capture rapid temporal variations over a broad field of\nview, enabling detailed spatiotemporal analysis. Through simulations, phantom\nexperiments, and in vivo studies, we validate the approach's potential for a\nwide range of biomedical applications, such as cuff occlusion tests and\nfunctional tissue monitoring. This work highlights the transformative impact of\nlarge SPAD cameras on DSCA, paving the way for new breakthroughs in optical\nimaging.",
    "pdf_url": "http://arxiv.org/pdf/2502.20048v1",
    "published": "2025-02-27",
    "source": "arxiv",
    "id": "2502.20048v1",
    "categories": [
      "physics.ins-det"
    ]
  },
  {
    "title": "Connecting the Persian-speaking World through Transliteration",
    "authors": [
      "Rayyan Merchant",
      "Akhilesh Kakolu Ramarao",
      "Kevin Tang"
    ],
    "abstract": "Despite speaking mutually intelligible varieties of the same language,\nspeakers of Tajik Persian, written in a modified Cyrillic alphabet, cannot read\nIranian and Afghan texts written in the Perso-Arabic script. As the vast\nmajority of Persian text on the Internet is written in Perso-Arabic,\nmonolingual Tajik speakers are unable to interface with the Internet in any\nmeaningful way. Due to overwhelming similarity between the formal registers of\nthese dialects and the scarcity of Tajik-Farsi parallel data, machine\ntransliteration has been proposed as more a practical and appropriate solution\nthan machine translation. This paper presents a transformer-based G2P approach\nto Tajik-Farsi transliteration, achieving chrF++ scores of 58.70 (Farsi to\nTajik) and 74.20 (Tajik to Farsi) on novel digraphic datasets, setting a\ncomparable baseline metric for future work. Our results also demonstrate the\nnon-trivial difficulty of this task in both directions. We also provide an\noverview of the differences between the two scripts and the challenges they\npresent, so as to aid future efforts in Tajik-Farsi transliteration.",
    "pdf_url": "http://arxiv.org/pdf/2502.20047v1",
    "published": "2025-02-27",
    "source": "arxiv",
    "id": "2502.20047v1",
    "categories": [
      "cs.CL"
    ]
  },
  {
    "title": "CleanMel: Mel-Spectrogram Enhancement for Improving Both Speech Quality and ASR",
    "authors": [
      "Nian Shao",
      "Rui Zhou",
      "Pengyu Wang",
      "Xian Li",
      "Ying Fang",
      "Yujie Yang",
      "Xiaofei Li"
    ],
    "abstract": "In this work, we propose CleanMel, a single-channel Mel-spectrogram denoising\nand dereverberation network for improving both speech quality and automatic\nspeech recognition (ASR) performance. The proposed network takes as input the\nnoisy and reverberant microphone recording and predicts the corresponding clean\nMel-spectrogram. The enhanced Mel-spectrogram can be either transformed to\nspeech waveform with a neural vocoder or directly used for ASR. The proposed\nnetwork is composed of interleaved cross-band and narrow-band processing in the\nMel-frequency domain, for learning the full-band spectral pattern and the\nnarrow-band properties of signals, respectively. Compared to linear-frequency\ndomain or time-domain speech enhancement, the key advantage of Mel-spectrogram\nenhancement is that Mel-frequency presents speech in a more compact way and\nthus is easier to learn, which will benefit both speech quality and ASR.\nExperimental results on four English and one Chinese datasets demonstrate a\nsignificant improvement in both speech quality and ASR performance achieved by\nthe proposed model. Code and audio examples of our model are available online\nin https://audio.westlake.edu.cn/Research/CleanMel.html.",
    "pdf_url": "http://arxiv.org/pdf/2502.20040v1",
    "published": "2025-02-27",
    "source": "arxiv",
    "id": "2502.20040v1",
    "categories": [
      "eess.AS",
      "cs.AI",
      "cs.SD"
    ]
  },
  {
    "title": "Dynamic Energy Flow Analysis of Integrated Electricity and Gas Systems: A Semi-Analytical Approach",
    "authors": [
      "Zhikai Huang",
      "Shuai Lu",
      "Wei Gu",
      "Ruizhi Yu",
      "Suhan Zhang",
      "Yijun Xu",
      "Yuan Li"
    ],
    "abstract": "Ensuring the safe and reliable operation of integrated electricity and gas\nsystems (IEGS) requires dynamic energy flow (DEF) simulation tools that achieve\nhigh accuracy and computational efficiency. However, the inherent strong\nnonlinearity of gas dynamics and its bidirectional coupling with power grids\nimpose significant challenges on conventional numerical algorithms,\nparticularly in computational efficiency and accuracy. Considering this, we\npropose a novel non-iterative semi-analytical algorithm based on differential\ntransformation (DT) for DEF simulation of IEGS. First, we introduce a\nsemi-discrete difference method to convert the partial differential algebraic\nequations of the DEF model into ordinary differential algebraic equations to\nresort to the DT. Particularly, by employing spatial central difference and\nnumerical boundary extrapolation, we effectively avoid the singularity issue of\nthe DT coefficient matrix. Second, we propose a DT-based semi-analytical\nsolution method, which can yield the solution of the DEF model by recursion.\nFinally, simulation results demonstrate the superiority of the proposed method.",
    "pdf_url": "http://arxiv.org/pdf/2502.20022v1",
    "published": "2025-02-27",
    "source": "arxiv",
    "id": "2502.20022v1",
    "categories": [
      "eess.SY",
      "cs.SY"
    ]
  },
  {
    "title": "Multi-Keypoint Affordance Representation for Functional Dexterous Grasping",
    "authors": [
      "Fan Yang",
      "Dongsheng Luo",
      "Wenrui Chen",
      "Jiacheng Lin",
      "Junjie Cai",
      "Kailun Yang",
      "Zhiyong Li",
      "Yaonan Wang"
    ],
    "abstract": "Functional dexterous grasping requires precise hand-object interaction, going\nbeyond simple gripping. Existing affordance-based methods primarily predict\ncoarse interaction regions and cannot directly constrain the grasping posture,\nleading to a disconnection between visual perception and manipulation. To\naddress this issue, we propose a multi-keypoint affordance representation for\nfunctional dexterous grasping, which directly encodes task-driven grasp\nconfigurations by localizing functional contact points. Our method introduces\nContact-guided Multi-Keypoint Affordance (CMKA), leveraging human grasping\nexperience images for weak supervision combined with Large Vision Models for\nfine affordance feature extraction, achieving generalization while avoiding\nmanual keypoint annotations. Additionally, we present a Keypoint-based Grasp\nmatrix Transformation (KGT) method, ensuring spatial consistency between hand\nkeypoints and object contact points, thus providing a direct link between\nvisual perception and dexterous grasping actions. Experiments on public\nreal-world FAH datasets, IsaacGym simulation, and challenging robotic tasks\ndemonstrate that our method significantly improves affordance localization\naccuracy, grasp consistency, and generalization to unseen tools and tasks,\nbridging the gap between visual affordance learning and dexterous robotic\nmanipulation. The source code and demo videos will be publicly available at\nhttps://github.com/PopeyePxx/MKA.",
    "pdf_url": "http://arxiv.org/pdf/2502.20018v1",
    "published": "2025-02-27",
    "source": "arxiv",
    "id": "2502.20018v1",
    "categories": [
      "cs.RO",
      "cs.CV",
      "eess.IV"
    ]
  },
  {
    "title": "Joint Fusion and Encoding: Advancing Multimodal Retrieval from the Ground Up",
    "authors": [
      "Lang Huang",
      "Qiyu Wu",
      "Zhongtao Miao",
      "Toshihiko Yamasaki"
    ],
    "abstract": "Information retrieval is indispensable for today's Internet applications, yet\ntraditional semantic matching techniques often fall short in capturing the\nfine-grained cross-modal interactions required for complex queries. Although\nlate-fusion two-tower architectures attempt to bridge this gap by independently\nencoding visual and textual data before merging them at a high level, they\nfrequently overlook the subtle interplay essential for comprehensive\nunderstanding. In this work, we rigorously assess these limitations and\nintroduce a unified retrieval framework that fuses visual and textual cues from\nthe ground up, enabling early cross-modal interactions for enhancing context\ninterpretation. Through a two-stage training process--comprising post-training\nadaptation followed by instruction tuning--we adapt MLLMs as retrievers using a\nsimple one-tower architecture. Our approach outperforms conventional methods\nacross diverse retrieval scenarios, particularly when processing complex\nmulti-modal inputs. Notably, the joint fusion encoder yields greater\nimprovements on tasks that require modality fusion compared to those that do\nnot, underscoring the transformative potential of early integration strategies\nand pointing toward a promising direction for contextually aware and effective\ninformation retrieval.",
    "pdf_url": "http://arxiv.org/pdf/2502.20008v1",
    "published": "2025-02-27",
    "source": "arxiv",
    "id": "2502.20008v1",
    "categories": [
      "cs.CV"
    ]
  },
  {
    "title": "Efficient Time Series Forecasting via Hyper-Complex Models and Frequency Aggregation",
    "authors": [
      "Eyal Yakir",
      "Dor Tsur",
      "Haim Permuter"
    ],
    "abstract": "Time series forecasting is a long-standing problem in statistics and machine\nlearning. One of the key challenges is processing sequences with long-range\ndependencies. To that end, a recent line of work applied the short-time Fourier\ntransform (STFT), which partitions the sequence into multiple subsequences and\napplies a Fourier transform to each separately. We propose the Frequency\nInformation Aggregation (FIA)-Net, which is based on a novel complex-valued MLP\narchitecture that aggregates adjacent window information in the frequency\ndomain. To further increase the receptive field of the FIA-Net, we treat the\nset of windows as hyper-complex (HC) valued vectors and employ HC algebra to\nefficiently combine information from all STFT windows altogether. Using the\nHC-MLP backbone allows for improved handling of sequences with long-term\ndependence. Furthermore, due to the nature of HC operations, the HC-MLP uses up\nto three times fewer parameters than the equivalent standard window aggregation\nmethod. We evaluate the FIA-Net on various time-series benchmarks and show that\nthe proposed methodologies outperform existing state of the art methods in\nterms of both accuracy and efficiency. Our code is publicly available on\nhttps://anonymous.4open.science/r/research-1803/.",
    "pdf_url": "http://arxiv.org/pdf/2502.19983v1",
    "published": "2025-02-27",
    "source": "arxiv",
    "id": "2502.19983v1",
    "categories": [
      "cs.LG",
      "62M20, 42A16, 68T05, 15A66 62M20, 42A16, 68T05, 15A66 62M20, 42A16,\n  68T05, 15A66",
      "I.2.6; I.5.1"
    ]
  },
  {
    "title": "Beyond costs: Mapping Norwegian youth preferences for a more inclusive energy transition",
    "authors": [
      "Muhammad Shahzad Javed",
      "Karin Fossheim",
      "Paola Velasco-Herrejón",
      "Nikolai Elias Koop",
      "Matylda N. Guzik",
      "Charles Dana Samuelson",
      "Beate Seibt",
      "Marianne Zeyringer"
    ],
    "abstract": "Environmental movements and climate strikes have made it apparent that youth\nfeel excluded from the ongoing energy transformation process, highlighting the\ncrucial need for their engagement to achieve a socially accepted transition.\nThis interdisciplinary study focuses on the Norwegian electricity system and\ninvolves conducting educational workshops with high school students aged 15 to\n16 to ascertain their perspectives towards a net-zero energy system. The\nworkshops were structured into three segments, starting with the dissemination\nof common knowledge about energy and climate, followed by interactive\nactivities designed to explore and develop an understanding of various aspects\nof energy transition. Three rounds of questionnaires, administered at distinct\ntime intervals, assessed changes in students' attitudes and\nsocio-techno-economic preferences. Our findings show that 33\\% of pupils\nfavored exclusively offshore wind as a main energy source, while 35\\% opted to\ncombine it with solar energy, indicating that over 68\\% viewed offshore wind as\nfavorable. Although 32\\% supported some form of land-based wind turbines, there\nwas strong disagreement about wind parks in agricultural, forested, and\nresidential areas. Preferences also exhibited considerable regional variation;\nsolar installations were favored in southern and southeastern Norway, while\nwind farms were suggested for central and northern regions. Pupils emphasized\nenergy independence, showed reluctance towards demand response, prioritized\nreducing emissions and preserving biodiversity over minimizing electricity\ncosts. Despite cost-minimization being core to most energy system models, youth\ndeemed it the least important factor, highlighting a disconnect between\nmodeling priorities and their perspectives.",
    "pdf_url": "http://arxiv.org/pdf/2502.19974v1",
    "published": "2025-02-27",
    "source": "arxiv",
    "id": "2502.19974v1",
    "categories": [
      "physics.soc-ph"
    ]
  },
  {
    "title": "Deterministic or probabilistic? The psychology of LLMs as random number generators",
    "authors": [
      "Javier Coronado-Blázquez"
    ],
    "abstract": "Large Language Models (LLMs) have transformed text generation through\ninherently probabilistic context-aware mechanisms, mimicking human natural\nlanguage. In this paper, we systematically investigate the performance of\nvarious LLMs when generating random numbers, considering diverse configurations\nsuch as different model architectures, numerical ranges, temperature, and\nprompt languages. Our results reveal that, despite their stochastic\ntransformers-based architecture, these models often exhibit deterministic\nresponses when prompted for random numerical outputs. In particular, we find\nsignificant differences when changing the model, as well as the prompt\nlanguage, attributing this phenomenon to biases deeply embedded within the\ntraining data. Models such as DeepSeek-R1 can shed some light on the internal\nreasoning process of LLMs, despite arriving to similar results. These biases\ninduce predictable patterns that undermine genuine randomness, as LLMs are\nnothing but reproducing our own human cognitive biases.",
    "pdf_url": "http://arxiv.org/pdf/2502.19965v1",
    "published": "2025-02-27",
    "source": "arxiv",
    "id": "2502.19965v1",
    "categories": [
      "cs.CL",
      "cs.AI"
    ]
  },
  {
    "title": "LLM Post-Training: A Deep Dive into Reasoning Large Language Models",
    "authors": [
      "Komal Kumar",
      "Tajamul Ashraf",
      "Omkar Thawakar",
      "Rao Muhammad Anwer",
      "Hisham Cholakkal",
      "Mubarak Shah",
      "Ming-Hsuan Yang",
      "Phillip H. S. Torr",
      "Salman Khan",
      "Fahad Shahbaz Khan"
    ],
    "abstract": "Large Language Models (LLMs) have transformed the natural language processing\nlandscape and brought to life diverse applications. Pretraining on vast\nweb-scale data has laid the foundation for these models, yet the research\ncommunity is now increasingly shifting focus toward post-training techniques to\nachieve further breakthroughs. While pretraining provides a broad linguistic\nfoundation, post-training methods enable LLMs to refine their knowledge,\nimprove reasoning, enhance factual accuracy, and align more effectively with\nuser intents and ethical considerations. Fine-tuning, reinforcement learning,\nand test-time scaling have emerged as critical strategies for optimizing LLMs\nperformance, ensuring robustness, and improving adaptability across various\nreal-world tasks. This survey provides a systematic exploration of\npost-training methodologies, analyzing their role in refining LLMs beyond\npretraining, addressing key challenges such as catastrophic forgetting, reward\nhacking, and inference-time trade-offs. We highlight emerging directions in\nmodel alignment, scalable adaptation, and inference-time reasoning, and outline\nfuture research directions. We also provide a public repository to continually\ntrack developments in this fast-evolving field:\nhttps://github.com/mbzuai-oryx/Awesome-LLM-Post-training.",
    "pdf_url": "http://arxiv.org/pdf/2502.21321v1",
    "published": "2025-02-28",
    "source": "arxiv",
    "id": "2502.21321v1",
    "categories": [
      "cs.CL",
      "cs.CV"
    ]
  },
  {
    "title": "TomoSelfDEQ: Self-Supervised Deep Equilibrium Learning for Sparse-Angle CT Reconstruction",
    "authors": [
      "Tatiana A. Bubba",
      "Matteo Santacesaria",
      "Andrea Sebastiani"
    ],
    "abstract": "Deep learning has emerged as a powerful tool for solving inverse problems in\nimaging, including computed tomography (CT). However, most approaches require\npaired training data with ground truth images, which can be difficult to\nobtain, e.g., in medical applications. We present TomoSelfDEQ, a\nself-supervised Deep Equilibrium (DEQ) framework for sparse-angle CT\nreconstruction that trains directly on undersampled measurements. We establish\ntheoretical guarantees showing that, under suitable assumptions, our\nself-supervised updates match those of fully-supervised training with a loss\nincluding the (possibly non-unitary) forward operator like the CT forward map.\nNumerical experiments on sparse-angle CT data confirm this finding, also\ndemonstrating that TomoSelfDEQ outperforms existing self-supervised methods,\nachieving state-of-the-art results with as few as 16 projection angles.",
    "pdf_url": "http://arxiv.org/pdf/2502.21320v1",
    "published": "2025-02-28",
    "source": "arxiv",
    "id": "2502.21320v1",
    "categories": [
      "eess.IV",
      "cs.CV"
    ]
  },
  {
    "title": "Assessing zero-shot generalisation behaviour in graph-neural-network interatomic potentials",
    "authors": [
      "Chiheb Ben Mahmoud",
      "Zakariya El-Machachi",
      "Krystian A. Gierczak",
      "John L. A. Gardner",
      "Volker L. Deringer"
    ],
    "abstract": "With the rapidly growing availability of machine-learned interatomic\npotential (MLIP) models for chemistry, much current research focuses on the\ndevelopment of generally applicable and ``foundational'' MLIPs. An important\nquestion in this context is whether, and how well, such models can transfer\nfrom one application domain to another. Here, we assess this transferability\nfor an MLIP model at the interface of materials and molecular chemistry.\nSpecifically, we study GO-MACE-23, a model designed for the extended covalent\nnetwork of graphene oxide, and quantify its zero-shot performance for small,\nisolated molecules and chemical reactions outside its direct scope--in direct\ncomparison with a state-of-the-art model which has been trained in-domain. Our\nwork provides quantitative insight into the transfer and generalisation ability\nof graph-neural-network potentials and, more generally, makes a step towards\nthe more widespread applicability of MLIPs in chemistry.",
    "pdf_url": "http://arxiv.org/pdf/2502.21317v1",
    "published": "2025-02-28",
    "source": "arxiv",
    "id": "2502.21317v1",
    "categories": [
      "physics.chem-ph",
      "cond-mat.mtrl-sci"
    ]
  },
  {
    "title": "Unsupervised Parameter Efficient Source-free Post-pretraining",
    "authors": [
      "Abhishek Jha",
      "Tinne Tuytelaars",
      "Yuki M. Asano"
    ],
    "abstract": "Following the success in NLP, the best vision models are now in the billion\nparameter ranges. Adapting these large models to a target distribution has\nbecome computationally and economically prohibitive. Addressing this challenge,\nwe introduce UpStep, an Unsupervised Parameter-efficient Source-free\npost-pretraining approach, designed to efficiently adapt a base model from a\nsource domain to a target domain: i) we design a self-supervised training\nscheme to adapt a pretrained model on an unlabeled target domain in a setting\nwhere source domain data is unavailable. Such source-free setting comes with\nthe risk of catastrophic forgetting, hence, ii) we propose center vector\nregularization (CVR), a set of auxiliary operations that minimize catastrophic\nforgetting and additionally reduces the computational cost by skipping\nbackpropagation in 50\\% of the training iterations. Finally iii) we perform\nthis adaptation process in a parameter-efficient way by adapting the pretrained\nmodel through low-rank adaptation methods, resulting in a fraction of\nparameters to optimize. We utilize various general backbone architectures, both\nsupervised and unsupervised, trained on Imagenet as our base model and adapt\nthem to a diverse set of eight target domains demonstrating the adaptability\nand generalizability of our proposed approach.",
    "pdf_url": "http://arxiv.org/pdf/2502.21313v1",
    "published": "2025-02-28",
    "source": "arxiv",
    "id": "2502.21313v1",
    "categories": [
      "cs.CV",
      "cs.LG"
    ]
  },
  {
    "title": "AutoComb: Automated Comb Sign Detector for 3D CTE Scans",
    "authors": [
      "Shashwat Gupta",
      "Sarthak Gupta",
      "Akshan Agrawal",
      "Mahim Naaz",
      "Rajanikanth Yadav",
      "Priyanka Bagade"
    ],
    "abstract": "Comb Sign is an important imaging biomarker to detect multiple\ngastrointestinal diseases. It shows up as increased blood flow along the\nintestinal wall indicating potential abnormality, which helps doctors diagnose\ninflammatory conditions. Despite its clinical significance, current detection\nmethods are manual, time-intensive, and prone to subjective interpretation due\nto the need for multi-planar image-orientation. To the best of our knowledge,\nwe are the first to propose a fully automated technique for the detection of\nComb Sign from CTE scans. Our novel approach is based on developing a\nprobabilistic map that shows areas of pathological hypervascularity by\nidentifying fine vascular bifurcations and wall enhancement via processing\nthrough stepwise algorithmic modules. These modules include utilising deep\nlearning segmentation model, a Gaussian Mixture Model (GMM), vessel extraction\nusing vesselness filter, iterative probabilistic enhancement of vesselness via\nneighborhood maximization and a distance-based weighting scheme over the\nvessels. Experimental results demonstrate that our pipeline effectively\nidentifies Comb Sign, offering an objective, accurate, and reliable tool to\nenhance diagnostic accuracy in Crohn's disease and related hypervascular\nconditions where Comb Sign is considered as one of the important biomarkers.",
    "pdf_url": "http://arxiv.org/pdf/2502.21311v1",
    "published": "2025-02-28",
    "source": "arxiv",
    "id": "2502.21311v1",
    "categories": [
      "eess.IV",
      "cs.CV"
    ]
  },
  {
    "title": "FANformer: Improving Large Language Models Through Effective Periodicity Modeling",
    "authors": [
      "Yihong Dong",
      "Ge Li",
      "Xue Jiang",
      "Yongding Tao",
      "Kechi Zhang",
      "Hao Zhu",
      "Huanyu Liu",
      "Jiazheng Ding",
      "Jia Li",
      "Jinliang Deng",
      "Hong Mei"
    ],
    "abstract": "Periodicity, as one of the most important basic characteristics, lays the\nfoundation for facilitating structured knowledge acquisition and systematic\ncognitive processes within human learning paradigms. However, the potential\nflaws of periodicity modeling in Transformer affect the learning efficiency and\nestablishment of underlying principles from data for large language models\n(LLMs) built upon it. In this paper, we demonstrate that integrating effective\nperiodicity modeling can improve the learning efficiency and performance of\nLLMs. We introduce FANformer, which integrates Fourier Analysis Network (FAN)\ninto attention mechanism to achieve efficient periodicity modeling, by\nmodifying the feature projection process of attention mechanism. Extensive\nexperimental results on language modeling show that FANformer consistently\noutperforms Transformer when scaling up model size and training tokens,\nunderscoring its superior learning efficiency. To further validate the\neffectiveness of FANformer, we pretrain a FANformer-1B on 1 trillion tokens.\nFANformer-1B exhibits marked improvements on downstream tasks compared to\nopen-source LLMs with similar model parameters or training tokens. The results\nposition FANformer as an effective and promising architecture for advancing\nLLMs.",
    "pdf_url": "http://arxiv.org/pdf/2502.21309v1",
    "published": "2025-02-28",
    "source": "arxiv",
    "id": "2502.21309v1",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ]
  },
  {
    "title": "Clustering Context in Off-Policy Evaluation",
    "authors": [
      "Daniel Guzman-Olivares",
      "Philipp Schmidt",
      "Jacek Golebiowski",
      "Artur Bekasov"
    ],
    "abstract": "Off-policy evaluation can leverage logged data to estimate the effectiveness\nof new policies in e-commerce, search engines, media streaming services, or\nautomatic diagnostic tools in healthcare. However, the performance of baseline\noff-policy estimators like IPS deteriorates when the logging policy\nsignificantly differs from the evaluation policy. Recent work proposes sharing\ninformation across similar actions to mitigate this problem. In this work, we\npropose an alternative estimator that shares information across similar\ncontexts using clustering. We study the theoretical properties of the proposed\nestimator, characterizing its bias and variance under different conditions. We\nalso compare the performance of the proposed estimator and existing approaches\nin various synthetic problems, as well as a real-world recommendation dataset.\nOur experimental results confirm that clustering contexts improves estimation\naccuracy, especially in deficient information settings.",
    "pdf_url": "http://arxiv.org/pdf/2502.21304v1",
    "published": "2025-02-28",
    "source": "arxiv",
    "id": "2502.21304v1",
    "categories": [
      "cs.LG",
      "cs.AI",
      "stat.ML"
    ]
  },
  {
    "title": "Impact of Quantum Well Thickness on Efficiency Loss in InGaN/GaN LEDs: Challenges for Thin-Well Designs",
    "authors": [
      "Xuefeng Li",
      "Nick Pant",
      "Sheikh Ifatur Rahman",
      "Rob Armitage",
      "Siddharth Rajan",
      "Emmanouil Kioupakis",
      "Daniel Feezell"
    ],
    "abstract": "We investigate the impact of quantum well (QW) thickness on efficiency loss\nin c-plane InGaN/GaN LEDs using a small-signal electroluminescence (SSEL)\ntechnique. Multiple mechanisms related to efficiency loss are independently\nexamined, including injection efficiency, carrier density vs. current density\nrelationship, phase space filling (PSF), quantum confined stark effect (QCSE),\nand Coulomb enhancement. An optimal QW thickness of around 2.7 nm in these\nInGaN/GaN LEDs was determined for quantum wells having constant In composition.\nDespite better control of deep-level defects and lower carrier density at a\ngiven current density, LEDs with thin QWs still suffer from an imbalance of\nenhancement effects on the radiative and intrinsic Auger-Meitner recombination\ncoefficients. The imbalance of enhancement effects results in a decline in\ninternal quantum efficiency (IQE) and radiative efficiency with decreasing QW\nthickness at low current density in LEDs with QW thicknesses below 2.7 nm. We\nalso investigate how LED modulation bandwidth varies with quantum well\nthickness, identifying the key trends and their implications for device\nperformance.",
    "pdf_url": "http://arxiv.org/pdf/2502.21302v1",
    "published": "2025-02-28",
    "source": "arxiv",
    "id": "2502.21302v1",
    "categories": [
      "physics.app-ph"
    ]
  },
  {
    "title": "Hybrid Team Tetris: A New Platform For Hybrid Multi-Agent, Multi-Human Teaming",
    "authors": [
      "Kaleb Mcdowell",
      "Nick Waytowich",
      "Javier Garcia",
      "Stephen Gordon",
      "Bryce Bartlett",
      "Jeremy Gaston"
    ],
    "abstract": "Metcalfe et al (1) argue that the greatest potential for human-AI\npartnerships lies in their application to highly complex problem spaces.\nHerein, we discuss three different forms of hybrid team intelligence and posit\nthat across all three forms, the hybridization of man and machine intelligence\ncan be effective under the right conditions. We foresee two significant\nresearch and development (R&D) challenges underlying the creation of effective\nhybrid intelligence. First, rapid advances in machine intelligence and/or\nfundamental changes in human behaviors or capabilities over time can outpace\nR&D. Second, the future conditions under which hybrid intelligence will operate\nare unknown, but unlikely to be the same as the conditions of today. Overcoming\nboth of these challenges requires a deep understanding of multiple\nhuman-centric and machine-centric disciplines that creates a large barrier to\nentry into the field. Herein, we outline an open, shareable research platform\nthat creates a form of hybrid team intelligence that functions under\nrepresentative future conditions. The intent for the platform is to facilitate\nnew forms of hybrid intelligence research allowing individuals with\nhuman-centric or machine-centric backgrounds to rapidly enter the field and\ninitiate research. Our hope is that through open, community research on the\nplatform, state-of-the-art advances in human and machine intelligence can\nquickly be communicated across what are currently different R&D communities and\nallow hybrid team intelligence research to stay at the forefront of scientific\nadvancement.",
    "pdf_url": "http://arxiv.org/pdf/2502.21300v1",
    "published": "2025-02-28",
    "source": "arxiv",
    "id": "2502.21300v1",
    "categories": [
      "cs.HC"
    ]
  },
  {
    "title": "Bilevel Optimized Implicit Neural Representation for Scan-Specific Accelerated MRI Reconstruction",
    "authors": [
      "Hongze Yu",
      "Jeffrey A. Fessler",
      "Yun Jiang"
    ],
    "abstract": "Deep Learning (DL) methods can reconstruct highly accelerated magnetic\nresonance imaging (MRI) scans, but they rely on application-specific large\ntraining datasets and often generalize poorly to out-of-distribution data.\nSelf-supervised deep learning algorithms perform scan-specific reconstructions,\nbut still require complicated hyperparameter tuning based on the acquisition\nand often offer limited acceleration. This work develops a bilevel-optimized\nimplicit neural representation (INR) approach for scan-specific MRI\nreconstruction. The method automatically optimizes the hyperparameters for a\ngiven acquisition protocol, enabling a tailored reconstruction without training\ndata. The proposed algorithm uses Gaussian process regression to optimize INR\nhyperparameters, accommodating various acquisitions. The INR includes a\ntrainable positional encoder for high-dimensional feature embedding and a small\nmultilayer perceptron for decoding. The bilevel optimization is computationally\nefficient, requiring only a few minutes per typical 2D Cartesian scan. On\nscanner hardware, the subsequent scan-specific reconstruction-using\noffline-optimized hyperparameters-is completed within seconds and achieves\nimproved image quality compared to previous model-based and self-supervised\nlearning methods.",
    "pdf_url": "http://arxiv.org/pdf/2502.21292v1",
    "published": "2025-02-28",
    "source": "arxiv",
    "id": "2502.21292v1",
    "categories": [
      "eess.IV",
      "eess.SP"
    ]
  },
  {
    "title": "MIGE: A Unified Framework for Multimodal Instruction-Based Image Generation and Editing",
    "authors": [
      "Xueyun Tian",
      "Wei Li",
      "Bingbing Xu",
      "Yige Yuan",
      "Yuanzhuo Wang",
      "Huawei Shen"
    ],
    "abstract": "Despite significant progress in diffusion-based image generation,\nsubject-driven generation and instruction-based editing remain challenging.\nExisting methods typically treat them separately, struggling with limited\nhigh-quality data and poor generalization. However, both tasks require\ncapturing complex visual variations while maintaining consistency between\ninputs and outputs. Therefore, we propose MIGE, a unified framework that\nstandardizes task representations using multimodal instructions. It treats\nsubject-driven generation as creation on a blank canvas and instruction-based\nediting as modification of an existing image, establishing a shared\ninput-output formulation. MIGE introduces a novel multimodal encoder that maps\nfree-form multimodal instructions into a unified vision-language space,\nintegrating visual and semantic features through a feature fusion mechanism.\nThis unification enables joint training of both tasks, providing two key\nadvantages: (1) Cross-Task Enhancement: By leveraging shared visual and\nsemantic representations, joint training improves instruction adherence and\nvisual consistency in both subject-driven generation and instruction-based\nediting. (2) Generalization: Learning in a unified format facilitates\ncross-task knowledge transfer, enabling MIGE to generalize to novel\ncompositional tasks, including instruction-based subject-driven editing.\nExperiments show that MIGE excels in both subject-driven generation and\ninstruction-based editing while setting a state-of-the-art in the new task of\ninstruction-based subject-driven editing. Code and model have been publicly\navailable at https://github.com/Eureka-Maggie/MIGE.",
    "pdf_url": "http://arxiv.org/pdf/2502.21291v2",
    "published": "2025-02-28",
    "source": "arxiv",
    "id": "2502.21291v2",
    "categories": [
      "cs.CV"
    ]
  },
  {
    "title": "Contextualizing biological perturbation experiments through language",
    "authors": [
      "Menghua Wu",
      "Russell Littman",
      "Jacob Levine",
      "Lin Qiu",
      "Tommaso Biancalani",
      "David Richmond",
      "Jan-Christian Huetter"
    ],
    "abstract": "High-content perturbation experiments allow scientists to probe biomolecular\nsystems at unprecedented resolution, but experimental and analysis costs pose\nsignificant barriers to widespread adoption. Machine learning has the potential\nto guide efficient exploration of the perturbation space and extract novel\ninsights from these data. However, current approaches neglect the semantic\nrichness of the relevant biology, and their objectives are misaligned with\ndownstream biological analyses. In this paper, we hypothesize that large\nlanguage models (LLMs) present a natural medium for representing complex\nbiological relationships and rationalizing experimental outcomes. We propose\nPerturbQA, a benchmark for structured reasoning over perturbation experiments.\nUnlike current benchmarks that primarily interrogate existing knowledge,\nPerturbQA is inspired by open problems in perturbation modeling: prediction of\ndifferential expression and change of direction for unseen perturbations, and\ngene set enrichment. We evaluate state-of-the-art machine learning and\nstatistical approaches for modeling perturbations, as well as standard LLM\nreasoning strategies, and we find that current methods perform poorly on\nPerturbQA. As a proof of feasibility, we introduce Summer (SUMMarize, retrievE,\nand answeR, a simple, domain-informed LLM framework that matches or exceeds the\ncurrent state-of-the-art. Our code and data are publicly available at\nhttps://github.com/genentech/PerturbQA.",
    "pdf_url": "http://arxiv.org/pdf/2502.21290v1",
    "published": "2025-02-28",
    "source": "arxiv",
    "id": "2502.21290v1",
    "categories": [
      "cs.AI",
      "cs.LG",
      "q-bio.QM"
    ]
  },
  {
    "title": "Enabling AutoML for Zero-Touch Network Security: Use-Case Driven Analysis",
    "authors": [
      "Li Yang",
      "Mirna El Rajab",
      "Abdallah Shami",
      "Sami Muhaidat"
    ],
    "abstract": "Zero-Touch Networks (ZTNs) represent a state-of-the-art paradigm shift\ntowards fully automated and intelligent network management, enabling the\nautomation and intelligence required to manage the complexity, scale, and\ndynamic nature of next-generation (6G) networks. ZTNs leverage Artificial\nIntelligence (AI) and Machine Learning (ML) to enhance operational efficiency,\nsupport intelligent decision-making, and ensure effective resource allocation.\nHowever, the implementation of ZTNs is subject to security challenges that need\nto be resolved to achieve their full potential. In particular, two critical\nchallenges arise: the need for human expertise in developing AI/ML-based\nsecurity mechanisms, and the threat of adversarial attacks targeting AI/ML\nmodels. In this survey paper, we provide a comprehensive review of current\nsecurity issues in ZTNs, emphasizing the need for advanced AI/ML-based security\nmechanisms that require minimal human intervention and protect AI/ML models\nthemselves. Furthermore, we explore the potential of Automated ML (AutoML)\ntechnologies in developing robust security solutions for ZTNs. Through case\nstudies, we illustrate practical approaches to securing ZTNs against both\nconventional and AI/ML-specific threats, including the development of\nautonomous intrusion detection systems and strategies to combat Adversarial ML\n(AML) attacks. The paper concludes with a discussion of the future research\ndirections for the development of ZTN security approaches.",
    "pdf_url": "http://arxiv.org/pdf/2502.21286v1",
    "published": "2025-02-28",
    "source": "arxiv",
    "id": "2502.21286v1",
    "categories": [
      "cs.CR",
      "cs.LG",
      "cs.NI",
      "68T01, 90C31",
      "I.2.1; I.2.6; C.2.0"
    ]
  },
  {
    "title": "Controlled Model Debiasing through Minimal and Interpretable Updates",
    "authors": [
      "Federico Di Gennaro",
      "Thibault Laugel",
      "Vincent Grari",
      "Marcin Detyniecki"
    ],
    "abstract": "Traditional approaches to learning fair machine learning models often require\nrebuilding models from scratch, generally without accounting for potentially\nexisting previous models. In a context where models need to be retrained\nfrequently, this can lead to inconsistent model updates, as well as redundant\nand costly validation testing. To address this limitation, we introduce the\nnotion of controlled model debiasing, a novel supervised learning task relying\non two desiderata: that the differences between new fair model and the existing\none should be (i) interpretable and (ii) minimal. After providing theoretical\nguarantees to this new problem, we introduce a novel algorithm for algorithmic\nfairness, COMMOD, that is both model-agnostic and does not require the\nsensitive attribute at test time. In addition, our algorithm is explicitly\ndesigned to enforce minimal and interpretable changes between biased and\ndebiased predictions -a property that, while highly desirable in high-stakes\napplications, is rarely prioritized as an explicit objective in fairness\nliterature. Our approach combines a concept-based architecture and adversarial\nlearning and we demonstrate through empirical results that it achieves\ncomparable performance to state-of-the-art debiasing methods while performing\nminimal and interpretable prediction changes.",
    "pdf_url": "http://arxiv.org/pdf/2502.21284v1",
    "published": "2025-02-28",
    "source": "arxiv",
    "id": "2502.21284v1",
    "categories": [
      "cs.LG",
      "stat.ML"
    ]
  },
  {
    "title": "Back to the Future Cyclopean Stereo: a human perception approach unifying deep and geometric constraints",
    "authors": [
      "Sherlon Almeida da Silva",
      "Davi Geiger",
      "Luiz Velho",
      "Moacir Antonelli Ponti"
    ],
    "abstract": "We innovate in stereo vision by explicitly providing analytical 3D surface\nmodels as viewed by a cyclopean eye model that incorporate depth\ndiscontinuities and occlusions. This geometrical foundation combined with\nlearned stereo features allows our system to benefit from the strengths of both\napproaches. We also invoke a prior monocular model of surfaces to fill in\nocclusion regions or texture-less regions where data matching is not\nsufficient. Our results already are on par with the state-of-the-art purely\ndata-driven methods and are of much better visual quality, emphasizing the\nimportance of the 3D geometrical model to capture critical visual information.\nSuch qualitative improvements may find applicability in virtual reality, for a\nbetter human experience, as well as in robotics, for reducing critical errors.\nOur approach aims to demonstrate that understanding and modeling geometrical\nproperties of 3D surfaces is beneficial to computer vision research.",
    "pdf_url": "http://arxiv.org/pdf/2502.21280v1",
    "published": "2025-02-28",
    "source": "arxiv",
    "id": "2502.21280v1",
    "categories": [
      "cs.CV"
    ]
  },
  {
    "title": "L-Lipschitz Gershgorin ResNet Network",
    "authors": [
      "Marius F. R. Juston",
      "William R. Norris",
      "Dustin Nottage",
      "Ahmet Soylemezoglu"
    ],
    "abstract": "Deep residual networks (ResNets) have demonstrated outstanding success in\ncomputer vision tasks, attributed to their ability to maintain gradient flow\nthrough deep architectures. Simultaneously, controlling the Lipschitz bound in\nneural networks has emerged as an essential area of research for enhancing\nadversarial robustness and network certifiability. This paper uses a rigorous\napproach to design $\\mathcal{L}$-Lipschitz deep residual networks using a\nLinear Matrix Inequality (LMI) framework. The ResNet architecture was\nreformulated as a pseudo-tri-diagonal LMI with off-diagonal elements and\nderived closed-form constraints on network parameters to ensure\n$\\mathcal{L}$-Lipschitz continuity. To address the lack of explicit eigenvalue\ncomputations for such matrix structures, the Gershgorin circle theorem was\nemployed to approximate eigenvalue locations, guaranteeing the LMI's negative\nsemi-definiteness. Our contributions include a provable parameterization\nmethodology for constructing Lipschitz-constrained networks and a compositional\nframework for managing recursive systems within hierarchical architectures.\nThese findings enable robust network designs applicable to adversarial\nrobustness, certified training, and control systems. However, a limitation was\nidentified in the Gershgorin-based approximations, which over-constrain the\nsystem, suppressing non-linear dynamics and diminishing the network's\nexpressive capacity.",
    "pdf_url": "http://arxiv.org/pdf/2502.21279v1",
    "published": "2025-02-28",
    "source": "arxiv",
    "id": "2502.21279v1",
    "categories": [
      "cs.LG",
      "cs.AI"
    ]
  },
  {
    "title": "Does Generation Require Memorization? Creative Diffusion Models using Ambient Diffusion",
    "authors": [
      "Kulin Shah",
      "Alkis Kalavasis",
      "Adam R. Klivans",
      "Giannis Daras"
    ],
    "abstract": "There is strong empirical evidence that the state-of-the-art diffusion\nmodeling paradigm leads to models that memorize the training set, especially\nwhen the training set is small. Prior methods to mitigate the memorization\nproblem often lead to a decrease in image quality. Is it possible to obtain\nstrong and creative generative models, i.e., models that achieve high\ngeneration quality and low memorization? Despite the current pessimistic\nlandscape of results, we make significant progress in pushing the trade-off\nbetween fidelity and memorization. We first provide theoretical evidence that\nmemorization in diffusion models is only necessary for denoising problems at\nlow noise scales (usually used in generating high-frequency details). Using\nthis theoretical insight, we propose a simple, principled method to train the\ndiffusion models using noisy data at large noise scales. We show that our\nmethod significantly reduces memorization without decreasing the image quality,\nfor both text-conditional and unconditional models and for a variety of data\navailability settings.",
    "pdf_url": "http://arxiv.org/pdf/2502.21278v1",
    "published": "2025-02-28",
    "source": "arxiv",
    "id": "2502.21278v1",
    "categories": [
      "cs.LG",
      "stat.ML"
    ]
  },
  {
    "title": "Boosting Prediction with Data Missing Not at Random",
    "authors": [
      "Yuan Bian",
      "Grace Y. Yi",
      "Wenqing He"
    ],
    "abstract": "Boosting has emerged as a useful machine learning technique over the past\nthree decades, attracting increased attention. Most advancements in this area,\nhowever, have primarily focused on numerical implementation procedures, often\nlacking rigorous theoretical justifications. Moreover, these approaches are\ngenerally designed for datasets with fully observed data, and their validity\ncan be compromised by the presence of missing observations. In this paper, we\nemploy semiparametric estimation approaches to develop boosting prediction\nmethods for data with missing responses. We explore two strategies for\nadjusting the loss functions to account for missingness effects. The proposed\nmethods are implemented using a functional gradient descent algorithm, and\ntheir theoretical properties, including algorithm convergence and estimator\nconsistency, are rigorously established. Numerical studies demonstrate that the\nproposed methods perform well in finite sample settings.",
    "pdf_url": "http://arxiv.org/pdf/2502.21276v1",
    "published": "2025-02-28",
    "source": "arxiv",
    "id": "2502.21276v1",
    "categories": [
      "stat.ME"
    ]
  },
  {
    "title": "Utilizing Quantum Fingerprints in Plant Cells to Evaluate Plant productivity",
    "authors": [
      "Umadini Ranasinghe",
      "Abigail L. Stressinger",
      "Guangpeng Xu",
      "Yasmin Sarhan",
      "Fred Harrington",
      "James Berry",
      "Tim Thomay"
    ],
    "abstract": "Overcoming the strong chlorophyll background poses a significant challenge\nfor measuring and optimizing plant growth. This research investigates the novel\napplication of specialized quantum light emitters introduced into intact leaves\nof tobacco (Nicotiana tabacum), a well-characterized model plant system for\nstudies of plant health and productivity. Leaves were harvested from plants\ncultivated under two distinct conditions: low light (LL), representing\nunhealthy leaves with reduced photosynthesis. and high light (HL), representing\nhealthy leaves with highly active photosynthesis. Higher-order correlation data\nwere collected and analyzed using machine learning (ML) techniques,\nspecifically a Convolutional Neural Network (CNN), to classify the photon\nemitter states. This CNN efficiently identified unique patterns and created\ndistinct fingerprints for Nicotiana leaves grown under LL and HL, demonstrating\nsignificantly different quantum profiles between the two conditions. These\nquantum fingerprints serve as a foundation for a novel unified analysis of\nplant growth parameters associated with different photosynthetic states. By\nemploying CNN, the emitter profiles were able to reproducibly classify the\nleaves as healthy or unhealthy. This model achieved high probability values for\neach classification, confirming its accuracy and reliability. The findings of\nthis study pave the way for broader applications, including the application of\nadvanced quantum and machine learning technologies in plant health monitoring\nsystems.",
    "pdf_url": "http://arxiv.org/pdf/2502.21275v1",
    "published": "2025-02-28",
    "source": "arxiv",
    "id": "2502.21275v1",
    "categories": [
      "physics.bio-ph"
    ]
  },
  {
    "title": "BAnG: Bidirectional Anchored Generation for Conditional RNA Design",
    "authors": [
      "Roman Klypa",
      "Alberto Bietti",
      "Sergei Grudinin"
    ],
    "abstract": "Designing RNA molecules that interact with specific proteins is a critical\nchallenge in experimental and computational biology. Existing computational\napproaches require a substantial amount of experimentally determined RNA\nsequences for each specific protein or a detailed knowledge of RNA structure,\nrestricting their utility in practice. To address this limitation, we develop\nRNA-BAnG, a deep learning-based model designed to generate RNA sequences for\nprotein interactions without these requirements. Central to our approach is a\nnovel generative method, Bidirectional Anchored Generation (BAnG), which\nleverages the observation that protein-binding RNA sequences often contain\nfunctional binding motifs embedded within broader sequence contexts. We first\nvalidate our method on generic synthetic tasks involving similar localized\nmotifs to those appearing in RNAs, demonstrating its benefits over existing\ngenerative approaches. We then evaluate our model on biological sequences,\nshowing its effectiveness for conditional RNA sequence design given a binding\nprotein.",
    "pdf_url": "http://arxiv.org/pdf/2502.21274v1",
    "published": "2025-02-28",
    "source": "arxiv",
    "id": "2502.21274v1",
    "categories": [
      "cs.LG",
      "cs.AI",
      "q-bio.BM"
    ]
  },
  {
    "title": "Adaptive Keyframe Sampling for Long Video Understanding",
    "authors": [
      "Xi Tang",
      "Jihao Qiu",
      "Lingxi Xie",
      "Yunjie Tian",
      "Jianbin Jiao",
      "Qixiang Ye"
    ],
    "abstract": "Multimodal large language models (MLLMs) have enabled open-world visual\nunderstanding by injecting visual input as extra tokens into large language\nmodels (LLMs) as contexts. However, when the visual input changes from a single\nimage to a long video, the above paradigm encounters difficulty because the\nvast amount of video tokens has significantly exceeded the maximal capacity of\nMLLMs. Therefore, existing video-based MLLMs are mostly established upon\nsampling a small portion of tokens from input data, which can cause key\ninformation to be lost and thus produce incorrect answers. This paper presents\na simple yet effective algorithm named Adaptive Keyframe Sampling (AKS). It\ninserts a plug-and-play module known as keyframe selection, which aims to\nmaximize the useful information with a fixed number of video tokens. We\nformulate keyframe selection as an optimization involving (1) the relevance\nbetween the keyframes and the prompt, and (2) the coverage of the keyframes\nover the video, and present an adaptive algorithm to approximate the best\nsolution. Experiments on two long video understanding benchmarks validate that\nAdaptive Keyframe Sampling improves video QA accuracy (beyond strong baselines)\nupon selecting informative keyframes. Our study reveals the importance of\ninformation pre-filtering in video-based MLLMs. Code is available at\nhttps://github.com/ncTimTang/AKS.",
    "pdf_url": "http://arxiv.org/pdf/2502.21271v1",
    "published": "2025-02-28",
    "source": "arxiv",
    "id": "2502.21271v1",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG"
    ]
  },
  {
    "title": "Dynamical Decoupling of Generalization and Overfitting in Large Two-Layer Networks",
    "authors": [
      "Andrea Montanari",
      "Pierfrancesco Urbani"
    ],
    "abstract": "The inductive bias and generalization properties of large machine learning\nmodels are -- to a substantial extent -- a byproduct of the optimization\nalgorithm used for training. Among others, the scale of the random\ninitialization, the learning rate, and early stopping all have crucial impact\non the quality of the model learnt by stochastic gradient descent or related\nalgorithms. In order to understand these phenomena, we study the training\ndynamics of large two-layer neural networks. We use a well-established\ntechnique from non-equilibrium statistical physics (dynamical mean field\ntheory) to obtain an asymptotic high-dimensional characterization of this\ndynamics. This characterization applies to a Gaussian approximation of the\nhidden neurons non-linearity, and empirically captures well the behavior of\nactual neural network models.\n  Our analysis uncovers several interesting new phenomena in the training\ndynamics: $(i)$ The emergence of a slow time scale associated with the growth\nin Gaussian/Rademacher complexity; $(ii)$ As a consequence, algorithmic\ninductive bias towards small complexity, but only if the initialization has\nsmall enough complexity; $(iii)$ A separation of time scales between feature\nlearning and overfitting; $(iv)$ A non-monotone behavior of the test error and,\ncorrespondingly, a `feature unlearning' phase at large times.",
    "pdf_url": "http://arxiv.org/pdf/2502.21269v1",
    "published": "2025-02-28",
    "source": "arxiv",
    "id": "2502.21269v1",
    "categories": [
      "stat.ML",
      "cond-mat.dis-nn",
      "cs.LG"
    ]
  },
  {
    "title": "Supporting the development of Machine Learning for fundamental science in a federated Cloud with the AI_INFN platform",
    "authors": [
      "Lucio Anderlini",
      "Matteo Barbetti",
      "Giulio Bianchini",
      "Diego Ciangottini",
      "Stefano Dal Pra",
      "Diego Michelotto",
      "Carmelo Pellegrino",
      "Rosa Petrini",
      "Alessandro Pascolini",
      "Daniele Spiga"
    ],
    "abstract": "Machine Learning (ML) is driving a revolution in the way scientists design,\ndevelop, and deploy data-intensive software. However, the adoption of ML\npresents new challenges for the computing infrastructure, particularly in terms\nof provisioning and orchestrating access to hardware accelerators for\ndevelopment, testing, and production. The INFN-funded project AI_INFN\n(\"Artificial Intelligence at INFN\") aims at fostering the adoption of ML\ntechniques within INFN use cases by providing support on multiple aspects,\nincluding the provision of AI-tailored computing resources. It leverages\ncloud-native solutions in the context of INFN Cloud, to share hardware\naccelerators as effectively as possible, ensuring the diversity of the\nInstitute's research activities is not compromised. In this contribution, we\nprovide an update on the commissioning of a Kubernetes platform designed to\nease the development of GPU-powered data analysis workflows and their\nscalability on heterogeneous, distributed computing resources, possibly\nfederated as Virtual Kubelets with the interLink provider.",
    "pdf_url": "http://arxiv.org/pdf/2502.21266v1",
    "published": "2025-02-28",
    "source": "arxiv",
    "id": "2502.21266v1",
    "categories": [
      "cs.DC",
      "cs.AI",
      "physics.data-an"
    ]
  },
  {
    "title": "ReaLJam: Real-Time Human-AI Music Jamming with Reinforcement Learning-Tuned Transformers",
    "authors": [
      "Alexander Scarlatos",
      "Yusong Wu",
      "Ian Simon",
      "Adam Roberts",
      "Tim Cooijmans",
      "Natasha Jaques",
      "Cassie Tarakajian",
      "Cheng-Zhi Anna Huang"
    ],
    "abstract": "Recent advances in generative artificial intelligence (AI) have created\nmodels capable of high-quality musical content generation. However, little\nconsideration is given to how to use these models for real-time or cooperative\njamming musical applications because of crucial required features: low latency,\nthe ability to communicate planned actions, and the ability to adapt to user\ninput in real-time. To support these needs, we introduce ReaLJam, an interface\nand protocol for live musical jamming sessions between a human and a\nTransformer-based AI agent trained with reinforcement learning. We enable\nreal-time interactions using the concept of anticipation, where the agent\ncontinually predicts how the performance will unfold and visually conveys its\nplan to the user. We conduct a user study where experienced musicians jam in\nreal-time with the agent through ReaLJam. Our results demonstrate that ReaLJam\nenables enjoyable and musically interesting sessions, and we uncover important\ntakeaways for future work.",
    "pdf_url": "http://arxiv.org/pdf/2502.21267v1",
    "published": "2025-02-28",
    "source": "arxiv",
    "id": "2502.21267v1",
    "categories": [
      "cs.HC",
      "cs.AI"
    ]
  },
  {
    "title": "Token-level Ensembling of Models with Different Vocabularies",
    "authors": [
      "Rachel Wicks",
      "Kartik Ravisankar",
      "Xinchen Yang",
      "Philipp Koehn",
      "Matt Post"
    ],
    "abstract": "Model ensembling is a technique to combine the predicted distributions of two\nor more models, often leading to improved robustness and performance. For\nensembling in text generation, the next token's probability distribution is\nderived from a weighted sum of the distributions of each individual model. This\nrequires the underlying models to share the same subword vocabulary, limiting\nthe applicability of ensembling, since many open-sourced models have distinct\nvocabularies. In research settings, experimentation or upgrades to vocabularies\nmay introduce multiple vocabulary sizes. This paper proposes an inference-time\nonly algorithm that allows for ensembling models with different vocabularies,\nwithout the need to learn additional parameters or alter the underlying models.\nInstead, the algorithm ensures that tokens generated by the ensembled models\n\\textit{agree} in their surface form. We apply this technique to combinations\nof traditional encoder-decoder models and decoder-only LLMs and evaluate on\nmachine translation. In addition to expanding to model pairs that were\npreviously incapable of token-level ensembling, our algorithm frequently\nimproves translation performance over either model individually.",
    "pdf_url": "http://arxiv.org/pdf/2502.21265v1",
    "published": "2025-02-28",
    "source": "arxiv",
    "id": "2502.21265v1",
    "categories": [
      "cs.CL"
    ]
  },
  {
    "title": "Foundation Models -- A Panacea for Artificial Intelligence in Pathology?",
    "authors": [
      "Nita Mulliqi",
      "Anders Blilie",
      "Xiaoyi Ji",
      "Kelvin Szolnoky",
      "Henrik Olsson",
      "Sol Erika Boman",
      "Matteo Titus",
      "Geraldine Martinez Gonzalez",
      "Julia Anna Mielcarz",
      "Masi Valkonen",
      "Einar Gudlaugsson",
      "Svein R. Kjosavik",
      "José Asenjo",
      "Marcello Gambacorta",
      "Paolo Libretti",
      "Marcin Braun",
      "Radzislaw Kordek",
      "Roman Łowicki",
      "Kristina Hotakainen",
      "Päivi Väre",
      "Bodil Ginnerup Pedersen",
      "Karina Dalsgaard Sørensen",
      "Benedicte Parm Ulhøi",
      "Pekka Ruusuvuori",
      "Brett Delahunt",
      "Hemamali Samaratunga",
      "Toyonori Tsuzuki",
      "Emilius A. M. Janssen",
      "Lars Egevad",
      "Martin Eklund",
      "Kimmo Kartasalo"
    ],
    "abstract": "The role of artificial intelligence (AI) in pathology has evolved from aiding\ndiagnostics to uncovering predictive morphological patterns in whole slide\nimages (WSIs). Recently, foundation models (FMs) leveraging self-supervised\npre-training have been widely advocated as a universal solution for diverse\ndownstream tasks. However, open questions remain about their clinical\napplicability and generalization advantages over end-to-end learning using\ntask-specific (TS) models. Here, we focused on AI with clinical-grade\nperformance for prostate cancer diagnosis and Gleason grading. We present the\nlargest validation of AI for this task, using over 100,000 core needle biopsies\nfrom 7,342 patients across 15 sites in 11 countries. We compared two FMs with a\nfully end-to-end TS model in a multiple instance learning framework. Our\nfindings challenge assumptions that FMs universally outperform TS models. While\nFMs demonstrated utility in data-scarce scenarios, their performance converged\nwith - and was in some cases surpassed by - TS models when sufficient labeled\ntraining data were available. Notably, extensive task-specific training\nmarkedly reduced clinically significant misgrading, misdiagnosis of challenging\nmorphologies, and variability across different WSI scanners. Additionally, FMs\nused up to 35 times more energy than the TS model, raising concerns about their\nsustainability. Our results underscore that while FMs offer clear advantages\nfor rapid prototyping and research, their role as a universal solution for\nclinically applicable medical AI remains uncertain. For high-stakes clinical\napplications, rigorous validation and consideration of task-specific training\nremain critically important. We advocate for integrating the strengths of FMs\nand end-to-end learning to achieve robust and resource-efficient AI pathology\nsolutions fit for clinical use.",
    "pdf_url": "http://arxiv.org/pdf/2502.21264v2",
    "published": "2025-02-28",
    "source": "arxiv",
    "id": "2502.21264v2",
    "categories": [
      "cs.CV",
      "cs.AI"
    ]
  },
  {
    "title": "RuCCoD: Towards Automated ICD Coding in Russian",
    "authors": [
      "Aleksandr Nesterov",
      "Andrey Sakhovskiy",
      "Ivan Sviridov",
      "Airat Valiev",
      "Vladimir Makharev",
      "Petr Anokhin",
      "Galina Zubkova",
      "Elena Tutubalina"
    ],
    "abstract": "This study investigates the feasibility of automating clinical coding in\nRussian, a language with limited biomedical resources. We present a new dataset\nfor ICD coding, which includes diagnosis fields from electronic health records\n(EHRs) annotated with over 10,000 entities and more than 1,500 unique ICD\ncodes. This dataset serves as a benchmark for several state-of-the-art models,\nincluding BERT, LLaMA with LoRA, and RAG, with additional experiments examining\ntransfer learning across domains (from PubMed abstracts to medical diagnosis)\nand terminologies (from UMLS concepts to ICD codes). We then apply the\nbest-performing model to label an in-house EHR dataset containing patient\nhistories from 2017 to 2021. Our experiments, conducted on a carefully curated\ntest set, demonstrate that training with the automated predicted codes leads to\na significant improvement in accuracy compared to manually annotated data from\nphysicians. We believe our findings offer valuable insights into the potential\nfor automating clinical coding in resource-limited languages like Russian,\nwhich could enhance clinical efficiency and data accuracy in these contexts.",
    "pdf_url": "http://arxiv.org/pdf/2502.21263v1",
    "published": "2025-02-28",
    "source": "arxiv",
    "id": "2502.21263v1",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.DB"
    ]
  },
  {
    "title": "Modeling Human Beliefs about AI Behavior for Scalable Oversight",
    "authors": [
      "Leon Lang",
      "Patrick Forré"
    ],
    "abstract": "Contemporary work in AI alignment often relies on human feedback to teach AI\nsystems human preferences and values. Yet as AI systems grow more capable,\nhuman feedback becomes increasingly unreliable. This raises the problem of\nscalable oversight: How can we supervise AI systems that exceed human\ncapabilities? In this work, we propose to model the human evaluator's beliefs\nabout the AI system's behavior to better interpret the human's feedback. We\nformalize human belief models and theoretically analyze their role in inferring\nhuman values. We then characterize the remaining ambiguity in this inference\nand conditions for which the ambiguity disappears. To mitigate reliance on\nexact belief models, we then introduce the relaxation of human belief model\ncovering. Finally, we propose using foundation models to construct covering\nbelief models, providing a new potential approach to scalable oversight.",
    "pdf_url": "http://arxiv.org/pdf/2502.21262v1",
    "published": "2025-02-28",
    "source": "arxiv",
    "id": "2502.21262v1",
    "categories": [
      "cs.AI",
      "cs.LG"
    ]
  },
  {
    "title": "Observations of UX Ori in deep minima with the Nordic Optical Telescope. I. Analysis of spectral lines",
    "authors": [
      "L. V. Tambovtseva",
      "A. A. Djupvik",
      "V. P. Grinin",
      "H. Weber",
      "H. Bengtsson",
      "H. De Angelis",
      "G. Duszanowicz",
      "D. Heinonen",
      "L. Hermansson",
      "G. Holmberg",
      "T. Karlsson",
      "M. Larsson",
      "J. Warell",
      "T. Wikander"
    ],
    "abstract": "UX Orionis stars are the most active young stars; they undergo sporadic\nfadings of 2 - 4 magnitudes in the V-band, due to variable circumstellar\nextinction caused by a nearly edge-on star-disc system. The long-lasting\nmonitoring of a number of stars of this type with the Nordic Optical Telescope\nfrom 2019 to 2024 has given a rich collection of material of high-resolution (R\n~ 25000) spectra obtained during different brightness states of the stars. In\nthis paper, we present the results of observations for UX Ori itself. Until now\nonly one spectrum of high resolution had been obtained for this star during\nbrightness minimum, making it difficult to do a comprehensive analysis. Our aim\nis to analyse how different spectral lines change during such irregular fading\nevents, when the star is going in and out of eclipses, obscured by dust along\nthe line of sight. For this purpose we provide a comparative analysis of the\nprofiles and equivalent widths of the spectral lines belonging to the different\natoms and ions. In addition we compare the results for UX Ori with those made\nfor another target in our sample: RR Tau. Common features of variability are\nrevealed: 1) a strengthening of the H-alpha line relatively to the continuum\nduring eclipses; 2) the appearance of additional emission on the frequencies of\nphotospheric lines (e.g. Fe II, Ca II, Si II). The different behaviour of the\nspectral lines during fading found for UX Ori and RR Tau may be caused by two\neffects: a different contribution of the scattered light to the stellar flux\nduring eclipses or a less intense disc wind of UX Ori.",
    "pdf_url": "http://arxiv.org/pdf/2502.21261v1",
    "published": "2025-02-28",
    "source": "arxiv",
    "id": "2502.21261v1",
    "categories": [
      "astro-ph.SR"
    ]
  },
  {
    "title": "ALVI Interface: Towards Full Hand Motion Decoding for Amputees Using sEMG",
    "authors": [
      "Aleksandr Kovalev",
      "Anna Makarova",
      "Petr Chizhov",
      "Matvey Antonov",
      "Gleb Duplin",
      "Vladislav Lomtev",
      "Viacheslav Gostevskii",
      "Vladimir Bessonov",
      "Andrey Tsurkan",
      "Mikhail Korobok",
      "Aleksejs Timčenko"
    ],
    "abstract": "We present a system for decoding hand movements using surface EMG signals.\nThe interface provides real-time (25 Hz) reconstruction of finger joint angles\nacross 20 degrees of freedom, designed for upper limb amputees. Our offline\nanalysis shows 0.8 correlation between predicted and actual hand movements. The\nsystem functions as an integrated pipeline with three key components: (1) a\nVR-based data collection platform, (2) a transformer-based model for\nEMG-to-motion transformation, and (3) a real-time calibration and feedback\nmodule called ALVI Interface. Using eight sEMG sensors and a VR training\nenvironment, users can control their virtual hand down to finger joint movement\nprecision, as demonstrated in our video: youtube link.",
    "pdf_url": "http://arxiv.org/pdf/2502.21256v1",
    "published": "2025-02-28",
    "source": "arxiv",
    "id": "2502.21256v1",
    "categories": [
      "cs.LG",
      "q-bio.NC"
    ]
  },
  {
    "title": "Corrected values of turbulence generated by general geothermal convection in deep Mediterranean waters",
    "authors": [
      "Hans van Haren"
    ],
    "abstract": "A correction by a reduction factor O(100) is proposed for previously\ncalculated turbulence values on unresolved convection-overturns induced by\ngeneral geothermal heating in the deep Western Mediterranean. The correction\nincludes modified application of reordering method for calculating turbulence\nvalues in convection turbulence with and without stratification above or below.\nThe result is improved correspondence between geophysical determined heat flow\nthrough the seafloor and turbulence kinetic energy dissipation rate determined\nfrom high-resolution temperature sensors moored over 109 m in the overlying\nwaters, with an average mixing coefficient of 0.5.",
    "pdf_url": "http://arxiv.org/pdf/2502.21254v1",
    "published": "2025-02-28",
    "source": "arxiv",
    "id": "2502.21254v1",
    "categories": [
      "physics.ao-ph"
    ]
  },
  {
    "title": "Learning-Driven Annealing with Adaptive Hamiltonian Modification for Solving Large-Scale Problems on Quantum Devices",
    "authors": [
      "Sebastian Schulz",
      "Dennis Willsch",
      "Kristel Michielsen"
    ],
    "abstract": "We present Learning-Driven Annealing (LDA), a framework that links individual\nquantum annealing evolutions into a global solution strategy to mitigate\nhardware constraints such as short annealing times and integrated control\nerrors. Unlike other iterative methods, LDA does not tune the annealing\nprocedure (e.g. annealing time or annealing schedule), but instead learns about\nthe problem structure to adaptively modify the problem Hamiltonian. By\ndeforming the instantaneous energy spectrum, LDA suppresses transitions into\nhigh-energy states and focuses the evolution into low-energy regions of the\nHilbert space. We demonstrate the efficacy of LDA by developing a hybrid\nquantum-classical solver for large-scale spin glasses. The hybrid solver is\nbased on a comprehensive study of the internal structure of spin glasses,\noutperforming other quantum and classical algorithms (e.g., reverse annealing,\ncyclic annealing, simulated annealing, Gurobi, Toshiba's SBM, VeloxQ and D-Wave\nhybrid) on 5580-qubit problem instances in both runtime and lowest energy. LDA\nis a step towards practical quantum computation that enables today's quantum\ndevices to compete with classical solvers.",
    "pdf_url": "http://arxiv.org/pdf/2502.21246v1",
    "published": "2025-02-28",
    "source": "arxiv",
    "id": "2502.21246v1",
    "categories": [
      "quant-ph"
    ]
  },
  {
    "title": "TimesBERT: A BERT-Style Foundation Model for Time Series Understanding",
    "authors": [
      "Haoran Zhang",
      "Yong Liu",
      "Yunzhong Qiu",
      "Haixuan Liu",
      "Zhongyi Pei",
      "Jianmin Wang",
      "Mingsheng Long"
    ],
    "abstract": "Time series analysis is crucial in diverse scenarios. Beyond forecasting,\nconsiderable real-world tasks are categorized into classification, imputation,\nand anomaly detection, underscoring different capabilities termed time series\nunderstanding in this paper. While GPT-style models have been positioned as\nfoundation models for time series forecasting, the BERT-style architecture,\nwhich has made significant advances in natural language understanding, has not\nbeen fully unlocked for time series understanding, possibly attributed to the\nundesirable dropout of essential elements of BERT. In this paper, inspired by\nthe shared multi-granularity structure between multivariate time series and\nmultisentence documents, we design TimesBERT to learn generic representations\nof time series including temporal patterns and variate-centric characteristics.\nIn addition to a natural adaptation of masked modeling, we propose a parallel\ntask of functional token prediction to embody vital multi-granularity\nstructures. Our model is pre-trained on 260 billion time points across diverse\ndomains. Leveraging multi-granularity representations, TimesBERT achieves\nstate-of-the-art performance across four typical downstream understanding\ntasks, outperforming task-specific models and language pre-trained backbones,\npositioning it as a versatile foundation model for time series understanding.",
    "pdf_url": "http://arxiv.org/pdf/2502.21245v1",
    "published": "2025-02-28",
    "source": "arxiv",
    "id": "2502.21245v1",
    "categories": [
      "cs.LG"
    ]
  },
  {
    "title": "Anatomically-guided masked autoencoder pre-training for aneurysm detection",
    "authors": [
      "Alberto Mario Ceballos-Arroyo",
      "Jisoo Kim",
      "Chu-Hsuan Lin",
      "Lei Qin",
      "Geoffrey S. Young",
      "Huaizu Jiang"
    ],
    "abstract": "Intracranial aneurysms are a major cause of morbidity and mortality\nworldwide, and detecting them manually is a complex, time-consuming task.\nAlbeit automated solutions are desirable, the limited availability of training\ndata makes it difficult to develop such solutions using typical supervised\nlearning frameworks. In this work, we propose a novel pre-training strategy\nusing more widely available unannotated head CT scan data to pre-train a 3D\nVision Transformer model prior to fine-tuning for the aneurysm detection task.\nSpecifically, we modify masked auto-encoder (MAE) pre-training in the following\nways: we use a factorized self-attention mechanism to make 3D attention\ncomputationally viable, we restrict the masked patches to areas near arteries\nto focus on areas where aneurysms are likely to occur, and we reconstruct not\nonly CT scan intensity values but also artery distance maps, which describe the\ndistance between each voxel and the closest artery, thereby enhancing the\nbackbone's learned representations. Compared with SOTA aneurysm detection\nmodels, our approach gains +4-8% absolute Sensitivity at a false positive rate\nof 0.5. Code and weights will be released.",
    "pdf_url": "http://arxiv.org/pdf/2502.21244v1",
    "published": "2025-02-28",
    "source": "arxiv",
    "id": "2502.21244v1",
    "categories": [
      "cs.CV"
    ]
  },
  {
    "title": "The Structural Complexity of Matrix-Vector Multiplication",
    "authors": [
      "Emile Anand",
      "Jan van den Brand",
      "Rose McCarty"
    ],
    "abstract": "We consider the problem of preprocessing an $n\\times n$ matrix M, and\nsupporting queries that, for any vector v, returns the matrix-vector product\nMv. This problem has been extensively studied in both theory and practice: on\none side, practitioners have developed algorithms that are highly efficient in\npractice, whereas theoreticians have proven that the problem cannot be solved\nfaster than naive multiplication in the worst-case. This lower bound holds even\nin the average-case, implying that existing average-case analyses cannot\nexplain this gap between theory and practice. Therefore, we study the problem\nfor structured matrices. We show that for $n\\times n$ matrices of VC-dimension\nd, the matrix-vector multiplication problem can be solved with $\\tilde{O}(n^2)$\npreprocessing and $\\tilde O(n^{2-1/d})$ query time. Given the low constant\nVC-dimensions observed in most real-world data, our results posit an\nexplanation for why the problem can be solved so much faster in practice.\nMoreover, our bounds hold even if the matrix does not have a low VC-dimension,\nbut is obtained by (possibly adversarially) corrupting at most a subquadratic\nnumber of entries of any unknown low VC-dimension matrix. Our results yield the\nfirst non-trivial upper bounds for many applications. In previous works, the\nonline matrix-vector hypothesis (conjecturing that quadratic time is needed per\nquery) was used to prove many conditional lower bounds, showing that it is\nimpossible to compute and maintain high-accuracy estimates for shortest paths,\nLaplacian solvers, effective resistance, and triangle detection in graphs\nsubject to node insertions and deletions in subquadratic time. Yet, via a\nreduction to our matrix-vector-multiplication result, we show we can maintain\nthe aforementioned problems efficiently if the input is structured, providing\nthe first subquadratic upper bounds in the high-accuracy regime.",
    "pdf_url": "http://arxiv.org/pdf/2502.21240v1",
    "published": "2025-02-28",
    "source": "arxiv",
    "id": "2502.21240v1",
    "categories": [
      "cs.DS",
      "cs.CC",
      "cs.CG",
      "cs.LG",
      "65F05",
      "F.2.1"
    ]
  },
  {
    "title": "Structure and Dynamics of Deep Eutectic Systems from Cluster-Optimized Energy Functions",
    "authors": [
      "Kai Töpfer",
      "Jingchun Wang",
      "Shimoni Patel",
      "Markus Meuwly"
    ],
    "abstract": "Generating energy functions for heterogeneous systems suitable for\nquantitative and predictive atomistic simulations is a challenging undertaking.\nThe present work combines a cluster-based approach with electronic structure\ncalculations at the density functional theory level and machine learning-based\nenergy functions for a spectroscopic reporter for eutectic mixtures consisting\nof water, acetamide and KSCN. Two water models are considered: TIP3P which is\nconsistent with the CGenFF energy function and TIP4P which - as a water model -\nis superior to TIP4P. Both fitted models, {\\bf M2$^{\\rm TIP3P}$} and {\\bf\n  M2$^{\\rm TIP4P}$}, yield favourable thermodynamic, structural, spectroscopic\nand transport properties from extensive molecular dynamics simulations. In\nparticular, the slow and fast decay times from 2-dimensional infrared\nspectroscopy and the viscosity for water-rich mixtures are described\nrealistically and consistent with experiments. On the other hand, including the\nco-solvent (acetamide) in the present case is expected to further improve the\ncomputed viscosity for low-water content. It is concluded that such a\ncluster-based approach is a promising and generalizable route for routine\nparametrization of heterogeneous, electrostatically dominated systems.",
    "pdf_url": "http://arxiv.org/pdf/2502.21233v1",
    "published": "2025-02-28",
    "source": "arxiv",
    "id": "2502.21233v1",
    "categories": [
      "physics.chem-ph"
    ]
  },
  {
    "title": "ByteScale: Efficient Scaling of LLM Training with a 2048K Context Length on More Than 12,000 GPUs",
    "authors": [
      "Hao Ge",
      "Junda Feng",
      "Qi Huang",
      "Fangcheng Fu",
      "Xiaonan Nie",
      "Lei Zuo",
      "Haibin Lin",
      "Bin Cui",
      "Xin Liu"
    ],
    "abstract": "Scaling long-context ability is essential for Large Language Models (LLMs).\nTo amortize the memory consumption across multiple devices in long-context\ntraining, inter-data partitioning (a.k.a. Data Parallelism) and intra-data\npartitioning (a.k.a. Context Parallelism) are commonly used. Current training\nframeworks predominantly treat the two techniques as orthogonal, and establish\nstatic communication groups to organize the devices as a static mesh (e.g., a\n2D mesh). However, the sequences for LLM training typically vary in lengths, no\nmatter for texts, multi-modalities or reinforcement learning. The mismatch\nbetween data heterogeneity and static mesh causes redundant communication and\nimbalanced computation, degrading the training efficiency.\n  In this work, we introduce ByteScale, an efficient, flexible, and scalable\nLLM training framework for large-scale mixed training of long and short\nsequences. The core of ByteScale is a novel parallelism strategy, namely Hybrid\nData Parallelism (HDP), which unifies the inter- and intra-data partitioning\nwith a dynamic mesh design. In particular, we build a communication optimizer,\nwhich eliminates the redundant communication for short sequences by data-aware\nsharding and dynamic communication, and further compresses the communication\ncost for long sequences by selective offloading. Besides, we also develop a\nbalance scheduler to mitigate the imbalanced computation by parallelism-aware\ndata assignment. We evaluate ByteScale with the model sizes ranging from 7B to\n141B, context lengths from 256K to 2048K, on a production cluster with more\nthan 12,000 GPUs. Experiment results show that ByteScale outperforms the\nstate-of-the-art training system by up to 7.89x.",
    "pdf_url": "http://arxiv.org/pdf/2502.21231v1",
    "published": "2025-02-28",
    "source": "arxiv",
    "id": "2502.21231v1",
    "categories": [
      "cs.DC",
      "cs.AI",
      "cs.LG"
    ]
  },
  {
    "title": "A Method of Selective Attention for Reservoir Based Agents",
    "authors": [
      "Kevin McKee"
    ],
    "abstract": "Training of deep reinforcement learning agents is slowed considerably by the\npresence of input dimensions that do not usefully condition the reward\nfunction. Existing modules such as layer normalization can be trained with\nweight decay to act as a form of selective attention, i.e. an input mask, that\nshrinks the scale of unnecessary inputs, which in turn accelerates training of\nthe policy. However, we find a surprising result that adding numerous\nparameters to the computation of the input mask results in much faster\ntraining. A simple, high dimensional masking module is compared with layer\nnormalization and a model without any input suppression. The high dimensional\nmask resulted in a four-fold speedup in training over the null hypothesis and a\ntwo-fold speedup in training over the layer normalization method.",
    "pdf_url": "http://arxiv.org/pdf/2502.21229v1",
    "published": "2025-02-28",
    "source": "arxiv",
    "id": "2502.21229v1",
    "categories": [
      "cs.LG"
    ]
  },
  {
    "title": "Recurrent CircuitSAT Sampling for Sequential Circuits",
    "authors": [
      "Arash Ardakani",
      "Kevin He",
      "John Wawrzynek"
    ],
    "abstract": "In this work, we introduce a novel GPU-accelerated circuit satisfiability\n(CircuitSAT) sampling technique for sequential circuits. This work is motivated\nby the requirement in constrained random verification (CRV) to generate input\nstimuli to validate the functionality of digital hardware circuits. A major\nchallenge in CRV is generating inputs for sequential circuits, along with the\nappropriate number of clock cycles required to meet design constraints.\nTraditional approaches often use Boolean satisfiability (SAT) samplers to\ngenerate inputs by unrolling state transitions over a fixed number of clock\ncycles. However, these methods do not guarantee that a solution exists for the\ngiven number of cycles. Consequently, producing input stimuli together with the\nrequired clock cycles is essential for thorough testing and verification. Our\napproach converts the logical constraints and temporal behavior of sequential\ncircuits into a recurrent CircuitSAT problem, optimized via gradient descent to\nefficiently explore a diverse set of valid solutions, including their\nassociated number of clock cycles. By operating directly on the circuit\nstructure, our method reinterprets the sampling process as a supervised\nmulti-output regression task. This differentiable framework enables independent\nelement-wise operations on each tensor element, facilitating parallel execution\nduring learning. As a result, we achieve GPU-accelerated sampling with\nsubstantial runtime improvements (up to 105.1x) over state-of-the-art heuristic\nsamplers. We demonstrate the effectiveness of our method through extensive\nevaluations on circuit problems from the ISCAS-89 and ITC'99 benchmark suites.",
    "pdf_url": "http://arxiv.org/pdf/2502.21226v2",
    "published": "2025-02-28",
    "source": "arxiv",
    "id": "2502.21226v2",
    "categories": [
      "cs.AR",
      "cs.PF"
    ]
  },
  {
    "title": "Exercises on the Kepler ellipses through a fixed point in space, after Otto Laporte",
    "authors": [
      "Gert Heckman"
    ],
    "abstract": "This article has a twofold purpose. On the one hand I would like to draw\nattention to some nice exercises on the Kepler laws, due to Otto Laporte from\n1970. Our discussion here has a more geometric flavour than the original\nanalytic approach of Laporte. On the other hand it serves as an addendum to a\npaper of mine from 1998 on the quantum integrability of the Kovalevsky top.\nLater I learned that this integrability result had been obtained already long\nbefore by Laporte in 1933.",
    "pdf_url": "http://arxiv.org/pdf/2502.21222v1",
    "published": "2025-02-28",
    "source": "arxiv",
    "id": "2502.21222v1",
    "categories": [
      "math.SG",
      "math-ph",
      "math.HO",
      "math.MP"
    ]
  },
  {
    "title": "Transformers Learn to Implement Multi-step Gradient Descent with Chain of Thought",
    "authors": [
      "Jianhao Huang",
      "Zixuan Wang",
      "Jason D. Lee"
    ],
    "abstract": "Chain of Thought (CoT) prompting has been shown to significantly improve the\nperformance of large language models (LLMs), particularly in arithmetic and\nreasoning tasks, by instructing the model to produce intermediate reasoning\nsteps. Despite the remarkable empirical success of CoT and its theoretical\nadvantages in enhancing expressivity, the mechanisms underlying CoT training\nremain largely unexplored. In this paper, we study the training dynamics of\ntransformers over a CoT objective on an in-context weight prediction task for\nlinear regression. We prove that while a one-layer linear transformer without\nCoT can only implement a single step of gradient descent (GD) and fails to\nrecover the ground-truth weight vector, a transformer with CoT prompting can\nlearn to perform multi-step GD autoregressively, achieving near-exact recovery.\nFurthermore, we show that the trained transformer effectively generalizes on\nthe unseen data. With our technique, we also show that looped transformers\nsignificantly improve final performance compared to transformers without\nlooping in the in-context learning of linear regression. Empirically, we\ndemonstrate that CoT prompting yields substantial performance improvements.",
    "pdf_url": "http://arxiv.org/pdf/2502.21212v1",
    "published": "2025-02-28",
    "source": "arxiv",
    "id": "2502.21212v1",
    "categories": [
      "cs.LG",
      "cs.AI"
    ]
  },
  {
    "title": "End-to-End Deep Learning in Phase Noisy Coherent Optical Link",
    "authors": [
      "Omar Alnaseri",
      "Yassine Himeur"
    ],
    "abstract": "In coherent optical orthogonal frequency-division multiplexing (CO-OFDM)\nfiber communications, a novel end-to-end learning framework to mitigate Laser\nPhase Noise (LPN) impairments is proposed in this paper. Inspired by\nAutoencoder (AE) principles, the proposed approach trains a model to learn\nrobust symbol sequences capable of combat LPN, even from low-cost distributed\nfeedback (DFB) lasers with linewidths up to 2 MHz. This allows for the use of\nhigh-level modulation formats and large-scale Fast Fourier Transform (FFT)\nprocessing, maximizing spectral efficiency in CO-OFDM systems. By eliminating\nthe need for complex traditional techniques, this approach offers a potentially\nmore efficient and streamlined solution for CO-OFDM systems. The most\nsignificant achievement of this study is the demonstration that the proposed\nAE-based model can enhance system performance by reducing the bit error rate\n(BER) to below the threshold of forward error correction (FEC), even under\nsevere phase noise conditions, thus proving its effectiveness and efficiency in\npractical deployment scenarios.",
    "pdf_url": "http://arxiv.org/pdf/2502.21209v1",
    "published": "2025-02-28",
    "source": "arxiv",
    "id": "2502.21209v1",
    "categories": [
      "eess.SP"
    ]
  },
  {
    "title": "ARIES: Autonomous Reasoning with LLMs on Interactive Thought Graph Environments",
    "authors": [
      "Pedro Gimenes",
      "Zeyu Cao",
      "Jeffrey Wong",
      "Yiren Zhao"
    ],
    "abstract": "Recent research has shown that LLM performance on reasoning tasks can be\nenhanced by scaling test-time compute. One promising approach, particularly\nwith decomposable problems, involves arranging intermediate solutions as a\ngraph on which transformations are performed to explore the solution space.\nHowever, prior works rely on pre-determined, task-specific transformation\nschedules which are subject to a set of searched hyperparameters. In this work,\nwe view thought graph transformations as actions in a Markov decision process,\nand implement policy agents to drive effective action policies for the\nunderlying reasoning LLM agent. In particular, we investigate the ability for\nanother LLM to act as a policy agent on thought graph environments and\nintroduce ARIES, a multi-agent architecture for reasoning with LLMs. In ARIES,\nreasoning LLM agents solve decomposed subproblems, while policy LLM agents\nmaintain visibility of the thought graph states, and dynamically adapt the\nproblem-solving strategy. Through extensive experiments, we observe that using\noff-the-shelf LLMs as policy agents with no supervised fine-tuning (SFT) can\nyield up to $29\\%$ higher accuracy on HumanEval relative to static\ntransformation schedules, as well as reducing inference costs by $35\\%$ and\navoid any search requirements. We also conduct a thorough analysis of observed\nfailure modes, highlighting that limitations on LLM sizes and the depth of\nproblem decomposition can be seen as challenges to scaling LLM-guided\nreasoning.",
    "pdf_url": "http://arxiv.org/pdf/2502.21208v1",
    "published": "2025-02-28",
    "source": "arxiv",
    "id": "2502.21208v1",
    "categories": [
      "cs.AI",
      "cs.LG"
    ]
  },
  {
    "title": "AI-Enhanced Self-Triggering for Extensive Air Showers: Performance and FPGA Feasibility",
    "authors": [
      "Qader Dorosti"
    ],
    "abstract": "Cosmic-ray detection with radio antennas has traditionally depended on\nexternal triggers from particle detectors, constraining sensitivity and\nincreasing complexity. Previous attempts at fully standalone, radio-only\ntriggers have often failed under intense radio frequency interference, making\ngenuine air-shower signals difficult to isolate. We present a\nproof-of-principle artificial intelligence-based self-triggering system that\novercomes these limitations. By training a deep learning model on both real\nnoise data and injected cosmic-ray-like pulses, we achieve an exceptionally low\nfalse-positive rate alongside high detection efficiency. Configurable operating\npoints can suppress false positives below 0.01\\% while retaining more than 88\\%\nof genuine signals, and can even eliminate false positives entirely at a modest\nreduction in signal efficiency. This flexibility makes single-station\ncosmic-ray detection feasible without requiring external trigger inputs.\nApplying our approach to real-world noise conditions reduces the initial\nfalse-positive event rate by several orders of magnitude, supporting\nlarge-scale deployments. Extrapolation to dedicated hardware implementations,\nsuch as FPGAs, indicates that sub-\\SI{}{\\micro\\second} inference times are\nachievable, enabling real-time autonomous triggering. These results highlight\nthe transformative potential of artificial intelligence for enhancing radio\ndetection sensitivity and inaugurate a new generation of fully self-triggered\ncosmic-ray observatories.",
    "pdf_url": "http://arxiv.org/pdf/2502.21198v1",
    "published": "2025-02-28",
    "source": "arxiv",
    "id": "2502.21198v1",
    "categories": [
      "astro-ph.IM",
      "physics.ins-det"
    ]
  },
  {
    "title": "AMPLE: Event-Driven Accelerator for Mixed-Precision Inference of Graph Neural Networks",
    "authors": [
      "Pedro Gimenes",
      "Yiren Zhao",
      "George Constantinides"
    ],
    "abstract": "Graph Neural Networks (GNNs) have recently gained attention due to their\nperformance on non-Euclidean data. The use of custom hardware architectures\nproves particularly beneficial for GNNs due to their irregular memory access\npatterns, resulting from the sparse structure of graphs. However, existing FPGA\naccelerators are limited by their double buffering mechanism, which doesn't\naccount for the irregular node distribution in typical graph datasets. To\naddress this, we introduce \\textbf{AMPLE} (Accelerated Message Passing Logic\nEngine), an FPGA accelerator leveraging a new event-driven programming flow. We\ndevelop a mixed-arithmetic architecture, enabling GNN inference to be quantized\nat a node-level granularity. Finally, prefetcher for data and instructions is\nimplemented to optimize off-chip memory access and maximize node parallelism.\nEvaluation on citation and social media graph datasets ranging from $2$K to\n$700$K nodes showed a mean speedup of $243\\times$ and $7.2\\times$ against CPU\nand GPU counterparts, respectively.",
    "pdf_url": "http://arxiv.org/pdf/2502.21196v1",
    "published": "2025-02-28",
    "source": "arxiv",
    "id": "2502.21196v1",
    "categories": [
      "cs.AR",
      "cs.AI",
      "cs.LG"
    ]
  },
  {
    "title": "Joint Modeling in Recommendations: A Survey",
    "authors": [
      "Xiangyu Zhao",
      "Yichao Wang",
      "Bo Chen",
      "Jingtong Gao",
      "Yuhao Wang",
      "Xiaopeng Li",
      "Pengyue Jia",
      "Qidong Liu",
      "Huifeng Guo",
      "Ruiming Tang"
    ],
    "abstract": "In today's digital landscape, Deep Recommender Systems (DRS) play a crucial\nrole in navigating and customizing online content for individual preferences.\nHowever, conventional methods, which mainly depend on single recommendation\ntask, scenario, data modality and user behavior, are increasingly seen as\ninsufficient due to their inability to accurately reflect users' complex and\nchanging preferences. This gap underscores the need for joint modeling\napproaches, which are central to overcoming these limitations by integrating\ndiverse tasks, scenarios, modalities, and behaviors in the recommendation\nprocess, thus promising significant enhancements in recommendation precision,\nefficiency, and customization. In this paper, we comprehensively survey the\njoint modeling methods in recommendations. We begin by defining the scope of\njoint modeling through four distinct dimensions: multi-task, multi-scenario,\nmulti-modal, and multi-behavior modeling. Subsequently, we examine these\nmethods in depth, identifying and summarizing their underlying paradigms based\non the latest advancements and potential research trajectories. Ultimately, we\nhighlight several promising avenues for future exploration in joint modeling\nfor recommendations and provide a concise conclusion to our findings.",
    "pdf_url": "http://arxiv.org/pdf/2502.21195v1",
    "published": "2025-02-28",
    "source": "arxiv",
    "id": "2502.21195v1",
    "categories": [
      "cs.IR"
    ]
  },
  {
    "title": "Class prior estimation for positive-unlabeled learning when label shift occurs",
    "authors": [
      "Jan Mielniczuk",
      "Wojciech Rejchel",
      "Paweł Teisseyre"
    ],
    "abstract": "We study estimation of class prior for unlabeled target samples which is\npossibly different from that of source population. It is assumed that for the\nsource data only samples from positive class and from the whole population are\navailable (PU learning scenario). We introduce a novel direct estimator of\nclass prior which avoids estimation of posterior probabilities and has a simple\ngeometric interpretation. It is based on a distribution matching technique\ntogether with kernel embedding and is obtained as an explicit solution to an\noptimisation task. We establish its asymptotic consistency as well as a\nnon-asymptotic bound on its deviation from the unknown prior, which is\ncalculable in practice. We study finite sample behaviour for synthetic and real\ndata and show that the proposal, together with a suitably modified version for\nlarge values of source prior, works on par or better than its competitors.",
    "pdf_url": "http://arxiv.org/pdf/2502.21194v1",
    "published": "2025-02-28",
    "source": "arxiv",
    "id": "2502.21194v1",
    "categories": [
      "stat.ML",
      "cs.LG"
    ]
  },
  {
    "title": "Geodesic Slice Sampler for Multimodal Distributions with Strong Curvature",
    "authors": [
      "Bernardo Williams",
      "Hanlin Yu",
      "Hoang Phuc Hau Luu",
      "Georgios Arvanitidis",
      "Arto Klami"
    ],
    "abstract": "Traditional Markov Chain Monte Carlo sampling methods often struggle with\nsharp curvatures, intricate geometries, and multimodal distributions. Slice\nsampling can resolve local exploration inefficiency issues and Riemannian\ngeometries help with sharp curvatures. Recent extensions enable slice sampling\non Riemannian manifolds, but they are restricted to cases where geodesics are\navailable in closed form. We propose a method that generalizes Hit-and-Run\nslice sampling to more general geometries tailored to the target distribution,\nby approximating geodesics as solutions to differential equations. Our approach\nenables exploration of regions with strong curvature and rapid transitions\nbetween modes in multimodal distributions. We demonstrate the advantages of the\napproach over challenging sampling problems.",
    "pdf_url": "http://arxiv.org/pdf/2502.21190v1",
    "published": "2025-02-28",
    "source": "arxiv",
    "id": "2502.21190v1",
    "categories": [
      "cs.LG"
    ]
  },
  {
    "title": "SYN-LUNGS: Towards Simulating Lung Nodules with Anatomy-Informed Digital Twins for AI Training",
    "authors": [
      "Fakrul Islam Tushar",
      "Lavsen Dahal",
      "Cindy McCabe",
      "Fong Chi Ho",
      "Paul Segars",
      "Ehsan Abadi",
      "Kyle J. Lafata",
      "Ehsan Samei",
      "Joseph Y. Lo"
    ],
    "abstract": "AI models for lung cancer screening are limited by data scarcity, impacting\ngeneralizability and clinical applicability. Generative models address this\nissue but are constrained by training data variability. We introduce SYN-LUNGS,\na framework for generating high-quality 3D CT images with detailed annotations.\nSYN-LUNGS integrates XCAT3 phantoms for digital twin generation, X-Lesions for\nnodule simulation (varying size, location, and appearance), and DukeSim for CT\nimage formation with vendor and parameter variability. The dataset includes\n3,072 nodule images from 1,044 simulated CT scans, with 512 lesions and 174\ndigital twins. Models trained on clinical + simulated data outperform clinical\nonly models, achieving 10% improvement in detection, 2-9% in segmentation and\nclassification, and enhanced synthesis.By incorporating anatomy-informed\nsimulations, SYN-LUNGS provides a scalable approach for AI model development,\nparticularly in rare disease representation and improving model reliability.",
    "pdf_url": "http://arxiv.org/pdf/2502.21187v1",
    "published": "2025-02-28",
    "source": "arxiv",
    "id": "2502.21187v1",
    "categories": [
      "cs.LG"
    ]
  },
  {
    "title": "Scalable Decision-Making in Stochastic Environments through Learned Temporal Abstraction",
    "authors": [
      "Baiting Luo",
      "Ava Pettet",
      "Aron Laszka",
      "Abhishek Dubey",
      "Ayan Mukhopadhyay"
    ],
    "abstract": "Sequential decision-making in high-dimensional continuous action spaces,\nparticularly in stochastic environments, faces significant computational\nchallenges. We explore this challenge in the traditional offline RL setting,\nwhere an agent must learn how to make decisions based on data collected through\na stochastic behavior policy. We present Latent Macro Action Planner (L-MAP),\nwhich addresses this challenge by learning a set of temporally extended\nmacro-actions through a state-conditional Vector Quantized Variational\nAutoencoder (VQ-VAE), effectively reducing action dimensionality. L-MAP employs\na (separate) learned prior model that acts as a latent transition model and\nallows efficient sampling of plausible actions. During planning, our approach\naccounts for stochasticity in both the environment and the behavior policy by\nusing Monte Carlo tree search (MCTS). In offline RL settings, including\nstochastic continuous control tasks, L-MAP efficiently searches over discrete\nlatent actions to yield high expected returns. Empirical results demonstrate\nthat L-MAP maintains low decision latency despite increased action\ndimensionality. Notably, across tasks ranging from continuous control with\ninherently stochastic dynamics to high-dimensional robotic hand manipulation,\nL-MAP significantly outperforms existing model-based methods and performs\non-par with strong model-free actor-critic baselines, highlighting the\neffectiveness of the proposed approach in planning in complex and stochastic\nenvironments with high-dimensional action spaces.",
    "pdf_url": "http://arxiv.org/pdf/2502.21186v2",
    "published": "2025-02-28",
    "source": "arxiv",
    "id": "2502.21186v2",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.RO"
    ]
  },
  {
    "title": "HQColon: A Hybrid Interactive Machine Learning Pipeline for High Quality Colon Labeling and Segmentation",
    "authors": [
      "Martina Finocchiaro",
      "Ronja Stern",
      "Abraham George Smith",
      "Jens Petersen",
      "Kenny Erleben",
      "Melanie Ganz"
    ],
    "abstract": "High-resolution colon segmentation is crucial for clinical and research\napplications, such as digital twins and personalized medicine. However, the\nleading open-source abdominal segmentation tool, TotalSegmentator, struggles\nwith accuracy for the colon, which has a complex and variable shape, requiring\ntime-intensive labeling. Here, we present the first fully automatic\nhigh-resolution colon segmentation method. To develop it, we first created a\nhigh resolution colon dataset using a pipeline that combines region growing\nwith interactive machine learning to efficiently and accurately label the colon\non CT colonography (CTC) images. Based on the generated dataset consisting of\n435 labeled CTC images we trained an nnU-Net model for fully automatic colon\nsegmentation. Our fully automatic model achieved an average symmetric surface\ndistance of 0.2 mm (vs. 4.0 mm from TotalSegmentator) and a 95th percentile\nHausdorff distance of 1.0 mm (vs. 18 mm from TotalSegmentator). Our\nsegmentation accuracy substantially surpasses TotalSegmentator. We share our\ntrained model and pipeline code, providing the first and only open-source tool\nfor high-resolution colon segmentation. Additionally, we created a large-scale\ndataset of publicly available high-resolution colon labels.",
    "pdf_url": "http://arxiv.org/pdf/2502.21183v1",
    "published": "2025-02-28",
    "source": "arxiv",
    "id": "2502.21183v1",
    "categories": [
      "cs.CV",
      "cs.LG"
    ]
  },
  {
    "title": "Reducing Reward Dependence in RL Through Adaptive Confidence Discounting",
    "authors": [
      "Muhammed Yusuf Satici",
      "David L. Roberts"
    ],
    "abstract": "In human-in-the-loop reinforcement learning or environments where calculating\na reward is expensive, the costly rewards can make learning efficiency\nchallenging to achieve. The cost of obtaining feedback from humans or\ncalculating expensive rewards means algorithms receiving feedback at every step\nof long training sessions may be infeasible, which may limit agents' abilities\nto efficiently improve performance. Our aim is to reduce the reliance of\nlearning agents on humans or expensive rewards, improving the efficiency of\nlearning while maintaining the quality of the learned policy. We offer a novel\nreinforcement learning algorithm that requests a reward only when its knowledge\nof the value of actions in an environment state is low. Our approach uses a\nreward function model as a proxy for human-delivered or expensive rewards when\nconfidence is high, and asks for those explicit rewards only when there is low\nconfidence in the model's predicted rewards and/or action selection. By\nreducing dependence on the expensive-to-obtain rewards, we are able to learn\nefficiently in settings where the logistics or expense of obtaining rewards may\notherwise prohibit it. In our experiments our approach obtains comparable\nperformance to a baseline in terms of return and number of episodes required to\nlearn, but achieves that performance with as few as 20% of the rewards.",
    "pdf_url": "http://arxiv.org/pdf/2502.21181v1",
    "published": "2025-02-28",
    "source": "arxiv",
    "id": "2502.21181v1",
    "categories": [
      "cs.LG"
    ]
  },
  {
    "title": "QFAL: Quantum Federated Adversarial Learning",
    "authors": [
      "Walid El Maouaki",
      "Nouhaila Innan",
      "Alberto Marchisio",
      "Taoufik Said",
      "Mohamed Bennai",
      "Muhammad Shafique"
    ],
    "abstract": "Quantum federated learning (QFL) merges the privacy advantages of federated\nsystems with the computational potential of quantum neural networks (QNNs), yet\nits vulnerability to adversarial attacks remains poorly understood. This work\npioneers the integration of adversarial training into QFL, proposing a robust\nframework, quantum federated adversarial learning (QFAL), where clients\ncollaboratively defend against perturbations by combining local adversarial\nexample generation with federated averaging (FedAvg). We systematically\nevaluate the interplay between three critical factors: client count (5, 10,\n15), adversarial training coverage (0-100%), and adversarial attack\nperturbation strength (epsilon = 0.01-0.5), using the MNIST dataset. Our\nexperimental results show that while fewer clients often yield higher\nclean-data accuracy, larger federations can more effectively balance accuracy\nand robustness when partially adversarially trained. Notably, even limited\nadversarial coverage (e.g., 20%-50%) can significantly improve resilience to\nmoderate perturbations, though at the cost of reduced baseline performance.\nConversely, full adversarial training (100%) may regain high clean accuracy but\nis vulnerable under stronger attacks. These findings underscore an inherent\ntrade-off between robust and standard objectives, which is further complicated\nby quantum-specific factors. We conclude that a carefully chosen combination of\nclient count and adversarial coverage is critical for mitigating adversarial\nvulnerabilities in QFL. Moreover, we highlight opportunities for future\nresearch, including adaptive adversarial training schedules, more diverse\nquantum encoding schemes, and personalized defense strategies to further\nenhance the robustness-accuracy trade-off in real-world quantum federated\nenvironments.",
    "pdf_url": "http://arxiv.org/pdf/2502.21171v1",
    "published": "2025-02-28",
    "source": "arxiv",
    "id": "2502.21171v1",
    "categories": [
      "cs.LG",
      "quant-ph"
    ]
  },
  {
    "title": "Autonomous Curriculum Design via Relative Entropy Based Task Modifications",
    "authors": [
      "Muhammed Yusuf Satici",
      "Jianxun Wang",
      "David L. Roberts"
    ],
    "abstract": "Curriculum learning is a training method in which an agent is first trained\non a curriculum of relatively simple tasks related to a target task in an\neffort to shorten the time required to train on the target task. Autonomous\ncurriculum design involves the design of such curriculum with no reliance on\nhuman knowledge and/or expertise. Finding an efficient and effective way of\nautonomously designing curricula remains an open problem. We propose a novel\napproach for automatically designing curricula by leveraging the learner's\nuncertainty to select curricula tasks. Our approach measures the uncertainty in\nthe learner's policy using relative entropy, and guides the agent to states of\nhigh uncertainty to facilitate learning. Our algorithm supports the generation\nof autonomous curricula in a self-assessed manner by leveraging the learner's\npast and current policies but it also allows the use of teacher guided design\nin an instructive setting. We provide theoretical guarantees for the\nconvergence of our algorithm using two time-scale optimization processes.\nResults show that our algorithm outperforms randomly generated curriculum, and\nlearning directly on the target task as well as the curriculum-learning\ncriteria existing in literature. We also present two additional heuristic\ndistance measures that could be combined with our relative-entropy approach for\nfurther performance improvements.",
    "pdf_url": "http://arxiv.org/pdf/2502.21166v1",
    "published": "2025-02-28",
    "source": "arxiv",
    "id": "2502.21166v1",
    "categories": [
      "cs.LG"
    ]
  },
  {
    "title": "Adaptive Illumination-Invariant Synergistic Feature Integration in a Stratified Granular Framework for Visible-Infrared Re-Identification",
    "authors": [
      "Yuheng Jia",
      "Wesley Armour"
    ],
    "abstract": "Visible-Infrared Person Re-Identification (VI-ReID) plays a crucial role in\napplications such as search and rescue, infrastructure protection, and\nnighttime surveillance. However, it faces significant challenges due to\nmodality discrepancies, varying illumination, and frequent occlusions. To\novercome these obstacles, we propose \\textbf{AMINet}, an Adaptive Modality\nInteraction Network. AMINet employs multi-granularity feature extraction to\ncapture comprehensive identity attributes from both full-body and upper-body\nimages, improving robustness against occlusions and background clutter. The\nmodel integrates an interactive feature fusion strategy for deep intra-modal\nand cross-modal alignment, enhancing generalization and effectively bridging\nthe RGB-IR modality gap. Furthermore, AMINet utilizes phase congruency for\nrobust, illumination-invariant feature extraction and incorporates an adaptive\nmulti-scale kernel MMD to align feature distributions across varying scales.\nExtensive experiments on benchmark datasets demonstrate the effectiveness of\nour approach, achieving a Rank-1 accuracy of $74.75\\%$ on SYSU-MM01, surpassing\nthe baseline by $7.93\\%$ and outperforming the current state-of-the-art by\n$3.95\\%$.",
    "pdf_url": "http://arxiv.org/pdf/2502.21163v1",
    "published": "2025-02-28",
    "source": "arxiv",
    "id": "2502.21163v1",
    "categories": [
      "cs.CV"
    ]
  },
  {
    "title": "Parallel-Learning of Invariant and Tempo-variant Attributes of Single-Lead Cardiac Signals: PLITA",
    "authors": [
      "Adtian Atienza",
      "Jakob E. Bardram",
      "Sadasivan Puthusserypady"
    ],
    "abstract": "Wearable sensing devices, such as Holter monitors, will play a crucial role\nin the future of digital health. Unsupervised learning frameworks such as\nSelf-Supervised Learning (SSL) are essential to map these single-lead\nelectrocardiogram (ECG) signals with their anticipated clinical outcomes. These\nsignals are characterized by a tempo-variant component whose patterns evolve\nthrough the recording and an invariant component with patterns that remain\nunchanged. However, existing SSL methods only drive the model to encode the\ninvariant attributes, leading the model to neglect tempo-variant information\nwhich reflects subject-state changes through time. In this paper, we present\nParallel-Learning of Invariant and Tempo-variant Attributes (PLITA), a novel\nSSL method designed for capturing both invariant and tempo-variant ECG\nattributes. The latter are captured by mandating closer representations in\nspace for closer inputs on time. We evaluate both the capability of the method\nto learn the attributes of these two distinct kinds, as well as PLITA's\nperformance compared to existing SSL methods for ECG analysis. PLITA performs\nsignificantly better in the set-ups where tempo-variant attributes play a major\nrole.",
    "pdf_url": "http://arxiv.org/pdf/2502.21162v1",
    "published": "2025-02-28",
    "source": "arxiv",
    "id": "2502.21162v1",
    "categories": [
      "cs.LG"
    ]
  },
  {
    "title": "Hypergraph Multi-Modal Learning for EEG-based Emotion Recognition in Conversation",
    "authors": [
      "Zijian Kang",
      "Yueyang Li",
      "Shengyu Gong",
      "Weiming Zeng",
      "Hongjie Yan",
      "Lingbin Bian",
      "Wai Ting Siok",
      "Nizhuan Wang"
    ],
    "abstract": "Emotional Recognition in Conversation (ERC) is an important method for\ndiagnosing health conditions such as autism or depression, as well as\nunderstanding emotions in individuals who struggle to express their feelings.\nCurrent ERC methods primarily rely on complete semantic textual information,\nincluding audio and visual data, but face challenges in integrating\nphysiological signals such as electroencephalogram (EEG). This paper proposes a\nnovel Hypergraph Multi-Modal Learning Framework (Hyper-MML), designed to\neffectively identify emotions in conversation by integrating EEG with audio and\nvideo information to capture complex emotional dynamics. Experimental results\ndemonstrate that Hyper-MML significantly outperforms traditional methods in\nemotion recognition. This is achieved through a Multi-modal Hypergraph Fusion\nModule (MHFM), which actively models higher-order relationships between\nmulti-modal signals, as validated on the EAV dataset. Our proposed Hyper-MML\nserves as an effective communication tool for healthcare professionals,\nenabling better engagement with patients who have difficulty expressing their\nemotions.",
    "pdf_url": "http://arxiv.org/pdf/2502.21154v1",
    "published": "2025-02-28",
    "source": "arxiv",
    "id": "2502.21154v1",
    "categories": [
      "cs.HC"
    ]
  },
  {
    "title": "Applications of Enhanced Sampling Methods to Biomolecular Self-Assembly: A Review",
    "authors": [
      "Mason Hooten",
      "Het Patel",
      "Yiwei Shao",
      "Rishabh Kumar Singh",
      "Meenakshi Dutt"
    ],
    "abstract": "This review article discusses some common enhanced sampling methods in\nrelation to the process of self-assembly of biomolecules. An introduction to\nself-assembly and its challenges is covered followed by a brief overview of the\nmethods and analysis for replica-exchange molecular dynamics, umbrella\nsampling, metadynamics, and machine learning based techniques. Applications of\nselect methods towards peptides, proteins, polymers, nucleic acids, and\nsupramolecules are discussed. Finally, a short discussion of the future\ndirections of some of these methods is provided.",
    "pdf_url": "http://arxiv.org/pdf/2502.21148v1",
    "published": "2025-02-28",
    "source": "arxiv",
    "id": "2502.21148v1",
    "categories": [
      "cond-mat.soft"
    ]
  },
  {
    "title": "Same accuracy, twice as fast: continuous training surpasses retraining from scratch",
    "authors": [
      "Eli Verwimp",
      "Guy Hacohen",
      "Tinne Tuytelaars"
    ],
    "abstract": "Continual learning aims to enable models to adapt to new datasets without\nlosing performance on previously learned data, often assuming that prior data\nis no longer available. However, in many practical scenarios, both old and new\ndata are accessible. In such cases, good performance on both datasets is\ntypically achieved by abandoning the model trained on the previous data and\nre-training a new model from scratch on both datasets. This training from\nscratch is computationally expensive. In contrast, methods that leverage the\npreviously trained model and old data are worthy of investigation, as they\ncould significantly reduce computational costs. Our evaluation framework\nquantifies the computational savings of such methods while maintaining or\nexceeding the performance of training from scratch. We identify key\noptimization aspects -- initialization, regularization, data selection, and\nhyper-parameters -- that can each contribute to reducing computational costs.\nFor each aspect, we propose effective first-step methods that already yield\nsubstantial computational savings. By combining these methods, we achieve up to\n2.7x reductions in computation time across various computer vision tasks,\nhighlighting the potential for further advancements in this area.",
    "pdf_url": "http://arxiv.org/pdf/2502.21147v1",
    "published": "2025-02-28",
    "source": "arxiv",
    "id": "2502.21147v1",
    "categories": [
      "cs.LG",
      "cs.CV"
    ]
  },
  {
    "title": "Variational Bayesian Pseudo-Coreset",
    "authors": [
      "Hyungi Lee",
      "Seungyoo Lee",
      "Juho Lee"
    ],
    "abstract": "The success of deep learning requires large datasets and extensive training,\nwhich can create significant computational challenges. To address these\nchallenges, pseudo-coresets, small learnable datasets that mimic the entire\ndata, have been proposed. Bayesian Neural Networks, which offer predictive\nuncertainty and probabilistic interpretation for deep neural networks, also\nface issues with large-scale datasets due to their high-dimensional parameter\nspace. Prior works on Bayesian Pseudo-Coresets (BPC) attempt to reduce the\ncomputational load for computing weight posterior distribution by a small\nnumber of pseudo-coresets but suffer from memory inefficiency during BPC\ntraining and sub-optimal results. To overcome these limitations, we propose\nVariational Bayesian Pseudo-Coreset (VBPC), a novel approach that utilizes\nvariational inference to efficiently approximate the posterior distribution,\nreducing memory usage and computational costs while improving performance\nacross benchmark datasets.",
    "pdf_url": "http://arxiv.org/pdf/2502.21143v1",
    "published": "2025-02-28",
    "source": "arxiv",
    "id": "2502.21143v1",
    "categories": [
      "cs.LG"
    ]
  },
  {
    "title": "Multimodal Dreaming: A Global Workspace Approach to World Model-Based Reinforcement Learning",
    "authors": [
      "Léopold Maytié",
      "Roland Bertin Johannet",
      "Rufin VanRullen"
    ],
    "abstract": "Humans leverage rich internal models of the world to reason about the future,\nimagine counterfactuals, and adapt flexibly to new situations. In Reinforcement\nLearning (RL), world models aim to capture how the environment evolves in\nresponse to the agent's actions, facilitating planning and generalization.\nHowever, typical world models directly operate on the environment variables\n(e.g. pixels, physical attributes), which can make their training slow and\ncumbersome; instead, it may be advantageous to rely on high-level latent\ndimensions that capture relevant multimodal variables. Global Workspace (GW)\nTheory offers a cognitive framework for multimodal integration and information\nbroadcasting in the brain, and recent studies have begun to introduce efficient\ndeep learning implementations of GW. Here, we evaluate the capabilities of an\nRL system combining GW with a world model. We compare our GW-Dreamer with\nvarious versions of the standard PPO and the original Dreamer algorithms. We\nshow that performing the dreaming process (i.e., mental simulation) inside the\nGW latent space allows for training with fewer environment steps. As an\nadditional emergent property, the resulting model (but not its comparison\nbaselines) displays strong robustness to the absence of one of its observation\nmodalities (images or simulation attributes). We conclude that the combination\nof GW with World Models holds great potential for improving decision-making in\nRL agents.",
    "pdf_url": "http://arxiv.org/pdf/2502.21142v1",
    "published": "2025-02-28",
    "source": "arxiv",
    "id": "2502.21142v1",
    "categories": [
      "cs.AI",
      "cs.LG",
      "q-bio.NC"
    ]
  },
  {
    "title": "Predicting clinical outcomes from patient care pathways represented with temporal knowledge graphs",
    "authors": [
      "Jong Ho Jhee",
      "Alberto Megina",
      "Pacôme Constant Dit Beaufils",
      "Matilde Karakachoff",
      "Richard Redon",
      "Alban Gaignard",
      "Adrien Coulet"
    ],
    "abstract": "Background: With the increasing availability of healthcare data, predictive\nmodeling finds many applications in the biomedical domain, such as the\nevaluation of the level of risk for various conditions, which in turn can guide\nclinical decision making. However, it is unclear how knowledge graph data\nrepresentations and their embedding, which are competitive in some settings,\ncould be of interest in biomedical predictive modeling. Method: We simulated\nsynthetic but realistic data of patients with intracranial aneurysm and\nexperimented on the task of predicting their clinical outcome. We compared the\nperformance of various classification approaches on tabular data versus a\ngraph-based representation of the same data. Next, we investigated how the\nadopted schema for representing first individual data and second temporal data\nimpacts predictive performances. Results: Our study illustrates that in our\ncase, a graph representation and Graph Convolutional Network (GCN) embeddings\nreach the best performance for a predictive task from observational data. We\nemphasize the importance of the adopted schema and of the consideration of\nliteral values in the representation of individual data. Our study also\nmoderates the relative impact of various time encoding on GCN performance.",
    "pdf_url": "http://arxiv.org/pdf/2502.21138v1",
    "published": "2025-02-28",
    "source": "arxiv",
    "id": "2502.21138v1",
    "categories": [
      "cs.LG",
      "cs.AI"
    ]
  },
  {
    "title": "Dynamically Local-Enhancement Planner for Large-Scale Autonomous Driving",
    "authors": [
      "Nanshan Deng",
      "Weitao Zhou",
      "Bo Zhang",
      "Junze Wen",
      "Kun Jiang",
      "Zhong Cao",
      "Diange Yang"
    ],
    "abstract": "Current autonomous vehicles operate primarily within limited regions, but\nthere is increasing demand for broader applications. However, as models scale,\ntheir limited capacity becomes a significant challenge for adapting to novel\nscenarios. It is increasingly difficult to improve models for new situations\nusing a single monolithic model. To address this issue, we introduce the\nconcept of dynamically enhancing a basic driving planner with local driving\ndata, without permanently modifying the planner itself. This approach, termed\nthe Dynamically Local-Enhancement (DLE) Planner, aims to improve the\nscalability of autonomous driving systems without significantly expanding the\nplanner's size. Our approach introduces a position-varying Markov Decision\nProcess formulation coupled with a graph neural network that extracts\nregion-specific driving features from local observation data. The learned\nfeatures describe the local behavior of the surrounding objects, which is then\nleveraged to enhance a basic reinforcement learning-based policy. We evaluated\nour approach in multiple scenarios and compared it with a one-for-all driving\nmodel. The results show that our method outperforms the baseline policy in both\nsafety (collision rate) and average reward, while maintaining a lighter scale.\nThis approach has the potential to benefit large-scale autonomous vehicles\nwithout the need for largely expanding on-device driving models.",
    "pdf_url": "http://arxiv.org/pdf/2502.21134v1",
    "published": "2025-02-28",
    "source": "arxiv",
    "id": "2502.21134v1",
    "categories": [
      "cs.RO",
      "cs.AI"
    ]
  },
  {
    "title": "Fast and Accurate Gigapixel Pathological Image Classification with Hierarchical Distillation Multi-Instance Learning",
    "authors": [
      "Jiuyang Dong",
      "Junjun Jiang",
      "Kui Jiang",
      "Jiahan Li",
      "Yongbing Zhang"
    ],
    "abstract": "Although multi-instance learning (MIL) has succeeded in pathological image\nclassification, it faces the challenge of high inference costs due to\nprocessing numerous patches from gigapixel whole slide images (WSIs). To\naddress this, we propose HDMIL, a hierarchical distillation multi-instance\nlearning framework that achieves fast and accurate classification by\neliminating irrelevant patches. HDMIL consists of two key components: the\ndynamic multi-instance network (DMIN) and the lightweight instance\npre-screening network (LIPN). DMIN operates on high-resolution WSIs, while LIPN\noperates on the corresponding low-resolution counterparts. During training,\nDMIN are trained for WSI classification while generating attention-score-based\nmasks that indicate irrelevant patches. These masks then guide the training of\nLIPN to predict the relevance of each low-resolution patch. During testing,\nLIPN first determines the useful regions within low-resolution WSIs, which\nindirectly enables us to eliminate irrelevant regions in high-resolution WSIs,\nthereby reducing inference time without causing performance degradation. In\naddition, we further design the first Chebyshev-polynomials-based\nKolmogorov-Arnold classifier in computational pathology, which enhances the\nperformance of HDMIL through learnable activation layers. Extensive experiments\non three public datasets demonstrate that HDMIL outperforms previous\nstate-of-the-art methods, e.g., achieving improvements of 3.13% in AUC while\nreducing inference time by 28.6% on the Camelyon16 dataset.",
    "pdf_url": "http://arxiv.org/pdf/2502.21130v2",
    "published": "2025-02-28",
    "source": "arxiv",
    "id": "2502.21130v2",
    "categories": [
      "cs.CV"
    ]
  },
  {
    "title": "Microscopic Propagator Imaging (MPI) with Diffusion MRI",
    "authors": [
      "Tommaso Zajac",
      "Gloria Menegaz",
      "Marco Pizzolato"
    ],
    "abstract": "We propose Microscopic Propagator Imaging (MPI) as a novel method to retrieve\nthe indices of the microscopic propagator which is the probability density\nfunction of water displacements due to diffusion within the nervous tissue\nmicrostructures. Unlike the Ensemble Average Propagator indices or the\nDiffusion Tensor Imaging metrics, MPI indices are independent from the\nmesoscopic organization of the tissue such as the presence of multiple axonal\nbundle directions and orientation dispersion. As a consequence, MPI indices are\nmore specific to the volumes, sizes, and types of microstructures, like axons\nand cells, that are present in the tissue. Thus, changes in MPI indices can be\nmore directly linked to alterations in the presence and integrity of\nmicrostructures themselves. The methodology behind MPI is rooted on zonal\nmodeling of spherical harmonics, signal simulation, and machine learning\nregression, and is demonstrated on both synthetic and Human Diffusion MRI data.",
    "pdf_url": "http://arxiv.org/pdf/2502.21129v1",
    "published": "2025-02-28",
    "source": "arxiv",
    "id": "2502.21129v1",
    "categories": [
      "q-bio.NC",
      "cs.LG",
      "physics.bio-ph",
      "physics.med-ph",
      "I.6.5"
    ]
  },
  {
    "title": "CuPID: Leveraging Masked Single-Lead ECG Modelling for Enhancing the Representations",
    "authors": [
      "Adtian Atienza",
      "Gouthamaan Manimaran",
      "Jakob E. Bardram",
      "Sadasivan Puthusserypady"
    ],
    "abstract": "Wearable sensing devices, such as Electrocardiogram (ECG) heart-rate\nmonitors, will play a crucial role in the future of digital health. This\ncontinuous monitoring leads to massive unlabeled data, incentivizing the\ndevelopment of unsupervised learning frameworks. While Masked Data Modelling\n(MDM) techniques have enjoyed wide use, their direct application to single-lead\nECG data is suboptimal due to the decoder's difficulty handling irregular\nheartbeat intervals when no contextual information is provided. In this paper,\nwe present Cueing the Predictor Increments the Detailing (CuPID), a novel MDM\nmethod tailored to single-lead ECGs. CuPID enhances existing MDM techniques by\ncueing spectrogram-derived context to the decoder, thus incentivizing the\nencoder to produce more detailed representations. This has a significant impact\non the encoder's performance across a wide range of different configurations,\nleading CuPID to outperform state-of-the-art methods in a variety of downstream\ntasks.",
    "pdf_url": "http://arxiv.org/pdf/2502.21127v1",
    "published": "2025-02-28",
    "source": "arxiv",
    "id": "2502.21127v1",
    "categories": [
      "cs.LG"
    ]
  },
  {
    "title": "Causality Is Key to Understand and Balance Multiple Goals in Trustworthy ML and Foundation Models",
    "authors": [
      "Ruta Binkyte",
      "Ivaxi Sheth",
      "Zhijing Jin",
      "Mohammad Havaei",
      "Bernhard Schölkopf",
      "Mario Fritz"
    ],
    "abstract": "Ensuring trustworthiness in machine learning (ML) systems is crucial as they\nbecome increasingly embedded in high-stakes domains. This paper advocates for\nintegrating causal methods into machine learning to navigate the trade-offs\namong key principles of trustworthy ML, including fairness, privacy,\nrobustness, accuracy, and explainability. While these objectives should ideally\nbe satisfied simultaneously, they are often addressed in isolation, leading to\nconflicts and suboptimal solutions. Drawing on existing applications of\ncausality in ML that successfully align goals such as fairness and accuracy or\nprivacy and robustness, this paper argues that a causal approach is essential\nfor balancing multiple competing objectives in both trustworthy ML and\nfoundation models. Beyond highlighting these trade-offs, we examine how\ncausality can be practically integrated into ML and foundation models, offering\nsolutions to enhance their reliability and interpretability. Finally, we\ndiscuss the challenges, limitations, and opportunities in adopting causal\nframeworks, paving the way for more accountable and ethically sound AI systems.",
    "pdf_url": "http://arxiv.org/pdf/2502.21123v2",
    "published": "2025-02-28",
    "source": "arxiv",
    "id": "2502.21123v2",
    "categories": [
      "cs.LG",
      "cs.AI"
    ]
  },
  {
    "title": "The two filter formula reconsidered: Smoothing in partially observed Gauss--Markov models without information parametrization",
    "authors": [
      "Filip Tronarp"
    ],
    "abstract": "In this article, the two filter formula is re-examined in the setting of\npartially observed Gauss--Markov models. It is traditionally formulated as a\nfilter running backward in time, where the Gaussian density is parametrized in\n``information form''. However, the quantity in the backward recursion is\nstrictly speaking not a distribution, but a likelihood. Taking this observation\nseriously, a recursion over log-quadratic likelihoods is formulated instead,\nwhich obviates the need for ``information'' parametrization. In particular, it\ngreatly simplifies the square-root formulation of the algorithm. Furthermore,\nformulae are given for producing the forward Markov representation of the a\nposteriori distribution over paths from the proposed likelihood representation.",
    "pdf_url": "http://arxiv.org/pdf/2502.21116v1",
    "published": "2025-02-28",
    "source": "arxiv",
    "id": "2502.21116v1",
    "categories": [
      "stat.ME",
      "cs.LG"
    ]
  },
  {
    "title": "Software development projects as a way for multidisciplinary soft and future skills education",
    "authors": [
      "Krzysztof Podlaski",
      "Michal Beczkowski",
      "Katharina Simbeck",
      "Katrin Dziergwa",
      "Derek O'Reilly",
      "Shane Dowdall",
      "Joao Monteiro",
      "Catarina Oliveira Lucas",
      "Johanna Hautamaki",
      "Heikki Ahonen",
      "Hiram Bollaert",
      "Philippe Possemiers",
      "Zofia Stawska"
    ],
    "abstract": "Soft and future skills are in high demand in the modern job market. These\nskills are required for both technical and non-technical people. It is\ndifficult to teach these competencies in a classical academic environment.\n  The paper presents a possible approach to teaching in soft and future skills\nin a short, intensive joint project. In our case, it is a project within the\nErasmus+ framework, but it can be organized in many different frameworks.\n  In the project we use problem based learning, active learning and group-work\nteaching methodologies. Moreover, the approach put high emphasizes diversity.\nWe arrange a set of multidisciplinary students in groups. Each group is working\non software development tasks. This type of projects demand diversity, and only\na part of the team needs technical skills. In our case less than half of\nparticipants had computer science background. Additionally, software\ndevelopment projects are usually interesting for non-technical students.\n  The multicultural, multidisciplinary and international aspects are very\nimportant in a modern global working environment. On the other hand, short time\nof the project and its intensity allow to simulate stressful situations in a\nreal word tasks. The effects of the project on the required competencies are\nmeasured using the KYSS method.\n  The results prove that the presented method increased participants soft\nskills in communication, cooperation, digital skills and self reflection.",
    "pdf_url": "http://arxiv.org/pdf/2502.21114v1",
    "published": "2025-02-28",
    "source": "arxiv",
    "id": "2502.21114v1",
    "categories": [
      "cs.CY"
    ]
  },
  {
    "title": "Rare event modeling with self-regularized normalizing flows: what can we learn from a single failure?",
    "authors": [
      "Charles Dawson",
      "Van Tran",
      "Max Z. Li",
      "Chuchu Fan"
    ],
    "abstract": "Increased deployment of autonomous systems in fields like transportation and\nrobotics have seen a corresponding increase in safety-critical failures. These\nfailures can be difficult to model and debug due to the relative lack of data:\ncompared to tens of thousands of examples from normal operations, we may have\nonly seconds of data leading up to the failure. This scarcity makes it\nchallenging to train generative models of rare failure events, as existing\nmethods risk either overfitting to noise in the limited failure dataset or\nunderfitting due to an overly strong prior. We address this challenge with\nCalNF, or calibrated normalizing flows, a self-regularized framework for\nposterior learning from limited data. CalNF achieves state-of-the-art\nperformance on data-limited failure modeling and inverse problems and enables a\nfirst-of-a-kind case study into the root causes of the 2022 Southwest Airlines\nscheduling crisis.",
    "pdf_url": "http://arxiv.org/pdf/2502.21110v1",
    "published": "2025-02-28",
    "source": "arxiv",
    "id": "2502.21110v1",
    "categories": [
      "cs.LG",
      "stat.ML"
    ]
  },
  {
    "title": "\"No negatives needed\": weakly-supervised regression for interpretable tumor detection in whole-slide histopathology images",
    "authors": [
      "Marina D'Amato",
      "Jeroen van der Laak",
      "Francesco Ciompi"
    ],
    "abstract": "Accurate tumor detection in digital pathology whole-slide images (WSIs) is\ncrucial for cancer diagnosis and treatment planning. Multiple Instance Learning\n(MIL) has emerged as a widely used approach for weakly-supervised tumor\ndetection with large-scale data without the need for manual annotations.\nHowever, traditional MIL methods often depend on classification tasks that\nrequire tumor-free cases as negative examples, which are challenging to obtain\nin real-world clinical workflows, especially for surgical resection specimens.\nWe address this limitation by reformulating tumor detection as a regression\ntask, estimating tumor percentages from WSIs, a clinically available target\nacross multiple cancer types. In this paper, we provide an analysis of the\nproposed weakly-supervised regression framework by applying it to multiple\norgans, specimen types and clinical scenarios. We characterize the robustness\nof our framework to tumor percentage as a noisy regression target, and\nintroduce a novel concept of amplification technique to improve tumor detection\nsensitivity when learning from small tumor regions. Finally, we provide\ninterpretable insights into the model's predictions by analyzing visual\nattention and logit maps. Our code is available at\nhttps://github.com/DIAGNijmegen/tumor-percentage-mil-regression.",
    "pdf_url": "http://arxiv.org/pdf/2502.21109v1",
    "published": "2025-02-28",
    "source": "arxiv",
    "id": "2502.21109v1",
    "categories": [
      "eess.IV",
      "cs.CV"
    ]
  },
  {
    "title": "Parameter-Varying Feedforward Control: A Kernel-Based Learning Approach",
    "authors": [
      "Max van Haren",
      "Lennart Blanken",
      "Tom Oomen"
    ],
    "abstract": "The increasing demands for high accuracy in mechatronic systems necessitate\nthe incorporation of parameter variations in feedforward control. The aim of\nthis paper is to develop a data-driven approach for direct learning of\nparameter-varying feedforward control to increase tracking performance. The\ndeveloped approach is based on kernel-regularized function estimation in\nconjunction with iterative learning to directly learn parameter-varying\nfeedforward control from data. This approach enables high tracking performance\nfor feedforward control of linear parameter-varying dynamics, providing\nflexibility to varying reference tasks. The developed framework is validated on\na benchmark industrial experimental setup featuring a belt-driven carriage.",
    "pdf_url": "http://arxiv.org/pdf/2502.21105v1",
    "published": "2025-02-28",
    "source": "arxiv",
    "id": "2502.21105v1",
    "categories": [
      "eess.SY",
      "cs.SY"
    ]
  },
  {
    "title": "AuthSim: Towards Authentic and Effective Safety-critical Scenario Generation for Autonomous Driving Tests",
    "authors": [
      "Yukuan Yang",
      "Xucheng Lu",
      "Zhili Zhang",
      "Zepeng Wu",
      "Guoqi Li",
      "Lingzhong Meng",
      "Yunzhi Xue"
    ],
    "abstract": "Generating adversarial safety-critical scenarios is a pivotal method for\ntesting autonomous driving systems, as it identifies potential weaknesses and\nenhances system robustness and reliability. However, existing approaches\npredominantly emphasize unrestricted collision scenarios, prompting non-player\ncharacter (NPC) vehicles to attack the ego vehicle indiscriminately. These\nworks overlook these scenarios' authenticity, rationality, and relevance,\nresulting in numerous extreme, contrived, and largely unrealistic collision\nevents involving aggressive NPC vehicles. To rectify this issue, we propose a\nthree-layer relative safety region model, which partitions the area based on\ndanger levels and increases the likelihood of NPC vehicles entering relative\nboundary regions. This model directs NPC vehicles to engage in adversarial\nactions within relatively safe boundary regions, thereby augmenting the\nscenarios' authenticity. We introduce AuthSim, a comprehensive platform for\ngenerating authentic and effective safety-critical scenarios by integrating the\nthree-layer relative safety region model with reinforcement learning. To our\nknowledge, this is the first attempt to address the authenticity and\neffectiveness of autonomous driving system test scenarios comprehensively.\nExtensive experiments demonstrate that AuthSim outperforms existing methods in\ngenerating effective safety-critical scenarios. Notably, AuthSim achieves a\n5.25% improvement in average cut-in distance and a 27.12% enhancement in\naverage collision interval time, while maintaining higher efficiency in\ngenerating effective safety-critical scenarios compared to existing methods.\nThis underscores its significant advantage in producing authentic scenarios\nover current methodologies.",
    "pdf_url": "http://arxiv.org/pdf/2502.21100v1",
    "published": "2025-02-28",
    "source": "arxiv",
    "id": "2502.21100v1",
    "categories": [
      "cs.RO",
      "cs.AI"
    ]
  },
  {
    "title": "Adaptive Accelerated Proximal Gradient Methods with Variance Reduction for Composite Nonconvex Finite-Sum Minimization",
    "authors": [
      "Ganzhao Yuan"
    ],
    "abstract": "This paper proposes {\\sf AAPG-SPIDER}, an Adaptive Accelerated Proximal\nGradient (AAPG) method with variance reduction for minimizing composite\nnonconvex finite-sum functions. It integrates three acceleration techniques:\nadaptive stepsizes, Nesterov's extrapolation, and the recursive stochastic\npath-integrated estimator SPIDER. While targeting stochastic finite-sum\nproblems, {\\sf AAPG-SPIDER} simplifies to {\\sf AAPG} in the full-batch,\nnon-stochastic setting, which is also of independent interest. To our\nknowledge, {\\sf AAPG-SPIDER} and {\\sf AAPG} are the first learning-rate-free\nmethods to achieve optimal iteration complexity for this class of\n\\textit{composite} minimization problems. Specifically, {\\sf AAPG} achieves the\noptimal iteration complexity of $\\mathcal{O}(N \\epsilon^{-2})$, while {\\sf\nAAPG-SPIDER} achieves $\\mathcal{O}(N + \\sqrt{N} \\epsilon^{-2})$ for finding\n$\\epsilon$-approximate stationary points, where $N$ is the number of component\nfunctions. Under the Kurdyka-Lojasiewicz (KL) assumption, we establish\nnon-ergodic convergence rates for both methods. Preliminary experiments on\nsparse phase retrieval and linear eigenvalue problems demonstrate the superior\nperformance of {\\sf AAPG-SPIDER} and {\\sf AAPG} compared to existing methods.",
    "pdf_url": "http://arxiv.org/pdf/2502.21099v1",
    "published": "2025-02-28",
    "source": "arxiv",
    "id": "2502.21099v1",
    "categories": [
      "math.OC",
      "cs.CV",
      "cs.NA",
      "math.NA"
    ]
  },
  {
    "title": "Deep learning-based filtering of cross-spectral matrices using generative adversarial networks",
    "authors": [
      "Christof Puhle"
    ],
    "abstract": "In this paper, we present a deep-learning method to filter out effects such\nas ambient noise, reflections, or source directivity from microphone array data\nrepresented as cross-spectral matrices. Specifically, we focus on a generative\nadversarial network (GAN) architecture designed to transform fixed-size\ncross-spectral matrices. Theses models were trained using sound pressure\nsimulations of varying complexity developed for this purpose. Based on the\nresults from applying these methods in a hyperparameter optimization of an\nauto-encoding task, we trained the optimized model to perform five distinct\ntransformation tasks derived from different complexities inherent in our sound\npressure simulations.",
    "pdf_url": "http://arxiv.org/pdf/2502.21097v1",
    "published": "2025-02-28",
    "source": "arxiv",
    "id": "2502.21097v1",
    "categories": [
      "cs.SD",
      "eess.AS",
      "eess.SP"
    ]
  },
  {
    "title": "Are foundation models useful feature extractors for electroencephalography analysis?",
    "authors": [
      "Özgün Turgut",
      "Felix S. Bott",
      "Markus Ploner",
      "Daniel Rueckert"
    ],
    "abstract": "The success of foundation models in natural language processing and computer\nvision has motivated similar approaches for general time series analysis. While\nthese models are effective for a variety of tasks, their applicability in\nmedical domains with limited data remains largely unexplored. To address this,\nwe investigate the effectiveness of foundation models in medical time series\nanalysis involving electroencephalography (EEG). Through extensive experiments\non tasks such as age prediction, seizure detection, and the classification of\nclinically relevant EEG events, we compare their diagnostic accuracy with that\nof specialised EEG models. Our analysis shows that foundation models extract\nmeaningful EEG features, outperform specialised models even without domain\nadaptation, and localise task-specific biomarkers. Moreover, we demonstrate\nthat diagnostic accuracy is substantially influenced by architectural choices\nsuch as context length. Overall, our study reveals that foundation models with\ngeneral time series understanding eliminate the dependency on large\ndomain-specific datasets, making them valuable tools for clinical practice.",
    "pdf_url": "http://arxiv.org/pdf/2502.21086v1",
    "published": "2025-02-28",
    "source": "arxiv",
    "id": "2502.21086v1",
    "categories": [
      "cs.AI",
      "cs.LG"
    ]
  },
  {
    "title": "Enhancing deep neural networks through complex-valued representations and Kuramoto synchronization dynamics",
    "authors": [
      "Sabine Muzellec",
      "Andrea Alamia",
      "Thomas Serre",
      "Rufin VanRullen"
    ],
    "abstract": "Neural synchrony is hypothesized to play a crucial role in how the brain\norganizes visual scenes into structured representations, enabling the robust\nencoding of multiple objects within a scene. However, current deep learning\nmodels often struggle with object binding, limiting their ability to represent\nmultiple objects effectively. Inspired by neuroscience, we investigate whether\nsynchrony-based mechanisms can enhance object encoding in artificial models\ntrained for visual categorization. Specifically, we combine complex-valued\nrepresentations with Kuramoto dynamics to promote phase alignment, facilitating\nthe grouping of features belonging to the same object. We evaluate two\narchitectures employing synchrony: a feedforward model and a recurrent model\nwith feedback connections to refine phase synchronization using top-down\ninformation. Both models outperform their real-valued counterparts and\ncomplex-valued models without Kuramoto synchronization on tasks involving\nmulti-object images, such as overlapping handwritten digits, noisy inputs, and\nout-of-distribution transformations. Our findings highlight the potential of\nsynchrony-driven mechanisms to enhance deep learning models, improving their\nperformance, robustness, and generalization in complex visual categorization\ntasks.",
    "pdf_url": "http://arxiv.org/pdf/2502.21077v1",
    "published": "2025-02-28",
    "source": "arxiv",
    "id": "2502.21077v1",
    "categories": [
      "cs.CV",
      "cs.AI",
      "nlin.AO",
      "q-bio.NC"
    ]
  },
  {
    "title": "Spatial Reasoning with Denoising Models",
    "authors": [
      "Christopher Wewer",
      "Bart Pogodzinski",
      "Bernt Schiele",
      "Jan Eric Lenssen"
    ],
    "abstract": "We introduce Spatial Reasoning Models (SRMs), a framework to perform\nreasoning over sets of continuous variables via denoising generative models.\nSRMs infer continuous representations on a set of unobserved variables, given\nobservations on observed variables. Current generative models on spatial\ndomains, such as diffusion and flow matching models, often collapse to\nhallucination in case of complex distributions. To measure this, we introduce a\nset of benchmark tasks that test the quality of complex reasoning in generative\nmodels and can quantify hallucination. The SRM framework allows to report key\nfindings about importance of sequentialization in generation, the associated\norder, as well as the sampling strategies during training. It demonstrates, for\nthe first time, that order of generation can successfully be predicted by the\ndenoising network itself. Using these findings, we can increase the accuracy of\nspecific reasoning tasks from <1% to >50%.",
    "pdf_url": "http://arxiv.org/pdf/2502.21075v1",
    "published": "2025-02-28",
    "source": "arxiv",
    "id": "2502.21075v1",
    "categories": [
      "cs.CV",
      "cs.LG"
    ]
  },
  {
    "title": "CODI: Compressing Chain-of-Thought into Continuous Space via Self-Distillation",
    "authors": [
      "Zhenyi Shen",
      "Hanqi Yan",
      "Linhai Zhang",
      "Zhanghao Hu",
      "Yali Du",
      "Yulan He"
    ],
    "abstract": "Chain-of-Thought (CoT) enhances Large Language Models (LLMs) by enabling\nstep-by-step reasoning in natural language. However, the language space may be\nsuboptimal for reasoning. While implicit CoT methods attempt to enable\nreasoning without explicit CoT tokens, they have consistently lagged behind\nexplicit CoT method in task performance. We propose CODI (Continuous\nChain-of-Thought via Self-Distillation), a novel framework that distills CoT\ninto a continuous space, where a shared model acts as both teacher and student,\njointly learning explicit and implicit CoT while aligning their hidden\nactivation on the token generating the final answer. CODI is the first implicit\nCoT method to match explicit CoT's performance on GSM8k while achieving 3.1x\ncompression, surpassing the previous state-of-the-art by 28.2% in accuracy.\nFurthermore, CODI demonstrates scalability, robustness, and generalizability to\nmore complex CoT datasets. Additionally, CODI retains interpretability by\ndecoding its continuous thoughts, making its reasoning process transparent. Our\nfindings establish implicit CoT as not only a more efficient but a powerful\nalternative to explicit CoT.",
    "pdf_url": "http://arxiv.org/pdf/2502.21074v1",
    "published": "2025-02-28",
    "source": "arxiv",
    "id": "2502.21074v1",
    "categories": [
      "cs.CL"
    ]
  },
  {
    "title": "Efficient Transformer-based Decoder for Varshamov-Tenengolts Codes",
    "authors": [
      "Yali Wei",
      "Alan J. X. Guo",
      "Zihui Yan",
      "Yufan Dai"
    ],
    "abstract": "In recent years, the rise of DNA data storage technology has brought\nsignificant attention to the challenge of correcting insertion, deletion, and\nsubstitution (IDS) errors. Among various coding methods for IDS correction,\nVarshamov-Tenengolts (VT) codes, primarily designed for single-error\ncorrection, have emerged as a central research focus. While existing decoding\nmethods achieve high accuracy in correcting a single error, they often fail to\ncorrect multiple IDS errors. In this work, we observe that VT codes retain some\ncapability for addressing multiple errors by introducing a transformer-based VT\ndecoder (TVTD) along with symbol- and statistic-based codeword embedding.\nExperimental results demonstrate that the proposed TVTD achieves perfect\ncorrection of a single error. Furthermore, when decoding multiple errors across\nvarious codeword lengths, the bit error rate and frame error rate are\nsignificantly improved compared to existing hard decision and soft-in soft-out\nalgorithms. Additionally, through model architecture optimization, the proposed\nmethod reduces time consumption by an order of magnitude compared to other soft\ndecoders.",
    "pdf_url": "http://arxiv.org/pdf/2502.21060v1",
    "published": "2025-02-28",
    "source": "arxiv",
    "id": "2502.21060v1",
    "categories": [
      "cs.LG",
      "cs.IT",
      "math.IT"
    ]
  },
  {
    "title": "FC-Attack: Jailbreaking Large Vision-Language Models via Auto-Generated Flowcharts",
    "authors": [
      "Ziyi Zhang",
      "Zhen Sun",
      "Zongmin Zhang",
      "Jihui Guo",
      "Xinlei He"
    ],
    "abstract": "Large Vision-Language Models (LVLMs) have become powerful and widely adopted\nin some practical applications. However, recent research has revealed their\nvulnerability to multimodal jailbreak attacks, whereby the model can be induced\nto generate harmful content, leading to safety risks. Although most LVLMs have\nundergone safety alignment, recent research shows that the visual modality is\nstill vulnerable to jailbreak attacks. In our work, we discover that by using\nflowcharts with partially harmful information, LVLMs can be induced to provide\nadditional harmful details. Based on this, we propose a jailbreak attack method\nbased on auto-generated flowcharts, FC-Attack. Specifically, FC-Attack first\nfine-tunes a pre-trained LLM to create a step-description generator based on\nbenign datasets. The generator is then used to produce step descriptions\ncorresponding to a harmful query, which are transformed into flowcharts in 3\ndifferent shapes (vertical, horizontal, and S-shaped) as visual prompts. These\nflowcharts are then combined with a benign textual prompt to execute a\njailbreak attack on LVLMs. Our evaluations using the Advbench dataset show that\nFC-Attack achieves over 90% attack success rates on Gemini-1.5, Llaval-Next,\nQwen2-VL, and InternVL-2.5 models, outperforming existing LVLM jailbreak\nmethods. Additionally, we investigate factors affecting the attack performance,\nincluding the number of steps and the font styles in the flowcharts. Our\nevaluation shows that FC-Attack can improve the jailbreak performance from 4%\nto 28% in Claude-3.5 by changing the font style. To mitigate the attack, we\nexplore several defenses and find that AdaShield can largely reduce the\njailbreak performance but with the cost of utility drop.",
    "pdf_url": "http://arxiv.org/pdf/2502.21059v1",
    "published": "2025-02-28",
    "source": "arxiv",
    "id": "2502.21059v1",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.CR",
      "cs.LG"
    ]
  },
  {
    "title": "Robust Deterministic Policy Gradient for Disturbance Attenuation and Its Application to Quadrotor Control",
    "authors": [
      "Taeho Lee",
      "Donghwan Lee"
    ],
    "abstract": "Practical control systems pose significant challenges in identifying optimal\ncontrol policies due to uncertainties in the system model and external\ndisturbances. While $H_\\infty$ control techniques are commonly used to design\nrobust controllers that mitigate the effects of disturbances, these methods\noften require complex and computationally intensive calculations. To address\nthis issue, this paper proposes a reinforcement learning algorithm called\nRobust Deterministic Policy Gradient (RDPG), which formulates the $H_\\infty$\ncontrol problem as a two-player zero-sum dynamic game. In this formulation, one\nplayer (the user) aims to minimize the cost, while the other player (the\nadversary) seeks to maximize it. We then employ deterministic policy gradient\n(DPG) and its deep reinforcement learning counterpart to train a robust control\npolicy with effective disturbance attenuation. In particular, for practical\nimplementation, we introduce an algorithm called robust deep deterministic\npolicy gradient (RDDPG), which employs a deep neural network architecture and\nintegrates techniques from the twin-delayed deep deterministic policy gradient\n(TD3) to enhance stability and learning efficiency. To evaluate the proposed\nalgorithm, we implement it on an unmanned aerial vehicle (UAV) tasked with\nfollowing a predefined path in a disturbance-prone environment. The\nexperimental results demonstrate that the proposed method outperforms other\ncontrol approaches in terms of robustness against disturbances, enabling\nprecise real-time tracking of moving targets even under severe disturbance\nconditions.",
    "pdf_url": "http://arxiv.org/pdf/2502.21057v1",
    "published": "2025-02-28",
    "source": "arxiv",
    "id": "2502.21057v1",
    "categories": [
      "cs.RO",
      "cs.AI"
    ]
  },
  {
    "title": "Quantum-aware Transformer model for state classification",
    "authors": [
      "Przemysław Sekuła",
      "Michał Romaszewski",
      "Przemysław Głomb",
      "Michał Cholewa",
      "Łukasz Pawela"
    ],
    "abstract": "Entanglement is a fundamental feature of quantum mechanics, playing a crucial\nrole in quantum information processing. However, classifying entangled states,\nparticularly in the mixed-state regime, remains a challenging problem,\nespecially as system dimensions increase. In this work, we focus on bipartite\nquantum states and present a data-driven approach to entanglement\nclassification using transformer-based neural networks. Our dataset consists of\na diverse set of bipartite states, including pure separable states, Werner\nentangled states, general entangled states, and maximally entangled states. We\npretrain the transformer in an unsupervised fashion by masking elements of\nvectorized Hermitian matrix representations of quantum states, allowing the\nmodel to learn structural properties of quantum density matrices. This approach\nenables the model to generalize entanglement characteristics across different\nclasses of states. Once trained, our method achieves near-perfect\nclassification accuracy, effectively distinguishing between separable and\nentangled states. Compared to previous Machine Learning, our method\nsuccessfully adapts transformers for quantum state analysis, demonstrating\ntheir ability to systematically identify entanglement in bipartite systems.\nThese results highlight the potential of modern machine learning techniques in\nautomating entanglement detection and classification, bridging the gap between\nquantum information theory and artificial intelligence.",
    "pdf_url": "http://arxiv.org/pdf/2502.21055v1",
    "published": "2025-02-28",
    "source": "arxiv",
    "id": "2502.21055v1",
    "categories": [
      "quant-ph",
      "cs.LG",
      "81P45, 68T05",
      "I.2.6"
    ]
  },
  {
    "title": "HoloMine: A Synthetic Dataset for Buried Landmines Recognition using Microwave Holographic Imaging",
    "authors": [
      "Emanuele Vivoli",
      "Lorenzo Capineri",
      "Marco Bertini"
    ],
    "abstract": "The detection and removal of landmines is a complex and risky task that\nrequires advanced remote sensing techniques to reduce the risk for the\nprofessionals involved in this task. In this paper, we propose a novel\nsynthetic dataset for buried landmine detection to provide researchers with a\nvaluable resource to observe, measure, locate, and address issues in landmine\ndetection. The dataset consists of 41,800 microwave holographic images (2D) and\ntheir holographic inverted scans (3D) of different types of buried objects,\nincluding landmines, clutter, and pottery objects, and is collected by means of\na microwave holography sensor.\n  We evaluate the performance of several state-of-the-art deep learning models\ntrained on our synthetic dataset for various classification tasks. While the\nresults do not yield yet high performances, showing the difficulty of the\nproposed task, we believe that our dataset has significant potential to drive\nprogress in the field of landmine detection thanks to the accuracy and\nresolution obtainable using holographic radars.\n  To the best of our knowledge, our dataset is the first of its kind and will\nhelp drive further research on computer vision methods to automatize mine\ndetection, with the overall goal of reducing the risks and the costs of the\ndemining process.",
    "pdf_url": "http://arxiv.org/pdf/2502.21054v1",
    "published": "2025-02-28",
    "source": "arxiv",
    "id": "2502.21054v1",
    "categories": [
      "cs.CV",
      "eess.IV",
      "eess.SP"
    ]
  },
  {
    "title": "Detection of anomalies in cow activity using wavelet transform based features",
    "authors": [
      "Valentin Guien",
      "Violaine Antoine",
      "Romain Lardy",
      "Isabelle Veissier",
      "Luis E C Rocha"
    ],
    "abstract": "In Precision Livestock Farming, detecting deviations from optimal or baseline\nvalues - i.e. anomalies in time series - is essential to allow undertaking\ncorrective actions rapidly. Here we aim at detecting anomalies in 24h time\nseries of cow activity, with a view to detect cases of disease or oestrus.\nDeviations must be distinguished from noise which can be very high in case of\nbiological data. It is also important to detect the anomaly early, e.g. before\na farmer would notice it visually. Here, we investigate the benefit of using\nwavelet transforms to denoise data and we assess the performance of an anomaly\ndetection algorithm considering the timing of the detection. We developed\nfeatures based on the comparisons between the wavelet transforms of the mean of\nthe time series and the wavelet transforms of individual time series instances.\nWe hypothesized that these features contribute to the detection of anomalies in\nperiodic time series using a feature-based algorithm. We tested this hypothesis\nwith two datasets representing cow activity, which typically follows a daily\npattern but can deviate due to specific physiological or pathological\nconditions. We applied features derived from wavelet transform as well as\nstatistical features in an Isolation Forest algorithm. We measured the distance\nof detection between the days annotated abnormal by animal caretakers days and\nthe days predicted abnormal by the algorithm. The results show that\nwavelet-based features are among the features most contributing to anomaly\ndetection. They also show that detections are close to the annotated days, and\noften precede it. In conclusion, using wavelet transforms on time series of cow\nactivity data helps to detect anomalies related to specific cow states. The\ndetection is often obtained on days that precede the day annotated by\ncaretakers, which offer possibility to take corrective actions at an early\nstage.",
    "pdf_url": "http://arxiv.org/pdf/2502.21051v1",
    "published": "2025-02-28",
    "source": "arxiv",
    "id": "2502.21051v1",
    "categories": [
      "cs.LG",
      "cs.CE"
    ]
  },
  {
    "title": "Synthesizing Individualized Aging Brains in Health and Disease with Generative Models and Parallel Transport",
    "authors": [
      "Jingru Fu",
      "Yuqi Zheng",
      "Neel Dey",
      "Daniel Ferreira",
      "Rodrigo Moreno"
    ],
    "abstract": "Simulating prospective magnetic resonance imaging (MRI) scans from a given\nindividual brain image is challenging, as it requires accounting for canonical\nchanges in aging and/or disease progression while also considering the\nindividual brain's current status and unique characteristics. While current\ndeep generative models can produce high-resolution anatomically accurate\ntemplates for population-wide studies, their ability to predict future aging\ntrajectories for individuals remains limited, particularly in capturing\nsubject-specific neuroanatomical variations over time. In this study, we\nintroduce Individualized Brain Synthesis (InBrainSyn), a framework for\nsynthesizing high-resolution subject-specific longitudinal MRI scans that\nsimulate neurodegeneration in both Alzheimer's disease (AD) and normal aging.\nInBrainSyn uses a parallel transport algorithm to adapt the population-level\naging trajectories learned by a generative deep template network, enabling\nindividualized aging synthesis. As InBrainSyn uses diffeomorphic\ntransformations to simulate aging, the synthesized images are topologically\nconsistent with the original anatomy by design. We evaluated InBrainSyn both\nquantitatively and qualitatively on AD and healthy control cohorts from the\nOpen Access Series of Imaging Studies - version 3 dataset. Experimentally,\nInBrainSyn can also model neuroanatomical transitions between normal aging and\nAD. An evaluation of an external set supports its generalizability. Overall,\nwith only a single baseline scan, InBrainSyn synthesizes realistic 3D\nspatiotemporal T1w MRI scans, producing personalized longitudinal aging\ntrajectories. The code for InBrainSyn is available at:\nhttps://github.com/Fjr9516/InBrainSyn.",
    "pdf_url": "http://arxiv.org/pdf/2502.21049v1",
    "published": "2025-02-28",
    "source": "arxiv",
    "id": "2502.21049v1",
    "categories": [
      "cs.CV",
      "cs.AI",
      "eess.IV"
    ]
  },
  {
    "title": "Data-free Universal Adversarial Perturbation with Pseudo-semantic Prior",
    "authors": [
      "Chanhui Lee",
      "Yeonghwan Song",
      "Jeany Son"
    ],
    "abstract": "Data-free Universal Adversarial Perturbation (UAP) is an image-agnostic\nadversarial attack that deceives deep neural networks using a single\nperturbation generated solely from random noise, without any data priors.\nHowever, traditional data-free UAP methods often suffer from limited\ntransferability due to the absence of semantic information in random noise. To\naddress this, we propose a novel data-free universal attack approach that\ngenerates a pseudo-semantic prior recursively from the UAPs, enriching semantic\ncontents within the data-free UAP framework. Our method is based on the\nobservation that UAPs inherently contain latent semantic information, enabling\nthe generated UAP to act as an alternative data prior, by capturing a diverse\nrange of semantics through region sampling. We further introduce a sample\nreweighting technique to emphasize hard examples by focusing on samples that\nare less affected by the UAP. By leveraging the semantic information from the\npseudo-semantic prior, we also incorporate input transformations, typically\nineffective in data-free UAPs due to the lack of semantic content in random\npriors, to boost black-box transferability. Comprehensive experiments on\nImageNet show that our method achieves state-of-the-art performance in average\nfooling rate by a substantial margin, significantly improves attack\ntransferability across various CNN architectures compared to existing data-free\nUAP methods, and even surpasses data-dependent UAP methods.",
    "pdf_url": "http://arxiv.org/pdf/2502.21048v1",
    "published": "2025-02-28",
    "source": "arxiv",
    "id": "2502.21048v1",
    "categories": [
      "cs.CV"
    ]
  },
  {
    "title": "Incorporating Long-Range Interactions via the Multipole Expansion into Ground and Excited-State Molecular Simulations",
    "authors": [
      "Rhyan Barrett",
      "Johannes C. B. Dietschreit",
      "Julia Westermayr"
    ],
    "abstract": "Simulating long-range interactions remains a significant challenge for\nmolecular machine learning potentials due to the need to accurately capture\ninteractions over large spatial regions. In this work, we introduce FieldMACE,\nan extension of the message-passing atomic cluster expansion (MACE)\narchitecture that integrates the multipole expansion to model long-range\ninteractions more efficiently. By incorporating the multipole expansion,\nFieldMACE effectively captures environmental and long-range effects in both\nground and excited states. Benchmark evaluations demonstrate its superior\nperformance in predictions and computational efficiency compared to previous\narchitectures, as well as its ability to accurately simulate nonadiabatic\nexcited-state dynamics. Furthermore, transfer learning from foundational models\nenhances data efficiency, making FieldMACE a scalable, robust, and transferable\nframework for large-scale molecular simulations.",
    "pdf_url": "http://arxiv.org/pdf/2502.21045v1",
    "published": "2025-02-28",
    "source": "arxiv",
    "id": "2502.21045v1",
    "categories": [
      "physics.comp-ph",
      "math-ph",
      "math.MP"
    ]
  },
  {
    "title": "Fast Adversarial Training against Sparse Attacks Requires Loss Smoothing",
    "authors": [
      "Xuyang Zhong",
      "Yixiao Huang",
      "Chen Liu"
    ],
    "abstract": "This paper studies fast adversarial training against sparse adversarial\nperturbations bounded by $l_0$ norm. We demonstrate the challenges of employing\n$1$-step attacks on $l_0$ bounded perturbations for fast adversarial training,\nincluding degraded performance and the occurrence of catastrophic overfitting\n(CO). We highlight that CO in $l_0$ adversarial training is caused by\nsub-optimal perturbation locations of $1$-step attack. Theoretical and\nempirical analyses reveal that the loss landscape of $l_0$ adversarial training\nis more craggy compared to its $l_\\infty$, $l_2$ and $l_1$ counterparts.\nMoreover, we corroborate that the craggy loss landscape can aggravate CO. To\naddress these issues, we propose Fast-LS-$l_0$ that incorporates soft labels\nand the trade-off loss function to smooth the adversarial loss landscape.\nExtensive experiments demonstrate our method can overcome the challenge of\ncatastrophic overfitting, achieve state-of-the-art performance, and narrow down\nthe performance gap between $1$-step and multi-step adversarial training\nagainst sparse attacks.",
    "pdf_url": "http://arxiv.org/pdf/2502.21041v1",
    "published": "2025-02-28",
    "source": "arxiv",
    "id": "2502.21041v1",
    "categories": [
      "cs.LG",
      "cs.AI"
    ]
  },
  {
    "title": "Reward Learning from Multiple Feedback Types",
    "authors": [
      "Yannick Metz",
      "András Geiszl",
      "Raphaël Baur",
      "Mennatallah El-Assady"
    ],
    "abstract": "Learning rewards from preference feedback has become an important tool in the\nalignment of agentic models. Preference-based feedback, often implemented as a\nbinary comparison between multiple completions, is an established method to\nacquire large-scale human feedback. However, human feedback in other contexts\nis often much more diverse. Such diverse feedback can better support the goals\nof a human annotator, and the simultaneous use of multiple sources might be\nmutually informative for the learning process or carry type-dependent biases\nfor the reward learning process. Despite these potential benefits, learning\nfrom different feedback types has yet to be explored extensively. In this\npaper, we bridge this gap by enabling experimentation and evaluating multi-type\nfeedback in a broad set of environments. We present a process to generate\nhigh-quality simulated feedback of six different types. Then, we implement\nreward models and downstream RL training for all six feedback types. Based on\nthe simulated feedback, we investigate the use of types of feedback across ten\nRL environments and compare them to pure preference-based baselines. We show\nempirically that diverse types of feedback can be utilized and lead to strong\nreward modeling performance. This work is the first strong indicator of the\npotential of multi-type feedback for RLHF.",
    "pdf_url": "http://arxiv.org/pdf/2502.21038v1",
    "published": "2025-02-28",
    "source": "arxiv",
    "id": "2502.21038v1",
    "categories": [
      "cs.LG",
      "cs.AI"
    ]
  },
  {
    "title": "S4ConvD: Adaptive Scaling and Frequency Adjustment for Energy-Efficient Sensor Networks in Smart Buildings",
    "authors": [
      "Melanie Schaller",
      "Bodo Rosenhahn"
    ],
    "abstract": "Predicting energy consumption in smart buildings is challenging due to\ndependencies in sensor data and the variability of environmental conditions. We\nintroduce S4ConvD, a novel convolutional variant of Deep State Space Models\n(Deep-SSMs), that minimizes reliance on extensive preprocessing steps. S4ConvD\nis designed to optimize runtime in resource-constrained environments. By\nimplementing adaptive scaling and frequency adjustments, this model shows to\ncapture complex temporal patterns in building energy dynamics. Experiments on\nthe ASHRAE Great Energy Predictor III dataset reveal that S4ConvD outperforms\ncurrent benchmarks. Additionally, S4ConvD benefits from significant\nimprovements in GPU runtime through the use of Block Tiling optimization\ntechniques. Thus, S4ConvD has the potential for practical deployment in\nreal-time energy modeling. Furthermore, the complete codebase and dataset are\naccessible on GitHub, fostering open-source contributions and facilitating\nfurther research. Our method also promotes resource-efficient model execution,\nenhancing both energy forecasting and the potential integration of renewable\nenergy sources into smart grid systems.",
    "pdf_url": "http://arxiv.org/pdf/2502.21035v1",
    "published": "2025-02-28",
    "source": "arxiv",
    "id": "2502.21035v1",
    "categories": [
      "cs.LG"
    ]
  },
  {
    "title": "Synthesizing Tabular Data Using Selectivity Enhanced Generative Adversarial Networks",
    "authors": [
      "Youran Zhou",
      "Jianzhong Qi"
    ],
    "abstract": "As E-commerce platforms face surging transactions during major shopping\nevents like Black Friday, stress testing with synthesized data is crucial for\nresource planning. Most recent studies use Generative Adversarial Networks\n(GANs) to generate tabular data while ensuring privacy and machine learning\nutility. However, these methods overlook the computational demands of\nprocessing GAN-generated data, making them unsuitable for E-commerce stress\ntesting.\n  This thesis introduces a novel GAN-based approach incorporating query\nselectivity constraints, a key factor in database transaction processing. We\nintegrate a pre-trained deep neural network to maintain selectivity consistency\nbetween real and synthetic data. Our method, tested on five real-world\ndatasets, outperforms three state-of-the-art GANs and a VAE model, improving\nselectivity estimation accuracy by up to 20pct and machine learning utility by\nup to 6 pct.",
    "pdf_url": "http://arxiv.org/pdf/2502.21034v1",
    "published": "2025-02-28",
    "source": "arxiv",
    "id": "2502.21034v1",
    "categories": [
      "cs.LG",
      "cs.AI"
    ]
  },
  {
    "title": "A data augmentation strategy for deep neural networks with application to epidemic modelling",
    "authors": [
      "Muhammad Awais",
      "Abu Sayfan Ali",
      "Giacomo Dimarco",
      "Federica Ferrarese",
      "Lorenzo Pareschi"
    ],
    "abstract": "In this work, we integrate the predictive capabilities of compartmental\ndisease dynamics models with machine learning ability to analyze complex,\nhigh-dimensional data and uncover patterns that conventional models may\noverlook. Specifically, we present a proof of concept demonstrating the\napplication of data-driven methods and deep neural networks to a recently\nintroduced SIR-type model with social features, including a saturated incidence\nrate, to improve epidemic prediction and forecasting. Our results show that a\nrobust data augmentation strategy trough suitable data-driven models can\nimprove the reliability of Feed-Forward Neural Networks (FNNs) and Nonlinear\nAutoregressive Networks (NARs), making them viable alternatives to\nPhysics-Informed Neural Networks (PINNs). This approach enhances the ability to\nhandle nonlinear dynamics and offers scalable, data-driven solutions for\nepidemic forecasting, prioritizing predictive accuracy over the constraints of\nphysics-based models. Numerical simulations of the post-lockdown phase of the\nCOVID-19 epidemic in Italy and Spain validate our methodology.",
    "pdf_url": "http://arxiv.org/pdf/2502.21033v1",
    "published": "2025-02-28",
    "source": "arxiv",
    "id": "2502.21033v1",
    "categories": [
      "math.NA",
      "cs.LG",
      "cs.NA",
      "physics.soc-ph",
      "q-bio.PE",
      "stat.ML"
    ]
  },
  {
    "title": "Sixth-Sense: Self-Supervised Learning of Spatial Awareness of Humans from a Planar Lidar",
    "authors": [
      "Simone Arreghini",
      "Nicholas Carlotti",
      "Mirko Nava",
      "Antonio Paolillo",
      "Alessandro Giusti"
    ],
    "abstract": "Localizing humans is a key prerequisite for any service robot operating in\nproximity to people. In these scenarios, robots rely on a multitude of\nstate-of-the-art detectors usually designed to operate with RGB-D cameras or\nexpensive 3D LiDARs. However, most commercially available service robots are\nequipped with cameras with a narrow field of view, making them blind when a\nuser is approaching from other directions, or inexpensive 1D LiDARs whose\nreadings are difficult to interpret. To address these limitations, we propose a\nself-supervised approach to detect humans and estimate their 2D pose from 1D\nLiDAR data, using detections from an RGB-D camera as a supervision source. Our\napproach aims to provide service robots with spatial awareness of nearby\nhumans. After training on 70 minutes of data autonomously collected in two\nenvironments, our model is capable of detecting humans omnidirectionally from\n1D LiDAR data in a novel environment, with 71% precision and 80% recall, while\nretaining an average absolute error of 13 cm in distance and 44{\\deg} in\norientation.",
    "pdf_url": "http://arxiv.org/pdf/2502.21029v1",
    "published": "2025-02-28",
    "source": "arxiv",
    "id": "2502.21029v1",
    "categories": [
      "cs.RO",
      "cs.LG"
    ]
  },
  {
    "title": "AutoQML: A Framework for Automated Quantum Machine Learning",
    "authors": [
      "Marco Roth",
      "David A. Kreplin",
      "Daniel Basilewitsch",
      "João F. Bravo",
      "Dennis Klau",
      "Milan Marinov",
      "Daniel Pranjic",
      "Horst Stuehler",
      "Moritz Willmann",
      "Marc-André Zöller"
    ],
    "abstract": "Automated Machine Learning (AutoML) has significantly advanced the efficiency\nof ML-focused software development by automating hyperparameter optimization\nand pipeline construction, reducing the need for manual intervention. Quantum\nMachine Learning (QML) offers the potential to surpass classical machine\nlearning (ML) capabilities by utilizing quantum computing. However, the\ncomplexity of QML presents substantial entry barriers. We introduce\n\\emph{AutoQML}, a novel framework that adapts the AutoML approach to QML,\nproviding a modular and unified programming interface to facilitate the\ndevelopment of QML pipelines. AutoQML leverages the QML library sQUlearn to\nsupport a variety of QML algorithms. The framework is capable of constructing\nend-to-end pipelines for supervised learning tasks, ensuring accessibility and\nefficacy. We evaluate AutoQML across four industrial use cases, demonstrating\nits ability to generate high-performing QML pipelines that are competitive with\nboth classical ML models and manually crafted quantum solutions.",
    "pdf_url": "http://arxiv.org/pdf/2502.21025v1",
    "published": "2025-02-28",
    "source": "arxiv",
    "id": "2502.21025v1",
    "categories": [
      "quant-ph",
      "cs.LG"
    ]
  },
  {
    "title": "When Unsupervised Domain Adaptation meets One-class Anomaly Detection: Addressing the Two-fold Unsupervised Curse by Leveraging Anomaly Scarcity",
    "authors": [
      "Nesryne Mejri",
      "Enjie Ghorbel",
      "Anis Kacem",
      "Pavel Chernakov",
      "Niki Foteinopoulou",
      "Djamila Aouada"
    ],
    "abstract": "This paper introduces the first fully unsupervised domain adaptation (UDA)\nframework for unsupervised anomaly detection (UAD). The performance of UAD\ntechniques degrades significantly in the presence of a domain shift, difficult\nto avoid in a real-world setting. While UDA has contributed to solving this\nissue in binary and multi-class classification, such a strategy is ill-posed in\nUAD. This might be explained by the unsupervised nature of the two tasks,\nnamely, domain adaptation and anomaly detection. Herein, we first formulate\nthis problem that we call the two-fold unsupervised curse. Then, we propose a\npioneering solution to this curse, considered intractable so far, by assuming\nthat anomalies are rare. Specifically, we leverage clustering techniques to\nidentify a dominant cluster in the target feature space. Posed as the normal\ncluster, the latter is aligned with the source normal features. Concretely,\ngiven a one-class source set and an unlabeled target set composed mostly of\nnormal data and some anomalies, we fit the source features within a hypersphere\nwhile jointly aligning them with the features of the dominant cluster from the\ntarget set. The paper provides extensive experiments and analysis on common\nadaptation benchmarks for anomaly detection, demonstrating the relevance of\nboth the newly introduced paradigm and the proposed approach. The code will be\nmade publicly available.",
    "pdf_url": "http://arxiv.org/pdf/2502.21022v1",
    "published": "2025-02-28",
    "source": "arxiv",
    "id": "2502.21022v1",
    "categories": [
      "cs.LG",
      "cs.CV"
    ]
  },
  {
    "title": "Nano Drone-based Indoor Crime Scene Analysis",
    "authors": [
      "Martin Cooney",
      "Sivadinesh Ponrajan",
      "Fernando Alonso-Fernandez"
    ],
    "abstract": "Technologies such as robotics, Artificial Intelligence (AI), and Computer\nVision (CV) can be applied to crime scene analysis (CSA) to help protect lives,\nfacilitate justice, and deter crime, but an overview of the tasks that can be\nautomated has been lacking. Here we follow a speculate prototyping approach:\nFirst, the STAIR tool is used to rapidly review the literature and identify\ntasks that seem to have not received much attention, like accessing crime sites\nthrough a window, mapping/gathering evidence, and analyzing blood smears.\nSecondly, we present a prototype of a small drone that implements these three\ntasks with 75%, 85%, and 80% performance, to perform a minimal analysis of an\nindoor crime scene. Lessons learned are reported, toward guiding next work in\nthe area.",
    "pdf_url": "http://arxiv.org/pdf/2502.21019v1",
    "published": "2025-02-28",
    "source": "arxiv",
    "id": "2502.21019v1",
    "categories": [
      "cs.RO"
    ]
  },
  {
    "title": "FedDyMem: Efficient Federated Learning with Dynamic Memory and Memory-Reduce for Unsupervised Image Anomaly Detection",
    "authors": [
      "Silin Chen",
      "Kangjian Di",
      "Yichu Xu",
      "Han-Jia Ye",
      "Wenhan Luo",
      "Ningmu Zou"
    ],
    "abstract": "Unsupervised image anomaly detection (UAD) has become a critical process in\nindustrial and medical applications, but it faces growing challenges due to\nincreasing concerns over data privacy. The limited class diversity inherent to\none-class classification tasks, combined with distribution biases caused by\nvariations in products across and within clients, poses significant challenges\nfor preserving data privacy with federated UAD. Thus, this article proposes an\nefficient federated learning method with dynamic memory and memory-reduce for\nunsupervised image anomaly detection, called FedDyMem. Considering all client\ndata belongs to a single class (i.e., normal sample) in UAD and the\ndistribution of intra-class features demonstrates significant skewness,\nFedDyMem facilitates knowledge sharing between the client and server through\nthe client's dynamic memory bank instead of model parameters. In the local\nclients, a memory generator and a metric loss are employed to improve the\nconsistency of the feature distribution for normal samples, leveraging the\nlocal model to update the memory bank dynamically. For efficient communication,\na memory-reduce method based on weighted averages is proposed to significantly\ndecrease the scale of memory banks. On the server, global memory is constructed\nand distributed to individual clients through k-means aggregation. Experiments\nconducted on six industrial and medical datasets, comprising a mixture of six\nproducts or health screening types derived from eleven public datasets,\ndemonstrate the effectiveness of FedDyMem.",
    "pdf_url": "http://arxiv.org/pdf/2502.21012v1",
    "published": "2025-02-28",
    "source": "arxiv",
    "id": "2502.21012v1",
    "categories": [
      "cs.DC",
      "cs.CV"
    ]
  },
  {
    "title": "Position: Solve Layerwise Linear Models First to Understand Neural Dynamical Phenomena (Neural Collapse, Emergence, Lazy/Rich Regime, and Grokking)",
    "authors": [
      "Yoonsoo Nam",
      "Seok Hyeong Lee",
      "Clementine Domine",
      "Yea Chan Park",
      "Charles London",
      "Wonyl Choi",
      "Niclas Goring",
      "Seungjai Lee"
    ],
    "abstract": "In physics, complex systems are often simplified into minimal, solvable\nmodels that retain only the core principles. In machine learning, layerwise\nlinear models (e.g., linear neural networks) act as simplified representations\nof neural network dynamics. These models follow the dynamical feedback\nprinciple, which describes how layers mutually govern and amplify each other's\nevolution. This principle extends beyond the simplified models, successfully\nexplaining a wide range of dynamical phenomena in deep neural networks,\nincluding neural collapse, emergence, lazy and rich regimes, and grokking. In\nthis position paper, we call for the use of layerwise linear models retaining\nthe core principles of neural dynamical phenomena to accelerate the science of\ndeep learning.",
    "pdf_url": "http://arxiv.org/pdf/2502.21009v1",
    "published": "2025-02-28",
    "source": "arxiv",
    "id": "2502.21009v1",
    "categories": [
      "stat.ML",
      "cs.LG",
      "physics.data-an"
    ]
  },
  {
    "title": "Towards Specialized Wireless Networks Using an ML-Driven Radio Interface",
    "authors": [
      "Kamil Szczech",
      "Maksymilian Wojnar",
      "Katarzyna Kosek-Szott",
      "Krzysztof Rusek",
      "Szymon Szott",
      "Dileepa Marasinghe",
      "Nandana Rajatheva",
      "Richard Combes",
      "Francesc Wilhelmi",
      "Anders Jonsson",
      "Boris Bellalta"
    ],
    "abstract": "Future wireless networks will need to support diverse applications (such as\nextended reality), scenarios (such as fully automated industries), and\ntechnological advances (such as terahertz communications). Current wireless\nnetworks are designed to perform adequately across multiple scenarios so they\nlack the adaptability needed for specific use cases. Therefore, meeting the\nstringent requirements of next-generation applications incorporating technology\nadvances and operating in novel scenarios will necessitate wireless specialized\nnetworks which we refer to as SpecNets. These networks, equipped with cognitive\ncapabilities, dynamically adapt to the unique demands of each application,\ne.g., by automatically selecting and configuring network mechanisms. An enabler\nof SpecNets are the recent advances in artificial intelligence and machine\nlearning (AI/ML), which allow to continuously learn and react to changing\nrequirements and scenarios. By integrating AI/ML functionalities, SpecNets will\nfully leverage the concept of AI/ML-defined radios (MLDRs) that are able to\nautonomously establish their own communication protocols by acquiring\ncontextual information and dynamically adapting to it. In this paper, we\nintroduce SpecNets and explain how MLDR interfaces enable this concept. We\npresent three illustrative use cases for wireless local area networks (WLANs):\nbespoke industrial networks, traffic-aware robust THz links, and coexisting\nnetworks. Finally, we showcase SpecNets' benefits in the industrial use case by\nintroducing a lightweight, fast-converging ML agent based on multi-armed\nbandits (MABs). This agent dynamically optimizes channel access to meet varying\nperformance needs: high throughput, low delay, or fair access. Results\ndemonstrate significant gains over IEEE 802.11, highlighting the system's\nautonomous adaptability across diverse scenarios.",
    "pdf_url": "http://arxiv.org/pdf/2502.20996v1",
    "published": "2025-02-28",
    "source": "arxiv",
    "id": "2502.20996v1",
    "categories": [
      "cs.NI"
    ]
  },
  {
    "title": "Forecasting Monthly Residential Natural Gas Demand Using Just-In-Time-Learning Modeling",
    "authors": [
      "Burak Alakent",
      "Erkan Isikli",
      "Cigdem Kadaifci",
      "Tonguc S. Taspinar"
    ],
    "abstract": "Natural gas (NG) is relatively a clean source of energy, particularly\ncompared to fossil fuels, and worldwide consumption of NG has been increasing\nalmost linearly in the last two decades. A similar trend can also be seen in\nTurkey, while another similarity is the high dependence on imports for the\ncontinuous NG supply. It is crucial to accurately forecast future NG demand\n(NGD) in Turkey, especially, for import contracts; in this respect, forecasts\nof monthly NGD for the following year are of utmost importance. In the current\nstudy, the historical monthly NG consumption data between 2014 and 2024\nprovided by SOCAR, the local residential NG distribution company for two cities\nin Turkey, Bursa and Kayseri, was used to determine out-of-sample monthly NGD\nforecasts for a period of one year and nine months using various time series\nmodels, including SARIMA and ETS models, and a novel proposed machine learning\nmethod. The proposed method, named Just-in-Time-Learning-Gaussian Process\nRegression (JITL-GPR), uses a novel feature representation for the past NG\ndemand values; instead of using past demand values as column-wise separate\nfeatures, they are placed on a two-dimensional (2-D) grid of year-month values.\nFor each test point, a kernel function, tailored for the NGD predictions, is\nused in GPR to predict the query point. Since a model is constructed separately\nfor each test point, the proposed method is, indeed, an example of JITL. The\nJITL-GPR method is easy to use and optimize, and offers a reduction in forecast\nerrors compared to traditional time series methods and a state-of-the-art\ncombination model; therefore, it is a promising tool for NGD forecasting in\nsimilar settings.",
    "pdf_url": "http://arxiv.org/pdf/2502.20989v1",
    "published": "2025-02-28",
    "source": "arxiv",
    "id": "2502.20989v1",
    "categories": [
      "stat.AP",
      "stat.ML"
    ]
  },
  {
    "title": "Merging Clinical Knowledge into Large Language Models for Medical Research and Applications: A Survey",
    "authors": [
      "Qiyuan Li",
      "Haijiang Liu",
      "Caicai Guo",
      "Deyu Chen",
      "Meng Wang",
      "Feng Gao",
      "Jinguang Gu"
    ],
    "abstract": "Clinical knowledge is the collection of information learned from studies on\nthe causes, prognosis, diagnosis, and treatment of diseases. This type of\nknowledge can improve curing performances, and promote physical health. With\nthe emergence of large language models (LLMs), medical artificial intelligence\n(medical AI), which aims to apply academic medical AI systems to real-world\nmedical scenarios, has entered a new age of development, resulting in excellent\nworks such as DoctorGPT and Pangu-Drug from academic and industrial researches.\nHowever, the field lacks a comprehensive compendium and comparison of building\nmedical AI systems from academia and industry. Therefore, this survey focuses\non the building paradigms of medical AI systems including the use of clinical\ndatabases, datasets, training pipelines, integrating medical knowledge graphs,\nsystem applications, and evaluation systems. We hope that this survey can help\nrelevant practical researchers understand the current performance of academic\nmodels in various fields of healthcare, as well as the potential problems and\nfuture directions for implementing these scientific achievements.",
    "pdf_url": "http://arxiv.org/pdf/2502.20988v1",
    "published": "2025-02-28",
    "source": "arxiv",
    "id": "2502.20988v1",
    "categories": [
      "cs.AI",
      "cs.CL"
    ]
  },
  {
    "title": "UoR-NCL at SemEval-2025 Task 1: Using Generative LLMs and CLIP Models for Multilingual Multimodal Idiomaticity Representation",
    "authors": [
      "Thanet Markchom",
      "Tong Wu",
      "Liting Huang",
      "Huizhi Liang"
    ],
    "abstract": "SemEval-2025 Task 1 focuses on ranking images based on their alignment with a\ngiven nominal compound that may carry idiomatic meaning in both English and\nBrazilian Portuguese. To address this challenge, this work uses generative\nlarge language models (LLMs) and multilingual CLIP models to enhance idiomatic\ncompound representations. LLMs generate idiomatic meanings for potentially\nidiomatic compounds, enriching their semantic interpretation. These meanings\nare then encoded using multilingual CLIP models, serving as representations for\nimage ranking. Contrastive learning and data augmentation techniques are\napplied to fine-tune these embeddings for improved performance. Experimental\nresults show that multimodal representations extracted through this method\noutperformed those based solely on the original nominal compounds. The\nfine-tuning approach shows promising outcomes but is less effective than using\nembeddings without fine-tuning. The source code used in this paper is available\nat https://github.com/tongwu17/SemEval-2025-Task1-UoR-NCL.",
    "pdf_url": "http://arxiv.org/pdf/2502.20984v1",
    "published": "2025-02-28",
    "source": "arxiv",
    "id": "2502.20984v1",
    "categories": [
      "cs.CL",
      "cs.AI"
    ]
  },
  {
    "title": "Target Selection for the Redshift-Limited WAVES-Wide with Machine Learning",
    "authors": [
      "Gursharanjit Kaur",
      "Maciej Bilicki",
      "Wojciech Hellwing",
      "the WAVES team"
    ],
    "abstract": "The forthcoming Wide Area Vista Extragalactic Survey (WAVES) on the 4-metre\nMulti-Object Spectroscopic Telescope (4MOST) has a key science goal of probing\nthe halo mass function to lower limits than possible with previous surveys. For\nthat purpose, in its Wide component, galaxies targetted by WAVES will be\nflux-limited to $Z<21.1$ mag and will cover the redshift range of $z<0.2$, at a\nspectroscopic success rate of $\\sim95\\%$. Meeting this completeness\nrequirement, when the redshift is unknown a priori, is a challenge. We solve\nthis problem with supervised machine learning to predict the probability of a\ngalaxy falling within the WAVES-Wide redshift limit, rather than estimate each\nobject's redshift. This is done by training an XGBoost tree-based classifier to\ndecide if a galaxy should be a target or not. Our photometric data come from\n9-band VST+VISTA observations, including KiDS+VIKING surveys. The redshift\nlabels for calibration are derived from an extensive spectroscopic sample\noverlapping with KiDS and ancillary fields. Our current results indicate that\nwith our approach, we should be able to achieve the completeness of $\\sim95\\%$,\nwhich is the WAVES success criterion.",
    "pdf_url": "http://arxiv.org/pdf/2502.20983v1",
    "published": "2025-02-28",
    "source": "arxiv",
    "id": "2502.20983v1",
    "categories": [
      "astro-ph.CO",
      "astro-ph.GA",
      "astro-ph.IM"
    ]
  },
  {
    "title": "Motion ReTouch: Motion Modification Using Four-Channel Bilateral Control",
    "authors": [
      "Koki Inami",
      "Sho Sakaino",
      "Toshiaki Tsuji"
    ],
    "abstract": "Recent research has demonstrated the usefulness of imitation learning in\nautonomous robot operation. In particular, teaching using four-channel\nbilateral control, which can obtain position and force information, has been\nproven effective. However, control performance that can easily execute\nhigh-speed, complex tasks in one go has not yet been achieved. We propose a\nmethod called Motion ReTouch, which retroactively modifies motion data obtained\nusing four-channel bilateral control. The proposed method enables modification\nof not only position but also force information. This was achieved by the\ncombination of multilateral control and motion-copying system. The proposed\nmethod was verified in experiments with a real robot, and the success rate of\nthe test tube transfer task was improved, demonstrating the possibility of\nmodification force information.",
    "pdf_url": "http://arxiv.org/pdf/2502.20982v1",
    "published": "2025-02-28",
    "source": "arxiv",
    "id": "2502.20982v1",
    "categories": [
      "cs.RO"
    ]
  },
  {
    "title": "Distribution Prototype Diffusion Learning for Open-set Supervised Anomaly Detection",
    "authors": [
      "Fuyun Wang",
      "Tong Zhang",
      "Yuanzhi Wang",
      "Yide Qiu",
      "Xin Liu",
      "Xu Guo",
      "Zhen Cui"
    ],
    "abstract": "In Open-set Supervised Anomaly Detection (OSAD), the existing methods\ntypically generate pseudo anomalies to compensate for the scarcity of observed\nanomaly samples, while overlooking critical priors of normal samples, leading\nto less effective discriminative boundaries. To address this issue, we propose\na Distribution Prototype Diffusion Learning (DPDL) method aimed at enclosing\nnormal samples within a compact and discriminative distribution space.\nSpecifically, we construct multiple learnable Gaussian prototypes to create a\nlatent representation space for abundant and diverse normal samples and learn a\nSchr\\\"odinger bridge to facilitate a diffusive transition toward these\nprototypes for normal samples while steering anomaly samples away. Moreover, to\nenhance inter-sample separation, we design a dispersion feature learning way in\nhyperspherical space, which benefits the identification of out-of-distribution\nanomalies. Experimental results demonstrate the effectiveness and superiority\nof our proposed DPDL, achieving state-of-the-art performance on 9 public\ndatasets.",
    "pdf_url": "http://arxiv.org/pdf/2502.20981v1",
    "published": "2025-02-28",
    "source": "arxiv",
    "id": "2502.20981v1",
    "categories": [
      "cs.CV"
    ]
  },
  {
    "title": "Improving Open-world Continual Learning under the Constraints of Scarce Labeled Data",
    "authors": [
      "Yujie Li",
      "Xiangkun Wang",
      "Xin Yang",
      "Marcello Bonsangue",
      "Junbo Zhang",
      "Tianrui Li"
    ],
    "abstract": "Open-world continual learning (OWCL) adapts to sequential tasks with open\nsamples, learning knowledge incrementally while preventing forgetting. However,\nexisting OWCL still requires a large amount of labeled data for training, which\nis often impractical in real-world applications. Given that new\ncategories/entities typically come with limited annotations and are in small\nquantities, a more realistic situation is OWCL with scarce labeled data, i.e.,\nfew-shot training samples. Hence, this paper investigates the problem of\nopen-world few-shot continual learning (OFCL), challenging in (i) learning\nunbounded tasks without forgetting previous knowledge and avoiding overfitting,\n(ii) constructing compact decision boundaries for open detection with limited\nlabeled data, and (iii) transferring knowledge about knowns and unknowns and\neven update the unknowns to knowns once the labels of open samples are learned.\nIn response, we propose a novel OFCL framework that integrates three key\ncomponents: (1) an instance-wise token augmentation (ITA) that represents and\nenriches sample representations with additional knowledge, (2) a margin-based\nopen boundary (MOB) that supports open detection with new tasks emerge over\ntime, and (3) an adaptive knowledge space (AKS) that endows unknowns with\nknowledge for the updating from unknowns to knowns. Finally, extensive\nexperiments show the proposed OFCL framework outperforms all baselines\nremarkably with practical importance and reproducibility. The source code is\nreleased at https://github.com/liyj1201/OFCL.",
    "pdf_url": "http://arxiv.org/pdf/2502.20974v1",
    "published": "2025-02-28",
    "source": "arxiv",
    "id": "2502.20974v1",
    "categories": [
      "cs.LG",
      "cs.AI"
    ]
  },
  {
    "title": "TeleRAG: Efficient Retrieval-Augmented Generation Inference with Lookahead Retrieval",
    "authors": [
      "Chien-Yu Lin",
      "Keisuke Kamahori",
      "Yiyu Liu",
      "Xiaoxiang Shi",
      "Madhav Kashyap",
      "Yile Gu",
      "Rulin Shao",
      "Zihao Ye",
      "Kan Zhu",
      "Stephanie Wang",
      "Arvind Krishnamurthy",
      "Rohan Kadekodi",
      "Luis Ceze",
      "Baris Kasikci"
    ],
    "abstract": "Retrieval-augmented generation (RAG) extends large language models (LLMs)\nwith external data sources to enhance factual correctness and domain coverage.\nModern RAG pipelines rely on large datastores, leading to system challenges in\nlatency-sensitive deployments, especially when limited GPU memory is available.\nTo address these challenges, we propose TeleRAG, an efficient inference system\nthat reduces RAG latency with minimal GPU memory requirements. The core\ninnovation of TeleRAG is lookahead retrieval, a prefetching mechanism that\nanticipates required data and transfers it from CPU to GPU in parallel with LLM\ngeneration. By leveraging the modularity of RAG pipelines, the inverted file\nindex (IVF) search algorithm and similarities between queries, TeleRAG\noptimally overlaps data movement and computation. Experimental results show\nthat TeleRAG reduces end-to-end RAG inference latency by up to 1.72x on average\ncompared to state-of-the-art systems, enabling faster, more memory-efficient\ndeployments of advanced RAG applications.",
    "pdf_url": "http://arxiv.org/pdf/2502.20969v1",
    "published": "2025-02-28",
    "source": "arxiv",
    "id": "2502.20969v1",
    "categories": [
      "cs.DC",
      "cs.LG"
    ]
  },
  {
    "title": "Effects of non-parallelism on standard and magnetorheological measurements",
    "authors": [
      "R. Rodrigues",
      "F. J. Galindo-Rosales",
      "L. Campo-Deaño"
    ],
    "abstract": "Human blood has a complex composition and unique rheological properties,\nmaking it challenging to measure accurately. In addition to this, its\nmechanical properties may be influenced by external magnetic fields, which,\ndespite being a characteristic of significant interest in the development of\nnew treatment therapies, remains relatively unexplored. To achieve an accurate\nmagnetorheological description of blood, the employed equipment must achieve\naccurate results taking into account its low viscous and elastic character.\nHowever, low and inconsistent apparent-viscosity values were observed\nsystematically in a rotational rheometer equipped with a magnetorheological\ncell, without the applied magnetic field. In this work, a parametric study was\nconducted, experimentally and numerically, to evaluate this error source.\nSteady shear measurements were carried out with low-viscosity Newtonian fluids\nwith two geometries: a parallel-plate, at different gap heights, and a\ncone-plate. An additional standard bottom plate for non-magnetic testing was\nalso employed for comparison. The standard bottom plate returned constant\nviscosities near the expected values, whereas the plate attached to the\nmagnetorheological cell showed a clear decrease of measured viscosity with\nparallel-plate gap reduction and an increase in cone-plate-measured viscosity.\nNumerical results corroborated the experimental observations, pointing towards\nan inclination of the bottom magnetic plate which can significantly affect the\nflow. Additional experimental and numerical work was conducted to evaluate the\neffects of the setup imperfection on magnetorheological measurements, unveiling\nmagnetorheology's deep dependence on the geometric characteristics.",
    "pdf_url": "http://arxiv.org/pdf/2502.20967v1",
    "published": "2025-02-28",
    "source": "arxiv",
    "id": "2502.20967v1",
    "categories": [
      "physics.flu-dyn"
    ]
  },
  {
    "title": "Post-Hoc Uncertainty Quantification in Pre-Trained Neural Networks via Activation-Level Gaussian Processes",
    "authors": [
      "Richard Bergna",
      "Stefan Depeweg",
      "Sergio Calvo Ordonez",
      "Jonathan Plenk",
      "Alvaro Cartea",
      "Jose Miguel Hernandez-Lobato"
    ],
    "abstract": "Uncertainty quantification in neural networks through methods such as\nDropout, Bayesian neural networks and Laplace approximations is either prone to\nunderfitting or computationally demanding, rendering these approaches\nimpractical for large-scale datasets. In this work, we address these\nshortcomings by shifting the focus from uncertainty in the weight space to\nuncertainty at the activation level, via Gaussian processes. More specifically,\nwe introduce the Gaussian Process Activation function (GAPA) to capture\nneuron-level uncertainties. Our approach operates in a post-hoc manner,\npreserving the original mean predictions of the pre-trained neural network and\nthereby avoiding the underfitting issues commonly encountered in previous\nmethods. We propose two methods. The first, GAPA-Free, employs empirical kernel\nlearning from the training data for the hyperparameters and is highly efficient\nduring training. The second, GAPA-Variational, learns the hyperparameters via\ngradient descent on the kernels, thus affording greater flexibility. Empirical\nresults demonstrate that GAPA-Variational outperforms the Laplace approximation\non most datasets in at least one of the uncertainty quantification metrics.",
    "pdf_url": "http://arxiv.org/pdf/2502.20966v1",
    "published": "2025-02-28",
    "source": "arxiv",
    "id": "2502.20966v1",
    "categories": [
      "stat.ML",
      "cs.LG"
    ]
  },
  {
    "title": "Retrieval Augmented Generation for Topic Modeling in Organizational Research: An Introduction with Empirical Demonstration",
    "authors": [
      "Gerion Spielberger",
      "Florian Artinger",
      "Jochen Reb",
      "Rudolf Kerschreiter"
    ],
    "abstract": "Analyzing textual data is the cornerstone of qualitative research. While\ntraditional methods such as grounded theory and content analysis are widely\nused, they are labor-intensive and time-consuming. Topic modeling offers an\nautomated complement. Yet, existing approaches, including LLM-based topic\nmodeling, still struggle with issues such as high data preprocessing\nrequirements, interpretability, and reliability. This paper introduces Agentic\nRetrieval-Augmented Generation (Agentic RAG) as a method for topic modeling\nwith LLMs. It integrates three key components: (1) retrieval, enabling\nautomatized access to external data beyond an LLM's pre-trained knowledge; (2)\ngeneration, leveraging LLM capabilities for text synthesis; and (3)\nagent-driven learning, iteratively refining retrieval and query formulation\nprocesses. To empirically validate Agentic RAG for topic modeling, we reanalyze\na Twitter/X dataset, previously examined by Mu et al. (2024a). Our findings\ndemonstrate that the approach is more efficient, interpretable and at the same\ntime achieves higher reliability and validity in comparison to the standard\nmachine learning approach but also in comparison to LLM prompting for topic\nmodeling. These results highlight Agentic RAG's ability to generate\nsemantically relevant and reproducible topics, positioning it as a robust,\nscalable, and transparent alternative for AI-driven qualitative research in\nleadership, managerial, and organizational research.",
    "pdf_url": "http://arxiv.org/pdf/2502.20963v1",
    "published": "2025-02-28",
    "source": "arxiv",
    "id": "2502.20963v1",
    "categories": [
      "cs.LG",
      "cs.AI",
      "econ.GN",
      "q-fin.EC"
    ]
  },
  {
    "title": "Cicada: A Pipeline-Efficient Approach to Serverless Inference with Decoupled Management",
    "authors": [
      "Z. Wu",
      "Y. Deng",
      "J. Hu",
      "L. Cui",
      "Z. Zhang",
      "L. Zeng",
      "G. Min"
    ],
    "abstract": "Serverless computing has emerged as a pivotal paradigm for deploying Deep\nLearning (DL) models, offering automatic scaling and cost efficiency. However,\nthe inherent cold start problem in serverless ML inference systems,\nparticularly the time-consuming model loading process, remains a significant\nbottleneck. Utilizing pipelined model loading improves efficiency but still\nsuffer from pipeline stalls due to sequential layer construction and monolithic\nweight loading. In this paper, we propose \\textit{Cicada}, a novel pipeline\noptimization framework that coordinates computational, storage, and scheduling\nresources through three key mechanisms: (1) \\textit{MiniLoader}: which reduces\nlayer construction overhead by opportunistically optimizing parameter\ninitialization; (2) \\textit{WeightDecoupler}: decoupling weight file processing\nfrom layer construction, enabling asynchronous weight retrieval and\nout-of-order weight application; (3) \\textit{Priority-Aware Scheduler}:\ndynamically allocating resources to ensure high-priority inference tasks are\nexecuted promptly. Our experimental results demonstrate that Cicada achieves\nsignificant performance improvements over the state-of-the-art PISeL framework.\nSpecifically, Cicada reduces end-to-end inference latency by an average of\n61.59\\%, with the MiniLoader component contributing the majority of this\noptimization (53.41\\%), and the WeightDecoupler achieves up to 26.17\\%\nimprovement. Additionally, Cicada achieves up to 2.52x speedup in the inference\npipeline utlization compared to PISeL.",
    "pdf_url": "http://arxiv.org/pdf/2502.20959v1",
    "published": "2025-02-28",
    "source": "arxiv",
    "id": "2502.20959v1",
    "categories": [
      "cs.DC"
    ]
  },
  {
    "title": "Reward Dimension Reduction for Scalable Multi-Objective Reinforcement Learning",
    "authors": [
      "Giseung Park",
      "Youngchul Sung"
    ],
    "abstract": "In this paper, we introduce a simple yet effective reward dimension reduction\nmethod to tackle the scalability challenges of multi-objective reinforcement\nlearning algorithms. While most existing approaches focus on optimizing two to\nfour objectives, their abilities to scale to environments with more objectives\nremain uncertain. Our method uses a dimension reduction approach to enhance\nlearning efficiency and policy performance in multi-objective settings. While\nmost traditional dimension reduction methods are designed for static datasets,\nour approach is tailored for online learning and preserves Pareto-optimality\nafter transformation. We propose a new training and evaluation framework for\nreward dimension reduction in multi-objective reinforcement learning and\ndemonstrate the superiority of our method in environments including one with\nsixteen objectives, significantly outperforming existing online dimension\nreduction methods.",
    "pdf_url": "http://arxiv.org/pdf/2502.20957v1",
    "published": "2025-02-28",
    "source": "arxiv",
    "id": "2502.20957v1",
    "categories": [
      "cs.LG"
    ]
  },
  {
    "title": "Robust and Efficient Writer-Independent IMU-Based Handwriting Recognization",
    "authors": [
      "Jindong Li",
      "Tim Hamann",
      "Jens Barth",
      "Peter Kaempf",
      "Dario Zanca",
      "Bjoern Eskofier"
    ],
    "abstract": "Online handwriting recognition (HWR) using data from inertial measurement\nunits (IMUs) remains challenging due to variations in writing styles and the\nlimited availability of high-quality annotated datasets. Traditional models\noften struggle to recognize handwriting from unseen writers, making\nwriter-independent (WI) recognition a crucial but difficult problem. This paper\npresents an HWR model with an encoder-decoder structure for IMU data, featuring\na CNN-based encoder for feature extraction and a BiLSTM decoder for sequence\nmodeling, which supports inputs of varying lengths. Our approach demonstrates\nstrong robustness and data efficiency, outperforming existing methods on WI\ndatasets, including the WI split of the OnHW dataset and our own dataset.\nExtensive evaluations show that our model maintains high accuracy across\ndifferent age groups and writing conditions while effectively learning from\nlimited data. Through comprehensive ablation studies, we analyze key design\nchoices, achieving a balance between accuracy and efficiency. These findings\ncontribute to the development of more adaptable and scalable HWR systems for\nreal-world applications.",
    "pdf_url": "http://arxiv.org/pdf/2502.20954v1",
    "published": "2025-02-28",
    "source": "arxiv",
    "id": "2502.20954v1",
    "categories": [
      "cs.LG"
    ]
  },
  {
    "title": "Optimality and Suboptimality of MPPI Control in Stochastic and Deterministic Settings",
    "authors": [
      "Hannes Homburger",
      "Florian Messerer",
      "Moritz Diehl",
      "Johannes Reuter"
    ],
    "abstract": "Model predictive path integral (MPPI) control has recently received a lot of\nattention, especially in the robotics and reinforcement learning communities.\nThis letter aims to make the MPPI control framework more accessible to the\noptimal control community. We present three classes of optimal control problems\nand their solutions by MPPI. Further, we investigate the suboptimality of MPPI\nto general deterministic nonlinear discrete-time systems. Here, suboptimality\nis defined as the deviation between the control provided by MPPI and the\noptimal solution to the deterministic optimal control problem. Our findings are\nthat in a smooth and unconstrained setting, the growth of suboptimality in the\ncontrol input trajectory is second-order with the scaling of uncertainty. The\nresults indicate that the suboptimality of the MPPI solution can be modulated\nby appropriately tuning the hyperparameters. We illustrate our findings using\nnumerical examples.",
    "pdf_url": "http://arxiv.org/pdf/2502.20953v1",
    "published": "2025-02-28",
    "source": "arxiv",
    "id": "2502.20953v1",
    "categories": [
      "eess.SY",
      "cs.SY"
    ]
  },
  {
    "title": "Efficient Jailbreaking of Large Models by Freeze Training: Lower Layers Exhibit Greater Sensitivity to Harmful Content",
    "authors": [
      "Hongyuan Shen",
      "Min Zheng",
      "Jincheng Wang",
      "Yang Zhao"
    ],
    "abstract": "With the widespread application of Large Language Models across various\ndomains, their security issues have increasingly garnered significant attention\nfrom both academic and industrial communities. This study conducts sampling and\nnormalization of the parameters of the LLM to generate visual representations\nand heatmaps of parameter distributions, revealing notable discrepancies in\nparameter distributions among certain layers within the hidden layers. Further\nanalysis involves calculating statistical metrics for each layer, followed by\nthe computation of a Comprehensive Sensitivity Score based on these metrics,\nwhich identifies the lower layers as being particularly sensitive to the\ngeneration of harmful content. Based on this finding, we employ a Freeze\ntraining strategy, selectively performing Supervised Fine-Tuning only on the\nlower layers. Experimental results demonstrate that this method significantly\nreduces training duration and GPU memory consumption while maintaining a high\njailbreak success rate and a high harm score, outperforming the results\nachieved by applying the LoRA method for SFT across all layers. Additionally,\nthe method has been successfully extended to other open-source large models,\nvalidating its generality and effectiveness across different model\narchitectures. Furthermore, we compare our method with ohter jailbreak method,\ndemonstrating the superior performance of our approach. By innovatively\nproposing a method to statistically analyze and compare large model parameters\nlayer by layer, this study provides new insights into the interpretability of\nlarge models. These discoveries emphasize the necessity of continuous research\nand the implementation of adaptive security measures in the rapidly evolving\nfield of LLMs to prevent potential jailbreak attack risks, thereby promoting\nthe development of more robust and secure LLMs.",
    "pdf_url": "http://arxiv.org/pdf/2502.20952v1",
    "published": "2025-02-28",
    "source": "arxiv",
    "id": "2502.20952v1",
    "categories": [
      "cs.CR",
      "cs.LG"
    ]
  },
  {
    "title": "Concealed Adversarial attacks on neural networks for sequential data",
    "authors": [
      "Petr Sokerin",
      "Dmitry Anikin",
      "Sofia Krehova",
      "Alexey Zaytsev"
    ],
    "abstract": "The emergence of deep learning led to the broad usage of neural networks in\nthe time series domain for various applications, including finance and\nmedicine. While powerful, these models are prone to adversarial attacks: a\nbenign targeted perturbation of input data leads to significant changes in a\nclassifier's output. However, formally small attacks in the time series domain\nbecome easily detected by the human eye or a simple detector model.\n  We develop a concealed adversarial attack for different time-series models:\nit provides more realistic perturbations, being hard to detect by a human or\nmodel discriminator. To achieve this goal, the proposed adversarial attack\nmaximizes an aggregation of a classifier and a trained discriminator loss. To\nmake the attack stronger, we also propose a training procedure for a\ndiscriminator that provides broader coverage of possible attacks. Extensive\nbenchmarking on six UCR time series datasets across four diverse architectures\n- including recurrent, convolutional, state-space, and transformer-based models\n- demonstrates the superiority of our attack for a concealability-efficiency\ntrade-off. Our findings highlight the growing challenge of designing robust\ntime series models, emphasizing the need for improved defenses against\nrealistic and effective attacks.",
    "pdf_url": "http://arxiv.org/pdf/2502.20948v1",
    "published": "2025-02-28",
    "source": "arxiv",
    "id": "2502.20948v1",
    "categories": [
      "cs.LG",
      "cs.AI"
    ]
  },
  {
    "title": "Generative Uncertainty in Diffusion Models",
    "authors": [
      "Metod Jazbec",
      "Eliot Wong-Toi",
      "Guoxuan Xia",
      "Dan Zhang",
      "Eric Nalisnick",
      "Stephan Mandt"
    ],
    "abstract": "Diffusion models have recently driven significant breakthroughs in generative\nmodeling. While state-of-the-art models produce high-quality samples on\naverage, individual samples can still be low quality. Detecting such samples\nwithout human inspection remains a challenging task. To address this, we\npropose a Bayesian framework for estimating generative uncertainty of synthetic\nsamples. We outline how to make Bayesian inference practical for large, modern\ngenerative models and introduce a new semantic likelihood (evaluated in the\nlatent space of a feature extractor) to address the challenges posed by\nhigh-dimensional sample spaces. Through our experiments, we demonstrate that\nthe proposed generative uncertainty effectively identifies poor-quality samples\nand significantly outperforms existing uncertainty-based methods. Notably, our\nBayesian framework can be applied post-hoc to any pretrained diffusion or flow\nmatching model (via the Laplace approximation), and we propose simple yet\neffective techniques to minimize its computational overhead during sampling.",
    "pdf_url": "http://arxiv.org/pdf/2502.20946v1",
    "published": "2025-02-28",
    "source": "arxiv",
    "id": "2502.20946v1",
    "categories": [
      "cs.LG",
      "cs.AI"
    ]
  },
  {
    "title": "A Deep User Interface for Exploring LLaMa",
    "authors": [
      "Divya Perumal",
      "Swaroop Panda"
    ],
    "abstract": "The growing popularity and widespread adoption of large language models\n(LLMs) necessitates the development of tools that enhance the effectiveness of\nuser interactions with these models. Understanding the structures and functions\nof these models poses a significant challenge for users. Visual\nanalytics-driven tools enables users to explore and compare, facilitating\nbetter decision-making. This paper presents a visual analytics-driven tool\nequipped with interactive controls for key hyperparameters, including top-p,\nfrequency and presence penalty, enabling users to explore, examine and compare\nthe outputs of LLMs. In a user study, we assessed the tool's effectiveness,\nwhich received favorable feedback for its visual design, with particular\ncommendation for the interface layout and ease of navigation. Additionally, the\nfeedback provided valuable insights for enhancing the effectiveness of\nHuman-LLM interaction tools.",
    "pdf_url": "http://arxiv.org/pdf/2502.20938v1",
    "published": "2025-02-28",
    "source": "arxiv",
    "id": "2502.20938v1",
    "categories": [
      "cs.HC",
      "cs.AI"
    ]
  },
  {
    "title": "Variations in Relevance Judgments and the Shelf Life of Test Collections",
    "authors": [
      "Andrew Parry",
      "Maik Fröbe",
      "Harrisen Scells",
      "Ferdinand Schlatt",
      "Guglielmo Faggioli",
      "Saber Zerhoudi",
      "Sean MacAvaney",
      "Eugene Yang"
    ],
    "abstract": "The fundamental property of Cranfield-style evaluations, that system rankings\nare stable even when assessors disagree on individual relevance decisions, was\nvalidated on traditional test collections. However, the paradigm shift towards\nneural retrieval models affected the characteristics of modern test\ncollections, e.g., documents are short, judged with four grades of relevance,\nand information needs have no descriptions or narratives. Under these changes,\nit is unclear whether assessor disagreement remains negligible for system\ncomparisons. We investigate this aspect under the additional condition that the\nfew modern test collections are heavily re-used. Given more possible query\ninterpretations due to less formalized information needs, an ''expiration\ndate'' for test collections might be needed if top-effectiveness requires\noverfitting to a single interpretation of relevance. We run a reproducibility\nstudy and re-annotate the relevance judgments of the 2019 TREC Deep Learning\ntrack. We can reproduce prior work in the neural retrieval setting, showing\nthat assessor disagreement does not affect system rankings. However, we observe\nthat some models substantially degrade with our new relevance judgments, and\nsome have already reached the effectiveness of humans as rankers, providing\nevidence that test collections can expire.",
    "pdf_url": "http://arxiv.org/pdf/2502.20937v1",
    "published": "2025-02-28",
    "source": "arxiv",
    "id": "2502.20937v1",
    "categories": [
      "cs.IR"
    ]
  },
  {
    "title": "Large Language Models Are Innate Crystal Structure Generators",
    "authors": [
      "Jingru Gan",
      "Peichen Zhong",
      "Yuanqi Du",
      "Yanqiao Zhu",
      "Chenru Duan",
      "Haorui Wang",
      "Carla P. Gomes",
      "Kristin A. Persson",
      "Daniel Schwalbe-Koda",
      "Wei Wang"
    ],
    "abstract": "Crystal structure generation is fundamental to materials discovery, enabling\nthe prediction of novel materials with desired properties. While existing\napproaches leverage Large Language Models (LLMs) through extensive fine-tuning\non materials databases, we show that pre-trained LLMs can inherently generate\nstable crystal structures without additional training. Our novel framework\nMatLLMSearch integrates pre-trained LLMs with evolutionary search algorithms,\nachieving a 78.38% metastable rate validated by machine learning interatomic\npotentials and 31.7% DFT-verified stability via quantum mechanical\ncalculations, outperforming specialized models such as CrystalTextLLM. Beyond\ncrystal structure generation, we further demonstrate that our framework can be\nreadily adapted to diverse materials design tasks, including crystal structure\nprediction and multi-objective optimization of properties such as deformation\nenergy and bulk modulus, all without fine-tuning. These results establish\npre-trained LLMs as versatile and effective tools for materials discovery,\nopening up new venues for crystal structure generation with reduced\ncomputational overhead and broader accessibility.",
    "pdf_url": "http://arxiv.org/pdf/2502.20933v1",
    "published": "2025-02-28",
    "source": "arxiv",
    "id": "2502.20933v1",
    "categories": [
      "cond-mat.mtrl-sci",
      "cs.LG"
    ]
  },
  {
    "title": "Goal-Oriented Semantic Communication for Wireless Video Transmission via Generative AI",
    "authors": [
      "Nan Li",
      "Yansha Deng",
      "Dusit Niyato"
    ],
    "abstract": "Efficient video transmission is essential for seamless communication and\ncollaboration within the visually-driven digital landscape. To achieve low\nlatency and high-quality video transmission over a bandwidth-constrained noisy\nwireless channel, we propose a stable diffusion (SD)-based goal-oriented\nsemantic communication (GSC) framework. In this framework, we first design a\nsemantic encoder that effectively identify the keyframes from video and extract\nthe relevant semantic information (SI) to reduce the transmission data size. We\nthen develop a semantic decoder to reconstruct the keyframes from the received\nSI and further generate the full video from the reconstructed keyframes using\nframe interpolation to ensure high-quality reconstruction. Recognizing the\nimpact of wireless channel noise on SI transmission, we also propose an\nSD-based denoiser for GSC (SD-GSC) condition on an instantaneous channel gain\nto remove the channel noise from the received noisy SI under a known channel.\nFor scenarios with an unknown channel, we further propose a parallel SD\ndenoiser for GSC (PSD-GSC) to jointly learn the distribution of channel gains\nand denoise the received SI. It is shown that, with the known channel, our\nproposed SD-GSC outperforms state-of-the-art ADJSCC, Latent-Diff DNSC, DeepWiVe\nand DVST, improving Peak Signal-to-Noise Ratio (PSNR) by 69%, 58%, 33% and 38%,\nreducing mean squared error (MSE) by 52%, 50%, 41% and 45%, and reducing\nFr\\'echet Video Distance (FVD) by 38%, 32%, 22% and 24%, respectively. With the\nunknown channel, our PSD-GSC achieves a 17% improvement in PSNR, a 29%\nreduction in MSE, and a 19% reduction in FVD compared to MMSE\nequalizer-enhanced SD-GSC. These significant performance improvements\ndemonstrate the robustness and superiority of our proposed methods in enhancing\nvideo transmission quality and efficiency under various channel conditions.",
    "pdf_url": "http://arxiv.org/pdf/2502.20927v1",
    "published": "2025-02-28",
    "source": "arxiv",
    "id": "2502.20927v1",
    "categories": [
      "eess.IV"
    ]
  },
  {
    "title": "Amortized Conditional Independence Testing",
    "authors": [
      "Bao Duong",
      "Nu Hoang",
      "Thin Nguyen"
    ],
    "abstract": "Testing for the conditional independence structure in data is a fundamental\nand critical task in statistics and machine learning, which finds natural\napplications in causal discovery - a highly relevant problem to many scientific\ndisciplines. Existing methods seek to design explicit test statistics that\nquantify the degree of conditional dependence, which is highly challenging yet\ncannot capture nor utilize prior knowledge in a data-driven manner. In this\nstudy, an entirely new approach is introduced, where we instead propose to\namortize conditional independence testing and devise ACID - a novel\ntransformer-based neural network architecture that learns to test for\nconditional independence. ACID can be trained on synthetic data in a supervised\nlearning fashion, and the learned model can then be applied to any dataset of\nsimilar natures or adapted to new domains by fine-tuning with a negligible\ncomputational cost. Our extensive empirical evaluations on both synthetic and\nreal data reveal that ACID consistently achieves state-of-the-art performance\nagainst existing baselines under multiple metrics, and is able to generalize\nrobustly to unseen sample sizes, dimensionalities, as well as non-linearities\nwith a remarkably low inference time.",
    "pdf_url": "http://arxiv.org/pdf/2502.20925v1",
    "published": "2025-02-28",
    "source": "arxiv",
    "id": "2502.20925v1",
    "categories": [
      "stat.ML",
      "cs.LG"
    ]
  },
  {
    "title": "Decoder Gradient Shield: Provable and High-Fidelity Prevention of Gradient-Based Box-Free Watermark Removal",
    "authors": [
      "Haonan An",
      "Guang Hua",
      "Zhengru Fang",
      "Guowen Xu",
      "Susanto Rahardja",
      "Yuguang Fang"
    ],
    "abstract": "The intellectual property of deep image-to-image models can be protected by\nthe so-called box-free watermarking. It uses an encoder and a decoder,\nrespectively, to embed into and extract from the model's output images\ninvisible copyright marks. Prior works have improved watermark robustness,\nfocusing on the design of better watermark encoders. In this paper, we reveal\nan overlooked vulnerability of the unprotected watermark decoder which is\njointly trained with the encoder and can be exploited to train a watermark\nremoval network. To defend against such an attack, we propose the decoder\ngradient shield (DGS) as a protection layer in the decoder API to prevent\ngradient-based watermark removal with a closed-form solution. The fundamental\nidea is inspired by the classical adversarial attack, but is utilized for the\nfirst time as a defensive mechanism in the box-free model watermarking. We then\ndemonstrate that DGS can reorient and rescale the gradient directions of\nwatermarked queries and stop the watermark remover's training loss from\nconverging to the level without DGS, while retaining decoder output image\nquality. Experimental results verify the effectiveness of proposed method. Code\nof paper will be made available upon acceptance.",
    "pdf_url": "http://arxiv.org/pdf/2502.20924v1",
    "published": "2025-02-28",
    "source": "arxiv",
    "id": "2502.20924v1",
    "categories": [
      "cs.CV"
    ]
  },
  {
    "title": "Everything, Everywhere, All at Once: Is Mechanistic Interpretability Identifiable?",
    "authors": [
      "Maxime Méloux",
      "Silviu Maniu",
      "François Portet",
      "Maxime Peyrard"
    ],
    "abstract": "As AI systems are used in high-stakes applications, ensuring interpretability\nis crucial. Mechanistic Interpretability (MI) aims to reverse-engineer neural\nnetworks by extracting human-understandable algorithms to explain their\nbehavior. This work examines a key question: for a given behavior, and under\nMI's criteria, does a unique explanation exist? Drawing on identifiability in\nstatistics, where parameters are uniquely inferred under specific assumptions,\nwe explore the identifiability of MI explanations.\n  We identify two main MI strategies: (1) \"where-then-what,\" which isolates a\ncircuit replicating model behavior before interpreting it, and (2)\n\"what-then-where,\" which starts with candidate algorithms and searches for\nneural activation subspaces implementing them, using causal alignment.\n  We test both strategies on Boolean functions and small multi-layer\nperceptrons, fully enumerating candidate explanations. Our experiments reveal\nsystematic non-identifiability: multiple circuits can replicate behavior, a\ncircuit can have multiple interpretations, several algorithms can align with\nthe network, and one algorithm can align with different subspaces.\n  Is uniqueness necessary? A pragmatic approach may require only predictive and\nmanipulability standards. If uniqueness is essential for understanding,\nstricter criteria may be needed. We also reference the inner interpretability\nframework, which validates explanations through multiple criteria. This work\ncontributes to defining explanation standards in AI.",
    "pdf_url": "http://arxiv.org/pdf/2502.20914v1",
    "published": "2025-02-28",
    "source": "arxiv",
    "id": "2502.20914v1",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL"
    ]
  },
  {
    "title": "LLM Post-Training: A Deep Dive into Reasoning Large Language Models",
    "authors": [
      "Komal Kumar",
      "Tajamul Ashraf",
      "Omkar Thawakar",
      "Rao Muhammad Anwer",
      "Hisham Cholakkal",
      "Mubarak Shah",
      "Ming-Hsuan Yang",
      "Phillip H. S. Torr",
      "Salman Khan",
      "Fahad Shahbaz Khan"
    ],
    "abstract": "Large Language Models (LLMs) have transformed the natural language processing\nlandscape and brought to life diverse applications. Pretraining on vast\nweb-scale data has laid the foundation for these models, yet the research\ncommunity is now increasingly shifting focus toward post-training techniques to\nachieve further breakthroughs. While pretraining provides a broad linguistic\nfoundation, post-training methods enable LLMs to refine their knowledge,\nimprove reasoning, enhance factual accuracy, and align more effectively with\nuser intents and ethical considerations. Fine-tuning, reinforcement learning,\nand test-time scaling have emerged as critical strategies for optimizing LLMs\nperformance, ensuring robustness, and improving adaptability across various\nreal-world tasks. This survey provides a systematic exploration of\npost-training methodologies, analyzing their role in refining LLMs beyond\npretraining, addressing key challenges such as catastrophic forgetting, reward\nhacking, and inference-time trade-offs. We highlight emerging directions in\nmodel alignment, scalable adaptation, and inference-time reasoning, and outline\nfuture research directions. We also provide a public repository to continually\ntrack developments in this fast-evolving field:\nhttps://github.com/mbzuai-oryx/Awesome-LLM-Post-training.",
    "pdf_url": "http://arxiv.org/pdf/2502.21321v1",
    "published": "2025-02-28",
    "source": "arxiv",
    "id": "2502.21321v1",
    "categories": [
      "cs.CL",
      "cs.CV"
    ]
  },
  {
    "title": "TomoSelfDEQ: Self-Supervised Deep Equilibrium Learning for Sparse-Angle CT Reconstruction",
    "authors": [
      "Tatiana A. Bubba",
      "Matteo Santacesaria",
      "Andrea Sebastiani"
    ],
    "abstract": "Deep learning has emerged as a powerful tool for solving inverse problems in\nimaging, including computed tomography (CT). However, most approaches require\npaired training data with ground truth images, which can be difficult to\nobtain, e.g., in medical applications. We present TomoSelfDEQ, a\nself-supervised Deep Equilibrium (DEQ) framework for sparse-angle CT\nreconstruction that trains directly on undersampled measurements. We establish\ntheoretical guarantees showing that, under suitable assumptions, our\nself-supervised updates match those of fully-supervised training with a loss\nincluding the (possibly non-unitary) forward operator like the CT forward map.\nNumerical experiments on sparse-angle CT data confirm this finding, also\ndemonstrating that TomoSelfDEQ outperforms existing self-supervised methods,\nachieving state-of-the-art results with as few as 16 projection angles.",
    "pdf_url": "http://arxiv.org/pdf/2502.21320v1",
    "published": "2025-02-28",
    "source": "arxiv",
    "id": "2502.21320v1",
    "categories": [
      "eess.IV",
      "cs.CV"
    ]
  },
  {
    "title": "Assessing zero-shot generalisation behaviour in graph-neural-network interatomic potentials",
    "authors": [
      "Chiheb Ben Mahmoud",
      "Zakariya El-Machachi",
      "Krystian A. Gierczak",
      "John L. A. Gardner",
      "Volker L. Deringer"
    ],
    "abstract": "With the rapidly growing availability of machine-learned interatomic\npotential (MLIP) models for chemistry, much current research focuses on the\ndevelopment of generally applicable and ``foundational'' MLIPs. An important\nquestion in this context is whether, and how well, such models can transfer\nfrom one application domain to another. Here, we assess this transferability\nfor an MLIP model at the interface of materials and molecular chemistry.\nSpecifically, we study GO-MACE-23, a model designed for the extended covalent\nnetwork of graphene oxide, and quantify its zero-shot performance for small,\nisolated molecules and chemical reactions outside its direct scope--in direct\ncomparison with a state-of-the-art model which has been trained in-domain. Our\nwork provides quantitative insight into the transfer and generalisation ability\nof graph-neural-network potentials and, more generally, makes a step towards\nthe more widespread applicability of MLIPs in chemistry.",
    "pdf_url": "http://arxiv.org/pdf/2502.21317v1",
    "published": "2025-02-28",
    "source": "arxiv",
    "id": "2502.21317v1",
    "categories": [
      "physics.chem-ph",
      "cond-mat.mtrl-sci"
    ]
  },
  {
    "title": "Unsupervised Parameter Efficient Source-free Post-pretraining",
    "authors": [
      "Abhishek Jha",
      "Tinne Tuytelaars",
      "Yuki M. Asano"
    ],
    "abstract": "Following the success in NLP, the best vision models are now in the billion\nparameter ranges. Adapting these large models to a target distribution has\nbecome computationally and economically prohibitive. Addressing this challenge,\nwe introduce UpStep, an Unsupervised Parameter-efficient Source-free\npost-pretraining approach, designed to efficiently adapt a base model from a\nsource domain to a target domain: i) we design a self-supervised training\nscheme to adapt a pretrained model on an unlabeled target domain in a setting\nwhere source domain data is unavailable. Such source-free setting comes with\nthe risk of catastrophic forgetting, hence, ii) we propose center vector\nregularization (CVR), a set of auxiliary operations that minimize catastrophic\nforgetting and additionally reduces the computational cost by skipping\nbackpropagation in 50\\% of the training iterations. Finally iii) we perform\nthis adaptation process in a parameter-efficient way by adapting the pretrained\nmodel through low-rank adaptation methods, resulting in a fraction of\nparameters to optimize. We utilize various general backbone architectures, both\nsupervised and unsupervised, trained on Imagenet as our base model and adapt\nthem to a diverse set of eight target domains demonstrating the adaptability\nand generalizability of our proposed approach.",
    "pdf_url": "http://arxiv.org/pdf/2502.21313v1",
    "published": "2025-02-28",
    "source": "arxiv",
    "id": "2502.21313v1",
    "categories": [
      "cs.CV",
      "cs.LG"
    ]
  },
  {
    "title": "AutoComb: Automated Comb Sign Detector for 3D CTE Scans",
    "authors": [
      "Shashwat Gupta",
      "Sarthak Gupta",
      "Akshan Agrawal",
      "Mahim Naaz",
      "Rajanikanth Yadav",
      "Priyanka Bagade"
    ],
    "abstract": "Comb Sign is an important imaging biomarker to detect multiple\ngastrointestinal diseases. It shows up as increased blood flow along the\nintestinal wall indicating potential abnormality, which helps doctors diagnose\ninflammatory conditions. Despite its clinical significance, current detection\nmethods are manual, time-intensive, and prone to subjective interpretation due\nto the need for multi-planar image-orientation. To the best of our knowledge,\nwe are the first to propose a fully automated technique for the detection of\nComb Sign from CTE scans. Our novel approach is based on developing a\nprobabilistic map that shows areas of pathological hypervascularity by\nidentifying fine vascular bifurcations and wall enhancement via processing\nthrough stepwise algorithmic modules. These modules include utilising deep\nlearning segmentation model, a Gaussian Mixture Model (GMM), vessel extraction\nusing vesselness filter, iterative probabilistic enhancement of vesselness via\nneighborhood maximization and a distance-based weighting scheme over the\nvessels. Experimental results demonstrate that our pipeline effectively\nidentifies Comb Sign, offering an objective, accurate, and reliable tool to\nenhance diagnostic accuracy in Crohn's disease and related hypervascular\nconditions where Comb Sign is considered as one of the important biomarkers.",
    "pdf_url": "http://arxiv.org/pdf/2502.21311v1",
    "published": "2025-02-28",
    "source": "arxiv",
    "id": "2502.21311v1",
    "categories": [
      "eess.IV",
      "cs.CV"
    ]
  },
  {
    "title": "FANformer: Improving Large Language Models Through Effective Periodicity Modeling",
    "authors": [
      "Yihong Dong",
      "Ge Li",
      "Xue Jiang",
      "Yongding Tao",
      "Kechi Zhang",
      "Hao Zhu",
      "Huanyu Liu",
      "Jiazheng Ding",
      "Jia Li",
      "Jinliang Deng",
      "Hong Mei"
    ],
    "abstract": "Periodicity, as one of the most important basic characteristics, lays the\nfoundation for facilitating structured knowledge acquisition and systematic\ncognitive processes within human learning paradigms. However, the potential\nflaws of periodicity modeling in Transformer affect the learning efficiency and\nestablishment of underlying principles from data for large language models\n(LLMs) built upon it. In this paper, we demonstrate that integrating effective\nperiodicity modeling can improve the learning efficiency and performance of\nLLMs. We introduce FANformer, which integrates Fourier Analysis Network (FAN)\ninto attention mechanism to achieve efficient periodicity modeling, by\nmodifying the feature projection process of attention mechanism. Extensive\nexperimental results on language modeling show that FANformer consistently\noutperforms Transformer when scaling up model size and training tokens,\nunderscoring its superior learning efficiency. To further validate the\neffectiveness of FANformer, we pretrain a FANformer-1B on 1 trillion tokens.\nFANformer-1B exhibits marked improvements on downstream tasks compared to\nopen-source LLMs with similar model parameters or training tokens. The results\nposition FANformer as an effective and promising architecture for advancing\nLLMs.",
    "pdf_url": "http://arxiv.org/pdf/2502.21309v1",
    "published": "2025-02-28",
    "source": "arxiv",
    "id": "2502.21309v1",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ]
  },
  {
    "title": "Clustering Context in Off-Policy Evaluation",
    "authors": [
      "Daniel Guzman-Olivares",
      "Philipp Schmidt",
      "Jacek Golebiowski",
      "Artur Bekasov"
    ],
    "abstract": "Off-policy evaluation can leverage logged data to estimate the effectiveness\nof new policies in e-commerce, search engines, media streaming services, or\nautomatic diagnostic tools in healthcare. However, the performance of baseline\noff-policy estimators like IPS deteriorates when the logging policy\nsignificantly differs from the evaluation policy. Recent work proposes sharing\ninformation across similar actions to mitigate this problem. In this work, we\npropose an alternative estimator that shares information across similar\ncontexts using clustering. We study the theoretical properties of the proposed\nestimator, characterizing its bias and variance under different conditions. We\nalso compare the performance of the proposed estimator and existing approaches\nin various synthetic problems, as well as a real-world recommendation dataset.\nOur experimental results confirm that clustering contexts improves estimation\naccuracy, especially in deficient information settings.",
    "pdf_url": "http://arxiv.org/pdf/2502.21304v1",
    "published": "2025-02-28",
    "source": "arxiv",
    "id": "2502.21304v1",
    "categories": [
      "cs.LG",
      "cs.AI",
      "stat.ML"
    ]
  },
  {
    "title": "Hybrid Team Tetris: A New Platform For Hybrid Multi-Agent, Multi-Human Teaming",
    "authors": [
      "Kaleb Mcdowell",
      "Nick Waytowich",
      "Javier Garcia",
      "Stephen Gordon",
      "Bryce Bartlett",
      "Jeremy Gaston"
    ],
    "abstract": "Metcalfe et al (1) argue that the greatest potential for human-AI\npartnerships lies in their application to highly complex problem spaces.\nHerein, we discuss three different forms of hybrid team intelligence and posit\nthat across all three forms, the hybridization of man and machine intelligence\ncan be effective under the right conditions. We foresee two significant\nresearch and development (R&D) challenges underlying the creation of effective\nhybrid intelligence. First, rapid advances in machine intelligence and/or\nfundamental changes in human behaviors or capabilities over time can outpace\nR&D. Second, the future conditions under which hybrid intelligence will operate\nare unknown, but unlikely to be the same as the conditions of today. Overcoming\nboth of these challenges requires a deep understanding of multiple\nhuman-centric and machine-centric disciplines that creates a large barrier to\nentry into the field. Herein, we outline an open, shareable research platform\nthat creates a form of hybrid team intelligence that functions under\nrepresentative future conditions. The intent for the platform is to facilitate\nnew forms of hybrid intelligence research allowing individuals with\nhuman-centric or machine-centric backgrounds to rapidly enter the field and\ninitiate research. Our hope is that through open, community research on the\nplatform, state-of-the-art advances in human and machine intelligence can\nquickly be communicated across what are currently different R&D communities and\nallow hybrid team intelligence research to stay at the forefront of scientific\nadvancement.",
    "pdf_url": "http://arxiv.org/pdf/2502.21300v1",
    "published": "2025-02-28",
    "source": "arxiv",
    "id": "2502.21300v1",
    "categories": [
      "cs.HC"
    ]
  },
  {
    "title": "Bilevel Optimized Implicit Neural Representation for Scan-Specific Accelerated MRI Reconstruction",
    "authors": [
      "Hongze Yu",
      "Jeffrey A. Fessler",
      "Yun Jiang"
    ],
    "abstract": "Deep Learning (DL) methods can reconstruct highly accelerated magnetic\nresonance imaging (MRI) scans, but they rely on application-specific large\ntraining datasets and often generalize poorly to out-of-distribution data.\nSelf-supervised deep learning algorithms perform scan-specific reconstructions,\nbut still require complicated hyperparameter tuning based on the acquisition\nand often offer limited acceleration. This work develops a bilevel-optimized\nimplicit neural representation (INR) approach for scan-specific MRI\nreconstruction. The method automatically optimizes the hyperparameters for a\ngiven acquisition protocol, enabling a tailored reconstruction without training\ndata. The proposed algorithm uses Gaussian process regression to optimize INR\nhyperparameters, accommodating various acquisitions. The INR includes a\ntrainable positional encoder for high-dimensional feature embedding and a small\nmultilayer perceptron for decoding. The bilevel optimization is computationally\nefficient, requiring only a few minutes per typical 2D Cartesian scan. On\nscanner hardware, the subsequent scan-specific reconstruction-using\noffline-optimized hyperparameters-is completed within seconds and achieves\nimproved image quality compared to previous model-based and self-supervised\nlearning methods.",
    "pdf_url": "http://arxiv.org/pdf/2502.21292v1",
    "published": "2025-02-28",
    "source": "arxiv",
    "id": "2502.21292v1",
    "categories": [
      "eess.IV",
      "eess.SP"
    ]
  },
  {
    "title": "MIGE: A Unified Framework for Multimodal Instruction-Based Image Generation and Editing",
    "authors": [
      "Xueyun Tian",
      "Wei Li",
      "Bingbing Xu",
      "Yige Yuan",
      "Yuanzhuo Wang",
      "Huawei Shen"
    ],
    "abstract": "Despite significant progress in diffusion-based image generation,\nsubject-driven generation and instruction-based editing remain challenging.\nExisting methods typically treat them separately, struggling with limited\nhigh-quality data and poor generalization. However, both tasks require\ncapturing complex visual variations while maintaining consistency between\ninputs and outputs. Therefore, we propose MIGE, a unified framework that\nstandardizes task representations using multimodal instructions. It treats\nsubject-driven generation as creation on a blank canvas and instruction-based\nediting as modification of an existing image, establishing a shared\ninput-output formulation. MIGE introduces a novel multimodal encoder that maps\nfree-form multimodal instructions into a unified vision-language space,\nintegrating visual and semantic features through a feature fusion mechanism.\nThis unification enables joint training of both tasks, providing two key\nadvantages: (1) Cross-Task Enhancement: By leveraging shared visual and\nsemantic representations, joint training improves instruction adherence and\nvisual consistency in both subject-driven generation and instruction-based\nediting. (2) Generalization: Learning in a unified format facilitates\ncross-task knowledge transfer, enabling MIGE to generalize to novel\ncompositional tasks, including instruction-based subject-driven editing.\nExperiments show that MIGE excels in both subject-driven generation and\ninstruction-based editing while setting a state-of-the-art in the new task of\ninstruction-based subject-driven editing. Code and model have been publicly\navailable at https://github.com/Eureka-Maggie/MIGE.",
    "pdf_url": "http://arxiv.org/pdf/2502.21291v2",
    "published": "2025-02-28",
    "source": "arxiv",
    "id": "2502.21291v2",
    "categories": [
      "cs.CV"
    ]
  },
  {
    "title": "Contextualizing biological perturbation experiments through language",
    "authors": [
      "Menghua Wu",
      "Russell Littman",
      "Jacob Levine",
      "Lin Qiu",
      "Tommaso Biancalani",
      "David Richmond",
      "Jan-Christian Huetter"
    ],
    "abstract": "High-content perturbation experiments allow scientists to probe biomolecular\nsystems at unprecedented resolution, but experimental and analysis costs pose\nsignificant barriers to widespread adoption. Machine learning has the potential\nto guide efficient exploration of the perturbation space and extract novel\ninsights from these data. However, current approaches neglect the semantic\nrichness of the relevant biology, and their objectives are misaligned with\ndownstream biological analyses. In this paper, we hypothesize that large\nlanguage models (LLMs) present a natural medium for representing complex\nbiological relationships and rationalizing experimental outcomes. We propose\nPerturbQA, a benchmark for structured reasoning over perturbation experiments.\nUnlike current benchmarks that primarily interrogate existing knowledge,\nPerturbQA is inspired by open problems in perturbation modeling: prediction of\ndifferential expression and change of direction for unseen perturbations, and\ngene set enrichment. We evaluate state-of-the-art machine learning and\nstatistical approaches for modeling perturbations, as well as standard LLM\nreasoning strategies, and we find that current methods perform poorly on\nPerturbQA. As a proof of feasibility, we introduce Summer (SUMMarize, retrievE,\nand answeR, a simple, domain-informed LLM framework that matches or exceeds the\ncurrent state-of-the-art. Our code and data are publicly available at\nhttps://github.com/genentech/PerturbQA.",
    "pdf_url": "http://arxiv.org/pdf/2502.21290v1",
    "published": "2025-02-28",
    "source": "arxiv",
    "id": "2502.21290v1",
    "categories": [
      "cs.AI",
      "cs.LG",
      "q-bio.QM"
    ]
  },
  {
    "title": "Enabling AutoML for Zero-Touch Network Security: Use-Case Driven Analysis",
    "authors": [
      "Li Yang",
      "Mirna El Rajab",
      "Abdallah Shami",
      "Sami Muhaidat"
    ],
    "abstract": "Zero-Touch Networks (ZTNs) represent a state-of-the-art paradigm shift\ntowards fully automated and intelligent network management, enabling the\nautomation and intelligence required to manage the complexity, scale, and\ndynamic nature of next-generation (6G) networks. ZTNs leverage Artificial\nIntelligence (AI) and Machine Learning (ML) to enhance operational efficiency,\nsupport intelligent decision-making, and ensure effective resource allocation.\nHowever, the implementation of ZTNs is subject to security challenges that need\nto be resolved to achieve their full potential. In particular, two critical\nchallenges arise: the need for human expertise in developing AI/ML-based\nsecurity mechanisms, and the threat of adversarial attacks targeting AI/ML\nmodels. In this survey paper, we provide a comprehensive review of current\nsecurity issues in ZTNs, emphasizing the need for advanced AI/ML-based security\nmechanisms that require minimal human intervention and protect AI/ML models\nthemselves. Furthermore, we explore the potential of Automated ML (AutoML)\ntechnologies in developing robust security solutions for ZTNs. Through case\nstudies, we illustrate practical approaches to securing ZTNs against both\nconventional and AI/ML-specific threats, including the development of\nautonomous intrusion detection systems and strategies to combat Adversarial ML\n(AML) attacks. The paper concludes with a discussion of the future research\ndirections for the development of ZTN security approaches.",
    "pdf_url": "http://arxiv.org/pdf/2502.21286v1",
    "published": "2025-02-28",
    "source": "arxiv",
    "id": "2502.21286v1",
    "categories": [
      "cs.CR",
      "cs.LG",
      "cs.NI",
      "68T01, 90C31",
      "I.2.1; I.2.6; C.2.0"
    ]
  },
  {
    "title": "Controlled Model Debiasing through Minimal and Interpretable Updates",
    "authors": [
      "Federico Di Gennaro",
      "Thibault Laugel",
      "Vincent Grari",
      "Marcin Detyniecki"
    ],
    "abstract": "Traditional approaches to learning fair machine learning models often require\nrebuilding models from scratch, generally without accounting for potentially\nexisting previous models. In a context where models need to be retrained\nfrequently, this can lead to inconsistent model updates, as well as redundant\nand costly validation testing. To address this limitation, we introduce the\nnotion of controlled model debiasing, a novel supervised learning task relying\non two desiderata: that the differences between new fair model and the existing\none should be (i) interpretable and (ii) minimal. After providing theoretical\nguarantees to this new problem, we introduce a novel algorithm for algorithmic\nfairness, COMMOD, that is both model-agnostic and does not require the\nsensitive attribute at test time. In addition, our algorithm is explicitly\ndesigned to enforce minimal and interpretable changes between biased and\ndebiased predictions -a property that, while highly desirable in high-stakes\napplications, is rarely prioritized as an explicit objective in fairness\nliterature. Our approach combines a concept-based architecture and adversarial\nlearning and we demonstrate through empirical results that it achieves\ncomparable performance to state-of-the-art debiasing methods while performing\nminimal and interpretable prediction changes.",
    "pdf_url": "http://arxiv.org/pdf/2502.21284v1",
    "published": "2025-02-28",
    "source": "arxiv",
    "id": "2502.21284v1",
    "categories": [
      "cs.LG",
      "stat.ML"
    ]
  },
  {
    "title": "Back to the Future Cyclopean Stereo: a human perception approach unifying deep and geometric constraints",
    "authors": [
      "Sherlon Almeida da Silva",
      "Davi Geiger",
      "Luiz Velho",
      "Moacir Antonelli Ponti"
    ],
    "abstract": "We innovate in stereo vision by explicitly providing analytical 3D surface\nmodels as viewed by a cyclopean eye model that incorporate depth\ndiscontinuities and occlusions. This geometrical foundation combined with\nlearned stereo features allows our system to benefit from the strengths of both\napproaches. We also invoke a prior monocular model of surfaces to fill in\nocclusion regions or texture-less regions where data matching is not\nsufficient. Our results already are on par with the state-of-the-art purely\ndata-driven methods and are of much better visual quality, emphasizing the\nimportance of the 3D geometrical model to capture critical visual information.\nSuch qualitative improvements may find applicability in virtual reality, for a\nbetter human experience, as well as in robotics, for reducing critical errors.\nOur approach aims to demonstrate that understanding and modeling geometrical\nproperties of 3D surfaces is beneficial to computer vision research.",
    "pdf_url": "http://arxiv.org/pdf/2502.21280v1",
    "published": "2025-02-28",
    "source": "arxiv",
    "id": "2502.21280v1",
    "categories": [
      "cs.CV"
    ]
  },
  {
    "title": "L-Lipschitz Gershgorin ResNet Network",
    "authors": [
      "Marius F. R. Juston",
      "William R. Norris",
      "Dustin Nottage",
      "Ahmet Soylemezoglu"
    ],
    "abstract": "Deep residual networks (ResNets) have demonstrated outstanding success in\ncomputer vision tasks, attributed to their ability to maintain gradient flow\nthrough deep architectures. Simultaneously, controlling the Lipschitz bound in\nneural networks has emerged as an essential area of research for enhancing\nadversarial robustness and network certifiability. This paper uses a rigorous\napproach to design $\\mathcal{L}$-Lipschitz deep residual networks using a\nLinear Matrix Inequality (LMI) framework. The ResNet architecture was\nreformulated as a pseudo-tri-diagonal LMI with off-diagonal elements and\nderived closed-form constraints on network parameters to ensure\n$\\mathcal{L}$-Lipschitz continuity. To address the lack of explicit eigenvalue\ncomputations for such matrix structures, the Gershgorin circle theorem was\nemployed to approximate eigenvalue locations, guaranteeing the LMI's negative\nsemi-definiteness. Our contributions include a provable parameterization\nmethodology for constructing Lipschitz-constrained networks and a compositional\nframework for managing recursive systems within hierarchical architectures.\nThese findings enable robust network designs applicable to adversarial\nrobustness, certified training, and control systems. However, a limitation was\nidentified in the Gershgorin-based approximations, which over-constrain the\nsystem, suppressing non-linear dynamics and diminishing the network's\nexpressive capacity.",
    "pdf_url": "http://arxiv.org/pdf/2502.21279v1",
    "published": "2025-02-28",
    "source": "arxiv",
    "id": "2502.21279v1",
    "categories": [
      "cs.LG",
      "cs.AI"
    ]
  },
  {
    "title": "Does Generation Require Memorization? Creative Diffusion Models using Ambient Diffusion",
    "authors": [
      "Kulin Shah",
      "Alkis Kalavasis",
      "Adam R. Klivans",
      "Giannis Daras"
    ],
    "abstract": "There is strong empirical evidence that the state-of-the-art diffusion\nmodeling paradigm leads to models that memorize the training set, especially\nwhen the training set is small. Prior methods to mitigate the memorization\nproblem often lead to a decrease in image quality. Is it possible to obtain\nstrong and creative generative models, i.e., models that achieve high\ngeneration quality and low memorization? Despite the current pessimistic\nlandscape of results, we make significant progress in pushing the trade-off\nbetween fidelity and memorization. We first provide theoretical evidence that\nmemorization in diffusion models is only necessary for denoising problems at\nlow noise scales (usually used in generating high-frequency details). Using\nthis theoretical insight, we propose a simple, principled method to train the\ndiffusion models using noisy data at large noise scales. We show that our\nmethod significantly reduces memorization without decreasing the image quality,\nfor both text-conditional and unconditional models and for a variety of data\navailability settings.",
    "pdf_url": "http://arxiv.org/pdf/2502.21278v1",
    "published": "2025-02-28",
    "source": "arxiv",
    "id": "2502.21278v1",
    "categories": [
      "cs.LG",
      "stat.ML"
    ]
  },
  {
    "title": "Boosting Prediction with Data Missing Not at Random",
    "authors": [
      "Yuan Bian",
      "Grace Y. Yi",
      "Wenqing He"
    ],
    "abstract": "Boosting has emerged as a useful machine learning technique over the past\nthree decades, attracting increased attention. Most advancements in this area,\nhowever, have primarily focused on numerical implementation procedures, often\nlacking rigorous theoretical justifications. Moreover, these approaches are\ngenerally designed for datasets with fully observed data, and their validity\ncan be compromised by the presence of missing observations. In this paper, we\nemploy semiparametric estimation approaches to develop boosting prediction\nmethods for data with missing responses. We explore two strategies for\nadjusting the loss functions to account for missingness effects. The proposed\nmethods are implemented using a functional gradient descent algorithm, and\ntheir theoretical properties, including algorithm convergence and estimator\nconsistency, are rigorously established. Numerical studies demonstrate that the\nproposed methods perform well in finite sample settings.",
    "pdf_url": "http://arxiv.org/pdf/2502.21276v1",
    "published": "2025-02-28",
    "source": "arxiv",
    "id": "2502.21276v1",
    "categories": [
      "stat.ME"
    ]
  },
  {
    "title": "Utilizing Quantum Fingerprints in Plant Cells to Evaluate Plant productivity",
    "authors": [
      "Umadini Ranasinghe",
      "Abigail L. Stressinger",
      "Guangpeng Xu",
      "Yasmin Sarhan",
      "Fred Harrington",
      "James Berry",
      "Tim Thomay"
    ],
    "abstract": "Overcoming the strong chlorophyll background poses a significant challenge\nfor measuring and optimizing plant growth. This research investigates the novel\napplication of specialized quantum light emitters introduced into intact leaves\nof tobacco (Nicotiana tabacum), a well-characterized model plant system for\nstudies of plant health and productivity. Leaves were harvested from plants\ncultivated under two distinct conditions: low light (LL), representing\nunhealthy leaves with reduced photosynthesis. and high light (HL), representing\nhealthy leaves with highly active photosynthesis. Higher-order correlation data\nwere collected and analyzed using machine learning (ML) techniques,\nspecifically a Convolutional Neural Network (CNN), to classify the photon\nemitter states. This CNN efficiently identified unique patterns and created\ndistinct fingerprints for Nicotiana leaves grown under LL and HL, demonstrating\nsignificantly different quantum profiles between the two conditions. These\nquantum fingerprints serve as a foundation for a novel unified analysis of\nplant growth parameters associated with different photosynthetic states. By\nemploying CNN, the emitter profiles were able to reproducibly classify the\nleaves as healthy or unhealthy. This model achieved high probability values for\neach classification, confirming its accuracy and reliability. The findings of\nthis study pave the way for broader applications, including the application of\nadvanced quantum and machine learning technologies in plant health monitoring\nsystems.",
    "pdf_url": "http://arxiv.org/pdf/2502.21275v1",
    "published": "2025-02-28",
    "source": "arxiv",
    "id": "2502.21275v1",
    "categories": [
      "physics.bio-ph"
    ]
  },
  {
    "title": "BAnG: Bidirectional Anchored Generation for Conditional RNA Design",
    "authors": [
      "Roman Klypa",
      "Alberto Bietti",
      "Sergei Grudinin"
    ],
    "abstract": "Designing RNA molecules that interact with specific proteins is a critical\nchallenge in experimental and computational biology. Existing computational\napproaches require a substantial amount of experimentally determined RNA\nsequences for each specific protein or a detailed knowledge of RNA structure,\nrestricting their utility in practice. To address this limitation, we develop\nRNA-BAnG, a deep learning-based model designed to generate RNA sequences for\nprotein interactions without these requirements. Central to our approach is a\nnovel generative method, Bidirectional Anchored Generation (BAnG), which\nleverages the observation that protein-binding RNA sequences often contain\nfunctional binding motifs embedded within broader sequence contexts. We first\nvalidate our method on generic synthetic tasks involving similar localized\nmotifs to those appearing in RNAs, demonstrating its benefits over existing\ngenerative approaches. We then evaluate our model on biological sequences,\nshowing its effectiveness for conditional RNA sequence design given a binding\nprotein.",
    "pdf_url": "http://arxiv.org/pdf/2502.21274v1",
    "published": "2025-02-28",
    "source": "arxiv",
    "id": "2502.21274v1",
    "categories": [
      "cs.LG",
      "cs.AI",
      "q-bio.BM"
    ]
  },
  {
    "title": "Adaptive Keyframe Sampling for Long Video Understanding",
    "authors": [
      "Xi Tang",
      "Jihao Qiu",
      "Lingxi Xie",
      "Yunjie Tian",
      "Jianbin Jiao",
      "Qixiang Ye"
    ],
    "abstract": "Multimodal large language models (MLLMs) have enabled open-world visual\nunderstanding by injecting visual input as extra tokens into large language\nmodels (LLMs) as contexts. However, when the visual input changes from a single\nimage to a long video, the above paradigm encounters difficulty because the\nvast amount of video tokens has significantly exceeded the maximal capacity of\nMLLMs. Therefore, existing video-based MLLMs are mostly established upon\nsampling a small portion of tokens from input data, which can cause key\ninformation to be lost and thus produce incorrect answers. This paper presents\na simple yet effective algorithm named Adaptive Keyframe Sampling (AKS). It\ninserts a plug-and-play module known as keyframe selection, which aims to\nmaximize the useful information with a fixed number of video tokens. We\nformulate keyframe selection as an optimization involving (1) the relevance\nbetween the keyframes and the prompt, and (2) the coverage of the keyframes\nover the video, and present an adaptive algorithm to approximate the best\nsolution. Experiments on two long video understanding benchmarks validate that\nAdaptive Keyframe Sampling improves video QA accuracy (beyond strong baselines)\nupon selecting informative keyframes. Our study reveals the importance of\ninformation pre-filtering in video-based MLLMs. Code is available at\nhttps://github.com/ncTimTang/AKS.",
    "pdf_url": "http://arxiv.org/pdf/2502.21271v1",
    "published": "2025-02-28",
    "source": "arxiv",
    "id": "2502.21271v1",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG"
    ]
  },
  {
    "title": "Dynamical Decoupling of Generalization and Overfitting in Large Two-Layer Networks",
    "authors": [
      "Andrea Montanari",
      "Pierfrancesco Urbani"
    ],
    "abstract": "The inductive bias and generalization properties of large machine learning\nmodels are -- to a substantial extent -- a byproduct of the optimization\nalgorithm used for training. Among others, the scale of the random\ninitialization, the learning rate, and early stopping all have crucial impact\non the quality of the model learnt by stochastic gradient descent or related\nalgorithms. In order to understand these phenomena, we study the training\ndynamics of large two-layer neural networks. We use a well-established\ntechnique from non-equilibrium statistical physics (dynamical mean field\ntheory) to obtain an asymptotic high-dimensional characterization of this\ndynamics. This characterization applies to a Gaussian approximation of the\nhidden neurons non-linearity, and empirically captures well the behavior of\nactual neural network models.\n  Our analysis uncovers several interesting new phenomena in the training\ndynamics: $(i)$ The emergence of a slow time scale associated with the growth\nin Gaussian/Rademacher complexity; $(ii)$ As a consequence, algorithmic\ninductive bias towards small complexity, but only if the initialization has\nsmall enough complexity; $(iii)$ A separation of time scales between feature\nlearning and overfitting; $(iv)$ A non-monotone behavior of the test error and,\ncorrespondingly, a `feature unlearning' phase at large times.",
    "pdf_url": "http://arxiv.org/pdf/2502.21269v1",
    "published": "2025-02-28",
    "source": "arxiv",
    "id": "2502.21269v1",
    "categories": [
      "stat.ML",
      "cond-mat.dis-nn",
      "cs.LG"
    ]
  },
  {
    "title": "Supporting the development of Machine Learning for fundamental science in a federated Cloud with the AI_INFN platform",
    "authors": [
      "Lucio Anderlini",
      "Matteo Barbetti",
      "Giulio Bianchini",
      "Diego Ciangottini",
      "Stefano Dal Pra",
      "Diego Michelotto",
      "Carmelo Pellegrino",
      "Rosa Petrini",
      "Alessandro Pascolini",
      "Daniele Spiga"
    ],
    "abstract": "Machine Learning (ML) is driving a revolution in the way scientists design,\ndevelop, and deploy data-intensive software. However, the adoption of ML\npresents new challenges for the computing infrastructure, particularly in terms\nof provisioning and orchestrating access to hardware accelerators for\ndevelopment, testing, and production. The INFN-funded project AI_INFN\n(\"Artificial Intelligence at INFN\") aims at fostering the adoption of ML\ntechniques within INFN use cases by providing support on multiple aspects,\nincluding the provision of AI-tailored computing resources. It leverages\ncloud-native solutions in the context of INFN Cloud, to share hardware\naccelerators as effectively as possible, ensuring the diversity of the\nInstitute's research activities is not compromised. In this contribution, we\nprovide an update on the commissioning of a Kubernetes platform designed to\nease the development of GPU-powered data analysis workflows and their\nscalability on heterogeneous, distributed computing resources, possibly\nfederated as Virtual Kubelets with the interLink provider.",
    "pdf_url": "http://arxiv.org/pdf/2502.21266v1",
    "published": "2025-02-28",
    "source": "arxiv",
    "id": "2502.21266v1",
    "categories": [
      "cs.DC",
      "cs.AI",
      "physics.data-an"
    ]
  },
  {
    "title": "ReaLJam: Real-Time Human-AI Music Jamming with Reinforcement Learning-Tuned Transformers",
    "authors": [
      "Alexander Scarlatos",
      "Yusong Wu",
      "Ian Simon",
      "Adam Roberts",
      "Tim Cooijmans",
      "Natasha Jaques",
      "Cassie Tarakajian",
      "Cheng-Zhi Anna Huang"
    ],
    "abstract": "Recent advances in generative artificial intelligence (AI) have created\nmodels capable of high-quality musical content generation. However, little\nconsideration is given to how to use these models for real-time or cooperative\njamming musical applications because of crucial required features: low latency,\nthe ability to communicate planned actions, and the ability to adapt to user\ninput in real-time. To support these needs, we introduce ReaLJam, an interface\nand protocol for live musical jamming sessions between a human and a\nTransformer-based AI agent trained with reinforcement learning. We enable\nreal-time interactions using the concept of anticipation, where the agent\ncontinually predicts how the performance will unfold and visually conveys its\nplan to the user. We conduct a user study where experienced musicians jam in\nreal-time with the agent through ReaLJam. Our results demonstrate that ReaLJam\nenables enjoyable and musically interesting sessions, and we uncover important\ntakeaways for future work.",
    "pdf_url": "http://arxiv.org/pdf/2502.21267v1",
    "published": "2025-02-28",
    "source": "arxiv",
    "id": "2502.21267v1",
    "categories": [
      "cs.HC",
      "cs.AI"
    ]
  },
  {
    "title": "Token-level Ensembling of Models with Different Vocabularies",
    "authors": [
      "Rachel Wicks",
      "Kartik Ravisankar",
      "Xinchen Yang",
      "Philipp Koehn",
      "Matt Post"
    ],
    "abstract": "Model ensembling is a technique to combine the predicted distributions of two\nor more models, often leading to improved robustness and performance. For\nensembling in text generation, the next token's probability distribution is\nderived from a weighted sum of the distributions of each individual model. This\nrequires the underlying models to share the same subword vocabulary, limiting\nthe applicability of ensembling, since many open-sourced models have distinct\nvocabularies. In research settings, experimentation or upgrades to vocabularies\nmay introduce multiple vocabulary sizes. This paper proposes an inference-time\nonly algorithm that allows for ensembling models with different vocabularies,\nwithout the need to learn additional parameters or alter the underlying models.\nInstead, the algorithm ensures that tokens generated by the ensembled models\n\\textit{agree} in their surface form. We apply this technique to combinations\nof traditional encoder-decoder models and decoder-only LLMs and evaluate on\nmachine translation. In addition to expanding to model pairs that were\npreviously incapable of token-level ensembling, our algorithm frequently\nimproves translation performance over either model individually.",
    "pdf_url": "http://arxiv.org/pdf/2502.21265v1",
    "published": "2025-02-28",
    "source": "arxiv",
    "id": "2502.21265v1",
    "categories": [
      "cs.CL"
    ]
  },
  {
    "title": "Foundation Models -- A Panacea for Artificial Intelligence in Pathology?",
    "authors": [
      "Nita Mulliqi",
      "Anders Blilie",
      "Xiaoyi Ji",
      "Kelvin Szolnoky",
      "Henrik Olsson",
      "Sol Erika Boman",
      "Matteo Titus",
      "Geraldine Martinez Gonzalez",
      "Julia Anna Mielcarz",
      "Masi Valkonen",
      "Einar Gudlaugsson",
      "Svein R. Kjosavik",
      "José Asenjo",
      "Marcello Gambacorta",
      "Paolo Libretti",
      "Marcin Braun",
      "Radzislaw Kordek",
      "Roman Łowicki",
      "Kristina Hotakainen",
      "Päivi Väre",
      "Bodil Ginnerup Pedersen",
      "Karina Dalsgaard Sørensen",
      "Benedicte Parm Ulhøi",
      "Pekka Ruusuvuori",
      "Brett Delahunt",
      "Hemamali Samaratunga",
      "Toyonori Tsuzuki",
      "Emilius A. M. Janssen",
      "Lars Egevad",
      "Martin Eklund",
      "Kimmo Kartasalo"
    ],
    "abstract": "The role of artificial intelligence (AI) in pathology has evolved from aiding\ndiagnostics to uncovering predictive morphological patterns in whole slide\nimages (WSIs). Recently, foundation models (FMs) leveraging self-supervised\npre-training have been widely advocated as a universal solution for diverse\ndownstream tasks. However, open questions remain about their clinical\napplicability and generalization advantages over end-to-end learning using\ntask-specific (TS) models. Here, we focused on AI with clinical-grade\nperformance for prostate cancer diagnosis and Gleason grading. We present the\nlargest validation of AI for this task, using over 100,000 core needle biopsies\nfrom 7,342 patients across 15 sites in 11 countries. We compared two FMs with a\nfully end-to-end TS model in a multiple instance learning framework. Our\nfindings challenge assumptions that FMs universally outperform TS models. While\nFMs demonstrated utility in data-scarce scenarios, their performance converged\nwith - and was in some cases surpassed by - TS models when sufficient labeled\ntraining data were available. Notably, extensive task-specific training\nmarkedly reduced clinically significant misgrading, misdiagnosis of challenging\nmorphologies, and variability across different WSI scanners. Additionally, FMs\nused up to 35 times more energy than the TS model, raising concerns about their\nsustainability. Our results underscore that while FMs offer clear advantages\nfor rapid prototyping and research, their role as a universal solution for\nclinically applicable medical AI remains uncertain. For high-stakes clinical\napplications, rigorous validation and consideration of task-specific training\nremain critically important. We advocate for integrating the strengths of FMs\nand end-to-end learning to achieve robust and resource-efficient AI pathology\nsolutions fit for clinical use.",
    "pdf_url": "http://arxiv.org/pdf/2502.21264v2",
    "published": "2025-02-28",
    "source": "arxiv",
    "id": "2502.21264v2",
    "categories": [
      "cs.CV",
      "cs.AI"
    ]
  },
  {
    "title": "RuCCoD: Towards Automated ICD Coding in Russian",
    "authors": [
      "Aleksandr Nesterov",
      "Andrey Sakhovskiy",
      "Ivan Sviridov",
      "Airat Valiev",
      "Vladimir Makharev",
      "Petr Anokhin",
      "Galina Zubkova",
      "Elena Tutubalina"
    ],
    "abstract": "This study investigates the feasibility of automating clinical coding in\nRussian, a language with limited biomedical resources. We present a new dataset\nfor ICD coding, which includes diagnosis fields from electronic health records\n(EHRs) annotated with over 10,000 entities and more than 1,500 unique ICD\ncodes. This dataset serves as a benchmark for several state-of-the-art models,\nincluding BERT, LLaMA with LoRA, and RAG, with additional experiments examining\ntransfer learning across domains (from PubMed abstracts to medical diagnosis)\nand terminologies (from UMLS concepts to ICD codes). We then apply the\nbest-performing model to label an in-house EHR dataset containing patient\nhistories from 2017 to 2021. Our experiments, conducted on a carefully curated\ntest set, demonstrate that training with the automated predicted codes leads to\na significant improvement in accuracy compared to manually annotated data from\nphysicians. We believe our findings offer valuable insights into the potential\nfor automating clinical coding in resource-limited languages like Russian,\nwhich could enhance clinical efficiency and data accuracy in these contexts.",
    "pdf_url": "http://arxiv.org/pdf/2502.21263v1",
    "published": "2025-02-28",
    "source": "arxiv",
    "id": "2502.21263v1",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.DB"
    ]
  },
  {
    "title": "Modeling Human Beliefs about AI Behavior for Scalable Oversight",
    "authors": [
      "Leon Lang",
      "Patrick Forré"
    ],
    "abstract": "Contemporary work in AI alignment often relies on human feedback to teach AI\nsystems human preferences and values. Yet as AI systems grow more capable,\nhuman feedback becomes increasingly unreliable. This raises the problem of\nscalable oversight: How can we supervise AI systems that exceed human\ncapabilities? In this work, we propose to model the human evaluator's beliefs\nabout the AI system's behavior to better interpret the human's feedback. We\nformalize human belief models and theoretically analyze their role in inferring\nhuman values. We then characterize the remaining ambiguity in this inference\nand conditions for which the ambiguity disappears. To mitigate reliance on\nexact belief models, we then introduce the relaxation of human belief model\ncovering. Finally, we propose using foundation models to construct covering\nbelief models, providing a new potential approach to scalable oversight.",
    "pdf_url": "http://arxiv.org/pdf/2502.21262v1",
    "published": "2025-02-28",
    "source": "arxiv",
    "id": "2502.21262v1",
    "categories": [
      "cs.AI",
      "cs.LG"
    ]
  },
  {
    "title": "ALVI Interface: Towards Full Hand Motion Decoding for Amputees Using sEMG",
    "authors": [
      "Aleksandr Kovalev",
      "Anna Makarova",
      "Petr Chizhov",
      "Matvey Antonov",
      "Gleb Duplin",
      "Vladislav Lomtev",
      "Viacheslav Gostevskii",
      "Vladimir Bessonov",
      "Andrey Tsurkan",
      "Mikhail Korobok",
      "Aleksejs Timčenko"
    ],
    "abstract": "We present a system for decoding hand movements using surface EMG signals.\nThe interface provides real-time (25 Hz) reconstruction of finger joint angles\nacross 20 degrees of freedom, designed for upper limb amputees. Our offline\nanalysis shows 0.8 correlation between predicted and actual hand movements. The\nsystem functions as an integrated pipeline with three key components: (1) a\nVR-based data collection platform, (2) a transformer-based model for\nEMG-to-motion transformation, and (3) a real-time calibration and feedback\nmodule called ALVI Interface. Using eight sEMG sensors and a VR training\nenvironment, users can control their virtual hand down to finger joint movement\nprecision, as demonstrated in our video: youtube link.",
    "pdf_url": "http://arxiv.org/pdf/2502.21256v1",
    "published": "2025-02-28",
    "source": "arxiv",
    "id": "2502.21256v1",
    "categories": [
      "cs.LG",
      "q-bio.NC"
    ]
  },
  {
    "title": "Learning-Driven Annealing with Adaptive Hamiltonian Modification for Solving Large-Scale Problems on Quantum Devices",
    "authors": [
      "Sebastian Schulz",
      "Dennis Willsch",
      "Kristel Michielsen"
    ],
    "abstract": "We present Learning-Driven Annealing (LDA), a framework that links individual\nquantum annealing evolutions into a global solution strategy to mitigate\nhardware constraints such as short annealing times and integrated control\nerrors. Unlike other iterative methods, LDA does not tune the annealing\nprocedure (e.g. annealing time or annealing schedule), but instead learns about\nthe problem structure to adaptively modify the problem Hamiltonian. By\ndeforming the instantaneous energy spectrum, LDA suppresses transitions into\nhigh-energy states and focuses the evolution into low-energy regions of the\nHilbert space. We demonstrate the efficacy of LDA by developing a hybrid\nquantum-classical solver for large-scale spin glasses. The hybrid solver is\nbased on a comprehensive study of the internal structure of spin glasses,\noutperforming other quantum and classical algorithms (e.g., reverse annealing,\ncyclic annealing, simulated annealing, Gurobi, Toshiba's SBM, VeloxQ and D-Wave\nhybrid) on 5580-qubit problem instances in both runtime and lowest energy. LDA\nis a step towards practical quantum computation that enables today's quantum\ndevices to compete with classical solvers.",
    "pdf_url": "http://arxiv.org/pdf/2502.21246v1",
    "published": "2025-02-28",
    "source": "arxiv",
    "id": "2502.21246v1",
    "categories": [
      "quant-ph"
    ]
  },
  {
    "title": "TimesBERT: A BERT-Style Foundation Model for Time Series Understanding",
    "authors": [
      "Haoran Zhang",
      "Yong Liu",
      "Yunzhong Qiu",
      "Haixuan Liu",
      "Zhongyi Pei",
      "Jianmin Wang",
      "Mingsheng Long"
    ],
    "abstract": "Time series analysis is crucial in diverse scenarios. Beyond forecasting,\nconsiderable real-world tasks are categorized into classification, imputation,\nand anomaly detection, underscoring different capabilities termed time series\nunderstanding in this paper. While GPT-style models have been positioned as\nfoundation models for time series forecasting, the BERT-style architecture,\nwhich has made significant advances in natural language understanding, has not\nbeen fully unlocked for time series understanding, possibly attributed to the\nundesirable dropout of essential elements of BERT. In this paper, inspired by\nthe shared multi-granularity structure between multivariate time series and\nmultisentence documents, we design TimesBERT to learn generic representations\nof time series including temporal patterns and variate-centric characteristics.\nIn addition to a natural adaptation of masked modeling, we propose a parallel\ntask of functional token prediction to embody vital multi-granularity\nstructures. Our model is pre-trained on 260 billion time points across diverse\ndomains. Leveraging multi-granularity representations, TimesBERT achieves\nstate-of-the-art performance across four typical downstream understanding\ntasks, outperforming task-specific models and language pre-trained backbones,\npositioning it as a versatile foundation model for time series understanding.",
    "pdf_url": "http://arxiv.org/pdf/2502.21245v1",
    "published": "2025-02-28",
    "source": "arxiv",
    "id": "2502.21245v1",
    "categories": [
      "cs.LG"
    ]
  },
  {
    "title": "Anatomically-guided masked autoencoder pre-training for aneurysm detection",
    "authors": [
      "Alberto Mario Ceballos-Arroyo",
      "Jisoo Kim",
      "Chu-Hsuan Lin",
      "Lei Qin",
      "Geoffrey S. Young",
      "Huaizu Jiang"
    ],
    "abstract": "Intracranial aneurysms are a major cause of morbidity and mortality\nworldwide, and detecting them manually is a complex, time-consuming task.\nAlbeit automated solutions are desirable, the limited availability of training\ndata makes it difficult to develop such solutions using typical supervised\nlearning frameworks. In this work, we propose a novel pre-training strategy\nusing more widely available unannotated head CT scan data to pre-train a 3D\nVision Transformer model prior to fine-tuning for the aneurysm detection task.\nSpecifically, we modify masked auto-encoder (MAE) pre-training in the following\nways: we use a factorized self-attention mechanism to make 3D attention\ncomputationally viable, we restrict the masked patches to areas near arteries\nto focus on areas where aneurysms are likely to occur, and we reconstruct not\nonly CT scan intensity values but also artery distance maps, which describe the\ndistance between each voxel and the closest artery, thereby enhancing the\nbackbone's learned representations. Compared with SOTA aneurysm detection\nmodels, our approach gains +4-8% absolute Sensitivity at a false positive rate\nof 0.5. Code and weights will be released.",
    "pdf_url": "http://arxiv.org/pdf/2502.21244v1",
    "published": "2025-02-28",
    "source": "arxiv",
    "id": "2502.21244v1",
    "categories": [
      "cs.CV"
    ]
  },
  {
    "title": "The Structural Complexity of Matrix-Vector Multiplication",
    "authors": [
      "Emile Anand",
      "Jan van den Brand",
      "Rose McCarty"
    ],
    "abstract": "We consider the problem of preprocessing an $n\\times n$ matrix M, and\nsupporting queries that, for any vector v, returns the matrix-vector product\nMv. This problem has been extensively studied in both theory and practice: on\none side, practitioners have developed algorithms that are highly efficient in\npractice, whereas theoreticians have proven that the problem cannot be solved\nfaster than naive multiplication in the worst-case. This lower bound holds even\nin the average-case, implying that existing average-case analyses cannot\nexplain this gap between theory and practice. Therefore, we study the problem\nfor structured matrices. We show that for $n\\times n$ matrices of VC-dimension\nd, the matrix-vector multiplication problem can be solved with $\\tilde{O}(n^2)$\npreprocessing and $\\tilde O(n^{2-1/d})$ query time. Given the low constant\nVC-dimensions observed in most real-world data, our results posit an\nexplanation for why the problem can be solved so much faster in practice.\nMoreover, our bounds hold even if the matrix does not have a low VC-dimension,\nbut is obtained by (possibly adversarially) corrupting at most a subquadratic\nnumber of entries of any unknown low VC-dimension matrix. Our results yield the\nfirst non-trivial upper bounds for many applications. In previous works, the\nonline matrix-vector hypothesis (conjecturing that quadratic time is needed per\nquery) was used to prove many conditional lower bounds, showing that it is\nimpossible to compute and maintain high-accuracy estimates for shortest paths,\nLaplacian solvers, effective resistance, and triangle detection in graphs\nsubject to node insertions and deletions in subquadratic time. Yet, via a\nreduction to our matrix-vector-multiplication result, we show we can maintain\nthe aforementioned problems efficiently if the input is structured, providing\nthe first subquadratic upper bounds in the high-accuracy regime.",
    "pdf_url": "http://arxiv.org/pdf/2502.21240v1",
    "published": "2025-02-28",
    "source": "arxiv",
    "id": "2502.21240v1",
    "categories": [
      "cs.DS",
      "cs.CC",
      "cs.CG",
      "cs.LG",
      "65F05",
      "F.2.1"
    ]
  },
  {
    "title": "Structure and Dynamics of Deep Eutectic Systems from Cluster-Optimized Energy Functions",
    "authors": [
      "Kai Töpfer",
      "Jingchun Wang",
      "Shimoni Patel",
      "Markus Meuwly"
    ],
    "abstract": "Generating energy functions for heterogeneous systems suitable for\nquantitative and predictive atomistic simulations is a challenging undertaking.\nThe present work combines a cluster-based approach with electronic structure\ncalculations at the density functional theory level and machine learning-based\nenergy functions for a spectroscopic reporter for eutectic mixtures consisting\nof water, acetamide and KSCN. Two water models are considered: TIP3P which is\nconsistent with the CGenFF energy function and TIP4P which - as a water model -\nis superior to TIP4P. Both fitted models, {\\bf M2$^{\\rm TIP3P}$} and {\\bf\n  M2$^{\\rm TIP4P}$}, yield favourable thermodynamic, structural, spectroscopic\nand transport properties from extensive molecular dynamics simulations. In\nparticular, the slow and fast decay times from 2-dimensional infrared\nspectroscopy and the viscosity for water-rich mixtures are described\nrealistically and consistent with experiments. On the other hand, including the\nco-solvent (acetamide) in the present case is expected to further improve the\ncomputed viscosity for low-water content. It is concluded that such a\ncluster-based approach is a promising and generalizable route for routine\nparametrization of heterogeneous, electrostatically dominated systems.",
    "pdf_url": "http://arxiv.org/pdf/2502.21233v1",
    "published": "2025-02-28",
    "source": "arxiv",
    "id": "2502.21233v1",
    "categories": [
      "physics.chem-ph"
    ]
  },
  {
    "title": "ByteScale: Efficient Scaling of LLM Training with a 2048K Context Length on More Than 12,000 GPUs",
    "authors": [
      "Hao Ge",
      "Junda Feng",
      "Qi Huang",
      "Fangcheng Fu",
      "Xiaonan Nie",
      "Lei Zuo",
      "Haibin Lin",
      "Bin Cui",
      "Xin Liu"
    ],
    "abstract": "Scaling long-context ability is essential for Large Language Models (LLMs).\nTo amortize the memory consumption across multiple devices in long-context\ntraining, inter-data partitioning (a.k.a. Data Parallelism) and intra-data\npartitioning (a.k.a. Context Parallelism) are commonly used. Current training\nframeworks predominantly treat the two techniques as orthogonal, and establish\nstatic communication groups to organize the devices as a static mesh (e.g., a\n2D mesh). However, the sequences for LLM training typically vary in lengths, no\nmatter for texts, multi-modalities or reinforcement learning. The mismatch\nbetween data heterogeneity and static mesh causes redundant communication and\nimbalanced computation, degrading the training efficiency.\n  In this work, we introduce ByteScale, an efficient, flexible, and scalable\nLLM training framework for large-scale mixed training of long and short\nsequences. The core of ByteScale is a novel parallelism strategy, namely Hybrid\nData Parallelism (HDP), which unifies the inter- and intra-data partitioning\nwith a dynamic mesh design. In particular, we build a communication optimizer,\nwhich eliminates the redundant communication for short sequences by data-aware\nsharding and dynamic communication, and further compresses the communication\ncost for long sequences by selective offloading. Besides, we also develop a\nbalance scheduler to mitigate the imbalanced computation by parallelism-aware\ndata assignment. We evaluate ByteScale with the model sizes ranging from 7B to\n141B, context lengths from 256K to 2048K, on a production cluster with more\nthan 12,000 GPUs. Experiment results show that ByteScale outperforms the\nstate-of-the-art training system by up to 7.89x.",
    "pdf_url": "http://arxiv.org/pdf/2502.21231v1",
    "published": "2025-02-28",
    "source": "arxiv",
    "id": "2502.21231v1",
    "categories": [
      "cs.DC",
      "cs.AI",
      "cs.LG"
    ]
  },
  {
    "title": "A Method of Selective Attention for Reservoir Based Agents",
    "authors": [
      "Kevin McKee"
    ],
    "abstract": "Training of deep reinforcement learning agents is slowed considerably by the\npresence of input dimensions that do not usefully condition the reward\nfunction. Existing modules such as layer normalization can be trained with\nweight decay to act as a form of selective attention, i.e. an input mask, that\nshrinks the scale of unnecessary inputs, which in turn accelerates training of\nthe policy. However, we find a surprising result that adding numerous\nparameters to the computation of the input mask results in much faster\ntraining. A simple, high dimensional masking module is compared with layer\nnormalization and a model without any input suppression. The high dimensional\nmask resulted in a four-fold speedup in training over the null hypothesis and a\ntwo-fold speedup in training over the layer normalization method.",
    "pdf_url": "http://arxiv.org/pdf/2502.21229v1",
    "published": "2025-02-28",
    "source": "arxiv",
    "id": "2502.21229v1",
    "categories": [
      "cs.LG"
    ]
  },
  {
    "title": "Recurrent CircuitSAT Sampling for Sequential Circuits",
    "authors": [
      "Arash Ardakani",
      "Kevin He",
      "John Wawrzynek"
    ],
    "abstract": "In this work, we introduce a novel GPU-accelerated circuit satisfiability\n(CircuitSAT) sampling technique for sequential circuits. This work is motivated\nby the requirement in constrained random verification (CRV) to generate input\nstimuli to validate the functionality of digital hardware circuits. A major\nchallenge in CRV is generating inputs for sequential circuits, along with the\nappropriate number of clock cycles required to meet design constraints.\nTraditional approaches often use Boolean satisfiability (SAT) samplers to\ngenerate inputs by unrolling state transitions over a fixed number of clock\ncycles. However, these methods do not guarantee that a solution exists for the\ngiven number of cycles. Consequently, producing input stimuli together with the\nrequired clock cycles is essential for thorough testing and verification. Our\napproach converts the logical constraints and temporal behavior of sequential\ncircuits into a recurrent CircuitSAT problem, optimized via gradient descent to\nefficiently explore a diverse set of valid solutions, including their\nassociated number of clock cycles. By operating directly on the circuit\nstructure, our method reinterprets the sampling process as a supervised\nmulti-output regression task. This differentiable framework enables independent\nelement-wise operations on each tensor element, facilitating parallel execution\nduring learning. As a result, we achieve GPU-accelerated sampling with\nsubstantial runtime improvements (up to 105.1x) over state-of-the-art heuristic\nsamplers. We demonstrate the effectiveness of our method through extensive\nevaluations on circuit problems from the ISCAS-89 and ITC'99 benchmark suites.",
    "pdf_url": "http://arxiv.org/pdf/2502.21226v2",
    "published": "2025-02-28",
    "source": "arxiv",
    "id": "2502.21226v2",
    "categories": [
      "cs.AR",
      "cs.PF"
    ]
  },
  {
    "title": "Exercises on the Kepler ellipses through a fixed point in space, after Otto Laporte",
    "authors": [
      "Gert Heckman"
    ],
    "abstract": "This article has a twofold purpose. On the one hand I would like to draw\nattention to some nice exercises on the Kepler laws, due to Otto Laporte from\n1970. Our discussion here has a more geometric flavour than the original\nanalytic approach of Laporte. On the other hand it serves as an addendum to a\npaper of mine from 1998 on the quantum integrability of the Kovalevsky top.\nLater I learned that this integrability result had been obtained already long\nbefore by Laporte in 1933.",
    "pdf_url": "http://arxiv.org/pdf/2502.21222v1",
    "published": "2025-02-28",
    "source": "arxiv",
    "id": "2502.21222v1",
    "categories": [
      "math.SG",
      "math-ph",
      "math.HO",
      "math.MP"
    ]
  },
  {
    "title": "Transformers Learn to Implement Multi-step Gradient Descent with Chain of Thought",
    "authors": [
      "Jianhao Huang",
      "Zixuan Wang",
      "Jason D. Lee"
    ],
    "abstract": "Chain of Thought (CoT) prompting has been shown to significantly improve the\nperformance of large language models (LLMs), particularly in arithmetic and\nreasoning tasks, by instructing the model to produce intermediate reasoning\nsteps. Despite the remarkable empirical success of CoT and its theoretical\nadvantages in enhancing expressivity, the mechanisms underlying CoT training\nremain largely unexplored. In this paper, we study the training dynamics of\ntransformers over a CoT objective on an in-context weight prediction task for\nlinear regression. We prove that while a one-layer linear transformer without\nCoT can only implement a single step of gradient descent (GD) and fails to\nrecover the ground-truth weight vector, a transformer with CoT prompting can\nlearn to perform multi-step GD autoregressively, achieving near-exact recovery.\nFurthermore, we show that the trained transformer effectively generalizes on\nthe unseen data. With our technique, we also show that looped transformers\nsignificantly improve final performance compared to transformers without\nlooping in the in-context learning of linear regression. Empirically, we\ndemonstrate that CoT prompting yields substantial performance improvements.",
    "pdf_url": "http://arxiv.org/pdf/2502.21212v1",
    "published": "2025-02-28",
    "source": "arxiv",
    "id": "2502.21212v1",
    "categories": [
      "cs.LG",
      "cs.AI"
    ]
  },
  {
    "title": "End-to-End Deep Learning in Phase Noisy Coherent Optical Link",
    "authors": [
      "Omar Alnaseri",
      "Yassine Himeur"
    ],
    "abstract": "In coherent optical orthogonal frequency-division multiplexing (CO-OFDM)\nfiber communications, a novel end-to-end learning framework to mitigate Laser\nPhase Noise (LPN) impairments is proposed in this paper. Inspired by\nAutoencoder (AE) principles, the proposed approach trains a model to learn\nrobust symbol sequences capable of combat LPN, even from low-cost distributed\nfeedback (DFB) lasers with linewidths up to 2 MHz. This allows for the use of\nhigh-level modulation formats and large-scale Fast Fourier Transform (FFT)\nprocessing, maximizing spectral efficiency in CO-OFDM systems. By eliminating\nthe need for complex traditional techniques, this approach offers a potentially\nmore efficient and streamlined solution for CO-OFDM systems. The most\nsignificant achievement of this study is the demonstration that the proposed\nAE-based model can enhance system performance by reducing the bit error rate\n(BER) to below the threshold of forward error correction (FEC), even under\nsevere phase noise conditions, thus proving its effectiveness and efficiency in\npractical deployment scenarios.",
    "pdf_url": "http://arxiv.org/pdf/2502.21209v1",
    "published": "2025-02-28",
    "source": "arxiv",
    "id": "2502.21209v1",
    "categories": [
      "eess.SP"
    ]
  },
  {
    "title": "ARIES: Autonomous Reasoning with LLMs on Interactive Thought Graph Environments",
    "authors": [
      "Pedro Gimenes",
      "Zeyu Cao",
      "Jeffrey Wong",
      "Yiren Zhao"
    ],
    "abstract": "Recent research has shown that LLM performance on reasoning tasks can be\nenhanced by scaling test-time compute. One promising approach, particularly\nwith decomposable problems, involves arranging intermediate solutions as a\ngraph on which transformations are performed to explore the solution space.\nHowever, prior works rely on pre-determined, task-specific transformation\nschedules which are subject to a set of searched hyperparameters. In this work,\nwe view thought graph transformations as actions in a Markov decision process,\nand implement policy agents to drive effective action policies for the\nunderlying reasoning LLM agent. In particular, we investigate the ability for\nanother LLM to act as a policy agent on thought graph environments and\nintroduce ARIES, a multi-agent architecture for reasoning with LLMs. In ARIES,\nreasoning LLM agents solve decomposed subproblems, while policy LLM agents\nmaintain visibility of the thought graph states, and dynamically adapt the\nproblem-solving strategy. Through extensive experiments, we observe that using\noff-the-shelf LLMs as policy agents with no supervised fine-tuning (SFT) can\nyield up to $29\\%$ higher accuracy on HumanEval relative to static\ntransformation schedules, as well as reducing inference costs by $35\\%$ and\navoid any search requirements. We also conduct a thorough analysis of observed\nfailure modes, highlighting that limitations on LLM sizes and the depth of\nproblem decomposition can be seen as challenges to scaling LLM-guided\nreasoning.",
    "pdf_url": "http://arxiv.org/pdf/2502.21208v1",
    "published": "2025-02-28",
    "source": "arxiv",
    "id": "2502.21208v1",
    "categories": [
      "cs.AI",
      "cs.LG"
    ]
  },
  {
    "title": "AI-Enhanced Self-Triggering for Extensive Air Showers: Performance and FPGA Feasibility",
    "authors": [
      "Qader Dorosti"
    ],
    "abstract": "Cosmic-ray detection with radio antennas has traditionally depended on\nexternal triggers from particle detectors, constraining sensitivity and\nincreasing complexity. Previous attempts at fully standalone, radio-only\ntriggers have often failed under intense radio frequency interference, making\ngenuine air-shower signals difficult to isolate. We present a\nproof-of-principle artificial intelligence-based self-triggering system that\novercomes these limitations. By training a deep learning model on both real\nnoise data and injected cosmic-ray-like pulses, we achieve an exceptionally low\nfalse-positive rate alongside high detection efficiency. Configurable operating\npoints can suppress false positives below 0.01\\% while retaining more than 88\\%\nof genuine signals, and can even eliminate false positives entirely at a modest\nreduction in signal efficiency. This flexibility makes single-station\ncosmic-ray detection feasible without requiring external trigger inputs.\nApplying our approach to real-world noise conditions reduces the initial\nfalse-positive event rate by several orders of magnitude, supporting\nlarge-scale deployments. Extrapolation to dedicated hardware implementations,\nsuch as FPGAs, indicates that sub-\\SI{}{\\micro\\second} inference times are\nachievable, enabling real-time autonomous triggering. These results highlight\nthe transformative potential of artificial intelligence for enhancing radio\ndetection sensitivity and inaugurate a new generation of fully self-triggered\ncosmic-ray observatories.",
    "pdf_url": "http://arxiv.org/pdf/2502.21198v1",
    "published": "2025-02-28",
    "source": "arxiv",
    "id": "2502.21198v1",
    "categories": [
      "astro-ph.IM",
      "physics.ins-det"
    ]
  },
  {
    "title": "AMPLE: Event-Driven Accelerator for Mixed-Precision Inference of Graph Neural Networks",
    "authors": [
      "Pedro Gimenes",
      "Yiren Zhao",
      "George Constantinides"
    ],
    "abstract": "Graph Neural Networks (GNNs) have recently gained attention due to their\nperformance on non-Euclidean data. The use of custom hardware architectures\nproves particularly beneficial for GNNs due to their irregular memory access\npatterns, resulting from the sparse structure of graphs. However, existing FPGA\naccelerators are limited by their double buffering mechanism, which doesn't\naccount for the irregular node distribution in typical graph datasets. To\naddress this, we introduce \\textbf{AMPLE} (Accelerated Message Passing Logic\nEngine), an FPGA accelerator leveraging a new event-driven programming flow. We\ndevelop a mixed-arithmetic architecture, enabling GNN inference to be quantized\nat a node-level granularity. Finally, prefetcher for data and instructions is\nimplemented to optimize off-chip memory access and maximize node parallelism.\nEvaluation on citation and social media graph datasets ranging from $2$K to\n$700$K nodes showed a mean speedup of $243\\times$ and $7.2\\times$ against CPU\nand GPU counterparts, respectively.",
    "pdf_url": "http://arxiv.org/pdf/2502.21196v1",
    "published": "2025-02-28",
    "source": "arxiv",
    "id": "2502.21196v1",
    "categories": [
      "cs.AR",
      "cs.AI",
      "cs.LG"
    ]
  },
  {
    "title": "Class prior estimation for positive-unlabeled learning when label shift occurs",
    "authors": [
      "Jan Mielniczuk",
      "Wojciech Rejchel",
      "Paweł Teisseyre"
    ],
    "abstract": "We study estimation of class prior for unlabeled target samples which is\npossibly different from that of source population. It is assumed that for the\nsource data only samples from positive class and from the whole population are\navailable (PU learning scenario). We introduce a novel direct estimator of\nclass prior which avoids estimation of posterior probabilities and has a simple\ngeometric interpretation. It is based on a distribution matching technique\ntogether with kernel embedding and is obtained as an explicit solution to an\noptimisation task. We establish its asymptotic consistency as well as a\nnon-asymptotic bound on its deviation from the unknown prior, which is\ncalculable in practice. We study finite sample behaviour for synthetic and real\ndata and show that the proposal, together with a suitably modified version for\nlarge values of source prior, works on par or better than its competitors.",
    "pdf_url": "http://arxiv.org/pdf/2502.21194v1",
    "published": "2025-02-28",
    "source": "arxiv",
    "id": "2502.21194v1",
    "categories": [
      "stat.ML",
      "cs.LG"
    ]
  },
  {
    "title": "Geodesic Slice Sampler for Multimodal Distributions with Strong Curvature",
    "authors": [
      "Bernardo Williams",
      "Hanlin Yu",
      "Hoang Phuc Hau Luu",
      "Georgios Arvanitidis",
      "Arto Klami"
    ],
    "abstract": "Traditional Markov Chain Monte Carlo sampling methods often struggle with\nsharp curvatures, intricate geometries, and multimodal distributions. Slice\nsampling can resolve local exploration inefficiency issues and Riemannian\ngeometries help with sharp curvatures. Recent extensions enable slice sampling\non Riemannian manifolds, but they are restricted to cases where geodesics are\navailable in closed form. We propose a method that generalizes Hit-and-Run\nslice sampling to more general geometries tailored to the target distribution,\nby approximating geodesics as solutions to differential equations. Our approach\nenables exploration of regions with strong curvature and rapid transitions\nbetween modes in multimodal distributions. We demonstrate the advantages of the\napproach over challenging sampling problems.",
    "pdf_url": "http://arxiv.org/pdf/2502.21190v1",
    "published": "2025-02-28",
    "source": "arxiv",
    "id": "2502.21190v1",
    "categories": [
      "cs.LG"
    ]
  },
  {
    "title": "SYN-LUNGS: Towards Simulating Lung Nodules with Anatomy-Informed Digital Twins for AI Training",
    "authors": [
      "Fakrul Islam Tushar",
      "Lavsen Dahal",
      "Cindy McCabe",
      "Fong Chi Ho",
      "Paul Segars",
      "Ehsan Abadi",
      "Kyle J. Lafata",
      "Ehsan Samei",
      "Joseph Y. Lo"
    ],
    "abstract": "AI models for lung cancer screening are limited by data scarcity, impacting\ngeneralizability and clinical applicability. Generative models address this\nissue but are constrained by training data variability. We introduce SYN-LUNGS,\na framework for generating high-quality 3D CT images with detailed annotations.\nSYN-LUNGS integrates XCAT3 phantoms for digital twin generation, X-Lesions for\nnodule simulation (varying size, location, and appearance), and DukeSim for CT\nimage formation with vendor and parameter variability. The dataset includes\n3,072 nodule images from 1,044 simulated CT scans, with 512 lesions and 174\ndigital twins. Models trained on clinical + simulated data outperform clinical\nonly models, achieving 10% improvement in detection, 2-9% in segmentation and\nclassification, and enhanced synthesis.By incorporating anatomy-informed\nsimulations, SYN-LUNGS provides a scalable approach for AI model development,\nparticularly in rare disease representation and improving model reliability.",
    "pdf_url": "http://arxiv.org/pdf/2502.21187v1",
    "published": "2025-02-28",
    "source": "arxiv",
    "id": "2502.21187v1",
    "categories": [
      "cs.LG"
    ]
  },
  {
    "title": "Scalable Decision-Making in Stochastic Environments through Learned Temporal Abstraction",
    "authors": [
      "Baiting Luo",
      "Ava Pettet",
      "Aron Laszka",
      "Abhishek Dubey",
      "Ayan Mukhopadhyay"
    ],
    "abstract": "Sequential decision-making in high-dimensional continuous action spaces,\nparticularly in stochastic environments, faces significant computational\nchallenges. We explore this challenge in the traditional offline RL setting,\nwhere an agent must learn how to make decisions based on data collected through\na stochastic behavior policy. We present Latent Macro Action Planner (L-MAP),\nwhich addresses this challenge by learning a set of temporally extended\nmacro-actions through a state-conditional Vector Quantized Variational\nAutoencoder (VQ-VAE), effectively reducing action dimensionality. L-MAP employs\na (separate) learned prior model that acts as a latent transition model and\nallows efficient sampling of plausible actions. During planning, our approach\naccounts for stochasticity in both the environment and the behavior policy by\nusing Monte Carlo tree search (MCTS). In offline RL settings, including\nstochastic continuous control tasks, L-MAP efficiently searches over discrete\nlatent actions to yield high expected returns. Empirical results demonstrate\nthat L-MAP maintains low decision latency despite increased action\ndimensionality. Notably, across tasks ranging from continuous control with\ninherently stochastic dynamics to high-dimensional robotic hand manipulation,\nL-MAP significantly outperforms existing model-based methods and performs\non-par with strong model-free actor-critic baselines, highlighting the\neffectiveness of the proposed approach in planning in complex and stochastic\nenvironments with high-dimensional action spaces.",
    "pdf_url": "http://arxiv.org/pdf/2502.21186v2",
    "published": "2025-02-28",
    "source": "arxiv",
    "id": "2502.21186v2",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.RO"
    ]
  },
  {
    "title": "HQColon: A Hybrid Interactive Machine Learning Pipeline for High Quality Colon Labeling and Segmentation",
    "authors": [
      "Martina Finocchiaro",
      "Ronja Stern",
      "Abraham George Smith",
      "Jens Petersen",
      "Kenny Erleben",
      "Melanie Ganz"
    ],
    "abstract": "High-resolution colon segmentation is crucial for clinical and research\napplications, such as digital twins and personalized medicine. However, the\nleading open-source abdominal segmentation tool, TotalSegmentator, struggles\nwith accuracy for the colon, which has a complex and variable shape, requiring\ntime-intensive labeling. Here, we present the first fully automatic\nhigh-resolution colon segmentation method. To develop it, we first created a\nhigh resolution colon dataset using a pipeline that combines region growing\nwith interactive machine learning to efficiently and accurately label the colon\non CT colonography (CTC) images. Based on the generated dataset consisting of\n435 labeled CTC images we trained an nnU-Net model for fully automatic colon\nsegmentation. Our fully automatic model achieved an average symmetric surface\ndistance of 0.2 mm (vs. 4.0 mm from TotalSegmentator) and a 95th percentile\nHausdorff distance of 1.0 mm (vs. 18 mm from TotalSegmentator). Our\nsegmentation accuracy substantially surpasses TotalSegmentator. We share our\ntrained model and pipeline code, providing the first and only open-source tool\nfor high-resolution colon segmentation. Additionally, we created a large-scale\ndataset of publicly available high-resolution colon labels.",
    "pdf_url": "http://arxiv.org/pdf/2502.21183v1",
    "published": "2025-02-28",
    "source": "arxiv",
    "id": "2502.21183v1",
    "categories": [
      "cs.CV",
      "cs.LG"
    ]
  },
  {
    "title": "Reducing Reward Dependence in RL Through Adaptive Confidence Discounting",
    "authors": [
      "Muhammed Yusuf Satici",
      "David L. Roberts"
    ],
    "abstract": "In human-in-the-loop reinforcement learning or environments where calculating\na reward is expensive, the costly rewards can make learning efficiency\nchallenging to achieve. The cost of obtaining feedback from humans or\ncalculating expensive rewards means algorithms receiving feedback at every step\nof long training sessions may be infeasible, which may limit agents' abilities\nto efficiently improve performance. Our aim is to reduce the reliance of\nlearning agents on humans or expensive rewards, improving the efficiency of\nlearning while maintaining the quality of the learned policy. We offer a novel\nreinforcement learning algorithm that requests a reward only when its knowledge\nof the value of actions in an environment state is low. Our approach uses a\nreward function model as a proxy for human-delivered or expensive rewards when\nconfidence is high, and asks for those explicit rewards only when there is low\nconfidence in the model's predicted rewards and/or action selection. By\nreducing dependence on the expensive-to-obtain rewards, we are able to learn\nefficiently in settings where the logistics or expense of obtaining rewards may\notherwise prohibit it. In our experiments our approach obtains comparable\nperformance to a baseline in terms of return and number of episodes required to\nlearn, but achieves that performance with as few as 20% of the rewards.",
    "pdf_url": "http://arxiv.org/pdf/2502.21181v1",
    "published": "2025-02-28",
    "source": "arxiv",
    "id": "2502.21181v1",
    "categories": [
      "cs.LG"
    ]
  },
  {
    "title": "QFAL: Quantum Federated Adversarial Learning",
    "authors": [
      "Walid El Maouaki",
      "Nouhaila Innan",
      "Alberto Marchisio",
      "Taoufik Said",
      "Mohamed Bennai",
      "Muhammad Shafique"
    ],
    "abstract": "Quantum federated learning (QFL) merges the privacy advantages of federated\nsystems with the computational potential of quantum neural networks (QNNs), yet\nits vulnerability to adversarial attacks remains poorly understood. This work\npioneers the integration of adversarial training into QFL, proposing a robust\nframework, quantum federated adversarial learning (QFAL), where clients\ncollaboratively defend against perturbations by combining local adversarial\nexample generation with federated averaging (FedAvg). We systematically\nevaluate the interplay between three critical factors: client count (5, 10,\n15), adversarial training coverage (0-100%), and adversarial attack\nperturbation strength (epsilon = 0.01-0.5), using the MNIST dataset. Our\nexperimental results show that while fewer clients often yield higher\nclean-data accuracy, larger federations can more effectively balance accuracy\nand robustness when partially adversarially trained. Notably, even limited\nadversarial coverage (e.g., 20%-50%) can significantly improve resilience to\nmoderate perturbations, though at the cost of reduced baseline performance.\nConversely, full adversarial training (100%) may regain high clean accuracy but\nis vulnerable under stronger attacks. These findings underscore an inherent\ntrade-off between robust and standard objectives, which is further complicated\nby quantum-specific factors. We conclude that a carefully chosen combination of\nclient count and adversarial coverage is critical for mitigating adversarial\nvulnerabilities in QFL. Moreover, we highlight opportunities for future\nresearch, including adaptive adversarial training schedules, more diverse\nquantum encoding schemes, and personalized defense strategies to further\nenhance the robustness-accuracy trade-off in real-world quantum federated\nenvironments.",
    "pdf_url": "http://arxiv.org/pdf/2502.21171v1",
    "published": "2025-02-28",
    "source": "arxiv",
    "id": "2502.21171v1",
    "categories": [
      "cs.LG",
      "quant-ph"
    ]
  },
  {
    "title": "Autonomous Curriculum Design via Relative Entropy Based Task Modifications",
    "authors": [
      "Muhammed Yusuf Satici",
      "Jianxun Wang",
      "David L. Roberts"
    ],
    "abstract": "Curriculum learning is a training method in which an agent is first trained\non a curriculum of relatively simple tasks related to a target task in an\neffort to shorten the time required to train on the target task. Autonomous\ncurriculum design involves the design of such curriculum with no reliance on\nhuman knowledge and/or expertise. Finding an efficient and effective way of\nautonomously designing curricula remains an open problem. We propose a novel\napproach for automatically designing curricula by leveraging the learner's\nuncertainty to select curricula tasks. Our approach measures the uncertainty in\nthe learner's policy using relative entropy, and guides the agent to states of\nhigh uncertainty to facilitate learning. Our algorithm supports the generation\nof autonomous curricula in a self-assessed manner by leveraging the learner's\npast and current policies but it also allows the use of teacher guided design\nin an instructive setting. We provide theoretical guarantees for the\nconvergence of our algorithm using two time-scale optimization processes.\nResults show that our algorithm outperforms randomly generated curriculum, and\nlearning directly on the target task as well as the curriculum-learning\ncriteria existing in literature. We also present two additional heuristic\ndistance measures that could be combined with our relative-entropy approach for\nfurther performance improvements.",
    "pdf_url": "http://arxiv.org/pdf/2502.21166v1",
    "published": "2025-02-28",
    "source": "arxiv",
    "id": "2502.21166v1",
    "categories": [
      "cs.LG"
    ]
  },
  {
    "title": "Parallel-Learning of Invariant and Tempo-variant Attributes of Single-Lead Cardiac Signals: PLITA",
    "authors": [
      "Adtian Atienza",
      "Jakob E. Bardram",
      "Sadasivan Puthusserypady"
    ],
    "abstract": "Wearable sensing devices, such as Holter monitors, will play a crucial role\nin the future of digital health. Unsupervised learning frameworks such as\nSelf-Supervised Learning (SSL) are essential to map these single-lead\nelectrocardiogram (ECG) signals with their anticipated clinical outcomes. These\nsignals are characterized by a tempo-variant component whose patterns evolve\nthrough the recording and an invariant component with patterns that remain\nunchanged. However, existing SSL methods only drive the model to encode the\ninvariant attributes, leading the model to neglect tempo-variant information\nwhich reflects subject-state changes through time. In this paper, we present\nParallel-Learning of Invariant and Tempo-variant Attributes (PLITA), a novel\nSSL method designed for capturing both invariant and tempo-variant ECG\nattributes. The latter are captured by mandating closer representations in\nspace for closer inputs on time. We evaluate both the capability of the method\nto learn the attributes of these two distinct kinds, as well as PLITA's\nperformance compared to existing SSL methods for ECG analysis. PLITA performs\nsignificantly better in the set-ups where tempo-variant attributes play a major\nrole.",
    "pdf_url": "http://arxiv.org/pdf/2502.21162v1",
    "published": "2025-02-28",
    "source": "arxiv",
    "id": "2502.21162v1",
    "categories": [
      "cs.LG"
    ]
  },
  {
    "title": "Hypergraph Multi-Modal Learning for EEG-based Emotion Recognition in Conversation",
    "authors": [
      "Zijian Kang",
      "Yueyang Li",
      "Shengyu Gong",
      "Weiming Zeng",
      "Hongjie Yan",
      "Lingbin Bian",
      "Wai Ting Siok",
      "Nizhuan Wang"
    ],
    "abstract": "Emotional Recognition in Conversation (ERC) is an important method for\ndiagnosing health conditions such as autism or depression, as well as\nunderstanding emotions in individuals who struggle to express their feelings.\nCurrent ERC methods primarily rely on complete semantic textual information,\nincluding audio and visual data, but face challenges in integrating\nphysiological signals such as electroencephalogram (EEG). This paper proposes a\nnovel Hypergraph Multi-Modal Learning Framework (Hyper-MML), designed to\neffectively identify emotions in conversation by integrating EEG with audio and\nvideo information to capture complex emotional dynamics. Experimental results\ndemonstrate that Hyper-MML significantly outperforms traditional methods in\nemotion recognition. This is achieved through a Multi-modal Hypergraph Fusion\nModule (MHFM), which actively models higher-order relationships between\nmulti-modal signals, as validated on the EAV dataset. Our proposed Hyper-MML\nserves as an effective communication tool for healthcare professionals,\nenabling better engagement with patients who have difficulty expressing their\nemotions.",
    "pdf_url": "http://arxiv.org/pdf/2502.21154v1",
    "published": "2025-02-28",
    "source": "arxiv",
    "id": "2502.21154v1",
    "categories": [
      "cs.HC"
    ]
  },
  {
    "title": "Applications of Enhanced Sampling Methods to Biomolecular Self-Assembly: A Review",
    "authors": [
      "Mason Hooten",
      "Het Patel",
      "Yiwei Shao",
      "Rishabh Kumar Singh",
      "Meenakshi Dutt"
    ],
    "abstract": "This review article discusses some common enhanced sampling methods in\nrelation to the process of self-assembly of biomolecules. An introduction to\nself-assembly and its challenges is covered followed by a brief overview of the\nmethods and analysis for replica-exchange molecular dynamics, umbrella\nsampling, metadynamics, and machine learning based techniques. Applications of\nselect methods towards peptides, proteins, polymers, nucleic acids, and\nsupramolecules are discussed. Finally, a short discussion of the future\ndirections of some of these methods is provided.",
    "pdf_url": "http://arxiv.org/pdf/2502.21148v1",
    "published": "2025-02-28",
    "source": "arxiv",
    "id": "2502.21148v1",
    "categories": [
      "cond-mat.soft"
    ]
  },
  {
    "title": "Same accuracy, twice as fast: continuous training surpasses retraining from scratch",
    "authors": [
      "Eli Verwimp",
      "Guy Hacohen",
      "Tinne Tuytelaars"
    ],
    "abstract": "Continual learning aims to enable models to adapt to new datasets without\nlosing performance on previously learned data, often assuming that prior data\nis no longer available. However, in many practical scenarios, both old and new\ndata are accessible. In such cases, good performance on both datasets is\ntypically achieved by abandoning the model trained on the previous data and\nre-training a new model from scratch on both datasets. This training from\nscratch is computationally expensive. In contrast, methods that leverage the\npreviously trained model and old data are worthy of investigation, as they\ncould significantly reduce computational costs. Our evaluation framework\nquantifies the computational savings of such methods while maintaining or\nexceeding the performance of training from scratch. We identify key\noptimization aspects -- initialization, regularization, data selection, and\nhyper-parameters -- that can each contribute to reducing computational costs.\nFor each aspect, we propose effective first-step methods that already yield\nsubstantial computational savings. By combining these methods, we achieve up to\n2.7x reductions in computation time across various computer vision tasks,\nhighlighting the potential for further advancements in this area.",
    "pdf_url": "http://arxiv.org/pdf/2502.21147v1",
    "published": "2025-02-28",
    "source": "arxiv",
    "id": "2502.21147v1",
    "categories": [
      "cs.LG",
      "cs.CV"
    ]
  },
  {
    "title": "Variational Bayesian Pseudo-Coreset",
    "authors": [
      "Hyungi Lee",
      "Seungyoo Lee",
      "Juho Lee"
    ],
    "abstract": "The success of deep learning requires large datasets and extensive training,\nwhich can create significant computational challenges. To address these\nchallenges, pseudo-coresets, small learnable datasets that mimic the entire\ndata, have been proposed. Bayesian Neural Networks, which offer predictive\nuncertainty and probabilistic interpretation for deep neural networks, also\nface issues with large-scale datasets due to their high-dimensional parameter\nspace. Prior works on Bayesian Pseudo-Coresets (BPC) attempt to reduce the\ncomputational load for computing weight posterior distribution by a small\nnumber of pseudo-coresets but suffer from memory inefficiency during BPC\ntraining and sub-optimal results. To overcome these limitations, we propose\nVariational Bayesian Pseudo-Coreset (VBPC), a novel approach that utilizes\nvariational inference to efficiently approximate the posterior distribution,\nreducing memory usage and computational costs while improving performance\nacross benchmark datasets.",
    "pdf_url": "http://arxiv.org/pdf/2502.21143v1",
    "published": "2025-02-28",
    "source": "arxiv",
    "id": "2502.21143v1",
    "categories": [
      "cs.LG"
    ]
  },
  {
    "title": "Multimodal Dreaming: A Global Workspace Approach to World Model-Based Reinforcement Learning",
    "authors": [
      "Léopold Maytié",
      "Roland Bertin Johannet",
      "Rufin VanRullen"
    ],
    "abstract": "Humans leverage rich internal models of the world to reason about the future,\nimagine counterfactuals, and adapt flexibly to new situations. In Reinforcement\nLearning (RL), world models aim to capture how the environment evolves in\nresponse to the agent's actions, facilitating planning and generalization.\nHowever, typical world models directly operate on the environment variables\n(e.g. pixels, physical attributes), which can make their training slow and\ncumbersome; instead, it may be advantageous to rely on high-level latent\ndimensions that capture relevant multimodal variables. Global Workspace (GW)\nTheory offers a cognitive framework for multimodal integration and information\nbroadcasting in the brain, and recent studies have begun to introduce efficient\ndeep learning implementations of GW. Here, we evaluate the capabilities of an\nRL system combining GW with a world model. We compare our GW-Dreamer with\nvarious versions of the standard PPO and the original Dreamer algorithms. We\nshow that performing the dreaming process (i.e., mental simulation) inside the\nGW latent space allows for training with fewer environment steps. As an\nadditional emergent property, the resulting model (but not its comparison\nbaselines) displays strong robustness to the absence of one of its observation\nmodalities (images or simulation attributes). We conclude that the combination\nof GW with World Models holds great potential for improving decision-making in\nRL agents.",
    "pdf_url": "http://arxiv.org/pdf/2502.21142v1",
    "published": "2025-02-28",
    "source": "arxiv",
    "id": "2502.21142v1",
    "categories": [
      "cs.AI",
      "cs.LG",
      "q-bio.NC"
    ]
  },
  {
    "title": "Predicting clinical outcomes from patient care pathways represented with temporal knowledge graphs",
    "authors": [
      "Jong Ho Jhee",
      "Alberto Megina",
      "Pacôme Constant Dit Beaufils",
      "Matilde Karakachoff",
      "Richard Redon",
      "Alban Gaignard",
      "Adrien Coulet"
    ],
    "abstract": "Background: With the increasing availability of healthcare data, predictive\nmodeling finds many applications in the biomedical domain, such as the\nevaluation of the level of risk for various conditions, which in turn can guide\nclinical decision making. However, it is unclear how knowledge graph data\nrepresentations and their embedding, which are competitive in some settings,\ncould be of interest in biomedical predictive modeling. Method: We simulated\nsynthetic but realistic data of patients with intracranial aneurysm and\nexperimented on the task of predicting their clinical outcome. We compared the\nperformance of various classification approaches on tabular data versus a\ngraph-based representation of the same data. Next, we investigated how the\nadopted schema for representing first individual data and second temporal data\nimpacts predictive performances. Results: Our study illustrates that in our\ncase, a graph representation and Graph Convolutional Network (GCN) embeddings\nreach the best performance for a predictive task from observational data. We\nemphasize the importance of the adopted schema and of the consideration of\nliteral values in the representation of individual data. Our study also\nmoderates the relative impact of various time encoding on GCN performance.",
    "pdf_url": "http://arxiv.org/pdf/2502.21138v1",
    "published": "2025-02-28",
    "source": "arxiv",
    "id": "2502.21138v1",
    "categories": [
      "cs.LG",
      "cs.AI"
    ]
  },
  {
    "title": "Dynamically Local-Enhancement Planner for Large-Scale Autonomous Driving",
    "authors": [
      "Nanshan Deng",
      "Weitao Zhou",
      "Bo Zhang",
      "Junze Wen",
      "Kun Jiang",
      "Zhong Cao",
      "Diange Yang"
    ],
    "abstract": "Current autonomous vehicles operate primarily within limited regions, but\nthere is increasing demand for broader applications. However, as models scale,\ntheir limited capacity becomes a significant challenge for adapting to novel\nscenarios. It is increasingly difficult to improve models for new situations\nusing a single monolithic model. To address this issue, we introduce the\nconcept of dynamically enhancing a basic driving planner with local driving\ndata, without permanently modifying the planner itself. This approach, termed\nthe Dynamically Local-Enhancement (DLE) Planner, aims to improve the\nscalability of autonomous driving systems without significantly expanding the\nplanner's size. Our approach introduces a position-varying Markov Decision\nProcess formulation coupled with a graph neural network that extracts\nregion-specific driving features from local observation data. The learned\nfeatures describe the local behavior of the surrounding objects, which is then\nleveraged to enhance a basic reinforcement learning-based policy. We evaluated\nour approach in multiple scenarios and compared it with a one-for-all driving\nmodel. The results show that our method outperforms the baseline policy in both\nsafety (collision rate) and average reward, while maintaining a lighter scale.\nThis approach has the potential to benefit large-scale autonomous vehicles\nwithout the need for largely expanding on-device driving models.",
    "pdf_url": "http://arxiv.org/pdf/2502.21134v1",
    "published": "2025-02-28",
    "source": "arxiv",
    "id": "2502.21134v1",
    "categories": [
      "cs.RO",
      "cs.AI"
    ]
  },
  {
    "title": "Fast and Accurate Gigapixel Pathological Image Classification with Hierarchical Distillation Multi-Instance Learning",
    "authors": [
      "Jiuyang Dong",
      "Junjun Jiang",
      "Kui Jiang",
      "Jiahan Li",
      "Yongbing Zhang"
    ],
    "abstract": "Although multi-instance learning (MIL) has succeeded in pathological image\nclassification, it faces the challenge of high inference costs due to\nprocessing numerous patches from gigapixel whole slide images (WSIs). To\naddress this, we propose HDMIL, a hierarchical distillation multi-instance\nlearning framework that achieves fast and accurate classification by\neliminating irrelevant patches. HDMIL consists of two key components: the\ndynamic multi-instance network (DMIN) and the lightweight instance\npre-screening network (LIPN). DMIN operates on high-resolution WSIs, while LIPN\noperates on the corresponding low-resolution counterparts. During training,\nDMIN are trained for WSI classification while generating attention-score-based\nmasks that indicate irrelevant patches. These masks then guide the training of\nLIPN to predict the relevance of each low-resolution patch. During testing,\nLIPN first determines the useful regions within low-resolution WSIs, which\nindirectly enables us to eliminate irrelevant regions in high-resolution WSIs,\nthereby reducing inference time without causing performance degradation. In\naddition, we further design the first Chebyshev-polynomials-based\nKolmogorov-Arnold classifier in computational pathology, which enhances the\nperformance of HDMIL through learnable activation layers. Extensive experiments\non three public datasets demonstrate that HDMIL outperforms previous\nstate-of-the-art methods, e.g., achieving improvements of 3.13% in AUC while\nreducing inference time by 28.6% on the Camelyon16 dataset.",
    "pdf_url": "http://arxiv.org/pdf/2502.21130v2",
    "published": "2025-02-28",
    "source": "arxiv",
    "id": "2502.21130v2",
    "categories": [
      "cs.CV"
    ]
  },
  {
    "title": "Microscopic Propagator Imaging (MPI) with Diffusion MRI",
    "authors": [
      "Tommaso Zajac",
      "Gloria Menegaz",
      "Marco Pizzolato"
    ],
    "abstract": "We propose Microscopic Propagator Imaging (MPI) as a novel method to retrieve\nthe indices of the microscopic propagator which is the probability density\nfunction of water displacements due to diffusion within the nervous tissue\nmicrostructures. Unlike the Ensemble Average Propagator indices or the\nDiffusion Tensor Imaging metrics, MPI indices are independent from the\nmesoscopic organization of the tissue such as the presence of multiple axonal\nbundle directions and orientation dispersion. As a consequence, MPI indices are\nmore specific to the volumes, sizes, and types of microstructures, like axons\nand cells, that are present in the tissue. Thus, changes in MPI indices can be\nmore directly linked to alterations in the presence and integrity of\nmicrostructures themselves. The methodology behind MPI is rooted on zonal\nmodeling of spherical harmonics, signal simulation, and machine learning\nregression, and is demonstrated on both synthetic and Human Diffusion MRI data.",
    "pdf_url": "http://arxiv.org/pdf/2502.21129v1",
    "published": "2025-02-28",
    "source": "arxiv",
    "id": "2502.21129v1",
    "categories": [
      "q-bio.NC",
      "cs.LG",
      "physics.bio-ph",
      "physics.med-ph",
      "I.6.5"
    ]
  },
  {
    "title": "CuPID: Leveraging Masked Single-Lead ECG Modelling for Enhancing the Representations",
    "authors": [
      "Adtian Atienza",
      "Gouthamaan Manimaran",
      "Jakob E. Bardram",
      "Sadasivan Puthusserypady"
    ],
    "abstract": "Wearable sensing devices, such as Electrocardiogram (ECG) heart-rate\nmonitors, will play a crucial role in the future of digital health. This\ncontinuous monitoring leads to massive unlabeled data, incentivizing the\ndevelopment of unsupervised learning frameworks. While Masked Data Modelling\n(MDM) techniques have enjoyed wide use, their direct application to single-lead\nECG data is suboptimal due to the decoder's difficulty handling irregular\nheartbeat intervals when no contextual information is provided. In this paper,\nwe present Cueing the Predictor Increments the Detailing (CuPID), a novel MDM\nmethod tailored to single-lead ECGs. CuPID enhances existing MDM techniques by\ncueing spectrogram-derived context to the decoder, thus incentivizing the\nencoder to produce more detailed representations. This has a significant impact\non the encoder's performance across a wide range of different configurations,\nleading CuPID to outperform state-of-the-art methods in a variety of downstream\ntasks.",
    "pdf_url": "http://arxiv.org/pdf/2502.21127v1",
    "published": "2025-02-28",
    "source": "arxiv",
    "id": "2502.21127v1",
    "categories": [
      "cs.LG"
    ]
  },
  {
    "title": "Causality Is Key to Understand and Balance Multiple Goals in Trustworthy ML and Foundation Models",
    "authors": [
      "Ruta Binkyte",
      "Ivaxi Sheth",
      "Zhijing Jin",
      "Mohammad Havaei",
      "Bernhard Schölkopf",
      "Mario Fritz"
    ],
    "abstract": "Ensuring trustworthiness in machine learning (ML) systems is crucial as they\nbecome increasingly embedded in high-stakes domains. This paper advocates for\nintegrating causal methods into machine learning to navigate the trade-offs\namong key principles of trustworthy ML, including fairness, privacy,\nrobustness, accuracy, and explainability. While these objectives should ideally\nbe satisfied simultaneously, they are often addressed in isolation, leading to\nconflicts and suboptimal solutions. Drawing on existing applications of\ncausality in ML that successfully align goals such as fairness and accuracy or\nprivacy and robustness, this paper argues that a causal approach is essential\nfor balancing multiple competing objectives in both trustworthy ML and\nfoundation models. Beyond highlighting these trade-offs, we examine how\ncausality can be practically integrated into ML and foundation models, offering\nsolutions to enhance their reliability and interpretability. Finally, we\ndiscuss the challenges, limitations, and opportunities in adopting causal\nframeworks, paving the way for more accountable and ethically sound AI systems.",
    "pdf_url": "http://arxiv.org/pdf/2502.21123v2",
    "published": "2025-02-28",
    "source": "arxiv",
    "id": "2502.21123v2",
    "categories": [
      "cs.LG",
      "cs.AI"
    ]
  },
  {
    "title": "Distributed Data Access in Industrial Edge Networks",
    "authors": [
      "Theofanis P. Raptis",
      "Andrea Passarella",
      "Marco Conti"
    ],
    "abstract": "Wireless edge networks in smart industrial environments increasingly operate\nusing advanced sensors and autonomous machines interacting with each other and\ngenerating huge amounts of data. Those huge amounts of data are bound to make\ndata management (e.g., for processing, storing, computing) a big challenge.\nCurrent data management approaches, relying primarily on centralized data\nstorage, might not be able to cope with the scalability and real time\nrequirements of Industry 4.0 environments, while distributed solutions are\nincreasingly being explored. In this paper, we introduce the problem of\ndistributed data access in multi-hop wireless industrial edge deployments,\nwhereby a set of consumer nodes needs to access data stored in a set of data\ncache nodes, satisfying the industrial data access delay requirements and at\nthe same time maximizing the network lifetime. We prove that the introduced\nproblem is computationally intractable and, after formulating the objective\nfunction, we design a two-step algorithm in order to address it. We use an open\ntestbed with real devices for conducting an experimental investigation on the\nperformance of the algorithm. Then, we provide two online improvements, so that\nthe data distribution can dynamically change before the first node in the\nnetwork runs out of energy. We compare the performance of the methods via\nsimulations for different numbers of network nodes and data consumers, and we\nshow significant lifetime prolongation and increased energy efficiency when\nemploying the method which is using only decentralized low-power wireless\ncommunication instead of the method which is using also centralized local area\nwireless communication.",
    "pdf_url": "http://arxiv.org/pdf/2502.21117v1",
    "published": "2025-02-28",
    "source": "arxiv",
    "id": "2502.21117v1",
    "categories": [
      "cs.NI"
    ]
  },
  {
    "title": "The two filter formula reconsidered: Smoothing in partially observed Gauss--Markov models without information parametrization",
    "authors": [
      "Filip Tronarp"
    ],
    "abstract": "In this article, the two filter formula is re-examined in the setting of\npartially observed Gauss--Markov models. It is traditionally formulated as a\nfilter running backward in time, where the Gaussian density is parametrized in\n``information form''. However, the quantity in the backward recursion is\nstrictly speaking not a distribution, but a likelihood. Taking this observation\nseriously, a recursion over log-quadratic likelihoods is formulated instead,\nwhich obviates the need for ``information'' parametrization. In particular, it\ngreatly simplifies the square-root formulation of the algorithm. Furthermore,\nformulae are given for producing the forward Markov representation of the a\nposteriori distribution over paths from the proposed likelihood representation.",
    "pdf_url": "http://arxiv.org/pdf/2502.21116v1",
    "published": "2025-02-28",
    "source": "arxiv",
    "id": "2502.21116v1",
    "categories": [
      "stat.ME",
      "cs.LG"
    ]
  },
  {
    "title": "Software development projects as a way for multidisciplinary soft and future skills education",
    "authors": [
      "Krzysztof Podlaski",
      "Michal Beczkowski",
      "Katharina Simbeck",
      "Katrin Dziergwa",
      "Derek O'Reilly",
      "Shane Dowdall",
      "Joao Monteiro",
      "Catarina Oliveira Lucas",
      "Johanna Hautamaki",
      "Heikki Ahonen",
      "Hiram Bollaert",
      "Philippe Possemiers",
      "Zofia Stawska"
    ],
    "abstract": "Soft and future skills are in high demand in the modern job market. These\nskills are required for both technical and non-technical people. It is\ndifficult to teach these competencies in a classical academic environment.\n  The paper presents a possible approach to teaching in soft and future skills\nin a short, intensive joint project. In our case, it is a project within the\nErasmus+ framework, but it can be organized in many different frameworks.\n  In the project we use problem based learning, active learning and group-work\nteaching methodologies. Moreover, the approach put high emphasizes diversity.\nWe arrange a set of multidisciplinary students in groups. Each group is working\non software development tasks. This type of projects demand diversity, and only\na part of the team needs technical skills. In our case less than half of\nparticipants had computer science background. Additionally, software\ndevelopment projects are usually interesting for non-technical students.\n  The multicultural, multidisciplinary and international aspects are very\nimportant in a modern global working environment. On the other hand, short time\nof the project and its intensity allow to simulate stressful situations in a\nreal word tasks. The effects of the project on the required competencies are\nmeasured using the KYSS method.\n  The results prove that the presented method increased participants soft\nskills in communication, cooperation, digital skills and self reflection.",
    "pdf_url": "http://arxiv.org/pdf/2502.21114v1",
    "published": "2025-02-28",
    "source": "arxiv",
    "id": "2502.21114v1",
    "categories": [
      "cs.CY"
    ]
  },
  {
    "title": "Rare event modeling with self-regularized normalizing flows: what can we learn from a single failure?",
    "authors": [
      "Charles Dawson",
      "Van Tran",
      "Max Z. Li",
      "Chuchu Fan"
    ],
    "abstract": "Increased deployment of autonomous systems in fields like transportation and\nrobotics have seen a corresponding increase in safety-critical failures. These\nfailures can be difficult to model and debug due to the relative lack of data:\ncompared to tens of thousands of examples from normal operations, we may have\nonly seconds of data leading up to the failure. This scarcity makes it\nchallenging to train generative models of rare failure events, as existing\nmethods risk either overfitting to noise in the limited failure dataset or\nunderfitting due to an overly strong prior. We address this challenge with\nCalNF, or calibrated normalizing flows, a self-regularized framework for\nposterior learning from limited data. CalNF achieves state-of-the-art\nperformance on data-limited failure modeling and inverse problems and enables a\nfirst-of-a-kind case study into the root causes of the 2022 Southwest Airlines\nscheduling crisis.",
    "pdf_url": "http://arxiv.org/pdf/2502.21110v1",
    "published": "2025-02-28",
    "source": "arxiv",
    "id": "2502.21110v1",
    "categories": [
      "cs.LG",
      "stat.ML"
    ]
  },
  {
    "title": "\"No negatives needed\": weakly-supervised regression for interpretable tumor detection in whole-slide histopathology images",
    "authors": [
      "Marina D'Amato",
      "Jeroen van der Laak",
      "Francesco Ciompi"
    ],
    "abstract": "Accurate tumor detection in digital pathology whole-slide images (WSIs) is\ncrucial for cancer diagnosis and treatment planning. Multiple Instance Learning\n(MIL) has emerged as a widely used approach for weakly-supervised tumor\ndetection with large-scale data without the need for manual annotations.\nHowever, traditional MIL methods often depend on classification tasks that\nrequire tumor-free cases as negative examples, which are challenging to obtain\nin real-world clinical workflows, especially for surgical resection specimens.\nWe address this limitation by reformulating tumor detection as a regression\ntask, estimating tumor percentages from WSIs, a clinically available target\nacross multiple cancer types. In this paper, we provide an analysis of the\nproposed weakly-supervised regression framework by applying it to multiple\norgans, specimen types and clinical scenarios. We characterize the robustness\nof our framework to tumor percentage as a noisy regression target, and\nintroduce a novel concept of amplification technique to improve tumor detection\nsensitivity when learning from small tumor regions. Finally, we provide\ninterpretable insights into the model's predictions by analyzing visual\nattention and logit maps. Our code is available at\nhttps://github.com/DIAGNijmegen/tumor-percentage-mil-regression.",
    "pdf_url": "http://arxiv.org/pdf/2502.21109v1",
    "published": "2025-02-28",
    "source": "arxiv",
    "id": "2502.21109v1",
    "categories": [
      "eess.IV",
      "cs.CV"
    ]
  },
  {
    "title": "Parameter-Varying Feedforward Control: A Kernel-Based Learning Approach",
    "authors": [
      "Max van Haren",
      "Lennart Blanken",
      "Tom Oomen"
    ],
    "abstract": "The increasing demands for high accuracy in mechatronic systems necessitate\nthe incorporation of parameter variations in feedforward control. The aim of\nthis paper is to develop a data-driven approach for direct learning of\nparameter-varying feedforward control to increase tracking performance. The\ndeveloped approach is based on kernel-regularized function estimation in\nconjunction with iterative learning to directly learn parameter-varying\nfeedforward control from data. This approach enables high tracking performance\nfor feedforward control of linear parameter-varying dynamics, providing\nflexibility to varying reference tasks. The developed framework is validated on\na benchmark industrial experimental setup featuring a belt-driven carriage.",
    "pdf_url": "http://arxiv.org/pdf/2502.21105v1",
    "published": "2025-02-28",
    "source": "arxiv",
    "id": "2502.21105v1",
    "categories": [
      "eess.SY",
      "cs.SY"
    ]
  },
  {
    "title": "Jointly Assigning Processes to Machines and Generating Plans for Autonomous Mobile Robots in a Smart Factory",
    "authors": [
      "Christopher Leet",
      "Aidan Sciortino",
      "Sven Koenig"
    ],
    "abstract": "A modern smart factory runs a manufacturing procedure using a collection of\nprogrammable machines. Typically, materials are ferried between these machines\nusing a team of mobile robots. To embed a manufacturing procedure in a smart\nfactory, a factory operator must a) assign its processes to the smart factory's\nmachines and b) determine how agents should carry materials between machines. A\ngood embedding maximizes the smart factory's throughput; the rate at which it\noutputs products. Existing smart factory management systems solve the\naforementioned problems sequentially, limiting the throughput that they can\nachieve. In this paper we introduce ACES, the Anytime Cyclic Embedding Solver,\nthe first solver which jointly optimizes the assignment of processes to\nmachines and the assignment of paths to agents. We evaluate ACES and show that\nit can scale to real industrial scenarios.",
    "pdf_url": "http://arxiv.org/pdf/2502.21101v1",
    "published": "2025-02-28",
    "source": "arxiv",
    "id": "2502.21101v1",
    "categories": [
      "cs.RO",
      "math.OC"
    ]
  },
  {
    "title": "AuthSim: Towards Authentic and Effective Safety-critical Scenario Generation for Autonomous Driving Tests",
    "authors": [
      "Yukuan Yang",
      "Xucheng Lu",
      "Zhili Zhang",
      "Zepeng Wu",
      "Guoqi Li",
      "Lingzhong Meng",
      "Yunzhi Xue"
    ],
    "abstract": "Generating adversarial safety-critical scenarios is a pivotal method for\ntesting autonomous driving systems, as it identifies potential weaknesses and\nenhances system robustness and reliability. However, existing approaches\npredominantly emphasize unrestricted collision scenarios, prompting non-player\ncharacter (NPC) vehicles to attack the ego vehicle indiscriminately. These\nworks overlook these scenarios' authenticity, rationality, and relevance,\nresulting in numerous extreme, contrived, and largely unrealistic collision\nevents involving aggressive NPC vehicles. To rectify this issue, we propose a\nthree-layer relative safety region model, which partitions the area based on\ndanger levels and increases the likelihood of NPC vehicles entering relative\nboundary regions. This model directs NPC vehicles to engage in adversarial\nactions within relatively safe boundary regions, thereby augmenting the\nscenarios' authenticity. We introduce AuthSim, a comprehensive platform for\ngenerating authentic and effective safety-critical scenarios by integrating the\nthree-layer relative safety region model with reinforcement learning. To our\nknowledge, this is the first attempt to address the authenticity and\neffectiveness of autonomous driving system test scenarios comprehensively.\nExtensive experiments demonstrate that AuthSim outperforms existing methods in\ngenerating effective safety-critical scenarios. Notably, AuthSim achieves a\n5.25% improvement in average cut-in distance and a 27.12% enhancement in\naverage collision interval time, while maintaining higher efficiency in\ngenerating effective safety-critical scenarios compared to existing methods.\nThis underscores its significant advantage in producing authentic scenarios\nover current methodologies.",
    "pdf_url": "http://arxiv.org/pdf/2502.21100v1",
    "published": "2025-02-28",
    "source": "arxiv",
    "id": "2502.21100v1",
    "categories": [
      "cs.RO",
      "cs.AI"
    ]
  },
  {
    "title": "Adaptive Accelerated Proximal Gradient Methods with Variance Reduction for Composite Nonconvex Finite-Sum Minimization",
    "authors": [
      "Ganzhao Yuan"
    ],
    "abstract": "This paper proposes {\\sf AAPG-SPIDER}, an Adaptive Accelerated Proximal\nGradient (AAPG) method with variance reduction for minimizing composite\nnonconvex finite-sum functions. It integrates three acceleration techniques:\nadaptive stepsizes, Nesterov's extrapolation, and the recursive stochastic\npath-integrated estimator SPIDER. While targeting stochastic finite-sum\nproblems, {\\sf AAPG-SPIDER} simplifies to {\\sf AAPG} in the full-batch,\nnon-stochastic setting, which is also of independent interest. To our\nknowledge, {\\sf AAPG-SPIDER} and {\\sf AAPG} are the first learning-rate-free\nmethods to achieve optimal iteration complexity for this class of\n\\textit{composite} minimization problems. Specifically, {\\sf AAPG} achieves the\noptimal iteration complexity of $\\mathcal{O}(N \\epsilon^{-2})$, while {\\sf\nAAPG-SPIDER} achieves $\\mathcal{O}(N + \\sqrt{N} \\epsilon^{-2})$ for finding\n$\\epsilon$-approximate stationary points, where $N$ is the number of component\nfunctions. Under the Kurdyka-Lojasiewicz (KL) assumption, we establish\nnon-ergodic convergence rates for both methods. Preliminary experiments on\nsparse phase retrieval and linear eigenvalue problems demonstrate the superior\nperformance of {\\sf AAPG-SPIDER} and {\\sf AAPG} compared to existing methods.",
    "pdf_url": "http://arxiv.org/pdf/2502.21099v1",
    "published": "2025-02-28",
    "source": "arxiv",
    "id": "2502.21099v1",
    "categories": [
      "math.OC",
      "cs.CV",
      "cs.NA",
      "math.NA"
    ]
  },
  {
    "title": "Deep learning-based filtering of cross-spectral matrices using generative adversarial networks",
    "authors": [
      "Christof Puhle"
    ],
    "abstract": "In this paper, we present a deep-learning method to filter out effects such\nas ambient noise, reflections, or source directivity from microphone array data\nrepresented as cross-spectral matrices. Specifically, we focus on a generative\nadversarial network (GAN) architecture designed to transform fixed-size\ncross-spectral matrices. Theses models were trained using sound pressure\nsimulations of varying complexity developed for this purpose. Based on the\nresults from applying these methods in a hyperparameter optimization of an\nauto-encoding task, we trained the optimized model to perform five distinct\ntransformation tasks derived from different complexities inherent in our sound\npressure simulations.",
    "pdf_url": "http://arxiv.org/pdf/2502.21097v1",
    "published": "2025-02-28",
    "source": "arxiv",
    "id": "2502.21097v1",
    "categories": [
      "cs.SD",
      "eess.AS",
      "eess.SP"
    ]
  },
  {
    "title": "Are foundation models useful feature extractors for electroencephalography analysis?",
    "authors": [
      "Özgün Turgut",
      "Felix S. Bott",
      "Markus Ploner",
      "Daniel Rueckert"
    ],
    "abstract": "The success of foundation models in natural language processing and computer\nvision has motivated similar approaches for general time series analysis. While\nthese models are effective for a variety of tasks, their applicability in\nmedical domains with limited data remains largely unexplored. To address this,\nwe investigate the effectiveness of foundation models in medical time series\nanalysis involving electroencephalography (EEG). Through extensive experiments\non tasks such as age prediction, seizure detection, and the classification of\nclinically relevant EEG events, we compare their diagnostic accuracy with that\nof specialised EEG models. Our analysis shows that foundation models extract\nmeaningful EEG features, outperform specialised models even without domain\nadaptation, and localise task-specific biomarkers. Moreover, we demonstrate\nthat diagnostic accuracy is substantially influenced by architectural choices\nsuch as context length. Overall, our study reveals that foundation models with\ngeneral time series understanding eliminate the dependency on large\ndomain-specific datasets, making them valuable tools for clinical practice.",
    "pdf_url": "http://arxiv.org/pdf/2502.21086v1",
    "published": "2025-02-28",
    "source": "arxiv",
    "id": "2502.21086v1",
    "categories": [
      "cs.AI",
      "cs.LG"
    ]
  },
  {
    "title": "Enhancing deep neural networks through complex-valued representations and Kuramoto synchronization dynamics",
    "authors": [
      "Sabine Muzellec",
      "Andrea Alamia",
      "Thomas Serre",
      "Rufin VanRullen"
    ],
    "abstract": "Neural synchrony is hypothesized to play a crucial role in how the brain\norganizes visual scenes into structured representations, enabling the robust\nencoding of multiple objects within a scene. However, current deep learning\nmodels often struggle with object binding, limiting their ability to represent\nmultiple objects effectively. Inspired by neuroscience, we investigate whether\nsynchrony-based mechanisms can enhance object encoding in artificial models\ntrained for visual categorization. Specifically, we combine complex-valued\nrepresentations with Kuramoto dynamics to promote phase alignment, facilitating\nthe grouping of features belonging to the same object. We evaluate two\narchitectures employing synchrony: a feedforward model and a recurrent model\nwith feedback connections to refine phase synchronization using top-down\ninformation. Both models outperform their real-valued counterparts and\ncomplex-valued models without Kuramoto synchronization on tasks involving\nmulti-object images, such as overlapping handwritten digits, noisy inputs, and\nout-of-distribution transformations. Our findings highlight the potential of\nsynchrony-driven mechanisms to enhance deep learning models, improving their\nperformance, robustness, and generalization in complex visual categorization\ntasks.",
    "pdf_url": "http://arxiv.org/pdf/2502.21077v1",
    "published": "2025-02-28",
    "source": "arxiv",
    "id": "2502.21077v1",
    "categories": [
      "cs.CV",
      "cs.AI",
      "nlin.AO",
      "q-bio.NC"
    ]
  },
  {
    "title": "Spatial Reasoning with Denoising Models",
    "authors": [
      "Christopher Wewer",
      "Bart Pogodzinski",
      "Bernt Schiele",
      "Jan Eric Lenssen"
    ],
    "abstract": "We introduce Spatial Reasoning Models (SRMs), a framework to perform\nreasoning over sets of continuous variables via denoising generative models.\nSRMs infer continuous representations on a set of unobserved variables, given\nobservations on observed variables. Current generative models on spatial\ndomains, such as diffusion and flow matching models, often collapse to\nhallucination in case of complex distributions. To measure this, we introduce a\nset of benchmark tasks that test the quality of complex reasoning in generative\nmodels and can quantify hallucination. The SRM framework allows to report key\nfindings about importance of sequentialization in generation, the associated\norder, as well as the sampling strategies during training. It demonstrates, for\nthe first time, that order of generation can successfully be predicted by the\ndenoising network itself. Using these findings, we can increase the accuracy of\nspecific reasoning tasks from <1% to >50%.",
    "pdf_url": "http://arxiv.org/pdf/2502.21075v1",
    "published": "2025-02-28",
    "source": "arxiv",
    "id": "2502.21075v1",
    "categories": [
      "cs.CV",
      "cs.LG"
    ]
  },
  {
    "title": "CODI: Compressing Chain-of-Thought into Continuous Space via Self-Distillation",
    "authors": [
      "Zhenyi Shen",
      "Hanqi Yan",
      "Linhai Zhang",
      "Zhanghao Hu",
      "Yali Du",
      "Yulan He"
    ],
    "abstract": "Chain-of-Thought (CoT) enhances Large Language Models (LLMs) by enabling\nstep-by-step reasoning in natural language. However, the language space may be\nsuboptimal for reasoning. While implicit CoT methods attempt to enable\nreasoning without explicit CoT tokens, they have consistently lagged behind\nexplicit CoT method in task performance. We propose CODI (Continuous\nChain-of-Thought via Self-Distillation), a novel framework that distills CoT\ninto a continuous space, where a shared model acts as both teacher and student,\njointly learning explicit and implicit CoT while aligning their hidden\nactivation on the token generating the final answer. CODI is the first implicit\nCoT method to match explicit CoT's performance on GSM8k while achieving 3.1x\ncompression, surpassing the previous state-of-the-art by 28.2% in accuracy.\nFurthermore, CODI demonstrates scalability, robustness, and generalizability to\nmore complex CoT datasets. Additionally, CODI retains interpretability by\ndecoding its continuous thoughts, making its reasoning process transparent. Our\nfindings establish implicit CoT as not only a more efficient but a powerful\nalternative to explicit CoT.",
    "pdf_url": "http://arxiv.org/pdf/2502.21074v1",
    "published": "2025-02-28",
    "source": "arxiv",
    "id": "2502.21074v1",
    "categories": [
      "cs.CL"
    ]
  },
  {
    "title": "Efficient Transformer-based Decoder for Varshamov-Tenengolts Codes",
    "authors": [
      "Yali Wei",
      "Alan J. X. Guo",
      "Zihui Yan",
      "Yufan Dai"
    ],
    "abstract": "In recent years, the rise of DNA data storage technology has brought\nsignificant attention to the challenge of correcting insertion, deletion, and\nsubstitution (IDS) errors. Among various coding methods for IDS correction,\nVarshamov-Tenengolts (VT) codes, primarily designed for single-error\ncorrection, have emerged as a central research focus. While existing decoding\nmethods achieve high accuracy in correcting a single error, they often fail to\ncorrect multiple IDS errors. In this work, we observe that VT codes retain some\ncapability for addressing multiple errors by introducing a transformer-based VT\ndecoder (TVTD) along with symbol- and statistic-based codeword embedding.\nExperimental results demonstrate that the proposed TVTD achieves perfect\ncorrection of a single error. Furthermore, when decoding multiple errors across\nvarious codeword lengths, the bit error rate and frame error rate are\nsignificantly improved compared to existing hard decision and soft-in soft-out\nalgorithms. Additionally, through model architecture optimization, the proposed\nmethod reduces time consumption by an order of magnitude compared to other soft\ndecoders.",
    "pdf_url": "http://arxiv.org/pdf/2502.21060v1",
    "published": "2025-02-28",
    "source": "arxiv",
    "id": "2502.21060v1",
    "categories": [
      "cs.LG",
      "cs.IT",
      "math.IT"
    ]
  },
  {
    "title": "FC-Attack: Jailbreaking Large Vision-Language Models via Auto-Generated Flowcharts",
    "authors": [
      "Ziyi Zhang",
      "Zhen Sun",
      "Zongmin Zhang",
      "Jihui Guo",
      "Xinlei He"
    ],
    "abstract": "Large Vision-Language Models (LVLMs) have become powerful and widely adopted\nin some practical applications. However, recent research has revealed their\nvulnerability to multimodal jailbreak attacks, whereby the model can be induced\nto generate harmful content, leading to safety risks. Although most LVLMs have\nundergone safety alignment, recent research shows that the visual modality is\nstill vulnerable to jailbreak attacks. In our work, we discover that by using\nflowcharts with partially harmful information, LVLMs can be induced to provide\nadditional harmful details. Based on this, we propose a jailbreak attack method\nbased on auto-generated flowcharts, FC-Attack. Specifically, FC-Attack first\nfine-tunes a pre-trained LLM to create a step-description generator based on\nbenign datasets. The generator is then used to produce step descriptions\ncorresponding to a harmful query, which are transformed into flowcharts in 3\ndifferent shapes (vertical, horizontal, and S-shaped) as visual prompts. These\nflowcharts are then combined with a benign textual prompt to execute a\njailbreak attack on LVLMs. Our evaluations using the Advbench dataset show that\nFC-Attack achieves over 90% attack success rates on Gemini-1.5, Llaval-Next,\nQwen2-VL, and InternVL-2.5 models, outperforming existing LVLM jailbreak\nmethods. Additionally, we investigate factors affecting the attack performance,\nincluding the number of steps and the font styles in the flowcharts. Our\nevaluation shows that FC-Attack can improve the jailbreak performance from 4%\nto 28% in Claude-3.5 by changing the font style. To mitigate the attack, we\nexplore several defenses and find that AdaShield can largely reduce the\njailbreak performance but with the cost of utility drop.",
    "pdf_url": "http://arxiv.org/pdf/2502.21059v1",
    "published": "2025-02-28",
    "source": "arxiv",
    "id": "2502.21059v1",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.CR",
      "cs.LG"
    ]
  },
  {
    "title": "Robust Deterministic Policy Gradient for Disturbance Attenuation and Its Application to Quadrotor Control",
    "authors": [
      "Taeho Lee",
      "Donghwan Lee"
    ],
    "abstract": "Practical control systems pose significant challenges in identifying optimal\ncontrol policies due to uncertainties in the system model and external\ndisturbances. While $H_\\infty$ control techniques are commonly used to design\nrobust controllers that mitigate the effects of disturbances, these methods\noften require complex and computationally intensive calculations. To address\nthis issue, this paper proposes a reinforcement learning algorithm called\nRobust Deterministic Policy Gradient (RDPG), which formulates the $H_\\infty$\ncontrol problem as a two-player zero-sum dynamic game. In this formulation, one\nplayer (the user) aims to minimize the cost, while the other player (the\nadversary) seeks to maximize it. We then employ deterministic policy gradient\n(DPG) and its deep reinforcement learning counterpart to train a robust control\npolicy with effective disturbance attenuation. In particular, for practical\nimplementation, we introduce an algorithm called robust deep deterministic\npolicy gradient (RDDPG), which employs a deep neural network architecture and\nintegrates techniques from the twin-delayed deep deterministic policy gradient\n(TD3) to enhance stability and learning efficiency. To evaluate the proposed\nalgorithm, we implement it on an unmanned aerial vehicle (UAV) tasked with\nfollowing a predefined path in a disturbance-prone environment. The\nexperimental results demonstrate that the proposed method outperforms other\ncontrol approaches in terms of robustness against disturbances, enabling\nprecise real-time tracking of moving targets even under severe disturbance\nconditions.",
    "pdf_url": "http://arxiv.org/pdf/2502.21057v1",
    "published": "2025-02-28",
    "source": "arxiv",
    "id": "2502.21057v1",
    "categories": [
      "cs.RO",
      "cs.AI"
    ]
  },
  {
    "title": "Quantum-aware Transformer model for state classification",
    "authors": [
      "Przemysław Sekuła",
      "Michał Romaszewski",
      "Przemysław Głomb",
      "Michał Cholewa",
      "Łukasz Pawela"
    ],
    "abstract": "Entanglement is a fundamental feature of quantum mechanics, playing a crucial\nrole in quantum information processing. However, classifying entangled states,\nparticularly in the mixed-state regime, remains a challenging problem,\nespecially as system dimensions increase. In this work, we focus on bipartite\nquantum states and present a data-driven approach to entanglement\nclassification using transformer-based neural networks. Our dataset consists of\na diverse set of bipartite states, including pure separable states, Werner\nentangled states, general entangled states, and maximally entangled states. We\npretrain the transformer in an unsupervised fashion by masking elements of\nvectorized Hermitian matrix representations of quantum states, allowing the\nmodel to learn structural properties of quantum density matrices. This approach\nenables the model to generalize entanglement characteristics across different\nclasses of states. Once trained, our method achieves near-perfect\nclassification accuracy, effectively distinguishing between separable and\nentangled states. Compared to previous Machine Learning, our method\nsuccessfully adapts transformers for quantum state analysis, demonstrating\ntheir ability to systematically identify entanglement in bipartite systems.\nThese results highlight the potential of modern machine learning techniques in\nautomating entanglement detection and classification, bridging the gap between\nquantum information theory and artificial intelligence.",
    "pdf_url": "http://arxiv.org/pdf/2502.21055v1",
    "published": "2025-02-28",
    "source": "arxiv",
    "id": "2502.21055v1",
    "categories": [
      "quant-ph",
      "cs.LG",
      "81P45, 68T05",
      "I.2.6"
    ]
  },
  {
    "title": "HoloMine: A Synthetic Dataset for Buried Landmines Recognition using Microwave Holographic Imaging",
    "authors": [
      "Emanuele Vivoli",
      "Lorenzo Capineri",
      "Marco Bertini"
    ],
    "abstract": "The detection and removal of landmines is a complex and risky task that\nrequires advanced remote sensing techniques to reduce the risk for the\nprofessionals involved in this task. In this paper, we propose a novel\nsynthetic dataset for buried landmine detection to provide researchers with a\nvaluable resource to observe, measure, locate, and address issues in landmine\ndetection. The dataset consists of 41,800 microwave holographic images (2D) and\ntheir holographic inverted scans (3D) of different types of buried objects,\nincluding landmines, clutter, and pottery objects, and is collected by means of\na microwave holography sensor.\n  We evaluate the performance of several state-of-the-art deep learning models\ntrained on our synthetic dataset for various classification tasks. While the\nresults do not yield yet high performances, showing the difficulty of the\nproposed task, we believe that our dataset has significant potential to drive\nprogress in the field of landmine detection thanks to the accuracy and\nresolution obtainable using holographic radars.\n  To the best of our knowledge, our dataset is the first of its kind and will\nhelp drive further research on computer vision methods to automatize mine\ndetection, with the overall goal of reducing the risks and the costs of the\ndemining process.",
    "pdf_url": "http://arxiv.org/pdf/2502.21054v1",
    "published": "2025-02-28",
    "source": "arxiv",
    "id": "2502.21054v1",
    "categories": [
      "cs.CV",
      "eess.IV",
      "eess.SP"
    ]
  },
  {
    "title": "Detection of anomalies in cow activity using wavelet transform based features",
    "authors": [
      "Valentin Guien",
      "Violaine Antoine",
      "Romain Lardy",
      "Isabelle Veissier",
      "Luis E C Rocha"
    ],
    "abstract": "In Precision Livestock Farming, detecting deviations from optimal or baseline\nvalues - i.e. anomalies in time series - is essential to allow undertaking\ncorrective actions rapidly. Here we aim at detecting anomalies in 24h time\nseries of cow activity, with a view to detect cases of disease or oestrus.\nDeviations must be distinguished from noise which can be very high in case of\nbiological data. It is also important to detect the anomaly early, e.g. before\na farmer would notice it visually. Here, we investigate the benefit of using\nwavelet transforms to denoise data and we assess the performance of an anomaly\ndetection algorithm considering the timing of the detection. We developed\nfeatures based on the comparisons between the wavelet transforms of the mean of\nthe time series and the wavelet transforms of individual time series instances.\nWe hypothesized that these features contribute to the detection of anomalies in\nperiodic time series using a feature-based algorithm. We tested this hypothesis\nwith two datasets representing cow activity, which typically follows a daily\npattern but can deviate due to specific physiological or pathological\nconditions. We applied features derived from wavelet transform as well as\nstatistical features in an Isolation Forest algorithm. We measured the distance\nof detection between the days annotated abnormal by animal caretakers days and\nthe days predicted abnormal by the algorithm. The results show that\nwavelet-based features are among the features most contributing to anomaly\ndetection. They also show that detections are close to the annotated days, and\noften precede it. In conclusion, using wavelet transforms on time series of cow\nactivity data helps to detect anomalies related to specific cow states. The\ndetection is often obtained on days that precede the day annotated by\ncaretakers, which offer possibility to take corrective actions at an early\nstage.",
    "pdf_url": "http://arxiv.org/pdf/2502.21051v1",
    "published": "2025-02-28",
    "source": "arxiv",
    "id": "2502.21051v1",
    "categories": [
      "cs.LG",
      "cs.CE"
    ]
  },
  {
    "title": "Synthesizing Individualized Aging Brains in Health and Disease with Generative Models and Parallel Transport",
    "authors": [
      "Jingru Fu",
      "Yuqi Zheng",
      "Neel Dey",
      "Daniel Ferreira",
      "Rodrigo Moreno"
    ],
    "abstract": "Simulating prospective magnetic resonance imaging (MRI) scans from a given\nindividual brain image is challenging, as it requires accounting for canonical\nchanges in aging and/or disease progression while also considering the\nindividual brain's current status and unique characteristics. While current\ndeep generative models can produce high-resolution anatomically accurate\ntemplates for population-wide studies, their ability to predict future aging\ntrajectories for individuals remains limited, particularly in capturing\nsubject-specific neuroanatomical variations over time. In this study, we\nintroduce Individualized Brain Synthesis (InBrainSyn), a framework for\nsynthesizing high-resolution subject-specific longitudinal MRI scans that\nsimulate neurodegeneration in both Alzheimer's disease (AD) and normal aging.\nInBrainSyn uses a parallel transport algorithm to adapt the population-level\naging trajectories learned by a generative deep template network, enabling\nindividualized aging synthesis. As InBrainSyn uses diffeomorphic\ntransformations to simulate aging, the synthesized images are topologically\nconsistent with the original anatomy by design. We evaluated InBrainSyn both\nquantitatively and qualitatively on AD and healthy control cohorts from the\nOpen Access Series of Imaging Studies - version 3 dataset. Experimentally,\nInBrainSyn can also model neuroanatomical transitions between normal aging and\nAD. An evaluation of an external set supports its generalizability. Overall,\nwith only a single baseline scan, InBrainSyn synthesizes realistic 3D\nspatiotemporal T1w MRI scans, producing personalized longitudinal aging\ntrajectories. The code for InBrainSyn is available at:\nhttps://github.com/Fjr9516/InBrainSyn.",
    "pdf_url": "http://arxiv.org/pdf/2502.21049v1",
    "published": "2025-02-28",
    "source": "arxiv",
    "id": "2502.21049v1",
    "categories": [
      "cs.CV",
      "cs.AI",
      "eess.IV"
    ]
  },
  {
    "title": "Incorporating Long-Range Interactions via the Multipole Expansion into Ground and Excited-State Molecular Simulations",
    "authors": [
      "Rhyan Barrett",
      "Johannes C. B. Dietschreit",
      "Julia Westermayr"
    ],
    "abstract": "Simulating long-range interactions remains a significant challenge for\nmolecular machine learning potentials due to the need to accurately capture\ninteractions over large spatial regions. In this work, we introduce FieldMACE,\nan extension of the message-passing atomic cluster expansion (MACE)\narchitecture that integrates the multipole expansion to model long-range\ninteractions more efficiently. By incorporating the multipole expansion,\nFieldMACE effectively captures environmental and long-range effects in both\nground and excited states. Benchmark evaluations demonstrate its superior\nperformance in predictions and computational efficiency compared to previous\narchitectures, as well as its ability to accurately simulate nonadiabatic\nexcited-state dynamics. Furthermore, transfer learning from foundational models\nenhances data efficiency, making FieldMACE a scalable, robust, and transferable\nframework for large-scale molecular simulations.",
    "pdf_url": "http://arxiv.org/pdf/2502.21045v1",
    "published": "2025-02-28",
    "source": "arxiv",
    "id": "2502.21045v1",
    "categories": [
      "physics.comp-ph",
      "math-ph",
      "math.MP"
    ]
  },
  {
    "title": "Fast Adversarial Training against Sparse Attacks Requires Loss Smoothing",
    "authors": [
      "Xuyang Zhong",
      "Yixiao Huang",
      "Chen Liu"
    ],
    "abstract": "This paper studies fast adversarial training against sparse adversarial\nperturbations bounded by $l_0$ norm. We demonstrate the challenges of employing\n$1$-step attacks on $l_0$ bounded perturbations for fast adversarial training,\nincluding degraded performance and the occurrence of catastrophic overfitting\n(CO). We highlight that CO in $l_0$ adversarial training is caused by\nsub-optimal perturbation locations of $1$-step attack. Theoretical and\nempirical analyses reveal that the loss landscape of $l_0$ adversarial training\nis more craggy compared to its $l_\\infty$, $l_2$ and $l_1$ counterparts.\nMoreover, we corroborate that the craggy loss landscape can aggravate CO. To\naddress these issues, we propose Fast-LS-$l_0$ that incorporates soft labels\nand the trade-off loss function to smooth the adversarial loss landscape.\nExtensive experiments demonstrate our method can overcome the challenge of\ncatastrophic overfitting, achieve state-of-the-art performance, and narrow down\nthe performance gap between $1$-step and multi-step adversarial training\nagainst sparse attacks.",
    "pdf_url": "http://arxiv.org/pdf/2502.21041v1",
    "published": "2025-02-28",
    "source": "arxiv",
    "id": "2502.21041v1",
    "categories": [
      "cs.LG",
      "cs.AI"
    ]
  },
  {
    "title": "Reward Learning from Multiple Feedback Types",
    "authors": [
      "Yannick Metz",
      "András Geiszl",
      "Raphaël Baur",
      "Mennatallah El-Assady"
    ],
    "abstract": "Learning rewards from preference feedback has become an important tool in the\nalignment of agentic models. Preference-based feedback, often implemented as a\nbinary comparison between multiple completions, is an established method to\nacquire large-scale human feedback. However, human feedback in other contexts\nis often much more diverse. Such diverse feedback can better support the goals\nof a human annotator, and the simultaneous use of multiple sources might be\nmutually informative for the learning process or carry type-dependent biases\nfor the reward learning process. Despite these potential benefits, learning\nfrom different feedback types has yet to be explored extensively. In this\npaper, we bridge this gap by enabling experimentation and evaluating multi-type\nfeedback in a broad set of environments. We present a process to generate\nhigh-quality simulated feedback of six different types. Then, we implement\nreward models and downstream RL training for all six feedback types. Based on\nthe simulated feedback, we investigate the use of types of feedback across ten\nRL environments and compare them to pure preference-based baselines. We show\nempirically that diverse types of feedback can be utilized and lead to strong\nreward modeling performance. This work is the first strong indicator of the\npotential of multi-type feedback for RLHF.",
    "pdf_url": "http://arxiv.org/pdf/2502.21038v1",
    "published": "2025-02-28",
    "source": "arxiv",
    "id": "2502.21038v1",
    "categories": [
      "cs.LG",
      "cs.AI"
    ]
  },
  {
    "title": "The amplifier effect of artificial agents in social contagion",
    "authors": [
      "Eric Hitz",
      "Mingmin Feng",
      "Radu Tanase",
      "René Algesheimer",
      "Manuel S. Mariani"
    ],
    "abstract": "Recent advances in artificial intelligence have led to the proliferation of\nartificial agents in social contexts, ranging from education to online social\nmedia and financial markets, among many others. The increasing rate at which\nartificial and human agents interact makes it urgent to understand the\nconsequences of human-machine interactions for the propagation of new ideas,\nproducts, and behaviors in society. Across two distinct empirical contexts, we\nfind here that artificial agents lead to significantly faster and wider social\ncontagion. To this end, we replicate a choice experiment previously conducted\nwith human subjects by using artificial agents powered by large language models\n(LLMs). We use the experiment's results to measure the adoption thresholds of\nartificial agents and their impact on the spread of social contagion. We find\nthat artificial agents tend to exhibit lower adoption thresholds than humans,\nwhich leads to wider network-based social contagions. Our findings suggest that\nthe increased presence of artificial agents in real-world networks may\naccelerate behavioral shifts, potentially in unforeseen ways.",
    "pdf_url": "http://arxiv.org/pdf/2502.21037v1",
    "published": "2025-02-28",
    "source": "arxiv",
    "id": "2502.21037v1",
    "categories": [
      "cs.SI",
      "econ.GN",
      "physics.soc-ph",
      "q-fin.EC"
    ]
  },
  {
    "title": "S4ConvD: Adaptive Scaling and Frequency Adjustment for Energy-Efficient Sensor Networks in Smart Buildings",
    "authors": [
      "Melanie Schaller",
      "Bodo Rosenhahn"
    ],
    "abstract": "Predicting energy consumption in smart buildings is challenging due to\ndependencies in sensor data and the variability of environmental conditions. We\nintroduce S4ConvD, a novel convolutional variant of Deep State Space Models\n(Deep-SSMs), that minimizes reliance on extensive preprocessing steps. S4ConvD\nis designed to optimize runtime in resource-constrained environments. By\nimplementing adaptive scaling and frequency adjustments, this model shows to\ncapture complex temporal patterns in building energy dynamics. Experiments on\nthe ASHRAE Great Energy Predictor III dataset reveal that S4ConvD outperforms\ncurrent benchmarks. Additionally, S4ConvD benefits from significant\nimprovements in GPU runtime through the use of Block Tiling optimization\ntechniques. Thus, S4ConvD has the potential for practical deployment in\nreal-time energy modeling. Furthermore, the complete codebase and dataset are\naccessible on GitHub, fostering open-source contributions and facilitating\nfurther research. Our method also promotes resource-efficient model execution,\nenhancing both energy forecasting and the potential integration of renewable\nenergy sources into smart grid systems.",
    "pdf_url": "http://arxiv.org/pdf/2502.21035v1",
    "published": "2025-02-28",
    "source": "arxiv",
    "id": "2502.21035v1",
    "categories": [
      "cs.LG"
    ]
  },
  {
    "title": "Synthesizing Tabular Data Using Selectivity Enhanced Generative Adversarial Networks",
    "authors": [
      "Youran Zhou",
      "Jianzhong Qi"
    ],
    "abstract": "As E-commerce platforms face surging transactions during major shopping\nevents like Black Friday, stress testing with synthesized data is crucial for\nresource planning. Most recent studies use Generative Adversarial Networks\n(GANs) to generate tabular data while ensuring privacy and machine learning\nutility. However, these methods overlook the computational demands of\nprocessing GAN-generated data, making them unsuitable for E-commerce stress\ntesting.\n  This thesis introduces a novel GAN-based approach incorporating query\nselectivity constraints, a key factor in database transaction processing. We\nintegrate a pre-trained deep neural network to maintain selectivity consistency\nbetween real and synthetic data. Our method, tested on five real-world\ndatasets, outperforms three state-of-the-art GANs and a VAE model, improving\nselectivity estimation accuracy by up to 20pct and machine learning utility by\nup to 6 pct.",
    "pdf_url": "http://arxiv.org/pdf/2502.21034v1",
    "published": "2025-02-28",
    "source": "arxiv",
    "id": "2502.21034v1",
    "categories": [
      "cs.LG",
      "cs.AI"
    ]
  },
  {
    "title": "A data augmentation strategy for deep neural networks with application to epidemic modelling",
    "authors": [
      "Muhammad Awais",
      "Abu Sayfan Ali",
      "Giacomo Dimarco",
      "Federica Ferrarese",
      "Lorenzo Pareschi"
    ],
    "abstract": "In this work, we integrate the predictive capabilities of compartmental\ndisease dynamics models with machine learning ability to analyze complex,\nhigh-dimensional data and uncover patterns that conventional models may\noverlook. Specifically, we present a proof of concept demonstrating the\napplication of data-driven methods and deep neural networks to a recently\nintroduced SIR-type model with social features, including a saturated incidence\nrate, to improve epidemic prediction and forecasting. Our results show that a\nrobust data augmentation strategy trough suitable data-driven models can\nimprove the reliability of Feed-Forward Neural Networks (FNNs) and Nonlinear\nAutoregressive Networks (NARs), making them viable alternatives to\nPhysics-Informed Neural Networks (PINNs). This approach enhances the ability to\nhandle nonlinear dynamics and offers scalable, data-driven solutions for\nepidemic forecasting, prioritizing predictive accuracy over the constraints of\nphysics-based models. Numerical simulations of the post-lockdown phase of the\nCOVID-19 epidemic in Italy and Spain validate our methodology.",
    "pdf_url": "http://arxiv.org/pdf/2502.21033v1",
    "published": "2025-02-28",
    "source": "arxiv",
    "id": "2502.21033v1",
    "categories": [
      "math.NA",
      "cs.LG",
      "cs.NA",
      "physics.soc-ph",
      "q-bio.PE",
      "stat.ML"
    ]
  },
  {
    "title": "Sixth-Sense: Self-Supervised Learning of Spatial Awareness of Humans from a Planar Lidar",
    "authors": [
      "Simone Arreghini",
      "Nicholas Carlotti",
      "Mirko Nava",
      "Antonio Paolillo",
      "Alessandro Giusti"
    ],
    "abstract": "Localizing humans is a key prerequisite for any service robot operating in\nproximity to people. In these scenarios, robots rely on a multitude of\nstate-of-the-art detectors usually designed to operate with RGB-D cameras or\nexpensive 3D LiDARs. However, most commercially available service robots are\nequipped with cameras with a narrow field of view, making them blind when a\nuser is approaching from other directions, or inexpensive 1D LiDARs whose\nreadings are difficult to interpret. To address these limitations, we propose a\nself-supervised approach to detect humans and estimate their 2D pose from 1D\nLiDAR data, using detections from an RGB-D camera as a supervision source. Our\napproach aims to provide service robots with spatial awareness of nearby\nhumans. After training on 70 minutes of data autonomously collected in two\nenvironments, our model is capable of detecting humans omnidirectionally from\n1D LiDAR data in a novel environment, with 71% precision and 80% recall, while\nretaining an average absolute error of 13 cm in distance and 44{\\deg} in\norientation.",
    "pdf_url": "http://arxiv.org/pdf/2502.21029v1",
    "published": "2025-02-28",
    "source": "arxiv",
    "id": "2502.21029v1",
    "categories": [
      "cs.RO",
      "cs.LG"
    ]
  },
  {
    "title": "AutoQML: A Framework for Automated Quantum Machine Learning",
    "authors": [
      "Marco Roth",
      "David A. Kreplin",
      "Daniel Basilewitsch",
      "João F. Bravo",
      "Dennis Klau",
      "Milan Marinov",
      "Daniel Pranjic",
      "Horst Stuehler",
      "Moritz Willmann",
      "Marc-André Zöller"
    ],
    "abstract": "Automated Machine Learning (AutoML) has significantly advanced the efficiency\nof ML-focused software development by automating hyperparameter optimization\nand pipeline construction, reducing the need for manual intervention. Quantum\nMachine Learning (QML) offers the potential to surpass classical machine\nlearning (ML) capabilities by utilizing quantum computing. However, the\ncomplexity of QML presents substantial entry barriers. We introduce\n\\emph{AutoQML}, a novel framework that adapts the AutoML approach to QML,\nproviding a modular and unified programming interface to facilitate the\ndevelopment of QML pipelines. AutoQML leverages the QML library sQUlearn to\nsupport a variety of QML algorithms. The framework is capable of constructing\nend-to-end pipelines for supervised learning tasks, ensuring accessibility and\nefficacy. We evaluate AutoQML across four industrial use cases, demonstrating\nits ability to generate high-performing QML pipelines that are competitive with\nboth classical ML models and manually crafted quantum solutions.",
    "pdf_url": "http://arxiv.org/pdf/2502.21025v1",
    "published": "2025-02-28",
    "source": "arxiv",
    "id": "2502.21025v1",
    "categories": [
      "quant-ph",
      "cs.LG"
    ]
  },
  {
    "title": "When Unsupervised Domain Adaptation meets One-class Anomaly Detection: Addressing the Two-fold Unsupervised Curse by Leveraging Anomaly Scarcity",
    "authors": [
      "Nesryne Mejri",
      "Enjie Ghorbel",
      "Anis Kacem",
      "Pavel Chernakov",
      "Niki Foteinopoulou",
      "Djamila Aouada"
    ],
    "abstract": "This paper introduces the first fully unsupervised domain adaptation (UDA)\nframework for unsupervised anomaly detection (UAD). The performance of UAD\ntechniques degrades significantly in the presence of a domain shift, difficult\nto avoid in a real-world setting. While UDA has contributed to solving this\nissue in binary and multi-class classification, such a strategy is ill-posed in\nUAD. This might be explained by the unsupervised nature of the two tasks,\nnamely, domain adaptation and anomaly detection. Herein, we first formulate\nthis problem that we call the two-fold unsupervised curse. Then, we propose a\npioneering solution to this curse, considered intractable so far, by assuming\nthat anomalies are rare. Specifically, we leverage clustering techniques to\nidentify a dominant cluster in the target feature space. Posed as the normal\ncluster, the latter is aligned with the source normal features. Concretely,\ngiven a one-class source set and an unlabeled target set composed mostly of\nnormal data and some anomalies, we fit the source features within a hypersphere\nwhile jointly aligning them with the features of the dominant cluster from the\ntarget set. The paper provides extensive experiments and analysis on common\nadaptation benchmarks for anomaly detection, demonstrating the relevance of\nboth the newly introduced paradigm and the proposed approach. The code will be\nmade publicly available.",
    "pdf_url": "http://arxiv.org/pdf/2502.21022v1",
    "published": "2025-02-28",
    "source": "arxiv",
    "id": "2502.21022v1",
    "categories": [
      "cs.LG",
      "cs.CV"
    ]
  },
  {
    "title": "Nano Drone-based Indoor Crime Scene Analysis",
    "authors": [
      "Martin Cooney",
      "Sivadinesh Ponrajan",
      "Fernando Alonso-Fernandez"
    ],
    "abstract": "Technologies such as robotics, Artificial Intelligence (AI), and Computer\nVision (CV) can be applied to crime scene analysis (CSA) to help protect lives,\nfacilitate justice, and deter crime, but an overview of the tasks that can be\nautomated has been lacking. Here we follow a speculate prototyping approach:\nFirst, the STAIR tool is used to rapidly review the literature and identify\ntasks that seem to have not received much attention, like accessing crime sites\nthrough a window, mapping/gathering evidence, and analyzing blood smears.\nSecondly, we present a prototype of a small drone that implements these three\ntasks with 75%, 85%, and 80% performance, to perform a minimal analysis of an\nindoor crime scene. Lessons learned are reported, toward guiding next work in\nthe area.",
    "pdf_url": "http://arxiv.org/pdf/2502.21019v1",
    "published": "2025-02-28",
    "source": "arxiv",
    "id": "2502.21019v1",
    "categories": [
      "cs.RO"
    ]
  },
  {
    "title": "PersuasiveToM: A Benchmark for Evaluating Machine Theory of Mind in Persuasive Dialogues",
    "authors": [
      "Fangxu Yu",
      "Lai Jiang",
      "Shenyi Huang",
      "Zhen Wu",
      "Xinyu Dai"
    ],
    "abstract": "The ability to understand and predict the mental states of oneself and\nothers, known as the Theory of Mind (ToM), is crucial for effective social\ninteractions. Recent research has emerged to evaluate whether Large Language\nModels (LLMs) exhibit a form of ToM. Although recent studies have evaluated ToM\nin LLMs, existing benchmarks focus predominantly on physical perception with\nprinciples guided by the Sally-Anne test in synthetic stories and\nconversations, failing to capture the complex psychological activities of\nmental states in real-life social interactions. To mitigate this gap, we\npropose PersuasiveToM, a benchmark designed to evaluate the ToM abilities of\nLLMs in persuasive dialogues. Our framework introduces two categories of\nquestions: (1) ToM Reasoning, assessing the capacity of LLMs to track evolving\nmental states (e.g., desire shifts in persuadees), and (2) ToM Application,\nevaluating whether LLMs can take advantage of inferred mental states to select\neffective persuasion strategies (e.g., emphasize rarity) and evaluate the\neffectiveness of persuasion strategies. Experiments across eight\nstate-of-the-art LLMs reveal that while models excel on multiple questions,\nthey struggle to answer questions that need tracking the dynamics and shifts of\nmental states and understanding the mental states in the whole dialogue\ncomprehensively. Our aim with PersuasiveToM is to allow an effective evaluation\nof the ToM reasoning ability of LLMs with more focus on complex psychological\nactivities. Our code is available at\nhttps://github.com/Yu-Fangxu/PersuasiveToM.",
    "pdf_url": "http://arxiv.org/pdf/2502.21017v1",
    "published": "2025-02-28",
    "source": "arxiv",
    "id": "2502.21017v1",
    "categories": [
      "cs.CL"
    ]
  },
  {
    "title": "FedDyMem: Efficient Federated Learning with Dynamic Memory and Memory-Reduce for Unsupervised Image Anomaly Detection",
    "authors": [
      "Silin Chen",
      "Kangjian Di",
      "Yichu Xu",
      "Han-Jia Ye",
      "Wenhan Luo",
      "Ningmu Zou"
    ],
    "abstract": "Unsupervised image anomaly detection (UAD) has become a critical process in\nindustrial and medical applications, but it faces growing challenges due to\nincreasing concerns over data privacy. The limited class diversity inherent to\none-class classification tasks, combined with distribution biases caused by\nvariations in products across and within clients, poses significant challenges\nfor preserving data privacy with federated UAD. Thus, this article proposes an\nefficient federated learning method with dynamic memory and memory-reduce for\nunsupervised image anomaly detection, called FedDyMem. Considering all client\ndata belongs to a single class (i.e., normal sample) in UAD and the\ndistribution of intra-class features demonstrates significant skewness,\nFedDyMem facilitates knowledge sharing between the client and server through\nthe client's dynamic memory bank instead of model parameters. In the local\nclients, a memory generator and a metric loss are employed to improve the\nconsistency of the feature distribution for normal samples, leveraging the\nlocal model to update the memory bank dynamically. For efficient communication,\na memory-reduce method based on weighted averages is proposed to significantly\ndecrease the scale of memory banks. On the server, global memory is constructed\nand distributed to individual clients through k-means aggregation. Experiments\nconducted on six industrial and medical datasets, comprising a mixture of six\nproducts or health screening types derived from eleven public datasets,\ndemonstrate the effectiveness of FedDyMem.",
    "pdf_url": "http://arxiv.org/pdf/2502.21012v1",
    "published": "2025-02-28",
    "source": "arxiv",
    "id": "2502.21012v1",
    "categories": [
      "cs.DC",
      "cs.CV"
    ]
  },
  {
    "title": "Position: Solve Layerwise Linear Models First to Understand Neural Dynamical Phenomena (Neural Collapse, Emergence, Lazy/Rich Regime, and Grokking)",
    "authors": [
      "Yoonsoo Nam",
      "Seok Hyeong Lee",
      "Clementine Domine",
      "Yea Chan Park",
      "Charles London",
      "Wonyl Choi",
      "Niclas Goring",
      "Seungjai Lee"
    ],
    "abstract": "In physics, complex systems are often simplified into minimal, solvable\nmodels that retain only the core principles. In machine learning, layerwise\nlinear models (e.g., linear neural networks) act as simplified representations\nof neural network dynamics. These models follow the dynamical feedback\nprinciple, which describes how layers mutually govern and amplify each other's\nevolution. This principle extends beyond the simplified models, successfully\nexplaining a wide range of dynamical phenomena in deep neural networks,\nincluding neural collapse, emergence, lazy and rich regimes, and grokking. In\nthis position paper, we call for the use of layerwise linear models retaining\nthe core principles of neural dynamical phenomena to accelerate the science of\ndeep learning.",
    "pdf_url": "http://arxiv.org/pdf/2502.21009v1",
    "published": "2025-02-28",
    "source": "arxiv",
    "id": "2502.21009v1",
    "categories": [
      "stat.ML",
      "cs.LG",
      "physics.data-an"
    ]
  },
  {
    "title": "Towards Specialized Wireless Networks Using an ML-Driven Radio Interface",
    "authors": [
      "Kamil Szczech",
      "Maksymilian Wojnar",
      "Katarzyna Kosek-Szott",
      "Krzysztof Rusek",
      "Szymon Szott",
      "Dileepa Marasinghe",
      "Nandana Rajatheva",
      "Richard Combes",
      "Francesc Wilhelmi",
      "Anders Jonsson",
      "Boris Bellalta"
    ],
    "abstract": "Future wireless networks will need to support diverse applications (such as\nextended reality), scenarios (such as fully automated industries), and\ntechnological advances (such as terahertz communications). Current wireless\nnetworks are designed to perform adequately across multiple scenarios so they\nlack the adaptability needed for specific use cases. Therefore, meeting the\nstringent requirements of next-generation applications incorporating technology\nadvances and operating in novel scenarios will necessitate wireless specialized\nnetworks which we refer to as SpecNets. These networks, equipped with cognitive\ncapabilities, dynamically adapt to the unique demands of each application,\ne.g., by automatically selecting and configuring network mechanisms. An enabler\nof SpecNets are the recent advances in artificial intelligence and machine\nlearning (AI/ML), which allow to continuously learn and react to changing\nrequirements and scenarios. By integrating AI/ML functionalities, SpecNets will\nfully leverage the concept of AI/ML-defined radios (MLDRs) that are able to\nautonomously establish their own communication protocols by acquiring\ncontextual information and dynamically adapting to it. In this paper, we\nintroduce SpecNets and explain how MLDR interfaces enable this concept. We\npresent three illustrative use cases for wireless local area networks (WLANs):\nbespoke industrial networks, traffic-aware robust THz links, and coexisting\nnetworks. Finally, we showcase SpecNets' benefits in the industrial use case by\nintroducing a lightweight, fast-converging ML agent based on multi-armed\nbandits (MABs). This agent dynamically optimizes channel access to meet varying\nperformance needs: high throughput, low delay, or fair access. Results\ndemonstrate significant gains over IEEE 802.11, highlighting the system's\nautonomous adaptability across diverse scenarios.",
    "pdf_url": "http://arxiv.org/pdf/2502.20996v1",
    "published": "2025-02-28",
    "source": "arxiv",
    "id": "2502.20996v1",
    "categories": [
      "cs.NI"
    ]
  },
  {
    "title": "Forecasting Monthly Residential Natural Gas Demand Using Just-In-Time-Learning Modeling",
    "authors": [
      "Burak Alakent",
      "Erkan Isikli",
      "Cigdem Kadaifci",
      "Tonguc S. Taspinar"
    ],
    "abstract": "Natural gas (NG) is relatively a clean source of energy, particularly\ncompared to fossil fuels, and worldwide consumption of NG has been increasing\nalmost linearly in the last two decades. A similar trend can also be seen in\nTurkey, while another similarity is the high dependence on imports for the\ncontinuous NG supply. It is crucial to accurately forecast future NG demand\n(NGD) in Turkey, especially, for import contracts; in this respect, forecasts\nof monthly NGD for the following year are of utmost importance. In the current\nstudy, the historical monthly NG consumption data between 2014 and 2024\nprovided by SOCAR, the local residential NG distribution company for two cities\nin Turkey, Bursa and Kayseri, was used to determine out-of-sample monthly NGD\nforecasts for a period of one year and nine months using various time series\nmodels, including SARIMA and ETS models, and a novel proposed machine learning\nmethod. The proposed method, named Just-in-Time-Learning-Gaussian Process\nRegression (JITL-GPR), uses a novel feature representation for the past NG\ndemand values; instead of using past demand values as column-wise separate\nfeatures, they are placed on a two-dimensional (2-D) grid of year-month values.\nFor each test point, a kernel function, tailored for the NGD predictions, is\nused in GPR to predict the query point. Since a model is constructed separately\nfor each test point, the proposed method is, indeed, an example of JITL. The\nJITL-GPR method is easy to use and optimize, and offers a reduction in forecast\nerrors compared to traditional time series methods and a state-of-the-art\ncombination model; therefore, it is a promising tool for NGD forecasting in\nsimilar settings.",
    "pdf_url": "http://arxiv.org/pdf/2502.20989v1",
    "published": "2025-02-28",
    "source": "arxiv",
    "id": "2502.20989v1",
    "categories": [
      "stat.AP",
      "stat.ML"
    ]
  },
  {
    "title": "Merging Clinical Knowledge into Large Language Models for Medical Research and Applications: A Survey",
    "authors": [
      "Qiyuan Li",
      "Haijiang Liu",
      "Caicai Guo",
      "Deyu Chen",
      "Meng Wang",
      "Feng Gao",
      "Jinguang Gu"
    ],
    "abstract": "Clinical knowledge is the collection of information learned from studies on\nthe causes, prognosis, diagnosis, and treatment of diseases. This type of\nknowledge can improve curing performances, and promote physical health. With\nthe emergence of large language models (LLMs), medical artificial intelligence\n(medical AI), which aims to apply academic medical AI systems to real-world\nmedical scenarios, has entered a new age of development, resulting in excellent\nworks such as DoctorGPT and Pangu-Drug from academic and industrial researches.\nHowever, the field lacks a comprehensive compendium and comparison of building\nmedical AI systems from academia and industry. Therefore, this survey focuses\non the building paradigms of medical AI systems including the use of clinical\ndatabases, datasets, training pipelines, integrating medical knowledge graphs,\nsystem applications, and evaluation systems. We hope that this survey can help\nrelevant practical researchers understand the current performance of academic\nmodels in various fields of healthcare, as well as the potential problems and\nfuture directions for implementing these scientific achievements.",
    "pdf_url": "http://arxiv.org/pdf/2502.20988v1",
    "published": "2025-02-28",
    "source": "arxiv",
    "id": "2502.20988v1",
    "categories": [
      "cs.AI",
      "cs.CL"
    ]
  },
  {
    "title": "UoR-NCL at SemEval-2025 Task 1: Using Generative LLMs and CLIP Models for Multilingual Multimodal Idiomaticity Representation",
    "authors": [
      "Thanet Markchom",
      "Tong Wu",
      "Liting Huang",
      "Huizhi Liang"
    ],
    "abstract": "SemEval-2025 Task 1 focuses on ranking images based on their alignment with a\ngiven nominal compound that may carry idiomatic meaning in both English and\nBrazilian Portuguese. To address this challenge, this work uses generative\nlarge language models (LLMs) and multilingual CLIP models to enhance idiomatic\ncompound representations. LLMs generate idiomatic meanings for potentially\nidiomatic compounds, enriching their semantic interpretation. These meanings\nare then encoded using multilingual CLIP models, serving as representations for\nimage ranking. Contrastive learning and data augmentation techniques are\napplied to fine-tune these embeddings for improved performance. Experimental\nresults show that multimodal representations extracted through this method\noutperformed those based solely on the original nominal compounds. The\nfine-tuning approach shows promising outcomes but is less effective than using\nembeddings without fine-tuning. The source code used in this paper is available\nat https://github.com/tongwu17/SemEval-2025-Task1-UoR-NCL.",
    "pdf_url": "http://arxiv.org/pdf/2502.20984v1",
    "published": "2025-02-28",
    "source": "arxiv",
    "id": "2502.20984v1",
    "categories": [
      "cs.CL",
      "cs.AI"
    ]
  },
  {
    "title": "Target Selection for the Redshift-Limited WAVES-Wide with Machine Learning",
    "authors": [
      "Gursharanjit Kaur",
      "Maciej Bilicki",
      "Wojciech Hellwing",
      "the WAVES team"
    ],
    "abstract": "The forthcoming Wide Area Vista Extragalactic Survey (WAVES) on the 4-metre\nMulti-Object Spectroscopic Telescope (4MOST) has a key science goal of probing\nthe halo mass function to lower limits than possible with previous surveys. For\nthat purpose, in its Wide component, galaxies targetted by WAVES will be\nflux-limited to $Z<21.1$ mag and will cover the redshift range of $z<0.2$, at a\nspectroscopic success rate of $\\sim95\\%$. Meeting this completeness\nrequirement, when the redshift is unknown a priori, is a challenge. We solve\nthis problem with supervised machine learning to predict the probability of a\ngalaxy falling within the WAVES-Wide redshift limit, rather than estimate each\nobject's redshift. This is done by training an XGBoost tree-based classifier to\ndecide if a galaxy should be a target or not. Our photometric data come from\n9-band VST+VISTA observations, including KiDS+VIKING surveys. The redshift\nlabels for calibration are derived from an extensive spectroscopic sample\noverlapping with KiDS and ancillary fields. Our current results indicate that\nwith our approach, we should be able to achieve the completeness of $\\sim95\\%$,\nwhich is the WAVES success criterion.",
    "pdf_url": "http://arxiv.org/pdf/2502.20983v1",
    "published": "2025-02-28",
    "source": "arxiv",
    "id": "2502.20983v1",
    "categories": [
      "astro-ph.CO",
      "astro-ph.GA",
      "astro-ph.IM"
    ]
  },
  {
    "title": "Motion ReTouch: Motion Modification Using Four-Channel Bilateral Control",
    "authors": [
      "Koki Inami",
      "Sho Sakaino",
      "Toshiaki Tsuji"
    ],
    "abstract": "Recent research has demonstrated the usefulness of imitation learning in\nautonomous robot operation. In particular, teaching using four-channel\nbilateral control, which can obtain position and force information, has been\nproven effective. However, control performance that can easily execute\nhigh-speed, complex tasks in one go has not yet been achieved. We propose a\nmethod called Motion ReTouch, which retroactively modifies motion data obtained\nusing four-channel bilateral control. The proposed method enables modification\nof not only position but also force information. This was achieved by the\ncombination of multilateral control and motion-copying system. The proposed\nmethod was verified in experiments with a real robot, and the success rate of\nthe test tube transfer task was improved, demonstrating the possibility of\nmodification force information.",
    "pdf_url": "http://arxiv.org/pdf/2502.20982v1",
    "published": "2025-02-28",
    "source": "arxiv",
    "id": "2502.20982v1",
    "categories": [
      "cs.RO"
    ]
  },
  {
    "title": "Distribution Prototype Diffusion Learning for Open-set Supervised Anomaly Detection",
    "authors": [
      "Fuyun Wang",
      "Tong Zhang",
      "Yuanzhi Wang",
      "Yide Qiu",
      "Xin Liu",
      "Xu Guo",
      "Zhen Cui"
    ],
    "abstract": "In Open-set Supervised Anomaly Detection (OSAD), the existing methods\ntypically generate pseudo anomalies to compensate for the scarcity of observed\nanomaly samples, while overlooking critical priors of normal samples, leading\nto less effective discriminative boundaries. To address this issue, we propose\na Distribution Prototype Diffusion Learning (DPDL) method aimed at enclosing\nnormal samples within a compact and discriminative distribution space.\nSpecifically, we construct multiple learnable Gaussian prototypes to create a\nlatent representation space for abundant and diverse normal samples and learn a\nSchr\\\"odinger bridge to facilitate a diffusive transition toward these\nprototypes for normal samples while steering anomaly samples away. Moreover, to\nenhance inter-sample separation, we design a dispersion feature learning way in\nhyperspherical space, which benefits the identification of out-of-distribution\nanomalies. Experimental results demonstrate the effectiveness and superiority\nof our proposed DPDL, achieving state-of-the-art performance on 9 public\ndatasets.",
    "pdf_url": "http://arxiv.org/pdf/2502.20981v1",
    "published": "2025-02-28",
    "source": "arxiv",
    "id": "2502.20981v1",
    "categories": [
      "cs.CV"
    ]
  },
  {
    "title": "Improving Open-world Continual Learning under the Constraints of Scarce Labeled Data",
    "authors": [
      "Yujie Li",
      "Xiangkun Wang",
      "Xin Yang",
      "Marcello Bonsangue",
      "Junbo Zhang",
      "Tianrui Li"
    ],
    "abstract": "Open-world continual learning (OWCL) adapts to sequential tasks with open\nsamples, learning knowledge incrementally while preventing forgetting. However,\nexisting OWCL still requires a large amount of labeled data for training, which\nis often impractical in real-world applications. Given that new\ncategories/entities typically come with limited annotations and are in small\nquantities, a more realistic situation is OWCL with scarce labeled data, i.e.,\nfew-shot training samples. Hence, this paper investigates the problem of\nopen-world few-shot continual learning (OFCL), challenging in (i) learning\nunbounded tasks without forgetting previous knowledge and avoiding overfitting,\n(ii) constructing compact decision boundaries for open detection with limited\nlabeled data, and (iii) transferring knowledge about knowns and unknowns and\neven update the unknowns to knowns once the labels of open samples are learned.\nIn response, we propose a novel OFCL framework that integrates three key\ncomponents: (1) an instance-wise token augmentation (ITA) that represents and\nenriches sample representations with additional knowledge, (2) a margin-based\nopen boundary (MOB) that supports open detection with new tasks emerge over\ntime, and (3) an adaptive knowledge space (AKS) that endows unknowns with\nknowledge for the updating from unknowns to knowns. Finally, extensive\nexperiments show the proposed OFCL framework outperforms all baselines\nremarkably with practical importance and reproducibility. The source code is\nreleased at https://github.com/liyj1201/OFCL.",
    "pdf_url": "http://arxiv.org/pdf/2502.20974v1",
    "published": "2025-02-28",
    "source": "arxiv",
    "id": "2502.20974v1",
    "categories": [
      "cs.LG",
      "cs.AI"
    ]
  },
  {
    "title": "Arabizi vs LLMs: Can the Genie Understand the Language of Aladdin?",
    "authors": [
      "Perla Al Almaoui",
      "Pierrette Bouillon",
      "Simon Hengchen"
    ],
    "abstract": "In this era of rapid technological advancements, communication continues to\nevolve as new linguistic phenomena emerge. Among these is Arabizi, a hybrid\nform of Arabic that incorporates Latin characters and numbers to represent the\nspoken dialects of Arab communities. Arabizi is widely used on social media and\nallows people to communicate in an informal and dynamic way, but it poses\nsignificant challenges for machine translation due to its lack of formal\nstructure and deeply embedded cultural nuances. This case study arises from a\ngrowing need to translate Arabizi for gisting purposes. It evaluates the\ncapacity of different LLMs to decode and translate Arabizi, focusing on\nmultiple Arabic dialects that have rarely been studied up until now. Using a\ncombination of human evaluators and automatic metrics, this research project\ninvestigates the model's performance in translating Arabizi into both Modern\nStandard Arabic and English. Key questions explored include which dialects are\ntranslated most effectively and whether translations into English surpass those\ninto Arabic.",
    "pdf_url": "http://arxiv.org/pdf/2502.20973v1",
    "published": "2025-02-28",
    "source": "arxiv",
    "id": "2502.20973v1",
    "categories": [
      "cs.CL"
    ]
  },
  {
    "title": "TeleRAG: Efficient Retrieval-Augmented Generation Inference with Lookahead Retrieval",
    "authors": [
      "Chien-Yu Lin",
      "Keisuke Kamahori",
      "Yiyu Liu",
      "Xiaoxiang Shi",
      "Madhav Kashyap",
      "Yile Gu",
      "Rulin Shao",
      "Zihao Ye",
      "Kan Zhu",
      "Stephanie Wang",
      "Arvind Krishnamurthy",
      "Rohan Kadekodi",
      "Luis Ceze",
      "Baris Kasikci"
    ],
    "abstract": "Retrieval-augmented generation (RAG) extends large language models (LLMs)\nwith external data sources to enhance factual correctness and domain coverage.\nModern RAG pipelines rely on large datastores, leading to system challenges in\nlatency-sensitive deployments, especially when limited GPU memory is available.\nTo address these challenges, we propose TeleRAG, an efficient inference system\nthat reduces RAG latency with minimal GPU memory requirements. The core\ninnovation of TeleRAG is lookahead retrieval, a prefetching mechanism that\nanticipates required data and transfers it from CPU to GPU in parallel with LLM\ngeneration. By leveraging the modularity of RAG pipelines, the inverted file\nindex (IVF) search algorithm and similarities between queries, TeleRAG\noptimally overlaps data movement and computation. Experimental results show\nthat TeleRAG reduces end-to-end RAG inference latency by up to 1.72x on average\ncompared to state-of-the-art systems, enabling faster, more memory-efficient\ndeployments of advanced RAG applications.",
    "pdf_url": "http://arxiv.org/pdf/2502.20969v1",
    "published": "2025-02-28",
    "source": "arxiv",
    "id": "2502.20969v1",
    "categories": [
      "cs.DC",
      "cs.LG"
    ]
  },
  {
    "title": "Post-Hoc Uncertainty Quantification in Pre-Trained Neural Networks via Activation-Level Gaussian Processes",
    "authors": [
      "Richard Bergna",
      "Stefan Depeweg",
      "Sergio Calvo Ordonez",
      "Jonathan Plenk",
      "Alvaro Cartea",
      "Jose Miguel Hernandez-Lobato"
    ],
    "abstract": "Uncertainty quantification in neural networks through methods such as\nDropout, Bayesian neural networks and Laplace approximations is either prone to\nunderfitting or computationally demanding, rendering these approaches\nimpractical for large-scale datasets. In this work, we address these\nshortcomings by shifting the focus from uncertainty in the weight space to\nuncertainty at the activation level, via Gaussian processes. More specifically,\nwe introduce the Gaussian Process Activation function (GAPA) to capture\nneuron-level uncertainties. Our approach operates in a post-hoc manner,\npreserving the original mean predictions of the pre-trained neural network and\nthereby avoiding the underfitting issues commonly encountered in previous\nmethods. We propose two methods. The first, GAPA-Free, employs empirical kernel\nlearning from the training data for the hyperparameters and is highly efficient\nduring training. The second, GAPA-Variational, learns the hyperparameters via\ngradient descent on the kernels, thus affording greater flexibility. Empirical\nresults demonstrate that GAPA-Variational outperforms the Laplace approximation\non most datasets in at least one of the uncertainty quantification metrics.",
    "pdf_url": "http://arxiv.org/pdf/2502.20966v1",
    "published": "2025-02-28",
    "source": "arxiv",
    "id": "2502.20966v1",
    "categories": [
      "stat.ML",
      "cs.LG"
    ]
  },
  {
    "title": "Retrieval Augmented Generation for Topic Modeling in Organizational Research: An Introduction with Empirical Demonstration",
    "authors": [
      "Gerion Spielberger",
      "Florian Artinger",
      "Jochen Reb",
      "Rudolf Kerschreiter"
    ],
    "abstract": "Analyzing textual data is the cornerstone of qualitative research. While\ntraditional methods such as grounded theory and content analysis are widely\nused, they are labor-intensive and time-consuming. Topic modeling offers an\nautomated complement. Yet, existing approaches, including LLM-based topic\nmodeling, still struggle with issues such as high data preprocessing\nrequirements, interpretability, and reliability. This paper introduces Agentic\nRetrieval-Augmented Generation (Agentic RAG) as a method for topic modeling\nwith LLMs. It integrates three key components: (1) retrieval, enabling\nautomatized access to external data beyond an LLM's pre-trained knowledge; (2)\ngeneration, leveraging LLM capabilities for text synthesis; and (3)\nagent-driven learning, iteratively refining retrieval and query formulation\nprocesses. To empirically validate Agentic RAG for topic modeling, we reanalyze\na Twitter/X dataset, previously examined by Mu et al. (2024a). Our findings\ndemonstrate that the approach is more efficient, interpretable and at the same\ntime achieves higher reliability and validity in comparison to the standard\nmachine learning approach but also in comparison to LLM prompting for topic\nmodeling. These results highlight Agentic RAG's ability to generate\nsemantically relevant and reproducible topics, positioning it as a robust,\nscalable, and transparent alternative for AI-driven qualitative research in\nleadership, managerial, and organizational research.",
    "pdf_url": "http://arxiv.org/pdf/2502.20963v1",
    "published": "2025-02-28",
    "source": "arxiv",
    "id": "2502.20963v1",
    "categories": [
      "cs.LG",
      "cs.AI",
      "econ.GN",
      "q-fin.EC"
    ]
  },
  {
    "title": "Cicada: A Pipeline-Efficient Approach to Serverless Inference with Decoupled Management",
    "authors": [
      "Z. Wu",
      "Y. Deng",
      "J. Hu",
      "L. Cui",
      "Z. Zhang",
      "L. Zeng",
      "G. Min"
    ],
    "abstract": "Serverless computing has emerged as a pivotal paradigm for deploying Deep\nLearning (DL) models, offering automatic scaling and cost efficiency. However,\nthe inherent cold start problem in serverless ML inference systems,\nparticularly the time-consuming model loading process, remains a significant\nbottleneck. Utilizing pipelined model loading improves efficiency but still\nsuffer from pipeline stalls due to sequential layer construction and monolithic\nweight loading. In this paper, we propose \\textit{Cicada}, a novel pipeline\noptimization framework that coordinates computational, storage, and scheduling\nresources through three key mechanisms: (1) \\textit{MiniLoader}: which reduces\nlayer construction overhead by opportunistically optimizing parameter\ninitialization; (2) \\textit{WeightDecoupler}: decoupling weight file processing\nfrom layer construction, enabling asynchronous weight retrieval and\nout-of-order weight application; (3) \\textit{Priority-Aware Scheduler}:\ndynamically allocating resources to ensure high-priority inference tasks are\nexecuted promptly. Our experimental results demonstrate that Cicada achieves\nsignificant performance improvements over the state-of-the-art PISeL framework.\nSpecifically, Cicada reduces end-to-end inference latency by an average of\n61.59\\%, with the MiniLoader component contributing the majority of this\noptimization (53.41\\%), and the WeightDecoupler achieves up to 26.17\\%\nimprovement. Additionally, Cicada achieves up to 2.52x speedup in the inference\npipeline utlization compared to PISeL.",
    "pdf_url": "http://arxiv.org/pdf/2502.20959v1",
    "published": "2025-02-28",
    "source": "arxiv",
    "id": "2502.20959v1",
    "categories": [
      "cs.DC"
    ]
  },
  {
    "title": "Reward Dimension Reduction for Scalable Multi-Objective Reinforcement Learning",
    "authors": [
      "Giseung Park",
      "Youngchul Sung"
    ],
    "abstract": "In this paper, we introduce a simple yet effective reward dimension reduction\nmethod to tackle the scalability challenges of multi-objective reinforcement\nlearning algorithms. While most existing approaches focus on optimizing two to\nfour objectives, their abilities to scale to environments with more objectives\nremain uncertain. Our method uses a dimension reduction approach to enhance\nlearning efficiency and policy performance in multi-objective settings. While\nmost traditional dimension reduction methods are designed for static datasets,\nour approach is tailored for online learning and preserves Pareto-optimality\nafter transformation. We propose a new training and evaluation framework for\nreward dimension reduction in multi-objective reinforcement learning and\ndemonstrate the superiority of our method in environments including one with\nsixteen objectives, significantly outperforming existing online dimension\nreduction methods.",
    "pdf_url": "http://arxiv.org/pdf/2502.20957v1",
    "published": "2025-02-28",
    "source": "arxiv",
    "id": "2502.20957v1",
    "categories": [
      "cs.LG"
    ]
  },
  {
    "title": "Robust and Efficient Writer-Independent IMU-Based Handwriting Recognization",
    "authors": [
      "Jindong Li",
      "Tim Hamann",
      "Jens Barth",
      "Peter Kaempf",
      "Dario Zanca",
      "Bjoern Eskofier"
    ],
    "abstract": "Online handwriting recognition (HWR) using data from inertial measurement\nunits (IMUs) remains challenging due to variations in writing styles and the\nlimited availability of high-quality annotated datasets. Traditional models\noften struggle to recognize handwriting from unseen writers, making\nwriter-independent (WI) recognition a crucial but difficult problem. This paper\npresents an HWR model with an encoder-decoder structure for IMU data, featuring\na CNN-based encoder for feature extraction and a BiLSTM decoder for sequence\nmodeling, which supports inputs of varying lengths. Our approach demonstrates\nstrong robustness and data efficiency, outperforming existing methods on WI\ndatasets, including the WI split of the OnHW dataset and our own dataset.\nExtensive evaluations show that our model maintains high accuracy across\ndifferent age groups and writing conditions while effectively learning from\nlimited data. Through comprehensive ablation studies, we analyze key design\nchoices, achieving a balance between accuracy and efficiency. These findings\ncontribute to the development of more adaptable and scalable HWR systems for\nreal-world applications.",
    "pdf_url": "http://arxiv.org/pdf/2502.20954v1",
    "published": "2025-02-28",
    "source": "arxiv",
    "id": "2502.20954v1",
    "categories": [
      "cs.LG"
    ]
  },
  {
    "title": "Optimality and Suboptimality of MPPI Control in Stochastic and Deterministic Settings",
    "authors": [
      "Hannes Homburger",
      "Florian Messerer",
      "Moritz Diehl",
      "Johannes Reuter"
    ],
    "abstract": "Model predictive path integral (MPPI) control has recently received a lot of\nattention, especially in the robotics and reinforcement learning communities.\nThis letter aims to make the MPPI control framework more accessible to the\noptimal control community. We present three classes of optimal control problems\nand their solutions by MPPI. Further, we investigate the suboptimality of MPPI\nto general deterministic nonlinear discrete-time systems. Here, suboptimality\nis defined as the deviation between the control provided by MPPI and the\noptimal solution to the deterministic optimal control problem. Our findings are\nthat in a smooth and unconstrained setting, the growth of suboptimality in the\ncontrol input trajectory is second-order with the scaling of uncertainty. The\nresults indicate that the suboptimality of the MPPI solution can be modulated\nby appropriately tuning the hyperparameters. We illustrate our findings using\nnumerical examples.",
    "pdf_url": "http://arxiv.org/pdf/2502.20953v1",
    "published": "2025-02-28",
    "source": "arxiv",
    "id": "2502.20953v1",
    "categories": [
      "eess.SY",
      "cs.SY"
    ]
  },
  {
    "title": "Efficient Jailbreaking of Large Models by Freeze Training: Lower Layers Exhibit Greater Sensitivity to Harmful Content",
    "authors": [
      "Hongyuan Shen",
      "Min Zheng",
      "Jincheng Wang",
      "Yang Zhao"
    ],
    "abstract": "With the widespread application of Large Language Models across various\ndomains, their security issues have increasingly garnered significant attention\nfrom both academic and industrial communities. This study conducts sampling and\nnormalization of the parameters of the LLM to generate visual representations\nand heatmaps of parameter distributions, revealing notable discrepancies in\nparameter distributions among certain layers within the hidden layers. Further\nanalysis involves calculating statistical metrics for each layer, followed by\nthe computation of a Comprehensive Sensitivity Score based on these metrics,\nwhich identifies the lower layers as being particularly sensitive to the\ngeneration of harmful content. Based on this finding, we employ a Freeze\ntraining strategy, selectively performing Supervised Fine-Tuning only on the\nlower layers. Experimental results demonstrate that this method significantly\nreduces training duration and GPU memory consumption while maintaining a high\njailbreak success rate and a high harm score, outperforming the results\nachieved by applying the LoRA method for SFT across all layers. Additionally,\nthe method has been successfully extended to other open-source large models,\nvalidating its generality and effectiveness across different model\narchitectures. Furthermore, we compare our method with ohter jailbreak method,\ndemonstrating the superior performance of our approach. By innovatively\nproposing a method to statistically analyze and compare large model parameters\nlayer by layer, this study provides new insights into the interpretability of\nlarge models. These discoveries emphasize the necessity of continuous research\nand the implementation of adaptive security measures in the rapidly evolving\nfield of LLMs to prevent potential jailbreak attack risks, thereby promoting\nthe development of more robust and secure LLMs.",
    "pdf_url": "http://arxiv.org/pdf/2502.20952v1",
    "published": "2025-02-28",
    "source": "arxiv",
    "id": "2502.20952v1",
    "categories": [
      "cs.CR",
      "cs.LG"
    ]
  },
  {
    "title": "Concealed Adversarial attacks on neural networks for sequential data",
    "authors": [
      "Petr Sokerin",
      "Dmitry Anikin",
      "Sofia Krehova",
      "Alexey Zaytsev"
    ],
    "abstract": "The emergence of deep learning led to the broad usage of neural networks in\nthe time series domain for various applications, including finance and\nmedicine. While powerful, these models are prone to adversarial attacks: a\nbenign targeted perturbation of input data leads to significant changes in a\nclassifier's output. However, formally small attacks in the time series domain\nbecome easily detected by the human eye or a simple detector model.\n  We develop a concealed adversarial attack for different time-series models:\nit provides more realistic perturbations, being hard to detect by a human or\nmodel discriminator. To achieve this goal, the proposed adversarial attack\nmaximizes an aggregation of a classifier and a trained discriminator loss. To\nmake the attack stronger, we also propose a training procedure for a\ndiscriminator that provides broader coverage of possible attacks. Extensive\nbenchmarking on six UCR time series datasets across four diverse architectures\n- including recurrent, convolutional, state-space, and transformer-based models\n- demonstrates the superiority of our attack for a concealability-efficiency\ntrade-off. Our findings highlight the growing challenge of designing robust\ntime series models, emphasizing the need for improved defenses against\nrealistic and effective attacks.",
    "pdf_url": "http://arxiv.org/pdf/2502.20948v1",
    "published": "2025-02-28",
    "source": "arxiv",
    "id": "2502.20948v1",
    "categories": [
      "cs.LG",
      "cs.AI"
    ]
  },
  {
    "title": "Generative Uncertainty in Diffusion Models",
    "authors": [
      "Metod Jazbec",
      "Eliot Wong-Toi",
      "Guoxuan Xia",
      "Dan Zhang",
      "Eric Nalisnick",
      "Stephan Mandt"
    ],
    "abstract": "Diffusion models have recently driven significant breakthroughs in generative\nmodeling. While state-of-the-art models produce high-quality samples on\naverage, individual samples can still be low quality. Detecting such samples\nwithout human inspection remains a challenging task. To address this, we\npropose a Bayesian framework for estimating generative uncertainty of synthetic\nsamples. We outline how to make Bayesian inference practical for large, modern\ngenerative models and introduce a new semantic likelihood (evaluated in the\nlatent space of a feature extractor) to address the challenges posed by\nhigh-dimensional sample spaces. Through our experiments, we demonstrate that\nthe proposed generative uncertainty effectively identifies poor-quality samples\nand significantly outperforms existing uncertainty-based methods. Notably, our\nBayesian framework can be applied post-hoc to any pretrained diffusion or flow\nmatching model (via the Laplace approximation), and we propose simple yet\neffective techniques to minimize its computational overhead during sampling.",
    "pdf_url": "http://arxiv.org/pdf/2502.20946v1",
    "published": "2025-02-28",
    "source": "arxiv",
    "id": "2502.20946v1",
    "categories": [
      "cs.LG",
      "cs.AI"
    ]
  },
  {
    "title": "Variations in Relevance Judgments and the Shelf Life of Test Collections",
    "authors": [
      "Andrew Parry",
      "Maik Fröbe",
      "Harrisen Scells",
      "Ferdinand Schlatt",
      "Guglielmo Faggioli",
      "Saber Zerhoudi",
      "Sean MacAvaney",
      "Eugene Yang"
    ],
    "abstract": "The fundamental property of Cranfield-style evaluations, that system rankings\nare stable even when assessors disagree on individual relevance decisions, was\nvalidated on traditional test collections. However, the paradigm shift towards\nneural retrieval models affected the characteristics of modern test\ncollections, e.g., documents are short, judged with four grades of relevance,\nand information needs have no descriptions or narratives. Under these changes,\nit is unclear whether assessor disagreement remains negligible for system\ncomparisons. We investigate this aspect under the additional condition that the\nfew modern test collections are heavily re-used. Given more possible query\ninterpretations due to less formalized information needs, an ''expiration\ndate'' for test collections might be needed if top-effectiveness requires\noverfitting to a single interpretation of relevance. We run a reproducibility\nstudy and re-annotate the relevance judgments of the 2019 TREC Deep Learning\ntrack. We can reproduce prior work in the neural retrieval setting, showing\nthat assessor disagreement does not affect system rankings. However, we observe\nthat some models substantially degrade with our new relevance judgments, and\nsome have already reached the effectiveness of humans as rankers, providing\nevidence that test collections can expire.",
    "pdf_url": "http://arxiv.org/pdf/2502.20937v1",
    "published": "2025-02-28",
    "source": "arxiv",
    "id": "2502.20937v1",
    "categories": [
      "cs.IR"
    ]
  },
  {
    "title": "Large Language Models Are Innate Crystal Structure Generators",
    "authors": [
      "Jingru Gan",
      "Peichen Zhong",
      "Yuanqi Du",
      "Yanqiao Zhu",
      "Chenru Duan",
      "Haorui Wang",
      "Carla P. Gomes",
      "Kristin A. Persson",
      "Daniel Schwalbe-Koda",
      "Wei Wang"
    ],
    "abstract": "Crystal structure generation is fundamental to materials discovery, enabling\nthe prediction of novel materials with desired properties. While existing\napproaches leverage Large Language Models (LLMs) through extensive fine-tuning\non materials databases, we show that pre-trained LLMs can inherently generate\nstable crystal structures without additional training. Our novel framework\nMatLLMSearch integrates pre-trained LLMs with evolutionary search algorithms,\nachieving a 78.38% metastable rate validated by machine learning interatomic\npotentials and 31.7% DFT-verified stability via quantum mechanical\ncalculations, outperforming specialized models such as CrystalTextLLM. Beyond\ncrystal structure generation, we further demonstrate that our framework can be\nreadily adapted to diverse materials design tasks, including crystal structure\nprediction and multi-objective optimization of properties such as deformation\nenergy and bulk modulus, all without fine-tuning. These results establish\npre-trained LLMs as versatile and effective tools for materials discovery,\nopening up new venues for crystal structure generation with reduced\ncomputational overhead and broader accessibility.",
    "pdf_url": "http://arxiv.org/pdf/2502.20933v1",
    "published": "2025-02-28",
    "source": "arxiv",
    "id": "2502.20933v1",
    "categories": [
      "cond-mat.mtrl-sci",
      "cs.LG"
    ]
  },
  {
    "title": "Goal-Oriented Semantic Communication for Wireless Video Transmission via Generative AI",
    "authors": [
      "Nan Li",
      "Yansha Deng",
      "Dusit Niyato"
    ],
    "abstract": "Efficient video transmission is essential for seamless communication and\ncollaboration within the visually-driven digital landscape. To achieve low\nlatency and high-quality video transmission over a bandwidth-constrained noisy\nwireless channel, we propose a stable diffusion (SD)-based goal-oriented\nsemantic communication (GSC) framework. In this framework, we first design a\nsemantic encoder that effectively identify the keyframes from video and extract\nthe relevant semantic information (SI) to reduce the transmission data size. We\nthen develop a semantic decoder to reconstruct the keyframes from the received\nSI and further generate the full video from the reconstructed keyframes using\nframe interpolation to ensure high-quality reconstruction. Recognizing the\nimpact of wireless channel noise on SI transmission, we also propose an\nSD-based denoiser for GSC (SD-GSC) condition on an instantaneous channel gain\nto remove the channel noise from the received noisy SI under a known channel.\nFor scenarios with an unknown channel, we further propose a parallel SD\ndenoiser for GSC (PSD-GSC) to jointly learn the distribution of channel gains\nand denoise the received SI. It is shown that, with the known channel, our\nproposed SD-GSC outperforms state-of-the-art ADJSCC, Latent-Diff DNSC, DeepWiVe\nand DVST, improving Peak Signal-to-Noise Ratio (PSNR) by 69%, 58%, 33% and 38%,\nreducing mean squared error (MSE) by 52%, 50%, 41% and 45%, and reducing\nFr\\'echet Video Distance (FVD) by 38%, 32%, 22% and 24%, respectively. With the\nunknown channel, our PSD-GSC achieves a 17% improvement in PSNR, a 29%\nreduction in MSE, and a 19% reduction in FVD compared to MMSE\nequalizer-enhanced SD-GSC. These significant performance improvements\ndemonstrate the robustness and superiority of our proposed methods in enhancing\nvideo transmission quality and efficiency under various channel conditions.",
    "pdf_url": "http://arxiv.org/pdf/2502.20927v1",
    "published": "2025-02-28",
    "source": "arxiv",
    "id": "2502.20927v1",
    "categories": [
      "eess.IV"
    ]
  },
  {
    "title": "Amortized Conditional Independence Testing",
    "authors": [
      "Bao Duong",
      "Nu Hoang",
      "Thin Nguyen"
    ],
    "abstract": "Testing for the conditional independence structure in data is a fundamental\nand critical task in statistics and machine learning, which finds natural\napplications in causal discovery - a highly relevant problem to many scientific\ndisciplines. Existing methods seek to design explicit test statistics that\nquantify the degree of conditional dependence, which is highly challenging yet\ncannot capture nor utilize prior knowledge in a data-driven manner. In this\nstudy, an entirely new approach is introduced, where we instead propose to\namortize conditional independence testing and devise ACID - a novel\ntransformer-based neural network architecture that learns to test for\nconditional independence. ACID can be trained on synthetic data in a supervised\nlearning fashion, and the learned model can then be applied to any dataset of\nsimilar natures or adapted to new domains by fine-tuning with a negligible\ncomputational cost. Our extensive empirical evaluations on both synthetic and\nreal data reveal that ACID consistently achieves state-of-the-art performance\nagainst existing baselines under multiple metrics, and is able to generalize\nrobustly to unseen sample sizes, dimensionalities, as well as non-linearities\nwith a remarkably low inference time.",
    "pdf_url": "http://arxiv.org/pdf/2502.20925v1",
    "published": "2025-02-28",
    "source": "arxiv",
    "id": "2502.20925v1",
    "categories": [
      "stat.ML",
      "cs.LG"
    ]
  },
  {
    "title": "Everything, Everywhere, All at Once: Is Mechanistic Interpretability Identifiable?",
    "authors": [
      "Maxime Méloux",
      "Silviu Maniu",
      "François Portet",
      "Maxime Peyrard"
    ],
    "abstract": "As AI systems are used in high-stakes applications, ensuring interpretability\nis crucial. Mechanistic Interpretability (MI) aims to reverse-engineer neural\nnetworks by extracting human-understandable algorithms to explain their\nbehavior. This work examines a key question: for a given behavior, and under\nMI's criteria, does a unique explanation exist? Drawing on identifiability in\nstatistics, where parameters are uniquely inferred under specific assumptions,\nwe explore the identifiability of MI explanations.\n  We identify two main MI strategies: (1) \"where-then-what,\" which isolates a\ncircuit replicating model behavior before interpreting it, and (2)\n\"what-then-where,\" which starts with candidate algorithms and searches for\nneural activation subspaces implementing them, using causal alignment.\n  We test both strategies on Boolean functions and small multi-layer\nperceptrons, fully enumerating candidate explanations. Our experiments reveal\nsystematic non-identifiability: multiple circuits can replicate behavior, a\ncircuit can have multiple interpretations, several algorithms can align with\nthe network, and one algorithm can align with different subspaces.\n  Is uniqueness necessary? A pragmatic approach may require only predictive and\nmanipulability standards. If uniqueness is essential for understanding,\nstricter criteria may be needed. We also reference the inner interpretability\nframework, which validates explanations through multiple criteria. This work\ncontributes to defining explanation standards in AI.",
    "pdf_url": "http://arxiv.org/pdf/2502.20914v1",
    "published": "2025-02-28",
    "source": "arxiv",
    "id": "2502.20914v1",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL"
    ]
  },
  {
    "title": "DexGraspVLA: A Vision-Language-Action Framework Towards General Dexterous Grasping",
    "authors": [
      "Yifan Zhong",
      "Xuchuan Huang",
      "Ruochong Li",
      "Ceyao Zhang",
      "Yitao Liang",
      "Yaodong Yang",
      "Yuanpei Chen"
    ],
    "abstract": "Dexterous grasping remains a fundamental yet challenging problem in robotics.\nA general-purpose robot must be capable of grasping diverse objects in\narbitrary scenarios. However, existing research typically relies on specific\nassumptions, such as single-object settings or limited environments, leading to\nconstrained generalization. Our solution is DexGraspVLA, a hierarchical\nframework that utilizes a pre-trained Vision-Language model as the high-level\ntask planner and learns a diffusion-based policy as the low-level Action\ncontroller. The key insight lies in iteratively transforming diverse language\nand visual inputs into domain-invariant representations, where imitation\nlearning can be effectively applied due to the alleviation of domain shift.\nThus, it enables robust generalization across a wide range of real-world\nscenarios. Notably, our method achieves a 90+% success rate under thousands of\nunseen object, lighting, and background combinations in a ``zero-shot''\nenvironment. Empirical analysis further confirms the consistency of internal\nmodel behavior across environmental variations, thereby validating our design\nand explaining its generalization performance. We hope our work can be a step\nforward in achieving general dexterous grasping. Our demo and code can be found\nat https://dexgraspvla.github.io/.",
    "pdf_url": "http://arxiv.org/pdf/2502.20900v1",
    "published": "2025-02-28",
    "source": "arxiv",
    "id": "2502.20900v1",
    "categories": [
      "cs.RO",
      "cs.AI"
    ]
  },
  {
    "title": "Beyond Demographics: Fine-tuning Large Language Models to Predict Individuals' Subjective Text Perceptions",
    "authors": [
      "Matthias Orlikowski",
      "Jiaxin Pei",
      "Paul Röttger",
      "Philipp Cimiano",
      "David Jurgens",
      "Dirk Hovy"
    ],
    "abstract": "People naturally vary in their annotations for subjective questions and some\nof this variation is thought to be due to the person's sociodemographic\ncharacteristics. LLMs have also been used to label data, but recent work has\nshown that models perform poorly when prompted with sociodemographic\nattributes, suggesting limited inherent sociodemographic knowledge. Here, we\nask whether LLMs can be trained to be accurate sociodemographic models of\nannotator variation. Using a curated dataset of five tasks with standardized\nsociodemographics, we show that models do improve in sociodemographic prompting\nwhen trained but that this performance gain is largely due to models learning\nannotator-specific behaviour rather than sociodemographic patterns. Across all\ntasks, our results suggest that models learn little meaningful connection\nbetween sociodemographics and annotation, raising doubts about the current use\nof LLMs for simulating sociodemographic variation and behaviour.",
    "pdf_url": "http://arxiv.org/pdf/2502.20897v1",
    "published": "2025-02-28",
    "source": "arxiv",
    "id": "2502.20897v1",
    "categories": [
      "cs.CL",
      "I.2.7"
    ]
  },
  {
    "title": "A Fused Gromov-Wasserstein Approach to Subgraph Contrastive Learning",
    "authors": [
      "Amadou S. Sangare",
      "Nicolas Dunou",
      "Jhony H. Giraldo",
      "Fragkiskos D. Malliaros"
    ],
    "abstract": "Self-supervised learning has become a key method for training deep learning\nmodels when labeled data is scarce or unavailable. While graph machine learning\nholds great promise across various domains, the design of effective pretext\ntasks for self-supervised graph representation learning remains challenging.\nContrastive learning, a popular approach in graph self-supervised learning,\nleverages positive and negative pairs to compute a contrastive loss function.\nHowever, current graph contrastive learning methods often struggle to fully use\nstructural patterns and node similarities. To address these issues, we present\na new method called Fused Gromov Wasserstein Subgraph Contrastive Learning\n(FOSSIL). Our model integrates node-level and subgraph-level contrastive\nlearning, seamlessly combining a standard node-level contrastive loss with the\nFused Gromov-Wasserstein distance. This combination helps our method capture\nboth node features and graph structure together. Importantly, our approach\nworks well with both homophilic and heterophilic graphs and can dynamically\ncreate views for generating positive and negative pairs. Through extensive\nexperiments on benchmark graph datasets, we show that FOSSIL outperforms or\nachieves competitive performance compared to current state-of-the-art methods.",
    "pdf_url": "http://arxiv.org/pdf/2502.20885v1",
    "published": "2025-02-28",
    "source": "arxiv",
    "id": "2502.20885v1",
    "categories": [
      "cs.LG",
      "cs.AI"
    ]
  },
  {
    "title": "Managing Federated Learning on Decentralized Infrastructures as a Reputation-based Collaborative Workflow",
    "authors": [
      "Yuandou Wang",
      "Zhiming Zhao"
    ],
    "abstract": "Federated Learning (FL) has recently emerged as a collaborative learning\nparadigm that can train a global model among distributed participants without\nraw data exchange to satisfy varying requirements. However, there remain\nseveral challenges in managing FL in a decentralized environment, where\npotential candidates exhibit varying motivation levels and reliability in the\nFL process management: 1) reconfiguring and automating diverse FL workflows are\nchallenging, 2) difficulty in incentivizing potential candidates with\nhigh-quality data and high-performance computing to join the FL, and 3)\ndifficulty in ensuring reliable system operations, which may be vulnerable to\nvarious malicious attacks from FL participants. To address these challenges, we\nfocus on the workflow-based methods to automate diverse FL pipelines and\npropose a novel approach to facilitate reliable FL system operations with\nrobust mechanism design and blockchain technology by considering a contribution\nmodel, fair committee selection, dynamic reputation updates, reward and penalty\nmethods, and contract theory. Moreover, we study the optimality of contracts to\nguide the design and implementation of smart contracts that can be deployed in\nblockchain networks. We perform theoretical analysis and conduct extensive\nsimulation experiments to validate the proposed approach. The results show that\nour incentive mechanisms are feasible and can achieve fairness in reward\nallocation in unreliable environment settings.",
    "pdf_url": "http://arxiv.org/pdf/2502.20882v1",
    "published": "2025-02-28",
    "source": "arxiv",
    "id": "2502.20882v1",
    "categories": [
      "cs.DC"
    ]
  }
]